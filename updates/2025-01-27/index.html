<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>2025-01-27科研追新(公众号) - LLM-DailyDigest</title><meta name="author" content="">
<meta name="author-link" content="">
<meta name="description" content="2025-01-27
统计1-26-14:00～1-27-11:00的相关新进展
1. 公众号
1.1 量子位

中科院院士鄂维南、字节AI实验室总监李航领衔，推出高级论文搜索Agent。名为PaSa，两个Agent分别执行多轮搜索和判断论文是否满足查询要求的任务，模仿人类复杂学术搜索行为。

项目官网: pasa-agent.ai
GitHub仓库: https://github.com/bytedance/pasa
arXiv技术论文: https://arxiv.org/pdf/2501.10120



1.2 新智元


TinyZero，采用了R1-Zero算法——给定一个基础语言模型、提示和真实奖励信号，运行强化学习。然后，团队将其应用在CountDown游戏中（这是一个玩家使用基础算术运算，将数字组合以达到目标数字的游戏）。


港科大助理教授何俊贤的团队（共同一作黄裕振、Weihao Zeng），只用了8K个样本，就在7B模型上复刻出了DeepSeek-R1-Zero和DeepSeek-R1的训练。

论文：7B Model and 8K Examples: EmergingReasoning with ReinforcementLearning is Both Effective andEfficient
Github: https://github.com/hkust-nlp/simpleRL-reason
这一表现不仅超越了Qwen2.5-Math-7B-Instruct，并且还可以和使用超过50倍数据量和更复杂组件的PRIME和rStar-MATH相媲美



TheAgentCompany：在重要的实际任务上对代理进行LLM基准测试

论文链接：https://arxiv.org/abs/2412.14161
该研究开发了一个全部由大模型驱动的智能体组成的虚拟软件开发公司The Agent Company，与人类员工类似，智能体需要执行软件开发、项目管理、财务分析等典型的商业环境中的任务。
除了创建175个多样化、真实、专业，且与真实公司运营模式一致的任务，这项研究还创建了不同任务对应的评估器，在每个任务中的多个阶段设置检查点。智能体每完成一步任务，都会获得相应的积分（类似于现实员工的KPI）；而当智能体只是部分正确地给出回答时，也会给予其部分过程分。



Humanity’s Last Exam  新基准全称「人类最后一次考试」

包含3000个问题，由数百位领域专家开发，用于追寻人类知识推理的边界。
目前，最好的模型，准确率也小于10%，而且自信「过头」。
项目链接：https://lastexam.ai/
paper：https://arxiv.org/abs/2501.14249
code：https://github.com/centerforaisafety/hle
dataset：https://huggingface.co/datasets/cais/hle
为了评估AI的能力的进展，已发布了多个数据集，针对语言模型，根据「Paper with code」网站统计，就有165个相关数据集。（Language Modellling）



AI走的是死路？专家剖析致命缺陷，不具备大规模应用前提 https://mp.weixin.qq.com/s/jJL6G2GJvv4t3md_8n4u6Q


可以根据LLMs上下文设计好的问题吗？ https://arxiv.org/abs/2501.03491

这篇文章首次揭示了LLMs在问题生成中的偏好，通过引入自动评估流程，扩展了现有的统计问题质量标准，研究发现为评估下游应用（如RAG系统和幻觉检测）的提示工程优化提供了经验，可以防止在不当情境下的滥用，更深入地了解LLMs在问题生成中的行为倾向。



1.3 机器之心

InfAlign: Inference-aware language model alignment

https://arxiv.org/abs/2412.19792
执行推理时能对齐语言模型吗？谷歌InfAlign带来一种对齐新思路 https://mp.weixin.qq.com/s/XIkTBTh9GUeaHXX-b26u_A


" /><meta name="keywords" content='Hugo, FixIt' />
  <meta itemprop="name" content="2025-01-27科研追新(公众号)">
  <meta itemprop="description" content="2025-01-27 统计1-26-14:00～1-27-11:00的相关新进展
1. 公众号 1.1 量子位 中科院院士鄂维南、字节AI实验室总监李航领衔，推出高级论文搜索Agent。名为PaSa，两个Agent分别执行多轮搜索和判断论文是否满足查询要求的任务，模仿人类复杂学术搜索行为。 项目官网: pasa-agent.ai GitHub仓库: https://github.com/bytedance/pasa arXiv技术论文: https://arxiv.org/pdf/2501.10120 1.2 新智元 TinyZero，采用了R1-Zero算法——给定一个基础语言模型、提示和真实奖励信号，运行强化学习。然后，团队将其应用在CountDown游戏中（这是一个玩家使用基础算术运算，将数字组合以达到目标数字的游戏）。
港科大助理教授何俊贤的团队（共同一作黄裕振、Weihao Zeng），只用了8K个样本，就在7B模型上复刻出了DeepSeek-R1-Zero和DeepSeek-R1的训练。
论文：7B Model and 8K Examples: EmergingReasoning with ReinforcementLearning is Both Effective andEfficient Github: https://github.com/hkust-nlp/simpleRL-reason 这一表现不仅超越了Qwen2.5-Math-7B-Instruct，并且还可以和使用超过50倍数据量和更复杂组件的PRIME和rStar-MATH相媲美 TheAgentCompany：在重要的实际任务上对代理进行LLM基准测试
论文链接：https://arxiv.org/abs/2412.14161 该研究开发了一个全部由大模型驱动的智能体组成的虚拟软件开发公司The Agent Company，与人类员工类似，智能体需要执行软件开发、项目管理、财务分析等典型的商业环境中的任务。 除了创建175个多样化、真实、专业，且与真实公司运营模式一致的任务，这项研究还创建了不同任务对应的评估器，在每个任务中的多个阶段设置检查点。智能体每完成一步任务，都会获得相应的积分（类似于现实员工的KPI）；而当智能体只是部分正确地给出回答时，也会给予其部分过程分。 Humanity’s Last Exam 新基准全称「人类最后一次考试」
包含3000个问题，由数百位领域专家开发，用于追寻人类知识推理的边界。 目前，最好的模型，准确率也小于10%，而且自信「过头」。 项目链接：https://lastexam.ai/ paper：https://arxiv.org/abs/2501.14249 code：https://github.com/centerforaisafety/hle dataset：https://huggingface.co/datasets/cais/hle 为了评估AI的能力的进展，已发布了多个数据集，针对语言模型，根据「Paper with code」网站统计，就有165个相关数据集。（Language Modellling） AI走的是死路？专家剖析致命缺陷，不具备大规模应用前提 https://mp.weixin.qq.com/s/jJL6G2GJvv4t3md_8n4u6Q
可以根据LLMs上下文设计好的问题吗？ https://arxiv.org/abs/2501.03491
这篇文章首次揭示了LLMs在问题生成中的偏好，通过引入自动评估流程，扩展了现有的统计问题质量标准，研究发现为评估下游应用（如RAG系统和幻觉检测）的提示工程优化提供了经验，可以防止在不当情境下的滥用，更深入地了解LLMs在问题生成中的行为倾向。 1.3 机器之心 InfAlign: Inference-aware language model alignment https://arxiv.org/abs/2412.19792 执行推理时能对齐语言模型吗？谷歌InfAlign带来一种对齐新思路 https://mp.weixin.qq.com/s/XIkTBTh9GUeaHXX-b26u_A">
  <meta itemprop="datePublished" content="2025-01-27T00:00:00+08:00">
  <meta itemprop="dateModified" content="2025-01-27T00:00:00+08:00">
  <meta itemprop="wordCount" content="68"><meta property="og:url" content="http://localhost:1313/updates/2025-01-27/">
  <meta property="og:site_name" content="LLM-DailyDigest">
  <meta property="og:title" content="2025-01-27科研追新(公众号)">
  <meta property="og:description" content="2025-01-27 统计1-26-14:00～1-27-11:00的相关新进展
1. 公众号 1.1 量子位 中科院院士鄂维南、字节AI实验室总监李航领衔，推出高级论文搜索Agent。名为PaSa，两个Agent分别执行多轮搜索和判断论文是否满足查询要求的任务，模仿人类复杂学术搜索行为。 项目官网: pasa-agent.ai GitHub仓库: https://github.com/bytedance/pasa arXiv技术论文: https://arxiv.org/pdf/2501.10120 1.2 新智元 TinyZero，采用了R1-Zero算法——给定一个基础语言模型、提示和真实奖励信号，运行强化学习。然后，团队将其应用在CountDown游戏中（这是一个玩家使用基础算术运算，将数字组合以达到目标数字的游戏）。
港科大助理教授何俊贤的团队（共同一作黄裕振、Weihao Zeng），只用了8K个样本，就在7B模型上复刻出了DeepSeek-R1-Zero和DeepSeek-R1的训练。
论文：7B Model and 8K Examples: EmergingReasoning with ReinforcementLearning is Both Effective andEfficient Github: https://github.com/hkust-nlp/simpleRL-reason 这一表现不仅超越了Qwen2.5-Math-7B-Instruct，并且还可以和使用超过50倍数据量和更复杂组件的PRIME和rStar-MATH相媲美 TheAgentCompany：在重要的实际任务上对代理进行LLM基准测试
论文链接：https://arxiv.org/abs/2412.14161 该研究开发了一个全部由大模型驱动的智能体组成的虚拟软件开发公司The Agent Company，与人类员工类似，智能体需要执行软件开发、项目管理、财务分析等典型的商业环境中的任务。 除了创建175个多样化、真实、专业，且与真实公司运营模式一致的任务，这项研究还创建了不同任务对应的评估器，在每个任务中的多个阶段设置检查点。智能体每完成一步任务，都会获得相应的积分（类似于现实员工的KPI）；而当智能体只是部分正确地给出回答时，也会给予其部分过程分。 Humanity’s Last Exam 新基准全称「人类最后一次考试」
包含3000个问题，由数百位领域专家开发，用于追寻人类知识推理的边界。 目前，最好的模型，准确率也小于10%，而且自信「过头」。 项目链接：https://lastexam.ai/ paper：https://arxiv.org/abs/2501.14249 code：https://github.com/centerforaisafety/hle dataset：https://huggingface.co/datasets/cais/hle 为了评估AI的能力的进展，已发布了多个数据集，针对语言模型，根据「Paper with code」网站统计，就有165个相关数据集。（Language Modellling） AI走的是死路？专家剖析致命缺陷，不具备大规模应用前提 https://mp.weixin.qq.com/s/jJL6G2GJvv4t3md_8n4u6Q
可以根据LLMs上下文设计好的问题吗？ https://arxiv.org/abs/2501.03491
这篇文章首次揭示了LLMs在问题生成中的偏好，通过引入自动评估流程，扩展了现有的统计问题质量标准，研究发现为评估下游应用（如RAG系统和幻觉检测）的提示工程优化提供了经验，可以防止在不当情境下的滥用，更深入地了解LLMs在问题生成中的行为倾向。 1.3 机器之心 InfAlign: Inference-aware language model alignment https://arxiv.org/abs/2412.19792 执行推理时能对齐语言模型吗？谷歌InfAlign带来一种对齐新思路 https://mp.weixin.qq.com/s/XIkTBTh9GUeaHXX-b26u_A">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="updates">
    <meta property="article:published_time" content="2025-01-27T00:00:00+08:00">
    <meta property="article:modified_time" content="2025-01-27T00:00:00+08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="2025-01-27科研追新(公众号)">
  <meta name="twitter:description" content="2025-01-27 统计1-26-14:00～1-27-11:00的相关新进展
1. 公众号 1.1 量子位 中科院院士鄂维南、字节AI实验室总监李航领衔，推出高级论文搜索Agent。名为PaSa，两个Agent分别执行多轮搜索和判断论文是否满足查询要求的任务，模仿人类复杂学术搜索行为。 项目官网: pasa-agent.ai GitHub仓库: https://github.com/bytedance/pasa arXiv技术论文: https://arxiv.org/pdf/2501.10120 1.2 新智元 TinyZero，采用了R1-Zero算法——给定一个基础语言模型、提示和真实奖励信号，运行强化学习。然后，团队将其应用在CountDown游戏中（这是一个玩家使用基础算术运算，将数字组合以达到目标数字的游戏）。
港科大助理教授何俊贤的团队（共同一作黄裕振、Weihao Zeng），只用了8K个样本，就在7B模型上复刻出了DeepSeek-R1-Zero和DeepSeek-R1的训练。
论文：7B Model and 8K Examples: EmergingReasoning with ReinforcementLearning is Both Effective andEfficient Github: https://github.com/hkust-nlp/simpleRL-reason 这一表现不仅超越了Qwen2.5-Math-7B-Instruct，并且还可以和使用超过50倍数据量和更复杂组件的PRIME和rStar-MATH相媲美 TheAgentCompany：在重要的实际任务上对代理进行LLM基准测试
论文链接：https://arxiv.org/abs/2412.14161 该研究开发了一个全部由大模型驱动的智能体组成的虚拟软件开发公司The Agent Company，与人类员工类似，智能体需要执行软件开发、项目管理、财务分析等典型的商业环境中的任务。 除了创建175个多样化、真实、专业，且与真实公司运营模式一致的任务，这项研究还创建了不同任务对应的评估器，在每个任务中的多个阶段设置检查点。智能体每完成一步任务，都会获得相应的积分（类似于现实员工的KPI）；而当智能体只是部分正确地给出回答时，也会给予其部分过程分。 Humanity’s Last Exam 新基准全称「人类最后一次考试」
包含3000个问题，由数百位领域专家开发，用于追寻人类知识推理的边界。 目前，最好的模型，准确率也小于10%，而且自信「过头」。 项目链接：https://lastexam.ai/ paper：https://arxiv.org/abs/2501.14249 code：https://github.com/centerforaisafety/hle dataset：https://huggingface.co/datasets/cais/hle 为了评估AI的能力的进展，已发布了多个数据集，针对语言模型，根据「Paper with code」网站统计，就有165个相关数据集。（Language Modellling） AI走的是死路？专家剖析致命缺陷，不具备大规模应用前提 https://mp.weixin.qq.com/s/jJL6G2GJvv4t3md_8n4u6Q
可以根据LLMs上下文设计好的问题吗？ https://arxiv.org/abs/2501.03491
这篇文章首次揭示了LLMs在问题生成中的偏好，通过引入自动评估流程，扩展了现有的统计问题质量标准，研究发现为评估下游应用（如RAG系统和幻觉检测）的提示工程优化提供了经验，可以防止在不当情境下的滥用，更深入地了解LLMs在问题生成中的行为倾向。 1.3 机器之心 InfAlign: Inference-aware language model alignment https://arxiv.org/abs/2412.19792 执行推理时能对齐语言模型吗？谷歌InfAlign带来一种对齐新思路 https://mp.weixin.qq.com/s/XIkTBTh9GUeaHXX-b26u_A">
<meta name="application-name" content="LLM-DailyDigest">
<meta name="apple-mobile-web-app-title" content="LLM-DailyDigest"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" href="http://localhost:1313/updates/2025-01-27/" /><link rel="prev" href="http://localhost:1313/updates/2025-01-26/" /><link rel="next" href="http://localhost:1313/updates/arxiv_daily_report_2025-01-27/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "2025-01-27科研追新(公众号)",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "http:\/\/localhost:1313\/updates\/2025-01-27\/"
    },"genre": "updates","wordcount":  68 ,
    "url": "http:\/\/localhost:1313\/updates\/2025-01-27\/","datePublished": "2025-01-27T00:00:00+08:00","dateModified": "2025-01-27T00:00:00+08:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "Author"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/" title="LLM-DailyDigest"><img loading="lazy" src="/fixit.svg" data-title="LLM-DailyDigest" data-alt="LLM-DailyDigest" class="logo" style="background: url(/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-desktop" class="typeit"></span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/llm-dailydigest"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/resources/"
                
                
              >资源</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/topic/"
                
                
              >主题</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/updates/"
                
                
              >日报</a></li><li class="menu-item delimiter"></li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="LLM-DailyDigest"><img loading="lazy" src="/fixit.svg" data-title="/fixit.svg" data-alt="/fixit.svg" class="logo" style="background: url(/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-title-mobile" class="typeit"></span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/llm-dailydigest"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/resources/"
                  
                  
                >资源</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/topic/"
                  
                  
                >主题</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/updates/"
                  
                  
                >日报</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><main class="container"><aside class="toc" id="toc-auto"><h2 class="toc-title">Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom">
    </aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span>2025-01-27科研追新(公众号)</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      </span></span></div>
      <div class="post-meta-line"><span title="published on 2025-01-27 00:00:00"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden="true"></i><time datetime="2025-01-27">2025-01-27</time></span>&nbsp;<span title="Updated on 2025-01-27 00:00:00"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden="true"></i><time datetime="2025-01-27">2025-01-27</time></span>&nbsp;<span title="68 words"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>About 100 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>One minute</span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" data-kept="false">
        <div class="details-summary toc-title">
          <span>Contents</span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-公众号">1. 公众号</a>
      <ul>
        <li><a href="#11-量子位">1.1 量子位</a></li>
        <li><a href="#12-新智元">1.2 新智元</a></li>
        <li><a href="#13-机器之心">1.3 机器之心</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h1 id="2025-01-27">2025-01-27</h1>
<p>统计1-26-14:00～1-27-11:00的相关新进展</p>
<h2 id="1-公众号">1. 公众号</h2>
<h3 id="11-量子位">1.1 量子位</h3>
<ol>
<li>中科院院士<strong>鄂维南</strong>、字节AI实验室总监<strong>李航</strong>领衔，推出高级论文搜索Agent。名为<strong>PaSa</strong>，两个Agent分别执行多轮搜索和判断论文是否满足查询要求的任务，模仿人类复杂学术搜索行为。
<ol>
<li>项目官网: <a href="pasa-agent.ai">pasa-agent.ai</a></li>
<li>GitHub仓库: <a href="https://github.com/bytedance/pasa"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/bytedance/pasa</a></li>
<li>arXiv技术论文: <a href="https://arxiv.org/pdf/2501.10120"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/pdf/2501.10120</a></li>
</ol>
</li>
</ol>
<h3 id="12-新智元">1.2 新智元</h3>
<ol>
<li>
<p>TinyZero，采用了R1-Zero算法——给定一个基础语言模型、提示和真实奖励信号，运行强化学习。然后，团队将其应用在CountDown游戏中（这是一个玩家使用基础算术运算，将数字组合以达到目标数字的游戏）。</p>
</li>
<li>
<p>港科大助理教授何俊贤的团队（共同一作黄裕振、Weihao Zeng），只用了8K个样本，就在7B模型上复刻出了DeepSeek-R1-Zero和DeepSeek-R1的训练。</p>
<ol>
<li>论文：7B Model and 8K Examples: EmergingReasoning with ReinforcementLearning is Both Effective andEfficient</li>
<li>Github: <a href="https://github.com/hkust-nlp/simpleRL-reason"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/hkust-nlp/simpleRL-reason</a></li>
<li>这一表现不仅超越了Qwen2.5-Math-7B-Instruct，并且还可以和使用超过50倍数据量和更复杂组件的PRIME和rStar-MATH相媲美</li>
</ol>
</li>
<li>
<p>TheAgentCompany：在重要的实际任务上对代理进行LLM基准测试</p>
<ol>
<li>论文链接：https://arxiv.org/abs/2412.14161</li>
<li>该研究开发了一个全部由大模型驱动的智能体组成的虚拟软件开发公司The Agent Company，与人类员工类似，智能体需要执行软件开发、项目管理、财务分析等典型的商业环境中的任务。</li>
<li>除了创建175个多样化、真实、专业，且与真实公司运营模式一致的任务，这项研究还创建了不同任务对应的评估器，在每个任务中的多个阶段设置检查点。智能体每完成一步任务，都会获得相应的积分（类似于现实员工的KPI）；而当智能体只是部分正确地给出回答时，也会给予其部分过程分。</li>
</ol>
</li>
<li>
<p>Humanity’s Last Exam  新基准全称「人类最后一次考试」</p>
<ol>
<li>包含3000个问题，由数百位领域专家开发，用于追寻人类知识推理的边界。</li>
<li>目前，最好的模型，准确率也小于10%，而且自信「过头」。</li>
<li>项目链接：https://lastexam.ai/</li>
<li>paper：https://arxiv.org/abs/2501.14249</li>
<li>code：https://github.com/centerforaisafety/hle</li>
<li>dataset：https://huggingface.co/datasets/cais/hle</li>
<li>为了评估AI的能力的进展，已发布了多个数据集，针对语言模型，根据「Paper with code」网站统计，就有165个相关数据集。（Language Modellling）</li>
</ol>
</li>
<li>
<p>AI走的是死路？专家剖析致命缺陷，不具备大规模应用前提 <a href="https://mp.weixin.qq.com/s/jJL6G2GJvv4t3md_8n4u6Q"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/jJL6G2GJvv4t3md_8n4u6Q</a></p>
</li>
<li>
<p>可以根据LLMs上下文设计好的问题吗？ <a href="https://arxiv.org/abs/2501.03491"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2501.03491</a></p>
<ol>
<li>这篇文章首次揭示了LLMs在问题生成中的偏好，通过引入自动评估流程，扩展了现有的统计问题质量标准，研究发现为评估下游应用（如RAG系统和幻觉检测）的提示工程优化提供了经验，可以防止在不当情境下的滥用，更深入地了解LLMs在问题生成中的行为倾向。</li>
</ol>
</li>
</ol>
<h3 id="13-机器之心">1.3 机器之心</h3>
<ol>
<li>InfAlign: Inference-aware language model alignment
<ol>
<li><a href="https://arxiv.org/abs/2412.19792"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2412.19792</a></li>
<li>执行推理时能对齐语言模型吗？谷歌InfAlign带来一种对齐新思路 <a href="https://mp.weixin.qq.com/s/XIkTBTh9GUeaHXX-b26u_A"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/XIkTBTh9GUeaHXX-b26u_A</a></li>
</ol>
</li>
</ol>
</div></article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">Public - 2025</span><span class="author" itemprop="copyrightHolder">
              <a href="/"></a></span></div><div class="footer-line statistics"></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">Theme FixIt works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="preload" href="/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-desktop":"LLM-DailyDigest 大模型研究日报","typeit-header-title-mobile":"LLM-DailyDigest 大模型研究日报"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-desktop":["typeit-header-desktop"],"typeit-header-title-mobile":["typeit-header-title-mobile"]},"duration":-1,"loop":false,"speed":100}};</script><script src="/js/theme.min.js" defer></script></body>
</html>
