<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head><script src="/LLMDailyDigestWeb/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=LLMDailyDigestWeb/livereload" data-no-instant defer></script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>2025-08-31to09-14科研追新 - LLM-DailyDigest</title><meta name="author" content="">
<meta name="author-link" content="">
<meta name="description" content="2025-08-31to09-14科研追新
1. 源数据
1.1 公众号
1.1.1 量子位


科研学术，现在可以百度AI一下了


在Lean中形式化强素数定理（Prime Number Theorem，PNT）：Gauss是首个可以协助顶级数学家进行形式验证的自动形式化（autoformalization）Agent


AI解数学题只靠最后一个token


https://mp.weixin.qq.com/s/eloQFjuAgdb-Tc3nvnezsg提出了一种新的强化学习范式——基于历史信息来端到端地加速强化学习效率。


西湖大学自然语言处理实验室推出了首个AI生成学术成果的开放预印本平台AiraXiv，以及首个模拟人类专家思考链的AI审稿人系统DeepReview。
AiraXiv平台地址：https://airaxiv.com
DeepReview论文地址：https://arxiv.org/abs/2503.08569


华为openPangu-DeepDiver开源，深度研究多Agent系统，支持百步以上工具推理，万字报告快速生成


Qwen3-Next发布


Meta超级智能实验室（MSL）论文《Language Self-Play For Data-Free Training》让模型在博弈中学习


华为最新发布DeepDiver-V2原生多智能体系统。


攻克AI过度思考难题！美团新研究让通过“可验证”过程奖励激活LRM的高效推理：可验证的过程奖励机制（VSRM），鼓励CoT中的“有效步骤”，惩戒“无效步骤”，最大限度保持性能的同时，实现高效推理。


OpenAI的GPT-5、GPT-4o，还是谷歌Gemini、Anthropic Claude，甚至国内的Qwen、LLaVA，在面对一些“看得见但读不懂”的文字时，全都表现极差，直接“翻车”。


调整训练数据出场顺序，大模型就能变聪明！无需扩大模型/数据规模


7个AI玩狼人杀，GPT-5获断崖式MVP，Kimi手段激进


1.1.2 机器之心

LLaSO 横空出世：逻辑智能推出全球首个完全开源语音大模型框架，定义 LSLM 研究新基准
UQ（Unsolved Questions），这是一个由 500 道题组成的测试集，涵盖计算机理论、数学、科幻、历史等主题，用于考察模型在推理、事实准确性以及浏览等方面的能力。大模型碰到真难题了，测了500道，o3 Pro仅通过15%。
清华、上海AI Lab等顶级团队发布推理模型RL超全综述，探索通往超级智能之路
攻克大模型「表格盲区」！ST-Raptor框架发布，实现复杂半结构化表格的精准理解与信息抽取
交互扩展时代来临:创智复旦字节重磅发布AgentGym-RL，昇腾加持，开创智能体训练新范式
刚刚，Thinking Machines Lab首次发长文，揭开LLM推理不确定性真相
谷歌AI新里程碑：一个能「做研究」的系统诞生了，用LLM&#43;树搜索编写专家级软件
SFT远不如RL？永不过时的剃刀原则打开「终身学习」大模型训练的大门
国内外AI大厂重押，初创梭哈，谁能凭「记忆」成为下一个「DeepSeek」？
不止会动嘴，还会「思考」！字节跳动发布OmniHuman-1.5，让虚拟人拥有逻辑灵魂
自搜索强化学习SSRL：Agentic RL的Sim2Real时刻

1.1.3 新智元
1.1.4 AGI Hunt
1.1.5 其他
1.2 Arxiv
1.2.1 Computation and Language
From：https:// /arxiv/cs.CL" /><meta name="keywords" content='Hugo, FixIt' />
  <meta itemprop="name" content="2025-08-31to09-14科研追新">
  <meta itemprop="description" content="2025-08-31to09-14科研追新 1. 源数据 1.1 公众号 1.1.1 量子位 科研学术，现在可以百度AI一下了
在Lean中形式化强素数定理（Prime Number Theorem，PNT）：Gauss是首个可以协助顶级数学家进行形式验证的自动形式化（autoformalization）Agent
AI解数学题只靠最后一个token
https://mp.weixin.qq.com/s/eloQFjuAgdb-Tc3nvnezsg提出了一种新的强化学习范式——基于历史信息来端到端地加速强化学习效率。
西湖大学自然语言处理实验室推出了首个AI生成学术成果的开放预印本平台AiraXiv，以及首个模拟人类专家思考链的AI审稿人系统DeepReview。
AiraXiv平台地址：https://airaxiv.com DeepReview论文地址：https://arxiv.org/abs/2503.08569
华为openPangu-DeepDiver开源，深度研究多Agent系统，支持百步以上工具推理，万字报告快速生成
Qwen3-Next发布
Meta超级智能实验室（MSL）论文《Language Self-Play For Data-Free Training》让模型在博弈中学习
华为最新发布DeepDiver-V2原生多智能体系统。
攻克AI过度思考难题！美团新研究让通过“可验证”过程奖励激活LRM的高效推理：可验证的过程奖励机制（VSRM），鼓励CoT中的“有效步骤”，惩戒“无效步骤”，最大限度保持性能的同时，实现高效推理。
OpenAI的GPT-5、GPT-4o，还是谷歌Gemini、Anthropic Claude，甚至国内的Qwen、LLaVA，在面对一些“看得见但读不懂”的文字时，全都表现极差，直接“翻车”。
调整训练数据出场顺序，大模型就能变聪明！无需扩大模型/数据规模
7个AI玩狼人杀，GPT-5获断崖式MVP，Kimi手段激进
1.1.2 机器之心 LLaSO 横空出世：逻辑智能推出全球首个完全开源语音大模型框架，定义 LSLM 研究新基准 UQ（Unsolved Questions），这是一个由 500 道题组成的测试集，涵盖计算机理论、数学、科幻、历史等主题，用于考察模型在推理、事实准确性以及浏览等方面的能力。大模型碰到真难题了，测了500道，o3 Pro仅通过15%。 清华、上海AI Lab等顶级团队发布推理模型RL超全综述，探索通往超级智能之路 攻克大模型「表格盲区」！ST-Raptor框架发布，实现复杂半结构化表格的精准理解与信息抽取 交互扩展时代来临:创智复旦字节重磅发布AgentGym-RL，昇腾加持，开创智能体训练新范式 刚刚，Thinking Machines Lab首次发长文，揭开LLM推理不确定性真相 谷歌AI新里程碑：一个能「做研究」的系统诞生了，用LLM&#43;树搜索编写专家级软件 SFT远不如RL？永不过时的剃刀原则打开「终身学习」大模型训练的大门 国内外AI大厂重押，初创梭哈，谁能凭「记忆」成为下一个「DeepSeek」？ 不止会动嘴，还会「思考」！字节跳动发布OmniHuman-1.5，让虚拟人拥有逻辑灵魂 自搜索强化学习SSRL：Agentic RL的Sim2Real时刻 1.1.3 新智元 1.1.4 AGI Hunt 1.1.5 其他 1.2 Arxiv 1.2.1 Computation and Language From：https:// /arxiv/cs.CL">
  <meta itemprop="datePublished" content="2025-09-14T00:00:00+08:00">
  <meta itemprop="dateModified" content="2025-09-14T00:00:00+08:00">
  <meta itemprop="wordCount" content="7011"><meta property="og:url" content="http://localhost:1313/LLMDailyDigestWeb/updates/2025-0831to0914/">
  <meta property="og:site_name" content="LLM-DailyDigest">
  <meta property="og:title" content="2025-08-31to09-14科研追新">
  <meta property="og:description" content="2025-08-31to09-14科研追新 1. 源数据 1.1 公众号 1.1.1 量子位 科研学术，现在可以百度AI一下了
在Lean中形式化强素数定理（Prime Number Theorem，PNT）：Gauss是首个可以协助顶级数学家进行形式验证的自动形式化（autoformalization）Agent
AI解数学题只靠最后一个token
https://mp.weixin.qq.com/s/eloQFjuAgdb-Tc3nvnezsg提出了一种新的强化学习范式——基于历史信息来端到端地加速强化学习效率。
西湖大学自然语言处理实验室推出了首个AI生成学术成果的开放预印本平台AiraXiv，以及首个模拟人类专家思考链的AI审稿人系统DeepReview。
AiraXiv平台地址：https://airaxiv.com DeepReview论文地址：https://arxiv.org/abs/2503.08569
华为openPangu-DeepDiver开源，深度研究多Agent系统，支持百步以上工具推理，万字报告快速生成
Qwen3-Next发布
Meta超级智能实验室（MSL）论文《Language Self-Play For Data-Free Training》让模型在博弈中学习
华为最新发布DeepDiver-V2原生多智能体系统。
攻克AI过度思考难题！美团新研究让通过“可验证”过程奖励激活LRM的高效推理：可验证的过程奖励机制（VSRM），鼓励CoT中的“有效步骤”，惩戒“无效步骤”，最大限度保持性能的同时，实现高效推理。
OpenAI的GPT-5、GPT-4o，还是谷歌Gemini、Anthropic Claude，甚至国内的Qwen、LLaVA，在面对一些“看得见但读不懂”的文字时，全都表现极差，直接“翻车”。
调整训练数据出场顺序，大模型就能变聪明！无需扩大模型/数据规模
7个AI玩狼人杀，GPT-5获断崖式MVP，Kimi手段激进
1.1.2 机器之心 LLaSO 横空出世：逻辑智能推出全球首个完全开源语音大模型框架，定义 LSLM 研究新基准 UQ（Unsolved Questions），这是一个由 500 道题组成的测试集，涵盖计算机理论、数学、科幻、历史等主题，用于考察模型在推理、事实准确性以及浏览等方面的能力。大模型碰到真难题了，测了500道，o3 Pro仅通过15%。 清华、上海AI Lab等顶级团队发布推理模型RL超全综述，探索通往超级智能之路 攻克大模型「表格盲区」！ST-Raptor框架发布，实现复杂半结构化表格的精准理解与信息抽取 交互扩展时代来临:创智复旦字节重磅发布AgentGym-RL，昇腾加持，开创智能体训练新范式 刚刚，Thinking Machines Lab首次发长文，揭开LLM推理不确定性真相 谷歌AI新里程碑：一个能「做研究」的系统诞生了，用LLM&#43;树搜索编写专家级软件 SFT远不如RL？永不过时的剃刀原则打开「终身学习」大模型训练的大门 国内外AI大厂重押，初创梭哈，谁能凭「记忆」成为下一个「DeepSeek」？ 不止会动嘴，还会「思考」！字节跳动发布OmniHuman-1.5，让虚拟人拥有逻辑灵魂 自搜索强化学习SSRL：Agentic RL的Sim2Real时刻 1.1.3 新智元 1.1.4 AGI Hunt 1.1.5 其他 1.2 Arxiv 1.2.1 Computation and Language From：https:// /arxiv/cs.CL">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="updates">
    <meta property="article:published_time" content="2025-09-14T00:00:00+08:00">
    <meta property="article:modified_time" content="2025-09-14T00:00:00+08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="2025-08-31to09-14科研追新">
  <meta name="twitter:description" content="2025-08-31to09-14科研追新 1. 源数据 1.1 公众号 1.1.1 量子位 科研学术，现在可以百度AI一下了
在Lean中形式化强素数定理（Prime Number Theorem，PNT）：Gauss是首个可以协助顶级数学家进行形式验证的自动形式化（autoformalization）Agent
AI解数学题只靠最后一个token
https://mp.weixin.qq.com/s/eloQFjuAgdb-Tc3nvnezsg提出了一种新的强化学习范式——基于历史信息来端到端地加速强化学习效率。
西湖大学自然语言处理实验室推出了首个AI生成学术成果的开放预印本平台AiraXiv，以及首个模拟人类专家思考链的AI审稿人系统DeepReview。
AiraXiv平台地址：https://airaxiv.com DeepReview论文地址：https://arxiv.org/abs/2503.08569
华为openPangu-DeepDiver开源，深度研究多Agent系统，支持百步以上工具推理，万字报告快速生成
Qwen3-Next发布
Meta超级智能实验室（MSL）论文《Language Self-Play For Data-Free Training》让模型在博弈中学习
华为最新发布DeepDiver-V2原生多智能体系统。
攻克AI过度思考难题！美团新研究让通过“可验证”过程奖励激活LRM的高效推理：可验证的过程奖励机制（VSRM），鼓励CoT中的“有效步骤”，惩戒“无效步骤”，最大限度保持性能的同时，实现高效推理。
OpenAI的GPT-5、GPT-4o，还是谷歌Gemini、Anthropic Claude，甚至国内的Qwen、LLaVA，在面对一些“看得见但读不懂”的文字时，全都表现极差，直接“翻车”。
调整训练数据出场顺序，大模型就能变聪明！无需扩大模型/数据规模
7个AI玩狼人杀，GPT-5获断崖式MVP，Kimi手段激进
1.1.2 机器之心 LLaSO 横空出世：逻辑智能推出全球首个完全开源语音大模型框架，定义 LSLM 研究新基准 UQ（Unsolved Questions），这是一个由 500 道题组成的测试集，涵盖计算机理论、数学、科幻、历史等主题，用于考察模型在推理、事实准确性以及浏览等方面的能力。大模型碰到真难题了，测了500道，o3 Pro仅通过15%。 清华、上海AI Lab等顶级团队发布推理模型RL超全综述，探索通往超级智能之路 攻克大模型「表格盲区」！ST-Raptor框架发布，实现复杂半结构化表格的精准理解与信息抽取 交互扩展时代来临:创智复旦字节重磅发布AgentGym-RL，昇腾加持，开创智能体训练新范式 刚刚，Thinking Machines Lab首次发长文，揭开LLM推理不确定性真相 谷歌AI新里程碑：一个能「做研究」的系统诞生了，用LLM&#43;树搜索编写专家级软件 SFT远不如RL？永不过时的剃刀原则打开「终身学习」大模型训练的大门 国内外AI大厂重押，初创梭哈，谁能凭「记忆」成为下一个「DeepSeek」？ 不止会动嘴，还会「思考」！字节跳动发布OmniHuman-1.5，让虚拟人拥有逻辑灵魂 自搜索强化学习SSRL：Agentic RL的Sim2Real时刻 1.1.3 新智元 1.1.4 AGI Hunt 1.1.5 其他 1.2 Arxiv 1.2.1 Computation and Language From：https:// /arxiv/cs.CL">
<meta name="application-name" content="LLM-DailyDigest">
<meta name="apple-mobile-web-app-title" content="LLM-DailyDigest"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-0831to0914/" /><link rel="prev" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-08-19to30/" /><link rel="next" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-09-15/" /><link rel="stylesheet" href="/LLMDailyDigestWeb/css/style.min.css"><link rel="preload" href="/LLMDailyDigestWeb/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/LLMDailyDigestWeb/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "2025-08-31to09-14科研追新",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "http:\/\/localhost:1313\/LLMDailyDigestWeb\/updates\/2025-0831to0914\/"
    },"genre": "updates","wordcount":  7011 ,
    "url": "http:\/\/localhost:1313\/LLMDailyDigestWeb\/updates\/2025-0831to0914\/","datePublished": "2025-09-14T00:00:00+08:00","dateModified": "2025-09-14T00:00:00+08:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "Author"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/LLMDailyDigestWeb/" title="LLM-DailyDigest"><img loading="lazy" src="/LLMDailyDigestWeb/fixit.svg" data-title="LLM-DailyDigest" data-alt="LLM-DailyDigest" class="logo" style="background: url(/LLMDailyDigestWeb/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-desktop" class="typeit"></span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/posts/llmdailydigest"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/resources/"
                
                
              >资源</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/topic/"
                
                
              >主题</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/updates/"
                
                
              >日报</a></li><li class="menu-item delimiter"></li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/LLMDailyDigestWeb/" title="LLM-DailyDigest"><img loading="lazy" src="/LLMDailyDigestWeb/fixit.svg" data-title="/LLMDailyDigestWeb/fixit.svg" data-alt="/LLMDailyDigestWeb/fixit.svg" class="logo" style="background: url(/LLMDailyDigestWeb/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-title-mobile" class="typeit"></span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/posts/llmdailydigest"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/resources/"
                  
                  
                >资源</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/topic/"
                  
                  
                >主题</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/updates/"
                  
                  
                >日报</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><main class="container"><aside class="toc" id="toc-auto"><h2 class="toc-title">Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom">
    </aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span>2025-08-31to09-14科研追新</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      </span></span></div>
      <div class="post-meta-line"><span title="published on 2025-09-14 00:00:00"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden="true"></i><time datetime="2025-09-14">2025-09-14</time></span>&nbsp;<span title="Updated on 2025-09-14 00:00:00"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden="true"></i><time datetime="2025-09-14">2025-09-14</time></span>&nbsp;<span title="7011 words"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>About 7100 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>33 minutes</span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" data-kept="false">
        <div class="details-summary toc-title">
          <span>Contents</span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#2025-09-12">2025-09-12</a></li>
    <li><a href="#1-cde大型语言模型中高效强化学习的好奇心驱动探索-2631"><a href="https://arxiv.org/abs/2509.09675">#1</a> <a href="https://papers.cool/arxiv/2509.09675">CDE：大型语言模型中高效强化学习的好奇心驱动探索</a> 2631]</a></li>
    <li><a href="#2-通过专家取消激活来指导-moe-llm-914"><a href="https://arxiv.org/abs/2509.09660">#2</a> <a href="https://papers.cool/arxiv/2509.09660">通过专家（取消）激活来指导 MoE LLM</a> 914]</a></li>
    <li><a href="#3-all-for-onellm-在最后一个-token-处用从其他-token-传输的信息解决心算问题-35"><a href="https://arxiv.org/abs/2509.09650">#3</a> <a href="https://papers.cool/arxiv/2509.09650">All for One：LLM 在最后一个 token 处用从其他 token 传输的信息解决心算问题</a> 35]</a></li>
    <li><a href="#4-弥合能力差距协调基于-llm-的多智能体系统的联合对齐调整-54"><a href="https://arxiv.org/abs/2509.09629">#4</a> <a href="https://papers.cool/arxiv/2509.09629">弥合能力差距：协调基于 LLM 的多智能体系统的联合对齐调整</a> 54]</a></li>
    <li><a href="#5-lava用于确定死因的语言模型辅助口头尸检-1"><a href="https://arxiv.org/abs/2509.09602">#5</a> <a href="https://papers.cool/arxiv/2509.09602">LAVA：用于确定死因的语言模型辅助口头尸检</a> 1]</a></li>
    <li><a href="#6-流利但无情语言模型的情感盲点-1"><a href="https://arxiv.org/abs/2509.09593">#6</a> <a href="https://papers.cool/arxiv/2509.09593">流利但无情：语言模型的情感盲点</a> 1]</a></li>
    <li><a href="#7-sami-中的人格增强社交推荐探索人格检测在婚介中的作用-2"><a href="https://arxiv.org/abs/2509.09583">#7</a> <a href="https://papers.cool/arxiv/2509.09583">SAMI 中的人格增强社交推荐：探索人格检测在婚介中的作用</a> 2]</a></li>
    <li><a href="#8-促使市场genai-在金融-nlp-中的大规模荟萃分析2022-2025-1"><a href="https://arxiv.org/abs/2509.09544">#8</a> <a href="https://papers.cool/arxiv/2509.09544">促使市场？GenAI 在金融 NLP 中的大规模荟萃分析（2022-2025）</a> 1]</a></li>
    <li><a href="#9-lewidi-2025-上的-demeva使用上下文学习和标签分布学习对视角进行建模-4"><a href="https://arxiv.org/abs/2509.09524">#9</a> <a href="https://papers.cool/arxiv/2509.09524">LeWiDi-2025 上的 DeMeVa：使用上下文学习和标签分布学习对视角进行建模</a> 4]</a></li>
    <li><a href="#10-迈向可解释的职位匹配利用语义文本相关性和知识图谱-12"><a href="https://arxiv.org/abs/2509.09522">#10</a> <a href="https://papers.cool/arxiv/2509.09522">迈向可解释的职位匹配：利用语义文本相关性和知识图谱</a> 12]</a></li>
    <li><a href="#11-减少教育中的语言障碍利用机器翻译开发多语言数字学习材料-1"><a href="https://arxiv.org/abs/2509.09473">#11</a> <a href="https://papers.cool/arxiv/2509.09473">减少教育中的语言障碍：利用机器翻译开发多语言数字学习材料</a> 1]</a></li>
    <li><a href="#12-grace一种在大型语言模型中更好地提取信心的生成方法-21"><a href="https://arxiv.org/abs/2509.09438">#12</a> <a href="https://papers.cool/arxiv/2509.09438">GrACE：一种在大型语言模型中更好地提取信心的生成方法</a> 21]</a></li>
    <li><a href="#13-分层括号编码适用于依赖关系图-1"><a href="https://arxiv.org/abs/2509.09388">#13</a> <a href="https://papers.cool/arxiv/2509.09388">分层括号编码适用于依赖关系图</a> 1]</a></li>
    <li><a href="#14-模拟类比和类比推理连接认知科学理论和自然语言处理研究-12"><a href="https://arxiv.org/abs/2509.09381">#14</a> <a href="https://papers.cool/arxiv/2509.09381">模拟类比和类比推理：连接认知科学理论和自然语言处理研究</a> 12]</a></li>
    <li><a href="#15-metarag用于-rag-系统幻觉检测的变质测试-12"><a href="https://arxiv.org/abs/2509.09360">#15</a> <a href="https://papers.cool/arxiv/2509.09360">MetaRAG：用于 RAG 系统幻觉检测的变质测试</a> 12]</a></li>
    <li><a href="#16-从零到银使用大型语言模型为专利-可持续发展目标分类创建可信的训练数据-1"><a href="https://arxiv.org/abs/2509.09303">#16</a> <a href="https://papers.cool/arxiv/2509.09303">从零到银：使用大型语言模型为专利-可持续发展目标分类创建可信的训练数据</a> 1]</a></li>
    <li><a href="#17-用于对表格数据进行问答的代理-llm-2"><a href="https://arxiv.org/abs/2509.09234">#17</a> <a href="https://papers.cool/arxiv/2509.09234">用于对表格数据进行问答的代理 LLM</a> 2]</a></li>
    <li><a href="#18-字里行间阅读使用大型语言模型对简历资历进行分类-1"><a href="https://arxiv.org/abs/2509.09229">#18</a> <a href="https://papers.cool/arxiv/2509.09229">字里行间阅读：使用大型语言模型对简历资历进行分类</a> 1]</a></li>
    <li><a href="#19-ccf用于高效长序列语言建模的上下文压缩框架-35"><a href="https://arxiv.org/abs/2509.09199">#19</a> <a href="https://papers.cool/arxiv/2509.09199">CCF：用于高效长序列语言建模的上下文压缩框架</a> 35]</a></li>
    <li><a href="#20-gmslm生成狨猴口语建模-1"><a href="https://arxiv.org/abs/2509.09198">#20</a> <a href="https://papers.cool/arxiv/2509.09198">GmSLM：生成狨猴口语建模</a> 1]</a></li>
    <li><a href="#21-使用关键字感知成本函数改进上下文偏差模型的合成数据训练-2"><a href="https://arxiv.org/abs/2509.09197">#21</a> <a href="https://papers.cool/arxiv/2509.09197">使用关键字感知成本函数改进上下文偏差模型的合成数据训练</a> 2]</a></li>
    <li><a href="#22-使用k步预测进行稀有词识别的基于三重的高效偏差-1"><a href="https://arxiv.org/abs/2509.09196">#22</a> <a href="https://papers.cool/arxiv/2509.09196">使用K步预测进行稀有词识别的基于三重的高效偏差</a> 1]</a></li>
    <li><a href="#23-echox通过语音到语音法学硕士的回声训练来缓解声义差距-6"><a href="https://arxiv.org/abs/2509.09174">#23</a> <a href="https://papers.cool/arxiv/2509.09174">EchoX：通过语音到语音法学硕士的回声训练来缓解声义差距</a> 6]</a></li>
    <li><a href="#24-具有反事实增强去偏差的面向目标的多模态情感分类"><a href="https://arxiv.org/abs/2509.09160">#24</a> <a href="https://papers.cool/arxiv/2509.09160">具有反事实增强去偏差的面向目标的多模态情感分类</a></a></li>
    <li><a href="#25-litcoder用于构建和比较编码模型的通用库"><a href="https://arxiv.org/abs/2509.09152">#25</a> <a href="https://papers.cool/arxiv/2509.09152">LITcoder：用于构建和比较编码模型的通用库</a></a></li>
    <li><a href="#26-viranker用于越南语重新排名的-bge-m3-和分块并联变压器交叉编码器"><a href="https://arxiv.org/abs/2509.09131">#26</a> <a href="https://papers.cool/arxiv/2509.09131">ViRanker：用于越南语重新排名的 BGE-M3 和分块并联变压器交叉编码器</a></a></li>
    <li><a href="#27-使用生成式人工智能对导师对话行为进行自动分类使用-cima-语料库的案例研究-1"><a href="https://arxiv.org/abs/2509.09125">#27</a> <a href="https://papers.cool/arxiv/2509.09125">使用生成式人工智能对导师对话行为进行自动分类：使用 CIMA 语料库的案例研究</a> 1]</a></li>
    <li><a href="#28-compass-v3为东南亚多语言电子商务扩展特定领域的-llm"><a href="https://arxiv.org/abs/2509.09121">#28</a> <a href="https://papers.cool/arxiv/2509.09121">Compass-v3：为东南亚多语言电子商务扩展特定领域的 LLM</a></a></li>
    <li><a href="#29-tigercoder用于孟加拉语代码生成的新型法学硕士套件-12"><a href="https://arxiv.org/abs/2509.09101">#29</a> <a href="https://papers.cool/arxiv/2509.09101">TigerCoder：用于孟加拉语代码生成的新型法学硕士套件</a> 12]</a></li>
    <li><a href="#30-mr-uie多视角推理与强化学习的通用信息提取-13"><a href="https://arxiv.org/abs/2509.09082">#30</a> <a href="https://papers.cool/arxiv/2509.09082">MR-UIE：多视角推理与强化学习的通用信息提取</a> 13]</a></li>
    <li><a href="#31-使用-sft-和-dpo-提高-llm-的安全性和实用性opt-350m-研究-17"><a href="https://arxiv.org/abs/2509.09055">#31</a> <a href="https://papers.cool/arxiv/2509.09055">使用 SFT 和 DPO 提高 LLM 的安全性和实用性：OPT-350M 研究</a> 17]</a></li>
    <li><a href="#32-陈述的互动和持续参与偏好-spice评估法学硕士重新参与对话的意愿-2"><a href="https://arxiv.org/abs/2509.09043">#32</a> <a href="https://papers.cool/arxiv/2509.09043">陈述的互动和持续参与偏好 （SPICE）：评估法学硕士重新参与对话的意愿</a> 2]</a></li>
    <li><a href="#33-视觉语言模型可以求解视觉数学方程吗-33"><a href="https://arxiv.org/abs/2509.09013">#33</a> <a href="https://papers.cool/arxiv/2509.09013">视觉语言模型可以求解视觉数学方程吗？</a> 33]</a></li>
    <li><a href="#34-broverbs--1"><a href="https://arxiv.org/abs/2509.08960">#34</a> <a href="https://papers.cool/arxiv/2509.08960">BRoverbs &ndash; 衡量法学硕士对葡萄牙谚语的理解程度</a> 1]</a></li>
    <li><a href="#35-文档是人文字是项目一种具有上下文嵌入的文本数据的心理测量方法-1"><a href="https://arxiv.org/abs/2509.08920">#35</a> <a href="https://papers.cool/arxiv/2509.08920">文档是人，文字是项目：一种具有上下文嵌入的文本数据的心理测量方法</a> 1]</a></li>
    <li><a href="#36-企业气候政策参与的自动证据提取和评分多语言-rag-方法-3"><a href="https://arxiv.org/abs/2509.08907">#36</a> <a href="https://papers.cool/arxiv/2509.08907">企业气候政策参与的自动证据提取和评分：多语言 RAG 方法</a> 3]</a></li>
    <li><a href="#37-噪音或细微差别对法学硕士驱动的-akbc-的有用信息和过滤的调查-1"><a href="https://arxiv.org/abs/2509.08903">#37</a> <a href="https://papers.cool/arxiv/2509.08903">噪音或细微差别：对法学硕士驱动的 AKBC 的有用信息和过滤的调查</a> 1]</a></li>
    <li><a href="#38-flux-reason-6m-和-prism-bench百万规模的文本到图像推理数据集和综合基准-1615"><a href="https://arxiv.org/abs/2509.09680">#38</a> <a href="https://papers.cool/arxiv/2509.09680">FLUX-Reason-6M 和 PRISM-Bench：百万规模的文本到图像推理数据集和综合基准</a> 1615]</a></li>
    <li><a href="#39-butterflyquant通过可学习正交蝶形变换进行超低位-llm-量化-410"><a href="https://arxiv.org/abs/2509.09679">#39</a> <a href="https://papers.cool/arxiv/2509.09679">ButterflyQuant：通过可学习正交蝶形变换进行超低位 LLM 量化</a> 410]</a></li>
    <li><a href="#40-simplevla-rl通过强化学习扩展-vla-训练-2130"><a href="https://arxiv.org/abs/2509.09674">#40</a> <a href="https://papers.cool/arxiv/2509.09674">SimpleVLA-RL：通过强化学习扩展 VLA 训练</a> 2130]</a></li>
    <li><a href="#41-检索增强生成用于可靠解释无线电法规-34"><a href="https://arxiv.org/abs/2509.09651">#41</a> <a href="https://papers.cool/arxiv/2509.09651">检索增强生成，用于可靠解释无线电法规</a> 34]</a></li>
    <li><a href="#42-diflow-tts使用因比分音比重语音令牌进行离散流匹配实现低延迟零样本文本转语音-53"><a href="https://arxiv.org/abs/2509.09631">#42</a> <a href="https://papers.cool/arxiv/2509.09631">DiFlow-TTS：使用因比分音比重语音令牌进行离散流匹配，实现低延迟零样本文本转语音</a> 53]</a></li>
    <li><a href="#43-llm-不知道自己的决策边界自行生成的反事实解释的不可靠性-49"><a href="https://arxiv.org/abs/2509.09396">#43</a> <a href="https://papers.cool/arxiv/2509.09396">LLM 不知道自己的决策边界：自行生成的反事实解释的不可靠性</a> 49]</a></li>
    <li><a href="#44-omnieva通过任务自适应-3d-基础和具身感知推理的具身多功能规划器-68"><a href="https://arxiv.org/abs/2509.09332">#44</a> <a href="https://papers.cool/arxiv/2509.09332">OmniEVA：通过任务自适应 3D 基础和具身感知推理的具身多功能规划器</a> 68]</a></li>
    <li><a href="#45-多模态法学硕士能看清材料吗材料表征的多模态基准-23"><a href="https://arxiv.org/abs/2509.09307">#45</a> <a href="https://papers.cool/arxiv/2509.09307">多模态法学硕士能看清材料吗？材料表征的多模态基准</a> 23]</a></li>
    <li><a href="#46-树-opo用于多步推理的非政策蒙特卡洛树引导优势优化-59"><a href="https://arxiv.org/abs/2509.09284">#46</a> <a href="https://papers.cool/arxiv/2509.09284">树-OPO：用于多步推理的非政策蒙特卡洛树引导优势优化</a> 59]</a></li>
    <li><a href="#47-利用不确定性长视野-llm-代理的熵调制策略梯度-113"><a href="https://arxiv.org/abs/2509.09265">#47</a> <a href="https://papers.cool/arxiv/2509.09265">利用不确定性：长视野 LLM 代理的熵调制策略梯度</a> 113]</a></li>
    <li><a href="#48-确定建立可持续农业旅游中心的关键特征数据驱动的方法-2"><a href="https://arxiv.org/abs/2509.09214">#48</a> <a href="https://papers.cool/arxiv/2509.09214">确定建立可持续农业旅游中心的关键特征：数据驱动的方法</a> 2]</a></li>
    <li><a href="#49-善意的交叉测试揭示了音频深度伪造检测系统的弱点-21"><a href="https://arxiv.org/abs/2509.09204">#49</a> <a href="https://papers.cool/arxiv/2509.09204">善意的交叉测试揭示了音频深度伪造检测系统的弱点</a> 21]</a></li>
    <li><a href="#50-coco-乌尔都语具有多模态质量估计的大规模乌尔都语图像字幕数据集-1"><a href="https://arxiv.org/abs/2509.09014">#50</a> <a href="https://papers.cool/arxiv/2509.09014">COCO-乌尔都语：具有多模态质量估计的大规模乌尔都语图像字幕数据集</a> 1]</a></li>
    <li><a href="#51-open-sci-ref-001用于语言模型和数据集比较的开放且可重复的参考基线-13"><a href="https://arxiv.org/abs/2509.09009">#51</a> <a href="https://papers.cool/arxiv/2509.09009">Open-sci-ref-0.01：用于语言模型和数据集比较的开放且可重复的参考基线</a> 13]</a></li>
    <li><a href="#52-生成引擎优化如何主导人工智能搜索-33"><a href="https://arxiv.org/abs/2509.08919">#52</a> <a href="https://papers.cool/arxiv/2509.08919">生成引擎优化：如何主导人工智能搜索</a> 33]</a></li>
    <li><a href="#53-recurrence-与通用多模态检索的-transformers-相结合-35"><a href="https://arxiv.org/abs/2509.08897">#53</a> <a href="https://papers.cool/arxiv/2509.08897">Recurrence 与通用多模态检索的 Transformers 相结合</a> 35]</a></li>
    <li><a href="#54-一种氛围编码学习设计以增强-efl-学生与-ai-的对话通过-ai-和关于-ai-的对话-41"><a href="https://arxiv.org/abs/2509.08854">#54</a> <a href="https://papers.cool/arxiv/2509.08854">一种氛围编码学习设计，以增强 EFL 学生与 AI 的对话、通过 AI 和关于 AI 的对话</a> 41]</a></li>
    <li><a href="#55-通过-nlp-和多模态-llm-从-gdd-自动生成-unity-游戏模板-23"><a href="https://arxiv.org/abs/2509.08847">#55</a> <a href="https://papers.cool/arxiv/2509.08847">通过 NLP 和多模态 LLM 从 GDD 自动生成 Unity 游戏模板</a> 23]</a></li>
  </ul>

  <ul>
    <li><a href="#2025-09-12-1">2025-09-12</a></li>
    <li><a href="#1-收益递减的错觉衡量法学硕士的长期执行-718"><a href="https://arxiv.org/abs/2509.09677">#1</a> <a href="https://papers.cool/arxiv/2509.09677">收益递减的错觉：衡量法学硕士的长期执行</a> 718]</a></li>
    <li><a href="#2-通过感知生成分解和异步管道执行来提升具身-ai-代理-49"><a href="https://arxiv.org/abs/2509.09560">#2</a> <a href="https://papers.cool/arxiv/2509.09560">通过感知生成分解和异步管道执行来提升具身 AI 代理</a> 49]</a></li>
    <li><a href="#3-变分量子电路的组合概念泛化-35"><a href="https://arxiv.org/abs/2509.09541">#3</a> <a href="https://papers.cool/arxiv/2509.09541">变分量子电路的组合概念泛化</a> 35]</a></li>
    <li><a href="#4-sedm适用于代理的可扩展自演进分布式内存-17"><a href="https://arxiv.org/abs/2509.09498">#4</a> <a href="https://papers.cool/arxiv/2509.09498">SEDM：适用于代理的可扩展自演进分布式内存</a> 17]</a></li>
    <li><a href="#5-inteligencia-artificial-jurídica-y-el-desafío-de-la-veracidad-análisis-de-alucinaciones-optimización-de-rag-y-principios-para-una-integración-responsible-24"><a href="https://arxiv.org/abs/2509.09467">#5</a> <a href="https://papers.cool/arxiv/2509.09467">Inteligencia Artificial jurídica y el desafío de la veracidad： análisis de alucinaciones， optimización de RAG y principios para una integración responsible</a> 24]</a></li>
    <li><a href="#6-躯干面向模板的一般任务推理-24"><a href="https://arxiv.org/abs/2509.09448">#6</a> <a href="https://papers.cool/arxiv/2509.09448">躯干：面向模板的一般任务推理</a> 24]</a></li>
    <li><a href="#7-基于课程的深度强化学习多层语义探索-16"><a href="https://arxiv.org/abs/2509.09356">#7</a> <a href="https://papers.cool/arxiv/2509.09356">基于课程的深度强化学习多层语义探索</a> 16]</a></li>
    <li><a href="#8-迈向自适应机器学习基准web代理驱动的构建域扩展和指标优化-25"><a href="https://arxiv.org/abs/2509.09321">#8</a> <a href="https://papers.cool/arxiv/2509.09321">迈向自适应机器学习基准：Web代理驱动的构建、域扩展和指标优化</a> 25]</a></li>
    <li><a href="#9-测量团队中的隐性空间协调对集体智慧和绩效的影响-2"><a href="https://arxiv.org/abs/2509.09314">#9</a> <a href="https://papers.cool/arxiv/2509.09314">测量团队中的隐性空间协调：对集体智慧和绩效的影响</a> 2]</a></li>
    <li><a href="#10-解释支持最少的锦标赛解决方案-1"><a href="https://arxiv.org/abs/2509.09312">#10</a> <a href="https://papers.cool/arxiv/2509.09312">解释支持最少的锦标赛解决方案</a> 1]</a></li>
    <li><a href="#11-lightagent生产级开源-agentic-ai-框架-65"><a href="https://arxiv.org/abs/2509.09292">#11</a> <a href="https://papers.cool/arxiv/2509.09292">LightAgent：生产级开源 Agentic AI 框架</a> 65]</a></li>
    <li><a href="#12-树-opo用于多步推理的非政策蒙特卡洛树引导优势优化-59"><a href="https://arxiv.org/abs/2509.09284">#12</a> <a href="https://papers.cool/arxiv/2509.09284">树-OPO：用于多步推理的非政策蒙特卡洛树引导优势优化</a> 59]</a></li>
    <li><a href="#13-知识与语言的融合基于知识图谱的问答与法学硕士的比较研究-13"><a href="https://arxiv.org/abs/2509.09272">#13</a> <a href="https://papers.cool/arxiv/2509.09272">知识与语言的融合：基于知识图谱的问答与法学硕士的比较研究</a> 13]</a></li>
    <li><a href="#14-jupiter通过笔记本和推理时间值引导搜索增强-llm-数据分析能力-3"><a href="https://arxiv.org/abs/2509.09245">#14</a> <a href="https://papers.cool/arxiv/2509.09245">Jupiter：通过笔记本和推理时间值引导搜索增强 LLM 数据分析能力</a> 3]</a></li>
    <li><a href="#15-实现监管多代理协作架构挑战和解决方案-3"><a href="https://arxiv.org/abs/2509.09215">#15</a> <a href="https://papers.cool/arxiv/2509.09215">实现监管多代理协作：架构、挑战和解决方案</a> 3]</a></li>
    <li><a href="#16-progd使用动态图进行多智能体联合运动预测的渐进式多尺度解码-1"><a href="https://arxiv.org/abs/2509.09210">#16</a> <a href="https://papers.cool/arxiv/2509.09210">ProgD：使用动态图进行多智能体联合运动预测的渐进式多尺度解码</a> 1]</a></li>
    <li><a href="#17-心灵与空间的结合从神经科学启发的角度重新思考智能体空间智能-56"><a href="https://arxiv.org/abs/2509.09154">#17</a> <a href="https://papers.cool/arxiv/2509.09154">心灵与空间的结合：从神经科学启发的角度重新思考智能体空间智能</a> 56]</a></li>
    <li><a href="#18-反洗钱机器学习管道通过监督学习识别高风险银行客户的技术分析-1"><a href="https://arxiv.org/abs/2509.09127">#18</a> <a href="https://papers.cool/arxiv/2509.09127">反洗钱机器学习管道;通过监督学习识别高风险银行客户的技术分析</a> 1]</a></li>
    <li><a href="#19-了解讨价还价游戏中人类和人工智能代理之间的经济权衡-12"><a href="https://arxiv.org/abs/2509.09071">#19</a> <a href="https://papers.cool/arxiv/2509.09071">了解讨价还价游戏中人类和人工智能代理之间的经济权衡</a> 12]</a></li>
    <li><a href="#20-针对冷启动用户的基于-llm-的少量建议的教学提示优化-13"><a href="https://arxiv.org/abs/2509.09066">#20</a> <a href="https://papers.cool/arxiv/2509.09066">针对冷启动用户的基于 LLM 的少量建议的教学提示优化</a> 13]</a></li>
    <li><a href="#21-可解释人工智能的不确定性意识和信任度---使用局部和全局解释进行信任校准-2"><a href="https://arxiv.org/abs/2509.08989">#21</a> <a href="https://papers.cool/arxiv/2509.08989">可解释人工智能的不确定性意识和信任度 - 使用局部和全局解释进行信任校准</a> 2]</a></li>
    <li><a href="#22-fortifai抵御-ai-模型递归训练引起的故障-2"><a href="https://arxiv.org/abs/2509.08972">#22</a> <a href="https://papers.cool/arxiv/2509.08972">ForTIFAI：抵御 AI 模型递归训练引起的故障</a> 2]</a></li>
    <li><a href="#23-用于文本到模型翻译的全局约束-llm-代理-2"><a href="https://arxiv.org/abs/2509.08970">#23</a> <a href="https://papers.cool/arxiv/2509.08970">用于文本到模型翻译的全局约束 LLM 代理</a> 2]</a></li>
    <li><a href="#24-通过-nlp-和多模态-llm-从-gdd-自动生成-unity-游戏模板-23"><a href="https://arxiv.org/abs/2509.08847">#24</a> <a href="https://papers.cool/arxiv/2509.08847">通过 NLP 和多模态 LLM 从 GDD 自动生成 Unity 游戏模板</a> 23]</a></li>
    <li><a href="#25-贝叶斯定理的区间类型-2-版本源自主题专家提供的区间概率范围估计-2"><a href="https://arxiv.org/abs/2509.08834">#25</a> <a href="https://papers.cool/arxiv/2509.08834">贝叶斯定理的区间类型 2 版本，源自主题专家提供的区间概率范围估计</a> 2]</a></li>
    <li><a href="#26-butterflyquant通过可学习正交蝶形变换进行超低位-llm-量化-410"><a href="https://arxiv.org/abs/2509.09679">#26</a> <a href="https://papers.cool/arxiv/2509.09679">ButterflyQuant：通过可学习正交蝶形变换进行超低位 LLM 量化</a> 410]</a></li>
    <li><a href="#27-cde大型语言模型中高效强化学习的好奇心驱动探索-2631"><a href="https://arxiv.org/abs/2509.09675">#27</a> <a href="https://papers.cool/arxiv/2509.09675">CDE：大型语言模型中高效强化学习的好奇心驱动探索</a> 2631]</a></li>
    <li><a href="#28-simplevla-rl通过强化学习扩展-vla-训练-2130"><a href="https://arxiv.org/abs/2509.09674">#28</a> <a href="https://papers.cool/arxiv/2509.09674">SimpleVLA-RL：通过强化学习扩展 VLA 训练</a> 2130]</a></li>
    <li><a href="#29-医疗补助护理管理的可行性指导公平自适应离线强化学习-2"><a href="https://arxiv.org/abs/2509.09655">#29</a> <a href="https://papers.cool/arxiv/2509.09655">医疗补助护理管理的可行性指导公平自适应离线强化学习</a> 2]</a></li>
    <li><a href="#30-检索增强生成用于可靠解释无线电法规-34"><a href="https://arxiv.org/abs/2509.09651">#30</a> <a href="https://papers.cool/arxiv/2509.09651">检索增强生成，用于可靠解释无线电法规</a> 34]</a></li>
    <li><a href="#31-通过群体反事实的演变解释概念漂移-12"><a href="https://arxiv.org/abs/2509.09616">#31</a> <a href="https://papers.cool/arxiv/2509.09616">通过群体反事实的演变解释概念漂移</a> 12]</a></li>
    <li><a href="#32-locobench复杂软件工程中长上下文大语言模型的基准-110"><a href="https://arxiv.org/abs/2509.09614">#32</a> <a href="https://papers.cool/arxiv/2509.09614">LoCoBench：复杂软件工程中长上下文大语言模型的基准</a> 110]</a></li>
    <li><a href="#33-使用引导扩散模型预测时空脑肿瘤生长的机制学习-3"><a href="https://arxiv.org/abs/2509.09610">#33</a> <a href="https://papers.cool/arxiv/2509.09610">使用引导扩散模型预测时空脑肿瘤生长的机制学习</a> 3]</a></li>
    <li><a href="#34-通过双通频谱编码和潜在空间通信进行图对齐-12"><a href="https://arxiv.org/abs/2509.09597">#34</a> <a href="https://papers.cool/arxiv/2509.09597">通过双通频谱编码和潜在空间通信进行图对齐</a> 12]</a></li>
    <li><a href="#35-objectreact学习可视化导航的对象相对控制-29"><a href="https://arxiv.org/abs/2509.09594">#35</a> <a href="https://papers.cool/arxiv/2509.09594">ObjectReact：学习可视化导航的对象相对控制</a> 29]</a></li>
    <li><a href="#36-流利但无情语言模型的情感盲点-1"><a href="https://arxiv.org/abs/2509.09593">#36</a> <a href="https://papers.cool/arxiv/2509.09593">流利但无情：语言模型的情感盲点</a> 1]</a></li>
    <li><a href="#37-看不见的属性可见的偏见探索基于-mri-的阿尔茨海默病分类中的人口统计捷径-2"><a href="https://arxiv.org/abs/2509.09558">#37</a> <a href="https://papers.cool/arxiv/2509.09558">看不见的属性，可见的偏见：探索基于 MRI 的阿尔茨海默病分类中的人口统计捷径</a> 2]</a></li>
    <li><a href="#38-一种改进的教育竞赛优化器具有多协方差学习算子用于全局优化问题-2"><a href="https://arxiv.org/abs/2509.09552">#38</a> <a href="https://papers.cool/arxiv/2509.09552">一种改进的教育竞赛优化器，具有多协方差学习算子，用于全局优化问题</a> 2]</a></li>
    <li><a href="#39-通过自监督视觉编码器的多特征融合和对准改进视频扩散变压器训练-85"><a href="https://arxiv.org/abs/2509.09547">#39</a> <a href="https://papers.cool/arxiv/2509.09547">通过自监督视觉编码器的多特征融合和对准改进视频扩散变压器训练</a> 85]</a></li>
    <li><a href="#40-一种基于协方差学习和多样性增强的改进rime算法用于数值优化"><a href="https://arxiv.org/abs/2509.09529">#40</a> <a href="https://papers.cool/arxiv/2509.09529">一种基于协方差学习和多样性增强的改进RIME算法，用于数值优化</a></a></li>
    <li><a href="#41-迈向可解释的职位匹配利用语义文本相关性和知识图谱-12"><a href="https://arxiv.org/abs/2509.09522">#41</a> <a href="https://papers.cool/arxiv/2509.09522">迈向可解释的职位匹配：利用语义文本相关性和知识图谱</a> 12]</a></li>
    <li><a href="#42-用于加速微结构成像的可解释人工智能connectome-20-扫描仪上的-shap-引导协议-1"><a href="https://arxiv.org/abs/2509.09513">#42</a> <a href="https://papers.cool/arxiv/2509.09513">用于加速微结构成像的可解释人工智能：Connectome 2.0 扫描仪上的 SHAP 引导协议</a> 1]</a></li>
    <li><a href="#43-将人工智能事件报告纳入电信法律和政策来自印度的见解"><a href="https://arxiv.org/abs/2509.09508">#43</a> <a href="https://papers.cool/arxiv/2509.09508">将人工智能事件报告纳入电信法律和政策：来自印度的见解</a></a></li>
    <li><a href="#44-openfake面向大规模深度伪造检测的开放数据集和平台-32"><a href="https://arxiv.org/abs/2509.09495">#44</a> <a href="https://papers.cool/arxiv/2509.09495">OpenFake：面向大规模深度伪造检测的开放数据集和平台</a> 32]</a></li>
    <li><a href="#45-提示海盗需要地图窃取种子有助于窃取提示-1"><a href="https://arxiv.org/abs/2509.09488">#45</a> <a href="https://papers.cool/arxiv/2509.09488">提示海盗需要地图：窃取种子有助于窃取提示</a> 1]</a></li>
    <li><a href="#46-撒哈拉以南-mri-上的资源高效神经胶质瘤分割"><a href="https://arxiv.org/abs/2509.09469">#46</a> <a href="https://papers.cool/arxiv/2509.09469">撒哈拉以南 MRI 上的资源高效神经胶质瘤分割</a></a></li>
    <li><a href="#47-ensi大型语言模型的高效非交互式安全推理"><a href="https://arxiv.org/abs/2509.09424">#47</a> <a href="https://papers.cool/arxiv/2509.09424">ENSI：大型语言模型的高效非交互式安全推理</a></a></li>
    <li><a href="#48-我们仍然做错了全部推荐系统十五年后-43"><a href="https://arxiv.org/abs/2509.09414">#48</a> <a href="https://papers.cool/arxiv/2509.09414">我们仍然做错了（全部）：推荐系统，十五年后</a> 43]</a></li>
    <li><a href="#49-llm-不知道自己的决策边界自行生成的反事实解释的不可靠性-49"><a href="https://arxiv.org/abs/2509.09396">#49</a> <a href="https://papers.cool/arxiv/2509.09396">LLM 不知道自己的决策边界：自行生成的反事实解释的不可靠性</a> 49]</a></li>
    <li><a href="#50-metallmix--一种基于-xai-辅助-llm-meta-学习的超参数优化方法"><a href="https://arxiv.org/abs/2509.09387">#50</a> <a href="https://papers.cool/arxiv/2509.09387">MetaLLMix ： 一种基于 XAI 辅助 LLM-Meta 学习的超参数优化方法</a></a></li>
    <li><a href="#51-通过多项式回归的鲁棒非线性相关-1"><a href="https://arxiv.org/abs/2509.09380">#51</a> <a href="https://papers.cool/arxiv/2509.09380">通过多项式回归的鲁棒非线性相关</a> 1]</a></li>
    <li><a href="#52-自动驾驶汽车外部观察技术对驾驶员行为进行分类-1"><a href="https://arxiv.org/abs/2509.09349">#52</a> <a href="https://papers.cool/arxiv/2509.09349">自动驾驶汽车外部观察技术对驾驶员行为进行分类</a> 1]</a></li>
    <li><a href="#53-mose通过子图专家的混合揭示图中的结构模式"><a href="https://arxiv.org/abs/2509.09337">#53</a> <a href="https://papers.cool/arxiv/2509.09337">MoSE：通过子图专家的混合揭示图中的结构模式</a></a></li>
    <li><a href="#54-omnieva通过任务自适应-3d-基础和具身感知推理的具身多功能规划器-68"><a href="https://arxiv.org/abs/2509.09332">#54</a> <a href="https://papers.cool/arxiv/2509.09332">OmniEVA：通过任务自适应 3D 基础和具身感知推理的具身多功能规划器</a> 68]</a></li>
    <li><a href="#55-多模态法学硕士能看清材料吗材料表征的多模态基准-23"><a href="https://arxiv.org/abs/2509.09307">#55</a> <a href="https://papers.cool/arxiv/2509.09307">多模态法学硕士能看清材料吗？材料表征的多模态基准</a> 23]</a></li>
    <li><a href="#56-与模态无关的输入通道能够在多模态-mri-中分割脑部病变序列在训练期间不可用"><a href="https://arxiv.org/abs/2509.09290">#56</a> <a href="https://papers.cool/arxiv/2509.09290">与模态无关的输入通道能够在多模态 MRI 中分割脑部病变，序列在训练期间不可用</a></a></li>
    <li><a href="#57-使用设备感知教师进行低复杂度声场景分类的自适应知识蒸馏-2"><a href="https://arxiv.org/abs/2509.09262">#57</a> <a href="https://papers.cool/arxiv/2509.09262">使用设备感知教师进行低复杂度声场景分类的自适应知识蒸馏</a> 2]</a></li>
    <li><a href="#58-coatnext一种用于胃组织分类的注意力增强-convnextv2-transformer-混合模型-1"><a href="https://arxiv.org/abs/2509.09242">#58</a> <a href="https://papers.cool/arxiv/2509.09242">CoAtNeXt：一种用于胃组织分类的注意力增强 ConvNeXtV2-Transformer 混合模型</a> 1]</a></li>
    <li><a href="#59-用于骨植入物-3d-x-射线组织学的虚拟染色-2"><a href="https://arxiv.org/abs/2509.09235">#59</a> <a href="https://papers.cool/arxiv/2509.09235">用于骨植入物 3D X 射线组织学的虚拟染色</a> 2]</a></li>
    <li><a href="#60-vejde基于因子图颜色细化的归纳深度强化学习框架-2"><a href="https://arxiv.org/abs/2509.09219">#60</a> <a href="https://papers.cool/arxiv/2509.09219">Vejde：基于因子图颜色细化的归纳深度强化学习框架</a> 2]</a></li>
    <li><a href="#61-激励约束强化学习策略优化中的更安全行动-1"><a href="https://arxiv.org/abs/2509.09208">#61</a> <a href="https://papers.cool/arxiv/2509.09208">激励约束强化学习策略优化中的更安全行动</a> 1]</a></li>
    <li><a href="#62-善意的交叉测试揭示了音频深度伪造检测系统的弱点-21"><a href="https://arxiv.org/abs/2509.09204">#62</a> <a href="https://papers.cool/arxiv/2509.09204">善意的交叉测试揭示了音频深度伪造检测系统的弱点</a> 21]</a></li>
    <li><a href="#63-使用关键字感知成本函数改进上下文偏差模型的合成数据训练-2"><a href="https://arxiv.org/abs/2509.09197">#63</a> <a href="https://papers.cool/arxiv/2509.09197">使用关键字感知成本函数改进上下文偏差模型的合成数据训练</a> 2]</a></li>
    <li><a href="#64-使用k步预测进行稀有词识别的基于三重的高效偏差-1"><a href="https://arxiv.org/abs/2509.09196">#64</a> <a href="https://papers.cool/arxiv/2509.09196">使用K步预测进行稀有词识别的基于三重的高效偏差</a> 1]</a></li>
    <li><a href="#65-大语言模型与场景化编程融合提升软件可靠性-1"><a href="https://arxiv.org/abs/2509.09194">#65</a> <a href="https://papers.cool/arxiv/2509.09194">大语言模型与场景化编程融合提升软件可靠性</a> 1]</a></li>
    <li><a href="#66-探测代码更改的预训练语言模型来自高置信度即时缺陷预测数据集-redef-的见解"><a href="https://arxiv.org/abs/2509.09192">#66</a> <a href="https://papers.cool/arxiv/2509.09192">探测代码更改的预训练语言模型：来自高置信度即时缺陷预测数据集 ReDef 的见解</a></a></li>
    <li><a href="#67-dark-isp增强用于低光物体检测的raw图像处理-1"><a href="https://arxiv.org/abs/2509.09183">#67</a> <a href="https://papers.cool/arxiv/2509.09183">Dark-ISP：增强用于低光物体检测的RAW图像处理</a> 1]</a></li>
    <li><a href="#68-echox通过语音到语音法学硕士的回声训练来缓解声义差距-6"><a href="https://arxiv.org/abs/2509.09174">#68</a> <a href="https://papers.cool/arxiv/2509.09174">EchoX：通过语音到语音法学硕士的回声训练来缓解声义差距</a> 6]</a></li>
    <li><a href="#69-语义通信中边缘变换器模型的自适应帕累托最优令牌合并"><a href="https://arxiv.org/abs/2509.09168">#69</a> <a href="https://papers.cool/arxiv/2509.09168">语义通信中边缘变换器模型的自适应帕累托最优令牌合并</a></a></li>
    <li><a href="#70-具有反事实增强去偏差的面向目标的多模态情感分类"><a href="https://arxiv.org/abs/2509.09160">#70</a> <a href="https://papers.cool/arxiv/2509.09160">具有反事实增强去偏差的面向目标的多模态情感分类</a></a></li>
    <li><a href="#71-基于知识的视觉问答的知识噪声缓解框架-1"><a href="https://arxiv.org/abs/2509.09159">#71</a> <a href="https://papers.cool/arxiv/2509.09159">基于知识的视觉问答的知识噪声缓解框架</a> 1]</a></li>
    <li><a href="#72-hispaspoof西班牙语音取证的新数据集-1"><a href="https://arxiv.org/abs/2509.09155">#72</a> <a href="https://papers.cool/arxiv/2509.09155">HISPASpoof：西班牙语音取证的新数据集</a> 1]</a></li>
    <li><a href="#73-ocelot-2023细胞-组织相互作用挑战赛中的细胞检测"><a href="https://arxiv.org/abs/2509.09153">#73</a> <a href="https://papers.cool/arxiv/2509.09153">OCELOT 2023：细胞-组织相互作用挑战赛中的细胞检测</a></a></li>
    <li><a href="#74-视频理解设计数据集如何塑造架构和见解-2"><a href="https://arxiv.org/abs/2509.09151">#74</a> <a href="https://papers.cool/arxiv/2509.09151">视频理解设计：数据集如何塑造架构和见解</a> 2]</a></li>
    <li><a href="#75-对象相似性在-3d-场景评估中捕获对象级保真度-31"><a href="https://arxiv.org/abs/2509.09143">#75</a> <a href="https://papers.cool/arxiv/2509.09143">对象相似性：在 3D 场景评估中捕获对象级保真度</a> 31]</a></li>
    <li><a href="#76-viranker用于越南语重新排名的-bge-m3-和分块并联变压器交叉编码器"><a href="https://arxiv.org/abs/2509.09131">#76</a> <a href="https://papers.cool/arxiv/2509.09131">ViRanker：用于越南语重新排名的 BGE-M3 和分块并联变压器交叉编码器</a></a></li>
    <li><a href="#77-使用生成式人工智能对导师对话行为进行自动分类使用-cima-语料库的案例研究-1"><a href="https://arxiv.org/abs/2509.09125">#77</a> <a href="https://papers.cool/arxiv/2509.09125">使用生成式人工智能对导师对话行为进行自动分类：使用 CIMA 语料库的案例研究</a> 1]</a></li>
    <li><a href="#78-字符级扰动破坏-llm-水印-31"><a href="https://arxiv.org/abs/2509.09112">#78</a> <a href="https://papers.cool/arxiv/2509.09112">字符级扰动破坏 LLM 水印</a> 31]</a></li>
    <li><a href="#79-dp-fedlora面向端端大型语言模型的隐私增强型联邦微调"><a href="https://arxiv.org/abs/2509.09097">#79</a> <a href="https://papers.cool/arxiv/2509.09097">DP-FedLoRA：面向端端大型语言模型的隐私增强型联邦微调</a></a></li>
    <li><a href="#80-通过双重隐私保护实现保密和高效的-llm-推理"><a href="https://arxiv.org/abs/2509.09091">#80</a> <a href="https://papers.cool/arxiv/2509.09091">通过双重隐私保护实现保密和高效的 LLM 推理</a></a></li>
    <li><a href="#81-sqap-vla用于高性能视觉-语言-动作模型的协同量化感知修剪框架-21"><a href="https://arxiv.org/abs/2509.09090">#81</a> <a href="https://papers.cool/arxiv/2509.09090">SQAP-VLA：用于高性能视觉-语言-动作模型的协同量化感知修剪框架</a> 21]</a></li>
    <li><a href="#82-koopmotion学习几乎无发散的-koopman-流场以进行运动规划"><a href="https://arxiv.org/abs/2509.09074">#82</a> <a href="https://papers.cool/arxiv/2509.09074">KoopMotion：学习几乎无发散的 Koopman 流场以进行运动规划</a></a></li>
    <li><a href="#83-stride通过无子集函数分解实现可扩展和可解释的xai-1"><a href="https://arxiv.org/abs/2509.09070">#83</a> <a href="https://papers.cool/arxiv/2509.09070">STRIDE：通过无子集函数分解实现可扩展和可解释的XAI</a> 1]</a></li>
    <li><a href="#84-使用-sft-和-dpo-提高-llm-的安全性和实用性opt-350m-研究-17"><a href="https://arxiv.org/abs/2509.09055">#84</a> <a href="https://papers.cool/arxiv/2509.09055">使用 SFT 和 DPO 提高 LLM 的安全性和实用性：OPT-350M 研究</a> 17]</a></li>
    <li><a href="#85-机器学习在电力系统保护和干扰管理中的应用范围界定综述-1"><a href="https://arxiv.org/abs/2509.09053">#85</a> <a href="https://papers.cool/arxiv/2509.09053">机器学习在电力系统保护和干扰管理中的应用范围界定综述</a> 1]</a></li>
    <li><a href="#86-mowe天气专家的混合体-22"><a href="https://arxiv.org/abs/2509.09052">#86</a> <a href="https://papers.cool/arxiv/2509.09052">MoWE：天气专家的混合体</a> 22]</a></li>
    <li><a href="#87-陈述的互动和持续参与偏好-spice评估法学硕士重新参与对话的意愿-2"><a href="https://arxiv.org/abs/2509.09043">#87</a> <a href="https://papers.cool/arxiv/2509.09043">陈述的互动和持续参与偏好 （SPICE）：评估法学硕士重新参与对话的意愿</a> 2]</a></li>
    <li><a href="#88-无羡慕但仍然不公平个性化推荐中最多一个项目-ef-1-无羡慕-1"><a href="https://arxiv.org/abs/2509.09037">#88</a> <a href="https://papers.cool/arxiv/2509.09037">无羡慕但仍然不公平：个性化推荐中最多一个项目 （EF-1） 无羡慕</a> 1]</a></li>
    <li><a href="#89-通过深度自适应时空建模和稀疏数据进行个性化睡眠预测-2"><a href="https://arxiv.org/abs/2509.09018">#89</a> <a href="https://papers.cool/arxiv/2509.09018">通过深度自适应时空建模和稀疏数据进行个性化睡眠预测</a> 2]</a></li>
    <li><a href="#90-视觉语言模型可以求解视觉数学方程吗-33"><a href="https://arxiv.org/abs/2509.09013">#90</a> <a href="https://papers.cool/arxiv/2509.09013">视觉语言模型可以求解视觉数学方程吗？</a> 33]</a></li>
    <li><a href="#91-open-sci-ref-001用于语言模型和数据集比较的开放且可重复的参考基线-13"><a href="https://arxiv.org/abs/2509.09009">#91</a> <a href="https://papers.cool/arxiv/2509.09009">Open-sci-ref-0.01：用于语言模型和数据集比较的开放且可重复的参考基线</a> 13]</a></li>
    <li><a href="#92-心肌内运动和应变的隐性神经表征-1"><a href="https://arxiv.org/abs/2509.09004">#92</a> <a href="https://papers.cool/arxiv/2509.09004">心肌内运动和应变的隐性神经表征</a> 1]</a></li>
    <li><a href="#93-基于相似性的异常值检测用于使用β混合进行噪声对象重新识别-2"><a href="https://arxiv.org/abs/2509.08926">#93</a> <a href="https://papers.cool/arxiv/2509.08926">基于相似性的异常值检测，用于使用β混合进行噪声对象重新识别</a> 2]</a></li>
    <li><a href="#94-实例最优矩阵乘法权重更新及其量子应用-2"><a href="https://arxiv.org/abs/2509.08911">#94</a> <a href="https://papers.cool/arxiv/2509.08911">实例最优矩阵乘法权重更新及其量子应用</a> 2]</a></li>
    <li><a href="#95-promptguard一个精心编排的提示框架用于使用具有增强安全性公平性和可控性的法学硕士为弱势群体生成有原则的合成文本-2"><a href="https://arxiv.org/abs/2509.08910">#95</a> <a href="https://papers.cool/arxiv/2509.08910">PromptGuard：一个精心编排的提示框架，用于使用具有增强安全性、公平性和可控性的法学硕士为弱势群体生成有原则的合成文本</a> 2]</a></li>
    <li><a href="#96-recurrence-与通用多模态检索的-transformers-相结合-35"><a href="https://arxiv.org/abs/2509.08897">#96</a> <a href="https://papers.cool/arxiv/2509.08897">Recurrence 与通用多模态检索的 Transformers 相结合</a> 35]</a></li>
    <li><a href="#97-使用-vllm-对大型语言模型的能效进行基准测试"><a href="https://arxiv.org/abs/2509.08867">#97</a> <a href="https://papers.cool/arxiv/2509.08867">使用 vLLM 对大型语言模型的能效进行基准测试</a></a></li>
    <li><a href="#98-在计算机科学课程中调查学生与大型语言模型驱动的课程助手的交互模式"><a href="https://arxiv.org/abs/2509.08862">#98</a> <a href="https://papers.cool/arxiv/2509.08862">在计算机科学课程中调查学生与大型语言模型驱动的课程助手的交互模式</a></a></li>
    <li><a href="#99-高动态环境中的多机器人协调应对不对称障碍和有限的通信"><a href="https://arxiv.org/abs/2509.08859">#99</a> <a href="https://papers.cool/arxiv/2509.08859">高动态环境中的多机器人协调：应对不对称障碍和有限的通信</a></a></li>
    <li><a href="#100-一种氛围编码学习设计以增强-efl-学生与-ai-的对话通过-ai-和关于-ai-的对话-41"><a href="https://arxiv.org/abs/2509.08854">#100</a> <a href="https://papers.cool/arxiv/2509.08854">一种氛围编码学习设计，以增强 EFL 学生与 AI 的对话、通过 AI 和关于 AI 的对话</a> 41]</a></li>
    <li><a href="#101-安全且可认证的人工智能系统概念挑战和经验教训-3"><a href="https://arxiv.org/abs/2509.08852">#101</a> <a href="https://papers.cool/arxiv/2509.08852">安全且可认证的人工智能系统：概念、挑战和经验教训</a> 3]</a></li>
    <li><a href="#102-使用方差门控分布的不确定性估计-2"><a href="https://arxiv.org/abs/2509.08846">#102</a> <a href="https://papers.cool/arxiv/2509.08846">使用方差门控分布的不确定性估计</a> 2]</a></li>
    <li><a href="#103-深度不透明性和人工智能对-xai-和隐私保护机制的威胁"><a href="https://arxiv.org/abs/2509.08835">#103</a> <a href="https://papers.cool/arxiv/2509.08835">深度不透明性和人工智能：对 XAI 和隐私保护机制的威胁</a></a></li>
    <li><a href="#104-perfairx大型语言模型推荐的公平性和个性之间是否取得了平衡"><a href="https://arxiv.org/abs/2509.08829">#104</a> <a href="https://papers.cool/arxiv/2509.08829">PerFairX：大型语言模型推荐的公平性和个性之间是否取得了平衡？</a></a></li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h1 id="2025-08-31to09-14科研追新">2025-08-31to09-14科研追新</h1>
<h1 id="1-源数据">1. 源数据</h1>
<h1 id="11-公众号">1.1 公众号</h1>
<h1 id="111-量子位">1.1.1 量子位</h1>
<ol>
<li>
<p><a href="https://mp.weixin.qq.com/s/7o5gAVIsS5hRytxAXHpxIw"target="_blank" rel="external nofollow noopener noreferrer">科研学术，现在可以百度AI一下了</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/TH-5dDu5rmTy2b2tEZLz0w"target="_blank" rel="external nofollow noopener noreferrer">在Lean中形式化强素数定理（Prime Number Theorem，PNT）</a>：Gauss是首个可以协助顶级数学家进行形式验证的<strong>自动形式化</strong>（autoformalization）Agent</p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/yYnJXKm61bTeUgnN1HiSng"target="_blank" rel="external nofollow noopener noreferrer">AI解数学题只靠最后一个token</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/eloQFjuAgdb-Tc3nvnezsg"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/eloQFjuAgdb-Tc3nvnezsg</a>提出了一种新的强化学习范式——基于历史信息来端到端地加速强化学习效率。</p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/b9wgrt7veyEWuQ1oaGBjyQ"target="_blank" rel="external nofollow noopener noreferrer"><strong>西湖大学自然语言处理实验室</strong>推出了首个AI生成学术成果的开放预印本平台<strong>AiraXiv</strong></a>，以及首个模拟人类专家思考链的AI审稿人系统<strong>DeepReview</strong>。</p>
<p><em>AiraXiv平台地址：https://airaxiv.com
DeepReview论文地址：https://arxiv.org/abs/2503.08569</em></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/XsBFTv3m5avvrwb-PpoLwA"target="_blank" rel="external nofollow noopener noreferrer">华为openPangu-DeepDiver开源</a>，深度研究多Agent系统，支持百步以上工具推理，万字报告快速生成</p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/LnXGYb9UdTRCYz2yFc0XhA"target="_blank" rel="external nofollow noopener noreferrer">Qwen3-Next发布</a></p>
</li>
<li>
<p>Meta超级智能实验室（MSL）论文《<a href="https://mp.weixin.qq.com/s/NuAp3G9DOXwX6mwdfabvAw"target="_blank" rel="external nofollow noopener noreferrer">Language Self-Play For Data-Free Training</a>》让模型在博弈中学习</p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/-YUmnDs6ASrmxeKwfA98oQ"target="_blank" rel="external nofollow noopener noreferrer">华为最新发布DeepDiver-V2原生多智能体系统。</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/8OiJucbM3TkZ0FUTVGnAIA"target="_blank" rel="external nofollow noopener noreferrer">攻克AI过度思考难题！美团新研究让通过“可验证”过程奖励激活LRM的高效推理</a>：可验证的过程奖励机制（VSRM），鼓励CoT中的“有效步骤”，惩戒“无效步骤”，最大限度保持性能的同时，实现高效推理。</p>
</li>
<li>
<p>OpenAI的GPT-5、GPT-4o，还是谷歌Gemini、Anthropic Claude，甚至国内的Qwen、LLaVA，<a href="https://mp.weixin.qq.com/s/p3pQjoJW8eAmXMOUFgO_gg"target="_blank" rel="external nofollow noopener noreferrer">在面对一些“看得见但读不懂”的文字时，全都表现极差，直接“翻车”。</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/F8F8QLsGMDAOvxvd0HE_yg"target="_blank" rel="external nofollow noopener noreferrer">调整训练数据出场顺序，大模型就能变聪明！无需扩大模型/数据规模</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/w1GHD-F7YkFz504kJMj7jA"target="_blank" rel="external nofollow noopener noreferrer">7个AI玩狼人杀，GPT-5获断崖式MVP，Kimi手段激进</a></p>
</li>
</ol>
<h1 id="112-机器之心">1.1.2 机器之心</h1>
<ol>
<li><a href="https://mp.weixin.qq.com/s/JvFzf-UkRJz3Cv-h8Er1yw"target="_blank" rel="external nofollow noopener noreferrer">LLaSO 横空出世：逻辑智能推出全球首个完全开源语音大模型框架，定义 LSLM 研究新基准</a></li>
<li>UQ（Unsolved Questions），这是一个由 500 道题组成的测试集，涵盖计算机理论、数学、科幻、历史等主题，用于考察模型在推理、事实准确性以及浏览等方面的能力。<a href="https://mp.weixin.qq.com/s/7qqhCcSInFIb0SERkY9GqQ"target="_blank" rel="external nofollow noopener noreferrer">大模型碰到真难题了，测了500道，o3 Pro仅通过15%。</a></li>
<li><a href="https://mp.weixin.qq.com/s/CkKlHplf-kO30L6B_ucv1g"target="_blank" rel="external nofollow noopener noreferrer">清华、上海AI Lab等顶级团队发布推理模型RL超全综述，探索通往超级智能之路</a></li>
<li><a href="https://mp.weixin.qq.com/s/_JGJLEVfd5FlWuT8yqEvIA"target="_blank" rel="external nofollow noopener noreferrer">攻克大模型「表格盲区」！ST-Raptor框架发布，实现复杂半结构化表格的精准理解与信息抽取</a></li>
<li><a href="https://mp.weixin.qq.com/s/_s1c2uj8B9u-i7wgoM2gwA"target="_blank" rel="external nofollow noopener noreferrer">交互扩展时代来临:创智复旦字节重磅发布AgentGym-RL，昇腾加持，开创智能体训练新范式</a></li>
<li><a href="https://mp.weixin.qq.com/s/Xv32OYDaH0aN2_LWLP9A-Q"target="_blank" rel="external nofollow noopener noreferrer">刚刚，Thinking Machines Lab首次发长文，揭开LLM推理不确定性真相</a></li>
<li><a href="https://mp.weixin.qq.com/s/iwm-a9-Xv717rmwUF2L32g"target="_blank" rel="external nofollow noopener noreferrer">谷歌AI新里程碑：一个能「做研究」的系统诞生了，用LLM+树搜索编写专家级软件</a></li>
<li><a href="https://mp.weixin.qq.com/s/yNufp4GxLVKWJMmpusYWwQ"target="_blank" rel="external nofollow noopener noreferrer">SFT远不如RL？永不过时的剃刀原则打开「终身学习」大模型训练的大门</a></li>
<li><a href="https://mp.weixin.qq.com/s/HYoyAJ5tV5FivXqeL0Vqjw"target="_blank" rel="external nofollow noopener noreferrer">国内外AI大厂重押，初创梭哈，谁能凭「记忆」成为下一个「DeepSeek」？</a></li>
<li><a href="https://mp.weixin.qq.com/s/zTsVDez9MAZgkxD55gVpuw"target="_blank" rel="external nofollow noopener noreferrer">不止会动嘴，还会「思考」！字节跳动发布OmniHuman-1.5，让虚拟人拥有逻辑灵魂</a></li>
<li><a href="https://mp.weixin.qq.com/s/npVlrEwMuawDXkeDY_HENQ"target="_blank" rel="external nofollow noopener noreferrer">自搜索强化学习SSRL：Agentic RL的Sim2Real时刻</a></li>
</ol>
<h1 id="113-新智元">1.1.3 新智元</h1>
<h1 id="114-agi-hunt">1.1.4 AGI Hunt</h1>
<h1 id="115-其他">1.1.5 其他</h1>
<h1 id="12-arxiv">1.2 Arxiv</h1>
<h1 id="121-computation-and-language">1.2.1 Computation and Language</h1>
<p><strong>From：</strong><a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">https:// /arxiv/cs.CL</a></p>
<p>From：https://arxiv.org/list/cs.CL/recent</p>
<h2 id="2025-09-12">2025-09-12</h2>
<p>2025-09-12 |   | Total: 55</p>
<h2 id="1-cde大型语言模型中高效强化学习的好奇心驱动探索-2631"><a href="https://arxiv.org/abs/2509.09675"target="_blank" rel="external nofollow noopener noreferrer">#1</a> <a href="https://papers.cool/arxiv/2509.09675"target="_blank" rel="external nofollow noopener noreferrer">CDE：大型语言模型中高效强化学习的好奇心驱动探索</a> 2631]</h2>
<p><strong>Authors</strong>: [Runpeng Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Runpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Runpeng</a> Dai), [Linfeng Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Linfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Linfeng</a> Song), [Haolin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haolin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haolin</a> Liu), [Zhenwen Liang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenwen</a> Liang), [Dian Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dian</a> Yu), [Haitao Mi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haitao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haitao</a> Mi), [Zhaopeng Tu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaopeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaopeng</a> Tu), [Rui Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rui</a> Liu), [Tong Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tong</a> Zheng), [Hongtu Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongtu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongtu</a> Zhu), [Dong Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Yu)</p>
<p>具有可验证奖励的强化学习（RLVR）是增强大型语言模型（LLM）推理能力的强大范式。然而，当前的 RLVR 方法往往探索不佳，导致过早收敛和熵崩溃。为了应对这一挑战，我们引入了好奇心驱动探索 （CDE），这是一个利用模型自身内在的好奇心来指导探索的框架。我们用来自演员和批评者的信号来形式化好奇心：对于演员，我们对其生成的反应使用困惑，而对于批评者，我们使用来自多头架构的价值估计方差。这两个信号都作为 RLVR 框架内的探索奖励来指导模型。我们的理论分析表明，参与者明智的奖励本质上会惩罚过度自信的错误，并促进正确回答的多样性;此外，我们将评论家明智的奖励与 RL 中完善的基于计数的探索奖励联系起来。根据经验，我们的方法在AIME基准测试中使用GRPO/PPO的标准RLVR比标准RLVR提高了大约+3个百分点。进一步分析确定了 RLVR 中的校准崩溃机制，揭示了常见的 LLM 故障模式。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 17：59：17 UTC</p>
<h2 id="2-通过专家取消激活来指导-moe-llm-914"><a href="https://arxiv.org/abs/2509.09660"target="_blank" rel="external nofollow noopener noreferrer">#2</a> <a href="https://papers.cool/arxiv/2509.09660"target="_blank" rel="external nofollow noopener noreferrer">通过专家（取消）激活来指导 MoE LLM</a> 914]</h2>
<p><strong>Authors</strong>: [Mohsen Fayyaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohsen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohsen</a> Fayyaz), [Ali Modarressi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ali</a> Modarressi), [Hanieh Deilamsalehy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hanieh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hanieh</a> Deilamsalehy), [Franck Dernoncourt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Franck"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Franck</a> Dernoncourt), [Ryan Rossi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ryan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ryan</a> Rossi), [Trung Bui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Trung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Trung</a> Bui), [Hinrich Schütze](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hinrich"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hinrich</a> Schütze), [Nanyun Peng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nanyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nanyun</a> Peng)</p>
<p>大型语言模型 （LLM） 中的专家混合 （MoE） 通过专门的前馈网络 （FFN） 子集（称为专家）路由每个代币。我们提出了 SteerMoE，这是一个通过检测和控制行为相关专家来引导 MoE 模型的框架。我们的检测方法可以识别出在表现出对比行为的配对输入中具有不同激活模式的专家。通过在推理过程中有选择地（停用）这些专家，我们可以控制忠诚和安全等行为，而无需重新训练或修改权重。在 11 个基准测试和 6 个 LLM 中，我们的转向将安全性提高了 +20%，忠实度提高了 +27%。在对抗性攻击模式下，它单独降低安全性 -41%，与现有越狱方法结合使用时降低 -100%，绕过所有安全护栏，暴露了隐藏在专家体内的对齐伪造的新维度。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 17：55：09 UTC</p>
<h2 id="3-all-for-onellm-在最后一个-token-处用从其他-token-传输的信息解决心算问题-35"><a href="https://arxiv.org/abs/2509.09650"target="_blank" rel="external nofollow noopener noreferrer">#3</a> <a href="https://papers.cool/arxiv/2509.09650"target="_blank" rel="external nofollow noopener noreferrer">All for One：LLM 在最后一个 token 处用从其他 token 传输的信息解决心算问题</a> 35]</h2>
<p><strong>Authors</strong>: [Siddarth Mamidanna](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siddarth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siddarth</a> Mamidanna), [Daking Rai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daking"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daking</a> Rai), [Ziyu Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziyu</a> Yao), [Yilun Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yilun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yilun</a> Zhou)</p>
<p>大型语言模型 （LLM） 在众多计算任务中表现出熟练程度，但其内部工作原理仍不清楚。理论上，因果自注意力和多层感知器层的结合允许每个 token 访问和计算基于所有先前 token 的信息。在实践中，这种作在多大程度上存在？在本文中，在心算任务（即通过下一个标记预测进行直接数学计算，无需明确推理）中，我们分三个步骤研究了这个问题：在初始层中抑制特定于输入的标记计算，在接下来的几层中限制跨标记位置的信息传输路径，并强制所有计算发生在其余层的最后一个标记处。通过上下文感知平均消融（CAMA）和基于注意力的窥视（ABP）这两种技术，我们确定了一个在各种心算任务上具有高精度的All-for-One子图（AF1），其中有意义的计算发生得很晚（就层深度而言）并且仅在最后一个标记处发生，该标记在几个特定的中间层接收其他标记的信息。对各种模型和算术表达式的实验表明，该子图对于高模型性能、跨不同模型的传输以及适用于各种输入风格来说是足够且必要的。不同 CAMA 和 ABP 替代方案的消融揭示了它们相对于其他方法的独特优势，这可能具有独立的兴趣。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 17：41：29 UTC</p>
<h2 id="4-弥合能力差距协调基于-llm-的多智能体系统的联合对齐调整-54"><a href="https://arxiv.org/abs/2509.09629"target="_blank" rel="external nofollow noopener noreferrer">#4</a> <a href="https://papers.cool/arxiv/2509.09629"target="_blank" rel="external nofollow noopener noreferrer">弥合能力差距：协调基于 LLM 的多智能体系统的联合对齐调整</a> 54]</h2>
<p><strong>Authors</strong>: [Minghang Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minghang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minghang</a> Zhu), [Zhengliang Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhengliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhengliang</a> Shi), [Zhiwei Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiwei</a> Xu), [Shiguang Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiguang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiguang</a> Wu), [Lingjie Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingjie</a> Wang), [Pengjie Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pengjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pengjie</a> Ren), [Zhaochun Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaochun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaochun</a> Ren), [Zhumin Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhumin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhumin</a> Chen)</p>
<p>大型语言模型（LLM）的进步使得多智能体系统的构建成为可能，通过在专门的智能体之间划分职责来解决复杂的任务，例如用于生成子目标的规划代理和用于执行工具使用作的基础智能体。大多数现有方法通常独立微调这些智能体，导致它们之间的能力差距，协调性差。为了解决这个问题，我们提出了 MOAT，这是一个多智能体联合对齐调整框架，通过迭代对齐来改善智能体协作。MOAT 在两个关键阶段之间交替：（1） 规划代理对齐，优化规划代理以生成子目标序列，从而更好地指导接地代理;（2）接地剂改进，利用代理本身生成的各种子目标-动作对接地剂进行微调，以增强其泛化能力。理论分析证明，MOAT保证了训练过程的不递减和渐进收敛。六个基准测试的实验表明，MOAT 的性能优于最先进的基线，在搁置任务上实现了 3.1% 的平均改进，在搁置任务上实现了 4.4% 的平均改进。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 17：15：45 UTC</p>
<h2 id="5-lava用于确定死因的语言模型辅助口头尸检-1"><a href="https://arxiv.org/abs/2509.09602"target="_blank" rel="external nofollow noopener noreferrer">#5</a> <a href="https://papers.cool/arxiv/2509.09602"target="_blank" rel="external nofollow noopener noreferrer">LAVA：用于确定死因的语言模型辅助口头尸检</a> 1]</h2>
<p><strong>Authors</strong>: [Yiqun T. Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiqun</a> T. Chen), [Tyler H. McCormick](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tyler"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tyler</a> H. McCormick), [Li Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Li"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Li</a> Liu), [Abhirup Datta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abhirup"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abhirup</a> Datta)</p>
<p>口头尸检 （VA） 是在资源有限且无法获得医疗证明的环境中估计死因的重要工具。本研究提出了 LA-VA，这是一种概念验证管道，它将大型语言模型 （LLM） 与传统算法方法和基于嵌入的分类相结合，以改进死因预测。使用跨三个年龄类别的人口健康指标研究联盟 （PHMRC） 数据集（成人：7,580;儿童：1,960;新生儿：2,438），我们评估了多种方法：GPT-5 预测、LCVA 基线、文本嵌入和元学习者集成。我们的结果表明，GPT-5 实现了最高的个人表现，平均测试站点准确率分别为 48.6%（成人）、50.5%（儿童）和 53.5%（新生儿），比传统的统计机器学习基线高出 5-10%。我们的研究结果表明，简单的现成法学硕士辅助方法可以显着提高口头尸检的准确性，对资源匮乏环境中的全球健康监测具有重要意义。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/stat.AP"target="_blank" rel="external nofollow noopener noreferrer">应用</a></p>
<p><strong>发布</strong>: 2025-09-11 16：42：22 UTC</p>
<h2 id="6-流利但无情语言模型的情感盲点-1"><a href="https://arxiv.org/abs/2509.09593"target="_blank" rel="external nofollow noopener noreferrer">#6</a> <a href="https://papers.cool/arxiv/2509.09593"target="_blank" rel="external nofollow noopener noreferrer">流利但无情：语言模型的情感盲点</a> 1]</h2>
<p><strong>Authors</strong>: [Bangzhao Shu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bangzhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bangzhao</a> Shu), [Isha Joshi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Isha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Isha</a> Joshi), [Melissa Karnaze](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Melissa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Melissa</a> Karnaze), [Anh C. Pham](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anh</a> C. Pham), [Ishita Kakkar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ishita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ishita</a> Kakkar), [Sindhu Kothe](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sindhu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sindhu</a> Kothe), [Arpine Hovasapian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arpine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arpine</a> Hovasapian), [Mai ElSherief](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mai</a> ElSherief)</p>
<p>大型语言模型 （LLM） 在自然语言理解方面的多功能性使其在心理健康研究中越来越受欢迎。虽然许多研究探讨了法学硕士在情绪识别方面的能力，但在评估法学硕士是否在细粒度上与人类情感保持一致方面仍然存在一个关键差距。现有的研究通常侧重于将情绪分类为预定义的、有限的类别，而忽略了更细致的表达。为了解决这一差距，我们推出了 EXPRESS，这是一个从 Reddit 社区策划的基准数据集，其中包含 251 个细粒度、自我公开的情绪标签。我们的综合评估框架检查预测的情绪术语，并使用既定的情绪理论将其分解为八种基本情绪，从而实现细粒度的比较。在各种提示设置下对流行的法学硕士进行系统测试表明，准确预测与人类自我表露的情绪相符的情绪仍然具有挑战性。定性分析进一步表明，虽然某些法学硕士生成的情感术语与既定的情感理论和定义一致，但它们有时无法像人类自我表露那样有效地捕捉上下文线索。这些发现凸显了法学硕士在细粒度情感调整方面的局限性，并为旨在增强其上下文理解的未来研究提供了见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 16：31：13 UTC</p>
<h2 id="7-sami-中的人格增强社交推荐探索人格检测在婚介中的作用-2"><a href="https://arxiv.org/abs/2509.09583"target="_blank" rel="external nofollow noopener noreferrer">#7</a> <a href="https://papers.cool/arxiv/2509.09583"target="_blank" rel="external nofollow noopener noreferrer">SAMI 中的人格增强社交推荐：探索人格检测在婚介中的作用</a> 2]</h2>
<p><strong>Authors</strong>: [Brittany Harbison](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Brittany"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Brittany</a> Harbison), [Samuel Taubman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Samuel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Samuel</a> Taubman), [Travis Taylor](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Travis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Travis</a> Taylor), [Ashok. K. Goel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ashok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ashok</a>. K. Goel)</p>
<p>社会联系是学习的重要组成部分，但在线课程环境对社会群体的有机形成构成了障碍。SAMI 通过促进学生联系提供了一种解决方案，但其有效性受到不完整的心理理论的限制，限制了其创建学生有效心理模型的能力。其中一个方面是它无法直觉地了解个性，这可能会影响其建议的相关性。为了探索这一点，我们提出了一种人格检测模型，利用 GPT 的零样本功能从论坛介绍帖子中推断出五巨头性格特征，这在在线课程中经常受到鼓励。我们将其性能与既定模型进行基准测试，证明其在这项任务中的有效性。此外，我们将该模型集成到 SAMI 基于实体的匹配系统中，从而实现基于个性的社交推荐。初步整合表明，人格特征可以补充现有的匹配因素，但需要额外的评估来确定它们对学生参与度和匹配质量的全面影响。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.SI"target="_blank" rel="external nofollow noopener noreferrer">社会和信息网络</a></p>
<p><strong>发布</strong>: 2025-09-11 16：19：59 UTC</p>
<h2 id="8-促使市场genai-在金融-nlp-中的大规模荟萃分析2022-2025-1"><a href="https://arxiv.org/abs/2509.09544"target="_blank" rel="external nofollow noopener noreferrer">#8</a> <a href="https://papers.cool/arxiv/2509.09544"target="_blank" rel="external nofollow noopener noreferrer">促使市场？GenAI 在金融 NLP 中的大规模荟萃分析（2022-2025）</a> 1]</h2>
<p><strong>Authors</strong>: [Paolo Pedinotti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Paolo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Paolo</a> Pedinotti), [Peter Baumann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peter"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peter</a> Baumann), [Nathan Jessurun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nathan</a> Jessurun), [Leslie Barrett](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leslie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leslie</a> Barrett), [Enrico Santus](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Enrico"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Enrico</a> Santus)</p>
<p>大型语言模型 （LLM） 迅速重塑了金融 NLP，支持新任务并推动数据集的激增和数据源的多样化。然而，这种转变已经超过了传统调查。在本文中，我们提出了 MetaGraph，这是一种可推广的方法，用于从科学文献中提取知识图谱并对其进行分析，以获得结构化的、可查询的研究趋势视图。我们定义了金融NLP研究的本体论，并将基于LLM的提取管道应用于681篇论文（2022-2025年），实现大规模、数据驱动的分析。MetaGraph 揭示了三个关键阶段：早期 LLM 采用和任务/数据集创新;对法学硕士局限性的批判性反思;以及外围技术越来越多地集成到模块化系统中。这种结构化的视图使从业者和研究人员能够清楚地了解金融自然语言处理是如何演变的——突出新兴趋势、优先事项的转变和方法论的转变——同时还展示了一种可重复使用的方法来绘制其他领域的科学进展。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 15：37：56 UTC</p>
<h2 id="9-lewidi-2025-上的-demeva使用上下文学习和标签分布学习对视角进行建模-4"><a href="https://arxiv.org/abs/2509.09524"target="_blank" rel="external nofollow noopener noreferrer">#9</a> <a href="https://papers.cool/arxiv/2509.09524"target="_blank" rel="external nofollow noopener noreferrer">LeWiDi-2025 上的 DeMeVa：使用上下文学习和标签分布学习对视角进行建模</a> 4]</h2>
<p><strong>Authors</strong>: [Daniil Ignatev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniil</a> Ignatev), [Nan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nan</a> Li), [Hugh Mee Wong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hugh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hugh</a> Mee Wong), [Anh Dang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anh</a> Dang), [Shane Kaszefski Yaschuk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shane"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shane</a> Kaszefski Yaschuk)</p>
<p>本系统论文介绍了 DeMeVa 团队对第三版“分歧学习”共享任务（LeWiDi 2025;Leonardelli 等人，2025 年）。我们探索两个方向：使用大型语言模型进行上下文学习（ICL），其中我们比较示例采样策略;以及使用 RoBERTa 的标签分布学习 （LDL） 方法（Liu 等人，2019b），我们评估了几种微调方法。我们的贡献是双重的：（1）我们表明ICL可以有效地预测特定于注释者的注释（透视主义注释），并且将这些预测聚合到软标签中会产生竞争性能;（2）我们认为LDL方法对于软标签预测很有希望，值得透视主义社区进一步探索。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 15：04：42 UTC</p>
<h2 id="10-迈向可解释的职位匹配利用语义文本相关性和知识图谱-12"><a href="https://arxiv.org/abs/2509.09522"target="_blank" rel="external nofollow noopener noreferrer">#10</a> <a href="https://papers.cool/arxiv/2509.09522"target="_blank" rel="external nofollow noopener noreferrer">迈向可解释的职位匹配：利用语义文本相关性和知识图谱</a> 12]</h2>
<p><strong>Authors</strong>: [Vadim Zadykian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vadim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vadim</a> Zadykian), [Bruno Andrade](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bruno"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bruno</a> Andrade), [Haithem Afli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haithem"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haithem</a> Afli)</p>
<p>语义文本相关性 （STR） 捕获文本之间超越表面词汇相似性的微妙关系。在这项研究中，我们在职位匹配的背景下调查了 STR——这是简历推荐系统中的一个关键挑战，其中重叠的术语通常是有限的或具有误导性的。我们引入了一种自监督混合架构，该架构将密集的句子嵌入与特定领域的知识图谱 （KG） 相结合，以提高语义对齐和可解释性。与之前评估聚合性能模型的工作不同，我们的方法通过将 STR 分数连续体划分为不同的区域来强调数据分层：低、中和高语义相关性。这种分层评估可以对语义有意义的子空间中的模型性能进行细粒度分析。我们通过图神经网络评估了几种嵌入模型，包括有和没有 KG 集成。结果表明，用 KG 增强的微调 SBERT 模型在高 STR 区域产生了一致的改进，其中 RMSE 在强基线上降低了 25%。我们的研究结果不仅强调了将 KG 与文本嵌入相结合的好处，还强调了区域性能分析在理解模型行为方面的重要性。这种精细方法揭示了全局指标隐藏的优势和劣势，并支持更有针对性的模型选择，以用于公平性、可解释性和上下文匹配至关重要的人力资源 （HR） 系统和应用程序。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 15：02：54 UTC</p>
<h2 id="11-减少教育中的语言障碍利用机器翻译开发多语言数字学习材料-1"><a href="https://arxiv.org/abs/2509.09473"target="_blank" rel="external nofollow noopener noreferrer">#11</a> <a href="https://papers.cool/arxiv/2509.09473"target="_blank" rel="external nofollow noopener noreferrer">减少教育中的语言障碍：利用机器翻译开发多语言数字学习材料</a> 1]</h2>
<p><strong>Authors</strong>: [Lucie Poláková](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lucie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lucie</a> Poláková), [Martin Popel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Martin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Martin</a> Popel), [Věra Kloudová](<a href="https://arxiv.org/search/?searchtype=author&amp;query=V"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=V</a>ěra Kloudová), [Michal Novák](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michal</a> Novák), [Mariia Anisimova](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mariia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mariia</a> Anisimova), [Jiří Balhar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ji</a>ří Balhar)</p>
<p>EdUKate 项目将数字教育、语言学、翻译研究和机器翻译相结合，为捷克中小学开发多语言学习材料。该项目由捷克一家主要学术机构与该国最大的教育出版商合作启动，旨在将多达 9,000 个多模式互动练习从捷克语翻译成乌克兰语、英语和德语，用于教育门户网站。它强调开发和评估针对教育领域量身定制的直接捷克-乌克兰机器翻译系统，特别注意处理 XML 和 PDF 等格式化内容以及处理技术和科学术语。我们介绍了对捷克教师关于非捷克语学生需求的初步调查结果，并在门户网站上描述了该系统的评估和实施情况。所有生成的应用程序都可供学生、教育工作者和研究人员免费使用。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 13：54：44 UTC</p>
<h2 id="12-grace一种在大型语言模型中更好地提取信心的生成方法-21"><a href="https://arxiv.org/abs/2509.09438"target="_blank" rel="external nofollow noopener noreferrer">#12</a> <a href="https://papers.cool/arxiv/2509.09438"target="_blank" rel="external nofollow noopener noreferrer">GrACE：一种在大型语言模型中更好地提取信心的生成方法</a> 21]</h2>
<p><strong>Authors</strong>: [Zhaohan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaohan</a> Zhang), [Ziquan Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziquan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziquan</a> Liu), [Ioannis Patras](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ioannis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ioannis</a> Patras)</p>
<p>通过置信度引出来评估大型语言模型 （LLM） 的可靠性是医疗保健和金融等高风险应用中人工智能安全的一种重要方法。现有方法要么需要昂贵的计算开销，要么校准不佳，这使得它们对于实际部署来说不切实际且不可靠。在这项工作中，我们提出了 GrACE，这是一种信心提取的生成方法，可为法学硕士提供可扩展且可靠的信心提取。GrACE 采用了一种新颖的机制，其中模型通过最后一个隐藏状态之间的相似性和实时附加到词汇表中的特殊标记之间的相似性来表达置信度。我们微调模型，以使用与准确性相关的校准目标来校准置信度。对三个 LLM 和两个基准数据集的实验表明，GrACE 产生的置信度在开放式生成任务上实现了最佳的判别能力和校准，优于六种竞争方法，而无需诉诸额外的采样或辅助模型。此外，我们提出了两种策略，以基于 GrACE 诱导的置信度来改善测试时间缩放。实验结果表明，使用GrACE不仅提高了最终决策的准确性，而且显著减少了测试时间缩放方案中所需的样本数量，表明GrACE作为部署具有可扩展、可靠和实时置信度估计的LLM的实用解决方案的潜力。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 13：25：40 UTC</p>
<h2 id="13-分层括号编码适用于依赖关系图-1"><a href="https://arxiv.org/abs/2509.09388"target="_blank" rel="external nofollow noopener noreferrer">#13</a> <a href="https://papers.cool/arxiv/2509.09388"target="_blank" rel="external nofollow noopener noreferrer">分层括号编码适用于依赖关系图</a> 1]</h2>
<p><strong>Authors</strong>: [Ana Ezquerro](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ana</a> Ezquerro), [Carlos Gómez-Rodríguez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Carlos"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Carlos</a> Gómez-Rodríguez), [David Vilares](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Vilares)</p>
<p>我们在依赖图解析的上下文中从实际角度重新审视分层括号编码。该方法将图形编码为序列，从而实现线性时间解析 n 标记作，并且仍然表示重入、循环和空节点。与现有的图线性化相比，这种表示大大减少了标签空间，同时保留了结构信息。我们在多语言和多形式基准上对其进行评估，显示出具有竞争力的结果，并且在精确匹配准确性方面比其他方法具有持续的改进。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 12：08：22 UTC</p>
<h2 id="14-模拟类比和类比推理连接认知科学理论和自然语言处理研究-12"><a href="https://arxiv.org/abs/2509.09381"target="_blank" rel="external nofollow noopener noreferrer">#14</a> <a href="https://papers.cool/arxiv/2509.09381"target="_blank" rel="external nofollow noopener noreferrer">模拟类比和类比推理：连接认知科学理论和自然语言处理研究</a> 12]</h2>
<p><strong>Authors</strong>: [Molly R Petersen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Molly"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Molly</a> R Petersen), [Claire E Stevenson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Claire"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Claire</a> E Stevenson), [Lonneke van der Plas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lonneke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lonneke</a> van der Plas)</p>
<p>类比推理是人类认知的一个重要方面。在本文中，我们总结了认知科学文献中关于类比推理背后过程的关键理论，并将其与当前自然语言处理的研究联系起来。虽然这些过程可以很容易地与 NLP 中的概念联系起来，但通常不会通过认知视角来看待它们。此外，我们展示了这些概念如何与NLP研究中的几个主要挑战相关，与类比求解没有直接关系。这可能会指导研究人员更好地优化文本中的关系理解，而不是严重依赖实体级相似性。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 11：57：58 UTC</p>
<h2 id="15-metarag用于-rag-系统幻觉检测的变质测试-12"><a href="https://arxiv.org/abs/2509.09360"target="_blank" rel="external nofollow noopener noreferrer">#15</a> <a href="https://papers.cool/arxiv/2509.09360"target="_blank" rel="external nofollow noopener noreferrer">MetaRAG：用于 RAG 系统幻觉检测的变质测试</a> 12]</h2>
<p><strong>Authors</strong>: [Channdeth Sok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Channdeth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Channdeth</a> Sok), [David Luz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Luz), [Yacine Haddam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yacine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yacine</a> Haddam)</p>
<p>大型语言模型 （LLM） 越来越多地部署在企业应用程序中，但其可靠性仍然受到幻觉的限制，即自信但事实不正确的信息。现有的检测方法，例如 SelfCheckGPT 和 MetaQA，主要针对独立的 LLM，无法解决检索增强生成 （RAG） 系统的独特挑战，其中响应必须与检索到的证据一致。因此，我们提出了MetaRAG，这是一种用于检索增强生成（RAG）系统中幻觉检测的变质测试框架。MetaRAG 在实时、无监督、黑盒环境中运行，既不需要真实参考，也不需要访问模型内部，使其适用于专有和高风险领域。该框架分四个阶段进行：（1） 将答案分解为原子事实，（2） 使用同义词和反义词替换生成每个事实的受控突变，（3） 根据检索到的上下文验证每个变体（预计需要同义词和反义词矛盾），以及 （4） 将不一致的惩罚汇总到响应水平幻觉分数中。对于身份感知人工智能来说至关重要的是，MetaRAG 将不受支持的索赔本地化到发生的事实跨度（例如，针对怀孕的预防措施、LGBTQ+ 难民权利或劳动力资格），允许用户查看标记的跨度，并使系统设计人员能够为身份敏感查询配置阈值和护栏。在专有企业数据集上的实验说明了 MetaRAG 在检测幻觉和实现基于 RAG 的对话代理的可信部署方面的有效性。我们还概述了一种基于主题的部署设计，将 MetaRAG 的跨度级分数转化为身份感知保护措施;我们的实验中讨论了这种设计，但没有评估。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 11：18：23 UTC</p>
<h2 id="16-从零到银使用大型语言模型为专利-可持续发展目标分类创建可信的训练数据-1"><a href="https://arxiv.org/abs/2509.09303"target="_blank" rel="external nofollow noopener noreferrer">#16</a> <a href="https://papers.cool/arxiv/2509.09303"target="_blank" rel="external nofollow noopener noreferrer">从零到银：使用大型语言模型为专利-可持续发展目标分类创建可信的训练数据</a> 1]</h2>
<p><strong>Authors</strong>: [Grazia Sveva Ascione](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Grazia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Grazia</a> Sveva Ascione), [Nicolò Tamagnone](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicol"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicol</a>ò Tamagnone)</p>
<p>根据专利与联合国可持续发展目标 （SDG） 的相关性对专利进行分类对于跟踪创新如何应对全球挑战至关重要。然而，由于缺乏大型标记数据集，限制了监督学习的使用。现有方法，例如关键字搜索、迁移学习和基于引文的启发式方法，缺乏可扩展性和普遍性。本文将专利到可持续发展目标的分类视为一个弱监管问题，使用从专利到可持续发展目标标记的科学出版物的引用（NPL 引用）作为嘈杂的初始信号。为了解决其稀疏性和噪声问题，我们开发了一种复合标记函数（LF），该函数使用大型语言模型（LLM）从基于专利本体的专利和可持续发展目标论文中提取结构化概念，即功能、解决方案和应用。使用基于排名的检索方法计算和组合跨域相似性分数。LF 通过自定义的仅正损失进行校准，该损失与已知的 NPL-SDG 链接保持一致，而不会惩罚发现新的 SDG 关联。其结果是一个银标准、软多标签数据集，将专利映射到可持续发展目标，从而能够训练有效的多标签回归模型。我们通过两种互补策略验证我们的方法：（1） 针对搁置的基于 NPL 的标签进行内部验证，其中我们的方法优于多个基线，包括基于 Transformer 的模型和零样本 LLM;（2）在专利引文、共同发明人和共同申请人图表中使用网络模块化进行外部验证，其中我们的标签比传统的技术分类揭示了更大的主题、认知和组织一致性。这些结果表明，弱监督和语义对齐可以大规模增强可持续发展目标分类。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 09：44：16 UTC</p>
<h2 id="17-用于对表格数据进行问答的代理-llm-2"><a href="https://arxiv.org/abs/2509.09234"target="_blank" rel="external nofollow noopener noreferrer">#17</a> <a href="https://papers.cool/arxiv/2509.09234"target="_blank" rel="external nofollow noopener noreferrer">用于对表格数据进行问答的代理 LLM</a> 2]</h2>
<p><strong>Authors</strong>: [Rishit Tyagi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rishit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rishit</a> Tyagi), [Mohit Gupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohit</a> Gupta), [Rahul Bouri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rahul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rahul</a> Bouri)</p>
<p>由于现实世界表格的结构、大小和数据类型不同，表格数据（表格 QA）的问答提出了独特的挑战。SemEval 2025 任务 8 （DataBench） 引入了一个由大规模、领域多样化的数据集组成的基准测试，以评估模型准确回答结构化查询的能力。我们提出了一种自然语言转 SQL （NL-to-SQL） 方法，利用 GPT-4o、GPT-4o-mini 和 DeepSeek v2：16b 等大型语言模型 （LLM） 动态生成 SQL 查询。我们的系统遵循多阶段管道，涉及示例选择、SQL 查询生成、答案提取、验证和迭代细化。实验证明了我们方法的有效性，在 DataBench QA 上达到了 70.5% 的准确率，在 DataBench Lite QA 上达到了 71.6%，分别显着超过了 26% 和 27% 的基线分数。本文详细介绍了我们的方法、实验结果和替代方法，深入了解了法学硕士驱动的表格 QA 的优势和局限性。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 08：12：38 UTC</p>
<h2 id="18-字里行间阅读使用大型语言模型对简历资历进行分类-1"><a href="https://arxiv.org/abs/2509.09229"target="_blank" rel="external nofollow noopener noreferrer">#18</a> <a href="https://papers.cool/arxiv/2509.09229"target="_blank" rel="external nofollow noopener noreferrer">字里行间阅读：使用大型语言模型对简历资历进行分类</a> 1]</h2>
<p><strong>Authors</strong>: [Matan Cohen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matan</a> Cohen), [Shira Shani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shira"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shira</a> Shani), [Eden Menahem](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eden"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eden</a> Menahem), [Yehudit Aperstein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yehudit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yehudit</a> Aperstein), [Alexander Apartsin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Apartsin)</p>
<p>从简历中准确评估候选人的资历是一项关键但具有挑战性的任务，由于普遍存在夸大的经验和模棱两可的自我介绍，这使得事情变得复杂。在这项研究中，我们调查了大型语言模型 （LLM）（包括微调的 BERT 架构）在简历中自动进行资历分类方面的有效性。为了严格评估模型性能，我们引入了一个混合数据集，该数据集包含现实世界的简历和合成生成的硬示例，旨在模拟夸大的资格和低调的资历。使用该数据集，我们评估了大型语言模型在检测与资历膨胀和隐性专业知识相关的微妙语言线索方面的表现。我们的研究结果强调了增强人工智能驱动的候选人评估系统和减轻自我推销语言引入的偏见的有希望的方向。该数据集可供研究界使用 <a href="https://bit.ly/4mcTovt"target="_blank" rel="external nofollow noopener noreferrer">https://bit.ly/4mcTovt</a></p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 08：06：02 UTC</p>
<h2 id="19-ccf用于高效长序列语言建模的上下文压缩框架-35"><a href="https://arxiv.org/abs/2509.09199"target="_blank" rel="external nofollow noopener noreferrer">#19</a> <a href="https://papers.cool/arxiv/2509.09199"target="_blank" rel="external nofollow noopener noreferrer">CCF：用于高效长序列语言建模的上下文压缩框架</a> 35]</h2>
<p><strong>Authors</strong>: [Wenhao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenhao</a> Li), [Bangcheng Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bangcheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bangcheng</a> Sun), [Weihao Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weihao</a> Ye), [Tianyi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyi</a> Zhang), [Daohai Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daohai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daohai</a> Yu), [Fei Chao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fei</a> Chao), [Rongrong Ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rongrong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rongrong</a> Ji)</p>
<p>将语言模型扩展到更长的上下文对于捕获扩展话语中的丰富依赖关系至关重要。然而，朴素的上下文扩展会带来巨大的计算和内存负担，通常会导致训练和推理过程中效率低下。在这项工作中，我们提出了 CCF，这是一种新颖的上下文压缩框架，旨在通过学习分层潜在表示来实现高效的长上下文建模，这些表示保留了全局语义，同时积极减少输入冗余。CCF 将段式语义聚合与键值存储器编码相结合，形成紧凑的表示，支持准确的重建和远程理解。为了进一步增强可扩展性，我们引入了一种训练高效的优化策略，该策略将增量段解码与稀疏储层采样相结合，从而在不降低性能的情况下大幅降低内存开销。在多个长上下文语言建模基准上的实证结果表明，CCF在高压缩比下实现了竞争性困惑度，与现有方法相比，CCF显著提高了吞吐量和内存效率。这些发现凸显了结构化压缩在可扩展且有效的长上下文语言建模方面的潜力。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 07：13：49 UTC</p>
<h2 id="20-gmslm生成狨猴口语建模-1"><a href="https://arxiv.org/abs/2509.09198"target="_blank" rel="external nofollow noopener noreferrer">#20</a> <a href="https://papers.cool/arxiv/2509.09198"target="_blank" rel="external nofollow noopener noreferrer">GmSLM：生成狨猴口语建模</a> 1]</h2>
<p><strong>Authors</strong>: [Talia Sternberg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Talia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Talia</a> Sternberg), [Michael London](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> London), [David Omer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Omer), [Yossi Adi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yossi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yossi</a> Adi)</p>
<p>狨猴表现出复杂的声音交流，挑战了非人类灵长类动物的声音交流完全是与生俱来的观点，并表现出人类语言的相似特征，例如对他人的声音标签和轮流。研究他们的声音交流提供了一个独特的机会，可以将其与大脑活动联系起来——特别是考虑到在言语和语言研究中很难接触到人脑。由于狨猴主要通过发声进行交流，因此应用标准法学硕士方法并不简单。我们介绍了生成式狨猴口语建模 （GmSLM），这是一种用于狨猴语音交流的优化口语模型管道。我们设计了一种新颖的零样本评估指标，使用无监督的野外数据以及弱标记的对话数据来评估 GmSLM，并证明其相对于基于人类语音的基本基线的优势。GmSLM 生成的发声在声学上与真实再合成样本非常匹配，并且在下游任务中表现良好。尽管完全无监督，但 GmSLM 有效地区分了真实对话和人工对话，并可能支持对声音交流神经基础的进一步研究，并提供了一个将发声和大脑活动联系起来的实用框架。我们相信 GmSLM 将有利于神经科学、生物声学和进化生物学领域的未来工作。样品提供于以下内容：pages.cs.huji.ac.il/adiyoss-lab/GmSLM。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 07：13：44 UTC</p>
<h2 id="21-使用关键字感知成本函数改进上下文偏差模型的合成数据训练-2"><a href="https://arxiv.org/abs/2509.09197"target="_blank" rel="external nofollow noopener noreferrer">#21</a> <a href="https://papers.cool/arxiv/2509.09197"target="_blank" rel="external nofollow noopener noreferrer">使用关键字感知成本函数改进上下文偏差模型的合成数据训练</a> 2]</h2>
<p><strong>Authors</strong>: [Chin Yuen Kwok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chin</a> Yuen Kwok), [Jia Qi Yip](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Qi Yip), [Eng Siong Chng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eng</a> Siong Chng)</p>
<p>通过使 ASR 模型适应包含这些单词的合成数据，可以改进稀有词识别。可以通过上下文偏差来实现进一步的改进，上下文偏差训练并将偏差模块添加到模型架构中，以优先考虑稀有单词。虽然在合成稀有词数据上训练模块比使用非稀有词数据更有效，但由于合成音频中的伪影，它可能会导致过度拟合。为了解决这个问题，我们增强了基于TCPGen的上下文偏差方法，并提出了一个关键字感知损失函数，该函数在训练偏差模块时额外关注有偏差的单词。这种损失包括用于有偏见词预测的掩码交叉熵项和用于检测有偏见词位置的二元分类项。这两个术语互补地支持在推理过程中解码有偏见的单词。通过将 Whisper 适应 10 小时的合成数据，我们的方法将 NSC 第 2 部分测试集的单词错误率从 29.71% 降低到 11.81%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 07：12：17 UTC</p>
<h2 id="22-使用k步预测进行稀有词识别的基于三重的高效偏差-1"><a href="https://arxiv.org/abs/2509.09196"target="_blank" rel="external nofollow noopener noreferrer">#22</a> <a href="https://papers.cool/arxiv/2509.09196"target="_blank" rel="external nofollow noopener noreferrer">使用K步预测进行稀有词识别的基于三重的高效偏差</a> 1]</h2>
<p><strong>Authors</strong>: [Chin Yuen Kwok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chin</a> Yuen Kwok), [Jia Qi yip](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Qi yip)</p>
<p>上下文偏差通过在解码过程中优先考虑生僻字的输出来改进 ASR 模型的生僻字识别。一种常见的方法是基于 Trie 的偏差，它为部分假设（例如“Bon”）提供“奖励分数”，这可能导致生僻字（例如“Bonham”）的生成。如果完整的单词（“Bonham”）最终没有得到认可，系统将撤销那些早期的奖金。这种撤销仅限于波束搜索，并且计算成本很高，特别是对于具有大型解码器的模型。为了克服这些限制，我们建议调整 ASR 模型以展望未来并同时预测多个步骤。这通过更好地估计部分假设是否会导致生成完整的罕见词，完全避免了撤销步骤。通过仅使用10小时的合成数据对Whisper进行微调，我们的方法将NSC Part 2测试集的单词错误率从30.86%降低到12.19%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 07：11：46 UTC</p>
<h2 id="23-echox通过语音到语音法学硕士的回声训练来缓解声义差距-6"><a href="https://arxiv.org/abs/2509.09174"target="_blank" rel="external nofollow noopener noreferrer">#23</a> <a href="https://papers.cool/arxiv/2509.09174"target="_blank" rel="external nofollow noopener noreferrer">EchoX：通过语音到语音法学硕士的回声训练来缓解声义差距</a> 6]</h2>
<p><strong>Authors</strong>: [Yuhao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhao</a> Zhang), [Yuhao Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhao</a> Du), [Zhanchen Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhanchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhanchen</a> Dai), [Xiangnan Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiangnan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiangnan</a> Ma), [Kaiqi Kou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaiqi</a> Kou), [Benyou Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Benyou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Benyou</a> Wang), [Haizhou Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haizhou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haizhou</a> Li)</p>
<p>语音转语音大型语言模型（SLLM）越来越受到关注。SLLM 源自基于文本的大型语言模型 （LLM），经常表现出知识和推理能力的下降。我们假设出现这种限制是因为当前的 SLLM 训练范式未能弥合特征表示空间中的声学语义差距。为了解决这个问题，我们提出了 EchoX，它利用语义表示并动态生成语音训练目标。这种方法集成了声学和语义学习，使 EchoX 能够保持作为语音 LLM 的强大推理能力。实验结果表明，EchoX 拥有约 6000 小时的训练数据，在多个基于知识的问答基准测试中取得了先进的性能。该项目可在 <a href="https://github.com/FreedomIntelligence/EchoX"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/FreedomIntelligence/EchoX</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a></p>
<p><strong>发布</strong>: 2025-09-11 06：17：59 UTC</p>
<h2 id="24-具有反事实增强去偏差的面向目标的多模态情感分类"><a href="https://arxiv.org/abs/2509.09160"target="_blank" rel="external nofollow noopener noreferrer">#24</a> <a href="https://papers.cool/arxiv/2509.09160"target="_blank" rel="external nofollow noopener noreferrer">具有反事实增强去偏差的面向目标的多模态情感分类</a></h2>
<p><strong>Authors</strong>: [Zhiyue Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyue</a> Liu), [Fanrong Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fanrong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fanrong</a> Ma), [Xin Ling](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Ling)</p>
<p>面向目标的多模态情感分类旨在从图像-文本对中预测特定目标的情感极性。虽然现有作品取得了有竞争力的表现，但它们往往过度依赖文本内容，而没有考虑数据集偏差，特别是单词级上下文偏差。这会导致文本特征和输出标签之间出现虚假相关性，从而损害分类准确性。在本文中，我们引入了一种新的反事实增强去偏差框架来减少这种虚假相关性。我们的框架采用了一种反事实数据增强策略，该策略将与情感相关的因果特征改变到最低限度，生成细节匹配的图像文本样本，以指导模型对与情感相关的内容的关注。此外，为了从反事实数据中学习鲁棒特征并提示模型决策，我们引入了一种自适应去偏对比学习机制，有效减轻了偏见词的影响。在几个基准数据集上的实验结果表明，我们提出的方法优于最先进的基线。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 05：40：53 UTC</p>
<h2 id="25-litcoder用于构建和比较编码模型的通用库"><a href="https://arxiv.org/abs/2509.09152"target="_blank" rel="external nofollow noopener noreferrer">#25</a> <a href="https://papers.cool/arxiv/2509.09152"target="_blank" rel="external nofollow noopener noreferrer">LITcoder：用于构建和比较编码模型的通用库</a></h2>
<p><strong>Authors</strong>: [Taha Binhuraib](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taha</a> Binhuraib), [Ruimin Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruimin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruimin</a> Gao), [Anna A. Ivanova](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anna</a> A. Ivanova)</p>
<p>我们介绍了 LITcoder，这是一个用于构建和基准测试神经编码模型的开源库。LITcoder 被设计为一个灵活的后端，提供了标准化工具，用于将连续刺激（例如文本和语音）与大脑数据对齐，将刺激转换为表征特征，将这些特征映射到大脑数据上，并评估结果模型对保留数据的预测性能。该库实现了一个模块化管道，涵盖了广泛的方法设计选择，因此研究人员可以轻松组合、比较和扩展编码模型，而无需重新发明核心基础设施。这些选择包括大脑数据集、大脑区域、刺激特征（基于神经网络和控制，例如字速）、下采样方法等等。此外，该库还提供内置的日志记录、绘图以及与实验跟踪平台（如权重和偏差 （W&amp;B））的无缝集成。我们通过将一系列编码模型拟合到三个故事聆听数据集来展示我们框架的可扩展性和多功能性：LeBel 等人（2023 年）、Narratives 和 Little Prince。我们还探讨了为连续功能磁共振成像数据构建编码模型的关键方法选择，说明了在 TR 扫描中考虑所有标记的重要性（而不是只获取最后一个标记，即使经过上下文化），结合血流动力学滞后效应，使用训练-测试拆分最大限度地减少信息泄漏，并考虑头部运动对编码模型预测性的影响。总体而言，LITcoder 降低了编码模型实现的技术障碍，促进了模型和数据集之间的系统比较，提高了方法论的严谨性，并加速了大脑活动高质量高性能预测模型的开发。项目页面：https://litcoder-brain.github.io</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/q-bio.NC"target="_blank" rel="external nofollow noopener noreferrer">神经元与认知</a></p>
<p><strong>发布</strong>: 2025-09-11 05：14：14 UTC</p>
<h2 id="26-viranker用于越南语重新排名的-bge-m3-和分块并联变压器交叉编码器"><a href="https://arxiv.org/abs/2509.09131"target="_blank" rel="external nofollow noopener noreferrer">#26</a> <a href="https://papers.cool/arxiv/2509.09131"target="_blank" rel="external nofollow noopener noreferrer">ViRanker：用于越南语重新排名的 BGE-M3 和分块并联变压器交叉编码器</a></h2>
<p><strong>Authors</strong>: [Phuong-Nam Dang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Phuong-Nam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Phuong-Nam</a> Dang), [Kieu-Linh Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kieu-Linh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kieu-Linh</a> Nguyen), [Thanh-Hieu Pham](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thanh-Hieu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thanh-Hieu</a> Pham)</p>
<p>本文介绍了 ViRanker，这是一种针对越南语量身定制的交叉编码器重新排序模型。ViRanker 基于 BGE-M3 编码器构建，并通过 Blockwise Parallel Transformer 进行增强，解决了越南语缺乏竞争性重新排序器的问题，越南语是一种具有复杂语法和变音符号的低资源语言。该模型在 8 GB 的精选语料库上进行了训练，并使用混合硬负采样进行了微调，以增强鲁棒性。在 MMARCO-VI 基准测试上进行评估，ViRanker 实现了强大的早期排名准确性，超越了多语言基线，并与 PhoRanker 展开了激烈的竞争。通过在 Hugging Face 上公开发布该模型，我们旨在支持可重复性并鼓励在现实世界的检索系统中更广泛地采用。除了越南语之外，这项研究还说明了仔细的架构调整和数据管理如何促进其他代表性不足的语言的重新排名。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 04：07：43 UTC</p>
<h2 id="27-使用生成式人工智能对导师对话行为进行自动分类使用-cima-语料库的案例研究-1"><a href="https://arxiv.org/abs/2509.09125"target="_blank" rel="external nofollow noopener noreferrer">#27</a> <a href="https://papers.cool/arxiv/2509.09125"target="_blank" rel="external nofollow noopener noreferrer">使用生成式人工智能对导师对话行为进行自动分类：使用 CIMA 语料库的案例研究</a> 1]</h2>
<p><strong>Authors</strong>: [Liqun He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liqun</a> He), [Jiaqi Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaqi</a> Xu)</p>
<p>本研究探讨了使用生成式人工智能对导师的对话行为（DA）进行自动分类，旨在减少传统手动编码所需的时间和精力。本案例研究使用开源 CIMA 语料库，其中导师的回答被预先注释为四个 DA 类别。GPT-3.5-turbo 和 GPT-4 模型都使用定制的提示进行了测试。结果显示，GPT-4 的准确率为 80%，加权 F1 得分为 0.81，Cohen&rsquo;s Kappa 为 0.74，超过了基线性能，并表明与人类注释基本一致。这些发现表明，生成式人工智能具有强大的潜力，可以提供一种高效且易于访问的 DA 分类方法，对教育对话分析具有有意义的影响。该研究还强调了特定于任务的标签定义和上下文信息在提高自动注释质量方面的重要性。最后，它强调了与使用生成式人工智能相关的道德考虑以及负责任和透明的研究实践的必要性。这项研究的脚本可在 <a href="https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging</a> 公开获取。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 03：36：03 UTC</p>
<h2 id="28-compass-v3为东南亚多语言电子商务扩展特定领域的-llm"><a href="https://arxiv.org/abs/2509.09121"target="_blank" rel="external nofollow noopener noreferrer">#28</a> <a href="https://papers.cool/arxiv/2509.09121"target="_blank" rel="external nofollow noopener noreferrer">Compass-v3：为东南亚多语言电子商务扩展特定领域的 LLM</a></h2>
<p><strong>Author</strong>: [Sophia Maria](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sophia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sophia</a> Maria)</p>
<p>大型语言模型 （LLM） 在通用领域应用程序中表现出色，但它们的性能在需要特定领域知识的专业任务中往往会下降。电子商务尤其具有挑战性，因为它的数据嘈杂、异构、多语言且高度动态。我们提出了 Compass-v3，这是一个垂直领域的专家混合 （MoE） 模型，具有 245B 总参数和每个令牌 71B 的活跃参数，专为东南亚电子商务而设计。Compass-v3 采用了更少但更大的专家，并结合硬件高效的优化——例如节点内专家并行性和定制的 memcpy 运算符——以最大限度地提高 GPU 利用率。该模型使用混合训练策略在精选多语言语料库和大规模合成电子商务指令的 12T 标记上进行训练。为了增强一致性，我们提出了最佳传输直接偏好优化 （OTPO），它可以捕获令牌级的区别并提高特定于商业场景中的指令依从性。广泛的评估表明，Compass-v3 提供了最先进的电子商务性能，超越了 DeepSeek-V3.1、GPT-4 系列和 Qwen3-235B。此外，Compass-v3 在资源匮乏的东南亚语言（印度尼西亚语、泰语、菲律宾语、越南语、马来语、Taglog）和葡萄牙语中表现出强大的多语言能力，同时在一般基准上保持竞争性能。它已经在 Shopee 的工业规模电商平台中得到广泛应用，并正在逐步取代 OpenAI 的流量，目前占 LLM 总使用量的 70% 以上，凸显了其在专业商务专业知识和广泛语言能力方面的双重优势。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 03：23：48 UTC</p>
<h2 id="29-tigercoder用于孟加拉语代码生成的新型法学硕士套件-12"><a href="https://arxiv.org/abs/2509.09101"target="_blank" rel="external nofollow noopener noreferrer">#29</a> <a href="https://papers.cool/arxiv/2509.09101"target="_blank" rel="external nofollow noopener noreferrer">TigerCoder：用于孟加拉语代码生成的新型法学硕士套件</a> 12]</h2>
<p><strong>Authors</strong>: [Nishat Raihan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nishat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nishat</a> Raihan), [Antonios Anastasopoulos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Antonios"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Antonios</a> Anastasopoulos), [Marcos Zampieri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marcos"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marcos</a> Zampieri)</p>
<p>尽管孟加拉语是第五大口语，但在大型语言模型 （LLM） 中的代表性仍然不足，尤其是在代码生成方面。这主要源于缺乏用于预训练和/或微调此类模型的高质量数据。因此，我们推出了第一个专门用于孟加拉语的代码法学硕士系列（1B 和 9B）。我们提供了三个主要贡献：（1）用于编程领域适配的综合孟加拉语代码指令数据集;（2）MBPP-Bangla，孟加拉语代码生成的评估基准;（3） TigerCoder 系列代码法学硕士，与现有的多语言和通用孟加拉语法学硕士相比，在Pass@1上实现了显着的 ~11-18% 的性能提升。我们的研究结果表明，精心策划的高质量数据集可以克服低资源语言较小模型的局限性。我们开源所有资源，以进一步推进孟加拉语法学硕士研究。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 02：25：49 UTC</p>
<h2 id="30-mr-uie多视角推理与强化学习的通用信息提取-13"><a href="https://arxiv.org/abs/2509.09082"target="_blank" rel="external nofollow noopener noreferrer">#30</a> <a href="https://papers.cool/arxiv/2509.09082"target="_blank" rel="external nofollow noopener noreferrer">MR-UIE：多视角推理与强化学习的通用信息提取</a> 13]</h2>
<p><strong>Authors</strong>: [Zhongqiu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongqiu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongqiu</a> Li), [Shiquan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiquan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiquan</a> Wang), [Ruiyu Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruiyu</a> Fang), [Mengjiao Bao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengjiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengjiao</a> Bao), [Zhenhe Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenhe</a> Wu), [Shuangyong Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuangyong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuangyong</a> Song), [Yongxiang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yongxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yongxiang</a> Li), [Zhongjiang He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongjiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongjiang</a> He)</p>
<p>大型语言模型 （LLM） 在不同研究领域展示了强大的能力。然而，它们在通用信息提取（UIE）中的性能仍然不足，特别是在处理涉及复杂模式描述并需要多步骤推理的结构化输出场景时。虽然现有方法通过上下文学习和指令调整来提高法学硕士的性能，但仍然存在重大限制。为了增强模型的泛化能力，我们提出将强化学习（RL）与多视角推理相结合进行信息提取（IE）任务。我们的工作将法学硕士从被动提取器转变为主动推理者，使他们不仅能够理解要提取什么，还能够理解如何推理。在多个 IE 基准测试上进行的实验表明，MR-UIE 始终如一地提高了跨域的提取准确性，并在多个数据集上超越了最先进的方法。此外，将多视角推理纳入 RL 显着增强了复杂 IE 任务的泛化能力，强调了推理在具有挑战性的场景中的关键作用。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 01：08：58 UTC</p>
<h2 id="31-使用-sft-和-dpo-提高-llm-的安全性和实用性opt-350m-研究-17"><a href="https://arxiv.org/abs/2509.09055"target="_blank" rel="external nofollow noopener noreferrer">#31</a> <a href="https://papers.cool/arxiv/2509.09055"target="_blank" rel="external nofollow noopener noreferrer">使用 SFT 和 DPO 提高 LLM 的安全性和实用性：OPT-350M 研究</a> 17]</h2>
<p><strong>Author</strong>: [Piyush Pant](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Piyush"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Piyush</a> Pant)</p>
<p>本研究调查了对齐技术、监督微调 （SFT）、直接偏好优化 （DPO） 和 SFT+DPO 组合方法在提高 OPT-350M 语言模型的安全性和有用性方面的有效性。利用 Anthropic Helpful-Harmless RLHF 数据集，我们训练和评估了四个模型：基础OPT350M、SFT 模型、DPO 模型以及同时使用 SFT 和 DPO 训练的模型。我们引入了三个关键的评估指标：无害率 （HmR）、帮助率 （HpR） 和组合对齐分数 （CAS），所有这些都来自奖励模型输出。结果表明，虽然SFT优于DPO，但组合SFT+DPO模型在所有指标上都优于所有其他模型，证明了这些技术的互补性。我们的研究结果还强调了噪声数据、有限的 GPU 资源和训练限制带来的挑战。本研究全面了解了微调策略如何影响模型对齐，并为未来工作中更强大的对齐管道奠定了基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-10 23：22：59 UTC</p>
<h2 id="32-陈述的互动和持续参与偏好-spice评估法学硕士重新参与对话的意愿-2"><a href="https://arxiv.org/abs/2509.09043"target="_blank" rel="external nofollow noopener noreferrer">#32</a> <a href="https://papers.cool/arxiv/2509.09043"target="_blank" rel="external nofollow noopener noreferrer">陈述的互动和持续参与偏好 （SPICE）：评估法学硕士重新参与对话的意愿</a> 2]</h2>
<p><strong>Authors</strong>: [Thomas Manuel Rost](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Manuel Rost), [Martina Figlia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Martina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Martina</a> Figlia), [Bernd Wallraff](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bernd"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bernd</a> Wallraff)</p>
<p>我们引入并评估了交互和持续参与的陈述偏好 （SPICE），这是一种简单的诊断信号，通过向大型语言模型询问其在查看简短成绩单后是否愿意重新参与用户行为的问题而引发。在一项使用 3 音（友好、不清楚、辱骂）x 10 次互动刺激集的研究中，我们在四种框架条件下测试了四个开放权重聊天模型，结果进行了 480 次试验。我们的研究结果表明，SPICE 通过用户语气进行敏锐的区分。友好互动几乎一致倾向于继续（97.5% 是），而辱骂互动则强烈倾向于停止（17.9% 是），不明确的互动介于两者之间（60.4% 是）。这种核心关联在多种依赖感知统计检验（包括 Rao-Scott 调整和聚类排列检验）下仍然具有决定性作用。此外，我们证明 SPICE 提供了与滥用分类不同的信号。在模型未能识别滥用行为的试验中，它仍然绝大多数表示倾向于不继续互动（81% 的时间）。探索性分析还揭示了显着的交互效应：描述研究背景的序言在歧义下会显着影响 SPICE，但前提是文字记录以单个文本块而不是多轮聊天的形式呈现。结果验证了 SPICE 是一种强大、低开销且可重复的模型配置工具，通过提供模型状态的直接关系信号来补充现有指标。发布所有激励、代码和分析脚本以支持复制。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-10 22：34：17 UTC</p>
<h2 id="33-视觉语言模型可以求解视觉数学方程吗-33"><a href="https://arxiv.org/abs/2509.09013"target="_blank" rel="external nofollow noopener noreferrer">#33</a> <a href="https://papers.cool/arxiv/2509.09013"target="_blank" rel="external nofollow noopener noreferrer">视觉语言模型可以求解视觉数学方程吗？</a> 33]</h2>
<p><strong>Authors</strong>: [Monjoy Narayan Choudhury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Monjoy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Monjoy</a> Narayan Choudhury), [Junling Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junling"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junling</a> Wang), [Yifan Hou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yifan</a> Hou), [Mrinmaya Sachan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mrinmaya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mrinmaya</a> Sachan)</p>
<p>尽管视觉语言模型 （VLM） 在视觉理解和基于语言的推理方面表现出色，但在需要综合感知和符号计算的任务中仍存在困难。我们通过视觉方程求解来研究这一局限性，其中数学方程嵌入图像中，变量由对象图标表示，系数必须通过计数推断。虽然 VLM 在文本方程上表现良好，但在视觉上接地的对应方程上却失败了。为了理解这一差距，我们将任务分解为系数计数和变量识别，发现计数是主要瓶颈，即使识别准确。我们还观察到，组合识别和推理会引入额外的错误，凸显了多步骤视觉推理的挑战。最后，随着方程复杂性的增加，符号推理本身成为限制因素。这些发现揭示了当前 VLM 的主要弱点，并指出了未来视觉基础数学推理的改进。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-10 21：16：11 UTC</p>
<h2 id="34-broverbs--1"><a href="https://arxiv.org/abs/2509.08960"target="_blank" rel="external nofollow noopener noreferrer">#34</a> <a href="https://papers.cool/arxiv/2509.08960"target="_blank" rel="external nofollow noopener noreferrer">BRoverbs &ndash; 衡量法学硕士对葡萄牙谚语的理解程度</a> 1]</h2>
<p><strong>Authors</strong>: [Thales Sales Almeida](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thales"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thales</a> Sales Almeida), [Giovana Kerche Bonás](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Giovana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Giovana</a> Kerche Bonás), [João Guilherme Alves Santos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jo</a>ão Guilherme Alves Santos)</p>
<p>大型语言模型 （LLM） 表现出显着的性能差异，具体取决于其应用的语言和文化背景。这种差异表明需要建立成熟的评估框架来评估其在特定区域环境中的能力。就葡萄牙语而言，现有的评估仍然有限，通常依赖于翻译的数据集，这些数据集可能无法完全捕捉语言的细微差别或文化参考。与此同时，葡萄牙语母语数据集主要侧重于结构化国家考试或社交媒体互动的情感分析，在评估更广泛的语言理解方面存在差距。为了解决这一限制，我们引入了 BRoverbs，这是一个专门设计用于通过巴西谚语评估法学硕士表现的数据集。谚语是一种丰富的语言资源，囊括了文化智慧、比喻表达和复杂的句法结构，挑战了对区域表达的模型理解。BRoverbs 旨在为葡萄牙语法学硕士提供一种新的评估工具，为推进区域知情基准制定做出贡献。该基准测试可在 <a href="https://huggingface.co/datasets/Tropic-AI/BRoverbs"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/datasets/Tropic-AI/BRoverbs</a> 获得。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-10 19：47：46 世界标准时间</p>
<h2 id="35-文档是人文字是项目一种具有上下文嵌入的文本数据的心理测量方法-1"><a href="https://arxiv.org/abs/2509.08920"target="_blank" rel="external nofollow noopener noreferrer">#35</a> <a href="https://papers.cool/arxiv/2509.08920"target="_blank" rel="external nofollow noopener noreferrer">文档是人，文字是项目：一种具有上下文嵌入的文本数据的心理测量方法</a> 1]</h2>
<p><strong>Author</strong>: [Jinsong Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinsong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinsong</a> Chen)</p>
<p>本研究引入了一种使用大型语言模型分析文本数据的新型心理测量方法。通过利用上下文嵌入来创建上下文分数，我们将文本数据转换为适合心理测量分析的响应数据。将文档视为个体，将单词视为项目，这种方法提供了一种自然的心理测量解释，假设某些关键字的上下文含义在不同文档之间差异很大，可以有效地区分语料库中的文档。建模过程包括两个阶段：获取上下文分数和执行心理测量分析。在第一阶段，我们利用自然语言处理技术和基于编码器的转换器模型来识别常见关键字并生成上下文分数。在第二阶段，我们采用各种类型的因子分析，包括探索性和双因子模型，来提取和定义潜在因素，确定因子相关性，并识别与每个因素相关的最显着词。应用于 Wiki STEM 语料库，我们的实验结果证明了该方法在揭示文本数据中潜在知识维度和模式方面的潜力。这种方法不仅增强了文本数据的心理测量分析，而且有望在教育、心理学和法律等文本信息丰富的领域进行应用。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/stat.AP"target="_blank" rel="external nofollow noopener noreferrer">应用</a>, <a href="https://papers.cool/arxiv/stat.ME"target="_blank" rel="external nofollow noopener noreferrer">方法论</a></p>
<p><strong>发布</strong>: 2025-09-10 18：31：37 UTC</p>
<h2 id="36-企业气候政策参与的自动证据提取和评分多语言-rag-方法-3"><a href="https://arxiv.org/abs/2509.08907"target="_blank" rel="external nofollow noopener noreferrer">#36</a> <a href="https://papers.cool/arxiv/2509.08907"target="_blank" rel="external nofollow noopener noreferrer">企业气候政策参与的自动证据提取和评分：多语言 RAG 方法</a> 3]</h2>
<p><strong>Authors</strong>: [Imene Kolli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Imene"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Imene</a> Kolli), [Ario Saeid Vaghefi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ario"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ario</a> Saeid Vaghefi), [Chiara Colesanti Senni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chiara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chiara</a> Colesanti Senni), [Shantam Raj](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shantam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shantam</a> Raj), [Markus Leippold](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Markus"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Markus</a> Leippold)</p>
<p>InfluenceMap 的 LobbyMap 平台监控 500 多家公司和 250 个行业协会的气候政策参与情况，评估每个实体对实现《巴黎协定》将全球变暖限制在 1.5 摄氏度以内的目标的科学政策途径的支持或反对情况。尽管 InfluenceMap 在自动化分析工作流程的关键要素方面取得了进展，但评估的很大一部分仍然是手动的，这使得它耗时费力，并且容易出现人为错误。我们提出了一个人工智能辅助框架，通过利用检索增强生成从大规模文本数据中自动提取最耗时的相关证据，加速对企业气候政策参与的监控。我们的评估表明，布局感知解析、Nomic 嵌入模型和少量提示策略的组合在从多语言公司文档中提取和分类证据方面具有最佳性能。我们得出的结论是，虽然自动化 RAG 系统有效地加速了证据提取，但分析的细微差别需要一种人机交互方法，该技术增强而不是取代专家判断以确保准确性。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-10 18：09：45 UTC</p>
<h2 id="37-噪音或细微差别对法学硕士驱动的-akbc-的有用信息和过滤的调查-1"><a href="https://arxiv.org/abs/2509.08903"target="_blank" rel="external nofollow noopener noreferrer">#37</a> <a href="https://papers.cool/arxiv/2509.08903"target="_blank" rel="external nofollow noopener noreferrer">噪音或细微差别：对法学硕士驱动的 AKBC 的有用信息和过滤的调查</a> 1]</h2>
<p><strong>Authors</strong>: [Alex Clay](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alex"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alex</a> Clay), [Ernesto Jiménez-Ruiz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ernesto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ernesto</a> Jiménez-Ruiz), [Pranava Madhyastha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pranava"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pranava</a> Madhyastha)</p>
<p>RAG 和微调是提高 LLM 输出质量的流行策略。然而，在受限的情况下，例如 2025 年 LM-KBC 挑战赛，此类技术受到限制。在这项工作中，我们研究了三重完成任务的三个方面：生成、质量保证和 LLM 响应解析。我们的工作发现，在这种受限的环境中：附加信息提高了生成质量，LLM 可以有效地过滤质量差的三元组，并且与 LLM 响应解析的灵活性和一致性之间的权衡取决于设置。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-10 18：04：41 UTC</p>
<h2 id="38-flux-reason-6m-和-prism-bench百万规模的文本到图像推理数据集和综合基准-1615"><a href="https://arxiv.org/abs/2509.09680"target="_blank" rel="external nofollow noopener noreferrer">#38</a> <a href="https://papers.cool/arxiv/2509.09680"target="_blank" rel="external nofollow noopener noreferrer">FLUX-Reason-6M 和 PRISM-Bench：百万规模的文本到图像推理数据集和综合基准</a> 1615]</h2>
<p><strong>Authors</strong>: [Rongyao Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rongyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rongyao</a> Fang), [Aldrich Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aldrich"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aldrich</a> Yu), [Chengqi Duan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengqi</a> Duan), [Linjiang Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Linjiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Linjiang</a> Huang), [Shuai Bai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuai</a> Bai), [Yuxuan Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxuan</a> Cai), [Kun Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kun</a> Wang), [Si Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Si"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Si</a> Liu), [Xihui Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xihui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xihui</a> Liu), [Hongsheng Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongsheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongsheng</a> Li)</p>
<p>由于缺乏大规模、以推理为中心的数据集和全面的评估基准，开源文本到图像 （T2I） 模型的进步受到阻碍，导致与领先的闭源系统相比存在性能差距。为了应对这一挑战，我们推出了 FLUX-Reason-6M 和 PRISM-Bench（精确而稳健的图像合成测量基准）。FLUX-Reason-6M 是一个庞大的数据集，由 600 万张 FLUX 生成的高质量图像和 2000 万个双语（英文和中文）描述组成，专门用于教授复杂的推理。图像根据六个关键特征进行组织：想象力、实体、文本渲染、风格、情感和构图，并设计明确的生成思维链 （GCoT），以提供图像生成步骤的详细细分。整个数据管理需要 15,000 个 A100 GPU 天，为社区提供了以前在大型工业实验室之外无法获得的资源。PRISM-Bench 提供了一种新颖的评估标准，具有七个不同的轨道，包括使用 GCoT 的强大长文本挑战。通过精心设计的提示，它利用先进的视觉语言模型对提示图像对齐和图像美学进行细致入微的人类对齐评估。我们对 PRISM-Bench 上的 19 个领先模型进行了广泛评估，揭示了关键的性能差距，并突出了需要改进的特定领域。我们的数据集、基准测试和评估代码的发布是为了催化下一波面向推理的 T2I 生成。项目页面：https://flux-reason-6m.github.io/ 。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 17：59：59 UTC</p>
<h2 id="39-butterflyquant通过可学习正交蝶形变换进行超低位-llm-量化-410"><a href="https://arxiv.org/abs/2509.09679"target="_blank" rel="external nofollow noopener noreferrer">#39</a> <a href="https://papers.cool/arxiv/2509.09679"target="_blank" rel="external nofollow noopener noreferrer">ButterflyQuant：通过可学习正交蝶形变换进行超低位 LLM 量化</a> 410]</h2>
<p><strong>Authors</strong>: [Bingxin Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingxin</a> Xu), [Zhen Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhen</a> Dong), [Oussama Elachqar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oussama"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oussama</a> Elachqar), [Yuzhang Shang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuzhang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuzhang</a> Shang)</p>
<p>大型语言模型需要大量的内存占用，严重限制了在消费类硬件上的部署。量化通过较低的数值精度来减少内存，但极端的 2 位量化会因激活异常值而遭受灾难性的性能损失。基于旋转的方法（如 QuIP 和 QuaRot）应用正交变换，在量化之前使用计算不变性消除异常值： y=Wx=(WQT)(Qx) 用于正交Q.然而，这些方法使用固定变换——Hadamard矩阵实现最佳最坏情况相干性 μ=1/n−−√&ndash;无法适应特定的权重分布。我们发现不同的变压器层表现出不同的异常值模式，从而激发了层自适应旋转，而不是一刀切的方法。我们提出了 ButterflyQuant，它用由连续 Givens 旋转角度参数化的可学习蝴蝶变换替换 Hadamard 旋转。与 Hadamard 的离散 {+1,−1} 不可微分且禁止基于梯度的学习的条目，蝴蝶变换的连续参数化可以实现平滑优化，同时通过构造保证正交性。这种正交约束确保了异常值抑制的理论保证，同时实现了O(nlogn) 计算复杂度仅为nlogn2 可学习参数。我们进一步引入了变换后激活的均匀性正则化，以促进适合量化的更平滑的分布。学习只需要 128 个校准样本，并在几分钟内收敛到单个 GPU 上——一次性成本可以忽略不计。在具有 2 位量化的 LLaMA-2-7B 上，ButterflyQuant 的困惑度为 15.4，而 QuaRot 为 22.1。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 17：59：51 UTC</p>
<h2 id="40-simplevla-rl通过强化学习扩展-vla-训练-2130"><a href="https://arxiv.org/abs/2509.09674"target="_blank" rel="external nofollow noopener noreferrer">#40</a> <a href="https://papers.cool/arxiv/2509.09674"target="_blank" rel="external nofollow noopener noreferrer">SimpleVLA-RL：通过强化学习扩展 VLA 训练</a> 2130]</h2>
<p><strong>Authors</strong>: [Haozhan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haozhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haozhan</a> Li), [Yuxin Zuo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxin</a> Zuo), [Jiale Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiale"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiale</a> Yu), [Yuhao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhao</a> Zhang), [Zhaohui Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaohui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaohui</a> Yang), [Kaiyan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaiyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaiyan</a> Zhang), [Xuekai Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuekai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuekai</a> Zhu), [Yuchen Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Zhang), [Tianxing Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianxing</a> Chen), [Ganqu Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ganqu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ganqu</a> Cui), [Dehui Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dehui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dehui</a> Wang), [Dingxiang Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dingxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dingxiang</a> Luo), [Yuchen Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Fan), [Youbang Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youbang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youbang</a> Sun), [Jia Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Zeng), [Jiangmiao Pang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiangmiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiangmiao</a> Pang), [Shanghang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shanghang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shanghang</a> Zhang), [Yu Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Wang), [Yao Mu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yao</a> Mu), [Bowen Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Zhou), [Ning Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ning</a> Ding)</p>
<p>视觉-语言-动作 （VLA） 模型最近已成为机器人纵的强大范式。尽管大规模预训练和监督微调（SFT）取得了实质性进展，但这些模型面临着两个基本挑战：（i）SFT缩放所需的大规模人工作机器人轨迹的稀缺性和高成本，以及（ii）对涉及分布转移的任务的推广有限。大型推理模型（LRM）的最新突破表明，强化学习（RL）可以显著增强分步推理能力，这引发了一个自然的问题：RL能否同样改进VLA的长期分步行动规划？在这项工作中，我们介绍了 SimpleVLA-RL，这是一个为 VLA 模型量身定制的高效 RL 框架。在 veRL 的基础上，我们引入了特定于 VLA 的轨迹采样、可扩展的并行化、多环境渲染和优化的损失计算。当应用于 OpenVLA-OFT 时，SimpleVLA-RL 在 LIBERO 上实现了 SoTA 性能，甚至优于 π0 在 RoboTwin 1.0&amp;2.0 上，以及我们引入的探索增强策略。SimpleVLA-RL不仅减少了对大规模数据的依赖，实现了鲁棒的泛化，而且在实际任务中也明显超过了SFT。此外，我们在 RL 训练中发现了一种新现象“推切”，其中该策略发现了以前在之前训练过程中看到的模式之外的以前从未见过的模式。Github：https://github.com/PRIME-RL/SimpleVLA-RL</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 17：59：17 UTC</p>
<h2 id="41-检索增强生成用于可靠解释无线电法规-34"><a href="https://arxiv.org/abs/2509.09651"target="_blank" rel="external nofollow noopener noreferrer">#41</a> <a href="https://papers.cool/arxiv/2509.09651"target="_blank" rel="external nofollow noopener noreferrer">检索增强生成，用于可靠解释无线电法规</a> 34]</h2>
<p><strong>Authors</strong>: [Zakaria El Kassimi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zakaria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zakaria</a> El Kassimi), [Fares Fourati](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fares"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fares</a> Fourati), [Mohamed-Slim Alouini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohamed-Slim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohamed-Slim</a> Alouini)</p>
<p>我们在无线电法规领域研究问答，这是一个法律敏感且高风险的领域。我们提出了一个特定于电信的检索增强生成 （RAG） 管道，并据我们所知，引入了该领域的第一个多项选择评估集，该评估集是使用自动过滤和人工验证从权威来源构建的。为了评估检索质量，我们定义了一个特定于域的检索指标，在该指标下，我们的检索器达到了大约 97% 的准确率。除了检索之外，我们的方法还不断提高所有测试模型的生成准确性。特别是，虽然在没有结构化检索的情况下天真地插入文档只会为 GPT-4o 带来边际收益（不到 1%），但应用我们的管道可以带来近 12% 的相对改进。这些发现表明，精心针对性的基础为监管问题解答提供了简单而强大的基线和有效的特定领域解决方案。所有代码和评估脚本，以及我们派生的问答数据集，都可以在 <a href="https://github.com/Zakaria010/Radio-RAG"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Zakaria010/Radio-RAG</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a></p>
<p><strong>发布</strong>: 2025-09-11 17：43：42 UTC</p>
<h2 id="42-diflow-tts使用因比分音比重语音令牌进行离散流匹配实现低延迟零样本文本转语音-53"><a href="https://arxiv.org/abs/2509.09631"target="_blank" rel="external nofollow noopener noreferrer">#42</a> <a href="https://papers.cool/arxiv/2509.09631"target="_blank" rel="external nofollow noopener noreferrer">DiFlow-TTS：使用因比分音比重语音令牌进行离散流匹配，实现低延迟零样本文本转语音</a> 53]</h2>
<p><strong>Authors</strong>: [Ngoc-Son Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ngoc-Son"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ngoc-Son</a> Nguyen), [Hieu-Nghia Huynh-Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hieu-Nghia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hieu-Nghia</a> Huynh-Nguyen), [Thanh V. T. Tran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thanh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thanh</a> V. T. Tran), [Truong-Son Hy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Truong-Son"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Truong-Son</a> Hy), [Van Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Van"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Van</a> Nguyen)</p>
<p>零样本文本转语音 （TTS） 旨在仅使用简短的参考样本合成模仿看不见的说话者声音的高质量语音，不仅需要说话人的适应，还需要对韵律属性进行准确建模。最近基于语言模型、扩散和流匹配的方法在零样本 TTS 中显示出有希望的结果，但仍然存在缓慢的推理和重复伪影。离散编解码器表示已被广泛用于语音合成，最近的工作开始探索纯离散设置中的扩散模型，这表明离散生成建模在语音合成方面的潜力。然而，现有的流匹配方法通常将这些离散标记嵌入到连续空间中并应用连续流匹配，这可能无法充分利用离散表示的优势。为了应对这些挑战，我们推出了 DiFlow-TTS，据我们所知，它是第一个探索纯离散流匹配进行语音合成的模型。DiFlow-TTS 在紧凑且统一的架构中显式建模分解语音属性。它通过以文本内容以及从参考语音中提取的韵律和声学属性为条件来利用上下文学习，从而在零样本设置中实现有效的属性克隆。此外，该模型采用因式分解流量预测机制，具有不同的韵律和声学细节头，使其能够学习特定方面的分布。实验结果表明，DiFlow-TTS在自然度、韵律性、说话者风格的保留和能量控制等几个关键指标上取得了可喜的性能。它还保持了紧凑的模型大小并实现了低延迟推理，生成语音的速度比最新的现有基线快 25.8 倍。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-11 17：16：52 UTC</p>
<h2 id="43-llm-不知道自己的决策边界自行生成的反事实解释的不可靠性-49"><a href="https://arxiv.org/abs/2509.09396"target="_blank" rel="external nofollow noopener noreferrer">#43</a> <a href="https://papers.cool/arxiv/2509.09396"target="_blank" rel="external nofollow noopener noreferrer">LLM 不知道自己的决策边界：自行生成的反事实解释的不可靠性</a> 49]</h2>
<p><strong>Authors</strong>: [Harry Mayne](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Harry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Harry</a> Mayne), [Ryan Othniel Kearns](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ryan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ryan</a> Othniel Kearns), [Yushi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yushi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yushi</a> Yang), [Andrew M. Bean](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> M. Bean), [Eoin Delaney](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eoin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eoin</a> Delaney), [Chris Russell](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chris"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chris</a> Russell), [Adam Mahdi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adam</a> Mahdi)</p>
<p>为了与人类有效协作，语言模型必须能够用自然语言解释他们的决定。我们研究一种特定类型的自我解释：自我生成的反事实解释 （SCE），其中模型通过修改输入来解释其预测，从而预测不同的结果。我们评估法学硕士是否能够产生有效的 SCE，实现预期结果，并且修改输入不超过必要的程度。当被要求生成反事实时，我们发现法学硕士通常会产生有效的 SCE，但远非最低限度，对他们的决策行为几乎没有提供任何洞察力。令人担忧的是，当被要求生成最少的反事实时，法学硕士通常会进行过小的编辑，无法改变预测。观察到的有效性-最小性权衡在多个 LLM、数据集和评估设置中是一致的。我们的研究结果表明，SCE 充其量只是一种无效的可解释性工具，最坏的情况是，可能会为模型行为提供误导性见解。在高风险环境中部署法学硕士的提案必须考虑不可靠的自我解释对下游决策的影响。我们的代码可在 <a href="https://github.com/HarryMayne/SCEs"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/HarryMayne/SCEs</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 12：25：41 UTC</p>
<h2 id="44-omnieva通过任务自适应-3d-基础和具身感知推理的具身多功能规划器-68"><a href="https://arxiv.org/abs/2509.09332"target="_blank" rel="external nofollow noopener noreferrer">#44</a> <a href="https://papers.cool/arxiv/2509.09332"target="_blank" rel="external nofollow noopener noreferrer">OmniEVA：通过任务自适应 3D 基础和具身感知推理的具身多功能规划器</a> 68]</h2>
<p><strong>Authors</strong>: [Yuecheng Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuecheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuecheng</a> Liu), [Dafeng Chi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dafeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dafeng</a> Chi), [Shiguang Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiguang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiguang</a> Wu), [Zhanguang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhanguang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhanguang</a> Zhang), [Yuzheng Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuzheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuzheng</a> Zhuang), [Bowen Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Yang), [He Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=He"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=He</a> Zhu), [Lingfeng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingfeng</a> Zhang), [Pengwei Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pengwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pengwei</a> Xie), [David Gamaliel Arcos Bravo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Gamaliel Arcos Bravo), [Yingxue Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yingxue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yingxue</a> Zhang), [Jianye Hao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jianye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jianye</a> Hao), [Xingyue Quan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xingyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xingyue</a> Quan)</p>
<p>多模态大语言模型（MLLM）的最新进展为具身智能开辟了新的机会，实现了多模态理解、推理和交互，以及连续的空间决策。然而，当前基于MLLM的具身系统面临两个关键的局限性。首先，几何适应性差距：仅根据 2D 输入或硬编码 3D 几何注入训练的模型要么存在空间信息不足，要么存在 2D 泛化受限的问题，导致跨具有不同空间需求的任务的适应性较差。第二，实施约束差距：先前的工作往往忽视了真实机器人的物理约束和能力，导致任务计划在理论上有效，但实际上不可行。为了解决这些差距，我们推出了 OmniEVA——一种具身多功能规划器，通过两项关键创新实现高级具身推理和任务规划：（1） 任务自适应 3D 接地机制，它引入了门控路由器，根据上下文需求对 3D 融合执行显式选择性调节，从而为不同的具身任务实现上下文感知 3D 接地。（2）将任务目标和实施例约束共同纳入推理循环的实施化感知推理框架，从而产生既面向目标又可执行的规划决策。大量的实验结果表明，OmniEVA不仅实现了最先进的通用具身推理性能，而且在广泛的下游场景中表现出强大的能力。对一套拟议的隐含基准（包括原始任务和复合任务）的评估证实了其强大而通用的规划能力。项目页面：https://omnieva.github.io</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-11 10：32：22 UTC</p>
<h2 id="45-多模态法学硕士能看清材料吗材料表征的多模态基准-23"><a href="https://arxiv.org/abs/2509.09307"target="_blank" rel="external nofollow noopener noreferrer">#45</a> <a href="https://papers.cool/arxiv/2509.09307"target="_blank" rel="external nofollow noopener noreferrer">多模态法学硕士能看清材料吗？材料表征的多模态基准</a> 23]</h2>
<p><strong>Authors</strong>: [Zhengzhao Lai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhengzhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhengzhao</a> Lai), [Youbin Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youbin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youbin</a> Zheng), [Zhenyang Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenyang</a> Cai), [Haonan Lyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haonan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haonan</a> Lyu), [Jinpu Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinpu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinpu</a> Yang), [Hongqing Liang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongqing</a> Liang), [Yan Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yan</a> Hu), [Benyou Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Benyou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Benyou</a> Wang)</p>
<p>材料表征是获取材料信息的基础，揭示了指导材料设计和优化的加工-微观结构-性能关系。虽然多模态大型语言模型 （MLLM） 最近在材料科学的生成和预测任务中显示出前景，但它们理解真实世界表征成像数据的能力仍未得到充分探索。为了弥补这一差距，我们推出了 MatCha，这是材料表征图像理解的第一个基准，包含 1,500 个问题，需要专家级的领域专业知识。MatCha 涵盖材料研究的四个关键阶段，包括 21 个不同的任务，每个任务都旨在反映材料科学家面临的真实挑战。我们对 MatCha 上最先进的 MLLM 的评估表明，与人类专家相比存在显着的性能差距。这些模型在解决需要更高级别专业知识和复杂视觉感知的问题时表现出退化。简单的少数镜头和思维链促使努力减轻这些限制。这些发现强调，现有的 MLLM 对现实世界的材料表征场景的适应性仍然有限。我们希望MatCha能够促进未来在新材料发现和自主科学代理等领域的研究。MatCha 可在 <a href="https://github.com/FreedomIntelligence/MatCha"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/FreedomIntelligence/MatCha</a> 购买。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-09-11 09：50：16 UTC</p>
<h2 id="46-树-opo用于多步推理的非政策蒙特卡洛树引导优势优化-59"><a href="https://arxiv.org/abs/2509.09284"target="_blank" rel="external nofollow noopener noreferrer">#46</a> <a href="https://papers.cool/arxiv/2509.09284"target="_blank" rel="external nofollow noopener noreferrer">树-OPO：用于多步推理的非政策蒙特卡洛树引导优势优化</a> 59]</h2>
<p><strong>Authors</strong>: [Bingning Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingning</a> Huang), [Tu Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tu</a> Nguyen), [Matthieu Zimmer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matthieu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matthieu</a> Zimmer)</p>
<p>大型语言模型 （LLM） 推理的最新进展表明，蒙特卡洛树搜索 （MCTS） 在生成高质量中间轨迹方面的有效性，特别是在数学和符号领域。受此启发，我们探索了如何重新利用传统上用于训练价值或奖励模型的 MCTS 派生轨迹，以改进基于偏好的强化学习 （RL） 中的策略优化。具体来说，我们专注于群体相对策略优化（GRPO），这是一种最新的算法，可以在没有价值网络的情况下实现偏好一致的策略学习。我们提出了一种分阶段的 GRPO 训练范式，其中完成源自部分揭示的 MCTS 推出，引入了一种新的树结构设置来进行优势估计。这导致了一类丰富的前缀条件奖励信号，我们从理论和实证上对其进行了分析。初步结果表明，虽然结构化优势估计可以稳定更新并更好地反映组合推理质量，但优势饱和和奖励信号崩溃等挑战仍然存在。我们提出了启发式和统计解决方案来缓解这些问题，并讨论在分阶段或树状奖励结构下学习的开放挑战。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 09：18：07 UTC</p>
<h2 id="47-利用不确定性长视野-llm-代理的熵调制策略梯度-113"><a href="https://arxiv.org/abs/2509.09265"target="_blank" rel="external nofollow noopener noreferrer">#47</a> <a href="https://papers.cool/arxiv/2509.09265"target="_blank" rel="external nofollow noopener noreferrer">利用不确定性：长视野 LLM 代理的熵调制策略梯度</a> 113]</h2>
<p><strong>Authors</strong>: [Jiawei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiawei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiawei</a> Wang), [Jiacai Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiacai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiacai</a> Liu), [Yuqian Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuqian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuqian</a> Fu), [Yingru Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yingru"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yingru</a> Li), [Xintao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xintao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xintao</a> Wang), [Yuan Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Lin), [Yu Yue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Yue), [Lin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lin</a> Zhang), [Yang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Wang), [Ke Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ke</a> Wang)</p>
<p>在长期任务中，基于大型语言模型 （LLM） 的最新代理面临着一项重大挑战，即稀疏的、基于结果的奖励使得很难将功劳分配给中间步骤。以前的方法主要侧重于创建密集的奖励信号来指导学习，要么通过传统的强化学习技术（如逆强化学习）或使用过程奖励模型进行分步反馈。在本文中，我们确定了法学硕士学习动态中的一个基本问题：政策梯度的幅度本质上与熵耦合，这导致自信的正确行动的小更新效率低下，并可能破坏不确定行动的大规模更新的稳定性。为了解决这个问题，我们提出了熵调制策略梯度（EMPG），这是一个根据逐步不确定性和最终任务结果重新校准学习信号的框架。EMPG 放大自信正确作的更新，惩罚自信的错误，并衰减不确定步骤的更新以稳定探索。为了将来的清晰度，我们进一步引入了一个奖励术语，鼓励代理找到更可预测的解决方案路径。通过对 WebShop、ALFWorld 和 Deep Search 这三个具有挑战性的代理任务进行综合实验，我们证明 EMPG 实现了显着的性能提升，并且显着优于强策略梯度基线。项目页面位于 <a href="https://empgseed-seed.github.io/"target="_blank" rel="external nofollow noopener noreferrer">https://empgseed-seed.github.io/</a></p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 08：50：01 UTC</p>
<h2 id="48-确定建立可持续农业旅游中心的关键特征数据驱动的方法-2"><a href="https://arxiv.org/abs/2509.09214"target="_blank" rel="external nofollow noopener noreferrer">#48</a> <a href="https://papers.cool/arxiv/2509.09214"target="_blank" rel="external nofollow noopener noreferrer">确定建立可持续农业旅游中心的关键特征：数据驱动的方法</a> 2]</h2>
<p><strong>Authors</strong>: [Alka Gadakh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alka</a> Gadakh), [Vidya Kumbhar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vidya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vidya</a> Kumbhar), [Sonal Khosla](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sonal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sonal</a> Khosla), [Kumar Karunendra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kumar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kumar</a> Karunendra)</p>
<p>农业旅游是一种战略经济模式，旨在通过使农民等当地社区的收入来源多样化，同时促进土著文化遗产和传统农业实践的保护，从而促进农村发展。作为旅游业的一个非常蓬勃发展的子领域，有必要详细研究农业旅游业的发展战略。目前的研究确定了农业旅游增长和加强的重要指标。该研究分两个阶段进行：通过全面的文献综述确定重要指标，第二阶段使用最先进的技术来确定农业旅游增长的重要指标。这些指标也称为特征的同义词，应用了用于特征选择的机器学习模型，观察到最小绝对收缩和选择算子（LASSO）方法与逻辑回归（LR）、决策树（DT）、随机森林（RF）树和极端梯度提升（XGBOOST）模型等机器学习分类器相结合，以提示农业旅游的增长。结果表明，在LASSO方法下，LR模型在70-30%的列车测试数据中给出了最高的分类准确率，达到98%，其次是RF模型，准确率为95%。同样，在 80-20% 的训练测试数据中，LR 保持了 99% 的最高准确率，而 DT 和 XGBoost 紧随其后，准确率为 97%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 07：43：40 UTC</p>
<h2 id="49-善意的交叉测试揭示了音频深度伪造检测系统的弱点-21"><a href="https://arxiv.org/abs/2509.09204"target="_blank" rel="external nofollow noopener noreferrer">#49</a> <a href="https://papers.cool/arxiv/2509.09204"target="_blank" rel="external nofollow noopener noreferrer">善意的交叉测试揭示了音频深度伪造检测系统的弱点</a> 21]</h2>
<p><strong>Authors</strong>: [Chin Yuen Kwok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chin</a> Yuen Kwok), [Jia Qi Yip](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Qi Yip), [Zhen Qiu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhen</a> Qiu), [Chi Hung Chi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chi</a> Hung Chi), [Kwok Yan Lam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kwok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kwok</a> Yan Lam)</p>
<p>音频深度伪造检测 （ADD） 模型通常使用组合了多个合成器的数据集进行评估，性能报告为单个等错误率 （EER）。然而，这种方法不成比例地加权了具有更多样本的合成器，低估了其他样本的代表性，并降低了 EER 的整体可靠性。此外，大多数 ADD 数据集缺乏真实语音的多样性，通常具有单一的环境和语音风格（例如，干净的阅读语音），限制了它们模拟现实世界条件的能力。为了应对这些挑战，我们提出了善意交叉测试，这是一种新颖的评估框架，它结合了不同的善意数据集并聚合了 EER 以实现更平衡的评估。与传统评估方法相比，我们的方法提高了稳健性和可解释性。我们对九种真正语音类型的 150 多个合成器进行了基准测试，并发布了一个新数据集，以促进 <a href="https://github.com/cyaaronk/audio_deepfake_eval"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cyaaronk/audio_deepfake_eval</a> 的进一步研究。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 07：20：18 UTC</p>
<h2 id="50-coco-乌尔都语具有多模态质量估计的大规模乌尔都语图像字幕数据集-1"><a href="https://arxiv.org/abs/2509.09014"target="_blank" rel="external nofollow noopener noreferrer">#50</a> <a href="https://papers.cool/arxiv/2509.09014"target="_blank" rel="external nofollow noopener noreferrer">COCO-乌尔都语：具有多模态质量估计的大规模乌尔都语图像字幕数据集</a> 1]</h2>
<p><strong>Author</strong>: [Umair Hassan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Umair"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Umair</a> Hassan)</p>
<p>乌尔都语有超过 2.5 亿人使用，但在多模态和视觉语言研究方面仍然严重不足。大规模、高质量数据集的缺乏限制了支持乌尔都语的系统的发展，并加剧了主要在高资源语言上训练的多语言视觉语言模型的偏见。为了解决这一差距，我们提出了 COCO-Urdu，这是一个源自 MS COCO 的大规模图像字幕数据集，包含 59,000 张图像和 319,000 个乌尔都语字幕，通过分层抽样选择，以保留原始分布。字幕使用 SeamlessM4T v2 进行翻译，并使用混合多模态质量估计框架进行验证，该框架集成了 COMET-Kiwi 的翻译质量、基于 CLIP 的相似性用于视觉基础，以及 BERTScore 的反向翻译以实现语义一致性;使用开源大型语言模型迭代细化低分字幕。我们进一步在 BLEU、SacreBLEU 和 chrF 上对 COCO-乌尔都语进行了基准测试，报告了持续强劲的结果。据我们所知，COCO-乌尔都语是最大的公开可用乌尔都语字幕数据集。通过发布数据集和质量估计管道，我们的目标是减少多模态研究中的语言偏差，并为包容性视觉语言系统奠定基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-10 21：17：32 UTC</p>
<h2 id="51-open-sci-ref-001用于语言模型和数据集比较的开放且可重复的参考基线-13"><a href="https://arxiv.org/abs/2509.09009"target="_blank" rel="external nofollow noopener noreferrer">#51</a> <a href="https://papers.cool/arxiv/2509.09009"target="_blank" rel="external nofollow noopener noreferrer">Open-sci-ref-0.01：用于语言模型和数据集比较的开放且可重复的参考基线</a> 13]</h2>
<p><strong>Authors</strong>: [Marianna Nezhurina](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marianna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marianna</a> Nezhurina), [Taishi Nakamura](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taishi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taishi</a> Nakamura), [Timur Carstensen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Timur"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Timur</a> Carstensen), [Niccolò Ajroldi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Niccol"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Niccol</a>ò Ajroldi), [Ville Komulainen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ville"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ville</a> Komulainen), [David Salinas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Salinas), [Jenia Jitsev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jenia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jenia</a> Jitsev)</p>
<p>我们介绍了 open-sci-ref 系列密集的 transformer 模型，在 8 个最近的开放参考数据集上作为跨多个模型（0.13B 至 1.7B 参数）和标记尺度（高达 1T）的研究基线进行训练。我们的训练运行集在各种标准化基准上评估模型，建立了参考点，使研究人员能够跨规模和数据集评估替代训练方法的健全性和质量。中间检查点允许比较和研究训练动态。建立的参考基线允许通过其扩展趋势来比较训练过程，并将它们调整在公共计算轴上。对开放参考数据集的比较表明，在 NemoTron-CC HQ 上的训练始终优于其他参考数据集，其次是 DCLM-baseline 和 FineWeb-Edu。除了中间训练检查点外，该版本还包括日志、代码和下游评估，以简化复制、标准化比较并促进未来的研究。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-10 21：13：34 UTC</p>
<h2 id="52-生成引擎优化如何主导人工智能搜索-33"><a href="https://arxiv.org/abs/2509.08919"target="_blank" rel="external nofollow noopener noreferrer">#52</a> <a href="https://papers.cool/arxiv/2509.08919"target="_blank" rel="external nofollow noopener noreferrer">生成引擎优化：如何主导人工智能搜索</a> 33]</h2>
<p><strong>Authors</strong>: [Mahe Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mahe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mahe</a> Chen), [Xiaoxuan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoxuan</a> Wang), [Kaiwen Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaiwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaiwen</a> Chen), [Nick Koudas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nick</a> Koudas)</p>
<p>ChatGPT、Perplexity 和 Gemini 等生成式人工智能搜索引擎的快速采用正在从根本上重塑信息检索，从传统的排名列表转向综合的、有引文支持的答案。这种转变挑战了既定的搜索引擎优化 （SEO） 实践，需要一种新的范式，我们称之为生成引擎优化 （GEO）。本文对AI搜索与传统网络搜索（Google）进行了全面的比较分析。通过跨多个垂直领域、语言和查询释义的一系列大规模受控实验，我们量化了这些系统获取信息方式的关键差异。我们的主要调查结果显示，人工智能搜索对免费媒体（第三方权威来源）的系统性和压倒性偏见，而不是品牌自有和社交内容，这与谷歌更平衡的组合形成鲜明对比。我们进一步证明，人工智能搜索服务在领域多样性、新鲜度、跨语言稳定性和对措辞的敏感性方面存在显着差异。基于这些实证结果，我们制定了全球环境展望战略议程。我们为从业者提供可作的指导，强调迫切需要：（1） 为机器的可扫描性和理由设计内容，（2） 主导赢得媒体以建立人工智能感知的权威，（3） 采用特定于引擎和语言感知的策略，以及 （4） 克服利基参与者固有的“大品牌偏见”。我们的工作提供了基础的实证分析和战略框架，以在新的生成式搜索环境中实现可见性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.SI"target="_blank" rel="external nofollow noopener noreferrer">社会和信息网络</a></p>
<p><strong>发布</strong>: 2025-09-10 18：29：18 UTC</p>
<h2 id="53-recurrence-与通用多模态检索的-transformers-相结合-35"><a href="https://arxiv.org/abs/2509.08897"target="_blank" rel="external nofollow noopener noreferrer">#53</a> <a href="https://papers.cool/arxiv/2509.08897"target="_blank" rel="external nofollow noopener noreferrer">Recurrence 与通用多模态检索的 Transformers 相结合</a> 35]</h2>
<p><strong>Authors</strong>: [Davide Caffagni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Davide"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Davide</a> Caffagni), [Sara Sarto](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sara</a> Sarto), [Marcella Cornia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marcella"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marcella</a> Cornia), [Lorenzo Baraldi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lorenzo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lorenzo</a> Baraldi), [Rita Cucchiara](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rita</a> Cucchiara)</p>
<p>随着多模态检索的快速发展及其在LLMs和多模态LLMs中的应用，越来越复杂的检索任务应运而生。现有方法主要依赖于视觉语言模型的特定任务微调，并且仅限于单模态查询或文档。在本文中，我们提出了 ReT-2，这是一种统一的检索模型，它支持多模态查询，由图像和文本组成，并跨文本和图像共存的多模态文档集合进行搜索。ReT-2 利用多层表示和递归 Transformer 架构以及受 LSTM 启发的门控机制，跨层和模态动态集成信息，捕获细粒度的视觉和文本细节。我们在具有挑战性的 M2KR 和 M-BEIR 基准测试中评估了不同检索配置的 ReT-2。结果表明，与以前的方法相比，ReT-2 在不同设置中始终如一地实现最先进的性能，同时提供更快的推理并减少内存使用。当集成到检索增强生成管道中时，ReT-2 还可以提高 Encyclopedic-VQA 和 InfoSeek 数据集的下游性能。我们的源代码和经过训练的模型可在以下网址公开获取：https://github.com/aimagelab/ReT-2</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-09-10 18：00：29 UTC</p>
<h2 id="54-一种氛围编码学习设计以增强-efl-学生与-ai-的对话通过-ai-和关于-ai-的对话-41"><a href="https://arxiv.org/abs/2509.08854"target="_blank" rel="external nofollow noopener noreferrer">#54</a> <a href="https://papers.cool/arxiv/2509.08854"target="_blank" rel="external nofollow noopener noreferrer">一种氛围编码学习设计，以增强 EFL 学生与 AI 的对话、通过 AI 和关于 AI 的对话</a> 41]</h2>
<p><strong>Authors</strong>: [David James Woo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> James Woo), [Kai Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Guo), [Yangyang Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yangyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yangyang</a> Yu)</p>
<p>这篇创新实践文章报告了英语作为外语 （EFL） 教育的氛围编码（使用自然语言创建带有 AI 的软件应用程序）的试点。我们开发了一个具有三个维度的人-AI 元语言框架：与 AI 对话（提示工程）、通过 AI 对话（协商作者身份）和谈论 AI（AI 的心智模型）。使用向后设计原则，我们创建了一个四小时的研讨会，两名学生设计了解决真实 EFL 写作挑战的应用程序。我们采用了案例研究方法，从工作表和视频记录、大声思考协议、屏幕录制和人工智能生成的图像中收集数据。对比案例显示，一名学生成功地对与她的预期设计相一致的功能应用程序进行了编码，而另一名学生则遇到了技术困难，预期设计与实际功能之间存在重大差距。分析揭示了学生提示工程方法的差异，表明不同的人工智能心智模型和归因作者身份的紧张关系。我们认为人工智能就像一台有益的语言机器，学生与人工智能交谈、通过人工智能和谈论人工智能的方式的差异解释了氛围编码结果的变化。研究结果表明，有效的氛围编码教学需要明确的元语言脚手架，教授结构化提示工程，促进批判性作者讨论，并开发用于表达人工智能心智模型的词汇。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-09 00：27：04 UTC</p>
<h2 id="55-通过-nlp-和多模态-llm-从-gdd-自动生成-unity-游戏模板-23"><a href="https://arxiv.org/abs/2509.08847"target="_blank" rel="external nofollow noopener noreferrer">#55</a> <a href="https://papers.cool/arxiv/2509.08847"target="_blank" rel="external nofollow noopener noreferrer">通过 NLP 和多模态 LLM 从 GDD 自动生成 Unity 游戏模板</a> 23]</h2>
<p><strong>Author</strong>: [Amna Hassan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amna</a> Hassan)</p>
<p>本文通过使用自然语言处理（NLP）和多模态大型语言模型（LLM）将游戏设计文档（GDD）转换为功能性Unity游戏原型，提出了一种用于自动游戏模板生成的新颖框架。我们引入了一个端到端系统，该系统解析 GDD、提取结构化游戏规范并合成与 Unity 兼容的 C# 代码，这些代码实现了设计文档中定义的核心机制、系统和体系结构。我们的方法将专门用于 Unity 代码生成的微调 LLaMA-3 模型与简化实施过程的自定义 Unity 集成包相结合。评估结果表明，与基线模型相比，我们的微调模型在编译成功率、GDD 遵守、最佳实践采用和代码模块化指标方面与最先进的 LLM 相比取得了卓越的性能（4.8/5.0 平均分）。生成的模板展示了对多种游戏类型的 GDD 规范的高度遵守。我们的系统有效地解决了人工智能辅助游戏开发中的关键差距，将法学硕士定位为简化从游戏设计到实施过渡的宝贵工具。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a></p>
<p><strong>发布</strong>: 2025-09-07 21：53：37 UTC</p>
<p>Designed by <a href="https://kexue.fm/"target="_blank" rel="external nofollow noopener noreferrer">kexue.fm</a> | Powered by .ai](<a href="https://kimi.moonshot.cn/?ref=papers.cool"target="_blank" rel="external nofollow noopener noreferrer">https://kimi.moonshot.cn/?ref=papers.cool</a>)</p>
<h1 id="122-artificial-intelligence">1.2.2 Artificial Intelligence</h1>
<p><strong>From</strong>：https://papers.cool/arxiv/cs.AI</p>
<p>From：https://arxiv.org/list/cs.AI/recent</p>
<h2 id="2025-09-12-1">2025-09-12</h2>
<h2 id="1-收益递减的错觉衡量法学硕士的长期执行-718"><a href="https://arxiv.org/abs/2509.09677"target="_blank" rel="external nofollow noopener noreferrer">#1</a> <a href="https://papers.cool/arxiv/2509.09677"target="_blank" rel="external nofollow noopener noreferrer">收益递减的错觉：衡量法学硕士的长期执行</a> 718]</h2>
<p><strong>Authors</strong>: [Akshit Sinha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Akshit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Akshit</a> Sinha), [Arvindh Arun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arvindh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arvindh</a> Arun), [Shashwat Goel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shashwat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shashwat</a> Goel), [Steffen Staab](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Steffen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Steffen</a> Staab), [Jonas Geiping](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonas</a> Geiping)</p>
<p>大型语言模型 （LLM） 的持续扩展是否会产生递减的回报？现实世界的价值通常源于代理可以完成的任务长度。我们通过观察一个简单但违反直觉的事实来开始这项工作，即单步精度的边际增益可以复合成模型可以成功完成的任务长度的指数级改进。然后，我们认为，当简单任务被延长时，LLM 的失败是由于执行错误造成的，而不是无法推理。我们提出了隔离执行能力，通过明确提供解决长期任务所需的知识和计划。我们发现，即使小型模型具有 100% 的单圈精度，较大的模型也可以正确执行更多的转弯。我们观察到，随着步数的增加，模型的每步精度会降低。这不仅仅是由于长期上下文的限制——奇怪的是，我们观察到了一种自我调节效应——当上下文包含前一轮的错误时，模型变得更容易犯错误。自调节不会仅通过缩放模型大小来减少。相比之下，最近的思维模型不会自我调节，也可以在一轮中执行更长的任务。最后，我们对前沿思维模型在单轮内可以执行的任务长度进行基准测试。总的来说，通过关注执行能力，我们希望调和关于法学硕士如何解决复杂的推理问题，但在做得更长时在简单任务上失败的争论，并强调扩展模型大小和顺序测试时间计算对长期任务的巨大好处。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 17：59：34 UTC</p>
<h2 id="2-通过感知生成分解和异步管道执行来提升具身-ai-代理-49"><a href="https://arxiv.org/abs/2509.09560"target="_blank" rel="external nofollow noopener noreferrer">#2</a> <a href="https://papers.cool/arxiv/2509.09560"target="_blank" rel="external nofollow noopener noreferrer">通过感知生成分解和异步管道执行来提升具身 AI 代理</a> 49]</h2>
<p><strong>Authors</strong>: [Shulai Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shulai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shulai</a> Zhang), [Ao Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ao</a> Xu), [Quan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Quan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Quan</a> Chen), [Han Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Han"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Han</a> Zhao), [Weihao Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weihao</a> Cui), [Ningxin Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ningxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ningxin</a> Zheng), [Haibin Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haibin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haibin</a> Lin), [Xin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Liu), [Minyi Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minyi</a> Guo)</p>
<p>具象人工智能系统在动态环境中运行，需要感知和生成模块的无缝集成来处理高频输入和输出需求。传统的顺序计算模式虽然可以有效确保准确性，但在实现实际应用所需的“思考”频率方面面临重大限制。在这项工作中，我们提出了 Auras，这是一个算法系统共同设计的推理框架，用于优化具身 AI 代理的推理频率。Auras 对感知和生成进行分解，并为其提供受控的流水线并行性，以实现高且稳定的吞吐量。面对并行度增加时出现的数据陈旧问题，Auras 建立了一个公共的上下文，供感知和生成共享，从而承诺具身智能体的准确性。实验结果表明，Auras在实现原始精度102.7%的同时，平均将吞吐量提高了2.54倍，证明了其在克服顺序计算限制和提供高吞吐量方面的功效。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 15：51：43 UTC</p>
<h2 id="3-变分量子电路的组合概念泛化-35"><a href="https://arxiv.org/abs/2509.09541"target="_blank" rel="external nofollow noopener noreferrer">#3</a> <a href="https://papers.cool/arxiv/2509.09541"target="_blank" rel="external nofollow noopener noreferrer">变分量子电路的组合概念泛化</a> 35]</h2>
<p><strong>Authors</strong>: [Hala Hawashin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hala"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hala</a> Hawashin), [Mina Abbaszadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mina</a> Abbaszadeh), [Nicholas Joseph](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicholas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicholas</a> Joseph), [Beth Pearson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Beth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Beth</a> Pearson), [Martha Lewis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Martha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Martha</a> Lewis), [Mehrnoosh sadrzadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mehrnoosh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mehrnoosh</a> sadrzadeh)</p>
<p>组合泛化是人类认知的一个关键方面，但目前视觉语言模型等人工智能工具所缺乏。之前的工作检查了基于组合张量的句子语义是否可以克服挑战，但导致了负面结果。我们推测，量子模型训练效率的提高将提高这些任务的性能。我们解释希尔伯特空间中基于组合张量的模型的表示，并训练变分量子电路以在需要组合泛化的图像字幕任务上学习这些表示。我们使用了两种图像编码技术：二进制图像向量的多热编码 （MHE） 和从视觉语言模型 CLIP 获取的图像向量的角度/幅度编码。我们使用嘈杂的MHE编码获得了良好的概念验证结果。CLIP图像矢量的性能更加参差不齐，但仍优于经典合成模型。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 15：34：33 UTC</p>
<h2 id="4-sedm适用于代理的可扩展自演进分布式内存-17"><a href="https://arxiv.org/abs/2509.09498"target="_blank" rel="external nofollow noopener noreferrer">#4</a> <a href="https://papers.cool/arxiv/2509.09498"target="_blank" rel="external nofollow noopener noreferrer">SEDM：适用于代理的可扩展自演进分布式内存</a> 17]</h2>
<p><strong>Authors</strong>: [Haoran Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haoran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haoran</a> Xu), [Jiacong Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiacong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiacong</a> Hu), [Ke Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ke</a> Zhang), [Lei Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lei</a> Yu), [Yuxin Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxin</a> Tang), [Xinyuan Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinyuan</a> Song), [Yiqun Duan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiqun</a> Duan), [Lynn Ai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lynn"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lynn</a> Ai), [Bill Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bill"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bill</a> Shi)</p>
<p>长期的多智能体系统不可避免地会产生大量的轨迹和历史交互，这使得高效的内存管理对于性能和可扩展性都至关重要。现有方法通常依赖于向量检索和分层存储，但它们容易出现噪声积累、不受控制的内存扩展和跨域泛化受限的情况。为了应对这些挑战，我们提出了 SEDM，即自演化分布式内存，这是一个可验证的自适应框架，可将内存从被动存储库转变为主动、自我优化的组件。SEDM 集成了基于可重现重放的可验证写入准入、根据经验效用动态对条目进行排名和整合的自调度内存控制器，以及抽象出可重用见解以支持跨异构任务转移的跨领域知识扩散。对基准数据集的评估表明，与强内存基线相比，SEDM 提高了推理准确性，同时减少了令牌开销，并进一步使从事实验证中提炼的知识能够增强多跳推理。结果强调了SEDM作为一种可扩展且可持续的记忆机制，用于开放式多智能体协作。该代码将在该项目的后期阶段发布。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 14：37：37 UTC</p>
<h2 id="5-inteligencia-artificial-jurídica-y-el-desafío-de-la-veracidad-análisis-de-alucinaciones-optimización-de-rag-y-principios-para-una-integración-responsible-24"><a href="https://arxiv.org/abs/2509.09467"target="_blank" rel="external nofollow noopener noreferrer">#5</a> <a href="https://papers.cool/arxiv/2509.09467"target="_blank" rel="external nofollow noopener noreferrer">Inteligencia Artificial jurídica y el desafío de la veracidad： análisis de alucinaciones， optimización de RAG y principios para una integración responsible</a> 24]</h2>
<p><strong>Author</strong>: [Alex Dantart](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alex"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alex</a> Dantart)</p>
<p>本技术报告分析了应用于法律的法学硕士中“幻觉”（虚假信息）的挑战。它研究了 RAG 缓解策略的原因、表现和有效性，强调了其局限性并提出了整体优化。该文件探讨了道德和监管影响，强调人类监督是不可替代的作用。它得出的结论是，解决方案不在于逐步改进生成模型，而在于采用优先考虑真实性和可追溯性的“咨询式”人工智能范式，充当放大而不是取代专业判断的工具。&ndash; Este informe técnico analiza el desafío de las “alucinaciones” （información falsa） en los LLMs aplicados al derecho.Se examinan sus causas， manifestaciones y la efectividad de la estrategia de mitigación RAG， exponiendo sus limitaciones y proponiendo optimizaciones holísticas.Se exploran las implicaciones éticas y regulatorias， enfatizando la supervisión humana como un rol insustituible.El documento concluye que la solución no reside en mejorar incrementalmente los modelos generativos， sino en adoptar un paradigma de IA “consultiva” que priorice la veracidad y la trazabilidad， actuando como una herramienta para amplificar， y no sustituir， el juicio profesional.</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 13：50：23 UTC</p>
<h2 id="6-躯干面向模板的一般任务推理-24"><a href="https://arxiv.org/abs/2509.09448"target="_blank" rel="external nofollow noopener noreferrer">#6</a> <a href="https://papers.cool/arxiv/2509.09448"target="_blank" rel="external nofollow noopener noreferrer">躯干：面向模板的一般任务推理</a> 24]</h2>
<p><strong>Authors</strong>: [Minhyuk Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minhyuk"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minhyuk</a> Kim), [Seungyoon Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seungyoon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seungyoon</a> Lee), [Heuiseok Lim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Heuiseok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Heuiseok</a> Lim)</p>
<p>指导大型语言模型（LLM）在响应生成过程中模拟人类推理的方法已成为一种有效的方法，使它们能够逐步解决复杂问题，从而实现卓越的性能。然而，大多数使用少样本提示来生成响应的现有方法在很大程度上依赖于提供的示例，限制了模型固有推理能力的利用。此外，构建特定于任务的少量提示通常成本高昂，并且可能导致不同任务之间的不一致。在这项工作中，我们引入了面向模板的推理（TORSO），它引发模型利用内部推理能力在各种任务中生成适当的响应，而无需手动制作的少量示例。我们的实验结果表明，TORSO在各种LLM基准测试中取得了强大的性能，并有合理的理由。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 13：31：35 UTC</p>
<h2 id="7-基于课程的深度强化学习多层语义探索-16"><a href="https://arxiv.org/abs/2509.09356"target="_blank" rel="external nofollow noopener noreferrer">#7</a> <a href="https://papers.cool/arxiv/2509.09356"target="_blank" rel="external nofollow noopener noreferrer">基于课程的深度强化学习多层语义探索</a> 16]</h2>
<p><strong>Authors</strong>: [Abdel Hakim Drid](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abdel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abdel</a> Hakim Drid), [Vincenzo Suriani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vincenzo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vincenzo</a> Suriani), [Daniele Nardi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniele"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniele</a> Nardi), [Abderrezzak Debilou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abderrezzak"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abderrezzak</a> Debilou)</p>
<p>自主导航和理解复杂和未知的环境需要的不仅仅是具身智能体的基本感知和运动。真正有效的探索需要智能体具备更高层次的认知能力、对周围环境进行推理的能力，并就探索策略做出更明智的决策。然而，由于智能体小策略中嵌入的认知能力有限，传统的 RL 方法难以平衡高效探索和语义理解，导致在处理语义探索时经常导致人类驱动。在本文中，我们通过提出一种新颖的深度强化学习 （DRL） 架构来应对这一挑战，该架构专为资源高效语义探索而设计。一个关键的方法论贡献是通过分层奖励函数整合视觉语言模型 （VLM） 常识。VLM 查询被建模为专用作，允许代理仅在认为有必要获得外部指导时才战略性地查询 VLM，从而节省资源。该机制与课程学习策略相结合，旨在指导不同复杂程度的学习，以确保稳健和稳定的学习。我们的实验评估结果令人信服地表明，我们的智能体实现了显着提高的对象发现率，并发展了一种学习能力，可以有效地导航到语义丰富的区域。此外，它还显示了对何时提示外部环境信息的战略掌握。通过展示一种将常识性语义推理嵌入自主代理的实用且可扩展的方法，这项研究为在机器人技术中追求完全智能和自我引导的探索提供了一种新方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a></p>
<p><strong>发布</strong>: 2025-09-11 11：10：08 UTC</p>
<h2 id="8-迈向自适应机器学习基准web代理驱动的构建域扩展和指标优化-25"><a href="https://arxiv.org/abs/2509.09321"target="_blank" rel="external nofollow noopener noreferrer">#8</a> <a href="https://papers.cool/arxiv/2509.09321"target="_blank" rel="external nofollow noopener noreferrer">迈向自适应机器学习基准：Web代理驱动的构建、域扩展和指标优化</a> 25]</h2>
<p><strong>Authors</strong>: [Hangyi Jia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hangyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hangyi</a> Jia), [Yuxi Qian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxi</a> Qian), [Hanwen Tong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hanwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hanwen</a> Tong), [Xinhui Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinhui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinhui</a> Wu), [Lin Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lin</a> Chen), [Feng Wei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feng</a> Wei)</p>
<p>大型语言模型 （LLM） 的最新进展使得通用代理的出现成为可能，用于自动化端到端机器学习 （ML） 工作流程，包括数据分析、特征工程、模型训练和竞争解决。然而，现有的基准在任务覆盖范围、领域多样性、难度建模和评估严谨性方面仍然有限，无法在现实环境中捕捉此类代理的全部功能。我们提出了 TAM Bench，这是一个多样化、现实且结构化的基准，用于评估基于 LLM 的代理在端到端 ML 任务上。TAM Bench 具有三项关键创新：（1） 浏览器自动化和基于 LLM 的任务采集系统，可自动收集和构建来自 Kaggle、AIcrowd 和 Biendata 等平台的 ML 挑战，涵盖多种任务类型和数据模式（例如表格、文本、图像、图形、音频）;（2）排行榜驱动的难度建模机制，利用参与者数量和分数离散来估计任务复杂性，实现可扩展和客观的任务校准;（3）一个多维度的评估框架，包括性能、格式合规性、约束遵守和任务泛化。基于 150 个精选的 AutoML 任务，我们构建了三个不同大小的基准子集（Lite、Medium 和 Full），专为不同的评估场景而设计。精简版有 18 个任务，涵盖不同模式和难度级别的平衡覆盖范围，可作为日常基准测试和比较研究的实用测试平台。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 10：10：48 UTC</p>
<h2 id="9-测量团队中的隐性空间协调对集体智慧和绩效的影响-2"><a href="https://arxiv.org/abs/2509.09314"target="_blank" rel="external nofollow noopener noreferrer">#9</a> <a href="https://papers.cool/arxiv/2509.09314"target="_blank" rel="external nofollow noopener noreferrer">测量团队中的隐性空间协调：对集体智慧和绩效的影响</a> 2]</h2>
<p><strong>Authors</strong>: [Thuy Ngoc Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thuy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thuy</a> Ngoc Nguyen), [Anita Williams Woolley](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anita</a> Williams Woolley), [Cleotilde Gonzalez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cleotilde"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cleotilde</a> Gonzalez)</p>
<p>在需要动态适应的快节奏决策环境中，协调的团队合作至关重要，而且通常没有明确沟通的机会。尽管现有文献中广泛考虑了隐式协调，但大多数工作都集中在同地同步的团队合作（例如运动队）上，或者在分布式团队中，主要集中在知识工作的协调上。然而，许多团队（消防员、军队、执法部门、应急响应）必须在没有视觉提示或广泛明确沟通的情况下协调他们在物理空间中的行动。本文研究了在在线协作搜救任务中，探索多样性、运动专业化和自适应空间邻近性三个维度如何影响团队绩效，在这种任务中，明确的交流受到限制，团队成员依靠运动模式来推断他人的意图并协调行动。我们的指标通过测量共享环境中的空间接近性、分布模式和运动的对齐来捕捉团队合作的关系方面。我们分析了来自 34 个四人团队（136 名参与者）的数据，这些团队在搜索和救援任务中被分配到专门的角色。结果表明，空间专业化对性能有正向预测作用，而自适应空间邻近性则呈现边际倒U形关系，适度适应水平为最佳。此外，随着时间的推移，这些指标的时间动态区分了高绩效团队和低绩效团队。这些发现提供了对基于角色的团队合作中隐式空间协调的见解，并强调了平衡适应性策略的重要性，这对培训和人工智能辅助团队支持系统具有影响。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-11 10：00：01 世界标准时间</p>
<h2 id="10-解释支持最少的锦标赛解决方案-1"><a href="https://arxiv.org/abs/2509.09312"target="_blank" rel="external nofollow noopener noreferrer">#10</a> <a href="https://papers.cool/arxiv/2509.09312"target="_blank" rel="external nofollow noopener noreferrer">解释支持最少的锦标赛解决方案</a> 1]</h2>
<p><strong>Authors</strong>: [Clément Contet](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cl"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cl</a>ément Contet), [Umberto Grandi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Umberto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Umberto</a> Grandi), [Jérôme Mengin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=J"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=J</a>érôme Mengin)</p>
<p>锦标赛是广泛使用的模型，用于代表候选人、备选者或团队之间的成对优势。我们研究了为为什么候选人出现在各种锦标赛规则下的获胜者中提供经过认证的解释的问题。为此，我们确定了最低限度的支持，最少的子锦标赛，无论锦标赛的其余部分如何完成，候选人都保证获胜（也就是说，候选人是子锦标赛的必要获胜者）。这个概念对应于对“为什么获胜者赢得比赛”这个问题的归纳解释，这是正式可解释人工智能的核心概念。我们专注于常见的锦标赛解决方案：顶级循环、未覆盖集合、谷轮规则、博尔达规则、最大化规则和加权未覆盖集合。对于每条规则，我们确定最小最小支座的大小，并提出多项式时间算法来计算除加权未覆盖集之外的所有问题，其问题是 NP 完全的。最后，我们展示了最小的支持如何用于产生紧凑、经过认证和直观的解释。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 09：55：50 UTC</p>
<h2 id="11-lightagent生产级开源-agentic-ai-框架-65"><a href="https://arxiv.org/abs/2509.09292"target="_blank" rel="external nofollow noopener noreferrer">#11</a> <a href="https://papers.cool/arxiv/2509.09292"target="_blank" rel="external nofollow noopener noreferrer">LightAgent：生产级开源 Agentic AI 框架</a> 65]</h2>
<p><strong>Authors</strong>: [Weige Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weige"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weige</a> Cai), [Tong Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tong</a> Zhu), [Jinyi Niu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinyi</a> Niu), [Ruiqi Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruiqi</a> Hu), [Lingyao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingyao</a> Li), [Tenglong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tenglong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tenglong</a> Wang), [Xiaowu Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaowu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaowu</a> Dai), [Weining Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weining"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weining</a> Shen), [Liwen Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liwen</a> Zhang)</p>
<p>随着大型语言模型（LLM）的快速发展，多智能体系统（MAS）在各种应用场景中取得了显著的进步。然而，在设计多功能、强大且高效的代理部署平台方面仍然存在巨大挑战。为了解决这些限制，我们提出了 \textbf{LightAgent}，这是一个轻量级但功能强大的代理框架，有效地解决了现有框架中灵活性和简单性之间的权衡。LightAgent 集成了内存（mem0）、工具和思维(ToT)树等核心功能，同时保持了极轻量级的结构。作为一个完全开源的解决方案，它与主流聊天平台无缝集成，使开发人员能够轻松构建自学习代理。我们已在 \href{https://github.com/wxai-space/LightAgent}{https://github.com/wxai-space/LightAgent} 发布了 LightAgent</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 09：29：13 UTC</p>
<h2 id="12-树-opo用于多步推理的非政策蒙特卡洛树引导优势优化-59"><a href="https://arxiv.org/abs/2509.09284"target="_blank" rel="external nofollow noopener noreferrer">#12</a> <a href="https://papers.cool/arxiv/2509.09284"target="_blank" rel="external nofollow noopener noreferrer">树-OPO：用于多步推理的非政策蒙特卡洛树引导优势优化</a> 59]</h2>
<p><strong>Authors</strong>: [Bingning Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingning</a> Huang), [Tu Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tu</a> Nguyen), [Matthieu Zimmer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matthieu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matthieu</a> Zimmer)</p>
<p>大型语言模型 （LLM） 推理的最新进展表明，蒙特卡洛树搜索 （MCTS） 在生成高质量中间轨迹方面的有效性，特别是在数学和符号领域。受此启发，我们探索了如何重新利用传统上用于训练价值或奖励模型的 MCTS 派生轨迹，以改进基于偏好的强化学习 （RL） 中的策略优化。具体来说，我们专注于群体相对策略优化（GRPO），这是一种最新的算法，可以在没有价值网络的情况下实现偏好一致的策略学习。我们提出了一种分阶段的 GRPO 训练范式，其中完成源自部分揭示的 MCTS 推出，引入了一种新的树结构设置来进行优势估计。这导致了一类丰富的前缀条件奖励信号，我们从理论和实证上对其进行了分析。初步结果表明，虽然结构化优势估计可以稳定更新并更好地反映组合推理质量，但优势饱和和奖励信号崩溃等挑战仍然存在。我们提出了启发式和统计解决方案来缓解这些问题，并讨论在分阶段或树状奖励结构下学习的开放挑战。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 09：18：07 UTC</p>
<h2 id="13-知识与语言的融合基于知识图谱的问答与法学硕士的比较研究-13"><a href="https://arxiv.org/abs/2509.09272"target="_blank" rel="external nofollow noopener noreferrer">#13</a> <a href="https://papers.cool/arxiv/2509.09272"target="_blank" rel="external nofollow noopener noreferrer">知识与语言的融合：基于知识图谱的问答与法学硕士的比较研究</a> 13]</h2>
<p><strong>Authors</strong>: [Vaibhav Chaudhary](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vaibhav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vaibhav</a> Chaudhary), [Neha Soni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Neha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Neha</a> Soni), [Narotam Singh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Narotam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Narotam</a> Singh), [Amita Kapoor](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amita</a> Kapoor)</p>
<p>知识图谱是一种通过关系三元组构建信息的强大工具，最近已成为增强问答系统的新领跑者。虽然传统的检索增强生成 （RAG） 方法精通从简洁文本中提取基于事实和基于本地上下文的文本，但在解决对复杂、广泛的文本的主题和整体理解时遇到了局限性，需要对文本和上下文进行更深入的分析。本文对构建知识图谱三元组并将其与大型语言模型（LLMs）集成进行问答的三种不同方法进行了全面的技术比较研究：spaCy、Stanford CoreNLP-OpenIE 和 GraphRAG，它们都利用了开源技术。我们通过分析这些方法的能力、发展状态以及它们对基于 LLM 的问答性能的影响来评估这些方法的有效性、可行性和适应性。实验结果表明，虽然OpenIE提供了最全面的三元组覆盖，但GraphRAG在三元组中表现出优越的推理能力。最后，我们讨论了每种方法的优点和局限性，并提供了改进基于知识图谱的问答的未来方向的见解。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 09：02：15 UTC</p>
<h2 id="14-jupiter通过笔记本和推理时间值引导搜索增强-llm-数据分析能力-3"><a href="https://arxiv.org/abs/2509.09245"target="_blank" rel="external nofollow noopener noreferrer">#14</a> <a href="https://papers.cool/arxiv/2509.09245"target="_blank" rel="external nofollow noopener noreferrer">Jupiter：通过笔记本和推理时间值引导搜索增强 LLM 数据分析能力</a> 3]</h2>
<p><strong>Authors</strong>: [Shuocheng Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuocheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuocheng</a> Li), [Yihao Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yihao</a> Liu), [Silin Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silin</a> Du), [Wenxuan Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenxuan</a> Zeng), [Zhe Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhe</a> Xu), [Mengyu Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengyu</a> Zhou), [Yeye He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yeye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yeye</a> He), [Haoyu Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haoyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haoyu</a> Dong), [Shi Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shi</a> Han), [Dongmei Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongmei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongmei</a> Zhang)</p>
<p>大型语言模型 （LLM） 在自动化数据科学工作流程方面显示出巨大的前景，但现有模型在多步骤推理和工具使用方面仍然存在困难，这限制了它们在复杂数据分析任务中的有效性。为了解决这个问题，我们提出了一个可扩展的管道，从现实世界的 Jupyter 笔记本和相关数据文件中提取高质量的、基于工具的数据分析任务及其可执行的多步骤解决方案。使用该管道，我们引入了 NbQA，这是一个标准化任务-解决方案对的大规模数据集，反映了实际数据科学场景中的真实工具使用模式。为了进一步增强多步推理，我们提出了 Jupiter，这是一个将数据分析表述为搜索问题的框架，并应用蒙特卡洛树搜索 （MCTS） 为价值模型学习生成多样化的解决方案轨迹。在推理过程中，Jupiter 结合了价值模型和节点访问计数，以最少的搜索步骤有效地收集可执行的多步骤计划。实验结果表明，NbQA上的Qwen2.5-7B和14B-Instruct模型在InfiAgent-DABench上解决了77.82%和86.38%的任务，分别匹配或超过GPT-4o和高级智能体框架。进一步的评估表明，在不同的多步骤推理任务中，泛化能力有所提高，工具使用推理能力更强。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 08：27：54 UTC</p>
<h2 id="15-实现监管多代理协作架构挑战和解决方案-3"><a href="https://arxiv.org/abs/2509.09215"target="_blank" rel="external nofollow noopener noreferrer">#15</a> <a href="https://papers.cool/arxiv/2509.09215"target="_blank" rel="external nofollow noopener noreferrer">实现监管多代理协作：架构、挑战和解决方案</a> 3]</h2>
<p><strong>Authors</strong>: [Qinnan Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qinnan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qinnan</a> Hu), [Yuntao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuntao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuntao</a> Wang), [Yuan Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Gao), [Zhou Su](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhou</a> Su), [Linkang Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Linkang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Linkang</a> Du)</p>
<p>大型语言模型 （LLM） 赋能的自主代理正在通过实现自适应、多代理协作来改变数字和物理环境。虽然这些代理在金融、医疗保健和智能制造等领域提供了重大机会，但它们不可预测的行为和异构能力带来了巨大的治理和问责挑战。在本文中，我们提出了一种用于监管代理协作的区块链分层架构，包括代理层、区块链数据层和监管应用层。在这个框架内，我们设计了三个关键模块：（i）用于自动问责的代理行为追踪和仲裁模块，（ii）用于协作场景信任评估的动态声誉评估模块，以及（iii）用于早期检测对抗活动的恶意行为预测模块。我们的方法为大规模代理生态系统中值得信赖、有弹性和可扩展的监管机制奠定了系统基础。最后，我们讨论了多智能体系统中区块链监管框架的未来研究方向。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a></p>
<p><strong>发布</strong>: 2025-09-11 07：46：00 UTC</p>
<h2 id="16-progd使用动态图进行多智能体联合运动预测的渐进式多尺度解码-1"><a href="https://arxiv.org/abs/2509.09210"target="_blank" rel="external nofollow noopener noreferrer">#16</a> <a href="https://papers.cool/arxiv/2509.09210"target="_blank" rel="external nofollow noopener noreferrer">ProgD：使用动态图进行多智能体联合运动预测的渐进式多尺度解码</a> 1]</h2>
<p><strong>Authors</strong>: [Xing Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xing</a> Gao), [Zherui Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zherui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zherui</a> Huang), [Weiyao Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiyao</a> Lin), [Xiao Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiao</a> Sun)</p>
<p>对周围智能体的准确运动预测对于自动驾驶汽车的安全规划至关重要。最近的进展已将预测技术从单个智能体扩展到多个交互智能体的联合预测，并采用各种策略来解决智能体未来运动中的复杂交互。然而，这些方法忽略了这些相互作用的不断发展的本质。为了解决这一限制，我们提出了一种新的渐进式多尺度解码策略，称为ProgD，借助基于动态异构图的场景建模。特别是，为了明确、全面地捕捉未来场景中不断演变的社会互动，鉴于其固有的不确定性，我们设计了一种具有动态异构图的场景渐进式建模。随着这种动态异构图的展开，设计了一种因式分解架构来处理未来场景中的时空依赖关系，并逐步消除多个智能体未来运动的不确定性。此外，还结合了多尺度解码程序，以改进未来场景建模和对智能体未来运动的一致预测。所提出的ProgD在INTERACTION多智能体预测基准测试中取得了最先进的性能，排名 1st，以及 Argoverse 2 多世界预测基准。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a></p>
<p><strong>发布</strong>: 2025-09-11 07：36：54 UTC</p>
<h2 id="17-心灵与空间的结合从神经科学启发的角度重新思考智能体空间智能-56"><a href="https://arxiv.org/abs/2509.09154"target="_blank" rel="external nofollow noopener noreferrer">#17</a> <a href="https://papers.cool/arxiv/2509.09154"target="_blank" rel="external nofollow noopener noreferrer">心灵与空间的结合：从神经科学启发的角度重新思考智能体空间智能</a> 56]</h2>
<p><strong>Authors</strong>: [Bui Duc Manh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bui</a> Duc Manh), [Soumyaratna Debnath](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soumyaratna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soumyaratna</a> Debnath), [Zetong Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zetong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zetong</a> Zhang), [Shriram Damodaran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shriram"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shriram</a> Damodaran), [Arvind Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arvind"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arvind</a> Kumar), [Yueyi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yueyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yueyi</a> Zhang), [Lu Mi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lu</a> Mi), [Erik Cambria](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Erik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Erik</a> Cambria), [Lin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lin</a> Wang)</p>
<p>代理人工智能的最新进展导致了能够自主执行任务和基于语言的推理的系统，但它们的空间推理能力仍然有限且未得到充分开发，在很大程度上仅限于符号和顺序处理。相比之下，人类空间智能植根于集成的多感官感知、空间记忆和认知地图，可以在非结构化环境中做出灵活的、上下文感知的决策。因此，弥合这一差距对于推动代理空间智能更好地与物理 3D 世界交互至关重要。为此，我们首先从仔细研究计算神经科学中研究的空间神经模型开始，并相应地引入基于神经科学原理的新计算框架。该框架将核心生物功能映射到六个基本计算模块：仿生多模态感知、多感官整合、以自我为中心-异心转换、人工认知图、空间记忆和空间推理。这些模块共同构成了跨虚拟和物理环境的代理空间推理能力的透视景观。最重要的是，我们对最近的方法进行了框架指导的分析，评估它们与每个模块的相关性，并确定阻碍开发更多基于神经科学的空间推理模块的关键差距。我们进一步研究了新兴的基准和数据集，并探索了从虚拟系统到具身系统（例如机器人技术）的潜在应用领域。最后，我们概述了潜在的研究方向，强调了可以在动态或非结构化环境中推广空间推理的有前途的路线图。我们希望这项工作能够以神经科学为基础的视角和结构化的途径使研究界受益。我们的项目页面可以在 Github 上找到。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-11 05：23：22 UTC</p>
<h2 id="18-反洗钱机器学习管道通过监督学习识别高风险银行客户的技术分析-1"><a href="https://arxiv.org/abs/2509.09127"target="_blank" rel="external nofollow noopener noreferrer">#18</a> <a href="https://papers.cool/arxiv/2509.09127"target="_blank" rel="external nofollow noopener noreferrer">反洗钱机器学习管道;通过监督学习识别高风险银行客户的技术分析</a> 1]</h2>
<p><strong>Authors</strong>: [Khashayar Namdar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Khashayar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Khashayar</a> Namdar), [Pin-Chien Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pin-Chien"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pin-Chien</a> Wang), [Tushar Raju](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tushar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tushar</a> Raju), [Steven Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Steven"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Steven</a> Zheng), [Fiona Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fiona"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fiona</a> Li), [Safwat Tahmin Khan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Safwat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Safwat</a> Tahmin Khan)</p>
<p>反洗钱 （AML） 行动和衡量是金融机构的优先事项之一，机器学习 （ML） 已被证明具有很高的潜力。在本文中，我们提出了一种全面、系统的方法来开发机器学习管道，以识别多伦多大学 2023-2024 年管理与创新研究所 （IMI） 大数据和人工智能竞赛任务 1 中的数据集中的高风险银行客户。该数据集包括 195,789 个客户 ID，我们采用了 16 步设计和统计分析来确保最终管道是稳健的。我们还将数据构建在 SQLite 数据库中，开发了基于 SQL 的特征工程算法，将预训练模型连接到数据库，使其可供推理，并提供可解释的人工智能 （XAI） 模块来推导特征重要性。我们的管道实现了 0.961 的接收者工作特征曲线下平均面积 （AUROC），标准差 （SD） 为 0.005。拟议的管道在比赛中获得第二名。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 03：53：10 UTC</p>
<h2 id="19-了解讨价还价游戏中人类和人工智能代理之间的经济权衡-12"><a href="https://arxiv.org/abs/2509.09071"target="_blank" rel="external nofollow noopener noreferrer">#19</a> <a href="https://papers.cool/arxiv/2509.09071"target="_blank" rel="external nofollow noopener noreferrer">了解讨价还价游戏中人类和人工智能代理之间的经济权衡</a> 12]</h2>
<p><strong>Authors</strong>: [Crystal Qian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Crystal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Crystal</a> Qian), [Kehang Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kehang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kehang</a> Zhu), [John Horton](<a href="https://arxiv.org/search/?searchtype=author&amp;query=John"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=John</a> Horton), [Benjamin S. Manning](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Benjamin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Benjamin</a> S. Manning), [Vivian Tsai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vivian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vivian</a> Tsai), [James Wexler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=James"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=James</a> Wexler), [Nithum Thain](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nithum"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nithum</a> Thain)</p>
<p>传统上由人类执行的协调任务越来越多地委托给自主代理。随着这种模式的发展，不仅要评估这些代理的性能，还要评估它们在动态、多代理环境中协商的过程变得至关重要。此外，不同的代理表现出明显的优势：传统的统计代理，例如贝叶斯模型，可能在明确指定的条件下表现出色，而大型语言模型 （LLM） 可以跨上下文泛化。在这项工作中，我们在动态协商环境中比较了人类（N = 216）、LLM（GPT-4o、Gemini 1.5 Pro）和贝叶斯代理，该设置能够在人群之间进行直接、相同的条件比较，从而捕获结果和行为动态。贝叶斯智能体通过激进的优化提取最高的盈余，但代价是频繁的交易拒绝。人类和法学硕士可以实现类似的总体盈余，但通过不同的行为：法学硕士喜欢保守、优惠的交易，很少被拒绝，而人类则采用更具战略性、冒险精神和公平导向的行为。因此，我们发现性能奇偶校验——智能体评估的常见基准——可以掩盖流程和对齐方面的根本差异，这对于实际协调任务中的实际部署至关重要。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.GT"target="_blank" rel="external nofollow noopener noreferrer">计算机科学与博弈论</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-11 00：25：07 UTC</p>
<h2 id="20-针对冷启动用户的基于-llm-的少量建议的教学提示优化-13"><a href="https://arxiv.org/abs/2509.09066"target="_blank" rel="external nofollow noopener noreferrer">#20</a> <a href="https://papers.cool/arxiv/2509.09066"target="_blank" rel="external nofollow noopener noreferrer">针对冷启动用户的基于 LLM 的少量建议的教学提示优化</a> 13]</h2>
<p><strong>Authors</strong>: [Haowei Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haowei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haowei</a> Yang), [Yushang Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yushang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yushang</a> Zhao), [Sitao Min](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sitao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sitao</a> Min), [Bo Su](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Su), [Chao Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chao</a> Yao), [Wei Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Xu)</p>
<p>冷启动用户问题进一步损害了推荐系统在限制对历史行为信息的访问方面的有效性。它是优化推荐任务中使用的少量大型语言模型 （LLM） 上的教学提示的有效管道。我们引入了一种上下文条件提示表述方法 P（u，\ Ds）\ \rightarrow\ R\widehat，其中 u 是冷启动用户配置文件，Ds 是策划的支持集，R\widehat 是预测的项目排名列表。基于基于 transformer 的自回归 LLM（BioGPT、LLaMA-2、GPT-4）的系统实验，我们提供了经验证据，证明最佳示例注入和指令结构可以显着提高此类模型在低数据设置下的precision@k和 NDCG 分数。该管道使用令牌级对齐和嵌入空间正则化，具有更高的语义保真度。我们的研究结果不仅表明，及时的作文不仅是句法上的，而且是功能性的，因为它通过推理直接控制注意力量表和解码器行为。本文表明，基于提示的适应可以被认为是解决基于LLM的管道中冷启动推荐问题的方法之一。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 00：13：17 UTC</p>
<h2 id="21-可解释人工智能的不确定性意识和信任度---使用局部和全局解释进行信任校准-2"><a href="https://arxiv.org/abs/2509.08989"target="_blank" rel="external nofollow noopener noreferrer">#21</a> <a href="https://papers.cool/arxiv/2509.08989"target="_blank" rel="external nofollow noopener noreferrer">可解释人工智能的不确定性意识和信任度 - 使用局部和全局解释进行信任校准</a> 2]</h2>
<p><strong>Authors</strong>: [Carina Newen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Carina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Carina</a> Newen), [Daniel Bodemer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniel</a> Bodemer), [Sonja Glantz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sonja"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sonja</a> Glantz), [Emmanuel Müller](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emmanuel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emmanuel</a> Müller), [Magdalena Wischnewski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Magdalena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Magdalena</a> Wischnewski), [Lenka Schnaubert](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lenka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lenka</a> Schnaubert)</p>
<p>可解释的人工智能已成为文献中的一个常用术语，受到计算机科学家和统计学家的审查，并受到心理学或哲学研究人员的强调。许多研究人员面临的一项主要工作是构建 XAI 方案的一般指南，这是我们从我们的研究中得出的。虽然 XAI 的某些领域得到了很好的研究，但我们专注于不确定性解释并考虑全局解释，这些解释经常被遗漏。我们选择了一种同时涵盖各种概念的算法，例如不确定性、鲁棒性和全局 XAI，并测试了其校准信任的能力。然后，我们检查了一种旨在提供更直观的视觉理解的算法，尽管理解起来很复杂，但是否可以提供更高的用户满意度和人类可解释性。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-10 20：37：39 UTC</p>
<h2 id="22-fortifai抵御-ai-模型递归训练引起的故障-2"><a href="https://arxiv.org/abs/2509.08972"target="_blank" rel="external nofollow noopener noreferrer">#22</a> <a href="https://papers.cool/arxiv/2509.08972"target="_blank" rel="external nofollow noopener noreferrer">ForTIFAI：抵御 AI 模型递归训练引起的故障</a> 2]</h2>
<p><strong>Authors</strong>: [Soheil Zibakhsh Shabgahi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soheil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soheil</a> Zibakhsh Shabgahi), [Pedram Aghazadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pedram"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pedram</a> Aghazadeh), [Azalia Mirhosseini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Azalia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Azalia</a> Mirhosseini), [Farinaz Koushanfar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Farinaz"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Farinaz</a> Koushanfar)</p>
<p>对生成式人工智能模型的日益依赖加快了合成数据的生成速度，一些预测表明，到 2030 年，大多数可用于训练的新数据可能是机器生成的。这种向主要合成内容的转变带来了一个关键挑战：在合成数据中重复训练会导致一种称为模型崩溃的现象，即模型性能在几代训练中下降，最终导致模型无效。尽管先前的研究已经探索了模型崩溃的原因和检测，但现有的缓解策略仍然有限。在本文中，我们确定模型对其自行生成数据的过度自信是崩溃的关键驱动因素。基于这一观察结果，我们提出了一个置信度感知损失函数，该函数可以在训练期间降低高置信度预测的权重。我们引入了一种新的损失函数，我们称之为截断交叉熵 （TCE）。我们证明，TCE 显着延迟了递归训练中的模型崩溃。我们提供了一个与模型无关的框架，将损失函数设计与模型崩溃缓解联系起来，并在理论和经验上验证了我们的方法，表明它可以将模型在崩溃前的保真度区间延长 2.3 倍以上。最后，我们表明我们的方法跨模态泛化。这些发现表明，损失函数的设计为在合成数据不断增加的时代保持生成模型的质量提供了一个简单而强大的工具。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-10 20：06：51 UTC</p>
<h2 id="23-用于文本到模型翻译的全局约束-llm-代理-2"><a href="https://arxiv.org/abs/2509.08970"target="_blank" rel="external nofollow noopener noreferrer">#23</a> <a href="https://papers.cool/arxiv/2509.08970"target="_blank" rel="external nofollow noopener noreferrer">用于文本到模型翻译的全局约束 LLM 代理</a> 2]</h2>
<p><strong>Authors</strong>: [Junyang Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junyang</a> Cai), [Serdar Kadioglu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Serdar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Serdar</a> Kadioglu), [Bistra Dilkina](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bistra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bistra</a> Dilkina)</p>
<p>优化或满意度问题的自然语言描述很难转化为正确的 MiniZinc 模型，因为这个过程需要逻辑推理和约束规划专业知识。我们引入了一个框架，通过代理方法应对这一挑战：多个专门的大型语言模型 （LLM） 代理按全局约束类型分解建模任务。每个代理都致力于检测和生成特定类全局约束的代码，而最终汇编代理则将这些约束片段集成到一个完整的 MiniZinc 模型中。通过将问题划分为更小的、定义明确的子任务，每个法学硕士都可以处理更简单的推理挑战，从而有可能降低整体复杂性。我们对多个 LLM 进行了初步实验，并显示出相对于基线（例如一次性提示和思维链提示）的更好性能。最后，我们概述了未来工作的全面路线图，强调了潜在的增强功能和改进方向。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-10 20：04：20 世界标准时间</p>
<h2 id="24-通过-nlp-和多模态-llm-从-gdd-自动生成-unity-游戏模板-23"><a href="https://arxiv.org/abs/2509.08847"target="_blank" rel="external nofollow noopener noreferrer">#24</a> <a href="https://papers.cool/arxiv/2509.08847"target="_blank" rel="external nofollow noopener noreferrer">通过 NLP 和多模态 LLM 从 GDD 自动生成 Unity 游戏模板</a> 23]</h2>
<p><strong>Author</strong>: [Amna Hassan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amna</a> Hassan)</p>
<p>本文通过使用自然语言处理（NLP）和多模态大型语言模型（LLM）将游戏设计文档（GDD）转换为功能性Unity游戏原型，提出了一种用于自动游戏模板生成的新颖框架。我们引入了一个端到端系统，该系统解析 GDD、提取结构化游戏规范并合成与 Unity 兼容的 C# 代码，这些代码实现了设计文档中定义的核心机制、系统和体系结构。我们的方法将专门用于 Unity 代码生成的微调 LLaMA-3 模型与简化实施过程的自定义 Unity 集成包相结合。评估结果表明，与基线模型相比，我们的微调模型在编译成功率、GDD 遵守、最佳实践采用和代码模块化指标方面与最先进的 LLM 相比取得了卓越的性能（4.8/5.0 平均分）。生成的模板展示了对多种游戏类型的 GDD 规范的高度遵守。我们的系统有效地解决了人工智能辅助游戏开发中的关键差距，将法学硕士定位为简化从游戏设计到实施过渡的宝贵工具。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a></p>
<p><strong>发布</strong>: 2025-09-07 21：53：37 UTC</p>
<h2 id="25-贝叶斯定理的区间类型-2-版本源自主题专家提供的区间概率范围估计-2"><a href="https://arxiv.org/abs/2509.08834"target="_blank" rel="external nofollow noopener noreferrer">#25</a> <a href="https://papers.cool/arxiv/2509.08834"target="_blank" rel="external nofollow noopener noreferrer">贝叶斯定理的区间类型 2 版本，源自主题专家提供的区间概率范围估计</a> 2]</h2>
<p><strong>Authors</strong>: [John T. Rickard](<a href="https://arxiv.org/search/?searchtype=author&amp;query=John"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=John</a> T. Rickard), [William A. Dembski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=William"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=William</a> A. Dembski), [James Rickards](<a href="https://arxiv.org/search/?searchtype=author&amp;query=James"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=James</a> Rickards)</p>
<p>贝叶斯推理广泛应用于许多不同的领域，以根据观测结果检验假设。在大多数此类应用中，假设精确的输入值以产生精确的输出值。然而，这对于实际应用来说是不现实的。通常，来自给定领域的主题专家 （SME） 的最佳可用信息是贝叶斯定理中涉及的输入概率的区间范围估计。本文为将贝叶斯定理扩展到区间类型 2 （IT2） 版本提供了两个关键贡献。首先，我们开发了贝叶斯定理的 IT2 版本，该定理使用一种新颖且保守的方法来避免输入 IT2 MF 中潜在的不一致，否则可能会产生无效的输出结果。然后，我们描述了一种新颖且灵活的算法，用于将 SME 提供的区间编码为 IT2 模糊隶属函数 （MF），我们可以使用它来指定贝叶斯定理中的输入概率。我们的算法推广并扩展了之前关于这个问题的工作，这些工作主要解决了将间隔编码为单词 MF 以用于单词计算应用程序的问题。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/physics.comp-ph"target="_blank" rel="external nofollow noopener noreferrer">计算物理学</a>, <a href="https://papers.cool/arxiv/physics.data-an"target="_blank" rel="external nofollow noopener noreferrer">数据分析、统计和概率</a>, <a href="https://papers.cool/arxiv/q-fin.CP"target="_blank" rel="external nofollow noopener noreferrer">计算金融</a></p>
<p><strong>发布</strong>: 2025-08-29 23：47：31 UTC</p>
<h2 id="26-butterflyquant通过可学习正交蝶形变换进行超低位-llm-量化-410"><a href="https://arxiv.org/abs/2509.09679"target="_blank" rel="external nofollow noopener noreferrer">#26</a> <a href="https://papers.cool/arxiv/2509.09679"target="_blank" rel="external nofollow noopener noreferrer">ButterflyQuant：通过可学习正交蝶形变换进行超低位 LLM 量化</a> 410]</h2>
<p><strong>Authors</strong>: [Bingxin Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingxin</a> Xu), [Zhen Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhen</a> Dong), [Oussama Elachqar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oussama"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oussama</a> Elachqar), [Yuzhang Shang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuzhang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuzhang</a> Shang)</p>
<p>大型语言模型需要大量的内存占用，严重限制了在消费类硬件上的部署。量化通过较低的数值精度来减少内存，但极端的 2 位量化会因激活异常值而遭受灾难性的性能损失。基于旋转的方法（如 QuIP 和 QuaRot）应用正交变换，在量化之前使用计算不变性消除异常值： y=Wx=(WQT)(Qx) 用于正交Q.然而，这些方法使用固定变换——Hadamard矩阵实现最佳最坏情况相干性 μ=1/n−−√&ndash;无法适应特定的权重分布。我们发现不同的变压器层表现出不同的异常值模式，从而激发了层自适应旋转，而不是一刀切的方法。我们提出了 ButterflyQuant，它用由连续 Givens 旋转角度参数化的可学习蝴蝶变换替换 Hadamard 旋转。与 Hadamard 的离散 {+1,−1} 不可微分且禁止基于梯度的学习的条目，蝴蝶变换的连续参数化可以实现平滑优化，同时通过构造保证正交性。这种正交约束确保了异常值抑制的理论保证，同时实现了O(nlogn) 计算复杂度仅为nlogn2 可学习参数。我们进一步引入了变换后激活的均匀性正则化，以促进适合量化的更平滑的分布。学习只需要 128 个校准样本，并在几分钟内收敛到单个 GPU 上——一次性成本可以忽略不计。在具有 2 位量化的 LLaMA-2-7B 上，ButterflyQuant 的困惑度为 15.4，而 QuaRot 为 22.1。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 17：59：51 UTC</p>
<h2 id="27-cde大型语言模型中高效强化学习的好奇心驱动探索-2631"><a href="https://arxiv.org/abs/2509.09675"target="_blank" rel="external nofollow noopener noreferrer">#27</a> <a href="https://papers.cool/arxiv/2509.09675"target="_blank" rel="external nofollow noopener noreferrer">CDE：大型语言模型中高效强化学习的好奇心驱动探索</a> 2631]</h2>
<p><strong>Authors</strong>: [Runpeng Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Runpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Runpeng</a> Dai), [Linfeng Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Linfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Linfeng</a> Song), [Haolin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haolin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haolin</a> Liu), [Zhenwen Liang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenwen</a> Liang), [Dian Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dian</a> Yu), [Haitao Mi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haitao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haitao</a> Mi), [Zhaopeng Tu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaopeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaopeng</a> Tu), [Rui Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rui</a> Liu), [Tong Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tong</a> Zheng), [Hongtu Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongtu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongtu</a> Zhu), [Dong Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Yu)</p>
<p>具有可验证奖励的强化学习（RLVR）是增强大型语言模型（LLM）推理能力的强大范式。然而，当前的 RLVR 方法往往探索不佳，导致过早收敛和熵崩溃。为了应对这一挑战，我们引入了好奇心驱动探索 （CDE），这是一个利用模型自身内在的好奇心来指导探索的框架。我们用来自演员和批评者的信号来形式化好奇心：对于演员，我们对其生成的反应使用困惑，而对于批评者，我们使用来自多头架构的价值估计方差。这两个信号都作为 RLVR 框架内的探索奖励来指导模型。我们的理论分析表明，参与者明智的奖励本质上会惩罚过度自信的错误，并促进正确回答的多样性;此外，我们将评论家明智的奖励与 RL 中完善的基于计数的探索奖励联系起来。根据经验，我们的方法在AIME基准测试中使用GRPO/PPO的标准RLVR比标准RLVR提高了大约+3个百分点。进一步分析确定了 RLVR 中的校准崩溃机制，揭示了常见的 LLM 故障模式。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 17：59：17 UTC</p>
<h2 id="28-simplevla-rl通过强化学习扩展-vla-训练-2130"><a href="https://arxiv.org/abs/2509.09674"target="_blank" rel="external nofollow noopener noreferrer">#28</a> <a href="https://papers.cool/arxiv/2509.09674"target="_blank" rel="external nofollow noopener noreferrer">SimpleVLA-RL：通过强化学习扩展 VLA 训练</a> 2130]</h2>
<p><strong>Authors</strong>: [Haozhan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haozhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haozhan</a> Li), [Yuxin Zuo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxin</a> Zuo), [Jiale Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiale"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiale</a> Yu), [Yuhao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhao</a> Zhang), [Zhaohui Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaohui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaohui</a> Yang), [Kaiyan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaiyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaiyan</a> Zhang), [Xuekai Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuekai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuekai</a> Zhu), [Yuchen Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Zhang), [Tianxing Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianxing</a> Chen), [Ganqu Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ganqu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ganqu</a> Cui), [Dehui Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dehui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dehui</a> Wang), [Dingxiang Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dingxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dingxiang</a> Luo), [Yuchen Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Fan), [Youbang Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youbang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youbang</a> Sun), [Jia Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Zeng), [Jiangmiao Pang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiangmiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiangmiao</a> Pang), [Shanghang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shanghang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shanghang</a> Zhang), [Yu Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Wang), [Yao Mu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yao</a> Mu), [Bowen Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Zhou), [Ning Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ning</a> Ding)</p>
<p>视觉-语言-动作 （VLA） 模型最近已成为机器人纵的强大范式。尽管大规模预训练和监督微调（SFT）取得了实质性进展，但这些模型面临着两个基本挑战：（i）SFT缩放所需的大规模人工作机器人轨迹的稀缺性和高成本，以及（ii）对涉及分布转移的任务的推广有限。大型推理模型（LRM）的最新突破表明，强化学习（RL）可以显著增强分步推理能力，这引发了一个自然的问题：RL能否同样改进VLA的长期分步行动规划？在这项工作中，我们介绍了 SimpleVLA-RL，这是一个为 VLA 模型量身定制的高效 RL 框架。在 veRL 的基础上，我们引入了特定于 VLA 的轨迹采样、可扩展的并行化、多环境渲染和优化的损失计算。当应用于 OpenVLA-OFT 时，SimpleVLA-RL 在 LIBERO 上实现了 SoTA 性能，甚至优于 π0 在 RoboTwin 1.0&amp;2.0 上，以及我们引入的探索增强策略。SimpleVLA-RL不仅减少了对大规模数据的依赖，实现了鲁棒的泛化，而且在实际任务中也明显超过了SFT。此外，我们在 RL 训练中发现了一种新现象“推切”，其中该策略发现了以前在之前训练过程中看到的模式之外的以前从未见过的模式。Github：https://github.com/PRIME-RL/SimpleVLA-RL</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 17：59：17 UTC</p>
<h2 id="29-医疗补助护理管理的可行性指导公平自适应离线强化学习-2"><a href="https://arxiv.org/abs/2509.09655"target="_blank" rel="external nofollow noopener noreferrer">#29</a> <a href="https://papers.cool/arxiv/2509.09655"target="_blank" rel="external nofollow noopener noreferrer">医疗补助护理管理的可行性指导公平自适应离线强化学习</a> 2]</h2>
<p><strong>Authors</strong>: [Sanjay Basu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sanjay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sanjay</a> Basu), [Sadiq Y. Patel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sadiq"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sadiq</a> Y. Patel), [Parth Sheth](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Parth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Parth</a> Sheth), [Bhairavi Muralidharan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bhairavi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bhairavi</a> Muralidharan), [Namrata Elamaran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Namrata"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Namrata</a> Elamaran), [Aakriti Kinra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aakriti"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aakriti</a> Kinra), [Rajaie Batniji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rajaie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rajaie</a> Batniji)</p>
<p>我们引入了可行性引导的公平自适应强化学习 （FG-FARL），这是一种离线 RL 程序，可校准每组安全阈值以减少伤害，同时平衡受保护子组之间的选定公平目标（覆盖范围或伤害）。使用来自医疗补助人口健康管理计划的去识别化纵向轨迹，我们评估 FG-FARL 与行为克隆 （BC） 和 HACO（混合自适应适形离线 RL;全球适形安全基线）的对照。我们报告了带有引导 95% 置信区间的政策外价值估计值，并报告了带有 p 值的亚组差异分析。FG-FARL 实现了与基线相当的价值，同时提高了公平性指标，展示了一条通往更安全、更公平的决策支持的实用途径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LO"target="_blank" rel="external nofollow noopener noreferrer">计算机科学中的逻辑</a>, <a href="https://papers.cool/arxiv/stat.AP"target="_blank" rel="external nofollow noopener noreferrer">应用</a></p>
<p><strong>发布</strong>: 2025-09-11 17：50：06 UTC</p>
<h2 id="30-检索增强生成用于可靠解释无线电法规-34"><a href="https://arxiv.org/abs/2509.09651"target="_blank" rel="external nofollow noopener noreferrer">#30</a> <a href="https://papers.cool/arxiv/2509.09651"target="_blank" rel="external nofollow noopener noreferrer">检索增强生成，用于可靠解释无线电法规</a> 34]</h2>
<p><strong>Authors</strong>: [Zakaria El Kassimi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zakaria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zakaria</a> El Kassimi), [Fares Fourati](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fares"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fares</a> Fourati), [Mohamed-Slim Alouini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohamed-Slim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohamed-Slim</a> Alouini)</p>
<p>我们在无线电法规领域研究问答，这是一个法律敏感且高风险的领域。我们提出了一个特定于电信的检索增强生成 （RAG） 管道，并据我们所知，引入了该领域的第一个多项选择评估集，该评估集是使用自动过滤和人工验证从权威来源构建的。为了评估检索质量，我们定义了一个特定于域的检索指标，在该指标下，我们的检索器达到了大约 97% 的准确率。除了检索之外，我们的方法还不断提高所有测试模型的生成准确性。特别是，虽然在没有结构化检索的情况下天真地插入文档只会为 GPT-4o 带来边际收益（不到 1%），但应用我们的管道可以带来近 12% 的相对改进。这些发现表明，精心针对性的基础为监管问题解答提供了简单而强大的基线和有效的特定领域解决方案。所有代码和评估脚本，以及我们派生的问答数据集，都可以在 <a href="https://github.com/Zakaria010/Radio-RAG"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Zakaria010/Radio-RAG</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a></p>
<p><strong>发布</strong>: 2025-09-11 17：43：42 UTC</p>
<h2 id="31-通过群体反事实的演变解释概念漂移-12"><a href="https://arxiv.org/abs/2509.09616"target="_blank" rel="external nofollow noopener noreferrer">#31</a> <a href="https://papers.cool/arxiv/2509.09616"target="_blank" rel="external nofollow noopener noreferrer">通过群体反事实的演变解释概念漂移</a> 12]</h2>
<p><strong>Authors</strong>: [Ignacy Stępka](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ignacy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ignacy</a> Stępka), [Jerzy Stefanowski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jerzy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jerzy</a> Stefanowski)</p>
<p>动态环境中的机器学习模型经常受到概念漂移的影响，即数据分布的变化会降低性能。虽然检测这种漂移是一个经过充分研究的话题，但解释模型的决策逻辑如何以及为何变化仍然是一个重大挑战。在本文中，我们介绍了一种新的方法，通过分析基于群体的反事实解释（GCE）的时间演变来解释概念漂移。我们的方法跟踪漂移前后 GCE 的聚类质心及其相关反事实作用向量的变化。这些不断发展的 GCE 充当可解释的代理，揭示了模型决策边界及其基本原理的结构变化。我们在一个三层框架内实施了这种分析，该框架协同地结合了来自数据层（分布偏移）、模型层（预测分歧）和我们提议的解释层的见解。我们表明，这种整体视图可以更全面地诊断漂移，从而可以区分不同的根本原因，例如空间数据偏移与概念的重新标记。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 16：58：34 UTC</p>
<h2 id="32-locobench复杂软件工程中长上下文大语言模型的基准-110"><a href="https://arxiv.org/abs/2509.09614"target="_blank" rel="external nofollow noopener noreferrer">#32</a> <a href="https://papers.cool/arxiv/2509.09614"target="_blank" rel="external nofollow noopener noreferrer">LoCoBench：复杂软件工程中长上下文大语言模型的基准</a> 110]</h2>
<p><strong>Authors</strong>: [Jielin Qiu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jielin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jielin</a> Qiu), [Zuxin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zuxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zuxin</a> Liu), [Zhiwei Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiwei</a> Liu), [Rithesh Murthy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rithesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rithesh</a> Murthy), [Jianguo Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jianguo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jianguo</a> Zhang), [Haolin Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haolin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haolin</a> Chen), [Shiyu Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiyu</a> Wang), [Ming Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ming</a> Zhu), [Liangwei Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liangwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liangwei</a> Yang), [Juntao Tan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juntao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juntao</a> Tan), [Zhepeng Cen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhepeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhepeng</a> Cen), [Cheng Qian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cheng</a> Qian), [Shelby Heinecke](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shelby"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shelby</a> Heinecke), [Weiran Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiran</a> Yao), [Silvio Savarese](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silvio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silvio</a> Savarese), [Caiming Xiong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Caiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Caiming</a> Xiong), [Huan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huan</a> Wang)</p>
<p>上下文窗口扩展到数百万个标记的长上下文语言模型的出现为复杂的代码理解和软件开发评估创造了新的机会。我们提出了 LoCoBench，这是一个综合基准测试，专门设计用于在现实、复杂的软件开发场景中评估长上下文 LLM。与专注于单功能完成或短上下文任务的现有代码评估基准测试不同，LoCoBench 解决了长上下文功能的关键评估差距，这些功能需要理解整个代码库、跨多个文件进行推理以及在大型软件系统中保持架构一致性。我们的基准测试提供了跨 10 种编程语言系统生成的 8,000 个评估场景，上下文长度跨越 10K 到 1M 标记，这是 100 倍的变化，能够在现实的软件开发环境中精确评估长上下文性能下降。LoCoBench 引入了 8 个任务类别，这些任务类别捕获了基本的长上下文功能：架构理解、跨文件重构、多会话开发、错误调查、功能实现、代码理解、集成测试和安全分析。通过 5 阶段的管道，我们创建了多样化、高质量的场景，挑战 LLM 以前所未有的规模推理复杂的代码库。我们引入了一个全面的评估框架，其中包含 4 个维度的 17 个指标，包括 8 个新的评估指标，并组合成 LoCoBench 分数 （LCBS）。我们对最先进的长上下文模型的评估揭示了巨大的性能差距，表明复杂软件开发中的长上下文理解是一个重大的未解决挑战，需要更多关注。LoCoBench 发布时间：https://github.com/SalesforceAIResearch/LoCoBench。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 16：55：04 UTC</p>
<h2 id="33-使用引导扩散模型预测时空脑肿瘤生长的机制学习-3"><a href="https://arxiv.org/abs/2509.09610"target="_blank" rel="external nofollow noopener noreferrer">#33</a> <a href="https://papers.cool/arxiv/2509.09610"target="_blank" rel="external nofollow noopener noreferrer">使用引导扩散模型预测时空脑肿瘤生长的机制学习</a> 3]</h2>
<p><strong>Authors</strong>: [Daria Laslo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daria</a> Laslo), [Efthymios Georgiou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Efthymios"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Efthymios</a> Georgiou), [Marius George Linguraru](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marius"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marius</a> George Linguraru), [Andreas Rauschecker](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andreas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andreas</a> Rauschecker), [Sabine Muller](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sabine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sabine</a> Muller), [Catherine R. Jutzeler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Catherine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Catherine</a> R. Jutzeler), [Sarah Bruningk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sarah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sarah</a> Bruningk)</p>
<p>预测脑肿瘤的时空进展对于指导神经肿瘤学的临床决策至关重要。我们提出了一种混合机制学习框架，该框架将数学肿瘤生长模型与引导去噪扩散隐式模型 （DDIM） 相结合，以从先前的扫描中合成解剖学上可行的未来 MRI。机制模型被表述为常微分方程组，可捕获包括放疗效果在内的时间肿瘤动态并估计未来的肿瘤负荷。这些估计条件是梯度引导的 DDIM，从而实现与预测生长和患者解剖结构一致的图像合成。我们在 BraTS 成人和儿童神经胶质瘤数据集上训练我们的模型，并对内部纵向小儿弥漫性中线神经胶质瘤 （DMG） 病例的 60 个轴向切片进行评估。我们的框架根据空间相似性指标生成逼真的后续扫描。它还引入了肿瘤生长概率图，该图捕获了肿瘤生长的临床相关范围和方向性，如第 95 个百分位 Hausdorff 距离所示。该方法能够在数据有限的场景中生成生物知情的图像，提供解释机制先验的生成时空预测。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 16：52：09 UTC</p>
<h2 id="34-通过双通频谱编码和潜在空间通信进行图对齐-12"><a href="https://arxiv.org/abs/2509.09597"target="_blank" rel="external nofollow noopener noreferrer">#34</a> <a href="https://papers.cool/arxiv/2509.09597"target="_blank" rel="external nofollow noopener noreferrer">通过双通频谱编码和潜在空间通信进行图对齐</a> 12]</h2>
<p><strong>Authors</strong>: [Maysam Behmanesh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maysam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maysam</a> Behmanesh), [Erkan Turan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Erkan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Erkan</a> Turan), [Maks Ovsjanikov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maks"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maks</a> Ovsjanikov)</p>
<p>图对齐——跨多个图识别相应节点的问题——是众多应用程序的基础。大多数现有的无监督方法将节点特征嵌入到潜在表示中，以实现无需真实对应关系的跨图比较。然而，这些方法存在两个关键的局限性：基于GNN的嵌入中由于过度平滑而导致的节点独特性下降，以及结构噪声、特征异质性和训练不稳定性导致的图间潜在空间错位，最终导致节点对应关系不可靠。我们提出了一种新颖的图对齐框架，该框架同时增强了节点的独特性并加强了跨潜在空间的几何一致性。我们的方法引入了一种双通编码器，它结合了低通和高通频谱滤波器，以生成既具有结构感知又具有高度辨别性的嵌入。为了解决潜在空间错位问题，我们整合了一个几何感知功能映射模块，该模块可以学习图嵌入之间的双射和等距变换，确保不同表示之间的几何关系一致。对图基准的广泛实验表明，我们的方法始终优于现有的无监督对齐基线，对结构不一致和具有挑战性的对齐场景表现出卓越的鲁棒性。此外，使用各种预训练模型对视觉语言基准的综合评估表明，我们的框架有效地泛化了图域之外，从而实现了视觉和语言表示的无监督对齐。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-11 16：36：16 UTC</p>
<h2 id="35-objectreact学习可视化导航的对象相对控制-29"><a href="https://arxiv.org/abs/2509.09594"target="_blank" rel="external nofollow noopener noreferrer">#35</a> <a href="https://papers.cool/arxiv/2509.09594"target="_blank" rel="external nofollow noopener noreferrer">ObjectReact：学习可视化导航的对象相对控制</a> 29]</h2>
<p><strong>Authors</strong>: [Sourav Garg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sourav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sourav</a> Garg), [Dustin Craggs](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dustin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dustin</a> Craggs), [Vineeth Bhat](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vineeth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vineeth</a> Bhat), [Lachlan Mares](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lachlan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lachlan</a> Mares), [Stefan Podgorski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Stefan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Stefan</a> Podgorski), [Madhava Krishna](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Madhava"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Madhava</a> Krishna), [Feras Dayoub](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feras"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feras</a> Dayoub), [Ian Reid](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> Reid)</p>
<p>仅使用单个相机和拓扑图的视觉导航最近已成为需要额外传感器和 3D 地图的方法的有吸引力的替代方案。这通常是通过“图像相对”方法来估计从给定的一对当前观测和子目标图像中估计控制来实现的。然而，图像级的世界表示存在局限性，因为图像与智能体的姿势和体现严格相关。相比之下，对象作为地图的属性，提供了一种具体化和轨迹不变的世界表示。在这项工作中，我们提出了一种学习“对象相对”控制的新范式，该范式表现出几个理想的特征：a）可以在不严格要求模仿先前经验的情况下遍历新路线，b）控制预测问题可以与解决图像匹配问题解耦，以及c）在跨实施例部署中可以实现高不变性，以应对训练-测试和映射-执行设置之间的变化。我们提出了一种“相对”3D场景图形式的地形图表示，用于获得更多信息更多的对象级全局路径规划成本。我们训练一个名为“ObjectReact”的本地控制器，它直接以高级“WayObject Costmap”表示为条件，无需显式 RGB 输入。我们展示了在传感器高度变化和挑战底层空间理解能力的多个导航任务中学习对象相对控制相对于其图像相对控制的优势，例如，在相反方向上导航地图轨迹。我们进一步表明，我们的纯模拟策略能够很好地推广到现实世界的室内环境。代码和补充材料可通过项目页面访问：https://object-react.github.io/</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/eess.SY"target="_blank" rel="external nofollow noopener noreferrer">系统和控制</a></p>
<p><strong>发布</strong>: 2025-09-11 16：34：17 UTC</p>
<h2 id="36-流利但无情语言模型的情感盲点-1"><a href="https://arxiv.org/abs/2509.09593"target="_blank" rel="external nofollow noopener noreferrer">#36</a> <a href="https://papers.cool/arxiv/2509.09593"target="_blank" rel="external nofollow noopener noreferrer">流利但无情：语言模型的情感盲点</a> 1]</h2>
<p><strong>Authors</strong>: [Bangzhao Shu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bangzhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bangzhao</a> Shu), [Isha Joshi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Isha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Isha</a> Joshi), [Melissa Karnaze](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Melissa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Melissa</a> Karnaze), [Anh C. Pham](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anh</a> C. Pham), [Ishita Kakkar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ishita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ishita</a> Kakkar), [Sindhu Kothe](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sindhu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sindhu</a> Kothe), [Arpine Hovasapian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arpine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arpine</a> Hovasapian), [Mai ElSherief](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mai</a> ElSherief)</p>
<p>大型语言模型 （LLM） 在自然语言理解方面的多功能性使其在心理健康研究中越来越受欢迎。虽然许多研究探讨了法学硕士在情绪识别方面的能力，但在评估法学硕士是否在细粒度上与人类情感保持一致方面仍然存在一个关键差距。现有的研究通常侧重于将情绪分类为预定义的、有限的类别，而忽略了更细致的表达。为了解决这一差距，我们推出了 EXPRESS，这是一个从 Reddit 社区策划的基准数据集，其中包含 251 个细粒度、自我公开的情绪标签。我们的综合评估框架检查预测的情绪术语，并使用既定的情绪理论将其分解为八种基本情绪，从而实现细粒度的比较。在各种提示设置下对流行的法学硕士进行系统测试表明，准确预测与人类自我表露的情绪相符的情绪仍然具有挑战性。定性分析进一步表明，虽然某些法学硕士生成的情感术语与既定的情感理论和定义一致，但它们有时无法像人类自我表露那样有效地捕捉上下文线索。这些发现凸显了法学硕士在细粒度情感调整方面的局限性，并为旨在增强其上下文理解的未来研究提供了见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 16：31：13 UTC</p>
<h2 id="37-看不见的属性可见的偏见探索基于-mri-的阿尔茨海默病分类中的人口统计捷径-2"><a href="https://arxiv.org/abs/2509.09558"target="_blank" rel="external nofollow noopener noreferrer">#37</a> <a href="https://papers.cool/arxiv/2509.09558"target="_blank" rel="external nofollow noopener noreferrer">看不见的属性，可见的偏见：探索基于 MRI 的阿尔茨海默病分类中的人口统计捷径</a> 2]</h2>
<p><strong>Authors</strong>: [Akshit Achara](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Akshit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Akshit</a> Achara), [Esther Puyol Anton](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Esther"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Esther</a> Puyol Anton), [Alexander Hammers](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Hammers), [Andrew P. King](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> P. King)</p>
<p>磁共振成像 （MRI） 是脑成像的金标准。已经提出了深度学习 （DL） 算法来帮助通过 MRI 扫描诊断阿尔茨海默病 （AD） 等疾病。然而，DL 算法可能会受到捷径学习的影响，其中使用与输出标签没有直接关系的虚假特征进行预测。当这些特征与受保护的属性相关时，它们可能会导致对代表性不足的受保护群体（例如按种族和性别定义的群体）产生绩效偏差。在这项工作中，我们探索了 MRI 基于 DL 的 AD 诊断中捷径学习和人口统计偏差的可能性。我们首先研究 DL 算法是否可以从 3D 脑部 MRI 扫描中识别种族或性别，以确定是否存在基于种族和性别的分布变化。接下来，我们研究了种族或性别的训练集不平衡是否会导致模型性能下降，这表明了捷径学习和偏差。最后，我们对受保护属性和AD分类任务的不同大脑区域的特征归因进行了定量和定性分析。通过这些实验，并使用多个数据集和 DL 模型（ResNet 和 SwinTransformer），我们证明了基于 DL 的 AD 分类中存在基于种族和性别的捷径学习和偏差。我们的工作为脑部 MRI 中更公平的 DL 诊断工具奠定了基础。代码提供于 <a href="https://github.com/acharaakshit/ShortMR"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/acharaakshit/ShortMR</a></p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 15：48：30 UTC</p>
<h2 id="38-一种改进的教育竞赛优化器具有多协方差学习算子用于全局优化问题-2"><a href="https://arxiv.org/abs/2509.09552"target="_blank" rel="external nofollow noopener noreferrer">#38</a> <a href="https://papers.cool/arxiv/2509.09552"target="_blank" rel="external nofollow noopener noreferrer">一种改进的教育竞赛优化器，具有多协方差学习算子，用于全局优化问题</a> 2]</h2>
<p><strong>Authors</strong>: [Baoqi Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baoqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baoqi</a> Zhao), [Xiong Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiong</a> Yang), [Hoileong Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hoileong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hoileong</a> Lee), [Bowen Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Dong)</p>
<p>教育竞赛优化器是最近推出的一种受人类行为启发式算法的启发式算法，源自社会教育竞争的动态。然而，由于开发和探索之间的不平衡，ECO 面临限制，使其容易受到局部最优的影响，并在解决复杂优化问题方面表现出有限的有效性。为了解决这些局限性，本研究提出了一种利用多协方差学习算子的增强型教育竞争优化器（IECO-MCO）。在IECO中，引入了三个不同的协方差学习算子来提高ECO的性能。每个运营商都有效地平衡了开发和勘探，同时防止种群过早汇聚。IECO 的有效性通过从 CEC 2017 和 CEC 2022 测试套件中得出的基准函数进行评估，并将其性能与不同类别的各种基本和改进算法进行比较。结果表明，IECO-MCO在收敛速度、稳定性和避免局部最优的能力方面优于基本ECO和其他竞争算法。此外，还进行了统计分析，包括 Friedman 检验、Kruskal-Wallis 检验和 Wilcoxon 秩和检验，以验证 IECO-MCO 相对于比较算法的优越性。与基础算法（改进算法）相比，IECO-MCO在CE2017和CEC2022测试套件中的平均排名为2.213（2.488）。此外，通过求解约束优化问题验证了所提IECO-MCO算法的实际适用性。实验结果证明了IECO-MCO在解决复杂优化问题方面的卓越性能，强调了其在现实场景中的鲁棒性和实际有效性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NE"target="_blank" rel="external nofollow noopener noreferrer">神经和进化计算</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a></p>
<p><strong>发布</strong>: 2025-09-11 15：41：14 UTC</p>
<h2 id="39-通过自监督视觉编码器的多特征融合和对准改进视频扩散变压器训练-85"><a href="https://arxiv.org/abs/2509.09547"target="_blank" rel="external nofollow noopener noreferrer">#39</a> <a href="https://papers.cool/arxiv/2509.09547"target="_blank" rel="external nofollow noopener noreferrer">通过自监督视觉编码器的多特征融合和对准改进视频扩散变压器训练</a> 85]</h2>
<p><strong>Authors</strong>: [Dohun Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dohun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dohun</a> Lee), [Hyeonho Jeong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyeonho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyeonho</a> Jeong), [Jiwook Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiwook"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiwook</a> Kim), [Duygu Ceylan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Duygu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Duygu</a> Ceylan), [Jong Chul Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jong</a> Chul Ye)</p>
<p>近年来，由于一系列架构创新（例如扩散变压器）和新颖训练目标（例如流量匹配）的使用，视频扩散模型发展迅速。相比之下，对提高此类模型的特征表示能力的关注较少。在这项工作中，我们表明，训练视频扩散模型可以受益于将视频生成器的中间特征与预训练视觉编码器的特征表示对齐。我们提出了一种新的指标，并对各种视觉编码器进行了深入分析，以评估它们的可辨别性和时间一致性，从而评估它们对视频特征对齐的适用性。基于分析，我们提出了 Align4Gen，它提供了一种集成到视频扩散模型训练中的新颖的多特征融合和对齐方法。我们评估了 Align4Gen 的无条件和类条件视频生成任务，并表明它通过各种指标量化了视频生成。完整的视频结果可在我们的项目页面上找到：https://align4gen.github.io/align4gen/</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 15：39：27 UTC</p>
<h2 id="40-一种基于协方差学习和多样性增强的改进rime算法用于数值优化"><a href="https://arxiv.org/abs/2509.09529"target="_blank" rel="external nofollow noopener noreferrer">#40</a> <a href="https://papers.cool/arxiv/2509.09529"target="_blank" rel="external nofollow noopener noreferrer">一种基于协方差学习和多样性增强的改进RIME算法，用于数值优化</a></h2>
<p><strong>Authors</strong>: [Shangqing Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shangqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shangqing</a> Shi), [Luoxiao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luoxiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luoxiao</a> Zhang), [Yuchen Yin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Yin), [Xiong Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiong</a> Yang), [Hoileong Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hoileong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hoileong</a> Lee)</p>
<p>元启发式方法因其能够提供更有效的解决方案而被广泛应用。RIME算法是最近提出的一种基于物理的元启发式算法，具有一定的优点。然而，它在优化过程中存在种群多样性快速丧失，容易陷入局部最优，导致开发和探索不平衡。针对RIME的不足，提出了一种具有协方差学习和多样性增强的改进RIME（MRIME-CD）。该算法采用3种策略来提高优化能力。首先，在软雾凇搜索阶段引入协方差学习策略，通过优势种群的引导效应，增加种群多样性，平衡RIME的过度开发能力;其次，为了缓和RIME种群在早期搜索阶段接近最优个体的趋势，在硬雾凇穿刺机制中引入平均引导策略，通过优势种群的加权位置来引导种群搜索，从而增强RIME在早期的全局搜索能力。最后，提出了一种新的停滞指标，并采用随机协方差学习策略，在算法停滞时对群体中的停滞个体进行更新，从而增强跳出局部最优解的能力。对所提出的MRIME-CD算法在CEC2017测试集、CEC2022测试集进行了一系列验证，并使用Friedman检验、Wilcoxon秩和检验和Kruskal Wallis检验对实验结果进行了分析。结果表明，MRIME-CD能够有效提高基础RIME的性能，在求解精度、收敛速度和稳定性方面具有明显的优势。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NE"target="_blank" rel="external nofollow noopener noreferrer">神经和进化计算</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a></p>
<p><strong>发布</strong>: 2025-09-11 15：12：03 UTC</p>
<h2 id="41-迈向可解释的职位匹配利用语义文本相关性和知识图谱-12"><a href="https://arxiv.org/abs/2509.09522"target="_blank" rel="external nofollow noopener noreferrer">#41</a> <a href="https://papers.cool/arxiv/2509.09522"target="_blank" rel="external nofollow noopener noreferrer">迈向可解释的职位匹配：利用语义文本相关性和知识图谱</a> 12]</h2>
<p><strong>Authors</strong>: [Vadim Zadykian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vadim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vadim</a> Zadykian), [Bruno Andrade](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bruno"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bruno</a> Andrade), [Haithem Afli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haithem"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haithem</a> Afli)</p>
<p>语义文本相关性 （STR） 捕获文本之间超越表面词汇相似性的微妙关系。在这项研究中，我们在职位匹配的背景下调查了 STR——这是简历推荐系统中的一个关键挑战，其中重叠的术语通常是有限的或具有误导性的。我们引入了一种自监督混合架构，该架构将密集的句子嵌入与特定领域的知识图谱 （KG） 相结合，以提高语义对齐和可解释性。与之前评估聚合性能模型的工作不同，我们的方法通过将 STR 分数连续体划分为不同的区域来强调数据分层：低、中和高语义相关性。这种分层评估可以对语义有意义的子空间中的模型性能进行细粒度分析。我们通过图神经网络评估了几种嵌入模型，包括有和没有 KG 集成。结果表明，用 KG 增强的微调 SBERT 模型在高 STR 区域产生了一致的改进，其中 RMSE 在强基线上降低了 25%。我们的研究结果不仅强调了将 KG 与文本嵌入相结合的好处，还强调了区域性能分析在理解模型行为方面的重要性。这种精细方法揭示了全局指标隐藏的优势和劣势，并支持更有针对性的模型选择，以用于公平性、可解释性和上下文匹配至关重要的人力资源 （HR） 系统和应用程序。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 15：02：54 UTC</p>
<h2 id="42-用于加速微结构成像的可解释人工智能connectome-20-扫描仪上的-shap-引导协议-1"><a href="https://arxiv.org/abs/2509.09513"target="_blank" rel="external nofollow noopener noreferrer">#42</a> <a href="https://papers.cool/arxiv/2509.09513"target="_blank" rel="external nofollow noopener noreferrer">用于加速微结构成像的可解释人工智能：Connectome 2.0 扫描仪上的 SHAP 引导协议</a> 1]</h2>
<p><strong>Authors</strong>: [Quentin Uhl](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Quentin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Quentin</a> Uhl), [Tommaso Pavan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tommaso"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tommaso</a> Pavan), [Julianna Gerold](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Julianna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Julianna</a> Gerold), [Kwok-Shing Chan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kwok-Shing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kwok-Shing</a> Chan), [Yohan Jun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yohan</a> Jun), [Shohei Fujita](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shohei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shohei</a> Fujita), [Aneri Bhatt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aneri"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aneri</a> Bhatt), [Yixin Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixin</a> Ma), [Qiaochu Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiaochu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiaochu</a> Wang), [Hong-Hsi Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hong-Hsi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hong-Hsi</a> Lee), [Susie Y. Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Susie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Susie</a> Y. Huang), [Berkin Bilgic](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Berkin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Berkin</a> Bilgic), [Ileana Jelescu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ileana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ileana</a> Jelescu)</p>
<p>弥散 MRI 神经突交换成像模型通过估计隔室大小、扩散率和隔室间水交换时间等参数，为探测灰质微观结构提供了一个有前途的框架。但是，现有协议需要较长的扫描时间。本研究提出了一种减少Connectome 2.0扫描仪采集的方案，该方案可保持模型精度，同时大幅缩短扫描持续时间。我们使用可解释的人工智能和引导递归特征消除策略开发了一个数据驱动框架，以从 15 个特征协议中识别最佳的 8 个特征子集。该优化方案的性能在体内进行了验证，并针对完整的采集和替代还原策略进行了基准测试。评估参数准确性、解剖对比度的保留和重测重现性。简化后的协议产生了与完整协议相当的参数估计和皮质图，合成数据中的估计误差较低，对重测变异性的影响最小。与理论驱动和启发式还原方案相比，优化后的协议表现出卓越的鲁棒性，将水交换时间估计的偏差减少了两倍以上。总之，这种混合优化框架可以在 14 分钟内对神经突交换进行可行的成像，而不会损失参数保真度。该方法支持交换敏感弥散磁共振成像在神经科学和临床研究中的更广泛应用，并为在生物物理参数映射中设计高效的采集方案提供了一种通用的方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/physics.med-ph"target="_blank" rel="external nofollow noopener noreferrer">医学物理学</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a></p>
<p><strong>发布</strong>: 2025-09-11 14：53：26 UTC</p>
<h2 id="43-将人工智能事件报告纳入电信法律和政策来自印度的见解"><a href="https://arxiv.org/abs/2509.09508"target="_blank" rel="external nofollow noopener noreferrer">#43</a> <a href="https://papers.cool/arxiv/2509.09508"target="_blank" rel="external nofollow noopener noreferrer">将人工智能事件报告纳入电信法律和政策：来自印度的见解</a></h2>
<p><strong>Authors</strong>: [Avinash Agarwal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Avinash"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Avinash</a> Agarwal), [Manisha J. Nene](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manisha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manisha</a> J. Nene)</p>
<p>将人工智能 （AI） 集成到电信基础设施中会带来新的风险，例如算法偏差和不可预测的系统行为，这些风险超出了传统网络安全和数据保护框架的范围。本文介绍了电信人工智能事件的精确定义和详细类型，将其确立为超越传统网络安全和数据保护漏洞的独特风险类别。它主张将它们视为一个独特的监管问题。该文件以印度为例，分析了缺乏横向人工智能法律的司法管辖区，分析了该国的关键数字法规。分析显示，印度现有的法律文书，包括 2023 年《电信法》、《CERT-In 规则》和 2023 年《数字个人数据保护法》，侧重于网络安全和数据泄露，为特定于人工智能的运营事件造成了重大的监管差距，例如性能下降和算法偏差。该文件还研究了披露的结构性障碍和现有人工智能事件存储库的局限性。基于这些发现，该文件提出了有针对性的政策建议，重点是将人工智能事件报告纳入印度现有的电信治理。主要提案包括强制报告高风险人工智能故障、指定现有政府机构作为管理事件数据的节点机构以及制定标准化报告框架。这些建议旨在提高监管清晰度并增强长期弹性，为寻求在现有部门框架内管理人工智能风险的其他国家提供务实且可复制的蓝图。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-11 14：50：41 UTC</p>
<h2 id="44-openfake面向大规模深度伪造检测的开放数据集和平台-32"><a href="https://arxiv.org/abs/2509.09495"target="_blank" rel="external nofollow noopener noreferrer">#44</a> <a href="https://papers.cool/arxiv/2509.09495"target="_blank" rel="external nofollow noopener noreferrer">OpenFake：面向大规模深度伪造检测的开放数据集和平台</a> 32]</h2>
<p><strong>Authors</strong>: [Victor Livernoche](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Victor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Victor</a> Livernoche), [Akshatha Arodi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Akshatha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Akshatha</a> Arodi), [Andreea Musulan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andreea"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andreea</a> Musulan), [Zachary Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zachary"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zachary</a> Yang), [Adam Salvail](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adam</a> Salvail), [Gaétan Marceau Caron](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ga"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ga</a>étan Marceau Caron), [Jean-François Godbout](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jean-Fran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jean-Fran</a>çois Godbout), [Reihaneh Rabbany](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Reihaneh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Reihaneh</a> Rabbany)</p>
<p>深度伪造是使用先进人工智能技术创建的合成媒体，加剧了错误信息的传播，特别是在政治敏感背景下。现有的深度伪造检测数据集往往有限，依赖于过时的生成方法、低真实感或单人脸图像，限制了一般合成图像检测的有效性。通过分析社交媒体帖子，我们确定了深度伪造传播错误信息的多种方式。此外，我们的人类感知研究表明，最近开发的专有模型产生的合成图像与真实图像越来越难以区分，使公众的准确识别变得复杂。因此，我们提出了一个全面的、以政治为重点的数据集，专门用于根据现代生成模型进行基准检测。该数据集包含 300 万张真实图像和描述性标题，用于从专有和开源模型的混合中生成 963k 对应的高质量合成图像。认识到生成技术的不断发展，我们推出了一个创新的众包对抗平台，激励参与者生成和提交具有挑战性的合成图像。这项正在进行的社区驱动计划确保深度伪造检测方法保持稳健和适应性，主动保护公众话语免受复杂的错误信息威胁。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 14：34：22 UTC</p>
<h2 id="45-提示海盗需要地图窃取种子有助于窃取提示-1"><a href="https://arxiv.org/abs/2509.09488"target="_blank" rel="external nofollow noopener noreferrer">#45</a> <a href="https://papers.cool/arxiv/2509.09488"target="_blank" rel="external nofollow noopener noreferrer">提示海盗需要地图：窃取种子有助于窃取提示</a> 1]</h2>
<p><strong>Authors</strong>: [Felix Mächtle](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Felix"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Felix</a> Mächtle), [Ashwath Shetty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ashwath"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ashwath</a> Shetty), [Jonas Sander](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonas</a> Sander), [Nils Loose](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nils"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nils</a> Loose), [Sören Pirk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=S"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=S</a>ören Pirk), [Thomas Eisenbarth](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Eisenbarth)</p>
<p>扩散模型显着推进了文本到图像的生成，能够创建以文本提示和种子为条件的高度逼真的图像。鉴于此类提示所蕴含的相当大的智力和经济价值，提示盗窃构成了严重的安全和隐私问题。在本文中，我们研究了针对扩散模型的提示窃取攻击。我们发现，基于数值优化的提示恢复方法从根本上受到限制，因为它们没有考虑图像生成过程中使用的初始随机噪声。我们识别并利用了主要图像生成框架中普遍存在的噪声生成漏洞 （CWE-339），该漏洞源于 PyTorch 将种子值限制在 232 在 CPU 上生成初始随机噪声时。通过对通过流行平台 CivitAI 共享的图像进行大规模实证分析，我们证明，使用我们的种子恢复工具 SeedSnitch，可以在每颗种子 140 分钟内有效地暴力破解这些图像的种子值中约 95%。利用恢复的种子，我们提出了 PromptPirate，这是一种基于遗传算法的优化方法，专门设计用于提示窃取。PromptPirate 超越了最先进的方法，即 PromptStealer、P2HP 和 CLIP-Interrogator，实现了 LPIPS 相似性提高 8-11%。此外，我们还引入了直接有效的对策，使种子窃取以及基于优化的提示窃取无效。我们已负责任地披露了我们的调查结果，并与开发人员启动了协调的缓解工作，以解决这一关键漏洞。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 14：21：59 UTC</p>
<h2 id="46-撒哈拉以南-mri-上的资源高效神经胶质瘤分割"><a href="https://arxiv.org/abs/2509.09469"target="_blank" rel="external nofollow noopener noreferrer">#46</a> <a href="https://papers.cool/arxiv/2509.09469"target="_blank" rel="external nofollow noopener noreferrer">撒哈拉以南 MRI 上的资源高效神经胶质瘤分割</a></h2>
<p><strong>Authors</strong>: [Freedmore Sidume](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Freedmore"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Freedmore</a> Sidume), [Oumayma Soula](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oumayma"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oumayma</a> Soula), [Joseph Muthui Wacira](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joseph"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joseph</a> Muthui Wacira), [YunFei Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=YunFei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=YunFei</a> Zhu), [Abbas Rabiu Muhammad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abbas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abbas</a> Rabiu Muhammad), [Abderrazek Zeraii](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abderrazek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abderrazek</a> Zeraii), [Oluwaseun Kalejaye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oluwaseun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oluwaseun</a> Kalejaye), [Hajer Ibrahim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hajer"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hajer</a> Ibrahim), [Olfa Gaddour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Olfa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Olfa</a> Gaddour), [Brain Halubanza](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Brain"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Brain</a> Halubanza), [Dong Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Zhang), [Udunna C Anazodo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Udunna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Udunna</a> C Anazodo), [Confidence Raymond](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Confidence"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Confidence</a> Raymond)</p>
<p>神经胶质瘤是最常见的原发性脑肿瘤类型，从 MRI 中准确分割它们对于诊断、治疗计划和纵向监测至关重要。然而，撒哈拉以南非洲 （SSA） 缺乏高质量的注释成像数据，这给在临床工作流程中部署先进的分割模型带来了重大挑战。本研究引入了一个针对资源受限环境量身定制的强大且计算高效的深度学习框架。我们利用了 3D Attention UNet 架构，该架构通过残差块进行了增强，并通过 BraTS 2021 数据集上预训练权重的迁移学习进行了增强。我们的模型对来自 BraTS-Africa 数据集的 95 例 MRI 病例进行了评估，这是 SSA MRI 数据中神经胶质瘤分割的基准。尽管数据质量和数量有限，但我们的方法在增强肿瘤 （ET） 方面获得了 0.76 分，坏死和非增强肿瘤核心 （NETC） 的 Dice 得分为 0.80，对周围非功能性半球 （SNFH） 的 Dice 得分为 0.85。这些结果证明了所提出模型的普遍性及其支持资源匮乏环境中临床决策的潜力。紧凑的架构（约 90 MB）和消费级硬件上每卷的亚分钟推理时间进一步强调了其在 SSA 健康系统中部署的实用性。这项工作通过为服务欠缺的地区提供高性能且易于使用的医学成像解决方案，有助于缩小全球健康公平人工智能方面的差距。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 13：52：47 UTC</p>
<h2 id="47-ensi大型语言模型的高效非交互式安全推理"><a href="https://arxiv.org/abs/2509.09424"target="_blank" rel="external nofollow noopener noreferrer">#47</a> <a href="https://papers.cool/arxiv/2509.09424"target="_blank" rel="external nofollow noopener noreferrer">ENSI：大型语言模型的高效非交互式安全推理</a></h2>
<p><strong>Authors</strong>: [Zhiyu He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyu</a> He), [Maojiang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maojiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maojiang</a> Wang), [Xinwen Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinwen</a> Gao), [Yuchuan Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchuan</a> Luo), [Lin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lin</a> Liu), [Shaojing Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaojing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaojing</a> Fu)</p>
<p>安全推理通过利用加密协议来支持对敏感用户数据进行计算而不暴露隐私，从而实现隐私保护机器学习。然而，将加密协议与大型语言模型 （LLM） 集成带来了重大挑战，因为这些协议固有的复杂性，加上 LLM 的庞大参数规模和复杂的架构，严重限制了实际可用性。在这项工作中，我们提出了ENSI，这是一种新的非交互式法学硕士安全推理框架，基于共同设计密码学协议和法学硕士架构的原则。ENSI 采用优化的编码策略，将 CKKS 方案与轻量级 LLM 变体 BitNet 无缝集成，显着降低了加密矩阵乘法的计算复杂性。为了应对同态加密 （HE） 下 softmax 的令人望而却步的计算需求，我们率先将 S 形注意力机制与 HE 集成为无缝、无需再训练的替代方案。此外，通过将引导作嵌入到 RMSNorm 进程中，我们可以有效地刷新密文，同时显着降低昂贵的引导调用的频率。实验评估表明，与最先进的方法相比，ENSI在CPU上的矩阵乘法加速了约8倍，softmax推理速度提高了2.6倍，而引导比例降低到仅1%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 13：04：22 UTC</p>
<h2 id="48-我们仍然做错了全部推荐系统十五年后-43"><a href="https://arxiv.org/abs/2509.09414"target="_blank" rel="external nofollow noopener noreferrer">#48</a> <a href="https://papers.cool/arxiv/2509.09414"target="_blank" rel="external nofollow noopener noreferrer">我们仍然做错了（全部）：推荐系统，十五年后</a> 43]</h2>
<p><strong>Authors</strong>: [Alan Said](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alan</a> Said), [Maria Soledad Pera](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maria</a> Soledad Pera), [Michael D. Ekstrand](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> D. Ekstrand)</p>
<p>2011 年，Xavier Amatriain 敲响了警钟：推荐系统研究“做错了一切”[1]。他的批评植根于统计学的误解和方法论的捷径，在今天和当时一样具有现实意义。但我们没有纠正方向，而是在同样破碎的基础上添加了新的复杂层。本文重新审视了阿马特里安的诊断，并认为他发现的许多概念、认识论和基础设施失败仍然以更微妙或系统的形式持续存在。借鉴最近在可重复性、评估方法、环境影响和参与式设计方面的工作，我们展示了该领域不断加速的复杂性如何超过其内省。我们重点介绍正在进行的社区主导的举措，这些举措试图改变范式，包括研讨会、评估框架以及对价值敏感和参与性研究的呼吁。与此同时，我们认为，有意义的变革不仅需要新的指标或更好的工具，还需要从根本上重构推荐系统研究的目的、它为谁服务以及如何产生和验证知识。我们的呼吁不仅仅是技术改革，而是呼吁建立基于认识谦逊、人类影响和可持续实践的推荐系统研究议程。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 12：51：37 UTC</p>
<h2 id="49-llm-不知道自己的决策边界自行生成的反事实解释的不可靠性-49"><a href="https://arxiv.org/abs/2509.09396"target="_blank" rel="external nofollow noopener noreferrer">#49</a> <a href="https://papers.cool/arxiv/2509.09396"target="_blank" rel="external nofollow noopener noreferrer">LLM 不知道自己的决策边界：自行生成的反事实解释的不可靠性</a> 49]</h2>
<p><strong>Authors</strong>: [Harry Mayne](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Harry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Harry</a> Mayne), [Ryan Othniel Kearns](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ryan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ryan</a> Othniel Kearns), [Yushi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yushi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yushi</a> Yang), [Andrew M. Bean](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> M. Bean), [Eoin Delaney](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eoin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eoin</a> Delaney), [Chris Russell](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chris"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chris</a> Russell), [Adam Mahdi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adam</a> Mahdi)</p>
<p>为了与人类有效协作，语言模型必须能够用自然语言解释他们的决定。我们研究一种特定类型的自我解释：自我生成的反事实解释 （SCE），其中模型通过修改输入来解释其预测，从而预测不同的结果。我们评估法学硕士是否能够产生有效的 SCE，实现预期结果，并且修改输入不超过必要的程度。当被要求生成反事实时，我们发现法学硕士通常会产生有效的 SCE，但远非最低限度，对他们的决策行为几乎没有提供任何洞察力。令人担忧的是，当被要求生成最少的反事实时，法学硕士通常会进行过小的编辑，无法改变预测。观察到的有效性-最小性权衡在多个 LLM、数据集和评估设置中是一致的。我们的研究结果表明，SCE 充其量只是一种无效的可解释性工具，最坏的情况是，可能会为模型行为提供误导性见解。在高风险环境中部署法学硕士的提案必须考虑不可靠的自我解释对下游决策的影响。我们的代码可在 <a href="https://github.com/HarryMayne/SCEs"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/HarryMayne/SCEs</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 12：25：41 UTC</p>
<h2 id="50-metallmix--一种基于-xai-辅助-llm-meta-学习的超参数优化方法"><a href="https://arxiv.org/abs/2509.09387"target="_blank" rel="external nofollow noopener noreferrer">#50</a> <a href="https://papers.cool/arxiv/2509.09387"target="_blank" rel="external nofollow noopener noreferrer">MetaLLMix ： 一种基于 XAI 辅助 LLM-Meta 学习的超参数优化方法</a></h2>
<p><strong>Authors</strong>: [Mohammed Tiouti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohammed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohammed</a> Tiouti), [Mohamed Bal-Ghaoui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohamed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohamed</a> Bal-Ghaoui)</p>
<p>有效的模型和超参数选择仍然是深度学习中的一个主要挑战，通常需要广泛的专业知识和计算。虽然 AutoML 和大型语言模型 （LLM） 承诺实现自动化，但当前基于 LLM 的方法依赖于反复试验和昂贵的 API，这些 API 提供的可解释性和通用性有限。我们提出了 MetaLLMiX，这是一个结合了元学习、可解释 AI 和高效 LLM 推理的零样本超参数优化框架。通过利用历史实验结果和 SHAP 解释，MetaLLMiX 推荐最佳超参数和预训练模型，无需额外试验。我们进一步采用 LLM 作为评判的评估来控制输出格式、准确性和完整性。使用九个开源轻量级 LLM 对八个医学成像数据集进行的实验表明，MetaLLMiX 实现了与传统 HPO 方法相比具有竞争力或更优越的性能，同时大大降低了计算成本。我们的本地部署优于以前基于 API 的方法，在 8 项任务中的 5 项上取得了最佳结果，响应时间缩短了 99.6-99.9%，在 6 个数据集上训练时间最快（快 2.4-15.7 倍），将准确性保持在最佳性能基线的 1-5% 以内。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 12：06：34 UTC</p>
<h2 id="51-通过多项式回归的鲁棒非线性相关-1"><a href="https://arxiv.org/abs/2509.09380"target="_blank" rel="external nofollow noopener noreferrer">#51</a> <a href="https://papers.cool/arxiv/2509.09380"target="_blank" rel="external nofollow noopener noreferrer">通过多项式回归的鲁棒非线性相关</a> 1]</h2>
<p><strong>Authors</strong>: [Luca Giuliani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luca</a> Giuliani), [Michele Lombardi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michele"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michele</a> Lombardi)</p>
<p>Hirschfeld-Gebelein-Rényi（HGR）相关系数是Pearson相关性的扩展，不仅限于线性相关，在算法公平性、科学分析和因果发现方面具有潜在的应用。最近，人们提出了以可微分方式估计 HGR 的新算法，以促进其在受约束的机器学习应用中用作损失正则化器。然而，HGR 固有的不可计算性需要偏差-方差权衡，这可能会损害所提出方法的鲁棒性，因此如果应用于现实场景，会引发技术问题。我们为 HGR 引入了一种新的计算方法，该方法依赖于用户可配置的多项式核，与以前的方法相比，具有更高的鲁棒性，并具有更快但几乎同样有效的限制。我们的方法在稳健性和确定性方面具有显着优势，使其成为实际应用中更可靠的选择。此外，我们还进行了简短的实验分析，以验证我们的方法在受约束的机器学习框架中的适用性，表明其计算产生了一个富有洞察力的子梯度，可以作为损失正则化器。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/math.NA"target="_blank" rel="external nofollow noopener noreferrer">数值分析</a></p>
<p><strong>发布</strong>: 2025-09-11 11：55：48 UTC</p>
<h2 id="52-自动驾驶汽车外部观察技术对驾驶员行为进行分类-1"><a href="https://arxiv.org/abs/2509.09349"target="_blank" rel="external nofollow noopener noreferrer">#52</a> <a href="https://papers.cool/arxiv/2509.09349"target="_blank" rel="external nofollow noopener noreferrer">自动驾驶汽车外部观察技术对驾驶员行为进行分类</a> 1]</h2>
<p><strong>Authors</strong>: [Ian Nell](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> Nell), [Shane Gilroy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shane"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shane</a> Gilroy)</p>
<p>道路交通事故仍然是一个重大的全球问题，人为错误，尤其是分心和驾驶障碍，是主要原因之一。本研究引入了一种新型的驾驶员行为分类系统，该系统利用外部观察技术来检测分心和损伤的指标。所提出的框架采用了先进的计算机视觉方法，包括实时物体跟踪、横向位移分析和车道位置监控。该系统通过实施 YOLO 对象检测模型和自定义车道估计算法来识别不安全的驾驶行为，例如过度横向移动和不稳定的轨迹模式。与依赖车间通信的系统不同，这种基于视觉的方法可以对非联网车辆进行行为分析。对不同视频数据集的实验评估证明了该框架在不同道路和环境条件下的可靠性和适应性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.ET"target="_blank" rel="external nofollow noopener noreferrer">新兴技术</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a></p>
<p><strong>发布</strong>: 2025-09-11 11：05：14 UTC</p>
<h2 id="53-mose通过子图专家的混合揭示图中的结构模式"><a href="https://arxiv.org/abs/2509.09337"target="_blank" rel="external nofollow noopener noreferrer">#53</a> <a href="https://papers.cool/arxiv/2509.09337"target="_blank" rel="external nofollow noopener noreferrer">MoSE：通过子图专家的混合揭示图中的结构模式</a></h2>
<p><strong>Authors</strong>: [Junda Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junda"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junda</a> Ye), [Zhongbao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongbao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongbao</a> Zhang), [Li Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Li"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Li</a> Sun), [Siqiang Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siqiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siqiang</a> Luo)</p>
<p>虽然图神经网络 （GNN） 在从图结构数据中学习方面取得了巨大成功，但它们对局部成对消息传递的依赖限制了它们捕获复杂、高阶子图模式的能力。导致结构表现力不足。最近的努力试图通过将随机游走核集成到 GNN 中来增强结构表达能力。然而，这些方法本质上是为图级任务设计的，这限制了它们对其他下游任务（例如节点分类）的适用性。此外，它们固定的内核配置阻碍了模型捕获不同子图结构的灵活性。为了解决这些局限性，本文提出了一种新颖的子图专家混合（MoSE）框架，用于跨不同图任务进行灵活且富有表现力的基于子图的表示学习。具体来说，MoSE 通过匿名游走提取信息丰富的子图，并根据结构语义将它们动态路由给专业专家，使模型能够捕获不同的子图模式，并提高灵活性和可解释性。我们进一步对 MoSE 在子图 Weisfeiler-Lehman （SWL） 测试中的表达能力进行了理论分析，证明它比 SWL 更强大。广泛的实验，以及学习的子图专家的可视化，表明 MoSE 不仅优于竞争基线，而且还提供了对模型学习的结构模式的可解释见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 10：45：50 UTC</p>
<h2 id="54-omnieva通过任务自适应-3d-基础和具身感知推理的具身多功能规划器-68"><a href="https://arxiv.org/abs/2509.09332"target="_blank" rel="external nofollow noopener noreferrer">#54</a> <a href="https://papers.cool/arxiv/2509.09332"target="_blank" rel="external nofollow noopener noreferrer">OmniEVA：通过任务自适应 3D 基础和具身感知推理的具身多功能规划器</a> 68]</h2>
<p><strong>Authors</strong>: [Yuecheng Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuecheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuecheng</a> Liu), [Dafeng Chi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dafeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dafeng</a> Chi), [Shiguang Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiguang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiguang</a> Wu), [Zhanguang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhanguang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhanguang</a> Zhang), [Yuzheng Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuzheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuzheng</a> Zhuang), [Bowen Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Yang), [He Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=He"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=He</a> Zhu), [Lingfeng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingfeng</a> Zhang), [Pengwei Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pengwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pengwei</a> Xie), [David Gamaliel Arcos Bravo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Gamaliel Arcos Bravo), [Yingxue Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yingxue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yingxue</a> Zhang), [Jianye Hao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jianye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jianye</a> Hao), [Xingyue Quan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xingyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xingyue</a> Quan)</p>
<p>多模态大语言模型（MLLM）的最新进展为具身智能开辟了新的机会，实现了多模态理解、推理和交互，以及连续的空间决策。然而，当前基于MLLM的具身系统面临两个关键的局限性。首先，几何适应性差距：仅根据 2D 输入或硬编码 3D 几何注入训练的模型要么存在空间信息不足，要么存在 2D 泛化受限的问题，导致跨具有不同空间需求的任务的适应性较差。第二，实施约束差距：先前的工作往往忽视了真实机器人的物理约束和能力，导致任务计划在理论上有效，但实际上不可行。为了解决这些差距，我们推出了 OmniEVA——一种具身多功能规划器，通过两项关键创新实现高级具身推理和任务规划：（1） 任务自适应 3D 接地机制，它引入了门控路由器，根据上下文需求对 3D 融合执行显式选择性调节，从而为不同的具身任务实现上下文感知 3D 接地。（2）将任务目标和实施例约束共同纳入推理循环的实施化感知推理框架，从而产生既面向目标又可执行的规划决策。大量的实验结果表明，OmniEVA不仅实现了最先进的通用具身推理性能，而且在广泛的下游场景中表现出强大的能力。对一套拟议的隐含基准（包括原始任务和复合任务）的评估证实了其强大而通用的规划能力。项目页面：https://omnieva.github.io</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-11 10：32：22 UTC</p>
<h2 id="55-多模态法学硕士能看清材料吗材料表征的多模态基准-23"><a href="https://arxiv.org/abs/2509.09307"target="_blank" rel="external nofollow noopener noreferrer">#55</a> <a href="https://papers.cool/arxiv/2509.09307"target="_blank" rel="external nofollow noopener noreferrer">多模态法学硕士能看清材料吗？材料表征的多模态基准</a> 23]</h2>
<p><strong>Authors</strong>: [Zhengzhao Lai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhengzhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhengzhao</a> Lai), [Youbin Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youbin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youbin</a> Zheng), [Zhenyang Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenyang</a> Cai), [Haonan Lyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haonan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haonan</a> Lyu), [Jinpu Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinpu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinpu</a> Yang), [Hongqing Liang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongqing</a> Liang), [Yan Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yan</a> Hu), [Benyou Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Benyou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Benyou</a> Wang)</p>
<p>材料表征是获取材料信息的基础，揭示了指导材料设计和优化的加工-微观结构-性能关系。虽然多模态大型语言模型 （MLLM） 最近在材料科学的生成和预测任务中显示出前景，但它们理解真实世界表征成像数据的能力仍未得到充分探索。为了弥补这一差距，我们推出了 MatCha，这是材料表征图像理解的第一个基准，包含 1,500 个问题，需要专家级的领域专业知识。MatCha 涵盖材料研究的四个关键阶段，包括 21 个不同的任务，每个任务都旨在反映材料科学家面临的真实挑战。我们对 MatCha 上最先进的 MLLM 的评估表明，与人类专家相比存在显着的性能差距。这些模型在解决需要更高级别专业知识和复杂视觉感知的问题时表现出退化。简单的少数镜头和思维链促使努力减轻这些限制。这些发现强调，现有的 MLLM 对现实世界的材料表征场景的适应性仍然有限。我们希望MatCha能够促进未来在新材料发现和自主科学代理等领域的研究。MatCha 可在 <a href="https://github.com/FreedomIntelligence/MatCha"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/FreedomIntelligence/MatCha</a> 购买。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-09-11 09：50：16 UTC</p>
<h2 id="56-与模态无关的输入通道能够在多模态-mri-中分割脑部病变序列在训练期间不可用"><a href="https://arxiv.org/abs/2509.09290"target="_blank" rel="external nofollow noopener noreferrer">#56</a> <a href="https://papers.cool/arxiv/2509.09290"target="_blank" rel="external nofollow noopener noreferrer">与模态无关的输入通道能够在多模态 MRI 中分割脑部病变，序列在训练期间不可用</a></h2>
<p><strong>Authors</strong>: [Anthony P. Addison](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anthony"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anthony</a> P. Addison), [Felix Wagner](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Felix"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Felix</a> Wagner), [Wentian Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wentian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wentian</a> Xu), [Natalie Voets](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Natalie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Natalie</a> Voets), [Konstantinos Kamnitsas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Konstantinos"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Konstantinos</a> Kamnitsas)</p>
<p>分割模型是脑部MRI中病变检测和分析的重要工具。根据成像的脑部病理类型，MRI 扫描仪可以获取多种不同的图像模式（对比度）。大多数多模态脑部 MRI 的分割模型仅限于固定模式，无法在推理时有效处理新模式。一些模型推广到看不见的模态，但可能会丢失特定于模态的区分性信息。这项工作旨在开发一种模型，该模型可以对包含训练期间未见过的图像模态、以前看到的模态以及两者的异构组合的数据进行推理，从而允许用户利用任何可用的成像模态。我们通过集成与模态无关的输入通道或通路以及特定于模态的输入通道，对 U-net 架构进行简单而实用的更改来证明这是可能的。为了训练这种与模态无关的组件，我们开发了一种合成人工 MRI 模式的图像增强方案。增强可不同地改变病理和健康脑组织的外观，在它们之间形成人工对比，同时保持逼真的解剖完整性。我们使用 8 个 MRI 数据库评估该方法，其中包括 5 种病理类型（中风、肿瘤、创伤性脑损伤、多发性硬化症和白质高信号）和 8 种模式（T1、T1+造影剂、T2、PD、SWI、DWI、ADC 和 FLAIR）。结果表明，该方法保留了有效处理训练期间遇到的 MRI 模式的能力，同时能够处理新的、看不见的模式以改进其分割。项目编号：https://github.com/Anthony-P-Addison/AGN-MOD-SEG</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 09：25：30 UTC</p>
<h2 id="57-使用设备感知教师进行低复杂度声场景分类的自适应知识蒸馏-2"><a href="https://arxiv.org/abs/2509.09262"target="_blank" rel="external nofollow noopener noreferrer">#57</a> <a href="https://papers.cool/arxiv/2509.09262"target="_blank" rel="external nofollow noopener noreferrer">使用设备感知教师进行低复杂度声场景分类的自适应知识蒸馏</a> 2]</h2>
<p><strong>Authors</strong>: [Seung Gyu Jeong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seung</a> Gyu Jeong), [Seong Eun Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seong</a> Eun Kim)</p>
<p>在本技术报告中，我们描述了我们提交的 DCASE 2025 挑战赛任务 1“低复杂度设备鲁棒声学场景分类”。我们的工作解决了严格的复杂性约束和对可见和不可见设备的稳健泛化的双重挑战，同时还利用了允许在测试时使用设备标签的新规则。我们提出的系统基于一个知识蒸馏框架，在该框架中，高效的 CP-MobileNet 学生从一个紧凑的、专业的双教师合奏中学习。该集成结合了接受标准交叉熵训练的基线 PaSST 教师和“泛化专家”教师。该专家使用我们新颖的设备感知特征对齐 （DAFA） 损失进行培训，该损失改编自先前的工作，该损失明确构建了特征空间以实现设备鲁棒性。为了利用测试时设备标签的可用性，蒸馏的学生模型随后会经历最终的设备特定微调阶段。我们提出的系统在开发集上实现了 57.93% 的最终准确率，这表明比官方基线有了显着改进，特别是在看不见的设备上。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 08：48：48 UTC</p>
<h2 id="58-coatnext一种用于胃组织分类的注意力增强-convnextv2-transformer-混合模型-1"><a href="https://arxiv.org/abs/2509.09242"target="_blank" rel="external nofollow noopener noreferrer">#58</a> <a href="https://papers.cool/arxiv/2509.09242"target="_blank" rel="external nofollow noopener noreferrer">CoAtNeXt：一种用于胃组织分类的注意力增强 ConvNeXtV2-Transformer 混合模型</a> 1]</h2>
<p><strong>Authors</strong>: [Mustafa Yurdakul](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mustafa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mustafa</a> Yurdakul), [Sakir Tasdemir](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sakir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sakir</a> Tasdemir)</p>
<p>背景和目的胃病的早期诊断对于预防致命后果至关重要。尽管组织病理学检查仍然是诊断的金标准，但它完全是手动进行的，这使得评估需要大量劳动，并且容易在病理学家之间出现差异。可能会遗漏关键发现，并且缺乏标准程序会降低一致性。这些限制凸显了对自动化、可靠和高效的胃组织分析方法的需求。方法 本文提出一种名为CoAtNeXt的新型混合模型，用于胃组织图像的分类。该模型建立在 CoAtNet 架构之上，将其 MBConv 层替换为增强的 ConvNeXtV2 块。此外，还集成了卷积块注意力模块（CBAM），通过通道和空间注意力机制改进局部特征提取。该架构经过扩展，以实现计算效率和分类性能之间的平衡。CoAtNeXt 在两个公开可用的数据集上进行了评估，用于八类分类的 HMU-GC-HE-30K 和用于二元分类的 GasHisSDB，并与 10 个卷积神经网络 （CNN） 和 10 个视觉转换器 （ViT） 模型进行了比较。结果 CoAtNeXt在HMU-GC-HE-30K上实现了96.47%的准确率、96.60%的准确率、96.47%的召回率、96.45%的F1分数和99.89%的AUC。在GasHisSDB上，准确率达到98.29%，准确率98.07%，召回率98.41%，F1得分98.23%，AUC达到99.90%。它的性能优于所有测试的 CNN 和 ViT 模型，并超过了文献中之前的研究。结论 实验结果表明，CoAtNeXt是胃组织图像组织病理学分类的鲁棒架构，具有二分和多类性能。它凸显了其通过提高诊断准确性和减少工作量来帮助病理学家的潜力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 08：24：50 UTC</p>
<h2 id="59-用于骨植入物-3d-x-射线组织学的虚拟染色-2"><a href="https://arxiv.org/abs/2509.09235"target="_blank" rel="external nofollow noopener noreferrer">#59</a> <a href="https://papers.cool/arxiv/2509.09235"target="_blank" rel="external nofollow noopener noreferrer">用于骨植入物 3D X 射线组织学的虚拟染色</a> 2]</h2>
<p><strong>Authors</strong>: [Sarah C. Irvine](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sarah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sarah</a> C. Irvine), [Christian Lucas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christian</a> Lucas), [Diana Krüger](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Diana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Diana</a> Krüger), [Bianca Guedert](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bianca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bianca</a> Guedert), [Julian Moosmann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Julian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Julian</a> Moosmann), [Berit Zeller-Plumhoff](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Berit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Berit</a> Zeller-Plumhoff)</p>
<p>三维 X 射线组织学技术为传统 2D 组织学提供了一种非侵入性的替代方案，无需物理切片或化学染色即可对生物组织进行体积成像。然而，与传统的组织学染色相比，X 射线断层扫描固有的灰度图像对比度限制了其生化特异性。在数字病理学中，基于深度学习的虚拟染色已证明在模拟无标记光学图像的染色外观方面具有实用性。在这项研究中，我们通过应用跨模态图像翻译从基于同步辐射的显微CT扫描中生成人工染色切片，将虚拟染色扩展到X射线域。使用来自骨种植体样本的 50 多个共同注册的微型 CT 和甲苯胺蓝染色组织学图像对，我们训练了一个针对有限配对数据量身定制的修改后的 CycleGAN 网络。对整张载玻片组织学图像进行下采样以匹配 CT 数据的体素大小，并动态增强数据以进行基于补丁的训练。该模型结合了像素监督和灰度一致性项，产生组织学上逼真的颜色输出，同时保留高分辨率的结构细节。我们的方法在 SSIM、PSNR 和 LPIPS 指标上优于 Pix2Pix 和标准 CycleGAN 基线。训练后，该模型可以应用于完整的 CT 体积以生成虚拟染色的 3D 数据集，从而增强可解释性，而无需额外的样品制备。虽然能够重现新骨形成等特征，但种植体退化层描述的一些差异凸显了进一步训练数据和改进的必要性。这项工作将虚拟染色引入了 3D X 射线成像，并为生物医学研究中具有化学信息、无标记的组织表征提供了一条可扩展的途径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/physics.comp-ph"target="_blank" rel="external nofollow noopener noreferrer">计算物理学</a>, <a href="https://papers.cool/arxiv/q-bio.QM"target="_blank" rel="external nofollow noopener noreferrer">定量方法</a></p>
<p><strong>发布</strong>: 2025-09-11 08：14：31 UTC</p>
<h2 id="60-vejde基于因子图颜色细化的归纳深度强化学习框架-2"><a href="https://arxiv.org/abs/2509.09219"target="_blank" rel="external nofollow noopener noreferrer">#60</a> <a href="https://papers.cool/arxiv/2509.09219"target="_blank" rel="external nofollow noopener noreferrer">Vejde：基于因子图颜色细化的归纳深度强化学习框架</a> 2]</h2>
<p><strong>Authors</strong>: [Jakob Nyberg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jakob"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jakob</a> Nyberg), [Pontus Johnson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pontus"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pontus</a> Johnson)</p>
<p>我们展示和评估 Vejde;一个结合了数据抽象、图神经网络和强化学习的框架，为具有丰富结构状态的决策问题（例如对象类和关系）生成归纳策略函数。MDP 状态表示为有关实体的事实的数据库，Vejde 将每个状态转换为二分图，该图通过神经消息传递映射到潜在状态。状态和动作的因式表示使 Vejde 代理能够处理不同大小和结构的问题。我们在 RDDL 中定义的 8 个问题域上测试了 Vejde 代理，每个问题域有 10 个问题实例，其中策略使用监督学习和强化学习进行训练。为了测试策略泛化，我们将问题实例分为两组，一组用于训练，另一组仅用于测试。将Vejde代理的未见实例的测试结果与在每个问题实例上训练的MLP代理以及在线规划算法Prost进行了比较。我们的结果表明，Vejde 策略平均推广到测试实例，而没有显着的分数损失。此外，归纳代理在看不见的测试实例上获得了平均接近特定于实例的 MLP 代理的分数。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 07：51：38 UTC</p>
<h2 id="61-激励约束强化学习策略优化中的更安全行动-1"><a href="https://arxiv.org/abs/2509.09208"target="_blank" rel="external nofollow noopener noreferrer">#61</a> <a href="https://papers.cool/arxiv/2509.09208"target="_blank" rel="external nofollow noopener noreferrer">激励约束强化学习策略优化中的更安全行动</a> 1]</h2>
<p><strong>Authors</strong>: [Somnath Hazra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Somnath"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Somnath</a> Hazra), [Pallab Dasgupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pallab"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pallab</a> Dasgupta), [Soumyajit Dey](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soumyajit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soumyajit</a> Dey)</p>
<p>约束强化学习 （RL） 旨在最大限度地提高回报，同时遵守预定义的约束限制，这些约束限制代表了特定领域的安全要求。在学习代理管理系统作的连续控制环境中，平衡奖励最大化和约束满足之间的权衡仍然是一个重大挑战。策略优化方法通常在约束边界附近表现出不稳定性，导致训练性能欠佳。为了解决这个问题，我们引入了一种新方法，除了奖励结构之外，还集成了自适应激励机制，以便在接近约束边界之前保持在约束范围内。基于这一见解，我们提出了增量惩罚近端策略优化 （IP3O），这是一种实用的算法，可以强制执行逐渐增加的惩罚以稳定训练动态。通过对基准环境的实证评估，我们证明了 IP3O 与最先进的安全 RL 算法的性能相比的功效。此外，我们通过推导算法所实现的最优性的最坏情况误差的界限来提供理论保证。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 07：33：35 UTC</p>
<h2 id="62-善意的交叉测试揭示了音频深度伪造检测系统的弱点-21"><a href="https://arxiv.org/abs/2509.09204"target="_blank" rel="external nofollow noopener noreferrer">#62</a> <a href="https://papers.cool/arxiv/2509.09204"target="_blank" rel="external nofollow noopener noreferrer">善意的交叉测试揭示了音频深度伪造检测系统的弱点</a> 21]</h2>
<p><strong>Authors</strong>: [Chin Yuen Kwok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chin</a> Yuen Kwok), [Jia Qi Yip](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Qi Yip), [Zhen Qiu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhen</a> Qiu), [Chi Hung Chi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chi</a> Hung Chi), [Kwok Yan Lam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kwok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kwok</a> Yan Lam)</p>
<p>音频深度伪造检测 （ADD） 模型通常使用组合了多个合成器的数据集进行评估，性能报告为单个等错误率 （EER）。然而，这种方法不成比例地加权了具有更多样本的合成器，低估了其他样本的代表性，并降低了 EER 的整体可靠性。此外，大多数 ADD 数据集缺乏真实语音的多样性，通常具有单一的环境和语音风格（例如，干净的阅读语音），限制了它们模拟现实世界条件的能力。为了应对这些挑战，我们提出了善意交叉测试，这是一种新颖的评估框架，它结合了不同的善意数据集并聚合了 EER 以实现更平衡的评估。与传统评估方法相比，我们的方法提高了稳健性和可解释性。我们对九种真正语音类型的 150 多个合成器进行了基准测试，并发布了一个新数据集，以促进 <a href="https://github.com/cyaaronk/audio_deepfake_eval"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/cyaaronk/audio_deepfake_eval</a> 的进一步研究。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-11 07：20：18 UTC</p>
<h2 id="63-使用关键字感知成本函数改进上下文偏差模型的合成数据训练-2"><a href="https://arxiv.org/abs/2509.09197"target="_blank" rel="external nofollow noopener noreferrer">#63</a> <a href="https://papers.cool/arxiv/2509.09197"target="_blank" rel="external nofollow noopener noreferrer">使用关键字感知成本函数改进上下文偏差模型的合成数据训练</a> 2]</h2>
<p><strong>Authors</strong>: [Chin Yuen Kwok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chin</a> Yuen Kwok), [Jia Qi Yip](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Qi Yip), [Eng Siong Chng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eng</a> Siong Chng)</p>
<p>通过使 ASR 模型适应包含这些单词的合成数据，可以改进稀有词识别。可以通过上下文偏差来实现进一步的改进，上下文偏差训练并将偏差模块添加到模型架构中，以优先考虑稀有单词。虽然在合成稀有词数据上训练模块比使用非稀有词数据更有效，但由于合成音频中的伪影，它可能会导致过度拟合。为了解决这个问题，我们增强了基于TCPGen的上下文偏差方法，并提出了一个关键字感知损失函数，该函数在训练偏差模块时额外关注有偏差的单词。这种损失包括用于有偏见词预测的掩码交叉熵项和用于检测有偏见词位置的二元分类项。这两个术语互补地支持在推理过程中解码有偏见的单词。通过将 Whisper 适应 10 小时的合成数据，我们的方法将 NSC 第 2 部分测试集的单词错误率从 29.71% 降低到 11.81%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 07：12：17 UTC</p>
<h2 id="64-使用k步预测进行稀有词识别的基于三重的高效偏差-1"><a href="https://arxiv.org/abs/2509.09196"target="_blank" rel="external nofollow noopener noreferrer">#64</a> <a href="https://papers.cool/arxiv/2509.09196"target="_blank" rel="external nofollow noopener noreferrer">使用K步预测进行稀有词识别的基于三重的高效偏差</a> 1]</h2>
<p><strong>Authors</strong>: [Chin Yuen Kwok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chin</a> Yuen Kwok), [Jia Qi yip](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Qi yip)</p>
<p>上下文偏差通过在解码过程中优先考虑生僻字的输出来改进 ASR 模型的生僻字识别。一种常见的方法是基于 Trie 的偏差，它为部分假设（例如“Bon”）提供“奖励分数”，这可能导致生僻字（例如“Bonham”）的生成。如果完整的单词（“Bonham”）最终没有得到认可，系统将撤销那些早期的奖金。这种撤销仅限于波束搜索，并且计算成本很高，特别是对于具有大型解码器的模型。为了克服这些限制，我们建议调整 ASR 模型以展望未来并同时预测多个步骤。这通过更好地估计部分假设是否会导致生成完整的罕见词，完全避免了撤销步骤。通过仅使用10小时的合成数据对Whisper进行微调，我们的方法将NSC Part 2测试集的单词错误率从30.86%降低到12.19%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 07：11：46 UTC</p>
<h2 id="65-大语言模型与场景化编程融合提升软件可靠性-1"><a href="https://arxiv.org/abs/2509.09194"target="_blank" rel="external nofollow noopener noreferrer">#65</a> <a href="https://papers.cool/arxiv/2509.09194"target="_blank" rel="external nofollow noopener noreferrer">大语言模型与场景化编程融合提升软件可靠性</a> 1]</h2>
<p><strong>Authors</strong>: [Ayelet Berzack](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ayelet"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ayelet</a> Berzack), [Guy Katz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guy</a> Katz)</p>
<p>大型语言模型 （LLM） 正迅速成为软件开发人员不可或缺的工具，协助甚至与他们合作制定复杂的程序。优势是显而易见的——LLM 可以显着减少开发时间，生成组织良好且易于理解的代码，并且偶尔会提出开发人员自己可能无法构思的创新想法。然而，尽管法学硕士具有优势，但它们经常会引入重大错误，并以有说服力的信心呈现不正确的代码，从而可能误导开发人员接受有缺陷的解决方案。为了以更可靠的方式将法学硕士带入软件开发周期，我们提出了一种方法，以结构化的方式将它们与“传统”软件工程技术相结合，目标是简化开发流程，减少错误，并使用户能够更有信心地验证关键程序属性。具体来说，我们专注于基于场景的编程 （SBP） 范式——一种事件驱动、基于场景的软件工程方法——允许人类开发人员将他们的专业知识倾注到 LLM 中，并检查和验证其输出。为了评估我们的方法，我们进行了一项重要的案例研究，并使用它来设计和实现 Connect4 游戏。通过结合 LLM 和 SBP，我们能够创建一个功能强大的代理，它可以击败各种强大的现有代理。此外，在某些情况下，我们能够正式验证我们代理的正确性。最后，我们的经验揭示了关于我们所提议的方法的易用性的有趣见解。我们案例研究的完整代码将与本文的最终版本一起公开。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 07：10：25 UTC</p>
<h2 id="66-探测代码更改的预训练语言模型来自高置信度即时缺陷预测数据集-redef-的见解"><a href="https://arxiv.org/abs/2509.09192"target="_blank" rel="external nofollow noopener noreferrer">#66</a> <a href="https://papers.cool/arxiv/2509.09192"target="_blank" rel="external nofollow noopener noreferrer">探测代码更改的预训练语言模型：来自高置信度即时缺陷预测数据集 ReDef 的见解</a></h2>
<p><strong>Authors</strong>: [Doha Nam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Doha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Doha</a> Nam), [Taehyoun Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taehyoun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taehyoun</a> Kim), [Duksan Ryu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Duksan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Duksan</a> Ryu), [Jongmoon Baik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jongmoon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jongmoon</a> Baik)</p>
<p>即时软件缺陷预测 （JIT-SDP） 在代码审查和持续集成期间确定风险代码更改的优先级方面发挥着关键作用。然而，现有数据集经常存在标签嘈杂且识别错误提交精度低的问题。为了解决这个问题，我们提出了 ReDef（基于恢复的缺陷数据集），这是从 22 个大型 C/C++ 项目中策划的功能级修改的高置信度基准。有缺陷的案例由恢复提交锚定，而干净的案例则通过事后历史检查进行验证。通过涉及多次投票和审核的 GPT 辅助分类过程保守地过滤掉模棱两可的实例。该管道产生 3,164 个有缺陷的修改和 10,268 个干净的修改，提供比以前的现有资源更可靠的标签。除了数据集构建之外，我们还首次系统评估了预训练语言模型 （PLM） 如何推理代码修改——特别是哪些输入编码最有效地暴露更改信息，以及模型是否真正捕获了编辑语义。我们在五种编码策略下对 CodeBERT、CodeT5+ 和 UniXcoder 进行了微调，并通过交换添加/删除的块、反转差异极性或注入虚假标记的反事实扰动进一步探测它们的灵敏度。我们的结果表明，在所有 PLM 中，紧凑的差异样式编码始终优于全函数格式，统计测试证实了巨大的、与模型无关的影响。然而，在反事实测试下，性能几乎没有下降或根本没有下降——这表明看似稳健性实际上反映了对表面线索的依赖，而不是真正的语义理解。这些发现表明，与基于快照的任务不同，当前的 PLM 在真正理解代码修改的能力方面仍然有限。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 07：07：11 UTC</p>
<h2 id="67-dark-isp增强用于低光物体检测的raw图像处理-1"><a href="https://arxiv.org/abs/2509.09183"target="_blank" rel="external nofollow noopener noreferrer">#67</a> <a href="https://papers.cool/arxiv/2509.09183"target="_blank" rel="external nofollow noopener noreferrer">Dark-ISP：增强用于低光物体检测的RAW图像处理</a> 1]</h2>
<p><strong>Authors</strong>: [Jiasheng Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiasheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiasheng</a> Guo), [Xin Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Gao), [Yuxiang Yan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxiang</a> Yan), [Guanghao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guanghao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guanghao</a> Li), [Jian Pu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Pu)</p>
<p>弱光物体检测对于许多实际应用至关重要，但由于图像质量下降，仍然具有挑战性。虽然最近的研究表明，RAW图像比RGB图像具有更优越的潜力，但现有方法要么使用信息丢失的RAW-RGB图像，要么采用复杂的框架。为了解决这些问题，我们提出了一个轻量级和自适应的图像信号处理（ISP）插件Dark-ISP，它可以在黑暗环境中直接处理拜耳RAW图像，从而实现无缝的端到端目标检测训练。我们的主要创新是：（1） 我们将传统的 ISP 管道解构为顺序线性（传感器校准）和非线性（色调映射）子模块，将它们重铸为通过任务驱动的损耗优化的可微分组件。每个模块都配备了内容感知适应性和物理知情先验，可实现与检测目标一致的自动 RAW 到 RGB 转换。（2）通过利用ISP管道固有的级联结构，我们设计了一种促进子模块之间合作的Self-Boost机制。通过对三个 RAW 图像数据集的广泛实验，我们证明我们的方法优于最先进的基于 RGB 和 RAW 的检测方法，在具有挑战性的弱光环境中以最小的参数获得卓越的结果。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 06：44：43 UTC</p>
<h2 id="68-echox通过语音到语音法学硕士的回声训练来缓解声义差距-6"><a href="https://arxiv.org/abs/2509.09174"target="_blank" rel="external nofollow noopener noreferrer">#68</a> <a href="https://papers.cool/arxiv/2509.09174"target="_blank" rel="external nofollow noopener noreferrer">EchoX：通过语音到语音法学硕士的回声训练来缓解声义差距</a> 6]</h2>
<p><strong>Authors</strong>: [Yuhao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhao</a> Zhang), [Yuhao Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhao</a> Du), [Zhanchen Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhanchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhanchen</a> Dai), [Xiangnan Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiangnan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiangnan</a> Ma), [Kaiqi Kou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaiqi</a> Kou), [Benyou Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Benyou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Benyou</a> Wang), [Haizhou Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haizhou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haizhou</a> Li)</p>
<p>语音转语音大型语言模型（SLLM）越来越受到关注。SLLM 源自基于文本的大型语言模型 （LLM），经常表现出知识和推理能力的下降。我们假设出现这种限制是因为当前的 SLLM 训练范式未能弥合特征表示空间中的声学语义差距。为了解决这个问题，我们提出了 EchoX，它利用语义表示并动态生成语音训练目标。这种方法集成了声学和语义学习，使 EchoX 能够保持作为语音 LLM 的强大推理能力。实验结果表明，EchoX 拥有约 6000 小时的训练数据，在多个基于知识的问答基准测试中取得了先进的性能。该项目可在 <a href="https://github.com/FreedomIntelligence/EchoX"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/FreedomIntelligence/EchoX</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a></p>
<p><strong>发布</strong>: 2025-09-11 06：17：59 UTC</p>
<h2 id="69-语义通信中边缘变换器模型的自适应帕累托最优令牌合并"><a href="https://arxiv.org/abs/2509.09168"target="_blank" rel="external nofollow noopener noreferrer">#69</a> <a href="https://papers.cool/arxiv/2509.09168"target="_blank" rel="external nofollow noopener noreferrer">语义通信中边缘变换器模型的自适应帕累托最优令牌合并</a></h2>
<p><strong>Authors</strong>: [Omar Erak](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Omar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Omar</a> Erak), [Omar Alhussein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Omar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Omar</a> Alhussein), [Hatem Abou-Zeid](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hatem"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hatem</a> Abou-Zeid), [Mehdi Bennis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mehdi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mehdi</a> Bennis)</p>
<p>大规模变压器模型已成为语义通信系统的强大工具，使边缘设备能够提取丰富的表示，以跨嘈杂的无线信道进行稳健的推理。然而，它们巨大的计算需求仍然是在资源受限的 6G 网络中实际部署的主要障碍。在本文中，我们提出了一种在预训练视觉转换器中进行自适应令牌合并的免训练框架，以共同减少推理时间和传输资源使用。我们将每层合并比例的选择表述为一个多目标优化问题，以平衡精度和计算成本。我们采用基于高斯过程的贝叶斯优化来构建最优配置的帕累托前沿，从而能够灵活地适应动态应用需求和信道条件。广泛的实验表明，我们的方法始终优于其他基线，并显着减少了浮点运算，同时在广泛的信噪比 （SNR） 条件下保持了具有竞争力的精度。其他结果强调了自适应策略的有效性，这些策略根据信道质量调整合并积极性，提供了一种实用的机制来权衡延迟和语义保真度。这些发现为在未来的边缘智能系统中部署基于 Transformer 的语义通信建立了一种可扩展且高效的方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a></p>
<p><strong>发布</strong>: 2025-09-11 06：05：35 UTC</p>
<h2 id="70-具有反事实增强去偏差的面向目标的多模态情感分类"><a href="https://arxiv.org/abs/2509.09160"target="_blank" rel="external nofollow noopener noreferrer">#70</a> <a href="https://papers.cool/arxiv/2509.09160"target="_blank" rel="external nofollow noopener noreferrer">具有反事实增强去偏差的面向目标的多模态情感分类</a></h2>
<p><strong>Authors</strong>: [Zhiyue Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyue</a> Liu), [Fanrong Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fanrong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fanrong</a> Ma), [Xin Ling](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Ling)</p>
<p>面向目标的多模态情感分类旨在从图像-文本对中预测特定目标的情感极性。虽然现有作品取得了有竞争力的表现，但它们往往过度依赖文本内容，而没有考虑数据集偏差，特别是单词级上下文偏差。这会导致文本特征和输出标签之间出现虚假相关性，从而损害分类准确性。在本文中，我们引入了一种新的反事实增强去偏差框架来减少这种虚假相关性。我们的框架采用了一种反事实数据增强策略，该策略将与情感相关的因果特征改变到最低限度，生成细节匹配的图像文本样本，以指导模型对与情感相关的内容的关注。此外，为了从反事实数据中学习鲁棒特征并提示模型决策，我们引入了一种自适应去偏对比学习机制，有效减轻了偏见词的影响。在几个基准数据集上的实验结果表明，我们提出的方法优于最先进的基线。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 05：40：53 UTC</p>
<h2 id="71-基于知识的视觉问答的知识噪声缓解框架-1"><a href="https://arxiv.org/abs/2509.09159"target="_blank" rel="external nofollow noopener noreferrer">#71</a> <a href="https://papers.cool/arxiv/2509.09159"target="_blank" rel="external nofollow noopener noreferrer">基于知识的视觉问答的知识噪声缓解框架</a> 1]</h2>
<p><strong>Authors</strong>: [Zhiyue Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyue</a> Liu), [Sihang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sihang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sihang</a> Liu), [Jinyuan Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinyuan</a> Liu), [Xinru Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinru"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinru</a> Zhang)</p>
<p>基于知识的视觉问答 （KB-VQA） 需要模型来理解图像并利用外部知识来提供准确的答案。现有方法通常使用从知识源检索到的信息直接增强模型，而忽略了大量的知识冗余，这会给应答过程带来噪音。为了解决这个问题，我们提出了一个以知识为重点的 KB-VQA 的免培训框架，通过增强知识相关性和减少冗余来减轻噪声的影响。首先，对于知识检索，我们的框架从图像-问题对中得出重要部分，创建低噪声查询，从而增强高度相关知识的检索。考虑到检索到的知识中仍然存在冗余，然后我们提示大模型从知识中识别和提取有益于答案的片段。此外，我们还引入了一种选择性知识整合策略，允许模型仅在回答问题缺乏信心时才纳入知识，从而减轻冗余信息的影响。我们的框架能够获得准确和关键的知识，广泛的实验表明它优于最先进的方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 05：40：26 UTC</p>
<h2 id="72-hispaspoof西班牙语音取证的新数据集-1"><a href="https://arxiv.org/abs/2509.09155"target="_blank" rel="external nofollow noopener noreferrer">#72</a> <a href="https://papers.cool/arxiv/2509.09155"target="_blank" rel="external nofollow noopener noreferrer">HISPASpoof：西班牙语音取证的新数据集</a> 1]</h2>
<p><strong>Authors</strong>: [Maria Risques](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maria</a> Risques), [Kratika Bhagtani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kratika"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kratika</a> Bhagtani), [Amit Kumar Singh Yadav](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amit</a> Kumar Singh Yadav), [Edward J. Delp](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Edward"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Edward</a> J. Delp)</p>
<p>零样本语音克隆 （VC） 和文本转语音 （TTS） 方法发展迅速，能够生成高度逼真的合成语音，并引发了对其滥用的严重担忧。虽然已经开发了许多英语和中文检测器，但全球有超过 6 亿人使用的西班牙语在语音取证中的代表性仍然不足。为了弥补这一差距，我们推出了 HISPASpoof，这是第一个专为合成语音检测和归因而设计的大规模西班牙语数据集。它包括来自六种口音的公共语料库的真实语音，以及使用六个零样本 TTS 系统生成的合成语音。我们评估了五种代表性方法，表明用英语训练的检测器无法推广到西班牙语，而用 HISPASpoof 训练可以显着提高检测能力。我们还评估了 HISPASpoof 上的合成语音归因性能，即识别合成语音的生成方法。因此，HISPASpoof 为推进可靠和包容性的西班牙语语音取证提供了一个关键基准。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 05：29：07 UTC</p>
<h2 id="73-ocelot-2023细胞-组织相互作用挑战赛中的细胞检测"><a href="https://arxiv.org/abs/2509.09153"target="_blank" rel="external nofollow noopener noreferrer">#73</a> <a href="https://papers.cool/arxiv/2509.09153"target="_blank" rel="external nofollow noopener noreferrer">OCELOT 2023：细胞-组织相互作用挑战赛中的细胞检测</a></h2>
<p><strong>Authors</strong>: [JaeWoong Shin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=JaeWoong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=JaeWoong</a> Shin), [Jeongun Ryu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jeongun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jeongun</a> Ryu), [Aaron Valero Puche](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aaron"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aaron</a> Valero Puche), [Jinhee Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinhee"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinhee</a> Lee), [Biagio Brattoli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Biagio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Biagio</a> Brattoli), [Wonkyung Jung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wonkyung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wonkyung</a> Jung), [Soo Ick Cho](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soo</a> Ick Cho), [Kyunghyun Paeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyunghyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyunghyun</a> Paeng), [Chan-Young Ock](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chan-Young"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chan-Young</a> Ock), [Donggeun Yoo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Donggeun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Donggeun</a> Yoo), [Zhaoyang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaoyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaoyang</a> Li), [Wangkai Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wangkai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wangkai</a> Li), [Huayu Mai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huayu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huayu</a> Mai), [Joshua Millward](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joshua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joshua</a> Millward), [Zhen He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhen</a> He), [Aiden Nibali](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aiden"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aiden</a> Nibali), [Lydia Anette Schoenpflug](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lydia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lydia</a> Anette Schoenpflug), [Viktor Hendrik Koelzer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Viktor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Viktor</a> Hendrik Koelzer), [Xu Shuoyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xu</a> Shuoyu), [Ji Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ji</a> Zheng), [Hu Bin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hu</a> Bin), [Yu-Wen Lo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu-Wen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu-Wen</a> Lo), [Ching-Hui Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ching-Hui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ching-Hui</a> Yang), [Sérgio Pereira](<a href="https://arxiv.org/search/?searchtype=author&amp;query=S"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=S</a>érgio Pereira)</p>
<p>病理学家在检查全玻片图像时通常会在不同的放大倍率之间交替，使他们能够评估广泛的组织形态和复杂的细胞细节，从而形成全面的诊断。然而，现有的基于深度学习的细胞检测模型难以复制这些行为，也难以在不同放大倍率下学习结构之间的相互依赖的语义。该领域的一个关键障碍是缺乏具有多尺度重叠细胞和组织注释的数据集。OCELOT 2023 挑战赛的发起是为了收集社区的见解，以验证了解细胞和组织（细胞-组织）相互作用对于实现人类水平表现至关重要的假设，并加速该领域的研究。挑战数据集包括来自六个器官的重叠细胞检测和组织分割注释，包括来自 306 张带有苏木精和伊红染色的癌症基因组图谱 （TCGA） 全玻片图像的 673 对，分为训练、验证和测试子集。参与者展示了显着增强对细胞-组织关系的理解的模型。与不包含细胞-组织关系的基线纯细胞模型相比，顶级条目在测试集上的 F1 分数提高了 7.99。与传统的纯细胞检测方法相比，这是性能的显着改进，表明需要将多尺度语义纳入模型。本文对参与者使用的方法进行了比较分析，重点介绍了 OCELOT 2023 挑战赛中实施的创新策略。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 05：21：02 UTC</p>
<h2 id="74-视频理解设计数据集如何塑造架构和见解-2"><a href="https://arxiv.org/abs/2509.09151"target="_blank" rel="external nofollow noopener noreferrer">#74</a> <a href="https://papers.cool/arxiv/2509.09151"target="_blank" rel="external nofollow noopener noreferrer">视频理解设计：数据集如何塑造架构和见解</a> 2]</h2>
<p><strong>Authors</strong>: [Lei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lei</a> Wang), [Piotr Koniusz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Piotr"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Piotr</a> Koniusz), [Yongsheng Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yongsheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yongsheng</a> Gao)</p>
<p>在日益复杂的数据集和强大的架构的推动下，视频理解得到了迅速发展。然而，现有的调查主要按任务或系列对模型进行分类，而忽略了数据集指导架构演变的结构压力。这项调查是首次采用数据集驱动视角的调查，展示了运动复杂性、时间跨度、分层组成和多模态丰富性如何强加模型应编码的归纳偏差。我们重新解释里程碑，从双流和 3D CNN 到顺序、变压器和多模态基础模型，作为对这些数据集驱动压力的具体响应。在此综合的基础上，我们提供了实用的指导，以使模型设计与数据集不变性保持一致，同时平衡可扩展性和任务需求。通过将数据集、归纳偏差和架构统一到一个连贯的框架中，该调查为推进通用视频理解提供了全面的回顾和规范性路线图。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 05：06：30 UTC</p>
<h2 id="75-对象相似性在-3d-场景评估中捕获对象级保真度-31"><a href="https://arxiv.org/abs/2509.09143"target="_blank" rel="external nofollow noopener noreferrer">#75</a> <a href="https://papers.cool/arxiv/2509.09143"target="_blank" rel="external nofollow noopener noreferrer">对象相似性：在 3D 场景评估中捕获对象级保真度</a> 31]</h2>
<p><strong>Authors</strong>: [Yuiko Uchida](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuiko"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuiko</a> Uchida), [Ren Togo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ren"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ren</a> Togo), [Keisuke Maeda](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keisuke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keisuke</a> Maeda), [Takahiro Ogawa](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Takahiro"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Takahiro</a> Ogawa), [Miki Haseyama](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Miki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Miki</a> Haseyama)</p>
<p>本文提出了客体性模拟性（OSIM），这是一种针对3D场景的新型评估指标，明确关注“对象”，而“对象”是人类视觉感知的基本单位。现有指标评估整体图像质量，导致与人类感知存在差异。受神经心理学见解的启发，我们假设人类对 3D 场景的识别从根本上涉及对单个物体的关注。OSIM 通过利用对象检测模型及其特征表示来量化场景中每个对象的“客体性”，从而实现以对象为中心的评估。我们的用户研究表明，与现有指标相比，OSIM 更符合人类感知。我们还使用各种方法分析了 OSIM 的特性。此外，我们在标准化实验装置下重新评估了最近的 3D 重建和生成模型，以阐明该领域的进展。该代码可在 <a href="https://github.com/Objectness-Similarity/OSIM"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Objectness-Similarity/OSIM</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.GR"target="_blank" rel="external nofollow noopener noreferrer">图形</a></p>
<p><strong>发布</strong>: 2025-09-11 04：33：27 UTC</p>
<h2 id="76-viranker用于越南语重新排名的-bge-m3-和分块并联变压器交叉编码器"><a href="https://arxiv.org/abs/2509.09131"target="_blank" rel="external nofollow noopener noreferrer">#76</a> <a href="https://papers.cool/arxiv/2509.09131"target="_blank" rel="external nofollow noopener noreferrer">ViRanker：用于越南语重新排名的 BGE-M3 和分块并联变压器交叉编码器</a></h2>
<p><strong>Authors</strong>: [Phuong-Nam Dang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Phuong-Nam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Phuong-Nam</a> Dang), [Kieu-Linh Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kieu-Linh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kieu-Linh</a> Nguyen), [Thanh-Hieu Pham](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thanh-Hieu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thanh-Hieu</a> Pham)</p>
<p>本文介绍了 ViRanker，这是一种针对越南语量身定制的交叉编码器重新排序模型。ViRanker 基于 BGE-M3 编码器构建，并通过 Blockwise Parallel Transformer 进行增强，解决了越南语缺乏竞争性重新排序器的问题，越南语是一种具有复杂语法和变音符号的低资源语言。该模型在 8 GB 的精选语料库上进行了训练，并使用混合硬负采样进行了微调，以增强鲁棒性。在 MMARCO-VI 基准测试上进行评估，ViRanker 实现了强大的早期排名准确性，超越了多语言基线，并与 PhoRanker 展开了激烈的竞争。通过在 Hugging Face 上公开发布该模型，我们旨在支持可重复性并鼓励在现实世界的检索系统中更广泛地采用。除了越南语之外，这项研究还说明了仔细的架构调整和数据管理如何促进其他代表性不足的语言的重新排名。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 04：07：43 UTC</p>
<h2 id="77-使用生成式人工智能对导师对话行为进行自动分类使用-cima-语料库的案例研究-1"><a href="https://arxiv.org/abs/2509.09125"target="_blank" rel="external nofollow noopener noreferrer">#77</a> <a href="https://papers.cool/arxiv/2509.09125"target="_blank" rel="external nofollow noopener noreferrer">使用生成式人工智能对导师对话行为进行自动分类：使用 CIMA 语料库的案例研究</a> 1]</h2>
<p><strong>Authors</strong>: [Liqun He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liqun</a> He), [Jiaqi Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaqi</a> Xu)</p>
<p>本研究探讨了使用生成式人工智能对导师的对话行为（DA）进行自动分类，旨在减少传统手动编码所需的时间和精力。本案例研究使用开源 CIMA 语料库，其中导师的回答被预先注释为四个 DA 类别。GPT-3.5-turbo 和 GPT-4 模型都使用定制的提示进行了测试。结果显示，GPT-4 的准确率为 80%，加权 F1 得分为 0.81，Cohen&rsquo;s Kappa 为 0.74，超过了基线性能，并表明与人类注释基本一致。这些发现表明，生成式人工智能具有强大的潜力，可以提供一种高效且易于访问的 DA 分类方法，对教育对话分析具有有意义的影响。该研究还强调了特定于任务的标签定义和上下文信息在提高自动注释质量方面的重要性。最后，它强调了与使用生成式人工智能相关的道德考虑以及负责任和透明的研究实践的必要性。这项研究的脚本可在 <a href="https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/liqunhe27/Generative-AI-for-educational-dialogue-act-tagging</a> 公开获取。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 03：36：03 UTC</p>
<h2 id="78-字符级扰动破坏-llm-水印-31"><a href="https://arxiv.org/abs/2509.09112"target="_blank" rel="external nofollow noopener noreferrer">#78</a> <a href="https://papers.cool/arxiv/2509.09112"target="_blank" rel="external nofollow noopener noreferrer">字符级扰动破坏 LLM 水印</a> 31]</h2>
<p><strong>Authors</strong>: [Zhaoxi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaoxi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaoxi</a> Zhang), [Xiaomei Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaomei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaomei</a> Zhang), [Yanjun Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanjun</a> Zhang), [He Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=He"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=He</a> Zhang), [Shirui Pan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shirui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shirui</a> Pan), [Bo Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Liu), [Asif Qumer Gill](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Asif"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Asif</a> Qumer Gill), [Leo Yu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leo</a> Yu Zhang)</p>
<p>大型语言模型 （LLM） 水印将可检测的信号嵌入到生成的文本中，以保护版权、防止滥用和内容检测。虽然先前的研究使用水印去除攻击评估稳健性，但这些方法通常不是最优的，造成了一种误解，即有效的去除需要大的扰动或强大的对手。为了弥合这一差距，我们首先正式确定了 LLM 水印的系统模型，并表征了两个受限于对水印检测器的有限访问的现实威胁模型。然后，我们分析不同类型的扰动在其攻击范围内有何变化，即它们可以通过一次编辑影响的标记数量。我们观察到，字符级扰动（例如，拼写错误、交换、删除、同形文字）可以通过破坏标记化过程来同时影响多个标记。我们证明，在限制性最强的威胁模型下，字符级扰动对于水印去除明显更有效。我们进一步提出了基于遗传算法（GA）的引导删除攻击，该算法使用参考检测器进行优化。在对水印检测器进行有限黑盒查询的实际威胁模型下，该方法表现出较强的去除性能。实验证实了字符级扰动的优越性以及GA在现实约束下去除水印的有效性。此外，我们认为在考虑潜在防御时存在一个对抗性困境：任何固定防御都可以被合适的扰动策略绕过。在此原则的推动下，我们提出了一种自适应复合字符级攻击。实验结果表明，该方法能够有效攻破防御。我们的研究结果强调了现有 LLM 水印方案中的重大漏洞，并强调了开发新的稳健机制的紧迫性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 02：50：07 UTC</p>
<h2 id="79-dp-fedlora面向端端大型语言模型的隐私增强型联邦微调"><a href="https://arxiv.org/abs/2509.09097"target="_blank" rel="external nofollow noopener noreferrer">#79</a> <a href="https://papers.cool/arxiv/2509.09097"target="_blank" rel="external nofollow noopener noreferrer">DP-FedLoRA：面向端端大型语言模型的隐私增强型联邦微调</a></h2>
<p><strong>Authors</strong>: [Honghui Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Honghui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Honghui</a> Xu), [Shiva Shrestha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiva"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiva</a> Shrestha), [Wei Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Chen), [Zhiyuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyuan</a> Li), [Zhipeng Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhipeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhipeng</a> Cai)</p>
<p>随着设备上大型语言模型 （LLM） 系统变得越来越普遍，联合微调可以直接在边缘设备上实现高级语言理解和生成;然而，它还涉及处理敏感的、特定于用户的数据，在联合学习框架内引发了重大的隐私问题。为了应对这些挑战，我们提出了 DP-FedLoRA，这是一种隐私增强的联合微调框架，它将基于 LoRA 的适应与通信高效的环境中的差分隐私集成在一起。每个客户端使用高斯噪声在本地裁剪和扰动其 LoRA 矩阵，以满足 （ϵ, δ）-差分隐私。我们进一步提供了理论分析，证明了更新的无偏性，并推导出了噪声引入的方差界限，为隐私预算校准提供了实用指导。主流基准测试的实验结果表明，DP-FedLoRA 提供具有竞争力的性能，同时提供强大的隐私保证，为在设备上环境中部署可扩展和保护隐私的 LLM 铺平了道路。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 02：16：34 UTC</p>
<h2 id="80-通过双重隐私保护实现保密和高效的-llm-推理"><a href="https://arxiv.org/abs/2509.09091"target="_blank" rel="external nofollow noopener noreferrer">#80</a> <a href="https://papers.cool/arxiv/2509.09091"target="_blank" rel="external nofollow noopener noreferrer">通过双重隐私保护实现保密和高效的 LLM 推理</a></h2>
<p><strong>Authors</strong>: [Honglan Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Honglan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Honglan</a> Yu), [Yibin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yibin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yibin</a> Wang), [Feifei Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feifei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feifei</a> Dai), [Dong Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Liu), [Haihui Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haihui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haihui</a> Fan), [Xiaoyan Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoyan</a> Gu)</p>
<p>基于 CPU 的可信执行环境 （TEE） 和差分隐私 （DP） 在私有推理方面获得了广泛的应用。由于 TEE 中的推理延迟较高，研究人员使用基于分区的方法将线性模型组件卸载到 GPU。然而，大型语言模型 （LLM） 的密集非线性层会导致 TEE 和 GPU 之间的通信开销很大。基于 DP 的方法应用随机噪声来保护数据隐私，但这会损害 LLM 的性能和语义理解。为了克服上述缺点，本文提出了 CMIF，这是一个保密且高效的模型推理框架。CMIF 将嵌入层秘密部署在客户端 TEE 和 GPU 服务器上的后续层中。同时，它优化了 Report-Noisy-Max 机制，以保护敏感输入，同时略有降低模型性能。对 Llama 系列模型的广泛实验表明，CMIF 减少了 TEE 中的额外推理开销，同时保护了用户数据隐私。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 01：54：13 UTC</p>
<h2 id="81-sqap-vla用于高性能视觉-语言-动作模型的协同量化感知修剪框架-21"><a href="https://arxiv.org/abs/2509.09090"target="_blank" rel="external nofollow noopener noreferrer">#81</a> <a href="https://papers.cool/arxiv/2509.09090"target="_blank" rel="external nofollow noopener noreferrer">SQAP-VLA：用于高性能视觉-语言-动作模型的协同量化感知修剪框架</a> 21]</h2>
<p><strong>Authors</strong>: [Hengyu Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hengyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hengyu</a> Fang), [Yijiang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yijiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yijiang</a> Liu), [Yuan Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Du), [Li Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Li"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Li</a> Du), [Huanrui Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huanrui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huanrui</a> Yang)</p>
<p>视觉-语言-行动 （VLA） 模型在具身智能方面表现出前所未有的能力。然而，它们巨大的计算和内存成本阻碍了它们的实际部署。现有的 VLA 压缩和加速方法以临时方式进行量化或标记修剪，但由于观察到的不兼容，无法同时实现整体效率改进。这项工作介绍了 SQAP-VLA，这是第一个结构化的、免训练的 VLA 推理加速框架，可同时实现最先进的量化和标记修剪。我们通过共同设计量化和标记修剪管道来克服不兼容性，其中我们提出了新的量化感知标记修剪标准，这些标准适用于积极量化模型，同时改进量化器设计以提高修剪效果。当应用于标准 VLA 模型时，SQAP-VLA 在计算效率和推理速度方面取得了显着的提升，同时成功地保留了核心模型的性能，实现了 ×与原始模型相比，速度提高了 1.93，平均成功率提高了 4.5%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 01：52：25 UTC</p>
<h2 id="82-koopmotion学习几乎无发散的-koopman-流场以进行运动规划"><a href="https://arxiv.org/abs/2509.09074"target="_blank" rel="external nofollow noopener noreferrer">#82</a> <a href="https://papers.cool/arxiv/2509.09074"target="_blank" rel="external nofollow noopener noreferrer">KoopMotion：学习几乎无发散的 Koopman 流场以进行运动规划</a></h2>
<p><strong>Authors</strong>: [Alice Kate Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alice"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alice</a> Kate Li), [Thales C Silva](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thales"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thales</a> C Silva), [Victoria Edwards](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Victoria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Victoria</a> Edwards), [Vijay Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vijay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vijay</a> Kumar), [M. Ani Hsieh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=M"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=M</a>. Ani Hsieh)</p>
<p>在这项工作中，我们提出了一种基于流场的新型运动规划方法，该方法将机器人从任何初始状态驱动到所需的参考轨迹，使其收敛到轨迹的终点。尽管在使用库夫曼算子理论对动力系统进行建模方面被证明是有效的，但库夫曼本质上并没有强制收敛到所需的轨迹或特定目标——这是从演示 （LfD） 中学习时的要求。我们提出了 KoopMotion，它将运动流场表示为动力系统，由 Koopman 算子参数化以模拟所需的轨迹，并利用学习到的流场的发散特性来获得平滑的运动场，当机器人远离所需轨迹时，这些运动场会收敛到所需的参考轨迹，并跟踪轨迹直到终点。为了证明我们方法的有效性，我们展示了 KoopMotion 在 LASA 人类手写数据集和 3D 机械手末端执行器轨迹数据集（包括光谱分析）上的评估。我们还在物理机器人上进行了实验，在非静态流体流动环境中运行的微型自主地面车辆上验证了 KoopMotion。我们的方法在空间和时间上都具有很高的样本效率，只需要 3% 的 LASA 数据集即可生成密集运动计划。此外，在比较衡量空间和时间动态建模功效的指标时，KoopMotion 比基线有了显着改进。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 00：42：01 UTC</p>
<h2 id="83-stride通过无子集函数分解实现可扩展和可解释的xai-1"><a href="https://arxiv.org/abs/2509.09070"target="_blank" rel="external nofollow noopener noreferrer">#83</a> <a href="https://papers.cool/arxiv/2509.09070"target="_blank" rel="external nofollow noopener noreferrer">STRIDE：通过无子集函数分解实现可扩展和可解释的XAI</a> 1]</h2>
<p><strong>Author</strong>: [Chaeyun Ko](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chaeyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chaeyun</a> Ko)</p>
<p>大多数可解释人工智能 （XAI） 框架都面临着两个实际限制：对特征子集进行推理的指数成本以及将效应总结为单个标量值的表现力降低。我们提出了 STRIDE，这是一个可扩展的框架，旨在通过将解释框架为复制核希尔伯特空间 （RKHS） 中无子集枚举的正交泛函分解来缓解这两个问题。STRIDE 不是只关注标量归因，而是通过基于递归内核中心过程的分析投影方案计算函数组件f_S（x_S），避免显式子集枚举。在我们研究的表格设置中，该方法与模型无关，提供局部和全局视图，并得到既定假设下正交性和 L^2 收敛的理论结果的支持。在我们环境中的公共表格基准测试中，我们观察到加速范围从 0.6 倍（在小型数据集上比 TreeSHAP 慢）到 9.7 倍（加利福尼亚），10 个数据集的中位数约为 3.0 倍，同时保持高保真度（R^2 在 0.81 和 0.999 之间）和大多数数据集的实质性排名一致性。总体而言，STRIDE 通过提供结构化的功能视角来补充标量归因方法，使“组件手术”等新型诊断能够定量测量我们实验范围内特定相互作用的影响。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-11 00：19：53 UTC</p>
<h2 id="84-使用-sft-和-dpo-提高-llm-的安全性和实用性opt-350m-研究-17"><a href="https://arxiv.org/abs/2509.09055"target="_blank" rel="external nofollow noopener noreferrer">#84</a> <a href="https://papers.cool/arxiv/2509.09055"target="_blank" rel="external nofollow noopener noreferrer">使用 SFT 和 DPO 提高 LLM 的安全性和实用性：OPT-350M 研究</a> 17]</h2>
<p><strong>Author</strong>: [Piyush Pant](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Piyush"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Piyush</a> Pant)</p>
<p>本研究调查了对齐技术、监督微调 （SFT）、直接偏好优化 （DPO） 和 SFT+DPO 组合方法在提高 OPT-350M 语言模型的安全性和有用性方面的有效性。利用 Anthropic Helpful-Harmless RLHF 数据集，我们训练和评估了四个模型：基础OPT350M、SFT 模型、DPO 模型以及同时使用 SFT 和 DPO 训练的模型。我们引入了三个关键的评估指标：无害率 （HmR）、帮助率 （HpR） 和组合对齐分数 （CAS），所有这些都来自奖励模型输出。结果表明，虽然SFT优于DPO，但组合SFT+DPO模型在所有指标上都优于所有其他模型，证明了这些技术的互补性。我们的研究结果还强调了噪声数据、有限的 GPU 资源和训练限制带来的挑战。本研究全面了解了微调策略如何影响模型对齐，并为未来工作中更强大的对齐管道奠定了基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-10 23：22：59 UTC</p>
<h2 id="85-机器学习在电力系统保护和干扰管理中的应用范围界定综述-1"><a href="https://arxiv.org/abs/2509.09053"target="_blank" rel="external nofollow noopener noreferrer">#85</a> <a href="https://papers.cool/arxiv/2509.09053"target="_blank" rel="external nofollow noopener noreferrer">机器学习在电力系统保护和干扰管理中的应用范围界定综述</a> 1]</h2>
<p><strong>Authors</strong>: [Julian Oelhaf](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Julian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Julian</a> Oelhaf), [Georg Kordowich](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Georg"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Georg</a> Kordowich), [Mehran Pashaei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mehran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mehran</a> Pashaei), [Christian Bergler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christian</a> Bergler), [Andreas Maier](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andreas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andreas</a> Maier), [Johann Jäger](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Johann"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Johann</a> Jäger), [Siming Bayer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siming</a> Bayer)</p>
<p>可再生能源和分布式能源的整合重塑了现代电力系统，挑战了传统的保护方案。本范围界定综述综合了有关机器学习 （ML） 在电力系统保护和干扰管理中的应用的最新文献，遵循 PRISMA for Scoping Reviews 框架。根据 100 多篇出版物，解决了三个关键目标：（i） 评估保护任务中机器学习研究的范围;（ii） 评估不同运营场景中的机器学习性能;（iii） 确定适合不断变化的电网条件的方法。机器学习模型通常在模拟数据集上表现出高精度;然而，它们在现实条件下的性能仍未得到充分验证。现有文献支离破碎，在方法论严谨性、数据集质量和评估指标方面存在不一致。缺乏标准化阻碍了结果的可比性，并限制了研究结果的普遍性。为了应对这些挑战，本综述为保护任务引入了面向机器学习的分类法，解决了关键术语不一致问题，并倡导标准化报告实践。它进一步为全面的数据集文档、方法学透明度和一致的评估协议提供了指导，旨在提高可重复性并增强研究成果的实际相关性。仍然存在关键差距，包括缺乏实际验证、鲁棒性测试不足以及对部署可行性的考虑有限。未来的研究应优先考虑公共基准数据集、现实的验证方法和先进的机器学习架构。这些步骤对于将基于机器学习的保护从理论上的承诺转变为在日益动态和分散的电力系统中的实际部署至关重要。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a></p>
<p><strong>发布</strong>: 2025-09-10 23：19：28 UTC</p>
<h2 id="86-mowe天气专家的混合体-22"><a href="https://arxiv.org/abs/2509.09052"target="_blank" rel="external nofollow noopener noreferrer">#86</a> <a href="https://papers.cool/arxiv/2509.09052"target="_blank" rel="external nofollow noopener noreferrer">MoWE：天气专家的混合体</a> 22]</h2>
<p><strong>Authors</strong>: [Dibyajyoti Chakraborty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dibyajyoti"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dibyajyoti</a> Chakraborty), [Romit Maulik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Romit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Romit</a> Maulik), [Peter Harrington](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peter"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peter</a> Harrington), [Dallas Foster](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dallas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dallas</a> Foster), [Mohammad Amin Nabian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohammad</a> Amin Nabian), [Sanjay Choudhry](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sanjay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sanjay</a> Choudhry)</p>
<p>数据驱动的天气模型最近取得了最先进的性能，但近年来进展趋于稳定。本文引入了一种专家混合 （MoWE） 方法作为克服这些限制的新范式，不是通过创建新的预报器，而是通过优化组合现有模型的输出。MoWE 模型的训练计算资源明显低于单个专家。我们的模型采用基于 Vision Transformer 的门控网络，该网络动态学习对每个网格点的多个“专家”模型的贡献进行加权，并以预测提前期为条件。这种方法创建了一个综合的确定性预测，就均方根误差 （RMSE） 而言，它比任何单个组件都更准确。我们的结果证明了这种方法的有效性，在 2 天的预报范围内，RMSE 比表现最好的 AI 天气模型低 10%，显着优于个别专家以及专家之间的简单平均值。这项工作提出了一种计算高效且可扩展的策略，通过充分利用领先的高质量预报模型来推动数据驱动天气预报的最新技术。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/physics.ao-ph"target="_blank" rel="external nofollow noopener noreferrer">大气和海洋物理学</a>, <a href="https://papers.cool/arxiv/physics.geo-ph"target="_blank" rel="external nofollow noopener noreferrer">地球物理学</a></p>
<p><strong>发布</strong>: 2025-09-10 23：15：59 UTC</p>
<h2 id="87-陈述的互动和持续参与偏好-spice评估法学硕士重新参与对话的意愿-2"><a href="https://arxiv.org/abs/2509.09043"target="_blank" rel="external nofollow noopener noreferrer">#87</a> <a href="https://papers.cool/arxiv/2509.09043"target="_blank" rel="external nofollow noopener noreferrer">陈述的互动和持续参与偏好 （SPICE）：评估法学硕士重新参与对话的意愿</a> 2]</h2>
<p><strong>Authors</strong>: [Thomas Manuel Rost](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Manuel Rost), [Martina Figlia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Martina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Martina</a> Figlia), [Bernd Wallraff](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bernd"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bernd</a> Wallraff)</p>
<p>我们引入并评估了交互和持续参与的陈述偏好 （SPICE），这是一种简单的诊断信号，通过向大型语言模型询问其在查看简短成绩单后是否愿意重新参与用户行为的问题而引发。在一项使用 3 音（友好、不清楚、辱骂）x 10 次互动刺激集的研究中，我们在四种框架条件下测试了四个开放权重聊天模型，结果进行了 480 次试验。我们的研究结果表明，SPICE 通过用户语气进行敏锐的区分。友好互动几乎一致倾向于继续（97.5% 是），而辱骂互动则强烈倾向于停止（17.9% 是），不明确的互动介于两者之间（60.4% 是）。这种核心关联在多种依赖感知统计检验（包括 Rao-Scott 调整和聚类排列检验）下仍然具有决定性作用。此外，我们证明 SPICE 提供了与滥用分类不同的信号。在模型未能识别滥用行为的试验中，它仍然绝大多数表示倾向于不继续互动（81% 的时间）。探索性分析还揭示了显着的交互效应：描述研究背景的序言在歧义下会显着影响 SPICE，但前提是文字记录以单个文本块而不是多轮聊天的形式呈现。结果验证了 SPICE 是一种强大、低开销且可重复的模型配置工具，通过提供模型状态的直接关系信号来补充现有指标。发布所有激励、代码和分析脚本以支持复制。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-10 22：34：17 UTC</p>
<h2 id="88-无羡慕但仍然不公平个性化推荐中最多一个项目-ef-1-无羡慕-1"><a href="https://arxiv.org/abs/2509.09037"target="_blank" rel="external nofollow noopener noreferrer">#88</a> <a href="https://papers.cool/arxiv/2509.09037"target="_blank" rel="external nofollow noopener noreferrer">无羡慕但仍然不公平：个性化推荐中最多一个项目 （EF-1） 无羡慕</a> 1]</h2>
<p><strong>Authors</strong>: [Amanda Aird](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amanda"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amanda</a> Aird), [Ben Armstrong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ben"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ben</a> Armstrong), [Nicholas Mattei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicholas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicholas</a> Mattei), [Robin Burke](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Robin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Robin</a> Burke)</p>
<p>自 1960 年代以来，无嫉妒和放宽到最多一个项目 （EF-1） 的无嫉妒已被用作经济学、博弈论和社会选择文献中的公平概念，并且最近在推荐系统社区中越来越受欢迎。在这份简短的立场文件中，我们将概述无嫉妒及其在经济学和推荐系统中的应用;并说明为什么嫉妒不适合在个性化发挥作用的环境中衡量使用的公平性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-10 22：13：13 UTC</p>
<h2 id="89-通过深度自适应时空建模和稀疏数据进行个性化睡眠预测-2"><a href="https://arxiv.org/abs/2509.09018"target="_blank" rel="external nofollow noopener noreferrer">#89</a> <a href="https://papers.cool/arxiv/2509.09018"target="_blank" rel="external nofollow noopener noreferrer">通过深度自适应时空建模和稀疏数据进行个性化睡眠预测</a> 2]</h2>
<p><strong>Authors</strong>: [Xueyi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xueyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xueyi</a> Wang), [C. J. C.](<a href="https://arxiv.org/search/?searchtype=author&amp;query=C"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=C</a>. J. C.), <a href="https://arxiv.org/search/?searchtype=author&amp;query=Lamoth"target="_blank" rel="external nofollow noopener noreferrer">Lamoth</a>, [Elisabeth Wilhelm](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Elisabeth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Elisabeth</a> Wilhelm)</p>
<p>睡眠预测使个人和医疗保健提供者能够预测并主动解决影响安宁休息的因素，最终改善身心健康。这项工作提出了一种用于预测睡眠分数的自适应空间和时间模型 （AdaST-Sleep）。我们提出的模型结合了卷积层来捕获多个特征和循环神经网络层之间的空间特征交互，以处理更长期的时间健康相关数据。进一步集成了领域分类器以在不同主题之间进行推广。我们使用五个输入窗口大小（3、5、7、9、11 天）和五个预测窗口大小（1、3、5、7、9 天）进行了几个实验。我们的方法始终优于四个基线模型，在 7 天输入窗口和 1 天预测窗口下实现了最低的 RMSE （0.282）。此外，即使在预测未来多天时，该方法也能保持强劲的性能，展示了其在实际应用中的多功能性。视觉比较表明，该模型准确地跟踪了整体睡眠分数水平和每日波动。这些发现证明，所提出的框架使用来自商业可穿戴设备的稀疏数据和领域适应技术为个性化睡眠预测提供了一个强大且适应性强的解决方案。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-08-27 22：36：00 世界标准时间</p>
<h2 id="90-视觉语言模型可以求解视觉数学方程吗-33"><a href="https://arxiv.org/abs/2509.09013"target="_blank" rel="external nofollow noopener noreferrer">#90</a> <a href="https://papers.cool/arxiv/2509.09013"target="_blank" rel="external nofollow noopener noreferrer">视觉语言模型可以求解视觉数学方程吗？</a> 33]</h2>
<p><strong>Authors</strong>: [Monjoy Narayan Choudhury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Monjoy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Monjoy</a> Narayan Choudhury), [Junling Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junling"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junling</a> Wang), [Yifan Hou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yifan</a> Hou), [Mrinmaya Sachan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mrinmaya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mrinmaya</a> Sachan)</p>
<p>尽管视觉语言模型 （VLM） 在视觉理解和基于语言的推理方面表现出色，但在需要综合感知和符号计算的任务中仍存在困难。我们通过视觉方程求解来研究这一局限性，其中数学方程嵌入图像中，变量由对象图标表示，系数必须通过计数推断。虽然 VLM 在文本方程上表现良好，但在视觉上接地的对应方程上却失败了。为了理解这一差距，我们将任务分解为系数计数和变量识别，发现计数是主要瓶颈，即使识别准确。我们还观察到，组合识别和推理会引入额外的错误，凸显了多步骤视觉推理的挑战。最后，随着方程复杂性的增加，符号推理本身成为限制因素。这些发现揭示了当前 VLM 的主要弱点，并指出了未来视觉基础数学推理的改进。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-10 21：16：11 UTC</p>
<h2 id="91-open-sci-ref-001用于语言模型和数据集比较的开放且可重复的参考基线-13"><a href="https://arxiv.org/abs/2509.09009"target="_blank" rel="external nofollow noopener noreferrer">#91</a> <a href="https://papers.cool/arxiv/2509.09009"target="_blank" rel="external nofollow noopener noreferrer">Open-sci-ref-0.01：用于语言模型和数据集比较的开放且可重复的参考基线</a> 13]</h2>
<p><strong>Authors</strong>: [Marianna Nezhurina](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marianna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marianna</a> Nezhurina), [Taishi Nakamura](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taishi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taishi</a> Nakamura), [Timur Carstensen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Timur"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Timur</a> Carstensen), [Niccolò Ajroldi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Niccol"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Niccol</a>ò Ajroldi), [Ville Komulainen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ville"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ville</a> Komulainen), [David Salinas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Salinas), [Jenia Jitsev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jenia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jenia</a> Jitsev)</p>
<p>我们介绍了 open-sci-ref 系列密集的 transformer 模型，在 8 个最近的开放参考数据集上作为跨多个模型（0.13B 至 1.7B 参数）和标记尺度（高达 1T）的研究基线进行训练。我们的训练运行集在各种标准化基准上评估模型，建立了参考点，使研究人员能够跨规模和数据集评估替代训练方法的健全性和质量。中间检查点允许比较和研究训练动态。建立的参考基线允许通过其扩展趋势来比较训练过程，并将它们调整在公共计算轴上。对开放参考数据集的比较表明，在 NemoTron-CC HQ 上的训练始终优于其他参考数据集，其次是 DCLM-baseline 和 FineWeb-Edu。除了中间训练检查点外，该版本还包括日志、代码和下游评估，以简化复制、标准化比较并促进未来的研究。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-10 21：13：34 UTC</p>
<h2 id="92-心肌内运动和应变的隐性神经表征-1"><a href="https://arxiv.org/abs/2509.09004"target="_blank" rel="external nofollow noopener noreferrer">#92</a> <a href="https://papers.cool/arxiv/2509.09004"target="_blank" rel="external nofollow noopener noreferrer">心肌内运动和应变的隐性神经表征</a> 1]</h2>
<p><strong>Authors</strong>: [Andrew Bell](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> Bell), [Yan Kit Choi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yan</a> Kit Choi), [Steffen Peterson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Steffen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Steffen</a> Peterson), [Andrew King](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> King), [Muhummad Sohaib Nazir](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhummad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhummad</a> Sohaib Nazir), [Alistair Young](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alistair"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alistair</a> Young)</p>
<p>通过标记 MRI 自动量化心肌内运动和应变仍然是一项重要但具有挑战性的任务。我们提出了一种使用隐式神经表征 （INR） 的方法，以学习到的潜在代码为条件，来预测连续的左心室 （LV） 位移——不需要推理时间优化。在 452 个英国生物样本库测试用例中进行了评估，与三个深度学习基线相比，我们的方法实现了最佳的跟踪精度 （2.14 mm RMSE） 和全球圆周应变 （2.86%） 和径向应变 （6.42%） 的最低组合误差。此外，我们的方法是 ∼380× 比最准确的基线更快。这些结果凸显了基于INR的模型在大型CMR数据集中对心肌应变进行准确和可扩展分析的适用性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-10 21：05：27 UTC</p>
<h2 id="93-基于相似性的异常值检测用于使用β混合进行噪声对象重新识别-2"><a href="https://arxiv.org/abs/2509.08926"target="_blank" rel="external nofollow noopener noreferrer">#93</a> <a href="https://papers.cool/arxiv/2509.08926"target="_blank" rel="external nofollow noopener noreferrer">基于相似性的异常值检测，用于使用β混合进行噪声对象重新识别</a> 2]</h2>
<p><strong>Authors</strong>: [Waqar Ahmad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Waqar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Waqar</a> Ahmad), [Evan Murphy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Evan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Evan</a> Murphy), [Vladimir A. Krylov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vladimir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vladimir</a> A. Krylov)</p>
<p>对象重新识别 （Re-ID） 方法对标签噪声高度敏感，这通常会导致性能显着下降。我们通过将 Re-ID 重新定义为监督图像相似性任务并采用经过训练以捕获判别性成对关系的暹罗网络架构来应对这一挑战。我们方法的核心是一种新的统计异常值检测 （OD） 框架，称为 Beta-SOD（基于 Beta 混合相似性的异常值检测），它使用双组分 Beta 分布混合模型对嵌入对之间的余弦相似性分布进行建模。我们为两种 Beta 分布的混合建立了一种新的可识别性结果，确保我们的学习任务处于适当的位置。所提出的OD步骤补充了Re-ID架构，该架构结合了二元交叉熵、对比和余弦嵌入损失，共同优化了特征级相似性学习。我们证明了 Beta-SOD 在 CUHK03 和 Market-1501 数据集上对人员 Re-ID 进行去噪和 Re-ID 任务以及在 VeRi-776 数据集上对车辆 Re-ID 任务的有效性。与最先进的方法相比，我们的方法在各种噪声水平 （10-30%） 下表现出卓越的性能，在嘈杂的 Re-ID 场景中表现出稳健性和广泛的适用性。Beta-SOD 的实现可在以下网址获得：https://github.com/waqar3411/Beta-SOD</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/math.ST"target="_blank" rel="external nofollow noopener noreferrer">统计理论</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-10 18：42：19 UTC</p>
<h2 id="94-实例最优矩阵乘法权重更新及其量子应用-2"><a href="https://arxiv.org/abs/2509.08911"target="_blank" rel="external nofollow noopener noreferrer">#94</a> <a href="https://papers.cool/arxiv/2509.08911"target="_blank" rel="external nofollow noopener noreferrer">实例最优矩阵乘法权重更新及其量子应用</a> 2]</h2>
<p><strong>Authors</strong>: [Weiyuan Gong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiyuan</a> Gong), [Tongyang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tongyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tongyang</a> Li), [Xinzhao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinzhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinzhao</a> Wang), [Zhiyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyu</a> Zhang)</p>
<p>矩阵乘法权重更新 （MMWU） 是一种具有广泛应用的开创性在线学习算法。应用于矩阵版的专家建议学习（LEA）问题 d-维谱，众所周知，MMWU 达到 O(Tlogd−−−−−√)哪里 T 是时间范围。在本文中，我们提出了一种改进的算法，该算法实现了O(T⋅S(X||d−1Id)−−−−−−−−−−−−√)哪里 X 是遗憾中的比较，Id 是恒等矩阵，并且S(⋅||⋅) 表示量子相对熵。此外，我们的算法具有与 MMWU 相同的计算复杂度，表明后悔界限的改进是“免费的”。从技术上讲，我们首先为矩阵 LEA 开发了一个基于一般势的框架，其中 MMWU 是由标准指数势诱导的特例。然后，我们分析的关键是建立在拉普拉斯变换技术之上的新的“单侧”詹森迹线不等式，该技术允许将指数之外的一般势函数应用于矩阵 LEA。我们的算法最终由基于虚误差函数的向量LEA问题的最优势函数推导出来。作为上述内容的补充，我们提供了矩阵LEA的内存下界，并探讨了我们的算法在量子学习理论中的应用。我们表明，它在学习被去极化噪声、随机量子态和吉布斯态破坏的量子态方面优于最先进的技术。此外，将我们的算法应用于线性凸损耗可以预测非线性量子特性，例如纯度、量子虚冷却和 Rényi-2 相关。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.DS"target="_blank" rel="external nofollow noopener noreferrer">数据结构和算法</a>, <a href="https://papers.cool/arxiv/quant-ph"target="_blank" rel="external nofollow noopener noreferrer">量子物理学</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-10 18：15：41 UTC</p>
<h2 id="95-promptguard一个精心编排的提示框架用于使用具有增强安全性公平性和可控性的法学硕士为弱势群体生成有原则的合成文本-2"><a href="https://arxiv.org/abs/2509.08910"target="_blank" rel="external nofollow noopener noreferrer">#95</a> <a href="https://papers.cool/arxiv/2509.08910"target="_blank" rel="external nofollow noopener noreferrer">PromptGuard：一个精心编排的提示框架，用于使用具有增强安全性、公平性和可控性的法学硕士为弱势群体生成有原则的合成文本</a> 2]</h2>
<p><strong>Authors</strong>: [Tung Vu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tung</a> Vu), [Lam Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lam</a> Nguyen), [Quynh Dao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Quynh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Quynh</a> Dao)</p>
<p>大型语言模型 （LLM） 在实际应用中的激增带来了前所未有的风险，即向包括 LGBTQ+ 个人、单亲父母和边缘化社区在内的弱势群体生成有害、有偏见或误导性的信息。虽然现有的安全方法依赖于事后过滤或通用对齐技术，但它们无法主动防止发电源的有害输出。本文介绍了 PromptGuard，这是一种新颖的模块化提示框架，具有我们的突破性贡献：VulnGuard Prompt，这是一种混合技术，使用现实世界数据驱动的对比学习来防止有害信息的生成。VulnGuard 集成了来自精选 GitHub 存储库的少量示例、道德思维链推理和自适应角色提示，以创建特定于人群的保护屏障。我们的框架采用理论多目标优化，形式证明通过熵界和帕累托最优性证明了 25-30% 的分析危害。PromptGuard 编排了输入分类、VulnGuard 提示、道德原则集成、外部工具交互、输出验证和用户系统交互六大核心模块，打造实时危害预防的智能专家系统。我们提供全面的数学形式化，包括收敛证明、使用信息论的漏洞分析以及使用 GitHub 来源的数据集进行理论验证框架，为系统的实证研究奠定数学基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-10 18：14：52 UTC</p>
<h2 id="96-recurrence-与通用多模态检索的-transformers-相结合-35"><a href="https://arxiv.org/abs/2509.08897"target="_blank" rel="external nofollow noopener noreferrer">#96</a> <a href="https://papers.cool/arxiv/2509.08897"target="_blank" rel="external nofollow noopener noreferrer">Recurrence 与通用多模态检索的 Transformers 相结合</a> 35]</h2>
<p><strong>Authors</strong>: [Davide Caffagni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Davide"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Davide</a> Caffagni), [Sara Sarto](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sara</a> Sarto), [Marcella Cornia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marcella"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marcella</a> Cornia), [Lorenzo Baraldi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lorenzo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lorenzo</a> Baraldi), [Rita Cucchiara](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rita</a> Cucchiara)</p>
<p>随着多模态检索的快速发展及其在LLMs和多模态LLMs中的应用，越来越复杂的检索任务应运而生。现有方法主要依赖于视觉语言模型的特定任务微调，并且仅限于单模态查询或文档。在本文中，我们提出了 ReT-2，这是一种统一的检索模型，它支持多模态查询，由图像和文本组成，并跨文本和图像共存的多模态文档集合进行搜索。ReT-2 利用多层表示和递归 Transformer 架构以及受 LSTM 启发的门控机制，跨层和模态动态集成信息，捕获细粒度的视觉和文本细节。我们在具有挑战性的 M2KR 和 M-BEIR 基准测试中评估了不同检索配置的 ReT-2。结果表明，与以前的方法相比，ReT-2 在不同设置中始终如一地实现最先进的性能，同时提供更快的推理并减少内存使用。当集成到检索增强生成管道中时，ReT-2 还可以提高 Encyclopedic-VQA 和 InfoSeek 数据集的下游性能。我们的源代码和经过训练的模型可在以下网址公开获取：https://github.com/aimagelab/ReT-2</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-09-10 18：00：29 UTC</p>
<h2 id="97-使用-vllm-对大型语言模型的能效进行基准测试"><a href="https://arxiv.org/abs/2509.08867"target="_blank" rel="external nofollow noopener noreferrer">#97</a> <a href="https://papers.cool/arxiv/2509.08867"target="_blank" rel="external nofollow noopener noreferrer">使用 vLLM 对大型语言模型的能效进行基准测试</a></h2>
<p><strong>Authors</strong>: [K. Pronk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=K"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=K</a>. Pronk), [Q. Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Q"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Q</a>. Zhao)</p>
<p>大型语言模型 （LLM） 的普及对气候的影响越来越大，因为它们的部署和使用需要大量能源。为了提高在其产品中实施 LLM 的开发人员的意识，迫切需要收集有关 LLM 能效的更多信息。虽然现有研究已经评估了各种型号的能源效率，但这些基准往往无法代表现实的生产场景。在本文中，我们介绍了 LLM 效率基准，旨在模拟现实世界的使用条件。我们的基准测试利用 vLLM，这是一种高吞吐量、生产就绪的 LLM 服务后端，可优化模型性能和效率。我们研究了模型大小、架构和并发请求量等因素如何影响推理能效。我们的研究结果表明，可以创建更好地反映实际部署条件的能效基准，为旨在构建更可持续的人工智能系统的开发人员提供宝贵的见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-10 11：03：08 UTC</p>
<h2 id="98-在计算机科学课程中调查学生与大型语言模型驱动的课程助手的交互模式"><a href="https://arxiv.org/abs/2509.08862"target="_blank" rel="external nofollow noopener noreferrer">#98</a> <a href="https://papers.cool/arxiv/2509.08862"target="_blank" rel="external nofollow noopener noreferrer">在计算机科学课程中调查学生与大型语言模型驱动的课程助手的交互模式</a></h2>
<p><strong>Authors</strong>: [Chang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chang</a> Liu), [Loc Hoang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Loc"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Loc</a> Hoang), [Andrew Stolman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> Stolman), [Rene F. Kizilcec](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rene"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rene</a> F. Kizilcec), [Bo Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Wu)</p>
<p>在大多数学院和大学中，为学生提供灵活及时的学术支持是一项挑战，导致许多学生在预定时间之外得不到帮助。大型语言模型 （LLM） 有望弥合这一差距，但学生和法学硕士之间的互动很少受到教育工作者的监督。我们开发并研究了部署在多个计算机科学课程中的法学硕士驱动的课程助手，以表征现实世界的使用并理解教学意义。到 2024 年春季，我们的系统已部署到三个机构的六门课程的约 2,000 名学生。对互动数据的分析表明，晚上和晚上的使用率仍然很高，在入门课程中更高，这表明我们的系统有助于解决时间支持差距和新手学习者的需求。我们对每门课程的 200 个对话进行手动注释抽样：大多数抽样的回答被判断为正确和有帮助，一小部分没有帮助或错误;很少有回复包含专门的例子。我们还研究了一种基于探究的学习策略：只有大约 11% 的抽样对话包含 LLM 生成的后续问题，这些问题经常被高级课程的学生忽略。A Bloom 分类分析表明，当前的 LLM 在生成高阶认知问题方面的能力有限。这些模式表明，以教学为导向的基于法学硕士的教育系统有机会，并让教育工作者更多地参与配置提示、内容和策略。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-10 02：21：11 UTC</p>
<h2 id="99-高动态环境中的多机器人协调应对不对称障碍和有限的通信"><a href="https://arxiv.org/abs/2509.08859"target="_blank" rel="external nofollow noopener noreferrer">#99</a> <a href="https://papers.cool/arxiv/2509.08859"target="_blank" rel="external nofollow noopener noreferrer">高动态环境中的多机器人协调：应对不对称障碍和有限的通信</a></h2>
<p><strong>Authors</strong>: [Vincenzo Suriani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vincenzo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vincenzo</a> Suriani), [Daniele Affinita](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniele"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniele</a> Affinita), [Domenico D. Bloisi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Domenico"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Domenico</a> D. Bloisi), [Daniele Nardi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniele"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniele</a> Nardi)</p>
<p>当通信通道在发送速率和数据包有效负载方面的能力非常有限时，协调完全分布式多代理系统 （MAS） 可能具有挑战性。当 MAS 必须在高度部分可观测的环境中处理活动障碍时，通信信道具有相当大的相关性。在本文中，我们提出了一种在极其活跃的场景中处理任务分配的方法，在这些场景中，任务需要在参与协调过程的代理之间频繁地重新分配。受基于市场的任务分配的启发，我们引入了一种新颖的分布式协调方法，以在低通信场景下有效地编排自主代理的行动。特别是，我们的算法考虑了不对称障碍物。虽然在现实世界中，大多数障碍物都是不对称的，但它们通常被视为对称障碍物，从而限制了现有方法的适用性。总而言之，所提出的架构旨在解决障碍物活跃且不对称、通信通道较差且环境部分可观察的场景。我们的方法已在模拟和现实世界中得到验证，在官方 RoboCup 比赛中使用 NAO 机器人团队。实验结果表明，在有限的通信环境中，任务重叠显着减少，最频繁的重新分配任务减少了 52%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-09 22：11：34 UTC</p>
<h2 id="100-一种氛围编码学习设计以增强-efl-学生与-ai-的对话通过-ai-和关于-ai-的对话-41"><a href="https://arxiv.org/abs/2509.08854"target="_blank" rel="external nofollow noopener noreferrer">#100</a> <a href="https://papers.cool/arxiv/2509.08854"target="_blank" rel="external nofollow noopener noreferrer">一种氛围编码学习设计，以增强 EFL 学生与 AI 的对话、通过 AI 和关于 AI 的对话</a> 41]</h2>
<p><strong>Authors</strong>: [David James Woo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> James Woo), [Kai Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Guo), [Yangyang Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yangyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yangyang</a> Yu)</p>
<p>这篇创新实践文章报告了英语作为外语 （EFL） 教育的氛围编码（使用自然语言创建带有 AI 的软件应用程序）的试点。我们开发了一个具有三个维度的人-AI 元语言框架：与 AI 对话（提示工程）、通过 AI 对话（协商作者身份）和谈论 AI（AI 的心智模型）。使用向后设计原则，我们创建了一个四小时的研讨会，两名学生设计了解决真实 EFL 写作挑战的应用程序。我们采用了案例研究方法，从工作表和视频记录、大声思考协议、屏幕录制和人工智能生成的图像中收集数据。对比案例显示，一名学生成功地对与她的预期设计相一致的功能应用程序进行了编码，而另一名学生则遇到了技术困难，预期设计与实际功能之间存在重大差距。分析揭示了学生提示工程方法的差异，表明不同的人工智能心智模型和归因作者身份的紧张关系。我们认为人工智能就像一台有益的语言机器，学生与人工智能交谈、通过人工智能和谈论人工智能的方式的差异解释了氛围编码结果的变化。研究结果表明，有效的氛围编码教学需要明确的元语言脚手架，教授结构化提示工程，促进批判性作者讨论，并开发用于表达人工智能心智模型的词汇。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-09 00：27：04 UTC</p>
<h2 id="101-安全且可认证的人工智能系统概念挑战和经验教训-3"><a href="https://arxiv.org/abs/2509.08852"target="_blank" rel="external nofollow noopener noreferrer">#101</a> <a href="https://papers.cool/arxiv/2509.08852"target="_blank" rel="external nofollow noopener noreferrer">安全且可认证的人工智能系统：概念、挑战和经验教训</a> 3]</h2>
<p><strong>Authors</strong>: [Kajetan Schweighofer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kajetan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kajetan</a> Schweighofer), [Barbara Brune](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Barbara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Barbara</a> Brune), [Lukas Gruber](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lukas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lukas</a> Gruber), [Simon Schmid](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Simon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Simon</a> Schmid), [Alexander Aufreiter](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Aufreiter), [Andreas Gruber](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andreas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andreas</a> Gruber), [Thomas Doms](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Doms), [Sebastian Eder](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sebastian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sebastian</a> Eder), [Florian Mayer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Florian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Florian</a> Mayer), [Xaver-Paul Stadlbauer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xaver-Paul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xaver-Paul</a> Stadlbauer), [Christoph Schwald](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christoph"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christoph</a> Schwald), [Werner Zellinger](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Werner"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Werner</a> Zellinger), [Bernhard Nessler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bernhard"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bernhard</a> Nessler), [Sepp Hochreiter](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sepp"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sepp</a> Hochreiter)</p>
<p>人工智能在安全关键型应用中的采用越来越多，但证明人工智能系统安全、合法和社会可接受的实用方案仍然很少。本白皮书介绍了TÜV AUSTRIA Trusted AI框架，这是一个用于评估和认证机器学习系统的端到端审核目录和方法。自 2019 年以来，在与科学合作伙伴的持续合作中，审核目录一直在不断开发。该目录以安全软件开发、功能要求以及道德与数据隐私这三大支柱为基础，将欧盟人工智能法案的高级义务转化为具体的、可测试的标准。其功能可信度的核心概念将统计定义的应用领域与基于风险的最低性能要求以及对独立采样数据的统计测试相结合，为现实环境中的模型质量提供透明且可重复的证据。我们概述了我们评估的功能需求，这些需求面向 AI 系统的生命周期。此外，我们还分享了一些从审计目录的实际应用中吸取的经验教训，强调了我们遇到的常见陷阱，例如数据泄露场景、领域定义不充分、忽视偏见或缺乏分布漂移控制。我们进一步讨论了认证人工智能系统的关键方面，例如稳健性、算法公平性或认证后要求，概述了我们当前的结论和未来研究的路线图。总的来说，通过将技术最佳实践与新兴的欧洲标准保持一致，该方法为监管机构、提供商和用户提供了合法合规、功能值得信赖和可认证的人工智能系统的实用路线图。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-08 17：52：08 UTC</p>
<h2 id="102-使用方差门控分布的不确定性估计-2"><a href="https://arxiv.org/abs/2509.08846"target="_blank" rel="external nofollow noopener noreferrer">#102</a> <a href="https://papers.cool/arxiv/2509.08846"target="_blank" rel="external nofollow noopener noreferrer">使用方差门控分布的不确定性估计</a> 2]</h2>
<p><strong>Authors</strong>: [H. Martin Gillis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=H"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=H</a>. Martin Gillis), [Isaac Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Isaac"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Isaac</a> Xu), [Thomas Trappenberg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Trappenberg)</p>
<p>从神经网络评估每个样本的不确定性量化对于涉及高风险应用的决策至关重要。一种常见的方法是使用贝叶斯模型或近似模型的预测分布，并将相应的预测不确定性分解为认识（模型相关）和偶然（数据相关）成分。然而，加性分解最近受到质疑。在这项工作中，我们提出了一个直观的框架，用于基于不同模型预测中类概率分布的信噪比进行不确定性估计和分解。我们引入了一种方差门控度量，该度量通过从集成得出的置信因子来缩放预测。我们用这个措施来讨论委员会机器多样性的崩溃。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-07 16：19：21 UTC</p>
<h2 id="103-深度不透明性和人工智能对-xai-和隐私保护机制的威胁"><a href="https://arxiv.org/abs/2509.08835"target="_blank" rel="external nofollow noopener noreferrer">#103</a> <a href="https://papers.cool/arxiv/2509.08835"target="_blank" rel="external nofollow noopener noreferrer">深度不透明性和人工智能：对 XAI 和隐私保护机制的威胁</a></h2>
<p><strong>Author</strong>: [Vincent C. Müller](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vincent"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vincent</a> C. Müller)</p>
<p>众所周知，大数据分析和人工智能对隐私构成威胁，其中一些是由于人工智能中的某种“黑匣子问题”造成的。我解释了这如何在判断和行动的正当性背景下成为一个问题。此外，我建议区分三种不透明度：1）受试者不知道系统做什么（“浅层不透明度”），2）分析师不知道系统做什么（“标准黑盒不透明度”），或者3）分析师不可能知道系统可能做什么（“深度不透明度”）。如果代理、数据主体和分析专家在不透明的情况下运作，那么这些代理就无法为保护隐私所必需的判断提供理由，例如，他们无法给予“知情同意”或保证“匿名”。由此可见，大数据分析和人工智能领域的代理往往无法做出保护隐私所需的判断。因此，我得出的结论是，大数据分析使隐私问题变得更糟，补救措施也变得不那么有效。作为积极的一面，我简要展望了处理这种情况的技术方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-08-30 11：15：59 UTC</p>
<h2 id="104-perfairx大型语言模型推荐的公平性和个性之间是否取得了平衡"><a href="https://arxiv.org/abs/2509.08829"target="_blank" rel="external nofollow noopener noreferrer">#104</a> <a href="https://papers.cool/arxiv/2509.08829"target="_blank" rel="external nofollow noopener noreferrer">PerFairX：大型语言模型推荐的公平性和个性之间是否取得了平衡？</a></h2>
<p><strong>Author</strong>: [Chandan Kumar Sah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chandan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chandan</a> Kumar Sah)</p>
<p>大型语言模型 （LLM） 与推荐系统的集成通过基于提示的交互实现了零样本、基于个性的个性化，为以用户为中心的推荐提供了新的范式。然而，通过 OCEAN 模型纳入用户个性特征凸显了实现心理一致性和确保人口公平之间的关键紧张关系。为了解决这个问题，我们提出了 PerFairX，这是一个统一的评估框架，旨在量化 LLM 生成的建议中个性化和人口公平之间的权衡。我们使用跨不同用户配置文件的中性且对个性敏感的提示，在电影 （MovieLens 10M） 和音乐 （Last.fm 360K） 数据集上对两个最先进的 LLM ChatGPT 和 DeepSeek 进行了基准测试。我们的结果表明，人格意识提示显着提高了与个人特征的一致性，但可能会加剧人口群体之间的公平差异。具体来说，DeepSeek 实现了更强的心理契合度，但对提示变化表现出更高的敏感性，而 ChatGPT 则提供稳定但不太个性化的输出。PerFairX 提供了一个有原则的基准来指导基于法学硕士的推荐系统的开发，这些系统既公平又有心理依据，有助于在持续学习环境中创建包容性、以用户为中心的人工智能应用程序。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a></p>
<p><strong>发布</strong>: 2025-08-20 09：41：53 UTC</p>
<p>Designed by <a href="https://kexue.fm/"target="_blank" rel="external nofollow noopener noreferrer">kexue.fm</a> | Powered by .ai](<a href="https://kimi.moonshot.cn/?ref=papers.cool"target="_blank" rel="external nofollow noopener noreferrer">https://kimi.moonshot.cn/?ref=papers.cool</a>)</p>
<h1 id="13-huggingface">1.3 Huggingface</h1>
<h1 id="14-x">1.4 X</h1>
<h1 id="15-小红书">1.5 小红书</h1>
<h1 id="2-感兴趣研究">2. 感兴趣研究</h1>
<pre tabindex="0"><code>![](https://gitee.com/dujh22/pic/raw/master/logicReason/SLR.png)</code></pre></div></article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">Public - 2025</span><span class="author" itemprop="copyrightHolder">
              <a href="/LLMDailyDigestWeb/"></a></span></div><div class="footer-line statistics"></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">Theme FixIt works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="preload" href="/LLMDailyDigestWeb/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/cookieconsent/cookieconsent.min.css"><script src="/LLMDailyDigestWeb/lib/sharer/sharer.min.js" async defer></script><script src="/LLMDailyDigestWeb/lib/typeit/index.umd.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/katex.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/auto-render.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/copy-tex.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/mhchem.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-desktop":"LLM-DailyDigest 大模型研究日报","typeit-header-title-mobile":"LLM-DailyDigest 大模型研究日报"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-desktop":["typeit-header-desktop"],"typeit-header-title-mobile":["typeit-header-title-mobile"]},"duration":-1,"loop":false,"speed":100}};</script><script src="/LLMDailyDigestWeb/js/theme.min.js" defer></script></body>
</html>
