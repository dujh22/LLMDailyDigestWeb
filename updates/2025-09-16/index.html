<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head><script src="/LLMDailyDigestWeb/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=LLMDailyDigestWeb/livereload" data-no-instant defer></script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>2025-09-16科研追新 - LLM-DailyDigest</title><meta name="author" content="">
<meta name="author-link" content="">
<meta name="description" content="2025-09-16科研追新
1. 源数据
1.1 媒体
From：量子位、机器之心、新智元、AGI Hunt、小红书、X其他


顶级大模型在AAI提出的FormulaOne基准集体翻车：三层难度递进，GPT-5进阶题仅约4%正确，最深层零分；Grok 4、o3 Pro全部失手。该基准以图上MSO逻辑与动态规划生成问题，贴近路径规划等现实优化，旨在衡量超越竞赛编程的算法推理深度。


GPT-5-Codex特化版模型，支持独立连续编程7个小时。


如今的AI还不具备真正的创造力，因为它还无法提出新的猜想或新的假设。它或许能够证明你提供给它的某些东西，但它本身无法提出新的想法或理论。这实际上将成为衡量AGI是否成熟的关键测试之一。

**AI 能否创造出像围棋这样复杂而优雅的游戏本身？**答案目前是否定的。
Google DeepMind CEO Hassabis 最新访谈：未来十年实现完整 AGI，引领科学黄金时代



xAI发布Grok 4 Fast，生成速度高达每秒75个 token


只要科学任务可以评分，AI就能找到超越人类专家的方法，实现SOTA结果？
这是谷歌一篇最新论文里的内容：
使用大模型&#43;树搜索，让AI大海捞针就行。


反转！LeCun刚转发「全球最快开源推理模型」，ETH苏黎世就直接打假


1.2 Arxiv
1.2.1 Computation and Language
From：https:// /arxiv/cs.CLhttps://arxiv.org/list/cs.CL/recent
2025-09-16 |   | Total: 129
#1 语音感知大型语言模型中语言理解能力的保留 [PDF1] [Copy] [Kimi] [REL]
Authors: [Marek Kubis](https://arxiv.org/search/?searchtype=author&query=Marek Kubis), [Paweł Skórzewski](https://arxiv.org/search/?searchtype=author&query=Paweł Skórzewski), [Iwona Christop](https://arxiv.org/search/?searchtype=author&query=Iwona Christop), [Mateusz Czyżnikiewicz](https://arxiv.org/search/?searchtype=author&query=Mateusz Czyżnikiewicz), [Jakub Kubiak](https://arxiv.org/search/?searchtype=author&query=Jakub Kubiak), [Łukasz Bondaruk](https://arxiv.org/search/?searchtype=author&query=Łukasz Bondaruk), [Marcin Lewandowski](https://arxiv.org/search/?searchtype=author&query=Marcin Lewandowski)" /><meta name="keywords" content='Hugo, FixIt' />
  <meta itemprop="name" content="2025-09-16科研追新">
  <meta itemprop="description" content="2025-09-16科研追新 1. 源数据 1.1 媒体 From：量子位、机器之心、新智元、AGI Hunt、小红书、X其他
顶级大模型在AAI提出的FormulaOne基准集体翻车：三层难度递进，GPT-5进阶题仅约4%正确，最深层零分；Grok 4、o3 Pro全部失手。该基准以图上MSO逻辑与动态规划生成问题，贴近路径规划等现实优化，旨在衡量超越竞赛编程的算法推理深度。 GPT-5-Codex特化版模型，支持独立连续编程7个小时。
如今的AI还不具备真正的创造力，因为它还无法提出新的猜想或新的假设。它或许能够证明你提供给它的某些东西，但它本身无法提出新的想法或理论。这实际上将成为衡量AGI是否成熟的关键测试之一。
**AI 能否创造出像围棋这样复杂而优雅的游戏本身？**答案目前是否定的。 Google DeepMind CEO Hassabis 最新访谈：未来十年实现完整 AGI，引领科学黄金时代 xAI发布Grok 4 Fast，生成速度高达每秒75个 token
只要科学任务可以评分，AI就能找到超越人类专家的方法，实现SOTA结果？
这是谷歌一篇最新论文里的内容：
使用大模型&#43;树搜索，让AI大海捞针就行。
反转！LeCun刚转发「全球最快开源推理模型」，ETH苏黎世就直接打假
1.2 Arxiv 1.2.1 Computation and Language From：https:// /arxiv/cs.CLhttps://arxiv.org/list/cs.CL/recent
2025-09-16 | | Total: 129
#1 语音感知大型语言模型中语言理解能力的保留 [PDF1] [Copy] [Kimi] [REL] Authors: [Marek Kubis](https://arxiv.org/search/?searchtype=author&amp;query=Marek Kubis), [Paweł Skórzewski](https://arxiv.org/search/?searchtype=author&amp;query=Paweł Skórzewski), [Iwona Christop](https://arxiv.org/search/?searchtype=author&amp;query=Iwona Christop), [Mateusz Czyżnikiewicz](https://arxiv.org/search/?searchtype=author&amp;query=Mateusz Czyżnikiewicz), [Jakub Kubiak](https://arxiv.org/search/?searchtype=author&amp;query=Jakub Kubiak), [Łukasz Bondaruk](https://arxiv.org/search/?searchtype=author&amp;query=Łukasz Bondaruk), [Marcin Lewandowski](https://arxiv.org/search/?searchtype=author&amp;query=Marcin Lewandowski)">
  <meta itemprop="datePublished" content="2025-09-16T00:00:00+08:00">
  <meta itemprop="dateModified" content="2025-09-16T00:00:00+08:00">
  <meta itemprop="wordCount" content="17769"><meta property="og:url" content="http://localhost:1313/LLMDailyDigestWeb/updates/2025-09-16/">
  <meta property="og:site_name" content="LLM-DailyDigest">
  <meta property="og:title" content="2025-09-16科研追新">
  <meta property="og:description" content="2025-09-16科研追新 1. 源数据 1.1 媒体 From：量子位、机器之心、新智元、AGI Hunt、小红书、X其他
顶级大模型在AAI提出的FormulaOne基准集体翻车：三层难度递进，GPT-5进阶题仅约4%正确，最深层零分；Grok 4、o3 Pro全部失手。该基准以图上MSO逻辑与动态规划生成问题，贴近路径规划等现实优化，旨在衡量超越竞赛编程的算法推理深度。 GPT-5-Codex特化版模型，支持独立连续编程7个小时。
如今的AI还不具备真正的创造力，因为它还无法提出新的猜想或新的假设。它或许能够证明你提供给它的某些东西，但它本身无法提出新的想法或理论。这实际上将成为衡量AGI是否成熟的关键测试之一。
**AI 能否创造出像围棋这样复杂而优雅的游戏本身？**答案目前是否定的。 Google DeepMind CEO Hassabis 最新访谈：未来十年实现完整 AGI，引领科学黄金时代 xAI发布Grok 4 Fast，生成速度高达每秒75个 token
只要科学任务可以评分，AI就能找到超越人类专家的方法，实现SOTA结果？
这是谷歌一篇最新论文里的内容：
使用大模型&#43;树搜索，让AI大海捞针就行。
反转！LeCun刚转发「全球最快开源推理模型」，ETH苏黎世就直接打假
1.2 Arxiv 1.2.1 Computation and Language From：https:// /arxiv/cs.CLhttps://arxiv.org/list/cs.CL/recent
2025-09-16 | | Total: 129
#1 语音感知大型语言模型中语言理解能力的保留 [PDF1] [Copy] [Kimi] [REL] Authors: [Marek Kubis](https://arxiv.org/search/?searchtype=author&amp;query=Marek Kubis), [Paweł Skórzewski](https://arxiv.org/search/?searchtype=author&amp;query=Paweł Skórzewski), [Iwona Christop](https://arxiv.org/search/?searchtype=author&amp;query=Iwona Christop), [Mateusz Czyżnikiewicz](https://arxiv.org/search/?searchtype=author&amp;query=Mateusz Czyżnikiewicz), [Jakub Kubiak](https://arxiv.org/search/?searchtype=author&amp;query=Jakub Kubiak), [Łukasz Bondaruk](https://arxiv.org/search/?searchtype=author&amp;query=Łukasz Bondaruk), [Marcin Lewandowski](https://arxiv.org/search/?searchtype=author&amp;query=Marcin Lewandowski)">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="updates">
    <meta property="article:published_time" content="2025-09-16T00:00:00+08:00">
    <meta property="article:modified_time" content="2025-09-16T00:00:00+08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="2025-09-16科研追新">
  <meta name="twitter:description" content="2025-09-16科研追新 1. 源数据 1.1 媒体 From：量子位、机器之心、新智元、AGI Hunt、小红书、X其他
顶级大模型在AAI提出的FormulaOne基准集体翻车：三层难度递进，GPT-5进阶题仅约4%正确，最深层零分；Grok 4、o3 Pro全部失手。该基准以图上MSO逻辑与动态规划生成问题，贴近路径规划等现实优化，旨在衡量超越竞赛编程的算法推理深度。 GPT-5-Codex特化版模型，支持独立连续编程7个小时。
如今的AI还不具备真正的创造力，因为它还无法提出新的猜想或新的假设。它或许能够证明你提供给它的某些东西，但它本身无法提出新的想法或理论。这实际上将成为衡量AGI是否成熟的关键测试之一。
**AI 能否创造出像围棋这样复杂而优雅的游戏本身？**答案目前是否定的。 Google DeepMind CEO Hassabis 最新访谈：未来十年实现完整 AGI，引领科学黄金时代 xAI发布Grok 4 Fast，生成速度高达每秒75个 token
只要科学任务可以评分，AI就能找到超越人类专家的方法，实现SOTA结果？
这是谷歌一篇最新论文里的内容：
使用大模型&#43;树搜索，让AI大海捞针就行。
反转！LeCun刚转发「全球最快开源推理模型」，ETH苏黎世就直接打假
1.2 Arxiv 1.2.1 Computation and Language From：https:// /arxiv/cs.CLhttps://arxiv.org/list/cs.CL/recent
2025-09-16 | | Total: 129
#1 语音感知大型语言模型中语言理解能力的保留 [PDF1] [Copy] [Kimi] [REL] Authors: [Marek Kubis](https://arxiv.org/search/?searchtype=author&amp;query=Marek Kubis), [Paweł Skórzewski](https://arxiv.org/search/?searchtype=author&amp;query=Paweł Skórzewski), [Iwona Christop](https://arxiv.org/search/?searchtype=author&amp;query=Iwona Christop), [Mateusz Czyżnikiewicz](https://arxiv.org/search/?searchtype=author&amp;query=Mateusz Czyżnikiewicz), [Jakub Kubiak](https://arxiv.org/search/?searchtype=author&amp;query=Jakub Kubiak), [Łukasz Bondaruk](https://arxiv.org/search/?searchtype=author&amp;query=Łukasz Bondaruk), [Marcin Lewandowski](https://arxiv.org/search/?searchtype=author&amp;query=Marcin Lewandowski)">
<meta name="application-name" content="LLM-DailyDigest">
<meta name="apple-mobile-web-app-title" content="LLM-DailyDigest"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-09-16/" /><link rel="prev" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-09-15/" /><link rel="next" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-09-17/" /><link rel="stylesheet" href="/LLMDailyDigestWeb/css/style.min.css"><link rel="preload" href="/LLMDailyDigestWeb/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/LLMDailyDigestWeb/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "2025-09-16科研追新",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "http:\/\/localhost:1313\/LLMDailyDigestWeb\/updates\/2025-09-16\/"
    },"genre": "updates","wordcount":  17769 ,
    "url": "http:\/\/localhost:1313\/LLMDailyDigestWeb\/updates\/2025-09-16\/","datePublished": "2025-09-16T00:00:00+08:00","dateModified": "2025-09-16T00:00:00+08:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "Author"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/LLMDailyDigestWeb/" title="LLM-DailyDigest"><img loading="lazy" src="/LLMDailyDigestWeb/fixit.svg" data-title="LLM-DailyDigest" data-alt="LLM-DailyDigest" class="logo" style="background: url(/LLMDailyDigestWeb/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-desktop" class="typeit"></span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/posts/llmdailydigest"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/resources/"
                
                
              >资源</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/topic/"
                
                
              >主题</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/updates/"
                
                
              >日报</a></li><li class="menu-item delimiter"></li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/LLMDailyDigestWeb/" title="LLM-DailyDigest"><img loading="lazy" src="/LLMDailyDigestWeb/fixit.svg" data-title="/LLMDailyDigestWeb/fixit.svg" data-alt="/LLMDailyDigestWeb/fixit.svg" class="logo" style="background: url(/LLMDailyDigestWeb/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-title-mobile" class="typeit"></span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/posts/llmdailydigest"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/resources/"
                  
                  
                >资源</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/topic/"
                  
                  
                >主题</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/updates/"
                  
                  
                >日报</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><main class="container"><aside class="toc" id="toc-auto"><h2 class="toc-title">Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom">
    </aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span>2025-09-16科研追新</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      </span></span></div>
      <div class="post-meta-line"><span title="published on 2025-09-16 00:00:00"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden="true"></i><time datetime="2025-09-16">2025-09-16</time></span>&nbsp;<span title="Updated on 2025-09-16 00:00:00"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden="true"></i><time datetime="2025-09-16">2025-09-16</time></span>&nbsp;<span title="17769 words"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>About 17800 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>84 minutes</span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" data-kept="false">
        <div class="details-summary toc-title">
          <span>Contents</span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li>
          <ul>
            <li>
              <ul>
                <li><a href="#顶级大模型在aai提出的formulaone基准集体翻车三层难度递进gpt-5进阶题仅约4正确最深层零分grok-4o3-pro全部失手该基准以图上mso逻辑与动态规划生成问题贴近路径规划等现实优化旨在衡量超越竞赛编程的算法推理深度"><a href="https://mp.weixin.qq.com/s/E4LilyWcLgb-H6SFWI8oew">顶级大模型在AAI提出的FormulaOne基准集体翻车：三层难度递进，GPT-5进阶题仅约4%正确，最深层零分；Grok 4、o3 Pro全部失手。该基准以图上MSO逻辑与动态规划生成问题，贴近路径规划等现实优化，旨在衡量超越竞赛编程的算法推理深度。</a></a></li>
              </ul>
            </li>
          </ul>
        </li>
      </ul>
    </li>
  </ul>

  <ul>
    <li><a href="#1-语音感知大型语言模型中语言理解能力的保留-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12171">#1</a> <a href="https://papers.cool/arxiv/2509.12171">语音感知大型语言模型中语言理解能力的保留</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#2-rags-to-riches大型语言模型角色扮演的类似-rag-的少样本学习-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12168">#2</a> <a href="https://papers.cool/arxiv/2509.12168">RAGs to Riches：大型语言模型角色扮演的类似 RAG 的少样本学习</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#3-双关语法学硕士和幽默理解的错觉-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12158">#3</a> <a href="https://papers.cool/arxiv/2509.12158">双关语：法学硕士和幽默理解的错觉</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#4-checkthat的xplainlp2025-年使用微调-transformer-进行多语言主观性检测和使用大型语言模型进行基于提示的推理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12130">#4</a> <a href="https://papers.cool/arxiv/2509.12130">CheckThat的XplaiNLP！2025 年：使用微调 Transformer 进行多语言主观性检测和使用大型语言模型进行基于提示的推理</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#5-cbp-tuning黑盒大型语言模型的高效本地定制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12112">#5</a> <a href="https://papers.cool/arxiv/2509.12112">CBP-Tuning：黑盒大型语言模型的高效本地定制</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#6-gta使用大型语言模型进行文本分类的监督引导强化学习-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12108">#6</a> <a href="https://papers.cool/arxiv/2509.12108">GTA：使用大型语言模型进行文本分类的监督引导强化学习</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#7-域内-ssl-预训练和流式-asr-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12101">#7</a> <a href="https://papers.cool/arxiv/2509.12101">域内 SSL 预训练和流式 ASR</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#8-希望是一个人还是一个想法ner-的试点基准比较传统-nlp-工具和模棱两可实体上的大型语言模型-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12098">#8</a> <a href="https://papers.cool/arxiv/2509.12098">“希望”是一个人还是一个想法？NER 的试点基准：比较传统 NLP 工具和模棱两可实体上的大型语言模型</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#9-sense-模型基于多语言和多模态语义的任务的开源解决方案-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12093">#9</a> <a href="https://papers.cool/arxiv/2509.12093">SENSE 模型：基于多语言和多模态语义的任务的开源解决方案</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#10-多标记生成中的语言模型引导时态和体的案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12065">#10</a> <a href="https://papers.cool/arxiv/2509.12065">多标记生成中的语言模型引导：时态和体的案例研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#11-文本适应通俗易懂的语言并通过自动译后编辑周期轻松阅读-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11991">#11</a> <a href="https://papers.cool/arxiv/2509.11991">文本适应通俗易懂的语言，并通过自动译后编辑周期轻松阅读</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#12-用于情感解释的以查询为中心的提取摘要-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11989">#12</a> <a href="https://papers.cool/arxiv/2509.11989">用于情感解释的以查询为中心的提取摘要</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#13-toolrm工具调用大型语言模型的结果奖励模型-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11963">#13</a> <a href="https://papers.cool/arxiv/2509.11963">ToolRM：工具调用大型语言模型的结果奖励模型</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#14-spec-llava通过基于动态树的推测解码加速视觉语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11961">#14</a> <a href="https://papers.cool/arxiv/2509.11961">Spec-LLaVA：通过基于动态树的推测解码加速视觉语言模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#15-设计具有文化敏感性的法学硕士来自英日翻译的证据-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11921">#15</a> <a href="https://papers.cool/arxiv/2509.11921">设计具有文化敏感性的法学硕士：来自英日翻译的证据</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#16-作者身份的不确定性为什么完美的人工智能检测在数学上是不可能的-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11915">#16</a> <a href="https://papers.cool/arxiv/2509.11915">作者身份的不确定性：为什么完美的人工智能检测在数学上是不可能的</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#17-成长的视角使用大型语言模型对具身视角采取和内在叙事发展进行建模-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11868">#17</a> <a href="https://papers.cool/arxiv/2509.11868">成长的视角：使用大型语言模型对具身视角采取和内在叙事发展进行建模</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#18-moom超长角色扮演对话中内存的维护组织和优化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11860">#18</a> <a href="https://papers.cool/arxiv/2509.11860">MOOM：超长角色扮演对话中内存的维护、组织和优化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#19-scdtour嵌入轴排序和合并以实现可解释的语义变化检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11818">#19</a> <a href="https://papers.cool/arxiv/2509.11818">SCDTour：嵌入轴排序和合并以实现可解释的语义变化检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#20-pledgetracker监控承诺履行情况的系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11804">#20</a> <a href="https://papers.cool/arxiv/2509.11804">PledgeTracker：监控承诺履行情况的系统</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#21-从模糊语音到医学洞察对嘈杂的患者叙述进行法学硕士的基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11803">#21</a> <a href="https://papers.cool/arxiv/2509.11803">从模糊语音到医学洞察：对嘈杂的患者叙述进行法学硕士的基准测试</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#22-当好奇心发出危险信号时通过在线药物查询预测健康危机-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11802">#22</a> <a href="https://papers.cool/arxiv/2509.11802">当好奇心发出危险信号时：通过在线药物查询预测健康危机</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#23-用户体验感知洞察数据集uxpid来自公共工业论坛的综合用户反馈-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11777">#23</a> <a href="https://papers.cool/arxiv/2509.11777">用户体验感知洞察数据集（UXPID）：来自公共工业论坛的综合用户反馈</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#24-从监管文件中自适应提取信息的代理工具包-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11773">#24</a> <a href="https://papers.cool/arxiv/2509.11773">从监管文件中自适应提取信息的代理工具包</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#25-室内声学影响混合会议空间的沟通成功一项试点研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11709">#25</a> <a href="https://papers.cool/arxiv/2509.11709">室内声学影响混合会议空间的沟通成功：一项试点研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#26-coachme使用基于参考的教练指导生成模型解码运动元素-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11698">#26</a> <a href="https://papers.cool/arxiv/2509.11698">CoachMe：使用基于参考的教练指导生成模型解码运动元素</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#27-基于大语言模型的动态知识更新驱动模型用于假新闻检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11687">#27</a> <a href="https://papers.cool/arxiv/2509.11687">基于大语言模型的动态知识更新驱动模型，用于假新闻检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#28-ethicsmh心理健康人工智能伦理推理的试点基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11648">#28</a> <a href="https://papers.cool/arxiv/2509.11648">EthicsMH：心理健康人工智能伦理推理的试点基准</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#29-aesbiasbench评估多模态语言模型中的偏差和对齐以进行个性化图像美学评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11620">#29</a> <a href="https://papers.cool/arxiv/2509.11620">AesBiasBench：评估多模态语言模型中的偏差和对齐，以进行个性化图像美学评估</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#30-halludetect检测缓解对话系统中的幻觉并对其进行基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11619">#30</a> <a href="https://papers.cool/arxiv/2509.11619">HalluDetect：检测、缓解对话系统中的幻觉并对其进行基准测试</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#31-用于实体级情感分类的动态跨度交互和图感知记忆-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11604">#31</a> <a href="https://papers.cool/arxiv/2509.11604">用于实体级情感分类的动态跨度交互和图感知记忆</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#32-分析客家人工智能聊天机器人中的信息寻求行为一项认知-语用研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11591">#32</a> <a href="https://papers.cool/arxiv/2509.11591">分析客家人工智能聊天机器人中的信息寻求行为：一项认知-语用研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#33-bhaashabhasazaban南亚资源匮乏语言调查---现阶段和挑战-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11570">#33</a> <a href="https://papers.cool/arxiv/2509.11570">Bhaasha、Bhasa、Zaban：南亚资源匮乏语言调查 - 现阶段和挑战</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#34-d2hscore通过语义广度和深度分析在法学硕士中进行推理感知幻觉检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11569">#34</a> <a href="https://papers.cool/arxiv/2509.11569">D2HScore：通过语义广度和深度分析在法学硕士中进行推理感知幻觉检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#35-hichunk使用分层分块评估和增强检索增强生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11552">#35</a> <a href="https://papers.cool/arxiv/2509.11552">HiChunk：使用分层分块评估和增强检索增强生成</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#36-harp通过推理子空间投影进行幻觉检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11536">#36</a> <a href="https://papers.cool/arxiv/2509.11536">HARP：通过推理子空间投影进行幻觉检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#37-论antonymy的显著共现特征-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11534">#37</a> <a href="https://papers.cool/arxiv/2509.11534">论Antonymy的显著共现特征</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#38-perumedqa秘鲁医学考试大型语言模型-llm-基准测试---数据集构建和评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11517">#38</a> <a href="https://papers.cool/arxiv/2509.11517">PeruMedQA：秘鲁医学考试大型语言模型 （LLM） 基准测试 - 数据集构建和评估</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#39-lvlm-不擅长偷听人类参考通信-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11514">#39</a> <a href="https://papers.cool/arxiv/2509.11514">LVLM 不擅长偷听人类参考通信</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#40-通过整体句子语义进行词汇替换的无监督候选人排名-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11513">#40</a> <a href="https://papers.cool/arxiv/2509.11513">通过整体句子语义进行词汇替换的无监督候选人排名</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#41-dedisco-参加-disrpt-2025-共享任务话语关系分类系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11498">#41</a> <a href="https://papers.cool/arxiv/2509.11498">DeDisCo 参加 DISRPT 2025 共享任务：话语关系分类系统</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#42-akcit-fn-at-checkthat2025-年切换微调的-slm-和-llm-提示以实现多语言声明规范化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11496">#42</a> <a href="https://papers.cool/arxiv/2509.11496">AKCIT-FN at CheckThat!2025 年：切换微调的 SLM 和 LLM 提示以实现多语言声明规范化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#43-checkthat-的-claimiq2025-年比较用于验证数字声明的提示和微调语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11492">#43</a> <a href="https://papers.cool/arxiv/2509.11492">CheckThat 的 ClaimIQ！2025 年：比较用于验证数字声明的提示和微调语言模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#44-提高法学硕士的学习能力实现共指解析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11466">#44</a> <a href="https://papers.cool/arxiv/2509.11466">提高法学硕士的学习能力，实现共指解析</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#45-cemtm基于上下文嵌入的多模态主题建模-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11465">#45</a> <a href="https://papers.cool/arxiv/2509.11465">CEMTM：基于上下文嵌入的多模态主题建模</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#46-cognitivesky去中心化社交媒体的可扩展情感和叙事分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11444">#46</a> <a href="https://papers.cool/arxiv/2509.11444">CognitiveSky：去中心化社交媒体的可扩展情感和叙事分析</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#47-基于transformer的15分钟城市范式公共话语跨平台分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11443">#47</a> <a href="https://papers.cool/arxiv/2509.11443">基于Transformer的15分钟城市范式公共话语跨平台分析</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#48-不断向多语言语言模型添加新语言-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11414">#48</a> <a href="https://papers.cool/arxiv/2509.11414">不断向多语言语言模型添加新语言</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#49-transformer-增强关系分类上下文性数据效率和序列复杂度的比较分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11374">#49</a> <a href="https://papers.cool/arxiv/2509.11374">Transformer 增强关系分类：上下文性、数据效率和序列复杂度的比较分析</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#50-arahealthqa-2025-的-msa-共享任务通过提示工程和集成学习提高阿拉伯语临床问答的法学硕士性能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11365">#50</a> <a href="https://papers.cool/arxiv/2509.11365">!AraHealthQA 2025 的 MSA 共享任务：通过提示工程和集成学习提高阿拉伯语临床问答的法学硕士性能</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#51-ko-piqa具有文化背景的韩国物理常识推理数据集-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11303">#51</a> <a href="https://papers.cool/arxiv/2509.11303">Ko-PIQA：具有文化背景的韩国物理常识推理数据集</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#52-提炼的即时工程报告生命科学快速入门指南-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11295">#52</a> <a href="https://papers.cool/arxiv/2509.11295">提炼的即时工程报告：生命科学快速入门指南</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#53-ranat4bie生物医学信息提取的随机对抗训练-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11191">#53</a> <a href="https://papers.cool/arxiv/2509.11191">RanAT4BIE：生物医学信息提取的随机对抗训练</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#54-llm联合量化和稀疏化的最佳大脑恢复-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11177">#54</a> <a href="https://papers.cool/arxiv/2509.11177">LLM联合量化和稀疏化的最佳大脑恢复</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#55-差分私有文本生成会降低输出语言质量-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11176">#55</a> <a href="https://papers.cool/arxiv/2509.11176">差分私有文本生成会降低输出语言质量</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#56-text2mem内存作系统的统一内存作语言-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11145">#56</a> <a href="https://papers.cool/arxiv/2509.11145">Text2Mem：内存作系统的统一内存作语言</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#57-当笑脸变得敌对时解释表情符号如何触发法学硕士的毒性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11141">#57</a> <a href="https://papers.cool/arxiv/2509.11141">当笑脸变得敌对时：解释表情符号如何触发法学硕士的毒性</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#58-论证理论音频模态和数据丰富对基于llm的谬误分类的联合影响-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11127">#58</a> <a href="https://papers.cool/arxiv/2509.11127">论证理论、音频模态和数据丰富对基于LLM的谬误分类的联合影响</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#59-我们主张同意迈向以个性驱动的基于论证的旅游谈判对话系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11118">#59</a> <a href="https://papers.cool/arxiv/2509.11118">我们主张同意：迈向以个性驱动的基于论证的旅游谈判对话系统</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#60-流体语言模型基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11106">#60</a> <a href="https://papers.cool/arxiv/2509.11106">流体语言模型基准测试</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#61-emobench-reddit评估多模态大语言模型情商的分层基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11101">#61</a> <a href="https://papers.cool/arxiv/2509.11101">EmoBench-Reddit：评估多模态大语言模型情商的分层基准</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#62-点击诱饵检测和策略归因的可解释基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10937">#62</a> <a href="https://papers.cool/arxiv/2509.10937">点击诱饵检测和策略归因的可解释基准</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#63-spotlight-简介一种从文档生成引人入胜的关键信息的新方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10935">#63</a> <a href="https://papers.cool/arxiv/2509.10935">Spotlight 简介：一种从文档生成引人入胜的关键信息的新方法</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#64-通过半自动本体构建使-esg-争议数据与国际准则保持一致-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10922">#64</a> <a href="https://papers.cool/arxiv/2509.10922">通过半自动本体构建使 ESG 争议数据与国际准则保持一致</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#65-culturesynth用于文化问答综合的分层分类学指导和检索增强框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10886">#65</a> <a href="https://papers.cool/arxiv/2509.10886">CultureSynth：用于文化问答综合的分层分类学指导和检索增强框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#66-term2note从医学术语中综合差异化私人临床笔记-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10882">#66</a> <a href="https://papers.cool/arxiv/2509.10882">Term2Note：从医学术语中综合差异化私人临床笔记</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#67-语言学习者和法学硕士的量词范围解释-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10860">#67</a> <a href="https://papers.cool/arxiv/2509.10860">语言学习者和法学硕士的量词范围解释</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#68-情景记忆的预存储推理将推理负担转移到记忆中以进行个性化对话-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10852">#68</a> <a href="https://papers.cool/arxiv/2509.10852">情景记忆的预存储推理：将推理负担转移到记忆中以进行个性化对话</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#69-有趣的伴侣对感知到的人工智能幽默与人类生成的幽默的不同神经反应-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10847">#69</a> <a href="https://papers.cool/arxiv/2509.10847">有趣的伴侣：对感知到的人工智能幽默与人类生成的幽默的不同神经反应</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#70-text2sign-diffusion一种无光泽手语制作的生成方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10845">#70</a> <a href="https://papers.cool/arxiv/2509.10845">Text2Sign Diffusion：一种无光泽手语制作的生成方法</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#71-gaprune用于领域感知嵌入的梯度对齐修剪-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10844">#71</a> <a href="https://papers.cool/arxiv/2509.10844">GAPrune：用于领域感知嵌入的梯度对齐修剪</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#72-评估大型语言模型以进行循证临床问答-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10843">#72</a> <a href="https://papers.cool/arxiv/2509.10843">评估大型语言模型以进行循证临床问答</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#73-实现自动错误发现对话式人工智能研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10833">#73</a> <a href="https://papers.cool/arxiv/2509.10833">实现自动错误发现：对话式人工智能研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#74-judge-qkv-缓存驱逐中优化信息保留的可训练查询-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10798">#74</a> <a href="https://papers.cool/arxiv/2509.10798">Judge Q：KV 缓存驱逐中优化信息保留的可训练查询</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#75-回顾医疗对话系统的透明推理-时间情绪对齐-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10746">#75</a> <a href="https://papers.cool/arxiv/2509.10746">回顾：医疗对话系统的透明推理-时间情绪对齐</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#76-大规模自动化-mcqa-基准测试评估推理轨迹作为小型语言模型领域适配的检索源-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10744">#76</a> <a href="https://papers.cool/arxiv/2509.10744">大规模自动化 MCQA 基准测试：评估推理轨迹作为小型语言模型领域适配的检索源</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#77-不确定性下的推理探索法学硕士的概率推理能力-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10739">#77</a> <a href="https://papers.cool/arxiv/2509.10739">不确定性下的推理：探索法学硕士的概率推理能力</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#78-polytruth使用基于-transformer-的语言模型进行多语言虚假信息检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10737">#78</a> <a href="https://papers.cool/arxiv/2509.10737">PolyTruth：使用基于 Transformer 的语言模型进行多语言虚假信息检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#79-searchinstruct通过基于检索的指令数据集创建增强领域适应-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10708">#79</a> <a href="https://papers.cool/arxiv/2509.10708">SearchInstruct：通过基于检索的指令数据集创建增强领域适应</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#80-基于大型语言模型的增强生成检索与结构化综述-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10697">#80</a> <a href="https://papers.cool/arxiv/2509.10697">基于大型语言模型的增强生成检索与结构化综述</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#81-struct-bench差分私有结构化文本生成的基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10696">#81</a> <a href="https://papers.cool/arxiv/2509.10696">Struct-Bench：差分私有结构化文本生成的基准</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#82-医疗保健的多元调整角色驱动的框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10685">#82</a> <a href="https://papers.cool/arxiv/2509.10685">医疗保健的多元调整：角色驱动的框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#83-上下文复制调制熵神经元在管理参数和上下文知识冲突中的作用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10663">#83</a> <a href="https://papers.cool/arxiv/2509.10663">上下文复制调制：熵神经元在管理参数和上下文知识冲突中的作用</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#84-对话中的跨学科研究语言文档计算形态学案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10644">#84</a> <a href="https://papers.cool/arxiv/2509.10644">对话中的跨学科研究：语言文档计算形态学案例研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#85-无需回答从纯问题线性探针预测-llm-答案准确性-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10625">#85</a> <a href="https://papers.cool/arxiv/2509.10625">无需回答：从纯问题线性探针预测 LLM 答案准确性</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#86-通过风险隐瞒揭示金融领域大语言模型的脆弱性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10546">#86</a> <a href="https://papers.cool/arxiv/2509.10546">通过风险隐瞒揭示金融领域大语言模型的脆弱性</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#87-不惜一切代价生存法学硕士以及自我保护与人类伤害之间的选择-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12190">#87</a> <a href="https://papers.cool/arxiv/2509.12190">不惜一切代价生存？法学硕士以及自我保护与人类伤害之间的选择</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#88-event2vec一种学习事件序列可组合表示的几何方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12188">#88</a> <a href="https://papers.cool/arxiv/2509.12188">Event2Vec：一种学习事件序列可组合表示的几何方法</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#89-再看一遍慢慢思考增强视觉语言模型中的视觉反射-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12132">#89</a> <a href="https://papers.cool/arxiv/2509.12132">再看一遍，慢慢思考：增强视觉语言模型中的视觉反射</a> [PDF2] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#90-当海洋雷达目标检测与预训练大语言模型相遇-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12110">#90</a> <a href="https://papers.cool/arxiv/2509.12110">当海洋雷达目标检测与预训练大语言模型相遇</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#91-radarllm将预训练的大型语言模型应用于具有偏好感知损失的海洋雷达目标检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12089">#91</a> <a href="https://papers.cool/arxiv/2509.12089">RadarLLM：将预训练的大型语言模型应用于具有偏好感知损失的海洋雷达目标检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#92-fingear财务映射引导的增强型答案检索-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12042">#92</a> <a href="https://papers.cool/arxiv/2509.12042">FinGEAR：财务映射引导的增强型答案检索</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#93-amq启用-automl-对大型语言模型进行混合精度仅权重量化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12019">#93</a> <a href="https://papers.cool/arxiv/2509.12019">AMQ：启用 AutoML 对大型语言模型进行混合精度仅权重量化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#94-迷失在嵌入中视觉语言模型中的信息丢失-pdf3-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11986">#94</a> <a href="https://papers.cool/arxiv/2509.11986">迷失在嵌入中：视觉语言模型中的信息丢失</a> [PDF3] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#95-millstone法学硕士的思想有多开放-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11967">#95</a> <a href="https://papers.cool/arxiv/2509.11967">MillStone：法学硕士的思想有多开放？</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#96-如何评估医疗人工智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11941">#96</a> <a href="https://papers.cool/arxiv/2509.11941">如何评估医疗人工智能</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#97-人工智能记忆差距用户错误地记住了他们在人工智能或没有人工智能的情况下创建了什么-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11851">#97</a> <a href="https://papers.cool/arxiv/2509.11851">人工智能记忆差距：用户错误地记住了他们在人工智能或没有人工智能的情况下创建了什么</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#98-与多个用户和-ai-代理协作编辑文档-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11826">#98</a> <a href="https://papers.cool/arxiv/2509.11826">与多个用户和 AI 代理协作编辑文档</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#99-不相关表示的崩溃-cir-确保稳健且无中断的-llm-忘却-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11816">#99</a> <a href="https://papers.cool/arxiv/2509.11816">不相关表示的崩溃 （CIR） 确保稳健且无中断的 LLM 忘却</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#100-测量电信领域的视觉理解使用-vlm-进行图像到-uml-转换的性能指标-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11667">#100</a> <a href="https://papers.cool/arxiv/2509.11667">测量电信领域的视觉理解：使用 VLM 进行图像到 UML 转换的性能指标</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#101-mindvl迈向昇腾npu上多模态大语言模型的高效训练-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11662">#101</a> <a href="https://papers.cool/arxiv/2509.11662">MindVL：迈向昇腾NPU上多模态大语言模型的高效训练</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#102-mallm多智能体大型语言模型框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11656">#102</a> <a href="https://papers.cool/arxiv/2509.11656">MALLM：多智能体大型语言模型框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#103-智能qa系统的形式推理教育领域的案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11572">#103</a> <a href="https://papers.cool/arxiv/2509.11572">智能QA系统的形式推理：教育领域的案例研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#104-学习通过动态奖励加权优化多目标对齐-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11452">#104</a> <a href="https://papers.cool/arxiv/2509.11452">学习通过动态奖励加权优化多目标对齐</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#105-保护-ai-代理为工业应用程序实施基于角色的访问控制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11431">#105</a> <a href="https://papers.cool/arxiv/2509.11431">保护 AI 代理：为工业应用程序实施基于角色的访问控制</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#106-fusecodec神经编解码器的语义上下文融合和监督-pdf1-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11425">#106</a> <a href="https://papers.cool/arxiv/2509.11425">FuseCodec：神经编解码器的语义上下文融合和监督</a> [PDF1] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#107-trading-r1通过强化学习使用-llm-推理进行金融交易-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11420">#107</a> <a href="https://papers.cool/arxiv/2509.11420">Trading-R1：通过强化学习使用 LLM 推理进行金融交易</a> [PDF2] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#108-opalrlhf-的算子代数视图-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11298">#108</a> <a href="https://papers.cool/arxiv/2509.11298">Opal：RLHF 的算子代数视图</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#109-通过自我注射幻觉减轻大型视觉语言模型中的幻觉-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11287">#109</a> <a href="https://papers.cool/arxiv/2509.11287">通过自我注射幻觉减轻大型视觉语言模型中的幻觉</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#110-evalet通过将输出碎片化为函数来评估大型语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11206">#110</a> <a href="https://papers.cool/arxiv/2509.11206">Evalet：通过将输出碎片化为函数来评估大型语言模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#111-dreamnav用于零样本视觉和语言导航的基于轨迹的想象力框架-pdf1-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11197">#111</a> <a href="https://papers.cool/arxiv/2509.11197">DreamNav：用于零样本视觉和语言导航的基于轨迹的想象力框架</a> [PDF1] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#112-aqua通过-query-magnitudes-在-llm-中进行记忆和计算高效推理的注意力-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11155">#112</a> <a href="https://papers.cool/arxiv/2509.11155">AQUA：通过 QUery mAgnitudes 在 LLM 中进行记忆和计算高效推理的注意力</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#113-在线平台中的代理用户名建议和多模态性别检测介绍-pngt-26k-数据集-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11136">#113</a> <a href="https://papers.cool/arxiv/2509.11136">在线平台中的代理用户名建议和多模态性别检测：介绍 PNGT-26K 数据集</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#114-用于文本-语音对齐的长度感知旋转位置嵌入-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11084">#114</a> <a href="https://papers.cool/arxiv/2509.11084">用于文本-语音对齐的长度感知旋转位置嵌入</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#115-cvpr-2024-自动驾驶大挑战赛语言驾驶赛道-cps-团队的系统描述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11071">#115</a> <a href="https://papers.cool/arxiv/2509.11071">CVPR 2024 自动驾驶大挑战赛语言驾驶赛道 CPS 团队的系统描述</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#116-重新思考对-llm-基本原理的人类偏好评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11026">#116</a> <a href="https://papers.cool/arxiv/2509.11026">重新思考对 LLM 基本原理的人类偏好评估</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#117-refineg协同小型监督模型和llms实现低资源接地多模态ner-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10975">#117</a> <a href="https://papers.cool/arxiv/2509.10975">ReFineG：协同小型监督模型和LLMs，实现低资源接地多模态NER</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#118-公共数据辅助差分私密情境学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10932">#118</a> <a href="https://papers.cool/arxiv/2509.10932">公共数据辅助差分私密情境学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#119-有害的提示洗钱使用绑架风格和符号编码越狱法学硕士-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10931">#119</a> <a href="https://papers.cool/arxiv/2509.10931">有害的提示洗钱：使用绑架风格和符号编码越狱法学硕士</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#120-为什么债券的失败方式不同用于多类默认预测的可解释多模态学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10802">#120</a> <a href="https://papers.cool/arxiv/2509.10802">为什么债券的失败方式不同？用于多类默认预测的可解释多模态学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#121-agentarch评估企业代理架构的综合基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10769">#121</a> <a href="https://papers.cool/arxiv/2509.10769">AgentArch：评估企业代理架构的综合基准</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#122-了解人工智能评估模式不同的-gpt-模型如何评估视觉语言描述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10707">#122</a> <a href="https://papers.cool/arxiv/2509.10707">了解人工智能评估模式：不同的 GPT 模型如何评估视觉语言描述</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#123-中间的法学硕士对现实世界基于法学硕士的系统的威胁和缓解措施的系统回顾-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10682">#123</a> <a href="https://papers.cool/arxiv/2509.10682">中间的法学硕士：对现实世界基于法学硕士的系统的威胁和缓解措施的系统回顾</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#124-智能试验评估使用大型语言模型通过社交媒体招募临床试验参与者-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10584">#124</a> <a href="https://papers.cool/arxiv/2509.10584">智能试验：评估使用大型语言模型通过社交媒体招募临床试验参与者</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#125-dualalign生成基于临床的合成数据-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10538">#125</a> <a href="https://papers.cool/arxiv/2509.10538">DualAlign：生成基于临床的合成数据</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#126-使用极坐标位置嵌入解耦什么和在哪里-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10534">#126</a> <a href="https://papers.cool/arxiv/2509.10534">使用极坐标位置嵌入解耦“什么”和“在哪里”</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#127-用于识别供应链漏洞的实时-rag-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10469">#127</a> <a href="https://papers.cool/arxiv/2509.10469">用于识别供应链漏洞的实时 RAG</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#128-从预训练和协作信号中学习分解的上下文标记表示以进行生成推荐-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10468">#128</a> <a href="https://papers.cool/arxiv/2509.10468">从预训练和协作信号中学习分解的上下文标记表示，以进行生成推荐</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#129-dsrag基于文档衍生多模态知识图谱的领域特定检索框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10467">#129</a> <a href="https://papers.cool/arxiv/2509.10467">DSRAG：基于文档衍生多模态知识图谱的领域特定检索框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
  </ul>

  <ul>
    <li><a href="#1-利用百年案例推进医疗人工智能-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12194">#1</a> <a href="https://papers.cool/arxiv/2509.12194">利用百年案例推进医疗人工智能</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#2-co-alignment重新思考将对齐作为双向人机认知适应-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12179">#2</a> <a href="https://papers.cool/arxiv/2509.12179">Co-Alignment：重新思考将对齐作为双向人机认知适应</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#3-justeva评估法律知识推理中法学硕士公平性的工具包-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12104">#3</a> <a href="https://papers.cool/arxiv/2509.12104">JustEva：评估法律知识推理中法学硕士公平性的工具包</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#4-通过基于模型的知识转换将工程和人工智能规划联系起来以验证自动化生产系统变体-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12091">#4</a> <a href="https://papers.cool/arxiv/2509.12091">通过基于模型的知识转换将工程和人工智能规划联系起来，以验证自动化生产系统变体</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#5-当安全单模态输入发生碰撞时优化多模态大语言模型中跨模态安全的推理链-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12060">#5</a> <a href="https://papers.cool/arxiv/2509.12060">当安全单模态输入发生碰撞时：优化多模态大语言模型中跨模态安全的推理链</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#6-灾害场景中人机在决策中的使用模式系统评价-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12034">#6</a> <a href="https://papers.cool/arxiv/2509.12034">灾害场景中人机在决策中的使用模式：系统评价</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#7-musicswarm用于音乐创作的生物启发智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11973">#7</a> <a href="https://papers.cool/arxiv/2509.11973">MusicSwarm：用于音乐创作的生物启发智能</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#8-多模态语言模型推理的代理时间图人工智能对医疗保健的潜在帮助-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11944">#8</a> <a href="https://papers.cool/arxiv/2509.11944">多模态语言模型推理的代理时间图：人工智能对医疗保健的潜在帮助</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#9-用于自主诊断的具有模态逻辑的神经符号代理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11943">#9</a> <a href="https://papers.cool/arxiv/2509.11943">用于自主诊断的具有模态逻辑的神经符号代理</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#10-如何评估医疗人工智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11941">#10</a> <a href="https://papers.cool/arxiv/2509.11941">如何评估医疗人工智能</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#11-神经形态智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11940">#11</a> <a href="https://papers.cool/arxiv/2509.11940">神经形态智能</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#12-buildinggym使用强化学习进行基于人工智能的建筑能源管理的开源工具箱-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11922">#12</a> <a href="https://papers.cool/arxiv/2509.11922">BuildingGym：使用强化学习进行基于人工智能的建筑能源管理的开源工具箱</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#13-egomem全双工全模态模型的终身记忆代理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11914">#13</a> <a href="https://papers.cool/arxiv/2509.11914">EgoMem：全双工全模态模型的终身记忆代理</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#14-具有监督对比模仿学习的视频游戏代理的学习表征-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11880">#14</a> <a href="https://papers.cool/arxiv/2509.11880">具有监督对比模仿学习的视频游戏代理的学习表征</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#15-helofusion一种高效且可扩展的编码器用于对轨迹预测中的异构和多尺度相互作用进行建模-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11719">#15</a> <a href="https://papers.cool/arxiv/2509.11719">HeLoFusion：一种高效且可扩展的编码器，用于对轨迹预测中的异构和多尺度相互作用进行建模</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#16-适应和评估青少年特发性脊柱侧弯自我管理的多模态大语言模型分而治之的框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11645">#16</a> <a href="https://papers.cool/arxiv/2509.11645">适应和评估青少年特发性脊柱侧弯自我管理的多模态大语言模型：分而治之的框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#17-amlnet基于知识的多代理框架用于生成和检测真实的洗钱交易-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11595">#17</a> <a href="https://papers.cool/arxiv/2509.11595">AMLNet：基于知识的多代理框架，用于生成和检测真实的洗钱交易</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#18-基于大型语言模型的时间序列推理与代理系统综述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11575">#18</a> <a href="https://papers.cool/arxiv/2509.11575">基于大型语言模型的时间序列推理与代理系统综述</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#19-智能qa系统的形式推理教育领域的案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11572">#19</a> <a href="https://papers.cool/arxiv/2509.11572">智能QA系统的形式推理：教育领域的案例研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#20-使用合成数据增强的基于眼球运动的任务解码-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11547">#20</a> <a href="https://papers.cool/arxiv/2509.11547">使用合成数据增强的基于眼球运动的任务解码</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#21-medicalos基于-llm-代理的数字医疗保健作系统-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11507">#21</a> <a href="https://papers.cool/arxiv/2509.11507">MedicalOS：基于 LLM 代理的数字医疗保健作系统</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#22-视觉-语言-动作模型从边缘到云gpu的跨平台扩展-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11480">#22</a> <a href="https://papers.cool/arxiv/2509.11480">视觉-语言-动作模型从边缘到云GPU的跨平台扩展</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#23-知识引导的自适应混合专家降水预报-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11459">#23</a> <a href="https://papers.cool/arxiv/2509.11459">知识引导的自适应混合专家降水预报</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#24-保护-ai-代理为工业应用程序实施基于角色的访问控制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11431">#24</a> <a href="https://papers.cool/arxiv/2509.11431">保护 AI 代理：为工业应用程序实施基于角色的访问控制</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#25-mapgd用于协作提示优化的多智能体提示梯度下降-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11361">#25</a> <a href="https://papers.cool/arxiv/2509.11361">MAPGD：用于协作提示优化的多智能体提示梯度下降</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#26-动态因果关系在基于观察者设计的软传感器应用中的力量-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11336">#26</a> <a href="https://papers.cool/arxiv/2509.11336">动态因果关系在基于观察者设计的软传感器应用中的力量</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#27-解码塑料毒性从科学摘要中提取冲突感知关系元路径的智能框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11330">#27</a> <a href="https://papers.cool/arxiv/2509.11330">解码塑料毒性：从科学摘要中提取冲突感知关系元路径的智能框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#28-代理提示通过紧凑的-llm-集成模拟人类偏好-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11311">#28</a> <a href="https://papers.cool/arxiv/2509.11311">代理提示：通过紧凑的 LLM 集成模拟人类偏好</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#29-videoagent科学视频的个性化合成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11253">#29</a> <a href="https://papers.cool/arxiv/2509.11253">VideoAgent：科学视频的个性化合成</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#30-跨领域应用中的人工智能生成内容研究趋势挑战和主张-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11151">#30</a> <a href="https://papers.cool/arxiv/2509.11151">跨领域应用中的人工智能生成内容：研究趋势、挑战和主张</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#31-alignkt使用理想状态对齐显式建模知识状态以进行知识追踪-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11135">#31</a> <a href="https://papers.cool/arxiv/2509.11135">AlignKT：使用理想状态对齐显式建模知识状态以进行知识追踪</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#32-神经元胞自动机在生物学和经典人工智能之外的应用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11131">#32</a> <a href="https://papers.cool/arxiv/2509.11131">神经元胞自动机：在生物学和经典人工智能之外的应用</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#33-llm-驱动的工作流程中的难度感知代理编排-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11079">#33</a> <a href="https://papers.cool/arxiv/2509.11079">LLM 驱动的工作流程中的难度感知代理编排</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#34-patient-zero用于生成真实无记录的患者代理的统一框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11078">#34</a> <a href="https://papers.cool/arxiv/2509.11078">Patient-Zero：用于生成真实无记录的患者代理的统一框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#35-通过确定性可复制性对大型语言模型进行可处理的非对称验证-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11068">#35</a> <a href="https://papers.cool/arxiv/2509.11068">通过确定性可复制性对大型语言模型进行可处理的非对称验证</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#36-agentic-lybic具有分层推理和编排功能的多代理执行系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11067">#36</a> <a href="https://papers.cool/arxiv/2509.11067">Agentic Lybic：具有分层推理和编排功能的多代理执行系统</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#37-free-mad无共识的多代理辩论-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11035">#37</a> <a href="https://papers.cool/arxiv/2509.11035">Free-MAD：无共识的多代理辩论</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#38-重新思考对-llm-基本原理的人类偏好评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11026">#38</a> <a href="https://papers.cool/arxiv/2509.11026">重新思考对 LLM 基本原理的人类偏好评估</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#39-使用法学硕士增强计算认知架构案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10972">#39</a> <a href="https://papers.cool/arxiv/2509.10972">使用法学硕士增强计算认知架构：案例研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#40-公共数据辅助差分私密情境学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10932">#40</a> <a href="https://papers.cool/arxiv/2509.10932">公共数据辅助差分私密情境学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#41-有害的提示洗钱使用绑架风格和符号编码越狱法学硕士-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10931">#41</a> <a href="https://papers.cool/arxiv/2509.10931">有害的提示洗钱：使用绑架风格和符号编码越狱法学硕士</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#42-代理范式是下一代智能系统的限制框架吗-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10875">#42</a> <a href="https://papers.cool/arxiv/2509.10875">“代理”范式是下一代智能系统的限制框架吗？</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#43-从接地到模板化一种用于复杂查询应答的逻辑约束向量符号架构-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10837">#43</a> <a href="https://papers.cool/arxiv/2509.10837">从接地到模板化：一种用于复杂查询应答的逻辑约束向量符号架构</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#44-使用领域专家心智模型增强-llm通过因果提示工程减少-llm-幻觉-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10818">#44</a> <a href="https://papers.cool/arxiv/2509.10818">使用领域专家心智模型增强 LLM，通过因果提示工程减少 LLM 幻觉</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#45-agentarch评估企业代理架构的综合基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10769">#45</a> <a href="https://papers.cool/arxiv/2509.10769">AgentArch：评估企业代理架构的综合基准</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#46-ai应答引擎引文行为geo16框架的实证分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10762">#46</a> <a href="https://papers.cool/arxiv/2509.10762">AI应答引擎引文行为：GEO16框架的实证分析</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#47-了解人工智能评估模式不同的-gpt-模型如何评估视觉语言描述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10707">#47</a> <a href="https://papers.cool/arxiv/2509.10707">了解人工智能评估模式：不同的 GPT 模型如何评估视觉语言描述</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#48-maestro通过代理编排自我改进的文本到图像生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10704">#48</a> <a href="https://papers.cool/arxiv/2509.10704">Maestro：通过代理编排自我改进的文本到图像生成</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#49-zapgpt用于模拟细胞控制的自由格式语言提示-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10660">#49</a> <a href="https://papers.cool/arxiv/2509.10660">ZapGPT：用于模拟细胞控制的自由格式语言提示</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#50-交通运输交通排放和气象条件的态势模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10541">#50</a> <a href="https://papers.cool/arxiv/2509.10541">交通运输、交通排放和气象条件的态势模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#51-动态关系启动改进了多元时间序列中的-transformer-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12196">#51</a> <a href="https://papers.cool/arxiv/2509.12196">动态关系启动改进了多元时间序列中的 Transformer</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#52-不惜一切代价生存法学硕士以及自我保护与人类伤害之间的选择-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12190">#52</a> <a href="https://papers.cool/arxiv/2509.12190">不惜一切代价生存？法学硕士以及自我保护与人类伤害之间的选择</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#53-hologarment野外服装的-360-新颖视角合成-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12187">#53</a> <a href="https://papers.cool/arxiv/2509.12187">HoloGarment：野外服装的 360° 新颖视角合成</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#54-语音感知大型语言模型中语言理解能力的保留-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12171">#54</a> <a href="https://papers.cool/arxiv/2509.12171">语音感知大型语言模型中语言理解能力的保留</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#55-基于人工智能的自动驾驶汽车的分析和设计方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12169">#55</a> <a href="https://papers.cool/arxiv/2509.12169">基于人工智能的自动驾驶汽车的分析和设计方法</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#56-rags-to-riches大型语言模型角色扮演的类似-rag-的少样本学习-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12168">#56</a> <a href="https://papers.cool/arxiv/2509.12168">RAGs to Riches：大型语言模型角色扮演的类似 RAG 的少样本学习</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#57-efficientuicoder通过输入和输出令牌压缩高效生成基于-mllm-的-ui-代码-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12159">#57</a> <a href="https://papers.cool/arxiv/2509.12159">EfficientUICoder：通过输入和输出令牌压缩高效生成基于 MLLM 的 UI 代码</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#58-双关语法学硕士和幽默理解的错觉-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12158">#58</a> <a href="https://papers.cool/arxiv/2509.12158">双关语：法学硕士和幽默理解的错觉</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#59-超越-pii用户如何尝试估计和缓解隐式-llm-推理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12152">#59</a> <a href="https://papers.cool/arxiv/2509.12152">超越 PII：用户如何尝试估计和缓解隐式 LLM 推理</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#60-多解剖-x-射线基础模型-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12146">#60</a> <a href="https://papers.cool/arxiv/2509.12146">多解剖 X 射线基础模型</a> [PDF2] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#61-3dvit-gat基于统一图集的-3d-视觉转换器和图形学习框架用于使用结构-mri-数据检测重度抑郁症-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12143">#61</a> <a href="https://papers.cool/arxiv/2509.12143">3DViT-GAT：基于统一图集的 3D 视觉转换器和图形学习框架，用于使用结构 MRI 数据检测重度抑郁症</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#62-基于人工智能感知不完善的自动驾驶汽车的控制分析与设计-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12137">#62</a> <a href="https://papers.cool/arxiv/2509.12137">基于人工智能感知不完善的自动驾驶汽车的控制分析与设计</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#63-k-多智能体强化学习的水平策略梯度-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12117">#63</a> <a href="https://papers.cool/arxiv/2509.12117">K-多智能体强化学习的水平策略梯度</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#64-出于教学目的探索法学硕士中的对话式设计选择改善教师教学实践的苏格拉底式和叙事方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12107">#64</a> <a href="https://papers.cool/arxiv/2509.12107">出于教学目的探索法学硕士中的对话式设计选择：改善教师教学实践的苏格拉底式和叙事方法</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#65-法学硕士可以解决心理健康问题吗与人类治疗师的比较-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12102">#65</a> <a href="https://papers.cool/arxiv/2509.12102">法学硕士可以解决心理健康问题吗？与人类治疗师的比较</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#66-域内-ssl-预训练和流式-asr-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12101">#66</a> <a href="https://papers.cool/arxiv/2509.12101">域内 SSL 预训练和流式 ASR</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#67-希望是一个人还是一个想法ner-的试点基准比较传统-nlp-工具和模棱两可实体上的大型语言模型-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12098">#67</a> <a href="https://papers.cool/arxiv/2509.12098">“希望”是一个人还是一个想法？NER 的试点基准：比较传统 NLP 工具和模棱两可实体上的大型语言模型</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#68-欺骗性风险最小化通过欺骗性分布偏移检测器进行分布外泛化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12081">#68</a> <a href="https://papers.cool/arxiv/2509.12081">欺骗性风险最小化：通过欺骗性分布偏移检测器进行分布外泛化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#69-基于通用延迟嵌入的时间序列基础模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12080">#69</a> <a href="https://papers.cool/arxiv/2509.12080">基于通用延迟嵌入的时间序列基础模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#70-利用叶谱分析和机器学习早期检测番茄作物中分枝扫帚phelipanche-ramosa侵染-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12074">#70</a> <a href="https://papers.cool/arxiv/2509.12074">利用叶谱分析和机器学习早期检测番茄作物中分枝扫帚（Phelipanche ramosa）侵染</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#71-u-mamba2在-cbct-中缩放用于牙齿解剖分割的状态空间模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12069">#71</a> <a href="https://papers.cool/arxiv/2509.12069">U-Mamba2：在 CBCT 中缩放用于牙齿解剖分割的状态空间模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#72-乐高张量应用的空间加速器生成和优化-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12053">#72</a> <a href="https://papers.cool/arxiv/2509.12053">乐高：张量应用的空间加速器生成和优化</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#73-交互驱动的浏览由使用浏览器的代理的人类网页浏览提供信息的人机交互概念框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12049">#73</a> <a href="https://papers.cool/arxiv/2509.12049">交互驱动的浏览：由使用浏览器的代理的人类网页浏览提供信息的人机交互概念框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#74-用于个体水平行为分析的计算机视觉管道爱丁堡猪数据集的基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12047">#74</a> <a href="https://papers.cool/arxiv/2509.12047">用于个体水平行为分析的计算机视觉管道：爱丁堡猪数据集的基准测试</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#75-通过结构化掩码生成布局条件的自回归文本到图像-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12046">#75</a> <a href="https://papers.cool/arxiv/2509.12046">通过结构化掩码生成布局条件的自回归文本到图像</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#76-探索遥感中的高效开放词汇分割-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12040">#76</a> <a href="https://papers.cool/arxiv/2509.12040">探索遥感中的高效开放词汇分割</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#77-模仿学习作为回报分布匹配-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12026">#77</a> <a href="https://papers.cool/arxiv/2509.12026">模仿学习作为回报分布匹配</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#78-amq启用-automl-对大型语言模型进行混合精度仅权重量化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12019">#78</a> <a href="https://papers.cool/arxiv/2509.12019">AMQ：启用 AutoML 对大型语言模型进行混合精度仅权重量化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#79-通过具有封闭形式奖励质心的逆强化学习泛化行为-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12010">#79</a> <a href="https://papers.cool/arxiv/2509.12010">通过具有封闭形式奖励质心的逆强化学习泛化行为</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#80-文本适应通俗易懂的语言并通过自动译后编辑周期轻松阅读-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11991">#80</a> <a href="https://papers.cool/arxiv/2509.11991">文本适应通俗易懂的语言，并通过自动译后编辑周期轻松阅读</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#81-poison-to-detect联邦学习中靶向过拟合的检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11974">#81</a> <a href="https://papers.cool/arxiv/2509.11974">Poison to Detect：联邦学习中靶向过拟合的检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#82-用于自动化漏洞测试的时间受限智能对手多机器人巡逻案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11971">#82</a> <a href="https://papers.cool/arxiv/2509.11971">用于自动化漏洞测试的时间受限智能对手：多机器人巡逻案例研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#83-基于-gpu-加速的-rag-电报助手用于支持并行处理学生-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11947">#83</a> <a href="https://papers.cool/arxiv/2509.11947">基于 GPU 加速的 RAG 电报助手，用于支持并行处理学生</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#84-visdocsketcher使用代理系统实现可扩展的可视化文档-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11942">#84</a> <a href="https://papers.cool/arxiv/2509.11942">VisDocSketcher：使用代理系统实现可扩展的可视化文档</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#85-mmore大规模多模态开放式-rag-和提取-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11937">#85</a> <a href="https://papers.cool/arxiv/2509.11937">MMORE：大规模多模态开放式 RAG 和提取</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#86-集成先验观测值以进行增量-3d-场景图预测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11895">#86</a> <a href="https://papers.cool/arxiv/2509.11895">集成先验观测值以进行增量 3D 场景图预测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#87-成长的视角使用大型语言模型对具身视角采取和内在叙事发展进行建模-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11868">#87</a> <a href="https://papers.cool/arxiv/2509.11868">成长的视角：使用大型语言模型对具身视角采取和内在叙事发展进行建模</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#88-tenma使用扩散变压器进行鲁棒的跨实施例机器人作-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11865">#88</a> <a href="https://papers.cool/arxiv/2509.11865">Tenma：使用扩散变压器进行鲁棒的跨实施例机器人作</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#89-连接视觉语言模型和视频问答的符号基础-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11862">#89</a> <a href="https://papers.cool/arxiv/2509.11862">连接视觉语言模型和视频问答的符号基础</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#90-高维空间中的概率鲁棒性分析在语义分割网络中的应用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11838">#90</a> <a href="https://papers.cool/arxiv/2509.11838">高维空间中的概率鲁棒性分析：在语义分割网络中的应用</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#91-文本条件人工智能生成音乐的数据驱动分析suno-和-udio-的案例研究-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11824">#91</a> <a href="https://papers.cool/arxiv/2509.11824">文本条件人工智能生成音乐的数据驱动分析：Suno 和 Udio 的案例研究</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#92-不相关表示的崩溃-cir-确保稳健且无中断的-llm-忘却-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11816">#92</a> <a href="https://papers.cool/arxiv/2509.11816">不相关表示的崩溃 （CIR） 确保稳健且无中断的 LLM 忘却</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#93-specvlm视觉语言模型中的快速推测解码-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11815">#93</a> <a href="https://papers.cool/arxiv/2509.11815">SpecVLM：视觉语言模型中的快速推测解码</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#94-弥合稀疏性和冗余之间的差距具有全局上下文的双解码框架用于地图推理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11731">#94</a> <a href="https://papers.cool/arxiv/2509.11731">弥合稀疏性和冗余之间的差距：具有全局上下文的双解码框架用于地图推理</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#95-机器人辅助手术的显微外科器械细分-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11727">#95</a> <a href="https://papers.cool/arxiv/2509.11727">机器人辅助手术的显微外科器械细分</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#96-coachme使用基于参考的教练指导生成模型解码运动元素-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11698">#96</a> <a href="https://papers.cool/arxiv/2509.11698">CoachMe：使用基于参考的教练指导生成模型解码运动元素</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#97-代码语义有帮助吗代码大语言模型基于执行跟踪信息的综合研究-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11686">#97</a> <a href="https://papers.cool/arxiv/2509.11686">代码语义有帮助吗？代码大语言模型基于执行跟踪信息的综合研究</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#98-paraeqsa并行和异步具身问题的调度和回答-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11663">#98</a> <a href="https://papers.cool/arxiv/2509.11663">ParaEQsA：并行和异步具身问题的调度和回答</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#99-mindvl迈向昇腾npu上多模态大语言模型的高效训练-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11662">#99</a> <a href="https://papers.cool/arxiv/2509.11662">MindVL：迈向昇腾NPU上多模态大语言模型的高效训练</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#100-dtgen基于生成式扩散的少样本数据增强用于细粒度脏餐具识别-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11661">#100</a> <a href="https://papers.cool/arxiv/2509.11661">DTGen：基于生成式扩散的少样本数据增强，用于细粒度脏餐具识别</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#101-mallm多智能体大型语言模型框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11656">#101</a> <a href="https://papers.cool/arxiv/2509.11656">MALLM：多智能体大型语言模型框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#102-ethicsmh心理健康人工智能伦理推理的试点基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11648">#102</a> <a href="https://papers.cool/arxiv/2509.11648">EthicsMH：心理健康人工智能伦理推理的试点基准</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#103-用于鲁棒语义通信的与任务无关的可学习加权知识库方案-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11636">#103</a> <a href="https://papers.cool/arxiv/2509.11636">用于鲁棒语义通信的与任务无关的可学习加权知识库方案</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#104-合理的安全调整通过回答后检查确保越狱防御-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11629">#104</a> <a href="https://papers.cool/arxiv/2509.11629">合理的安全调整：通过“回答后检查”确保越狱防御</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#105-speca使用推测特征缓存加速扩散变压器-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11628">#105</a> <a href="https://papers.cool/arxiv/2509.11628">SpeCa：使用推测特征缓存加速扩散变压器</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#106-自动创建和扩充框架用于改进企业-api-作为工具的调用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11626">#106</a> <a href="https://papers.cool/arxiv/2509.11626">自动创建和扩充框架，用于改进企业 API 作为工具的调用</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#107-对测试时隐私产生不确定性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11625">#107</a> <a href="https://papers.cool/arxiv/2509.11625">对测试时隐私产生不确定性</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#108-用于网络状态分类的时态和跨变量模式的动态自适应解析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11601">#108</a> <a href="https://papers.cool/arxiv/2509.11601">用于网络状态分类的时态和跨变量模式的动态自适应解析</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#109-gbpp通过两阶段学习为机器人提供可把握的碱基放置预测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11594">#109</a> <a href="https://papers.cool/arxiv/2509.11594">GBPP：通过两阶段学习为机器人提供可把握的碱基放置预测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#110-无监督可见红外人再识别的分层身份学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11587">#110</a> <a href="https://papers.cool/arxiv/2509.11587">无监督可见红外人再识别的分层身份学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#111-dstack机密容器的零信任框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11555">#111</a> <a href="https://papers.cool/arxiv/2509.11555">Dstack：机密容器的零信任框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#112-hichunk使用分层分块评估和增强检索增强生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11552">#112</a> <a href="https://papers.cool/arxiv/2509.11552">HiChunk：使用分层分块评估和增强检索增强生成</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#113-ui-s1通过半在线强化学习推进-gui-自动化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11543">#113</a> <a href="https://papers.cool/arxiv/2509.11543">UI-S1：通过半在线强化学习推进 GUI 自动化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#114-harp通过推理子空间投影进行幻觉检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11536">#114</a> <a href="https://papers.cool/arxiv/2509.11536">HARP：通过推理子空间投影进行幻觉检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#115-知道你不知道什么提前退出-dnn-的选择性预测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11520">#115</a> <a href="https://papers.cool/arxiv/2509.11520">知道你不知道什么：提前退出 DNN 的选择性预测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#116-通过整体句子语义进行词汇替换的无监督候选人排名-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11513">#116</a> <a href="https://papers.cool/arxiv/2509.11513">通过整体句子语义进行词汇替换的无监督候选人排名</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#117-复杂科学工作流程中机器学习驱动的预测性资源管理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11512">#117</a> <a href="https://papers.cool/arxiv/2509.11512">复杂科学工作流程中机器学习驱动的预测性资源管理</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#118-checkthat-的-claimiq2025-年比较用于验证数字声明的提示和微调语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11492">#118</a> <a href="https://papers.cool/arxiv/2509.11492">CheckThat 的 ClaimIQ！2025 年：比较用于验证数字声明的提示和微调语言模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#119-raptor四旋翼控制的基础政策-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11481">#119</a> <a href="https://papers.cool/arxiv/2509.11481">RAPTOR：四旋翼控制的基础政策</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#120-设计和评估用于早期检测阿尔茨海默病和相关痴呆症的对话代理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11478">#120</a> <a href="https://papers.cool/arxiv/2509.11478">设计和评估用于早期检测阿尔茨海默病和相关痴呆症的对话代理</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#121-careerpooler人工智能驱动的隐喻池模拟改善职业探索的体验和成果-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11461">#121</a> <a href="https://papers.cool/arxiv/2509.11461">CareerPooler：人工智能驱动的隐喻池模拟改善职业探索的体验和成果</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#122-超越帧跟踪基于轨迹的高效点云跟踪范式-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11453">#122</a> <a href="https://papers.cool/arxiv/2509.11453">超越帧跟踪：基于轨迹的高效点云跟踪范式</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#123-类不平衡的表格数据使用预训练变压器-tabpfn-和基于-mamba-的模型预测电动汽车碰撞严重程度-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11449">#123</a> <a href="https://papers.cool/arxiv/2509.11449">类不平衡的表格数据：使用预训练变压器 （TabPFN） 和基于 Mamba 的模型预测电动汽车碰撞严重程度</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#124-fusecodec神经编解码器的语义上下文融合和监督-pdf1-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11425">#124</a> <a href="https://papers.cool/arxiv/2509.11425">FuseCodec：神经编解码器的语义上下文融合和监督</a> [PDF1] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#125-trading-r1通过强化学习使用-llm-推理进行金融交易-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11420">#125</a> <a href="https://papers.cool/arxiv/2509.11420">Trading-R1：通过强化学习使用 LLM 推理进行金融交易</a> [PDF2] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#126-通过保留预训练的表示来增强视觉-语言-行动模型的泛化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11417">#126</a> <a href="https://papers.cool/arxiv/2509.11417">通过保留预训练的表示来增强视觉-语言-行动模型的泛化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#127-将-ai-系统基准测试视为一项学习任务flexbench-和开放-mlperf-数据集-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11413">#127</a> <a href="https://papers.cool/arxiv/2509.11413">将 AI 系统基准测试视为一项学习任务：FlexBench 和开放 MLPerf 数据集</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#128-从防火墙到前沿人工智能红队是网络红队的特定领域演变-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11398">#128</a> <a href="https://papers.cool/arxiv/2509.11398">从防火墙到前沿：人工智能红队是网络红队的特定领域演变</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#129-智能油藏决策支持结合大语言模型高级提示工程和多模态数据融合的集成框架用于石油实时运营-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11376">#129</a> <a href="https://papers.cool/arxiv/2509.11376">智能油藏决策支持：结合大语言模型、高级提示工程和多模态数据融合的集成框架，用于石油实时运营</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#130-transformer-增强关系分类上下文性数据效率和序列复杂度的比较分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11374">#130</a> <a href="https://papers.cool/arxiv/2509.11374">Transformer 增强关系分类：上下文性、数据效率和序列复杂度的比较分析</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#131-使用编辑作测量值检测非平稳环境中的模型漂移-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11367">#131</a> <a href="https://papers.cool/arxiv/2509.11367">使用编辑作测量值检测非平稳环境中的模型漂移</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#132-促进-cnn-中的形状偏差基于频率和对比正则化以实现腐败鲁棒性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11355">#132</a> <a href="https://papers.cool/arxiv/2509.11355">促进 CNN 中的形状偏差：基于频率和对比正则化以实现腐败鲁棒性</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#133-人工智能治理的五层框架整合监管标准和认证-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11332">#133</a> <a href="https://papers.cool/arxiv/2509.11332">人工智能治理的五层框架：整合监管、标准和认证</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#134-使用kalmannet进行多目标跟踪的运动估计与语义无关的编码-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11323">#134</a> <a href="https://papers.cool/arxiv/2509.11323">使用KalmanNet进行多目标跟踪的运动估计，与语义无关的编码</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#135-通过多实例学习进行弱监督漏洞定位-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11312">#135</a> <a href="https://papers.cool/arxiv/2509.11312">通过多实例学习进行弱监督漏洞定位</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#136-opalrlhf-的算子代数视图-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11298">#136</a> <a href="https://papers.cool/arxiv/2509.11298">Opal：RLHF 的算子代数视图</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#137-社交机器人主导物理治疗的政策学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11297">#137</a> <a href="https://papers.cool/arxiv/2509.11297">社交机器人主导物理治疗的政策学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#138-能源感知-6g-网络设计一项调查-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11289">#138</a> <a href="https://papers.cool/arxiv/2509.11289">能源感知 6G 网络设计：一项调查</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#139-神经网络增量类学习的高效单步框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11285">#139</a> <a href="https://papers.cool/arxiv/2509.11285">神经网络增量类学习的高效单步框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#140-分解中的具身智能神经符号-tamp-中的多模态感知交叉验证和持续学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11270">#140</a> <a href="https://papers.cool/arxiv/2509.11270">分解中的具身智能：神经符号 TAMP 中的多模态感知交叉验证和持续学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#141-使用-tabpfn-进行无梯度深度强化学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11259">#141</a> <a href="https://papers.cool/arxiv/2509.11259">使用 TabPFN 进行无梯度深度强化学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#142-超越自回归用于代码生成的扩散大型语言模型的实证研究-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11252">#142</a> <a href="https://papers.cool/arxiv/2509.11252">超越自回归：用于代码生成的扩散大型语言模型的实证研究</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#143-transzero使用-transformer-网络在-muzero-中进行并行树扩展-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11233">#143</a> <a href="https://papers.cool/arxiv/2509.11233">TransZero：使用 Transformer 网络在 MuZero 中进行并行树扩展</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#144-mis-lstm用于睡眠质量和压力预测的多通道图像序列-lstm-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11232">#144</a> <a href="https://papers.cool/arxiv/2509.11232">MIS-LSTM：用于睡眠质量和压力预测的多通道图像序列 LSTM</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#145-membot间歇性pomdp中基于内存的机器人-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11225">#145</a> <a href="https://papers.cool/arxiv/2509.11225">MEMBOT：间歇性POMDP中基于内存的机器人</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#146-几何约束和基于标记的概率空间转换器-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11218">#146</a> <a href="https://papers.cool/arxiv/2509.11218">几何约束和基于标记的概率空间转换器</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#147-evalet通过将输出碎片化为函数来评估大型语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11206">#147</a> <a href="https://papers.cool/arxiv/2509.11206">Evalet：通过将输出碎片化为函数来评估大型语言模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#148-用于解决量子机器学习任务的量子架构搜索-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11198">#148</a> <a href="https://papers.cool/arxiv/2509.11198">用于解决量子机器学习任务的量子架构搜索</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#149-dreamnav用于零样本视觉和语言导航的基于轨迹的想象力框架-pdf1-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11197">#149</a> <a href="https://papers.cool/arxiv/2509.11197">DreamNav：用于零样本视觉和语言导航的基于轨迹的想象力框架</a> [PDF1] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#150-面向电子商务平台的数据估值联合推荐系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11196">#150</a> <a href="https://papers.cool/arxiv/2509.11196">面向电子商务平台的数据估值联合推荐系统</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#151-研究变分量子电路的彩票假说-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11190">#151</a> <a href="https://papers.cool/arxiv/2509.11190">研究变分量子电路的彩票假说</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#152-隐写术通过最佳传输进行隐写术的权衡-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11178">#152</a> <a href="https://papers.cool/arxiv/2509.11178">隐写术：通过最佳传输进行隐写术的权衡</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#153-差分私有文本生成会降低输出语言质量-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11176">#153</a> <a href="https://papers.cool/arxiv/2509.11176">差分私有文本生成会降低输出语言质量</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#154-您的编译器正在为您的模型提供后门了解和利用深度学习编译器中的编译不一致漏洞-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11173">#154</a> <a href="https://papers.cool/arxiv/2509.11173">您的编译器正在为您的模型提供后门：了解和利用深度学习编译器中的编译不一致漏洞</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#155-域偏移下数据高效声场景分类的熵引导课程学习策略-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11168">#155</a> <a href="https://papers.cool/arxiv/2509.11168">域偏移下数据高效声场景分类的熵引导课程学习策略</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#156-利用优化动力学进行曲率知情模型合并-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11167">#156</a> <a href="https://papers.cool/arxiv/2509.11167">利用优化动力学进行曲率知情模型合并</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#157-aqua通过-query-magnitudes-在-llm-中进行记忆和计算高效推理的注意力-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11155">#157</a> <a href="https://papers.cool/arxiv/2509.11155">AQUA：通过 QUery mAgnitudes 在 LLM 中进行记忆和计算高效推理的注意力</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#158-通过霍普金斯损耗控制特征空间拓扑-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11154">#158</a> <a href="https://papers.cool/arxiv/2509.11154">通过霍普金斯损耗控制特征空间拓扑</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#159-roverfly跨有效载荷配置的基于学习的四旋翼强大且多功能的控制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11149">#159</a> <a href="https://papers.cool/arxiv/2509.11149">RoVerFly：跨有效载荷配置的基于学习的四旋翼强大且多功能的控制</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#160-在线平台中的代理用户名建议和多模态性别检测介绍-pngt-26k-数据集-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11136">#160</a> <a href="https://papers.cool/arxiv/2509.11136">在线平台中的代理用户名建议和多模态性别检测：介绍 PNGT-26K 数据集</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#161-enj利用遗传算法优化噪声以越狱lsm-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11128">#161</a> <a href="https://papers.cool/arxiv/2509.11128">ENJ：利用遗传算法优化噪声以越狱LSM</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#162-我们主张同意迈向以个性驱动的基于论证的旅游谈判对话系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11118">#162</a> <a href="https://papers.cool/arxiv/2509.11118">我们主张同意：迈向以个性驱动的基于论证的旅游谈判对话系统</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#163-机器学习在纠正缺陷引起的神经形态电路推理错误中的应用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11113">#163</a> <a href="https://papers.cool/arxiv/2509.11113">机器学习在纠正缺陷引起的神经形态电路推理错误中的应用</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#164-用于与变压器的-v2v-通信的多模态传感辅助毫米波波束成形-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11112">#164</a> <a href="https://papers.cool/arxiv/2509.11112">用于与变压器的 V2V 通信的多模态传感辅助毫米波波束成形</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#165-流体语言模型基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11106">#165</a> <a href="https://papers.cool/arxiv/2509.11106">流体语言模型基准测试</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#166-panolora通过-lora-适配连接透视和全景视频生成-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11092">#166</a> <a href="https://papers.cool/arxiv/2509.11092">PanoLora：通过 LoRA 适配连接透视和全景视频生成</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#167-用于文本-语音对齐的长度感知旋转位置嵌入-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11084">#167</a> <a href="https://papers.cool/arxiv/2509.11084">用于文本-语音对齐的长度感知旋转位置嵌入</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#168-推荐系统成员推理攻击调查-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11080">#168</a> <a href="https://papers.cool/arxiv/2509.11080">推荐系统成员推理攻击：调查</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#169-cvpr-2024-自动驾驶大挑战赛语言驾驶赛道-cps-团队的系统描述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11071">#169</a> <a href="https://papers.cool/arxiv/2509.11071">CVPR 2024 自动驾驶大挑战赛语言驾驶赛道 CPS 团队的系统描述</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#170-一种用于有限数据下轴承故障诊断的先进卷积神经网络-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11053">#170</a> <a href="https://papers.cool/arxiv/2509.11053">一种用于有限数据下轴承故障诊断的先进卷积神经网络</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#171-fragmentgpt用于分子设计中片段生长链接和合并的统一-gpt-模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11044">#171</a> <a href="https://papers.cool/arxiv/2509.11044">FragmentGPT：用于分子设计中片段生长、链接和合并的统一 GPT 模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#172-硬度结构知识和机会模块化性能建模的分析框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11000">#172</a> <a href="https://papers.cool/arxiv/2509.11000">硬度、结构知识和机会：模块化性能建模的分析框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#173-配水管网泄漏定位的因子图优化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10982">#173</a> <a href="https://papers.cool/arxiv/2509.10982">配水管网泄漏定位的因子图优化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#174-神经网络训练中的解耦搜索和学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10973">#174</a> <a href="https://papers.cool/arxiv/2509.10973">神经网络训练中的解耦搜索和学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#175-phlora从全等级检查点提取无数据的事后低秩适配器-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10971">#175</a> <a href="https://papers.cool/arxiv/2509.10971">PHLoRA：从全等级检查点提取无数据的事后低秩适配器</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#176-心因性机器在大型语言模型中模拟人工智能精神病妄想强化和伤害支持-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10970">#176</a> <a href="https://papers.cool/arxiv/2509.10970">心因性机器：在大型语言模型中模拟人工智能精神病、妄想强化和伤害支持。</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#177-测试-llm-响应差异由语义上不相关的查询扰动组成的复合-null-的情况-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10963">#177</a> <a href="https://papers.cool/arxiv/2509.10963">测试 LLM 响应差异：由语义上不相关的查询扰动组成的复合 null 的情况</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#178-vistr-gp自动化机器人作中通过视觉到状态张量回归和高斯过程进行在线网络攻击检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10948">#178</a> <a href="https://papers.cool/arxiv/2509.10948">ViSTR-GP：自动化机器人作中通过视觉到状态张量回归和高斯过程进行在线网络攻击检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#179-当代码自动驾驶仪中断时为什么法学硕士在嵌入式机器学习中步履蹒跚-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10946">#179</a> <a href="https://papers.cool/arxiv/2509.10946">当代码自动驾驶仪中断时：为什么法学硕士在嵌入式机器学习中步履蹒跚</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#180-阐明模型透明度使用-mnist-和-imdb-示例进行深度学习中的可解释性与可解释性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10929">#180</a> <a href="https://papers.cool/arxiv/2509.10929">阐明模型透明度：使用 MNIST 和 IMDB 示例进行深度学习中的可解释性与可解释性</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#181-toma使用扩散模型生成图像的代币合并与注意力-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10918">#181</a> <a href="https://papers.cool/arxiv/2509.10918">ToMA：使用扩散模型生成图像的代币合并与注意力</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#182-culturesynth用于文化问答综合的分层分类学指导和检索增强框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10886">#182</a> <a href="https://papers.cool/arxiv/2509.10886">CultureSynth：用于文化问答综合的分层分类学指导和检索增强框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#183-分子预测的最佳消息传递是简单细心和空间的-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10871">#183</a> <a href="https://papers.cool/arxiv/2509.10871">分子预测的最佳消息传递是简单、细心和空间的</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#184-gthna用于整体节点异常评估的具有内存重建的局部-全局图转换器-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10869">#184</a> <a href="https://papers.cool/arxiv/2509.10869">GTHNA：用于整体节点异常评估的具有内存重建的局部-全局图转换器</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#185-物理信息神经网络求解弯曲时空中的最小曲面-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10866">#185</a> <a href="https://papers.cool/arxiv/2509.10866">物理信息神经网络求解弯曲时空中的最小曲面</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#186-安全运营中心的大型语言模型综合调查-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10858">#186</a> <a href="https://papers.cool/arxiv/2509.10858">安全运营中心的大型语言模型：综合调查</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#187-情景记忆的预存储推理将推理负担转移到记忆中以进行个性化对话-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10852">#187</a> <a href="https://papers.cool/arxiv/2509.10852">情景记忆的预存储推理：将推理负担转移到记忆中以进行个性化对话</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#188-有趣的伴侣对感知到的人工智能幽默与人类生成的幽默的不同神经反应-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10847">#188</a> <a href="https://papers.cool/arxiv/2509.10847">有趣的伴侣：对感知到的人工智能幽默与人类生成的幽默的不同神经反应</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#189-实现自动错误发现对话式人工智能研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10833">#189</a> <a href="https://papers.cool/arxiv/2509.10833">实现自动错误发现：对话式人工智能研究</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#190-因素使用风险感知评分进行互补双因素优化的阶乘近似-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10825">#190</a> <a href="https://papers.cool/arxiv/2509.10825">因素：使用风险感知评分进行互补双因素优化的阶乘近似</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#191-重新思考稀疏自动编码器仅从编码器功能中实现公平性和控制的选择和投影-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10809">#191</a> <a href="https://papers.cool/arxiv/2509.10809">重新思考稀疏自动编码器：仅从编码器功能中实现公平性和控制的选择和投影</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#192-基于卫星影像和时间序列分析的番茄农场分枝扫帚检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10804">#192</a> <a href="https://papers.cool/arxiv/2509.10804">基于卫星影像和时间序列分析的番茄农场分枝扫帚检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#193-judge-qkv-缓存驱逐中优化信息保留的可训练查询-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10798">#193</a> <a href="https://papers.cool/arxiv/2509.10798">Judge Q：KV 缓存驱逐中优化信息保留的可训练查询</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#194-goldentransformer用于变压器鲁棒性研究的模块化故障注入框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10790">#194</a> <a href="https://papers.cool/arxiv/2509.10790">GoldenTransformer：用于变压器鲁棒性研究的模块化故障注入框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#195-弥合默认模式与当地课堂需求之间的文化距离全球教师如何采用-genai-来支持日常教学实践-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10780">#195</a> <a href="https://papers.cool/arxiv/2509.10780">弥合默认模式与当地课堂需求之间的文化距离：全球教师如何采用 GenAI 来支持日常教学实践</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#196-食品救援志愿者参与的情境预算强盗-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10777">#196</a> <a href="https://papers.cool/arxiv/2509.10777">食品救援志愿者参与的情境预算强盗</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#197-用于保护图像归属的内容相关水印-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10766">#197</a> <a href="https://papers.cool/arxiv/2509.10766">用于保护图像归属的内容相关水印</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#198-hallufield通过场论建模检测-llm-幻觉-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10753">#198</a> <a href="https://papers.cool/arxiv/2509.10753">HalluField：通过场论建模检测 LLM 幻觉</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#199-大规模自动化-mcqa-基准测试评估推理轨迹作为小型语言模型领域适配的检索源-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10744">#199</a> <a href="https://papers.cool/arxiv/2509.10744">大规模自动化 MCQA 基准测试：评估推理轨迹作为小型语言模型领域适配的检索源</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#200-暗模式遇见-gui-代理llm-代理对纵界面的敏感性和人类监督的作用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10723">#200</a> <a href="https://papers.cool/arxiv/2509.10723">暗模式遇见 GUI 代理：LLM 代理对纵界面的敏感性和人类监督的作用</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#201-kalman-bayesian-transformer-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10695">#201</a> <a href="https://papers.cool/arxiv/2509.10695">Kalman Bayesian Transformer</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#202-通过度量值近端优化学习在线拍卖中的凹面出价着色策略-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10693">#202</a> <a href="https://papers.cool/arxiv/2509.10693">通过度量值近端优化学习在线拍卖中的凹面出价着色策略</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#203-通过可解释的自适应差分隐私保护隐私的去中心化联邦学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10691">#203</a> <a href="https://papers.cool/arxiv/2509.10691">通过可解释的自适应差分隐私保护隐私的去中心化联邦学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#204-医疗保健的多元调整角色驱动的框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10685">#204</a> <a href="https://papers.cool/arxiv/2509.10685">医疗保健的多元调整：角色驱动的框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#205-微调卷积神经网络与大型语言模型在mri上脑肿瘤图像分类和分割的比较与评价-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10683">#205</a> <a href="https://papers.cool/arxiv/2509.10683">微调卷积神经网络与大型语言模型在MRI上脑肿瘤图像分类和分割的比较与评价</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#206-中间的法学硕士对现实世界基于法学硕士的系统的威胁和缓解措施的系统回顾-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10682">#206</a> <a href="https://papers.cool/arxiv/2509.10682">中间的法学硕士：对现实世界基于法学硕士的系统的威胁和缓解措施的系统回顾</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#207-多智能体合作与探索中的自监督目标达标结果-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10656">#207</a> <a href="https://papers.cool/arxiv/2509.10656">多智能体合作与探索中的自监督目标达标结果</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#208-scor数字生态系统中负责任的人工智能创新框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10653">#208</a> <a href="https://papers.cool/arxiv/2509.10653">SCOR：数字生态系统中负责任的人工智能创新框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#209-用户体验设计的氛围编码了解用户体验专业人士对人工智能辅助设计和开发的看法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10652">#209</a> <a href="https://papers.cool/arxiv/2509.10652">用户体验设计的氛围编码：了解用户体验专业人士对人工智能辅助设计和开发的看法</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#210-多模态大型语言模型的测试时间预热-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10641">#210</a> <a href="https://papers.cool/arxiv/2509.10641">多模态大型语言模型的测试时间预热</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#211-最优多边薛定谔桥测量值顶点上的最小生成树-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10626">#211</a> <a href="https://papers.cool/arxiv/2509.10626">最优多边薛定谔桥：测量值顶点上的最小生成树</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#212-无需回答从纯问题线性探针预测-llm-答案准确性-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10625">#212</a> <a href="https://papers.cool/arxiv/2509.10625">无需回答：从纯问题线性探针预测 LLM 答案准确性</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
    <li><a href="#213-国家跑步俱乐部数据库评估大学俱乐部运动员的越野比赛成绩-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10600">#213</a> <a href="https://papers.cool/arxiv/2509.10600">国家跑步俱乐部数据库：评估大学俱乐部运动员的越野比赛成绩</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#214-编程教育中的-genai-语音模式-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10596">#214</a> <a href="https://papers.cool/arxiv/2509.10596">编程教育中的 GenAI 语音模式</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#215-sme-team利用信任和道德在中小企业中安全负责任地使用人工智能和法学硕士-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10594">#215</a> <a href="https://papers.cool/arxiv/2509.10594">SME-TEAM：利用信任和道德在中小企业中安全、负责任地使用人工智能和法学硕士</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#216-使用人工智能协助手写普通化学考试的评分-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10591">#216</a> <a href="https://papers.cool/arxiv/2509.10591">使用人工智能协助手写普通化学考试的评分</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#217-机器学习在教育中实现负责任和自适应的人工智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10590">#217</a> <a href="https://papers.cool/arxiv/2509.10590">机器学习在教育中实现负责任和自适应的人工智能</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#218-智能试验评估使用大型语言模型通过社交媒体招募临床试验参与者-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10584">#218</a> <a href="https://papers.cool/arxiv/2509.10584">智能试验：评估使用大型语言模型通过社交媒体招募临床试验参与者</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#219-learnlens一个人工智能增强的仪表板为开放式课堂中的教师提供支持-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10582">#219</a> <a href="https://papers.cool/arxiv/2509.10582">LearnLens：一个人工智能增强的仪表板，为开放式课堂中的教师提供支持</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#220-生成模型鲁棒水印的编码限制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10577">#220</a> <a href="https://papers.cool/arxiv/2509.10577">生成模型鲁棒水印的编码限制</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#221-与生成式人工智能共同创造艺术的审美体验和教育价值来自年轻学习者调查的证据-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10576">#221</a> <a href="https://papers.cool/arxiv/2509.10576">与生成式人工智能共同创造艺术的审美体验和教育价值：来自年轻学习者调查的证据</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#222-gene-r1使用数据增强的轻量级-llm-进行基因集分析的推理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10575">#222</a> <a href="https://papers.cool/arxiv/2509.10575">Gene-R1：使用数据增强的轻量级 LLM 进行基因集分析的推理</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#223-使用大型语言模型和代码生成对表格数据进行质量评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10572">#223</a> <a href="https://papers.cool/arxiv/2509.10572">使用大型语言模型和代码生成对表格数据进行质量评估</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#224-自动驾驶轨迹预测大基础模型综合综述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10570">#224</a> <a href="https://papers.cool/arxiv/2509.10570">自动驾驶轨迹预测大基础模型：综合综述</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#225-markdiffusion用于潜在扩散模型生成水印的开源工具包-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10569">#225</a> <a href="https://papers.cool/arxiv/2509.10569">MarkDiffusion：用于潜在扩散模型生成水印的开源工具包</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#226-avec本地法学硕士的引导隐私-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10561">#226</a> <a href="https://papers.cool/arxiv/2509.10561">AVEC：本地法学硕士的引导隐私</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#227-脑部疾病的生物标志物-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10547">#227</a> <a href="https://papers.cool/arxiv/2509.10547">脑部疾病的生物标志物</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#228-通过风险隐瞒揭示金融领域大语言模型的脆弱性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10546">#228</a> <a href="https://papers.cool/arxiv/2509.10546">通过风险隐瞒揭示金融领域大语言模型的脆弱性</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#229-asl360通过无人机辅助无线网络实现-ai-支持的分层-360-视频自适应流-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10544">#229</a> <a href="https://papers.cool/arxiv/2509.10544">ASL360：通过无人机辅助无线网络实现 AI 支持的分层 360° 视频自适应流</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#230-使用3d-cnn对抗性方法进行稳健的ddos攻击分类-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10543">#230</a> <a href="https://papers.cool/arxiv/2509.10543">使用3D CNN对抗性方法进行稳健的DDoS攻击分类</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#231-echoleak生产-llm-系统中第一个真实世界的零点击提示注入漏洞-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10540">#231</a> <a href="https://papers.cool/arxiv/2509.10540">EchoLeak：生产 LLM 系统中第一个真实世界的零点击提示注入漏洞</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#232-dualalign生成基于临床的合成数据-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10538">#232</a> <a href="https://papers.cool/arxiv/2509.10538">DualAlign：生成基于临床的合成数据</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#233-关于在联邦学习中使用大批量-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10537">#233</a> <a href="https://papers.cool/arxiv/2509.10537">关于在联邦学习中使用大批量</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#234-语义引导的-lora-参数生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10535">#234</a> <a href="https://papers.cool/arxiv/2509.10535">语义引导的 LoRA 参数生成</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#235-使用极坐标位置嵌入解耦什么和在哪里-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10534">#235</a> <a href="https://papers.cool/arxiv/2509.10534">使用极坐标位置嵌入解耦“什么”和“在哪里”</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#236-finxplore用于平衡和发现投资机会的自适应深度强化学习框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10531">#236</a> <a href="https://papers.cool/arxiv/2509.10531">FinXplore：用于平衡和发现投资机会的自适应深度强化学习框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#237-动态自适应共享专家与专家的分组多头注意力混合-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10530">#237</a> <a href="https://papers.cool/arxiv/2509.10530">动态自适应共享专家与专家的分组多头注意力混合</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#238-通过潜在回放减轻文本到图像扩散中的灾难性遗忘和模式崩溃-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10529">#238</a> <a href="https://papers.cool/arxiv/2509.10529">通过潜在回放减轻文本到图像扩散中的灾难性遗忘和模式崩溃</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#239-stm-graph用于时空映射和图神经网络预测的-python-框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10528">#239</a> <a href="https://papers.cool/arxiv/2509.10528">STM-Graph：用于时空映射和图神经网络预测的 Python 框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#240-基于图的强化学习的资源感知神经网络剪枝-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10526">#240</a> <a href="https://papers.cool/arxiv/2509.10526">基于图的强化学习的资源感知神经网络剪枝</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#241-通过频率增强脑网络上的自监督学习进行数据高效的精神疾病检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10524">#241</a> <a href="https://papers.cool/arxiv/2509.10524">通过频率增强脑网络上的自监督学习进行数据高效的精神疾病检测</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#242-从预测到解释用于自闭症诊断和关键大脑区域识别的可解释人工智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10523">#242</a> <a href="https://papers.cool/arxiv/2509.10523">从预测到解释：用于自闭症诊断和关键大脑区域识别的可解释人工智能</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#243-用于-atco-命令生命周期建模和工作负载预测的多模态深度学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10522">#243</a> <a href="https://papers.cool/arxiv/2509.10522">用于 ATCO 命令生命周期建模和工作负载预测的多模态深度学习</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#244-异质性和不平衡临床数据死亡率预测的联邦学习策略的比较基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10517">#244</a> <a href="https://papers.cool/arxiv/2509.10517">异质性和不平衡临床数据死亡率预测的联邦学习策略的比较基准</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#245-教育中的隐私保护个性化用于学生表现预测的联合推荐系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10516">#245</a> <a href="https://papers.cool/arxiv/2509.10516">教育中的隐私保护个性化：用于学生表现预测的联合推荐系统</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#246-logguardq用于安全日志中网络安全异常检测的认知增强强化学习框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10511">#246</a> <a href="https://papers.cool/arxiv/2509.10511">LogGuardQ：用于安全日志中网络安全异常检测的认知增强强化学习框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#247-firegnn具有可训练模糊规则的神经符号图神经网络用于可解释的医学图像分类-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10510">#247</a> <a href="https://papers.cool/arxiv/2509.10510">FireGNN：具有可训练模糊规则的神经符号图神经网络，用于可解释的医学图像分类</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#248-反衔尾蛇效应递归选择性反馈对大型语言模型的涌现弹性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10509">#248</a> <a href="https://papers.cool/arxiv/2509.10509">反衔尾蛇效应：递归选择性反馈对大型语言模型的涌现弹性</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#249-car-brainet用于异构车联网的sub-6ghz辅助空间自适应波束预测具有多头注意力-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10508">#249</a> <a href="https://papers.cool/arxiv/2509.10508">CAR-BRAINet：用于异构车联网的Sub-6GHz辅助空间自适应波束预测，具有多头注意力</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#250-面向去中心化异构平台的智能物联网框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10507">#250</a> <a href="https://papers.cool/arxiv/2509.10507">面向去中心化异构平台的智能物联网框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#251-树结构mdp中通过最差路径策略优化进行逆合成规划-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10504">#251</a> <a href="https://papers.cool/arxiv/2509.10504">树结构MDP中通过最差路径策略优化进行逆合成规划</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#252-fedexchange免费弥合联合对象检测中的域差距-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10503">#252</a> <a href="https://papers.cool/arxiv/2509.10503">FEDEXCHANGE：免费弥合联合对象检测中的域差距</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#253-从噪声到精度一种扩散驱动的零膨胀降水预测方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10501">#253</a> <a href="https://papers.cool/arxiv/2509.10501">从噪声到精度：一种扩散驱动的零膨胀降水预测方法</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#254-迈向可扩展的o-ran资源管理图增强的近端策略优化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10499">#254</a> <a href="https://papers.cool/arxiv/2509.10499">迈向可扩展的O-RAN资源管理：图增强的近端策略优化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#255-基于在线学习的lorawan网络高效资源分配-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10493">#255</a> <a href="https://papers.cool/arxiv/2509.10493">基于在线学习的LoRaWAN网络高效资源分配</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#256-分布式gossip-gan在fdd-mmimo-ofdm系统中进行低开销csi反馈训练-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10490">#256</a> <a href="https://papers.cool/arxiv/2509.10490">分布式Gossip-GAN在FDD mMIMO-OFDM系统中进行低开销CSI反馈训练</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#257-sabr使用行为克隆预训练和强化学习微调的稳定自适应比特率框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10486">#257</a> <a href="https://papers.cool/arxiv/2509.10486">SABR：使用行为克隆预训练和强化学习微调的稳定自适应比特率框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#258-aegisshield利用生成式人工智能实现网络威胁建模民主化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10482">#258</a> <a href="https://papers.cool/arxiv/2509.10482">AegisShield：利用生成式人工智能实现网络威胁建模民主化</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#259-用于识别供应链漏洞的实时-rag-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10469">#259</a> <a href="https://papers.cool/arxiv/2509.10469">用于识别供应链漏洞的实时 RAG</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#260-从预训练和协作信号中学习分解的上下文标记表示以进行生成推荐-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10468">#260</a> <a href="https://papers.cool/arxiv/2509.10468">从预训练和协作信号中学习分解的上下文标记表示，以进行生成推荐</a> [PDF1] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#261-dsrag基于文档衍生多模态知识图谱的领域特定检索框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10467">#261</a> <a href="https://papers.cool/arxiv/2509.10467">DSRAG：基于文档衍生多模态知识图谱的领域特定检索框架</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#262-基于收敛优化的动量集成多任务股票推荐-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10461">#262</a> <a href="https://papers.cool/arxiv/2509.10461">基于收敛优化的动量集成多任务股票推荐</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#263-在正确的水平上说话使用-rag-rl-进行识字控制的反语音生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.01058">#263</a> <a href="https://papers.cool/arxiv/2509.01058">在正确的水平上说话：使用 RAG-RL 进行识字控制的反语音生成</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#264-用于一致危机响应的动态融合模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.01053">#264</a> <a href="https://papers.cool/arxiv/2509.01053">用于一致危机响应的动态融合模型</a> [PDF] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#265-用于自动程序转换的程序骨架-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2504.07483">#265</a> <a href="https://papers.cool/arxiv/2504.07483">用于自动程序转换的程序骨架</a> [PDF2] [Copy] [Kimi] [REL]</a></li>
    <li><a href="#266-使用深度卷积神经网络进行音频分类的频谱和节奏特征-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2410.06927">#266</a> <a href="https://papers.cool/arxiv/2410.06927">使用深度卷积神经网络进行音频分类的频谱和节奏特征</a> [PDF] [Copy] [Kimi1] [REL]</a></li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h1 id="2025-09-16科研追新">2025-09-16科研追新</h1>
<h1 id="1-源数据">1. 源数据</h1>
<h1 id="11-媒体">1.1 媒体</h1>
<p><strong>From</strong>：量子位、机器之心、新智元、AGI Hunt、小红书、X其他</p>
<ol>
<li>
<h5 id="顶级大模型在aai提出的formulaone基准集体翻车三层难度递进gpt-5进阶题仅约4正确最深层零分grok-4o3-pro全部失手该基准以图上mso逻辑与动态规划生成问题贴近路径规划等现实优化旨在衡量超越竞赛编程的算法推理深度"><a href="https://mp.weixin.qq.com/s/E4LilyWcLgb-H6SFWI8oew"target="_blank" rel="external nofollow noopener noreferrer">顶级大模型在AAI提出的FormulaOne基准集体翻车：三层难度递进，GPT-5进阶题仅约4%正确，最深层零分；Grok 4、o3 Pro全部失手。该基准以图上MSO逻辑与动态规划生成问题，贴近路径规划等现实优化，旨在衡量超越竞赛编程的算法推理深度。</a></h5>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/6pt632HiyIqGfoJs__kNsA"target="_blank" rel="external nofollow noopener noreferrer"><strong>GPT-5-Codex</strong>特化版模型，支持<strong>独立连续编程7个小时</strong>。</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/WUw7Mu0duQ7qGWjZ0Ew5Xg"target="_blank" rel="external nofollow noopener noreferrer"><strong>如今的AI还不具备真正的创造力，因为它还无法提出新的猜想或新的假设</strong>。</a>它或许能够证明你提供给它的某些东西，但它本身无法提出新的想法或理论。这实际上将成为衡量AGI是否成熟的关键测试之一。</p>
<ol>
<li>**AI 能否创造出像围棋这样复杂而优雅的游戏本身？**答案目前是否定的。</li>
<li><a href="https://mp.weixin.qq.com/s/WCR08JiYYeXDFrgPWGkytg"target="_blank" rel="external nofollow noopener noreferrer">Google DeepMind CEO Hassabis 最新访谈：未来十年实现完整 AGI，引领科学黄金时代</a></li>
</ol>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/5TRim0q2ZI-b-LFXGJaKmA"target="_blank" rel="external nofollow noopener noreferrer">xAI发布<strong>Grok 4 Fast</strong>，生成速度高达每秒<strong>75</strong>个 token</a></p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/8oexpVDLJ8mRtcL59YpGjA"target="_blank" rel="external nofollow noopener noreferrer">只要科学任务可以评分，AI就能找到超越人类专家的方法，实现SOTA结果？</a></p>
<p>这是谷歌一篇最新论文里的内容：</p>
<p>使用大模型+树搜索，让AI大海捞针就行。</p>
</li>
<li>
<p><a href="https://mp.weixin.qq.com/s/AGOpqaDEPA11tIzQRPX8ew"target="_blank" rel="external nofollow noopener noreferrer">反转！LeCun刚转发「全球最快开源推理模型」，ETH苏黎世就直接打假</a></p>
</li>
</ol>
<h1 id="12-arxiv">1.2 Arxiv</h1>
<h1 id="121-computation-and-language">1.2.1 Computation and Language</h1>
<p><strong>From：</strong><a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">https:// /arxiv/cs.CL</a><a href="https://arxiv.org/list/cs.CL/recent"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/list/cs.CL/recent</a></p>
<p>2025-09-16 |   | Total: 129</p>
<h2 id="1-语音感知大型语言模型中语言理解能力的保留-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12171"target="_blank" rel="external nofollow noopener noreferrer">#1</a> <a href="https://papers.cool/arxiv/2509.12171"target="_blank" rel="external nofollow noopener noreferrer">语音感知大型语言模型中语言理解能力的保留</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Marek Kubis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marek</a> Kubis), [Paweł Skórzewski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pawe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pawe</a>ł Skórzewski), [Iwona Christop](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iwona"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iwona</a> Christop), [Mateusz Czyżnikiewicz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mateusz"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mateusz</a> Czyżnikiewicz), [Jakub Kubiak](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jakub"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jakub</a> Kubiak), [Łukasz Bondaruk](<a href="https://arxiv.org/search/?searchtype=author&amp;query="target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=</a>Łukasz Bondaruk), [Marcin Lewandowski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marcin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marcin</a> Lewandowski)</p>
<p>该论文提出了 C3T（跨模态能力保护测试），这是评估语音感知大型语言模型性能的新基准。该基准测试利用文本任务和语音克隆文本转语音模型来量化通过语音输入访问模型时语言理解能力的保留程度。C3T 量化了模型对不同类别说话者的公平性及其跨文本和语音模态的稳健性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：34：45 UTC</p>
<h2 id="2-rags-to-riches大型语言模型角色扮演的类似-rag-的少样本学习-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12168"target="_blank" rel="external nofollow noopener noreferrer">#2</a> <a href="https://papers.cool/arxiv/2509.12168"target="_blank" rel="external nofollow noopener noreferrer">RAGs to Riches：大型语言模型角色扮演的类似 RAG 的少样本学习</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Timothy Rupprecht](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Timothy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Timothy</a> Rupprecht), [Enfu Nan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Enfu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Enfu</a> Nan), [Arash Akbari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arash"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arash</a> Akbari), [Arman Akbari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arman</a> Akbari), [Lei Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lei</a> Lu), [Priyanka Maan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Priyanka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Priyanka</a> Maan), [Sean Duffy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sean"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sean</a> Duffy), [Pu Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pu</a> Zhao), [Yumei He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yumei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yumei</a> He), [David Kaeli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Kaeli), [Yanzhi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanzhi</a> Wang)</p>
<p>角色扮演大型语言模型 （LLM） 越来越多地部署在医疗保健、教育和治理等高风险领域，在这些领域，故障可能会直接影响用户的信任和福祉。LLM 角色扮演的一种具有成本效益的范式是少样本学习，但现有方法通常会导致模型以意想不到的和潜在有害的方式破坏角色，尤其是在与敌对用户交互时。受检索增强生成（RAG）的启发，我们将LLM角色扮演重新表述为文本检索问题，并提出了一种名为RAGs-to-Riches的新提示框架，该框架利用精心策划的参考演示来调节LLM响应。我们通过 LLM-as-a-judge 偏好投票来评估我们的框架，并引入了两个新颖的代币级 ROUGE 指标：Intersection over Output （IOO） 用于量化 LLM 即兴创作的量，以及 Intersection over References （IOR） 用于衡量评估任务期间的少镜头演示利用率。在模拟与敌对用户的交互时，我们的提示策略在推理过程中的响应中包含来自参考演示的标记平均多 35%。因此，在 453 次角色扮演交互中，我们的模型始终被判断为比零样本和上下文学习 （ICL） 方法更真实，并且更频繁地保持角色。我们的方法提出了一种可扩展的策略，用于构建强大的、与人类一致的 LLM 角色扮演框架。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：31：15 世界标准时间</p>
<h2 id="3-双关语法学硕士和幽默理解的错觉-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12158"target="_blank" rel="external nofollow noopener noreferrer">#3</a> <a href="https://papers.cool/arxiv/2509.12158"target="_blank" rel="external nofollow noopener noreferrer">双关语：法学硕士和幽默理解的错觉</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alessandro Zangari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alessandro"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alessandro</a> Zangari), [Matteo Marcuzzo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matteo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matteo</a> Marcuzzo), [Andrea Albarelli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrea"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrea</a> Albarelli), [Mohammad Taher Pilehvar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohammad</a> Taher Pilehvar), [Jose Camacho-Collados](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jose"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jose</a> Camacho-Collados)</p>
<p>双关语是一种利用多义性和语音相似性的幽默双关语。虽然法学硕士在检测双关语方面显示出希望，但我们在本文中表明，他们的理解往往仍然很浅薄，缺乏人类解释典型的细致入微的把握。通过系统地分析和重新制定现有的双关语基准，我们展示了双关语的细微变化如何足以误导法学硕士。我们的贡献包括全面而细致的双关语检测基准、对最近 LLM 的人工评估，以及对这些模型在处理双关语时面临的稳健性挑战的分析。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：22：30 UTC</p>
<h2 id="4-checkthat的xplainlp2025-年使用微调-transformer-进行多语言主观性检测和使用大型语言模型进行基于提示的推理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12130"target="_blank" rel="external nofollow noopener noreferrer">#4</a> <a href="https://papers.cool/arxiv/2509.12130"target="_blank" rel="external nofollow noopener noreferrer">CheckThat的XplaiNLP！2025 年：使用微调 Transformer 进行多语言主观性检测和使用大型语言模型进行基于提示的推理</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ariana Sahitaj](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ariana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ariana</a> Sahitaj), [Jiaao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaao</a> Li), [Pia Wenzel Neves](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pia</a> Wenzel Neves), [Fedor Splitt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fedor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fedor</a> Splitt), [Premtim Sahitaj](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Premtim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Premtim</a> Sahitaj), [Charlott Jakob](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Charlott"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Charlott</a> Jakob), [Veronika Solopova](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Veronika"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Veronika</a> Solopova), [Vera Schmitt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vera"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vera</a> Schmitt)</p>
<p>此笔记本将 XplaiNLP 提交报告给 CheckThat！2025年多语言主观性检测分担任务。我们评估了两种方法：（1）对单语和机器翻译训练数据的变压器编码器EuroBERT、XLM-RoBERTa和German-BERT进行监督微调;（2） 使用两个 LLM 进行零样本提示：用于 Annotation（基于规则的标记）的 o3-mini 和用于 DoubleDown（对比重写）和 Perspective（比较推理）的 gpt-4.1-mini。注释方法以 0.8104 的F_1分在意大利语单语子任务中排名第一，优于基线 0.6941。在罗马尼亚零样本设置中，微调后的XLM-RoBERTa模型获得0.7917的F_1分数，排名第3，超过基线0.6461。同一模型在多语言任务中也表现可靠，并且比希腊语的基线有所改进。对于德语，根据类型相关语言的翻译训练数据进行微调的德语-BERT 模型会产生比基线更具竞争力的性能。相比之下，乌克兰和波兰的零样本设置的性能略低于各自的基线，反映了在低资源跨语言场景中泛化的挑战。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 16：53：41 UTC</p>
<h2 id="5-cbp-tuning黑盒大型语言模型的高效本地定制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12112"target="_blank" rel="external nofollow noopener noreferrer">#5</a> <a href="https://papers.cool/arxiv/2509.12112"target="_blank" rel="external nofollow noopener noreferrer">CBP-Tuning：黑盒大型语言模型的高效本地定制</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jiaxuan Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaxuan</a> Zhao), [Naibin Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Naibin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Naibin</a> Gu), [Yuchen Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Feng), [Xiyu Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiyu</a> Liu), [Peng Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peng</a> Fu), [Zheng Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zheng</a> Lin), [Weiping Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiping</a> Wang)</p>
<p>定制大型语言模型 （LLM） 的高成本从根本上限制了它们对用户特定需求的适应性。因此，法学硕士越来越多地作为基于云的服务提供，这种范式引入了关键的局限性：提供商难以大规模支持个性化定制，而用户在暴露敏感数据时面临隐私风险。为了应对这一双重挑战，我们提出了定制黑盒提示调整（CBP-Tuning），这是一种新颖的框架，可以促进高效的本地定制，同时保护双向隐私。具体来说，我们设计了一个两阶段框架：（1）在服务器端训练的提示生成器，以捕获特定领域和与任务无关的功能，以及（2）用户端无梯度优化，为单个任务定制软提示。这种方法消除了用户访问模型权重或上传私有数据的需要，每个任务只需要一个自定义向量，同时实现有效适配。此外，CBP-Tuning在常识性推理、医疗和金融领域设置中的评估显示出与基线相比的卓越性能，展示了其在与任务无关的处理和隐私保护方面的优势。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 16：41：08 UTC</p>
<h2 id="6-gta使用大型语言模型进行文本分类的监督引导强化学习-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12108"target="_blank" rel="external nofollow noopener noreferrer">#6</a> <a href="https://papers.cool/arxiv/2509.12108"target="_blank" rel="external nofollow noopener noreferrer">GTA：使用大型语言模型进行文本分类的监督引导强化学习</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Min Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Min"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Min</a> Zeng), [Jinfei Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinfei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinfei</a> Sun), [Xueyou Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xueyou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xueyou</a> Luo), [Caiquan Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Caiquan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Caiquan</a> Liu), [Shiqi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiqi</a> Zhang), [Li Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Li"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Li</a> Xie), [Xiaoxin Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoxin</a> Chen)</p>
<p>在自然语言处理任务中，纯强化学习（RL）微调方法往往存在探索效率低下、收敛缓慢等问题;而监督微调（supervised fine-tuning，SFT）方法虽然训练效率高，但与RL相比，性能上限有限，理论基础较不扎实。为了解决效率-能力权衡的问题，我们提出了猜测-思考-回答（GTA）框架，该框架将SFT的效率与RL的能力增益结合在一个统一的训练范式中。GTA 的工作原理是让模型首先产生一个临时猜测（通过交叉熵损失进行优化），然后在生成最终答案之前反思这个猜测，RL 奖励塑造了最终输出和整个 GTA 结构的格式。这种混合方法既实现了比纯 RL 更快的收敛速度，又实现了比纯 SFT 更高的性能上限。为了减轻两个训练信号之间的梯度冲突，我们采用了损失掩蔽和梯度约束。四个文本分类基准的实证结果表明，GTA 显着加速了收敛，同时优于独立的 SFT 和 RL 基线。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 16：33：56 UTC</p>
<h2 id="7-域内-ssl-预训练和流式-asr-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12101"target="_blank" rel="external nofollow noopener noreferrer">#7</a> <a href="https://papers.cool/arxiv/2509.12101"target="_blank" rel="external nofollow noopener noreferrer">域内 SSL 预训练和流式 ASR</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jarod Duret](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jarod"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jarod</a> Duret), [Salima Mdhaffar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Salima"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Salima</a> Mdhaffar), [Gaëlle Laperrière](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ga"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ga</a>ëlle Laperrière), [Ryan Whetten](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ryan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ryan</a> Whetten), [Audrey Galametz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Audrey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Audrey</a> Galametz), [Catherine Kobus](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Catherine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Catherine</a> Kobus), [Marion-Cécile Martin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marion-C"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marion-C</a>écile Martin), [Jo Oleiwan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jo</a> Oleiwan), [Yannick Estève](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yannick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yannick</a> Estève)</p>
<p>在这项研究中，我们调查了空中交通管制 （ATC） 环境中离线和流式 ASR 的特定域自监督预训练的好处。我们在 4.5k 小时的未标记 ATC 数据上训练 BEST-RQ 模型，然后在较小的监督 ATC 集上进行微调。为了实现实时处理，我们建议使用分块注意力和动态卷积，确保低延迟推理。我们将这些域内 SSL 模型与最先进的通用语音编码器（例如 w2v-BERT 2.0 和 HuBERT）进行了比较。结果表明，与在广泛的语音语料库上训练的模型相比，域适配预训练显着提高了标准 ATC 基准测试的性能，显着降低了单词错误率。此外，所提出的流式处理方法在更严格的延迟约束下进一步提高了字错误率，使其特别适用于安全关键型航空应用。这些发现强调，专门针对 ATC 数据进行 SSL 表示是在实际作环境中实现更准确、更高效的 ASR 系统的实用途径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：25：43 UTC</p>
<h2 id="8-希望是一个人还是一个想法ner-的试点基准比较传统-nlp-工具和模棱两可实体上的大型语言模型-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12098"target="_blank" rel="external nofollow noopener noreferrer">#8</a> <a href="https://papers.cool/arxiv/2509.12098"target="_blank" rel="external nofollow noopener noreferrer">“希望”是一个人还是一个想法？NER 的试点基准：比较传统 NLP 工具和模棱两可实体上的大型语言模型</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Payam Latifi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Payam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Payam</a> Latifi)</p>
<p>这项试点研究提出了一个小规模但经过仔细注释的命名实体识别 （NER） 性能基准，跨六个系统：三个非 LLM NLP 工具（NLTK、spaCy、Stanza）和三个通用大型语言模型（LLM：Gemini-1.5-flash、DeepSeek-V3、Qwen-3-4B）。该数据集包含 119 个标记，涵盖五种实体类型（PERSON、LOCATION、ORGANIZATION、DATE、TIME）。我们使用 F1 分数根据手动注释的金标准数据集评估了每个系统的输出。结果表明，法学硕士在识别人名等上下文相关实体方面通常优于传统工具，其中 Gemini 获得了最高的平均 F1 分数。然而，像 Stanza 这样的传统系统在结构化标签（例如 LOCATION 和 DATE）中表现出更高的一致性。我们还观察到法学硕士之间的差异，特别是在处理时间表达和多词组织方面。我们的研究结果强调，虽然法学硕士提供了改进的上下文理解，但传统工具在特定任务上仍然具有竞争力，为模型选择提供信息。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：21：59 UTC</p>
<h2 id="9-sense-模型基于多语言和多模态语义的任务的开源解决方案-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12093"target="_blank" rel="external nofollow noopener noreferrer">#9</a> <a href="https://papers.cool/arxiv/2509.12093"target="_blank" rel="external nofollow noopener noreferrer">SENSE 模型：基于多语言和多模态语义的任务的开源解决方案</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Salima Mdhaffar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Salima"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Salima</a> Mdhaffar), [Haroun Elleuch](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haroun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haroun</a> Elleuch), [Chaimae Chellaf](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chaimae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chaimae</a> Chellaf), [Ha Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ha</a> Nguyen), [Yannick Estève](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yannick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yannick</a> Estève)</p>
<p>本文介绍了 SENSE（Shared Embedding for N-lingual Speech and tExt），这是一种受 SAMU-XLSR 框架启发的开源解决方案，在概念上类似于 Meta AI 的 SONAR 模型。这些方法依赖于教师-学生框架，在话语级别将自监督语音编码器与文本编码器的与语言无关的连续表示保持一致。我们描述了如何通过选择更强的教师文本模型和更好的初始语音编码器来更新原始的 SAMU-XLSR 方法。用于训练和使用 SENSE 模型的源代码已集成到 SpeechBrain 工具包中，我们训练的第一个 SENSE 模型已经公开发布。我们报告了多语言和多模态语义任务的实验结果，其中我们的 SENSE 模型取得了极具竞争力的性能。最后，这项研究为如何在这种语义对齐的语音编码器中捕获语义提供了新的见解。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 16：18：51 UTC</p>
<h2 id="10-多标记生成中的语言模型引导时态和体的案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12065"target="_blank" rel="external nofollow noopener noreferrer">#10</a> <a href="https://papers.cool/arxiv/2509.12065"target="_blank" rel="external nofollow noopener noreferrer">多标记生成中的语言模型引导：时态和体的案例研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alina Klerings](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alina</a> Klerings), [Jannik Brinkmann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jannik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jannik</a> Brinkmann), [Daniel Ruffinelli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniel</a> Ruffinelli), [Simone Ponzetto](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Simone"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Simone</a> Ponzetto)</p>
<p>大型语言模型 （LLM） 能够生成语法格式良好的文本，但它们如何在内部编码其句法知识呢？虽然之前的工作主要集中在二元语法对比上，但在这项工作中，我们研究了两种多维分层语法现象（动词时态和体）的表示和控制，并针对每种现象，使用线性判别分析识别残差空间中不同的正交方向。接下来，我们通过跨三个生成任务的概念引导来展示对这两个语法特征的因果控制。然后，我们在案例研究中使用这些已识别的特征来研究影响多标记生成有效转向的因素。我们发现，转向强度、位置和持续时间是减少不良副作用（如主题转移和退化）的关键参数。我们的研究结果表明，模型以结构组织的、类似人类的方式对时态和体进行编码，但在生成过程中对此类特征的有效控制对多种因素敏感，需要手动调整或自动优化。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 15：48：09 UTC</p>
<h2 id="11-文本适应通俗易懂的语言并通过自动译后编辑周期轻松阅读-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11991"target="_blank" rel="external nofollow noopener noreferrer">#11</a> <a href="https://papers.cool/arxiv/2509.11991"target="_blank" rel="external nofollow noopener noreferrer">文本适应通俗易懂的语言，并通过自动译后编辑周期轻松阅读</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jesús Calleja](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jes"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jes</a>ús Calleja), [David Ponce](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Ponce), [Thierry Etchegoyhen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thierry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thierry</a> Etchegoyhen)</p>
<p>我们描述了 Vicomtech 参与的 CLEARS 挑战赛，即文本改编为西班牙语的通俗语言和易读。我们的方法具有对不同类型的初始大型语言模型适配进行自动后期编辑的特点，其中迭代生成连续的适配，直到可读性和相似性指标表明无法成功执行进一步的适配细化。取所有官方指标的平均值，我们提交的作品分别在通俗语言和易读改编方面获得第一和第二名。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 14：42：44 UTC</p>
<h2 id="12-用于情感解释的以查询为中心的提取摘要-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11989"target="_blank" rel="external nofollow noopener noreferrer">#12</a> <a href="https://papers.cool/arxiv/2509.11989"target="_blank" rel="external nofollow noopener noreferrer">用于情感解释的以查询为中心的提取摘要</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ahmed Moubtahij](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ahmed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ahmed</a> Moubtahij), [Sylvie Ratté](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sylvie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sylvie</a> Ratté), [Yazid Attabi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yazid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yazid</a> Attabi), [Maxime Dumas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maxime"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maxime</a> Dumas)</p>
<p>对客户反馈的建设性分析通常需要从大量文本文档中确定他们情绪的原因。为了协助和提高此类工作的生产力，我们利用了以查询为中心的摘要 （QFS） 任务。此任务的模型经常受到查询和源文档之间的语言不协调的阻碍。我们提出并证实了一个多偏见框架，以帮助在与领域无关的通用层面上弥合这一差距;然后，我们通过基于情感的偏差和查询扩展来制定针对情感解释问题的专门方法。我们在现实世界的专有情感感知 QFS 数据集上取得的实验结果优于基线模型。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 14：41：18 UTC</p>
<h2 id="13-toolrm工具调用大型语言模型的结果奖励模型-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11963"target="_blank" rel="external nofollow noopener noreferrer">#13</a> <a href="https://papers.cool/arxiv/2509.11963"target="_blank" rel="external nofollow noopener noreferrer">ToolRM：工具调用大型语言模型的结果奖励模型</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mayank Agarwal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mayank"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mayank</a> Agarwal), [Ibrahim Abdelaziz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ibrahim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ibrahim</a> Abdelaziz), [Kinjal Basu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kinjal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kinjal</a> Basu), [Merve Unuvar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Merve"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Merve</a> Unuvar), [Luis A. Lastras](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luis</a> A. Lastras), [Yara Rizk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yara</a> Rizk), [Pavan Kapanipathi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pavan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pavan</a> Kapanipathi)</p>
<p>随着大型语言模型 （LLM） 越来越多地与外部工具交互，工具使用的奖励建模已成为一个关键但未被充分探索的领域。现有的奖励模型主要根据自然语言输出进行训练，难以评估基于工具的推理和执行。为了量化这一差距，我们引入了 FC-RewardBench，这是第一个旨在系统评估奖励模型在工具调用场景中的性能的基准测试。我们的分析表明，当前的奖励模型经常错过有效使用工具的关键信号，这凸显了特定领域建模的必要性。为了解决这个问题，我们提出了一个基于结果的奖励模型的训练框架，使用从允许许可的开放权重法学硕士中合成的数据。我们训练从 1.7B 到 14B 参数的模型，并在七个域外基准测试中对其进行评估。这些模型的性能始终优于通用基线，实现了下游任务性能高达 25% 的平均改进，并通过奖励引导过滤实现了数据高效的微调。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 14：17：17 UTC</p>
<h2 id="14-spec-llava通过基于动态树的推测解码加速视觉语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11961"target="_blank" rel="external nofollow noopener noreferrer">#14</a> <a href="https://papers.cool/arxiv/2509.11961"target="_blank" rel="external nofollow noopener noreferrer">Spec-LLaVA：通过基于动态树的推测解码加速视觉语言模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mingxiao Huo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingxiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingxiao</a> Huo), [Jiayi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiayi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiayi</a> Zhang), [Hewei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hewei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hewei</a> Wang), [Jinfeng Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinfeng</a> Xu), [Zheyu Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zheyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zheyu</a> Chen), [Huilin Tai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huilin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huilin</a> Tai), [Yijun Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yijun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yijun</a> Chen)</p>
<p>视觉语言模型 （VLM） 支持强大的多模态推理，但自回归推理速度慢，限制了它们在实时应用程序中的部署。我们介绍了 Spec-LLaVA，这是一种应用推测解码来加速 VLM 而不牺牲输出质量的系统。Spec-LLaVA 将轻量级草稿 VLM 与大型目标模型配对：草稿推测未来的代币，目标并行验证，允许每一步生成多个代币。为了最大限度地提高效率，我们设计了一种基于动态树的验证算法，该算法使用草稿模型置信度自适应地扩展和修剪推测性分支。在 MS COCO 域外图像上，Spec-LLaVA 可达到 3.28× 在 LLaVA-1.5（7B、13B）上解码速度更快，不会降低生成质量。这项工作为使用动态树结构推测解码的VLM提供了一个无损加速框架，为实用的实时多模态助手开辟了道路。重要的是，轻量级草稿模型设计使框架适用于资源受限或设备上的部署设置。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 14：16：51 UTC</p>
<h2 id="15-设计具有文化敏感性的法学硕士来自英日翻译的证据-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11921"target="_blank" rel="external nofollow noopener noreferrer">#15</a> <a href="https://papers.cool/arxiv/2509.11921"target="_blank" rel="external nofollow noopener noreferrer">设计具有文化敏感性的法学硕士：来自英日翻译的证据</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Helene Tenzer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helene"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helene</a> Tenzer), [Oumnia Abidi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oumnia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oumnia</a> Abidi), [Stefan Feuerriegel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Stefan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Stefan</a> Feuerriegel)</p>
<p>大型语言模型 （LLM） 越来越多地用于日常交流，包括跨不同文化背景的多语言交互。虽然法学硕士现在可以生成近乎完美的直译，但目前尚不清楚法学硕士是否支持文化上适当的交流。在本文中，我们分析了不同LLM设计在应用于工作场所电子邮件的英日翻译时的文化敏感性。在这里，我们改变了提示策略：（1） 天真的“只需翻译”提示，（2） 指定收件人文化背景的针对受众的提示，以及 （3） 具有明确指导的日语沟通规范的教学提示。然后，我们使用混合方法研究分析特定文化的语言模式，以评估翻译对文化规范的适应程度。此外，我们检查了母语人士感知的翻译语气的适当性。我们发现，根据文化量身定制的提示可以提高文化契合度，在此基础上，我们为在多语言环境中设计具有文化包容性的法学硕士提供了建议。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-15 13：37：35 UTC</p>
<h2 id="16-作者身份的不确定性为什么完美的人工智能检测在数学上是不可能的-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11915"target="_blank" rel="external nofollow noopener noreferrer">#16</a> <a href="https://papers.cool/arxiv/2509.11915"target="_blank" rel="external nofollow noopener noreferrer">作者身份的不确定性：为什么完美的人工智能检测在数学上是不可能的</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Aadil Gani Ganie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aadil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aadil</a> Gani Ganie)</p>
<p>随着大型语言模型 （LLM） 变得越来越先进，区分人类编写的文本和人工智能生成的文本变得越来越困难。本文在自然语言中将量子不确定性与作者身份检测的局限性进行了概念上的相似之处。我们认为存在一个根本的权衡：人们越是自信地试图识别文本是由人类还是人工智能编写的，就越有可能破坏文本的自然流畅性和真实性。这反映了量子系统中精度和干扰之间的紧张关系。我们探讨了当前的检测方法（例如文体测量、水印和神经分类器）如何面临固有的局限性。提高检测精度通常会导致人工智能输出发生变化，从而降低其他功能的可靠性。实际上，试图检测人工智能作者身份的行为本身就在文本的其他地方引入了不确定性。我们的分析表明，当人工智能生成的文本与人类书写非常相似时，完美的检测不仅在技术上变得困难，而且在理论上也变得不可能。我们讨论反驳并讨论对作者身份、道德和政策的更广泛影响。最终，我们认为人工智能文本检测的挑战不仅仅是更好工具的问题，它反映了语言本身本质中更深层次的、不可避免的紧张关系。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 13：33：32 UTC</p>
<h2 id="17-成长的视角使用大型语言模型对具身视角采取和内在叙事发展进行建模-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11868"target="_blank" rel="external nofollow noopener noreferrer">#17</a> <a href="https://papers.cool/arxiv/2509.11868"target="_blank" rel="external nofollow noopener noreferrer">成长的视角：使用大型语言模型对具身视角采取和内在叙事发展进行建模</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sabrina Patania](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sabrina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sabrina</a> Patania), [Luca Annese](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luca</a> Annese), [Anna Lambiase](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anna</a> Lambiase), [Anita Pellegrini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anita</a> Pellegrini), [Tom Foulsham](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tom"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tom</a> Foulsham), [Azzurra Ruggeri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Azzurra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Azzurra</a> Ruggeri), [Silvia Rossi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silvia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silvia</a> Rossi), [Silvia Serino](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silvia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silvia</a> Serino), [Dimitri Ognibene](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dimitri"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dimitri</a> Ognibene)</p>
<p>语言和具身透视对于人类协作至关重要，但很少有计算模型同时解决这两者。这项工作研究了PerspAct系统[1]，该系统将ReAct（理性和行为）范式与大型语言模型（LLM）相结合，以模拟基于Selman理论[2]的透视制定的发展阶段。使用扩展导演任务，我们评估 GPT 生成与特定发展阶段一致的内部叙述的能力，并评估这些叙述如何从定性（行动选择）和定量（任务效率）上影响协作绩效。结果表明，GPT 在任务执行之前可靠地产生发展一致的叙述，但在交互过程中经常转向更高级的阶段，这表明语言交换有助于完善内部表征。较高的发展阶段通常会提高协作效率，而较早的发展阶段在复杂的环境中会产生更多可变的结果。这些发现强调了在法学硕士中整合具身观点和语言以更好地模拟发展动态的潜力，并强调在语言和具身组合任务中评估内部言语的重要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a></p>
<p><strong>发布</strong>: 2025-09-15 12：39：55 UTC</p>
<h2 id="18-moom超长角色扮演对话中内存的维护组织和优化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11860"target="_blank" rel="external nofollow noopener noreferrer">#18</a> <a href="https://papers.cool/arxiv/2509.11860"target="_blank" rel="external nofollow noopener noreferrer">MOOM：超长角色扮演对话中内存的维护、组织和优化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Weishu Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weishu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weishu</a> Chen), [Jinyi Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinyi</a> Tang), [Zhouhui Hou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhouhui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhouhui</a> Hou), [Shihao Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shihao</a> Han), [Mingjie Zhan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingjie</a> Zhan), [Zhiyuan Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyuan</a> Huang), [Delong Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Delong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Delong</a> Liu), [Jiawei Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiawei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiawei</a> Guo), [Zhicheng Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhicheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhicheng</a> Zhao), [Fei Su](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fei</a> Su)</p>
<p>记忆提取对于在人机角色扮演场景中保持连贯的超长对话至关重要。然而，现有方法通常表现出不受控制的内存增长。为了解决这个问题，我们提出了 MOOM，这是第一个利用文学理论的双分支内存插件，它通过将情节发展和人物刻画建模为核心叙事元素。具体来说，一个分支总结了多个时间尺度的情节冲突，而另一个分支则提取用户的角色概况。MOOM 进一步整合了一种遗忘机制，受“竞争抑制”记忆理论的启发，以限制记忆容量并减轻不受控制的增长。此外，我们还推出了 ZH-4O，这是一个专为角色扮演设计的中文超长对话数据集，其对话平均为 600 回合，并包含手动注释的记忆信息。实验结果表明，MOOM优于所有最先进的内存提取方法，在保持可控内存容量的同时，需要更少的大型语言模型调用。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 12：35：14 UTC</p>
<h2 id="19-scdtour嵌入轴排序和合并以实现可解释的语义变化检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11818"target="_blank" rel="external nofollow noopener noreferrer">#19</a> <a href="https://papers.cool/arxiv/2509.11818"target="_blank" rel="external nofollow noopener noreferrer">SCDTour：嵌入轴排序和合并以实现可解释的语义变化检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Taichi Aida](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taichi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taichi</a> Aida), [Danushka Bollegala](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Danushka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Danushka</a> Bollegala)</p>
<p>在语义变化检测 （SCD） 中，获得可解释且高性能的嵌入是一个常见问题。然而，提高可解释性通常会导致 SCD 性能下降，反之亦然。为了解决这个问题，我们提出了SCDTour，这是一种对可解释轴进行排序和合并以减轻SCD性能下降的方法。SCDTour 考虑了 （a） 嵌入空间中轴之间的语义相似性，以及 （b） 每个轴对语义变化的贡献程度。实验结果表明，SCDTour在保持高可解释性的同时，保持了语义变化检测的性能。此外，聚集排序的轴会产生一组更精细的词义，从而实现与 SCD 任务中的原始全维嵌入相当或改进的性能。这些发现表明，SCDTour 有效地平衡了可解释性和 SCD 性能，能够通过少量精细轴对语义偏移进行有意义的解释。源代码可在 <a href="https://github.com/LivNLP/svp-tour"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/LivNLP/svp-tour</a> 获得。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 12：01：24 UTC</p>
<h2 id="20-pledgetracker监控承诺履行情况的系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11804"target="_blank" rel="external nofollow noopener noreferrer">#20</a> <a href="https://papers.cool/arxiv/2509.11804"target="_blank" rel="external nofollow noopener noreferrer">PledgeTracker：监控承诺履行情况的系统</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yulong Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yulong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yulong</a> Chen), [Michael Sejr Schlichtkrull](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Sejr Schlichtkrull), [Zhenyun Deng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenyun</a> Deng), [David Corney](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Corney), [Nasim Asl](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nasim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nasim</a> Asl), [Joshua Salisbury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joshua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joshua</a> Salisbury), [Andrew Dudfield](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> Dudfield), [Andreas Vlachos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andreas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andreas</a> Vlachos)</p>
<p>政治承诺反映了候选人的政策承诺，但跟踪其履行情况需要对分布在多个动态更新来源中的增量证据进行推理。现有方法将此任务简化为文档分类任务，而忽略了其动态、时间和多文档的性质。为了解决这个问题，我们引入了 \textsc{PledgeTracker}，这是一个将质押验证重新表述为结构化事件时间线构建的系统。PledgeTracker由三个核心组件组成：（1）多步骤证据检索模块;（2）时间线构建模块;（3） 履行过滤模块，允许捕捉承诺履行的不断变化的性质，并生成可解释和结构化的时间表。我们在现实世界的工作流程中与专业事实核查员合作评估 PledgeTracker，证明其在检索相关证据和减少人工验证工作方面的有效性。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 11：37：47 UTC</p>
<h2 id="21-从模糊语音到医学洞察对嘈杂的患者叙述进行法学硕士的基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11803"target="_blank" rel="external nofollow noopener noreferrer">#21</a> <a href="https://papers.cool/arxiv/2509.11803"target="_blank" rel="external nofollow noopener noreferrer">从模糊语音到医学洞察：对嘈杂的患者叙述进行法学硕士的基准测试</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Eden Mama](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eden"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eden</a> Mama), [Liel Sheri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liel</a> Sheri), [Yehudit Aperstein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yehudit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yehudit</a> Aperstein), [Alexander Apartsin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Apartsin)</p>
<p>大型语言模型 （LLM） 在医疗保健领域的广泛采用引发了人们对其解释患者生成的叙述的能力提出了关键问题，这些叙述通常是非正式的、模棱两可的和嘈杂的。现有的基准通常依赖于干净、结构化的临床文本，对模型在现实条件下的性能提供有限的洞察力。在这项工作中，我们提出了一个新颖的合成数据集，旨在模拟患者的自我描述，其特征是不同程度的语言噪音、模糊语言和外行术语。我们的数据集包含临床一致的场景，并带有地面实况诊断的注释，涵盖一系列沟通清晰度，以反映不同的现实世界报告风格。使用该基准测试，我们微调和评估了几种最先进的模型 （LLM），包括基于 BERT 和编码器-解码器 T5 模型。为了支持可重复性和未来的研究，我们发布了嘈杂诊断基准 （NDB），这是一个包含嘈杂的合成患者描述的结构化数据集，旨在对大型语言模型 （LLM） 在现实语言条件下的诊断能力进行压力测试和比较。我们向社区提供了基准：https://github.com/lielsheri/PatientSignal</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 11：34：46 UTC</p>
<h2 id="22-当好奇心发出危险信号时通过在线药物查询预测健康危机-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11802"target="_blank" rel="external nofollow noopener noreferrer">#22</a> <a href="https://papers.cool/arxiv/2509.11802"target="_blank" rel="external nofollow noopener noreferrer">当好奇心发出危险信号时：通过在线药物查询预测健康危机</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Dvora Goncharok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dvora"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dvora</a> Goncharok), [Arbel Shifman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arbel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arbel</a> Shifman), [Alexander Apartsin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Apartsin), [Yehudit Aperstein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yehudit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yehudit</a> Aperstein)</p>
<p>在线医疗论坛是深入了解患者问题的丰富且未充分利用的来源，尤其是关于药物使用的问题。用户提出的众多问题中的一些可能预示着混乱、滥用，甚至是正在发展的健康危机的早期预警信号。检测这些可能先于严重不良事件或危及生命的并发症的关键问题对于及时干预和提高患者安全至关重要。本研究引入了一个从在线论坛中提取的药物相关问题的新型注释数据集。每个条目都根据临床风险因素手动标记关键性。我们使用 TF-IDF 文本表示以及三种利用深度上下文理解的最先进的基于大型语言模型 （LLM） 的分类方法对六种传统机器学习分类器的性能进行了基准测试。我们的研究结果强调了经典和现代方法在支持数字健康空间中实时分类和警报系统的潜力。精选的数据集将公开，以鼓励在患者生成的数据、自然语言处理和关键健康事件的早期预警系统的交叉点进行进一步研究。数据集和基准可在以下网址获得：https://github.com/Dvora-coder/LLM-Medication-QA-Risk-Classifier-MediGuard。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 11：31：25 UTC</p>
<h2 id="23-用户体验感知洞察数据集uxpid来自公共工业论坛的综合用户反馈-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11777"target="_blank" rel="external nofollow noopener noreferrer">#23</a> <a href="https://papers.cool/arxiv/2509.11777"target="_blank" rel="external nofollow noopener noreferrer">用户体验感知洞察数据集（UXPID）：来自公共工业论坛的综合用户反馈</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mikhail Kulyabin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mikhail"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mikhail</a> Kulyabin), [Jan Joosten](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jan</a> Joosten), [Choro Ulan uulu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Choro"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Choro</a> Ulan uulu), [Nuno Miguel Martins Pacheco](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nuno"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nuno</a> Miguel Martins Pacheco), [Fabian Ries](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fabian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fabian</a> Ries), [Filippos Petridis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Filippos"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Filippos</a> Petridis), [Jan Bosch](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jan</a> Bosch), [Helena Holmström Olsson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helena</a> Holmström Olsson)</p>
<p>行业论坛中的客户反馈反映了对实际产品体验的丰富但未被充分探索的洞察来源。这些公开共享的讨论提供了由特定使用环境塑造的用户期望、挫折和成功故事的有机视图。然而，由于内容的非结构化和特定领域的性质，利用这些信息进行系统分析仍然具有挑战性。缺乏结构和专业词汇使得传统的数据分析技术难以准确解释、分类和量化反馈，从而限制了其为产品开发和支持策略提供信息的潜力。为了应对这些挑战，本文提出了用户体验感知洞察数据集（User eXperience Perception Insights Dataset，UXPID），该数据集收集了从公共工业自动化论坛中提取的7130个人工合成和匿名用户反馈分支。每个 JavaScript 对象表示法 （JSON） 记录都包含与特定硬件和软件产品相关的多帖子评论，并丰富了元数据和上下文对话数据。利用大型语言模型 （LLM），对每个分支进行系统分析和注释，以获取用户体验洞察、用户期望、严重性和情绪评级以及主题分类。UXPID 数据集旨在促进用户需求、用户体验 （UX） 分析和人工智能驱动的反馈处理的研究，特别是在隐私和许可限制限制对现实世界数据的访问的情况下。UXPID 支持在技术论坛的背景下训练和评估基于 Transformer 的模型，以执行问题检测、情感分析和需求提取等任务。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 10：58：41 UTC</p>
<h2 id="24-从监管文件中自适应提取信息的代理工具包-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11773"target="_blank" rel="external nofollow noopener noreferrer">#24</a> <a href="https://papers.cool/arxiv/2509.11773"target="_blank" rel="external nofollow noopener noreferrer">从监管文件中自适应提取信息的代理工具包</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Gaye Colakoglu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gaye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gaye</a> Colakoglu), [Gürkan Solmaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=G"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=G</a>ürkan Solmaz), [Jonathan Fürst](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonathan</a> Fürst)</p>
<p>欧盟法规规定的性能声明 （DoP） 文件证明建筑产品的性能。虽然它们的一些内容是标准化的，但 DoP 在布局、语言、模式和格式方面差异很大，这给自动键值对提取 （KVP） 和问答 （QA） 带来了挑战。现有的静态或仅 LLM 的 IE 管道经常会出现幻觉，无法适应这种结构多样性。我们特定于域的有状态代理系统通过规划器-执行者-响应者架构解决了这些挑战。该系统推断用户意图，检测文档模式，并动态编排工具以实现稳健、可追溯的推理，同时避免工具滥用或执行循环。对精选的 DoP 数据集的评估表明，跨格式和语言的稳健性有所提高，为受监管工作流程中的结构化数据提取提供了可扩展的解决方案。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 10：53：05 UTC</p>
<h2 id="25-室内声学影响混合会议空间的沟通成功一项试点研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11709"target="_blank" rel="external nofollow noopener noreferrer">#25</a> <a href="https://papers.cool/arxiv/2509.11709"target="_blank" rel="external nofollow noopener noreferrer">室内声学影响混合会议空间的沟通成功：一项试点研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Robert Einig](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Robert"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Robert</a> Einig), [Stefan Janscha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Stefan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Stefan</a> Janscha), [Jonas Schuster](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonas</a> Schuster), [Julian Koch](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Julian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Julian</a> Koch), [Martin Hagmueller](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Martin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Martin</a> Hagmueller), [Barbara Schuppler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Barbara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Barbara</a> Schuppler)</p>
<p>自 2020 年 COVID-19 大流行以来，大学和公司越来越多地将混合功能集成到他们的会议空间中，甚至为此目的创建了专用房间。虽然快速稳定的互联网连接的重要性通常被优先考虑，但会议室的声学设计却经常被忽视。声学效果差，尤其是过度的混响，可能会导致误解、语音清晰度下降或认知和声音疲劳等问题。这项试点研究调查了格拉茨理工大学会议室的室内声学干预是否支持混合会议中更好的沟通。为此，我们记录了两组人两次，一次是在改善房间声学之前，一次是在改善房间声学之后。尽管由于样本量小，我们的研究结果没有达到统计学意义，但清楚地表明，我们的空间干预提高了混合会议的沟通成功率。为了让语音交流界的读者也能够阅读这篇论文，我们解释了与我们结果的解释相关的室内声学背景。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">音频和语音处理</a></p>
<p><strong>发布</strong>: 2025-09-15 09：09：33 UTC</p>
<h2 id="26-coachme使用基于参考的教练指导生成模型解码运动元素-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11698"target="_blank" rel="external nofollow noopener noreferrer">#26</a> <a href="https://papers.cool/arxiv/2509.11698"target="_blank" rel="external nofollow noopener noreferrer">CoachMe：使用基于参考的教练指导生成模型解码运动元素</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wei-Hsin Yeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei-Hsin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei-Hsin</a> Yeh), [Yu-An Su](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu-An"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu-An</a> Su), [Chih-Ning Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chih-Ning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chih-Ning</a> Chen), [Yi-Hsueh Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi-Hsueh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi-Hsueh</a> Lin), [Calvin Ku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Calvin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Calvin</a> Ku), [Wen-Hsin Chiu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wen-Hsin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wen-Hsin</a> Chiu), [Min-Chun Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Min-Chun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Min-Chun</a> Hu), [Lun-Wei Ku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lun-Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lun-Wei</a> Ku)</p>
<p>动作指导是一项至关重要的任务，它通过分析动作和提供纠正指导来帮助运动员完善技术。尽管多模态模型的最新进展提高了运动理解能力，但由于运动具有高度特定领域的性质以及对信息指导的需求，生成精确且针对特定运动的指令仍然具有挑战性。我们提出了 CoachMe，这是一种基于参考的模型，用于分析学习者的运动与参考在时间和物理方面的差异。这种方法既可以学习领域知识，也可以获得类似教练的思维过程，可以有效识别运动错误并提供反馈来解释如何改进。在本文中，我们说明了 CoachMe 如何通过从一般动作中学习，然后利用有限的数据来很好地适应滑冰和拳击等特定运动。实验表明，CoachMe 提供高质量的指导，而不是仅仅以教练的语气提供指导，但没有关键信息。CoachMe 在花样滑冰方面的 G-Eval 中比 GPT-4o 高出 31.6%，在拳击方面比 GPT-4o 高出 58.3%。分析进一步证实，它详细阐述了生成指令中的错误及其相应的改进方法。你可以在这里找到 CoachMe： <a href="https://motionxperts.github.io/"target="_blank" rel="external nofollow noopener noreferrer">https://motionxperts.github.io/</a></p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 09：01：39 UTC</p>
<h2 id="27-基于大语言模型的动态知识更新驱动模型用于假新闻检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11687"target="_blank" rel="external nofollow noopener noreferrer">#27</a> <a href="https://papers.cool/arxiv/2509.11687"target="_blank" rel="external nofollow noopener noreferrer">基于大语言模型的动态知识更新驱动模型，用于假新闻检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Di Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Di"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Di</a> Jin), [Jun Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jun</a> Yang), [Xiaobao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaobao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaobao</a> Wang), [Junwei Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junwei</a> Zhang), [Shuqi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuqi</a> Li), [Dongxiao He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongxiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongxiao</a> He)</p>
<p>随着互联网和社交媒体的迅速发展，将可信的新闻与大量复杂的信息区分开来是一项重大挑战。由于新闻事件的突然性和不稳定性，新闻的真实性标签可能会随着事件的发展而发生变化，因此假新闻检测获得最新的事件更新至关重要。现有方法采用检索增强生成来填补知识空白，但存在检索内容可信度不足、嘈杂信息干扰等问题。我们提出了一种动态知识更新驱动的假新闻检测模型（DYNAMO），利用知识图谱实现新知识的持续更新，并与大语言模型集成，实现新闻真实性检测和新知识正确性验证双重功能，解决了保证新知识真实性和深度挖掘新闻语义两大关键问题。具体来说，我们首先构建一个特定于新闻领域的知识图谱。然后，我们使用蒙特卡洛树搜索对复杂的新闻进行分解，并逐步验证。最后，从经过验证的真实新闻文本和推理路径中提取和更新新知识。实验结果表明，DYNAMO在两个真实世界的数据集上取得了最佳性能。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 08：38：08 UTC</p>
<h2 id="28-ethicsmh心理健康人工智能伦理推理的试点基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11648"target="_blank" rel="external nofollow noopener noreferrer">#28</a> <a href="https://papers.cool/arxiv/2509.11648"target="_blank" rel="external nofollow noopener noreferrer">EthicsMH：心理健康人工智能伦理推理的试点基准</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Sai Kartheek Reddy Kasu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sai</a> Kartheek Reddy Kasu)</p>
<p>大型语言模型 （LLM） 在心理健康和其他敏感领域的部署引发了有关道德推理、公平和负责任的一致性的紧迫问题。然而，现有的道德和临床决策基准并没有充分反映心理健康实践中遇到的独特伦理困境，其中保密性、自主性、仁慈性和偏见经常交叉。为了解决这一差距，我们推出了心理健康伦理推理 （EthicsMH），这是一个包含 125 个场景的试点数据集，旨在评估人工智能系统如何在治疗和精神病学环境中驾驭道德情况。每个场景都丰富了结构化字段，包括多个决策选项、专家一致的推理、预期模型行为、现实世界的影响和多利益相关者的观点。这种结构不仅可以评估决策的准确性，还可以评估解释质量和与专业规范的一致性。尽管规模不大且采用模型辅助生成开发，但 EthicsMH 建立了一个连接人工智能伦理和心理健康决策的任务框架。通过发布该数据集，我们的目标是提供一种种子资源，可以通过社区和专家的贡献进行扩展，促进能够负责任地处理社会一些最微妙决策的人工智能系统的发展。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-15 07：35：35 UTC</p>
<h2 id="29-aesbiasbench评估多模态语言模型中的偏差和对齐以进行个性化图像美学评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11620"target="_blank" rel="external nofollow noopener noreferrer">#29</a> <a href="https://papers.cool/arxiv/2509.11620"target="_blank" rel="external nofollow noopener noreferrer">AesBiasBench：评估多模态语言模型中的偏差和对齐，以进行个性化图像美学评估</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Kun Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kun</a> Li), [Lai-Man Po](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lai-Man"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lai-Man</a> Po), [Hongzheng Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongzheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongzheng</a> Yang), [Xuyuan Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuyuan</a> Xu), [Kangcheng Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kangcheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kangcheng</a> Liu), [Yuzhi Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuzhi</a> Zhao)</p>
<p>多模态大型语言模型 （MLLM） 越来越多地应用于个性化图像美学评估 （PIAA），作为专家评估的可扩展替代方案。然而，他们的预测可能反映了受性别、年龄和教育程度等人口因素影响的微妙偏见。在这项工作中，我们提出了 AesBiasBench，这是一个基准，旨在从两个互补的维度评估 MLLM：（1） 刻板印象偏差，通过测量不同人口群体审美评估的差异来量化;（2） 模型输出与真正的人类审美偏好之间的一致性。我们的基准涵盖三个子任务（审美感知、评估、同理心），并引入结构化指标（IFD、NRD、AAS）来评估偏见和一致性。我们评估了 19 个 MLLM，包括专有模型（例如 GPT-4o、Claude-3.5-Sonnet）和开源模型（例如 InternVL-2.5、Qwen2.5-VL）。结果表明，较小的模型表现出更强的刻板印象偏差，而较大的模型更符合人类偏好。纳入身份信息往往会加剧偏见，尤其是在情感判断方面。这些发现强调了身份感知评估框架在主观视觉语言任务中的重要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-15 06：25：39 UTC</p>
<h2 id="30-halludetect检测缓解对话系统中的幻觉并对其进行基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11619"target="_blank" rel="external nofollow noopener noreferrer">#30</a> <a href="https://papers.cool/arxiv/2509.11619"target="_blank" rel="external nofollow noopener noreferrer">HalluDetect：检测、缓解对话系统中的幻觉并对其进行基准测试</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Spandan Anaokar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Spandan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Spandan</a> Anaokar), [Shrey Ganatra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shrey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shrey</a> Ganatra), [Harshvivek Kashid](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Harshvivek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Harshvivek</a> Kashid), [Swapnil Bhattacharyya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Swapnil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Swapnil</a> Bhattacharyya), [Shruti Nair](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shruti"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shruti</a> Nair), [Reshma Sekhar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Reshma"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Reshma</a> Sekhar), [Siddharth Manohar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siddharth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siddharth</a> Manohar), [Rahul Hemrajani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rahul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rahul</a> Hemrajani), [Pushpak Bhattacharyya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pushpak"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pushpak</a> Bhattacharyya)</p>
<p>大型语言模型 （LLM） 在工业中广泛使用，但仍然容易出现幻觉，限制了其在关键应用中的可靠性。这项工作解决了使用 LLaMA 3.1 8B Instruct（工业中经常使用的紧凑模型）构建的消费者不满聊天机器人的幻觉减少问题。我们开发了 HalluDetect，这是一种基于 LLM 的幻觉检测系统，其 F1 分数为 69%，比基线检测器高出 25.44%。对五种聊天机器人架构进行基准测试，我们发现其中，AgentBot 将幻觉降至每回合 0.4159 次，同时保持最高的令牌准确率 （96.13%），使其成为最有效的缓解策略。我们的研究结果为缓解幻觉提供了一个可扩展的框架，表明优化的推理策略可以显着提高事实准确性。在应用于消费者法的同时，我们的方法也推广到其他高风险领域，增强了对法学硕士驱动的助手的信任。我们将发布代码和数据集</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 06：23：36 UTC</p>
<h2 id="31-用于实体级情感分类的动态跨度交互和图感知记忆-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11604"target="_blank" rel="external nofollow noopener noreferrer">#31</a> <a href="https://papers.cool/arxiv/2509.11604"target="_blank" rel="external nofollow noopener noreferrer">用于实体级情感分类的动态跨度交互和图感知记忆</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Md. Mithun Hossain](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Md"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Md</a>. Mithun Hossain), <a href="https://arxiv.org/search/?searchtype=author&amp;query=Sanjara"target="_blank" rel="external nofollow noopener noreferrer">Sanjara</a>, [Md. Shakil Hossain](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Md"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Md</a>. Shakil Hossain), [Sudipto Chaki](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sudipto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sudipto</a> Chaki)</p>
<p>实体级情感分类涉及识别与文本中特定实体相关的情感极性。这项任务带来了几个挑战：有效地模拟实体与其周围情感表达之间微妙而复杂的相互作用;捕获可能跨越句子的依赖关系;并通过共同引用解析确保对同一实体的多次提及的一致情绪预测。此外，否定、歧义和意见重叠等语言现象使分析更加复杂。这些复杂性使实体级情感分类成为一个难题，尤其是在现实世界的嘈杂文本数据中。为了解决这些问题，我们提出了 SpanEIT，这是一种集成了动态跨度交互和图感知记忆机制的新型框架，用于增强实体情感关系建模。SpanEIT 为实体和候选情感短语构建基于跨度的表示，采用双向注意力进行细粒度交互，并使用图注意力网络来捕获句法和共现关系。协同引用感知内存模块可确保文档之间的实体级一致性。对 FSAD、BARU 和 IMDB 数据集的实验表明，SpanEIT 在准确性和 F1 分数方面优于最先进的 Transformer 和混合基线。消融和可解释性分析验证了我们方法的有效性，强调了其在社交媒体监控和客户反馈分析等应用中进行细粒度情感分析的潜力。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 05：47：57 UTC</p>
<h2 id="32-分析客家人工智能聊天机器人中的信息寻求行为一项认知-语用研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11591"target="_blank" rel="external nofollow noopener noreferrer">#32</a> <a href="https://papers.cool/arxiv/2509.11591"target="_blank" rel="external nofollow noopener noreferrer">分析客家人工智能聊天机器人中的信息寻求行为：一项认知-语用研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Chu-Hsuan Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chu-Hsuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chu-Hsuan</a> Lee), [Chen-Chi Chang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chen-Chi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chen-Chi</a> Chang), [Hung-Shin Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hung-Shin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hung-Shin</a> Lee), [Yun-Hsiang Hsu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yun-Hsiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yun-Hsiang</a> Hsu), [Ching-Yuan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ching-Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ching-Yuan</a> Chen)</p>
<p>由于许多濒临灭绝的语言面临消失的危险，保护它们的努力现在比以往任何时候都更加依赖于使用技术和文化明智的教学策略。本研究通过采用基于布鲁姆认知过程分类法和对话行为分类的双层分析框架，检查了 TALKA 中的用户行为，TALKA 是一种专为客语参与而设计的生成式人工智能聊天机器人。我们分析了 7,077 个用户话语，每个话语都根据六个认知水平和 11 种对话行为类型进行了仔细注释。其中包括各种功能，例如询问信息、请求翻译、进行文化查询以及创造性地使用语言。语用分类进一步强调了不同类型的对话行为（例如反馈、控制命令和社交问候）如何与特定的认知意图保持一致。结果表明，生成式人工智能聊天机器人可以以有意义的方式支持语言学习，尤其是当它们的设计理解用户如何思考和交流时。它们还可以帮助学习者更自信地表达自己并与他们的文化身份联系起来。TALKA 案例提供了关于人工智能介导的对话如何促进资源匮乏的语言学习者的认知发展以及务实谈判和社会文化归属的实证见解。通过关注人工智能辅助语言学习，这项研究为技术如何支持语言保存和教育实践提供了新的见解。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 05：18：17 UTC</p>
<h2 id="33-bhaashabhasazaban南亚资源匮乏语言调查---现阶段和挑战-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11570"target="_blank" rel="external nofollow noopener noreferrer">#33</a> <a href="https://papers.cool/arxiv/2509.11570"target="_blank" rel="external nofollow noopener noreferrer">Bhaasha、Bhasa、Zaban：南亚资源匮乏语言调查 - 现阶段和挑战</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sampoorna Poria](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sampoorna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sampoorna</a> Poria), [Xiaolei Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaolei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaolei</a> Huang)</p>
<p>大型语言模型的快速发展彻底改变了许多英语数据的 NLP 任务。不幸的是，对低资源语言的模型及其评估被忽视了，尤其是对于南亚语言。尽管南亚有 650 多种语言，但其中许多语言要么计算资源非常有限，要么在现有语言模型中缺失。因此，需要回答的一个具体问题是：我们能否评估当前阶段和挑战，为我们的 NLP 社区提供信息并促进南亚语言的模型开发？在本次调查中，我们通过检索自 2020 年以来的研究，全面考察了南亚语言 NLP 模型的当前努力和挑战，重点关注基于 Transformer 的模型，例如 BERT、T5 和 GPT。我们介绍了 3 个基本方面的进步和差距：数据、模型和任务，例如可用数据源、微调策略和领域应用程序。我们的研究结果凸显了重大问题，包括关键领域（例如健康）数据缺失、代码混合以及缺乏标准化评估基准。我们的调查旨在提高NLP社区对更有针对性的数据管理的认识，统一针对南亚文化和语言细微差别量身定制的基准，并鼓励南亚语言的公平代表。完整的资源列表可在以下网址获得：https://github.com/trust-nlp/LM4SouthAsia-Survey。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 04：31：22 UTC</p>
<h2 id="34-d2hscore通过语义广度和深度分析在法学硕士中进行推理感知幻觉检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11569"target="_blank" rel="external nofollow noopener noreferrer">#34</a> <a href="https://papers.cool/arxiv/2509.11569"target="_blank" rel="external nofollow noopener noreferrer">D2HScore：通过语义广度和深度分析在法学硕士中进行推理感知幻觉检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yue Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yue</a> Ding), [Xiaofang Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaofang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaofang</a> Zhu), [Tianze Xia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianze"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianze</a> Xia), [Junfei Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junfei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junfei</a> Wu), [Xinlong Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinlong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinlong</a> Chen), [Qiang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiang</a> Liu), [Liang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liang</a> Wang)</p>
<p>尽管大型语言模型（LLMs）取得了显著的成功，但其实际应用往往受到非事实内容生成的阻碍，这被称为“幻觉”。确保法学硕士输出的可靠性是一项严峻的挑战，特别是在金融、安全和医疗保健等高风险领域。在这项工作中，我们从模型架构和生成动态的角度重新审视幻觉检测。利用 LLM 的多层结构和自回归解码过程，我们将幻觉信号分解为两个互补的维度：每一层内标记表示的语义广度，以及核心概念跨层演变时的语义深度。基于这一见解，我们提出了 \textbf{D2HScore（Dispersion and Drift-based Hallucination Score）}，一个免训练和无标签的框架，联合测量：（1）\textbf{Intra-Layer Dispersion}，量化每层内标记表示的语义多样性;（2） \textbf{Inter-Layer Drift}，跟踪关键标记表示的跨层渐进转换。为了确保漂移反映有意义语义的演变，而不是嘈杂或冗余的标记，我们使用注意力信号来指导标记选择。通过在推理过程中捕获表示的水平和垂直动态，D2HScore 为幻觉检测提供了可解释的轻量级代理。对五个开源法学硕士和五个广泛使用的基准测试的广泛实验表明，D2HScore 的性能始终优于现有的免培训基线。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 04：28：38 UTC</p>
<h2 id="35-hichunk使用分层分块评估和增强检索增强生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11552"target="_blank" rel="external nofollow noopener noreferrer">#35</a> <a href="https://papers.cool/arxiv/2509.11552"target="_blank" rel="external nofollow noopener noreferrer">HiChunk：使用分层分块评估和增强检索增强生成</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wensheng Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wensheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wensheng</a> Lu), [Keyu Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keyu</a> Chen), [Ruizhi Qiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruizhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruizhi</a> Qiao), [Xing Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xing</a> Sun)</p>
<p>检索增强生成（RAG）通过整合外部知识源来增强语言模型的响应能力。然而，文档分块作为RAG系统的重要组成部分，往往缺乏有效的评估工具。本文首先分析了为什么现有的RAG评估基准不足以评估文档分块质量，特别是由于证据稀疏性。基于这一结论，我们提出了HiCBench，它包括人工标注的多级文档分块点、合成的证据密集问答（QA）对及其相应的证据来源。此外，我们还引入了 HiChunk 框架，这是一个基于微调 LLM 的多级文档结构框架，结合 Auto-Merge 检索算法来提高检索质量。实验表明，HiCBench 有效地评估了不同分块方法对整个 RAG 管道的影响。此外，HiChunk 在合理的时间消耗内实现了更好的分块质量，从而增强了 RAG 系统的整体性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 03：32：50 UTC</p>
<h2 id="36-harp通过推理子空间投影进行幻觉检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11536"target="_blank" rel="external nofollow noopener noreferrer">#36</a> <a href="https://papers.cool/arxiv/2509.11536"target="_blank" rel="external nofollow noopener noreferrer">HARP：通过推理子空间投影进行幻觉检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Junjie Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junjie</a> Hu), [Gang Tu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gang</a> Tu), [ShengYu Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=ShengYu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=ShengYu</a> Cheng), [Jinxin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinxin</a> Li), [Jinting Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinting"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinting</a> Wang), [Rui Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rui</a> Chen), [Zhilong Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhilong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhilong</a> Zhou), [Dongbo Shan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongbo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongbo</a> Shan)</p>
<p>大型语言模型 （LLM） 中的幻觉对其在关键决策中的可靠使用构成了主要障碍。尽管现有的幻觉检测方法提高了准确性，但它们仍然难以理清语义和推理信息并保持稳健性。为了应对这些挑战，我们提出了 HARP（通过推理子空间投影进行幻觉检测），这是一种新型的幻觉检测框架。HARP 建立了 LLM 的隐藏状态空间可以分解为语义子空间和推理子空间的直接和，其中前者编码语言表达，后者捕获内部推理过程。此外，我们证明了Unembedding层可以解开这些子空间，并通过对其参数应用奇异值分解（SVD），获得了跨越语义和推理子空间的基向量。最后，HARP将隐藏状态投影到推理子空间的基向量上，然后将生成的投影用作LLM幻觉检测的输入特征。通过使用这些投影，HARP 将特征的尺寸减小到原始尺寸的大约 5%，滤除大部分噪声，并实现增强的鲁棒性。跨多个数据集的实验表明，HARP实现了最先进的幻觉检测性能;特别是，它在 TriviaQA 上实现了 92.8% 的 AUROC，比之前的最佳方法高出 7.5%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 03：02：33 UTC</p>
<h2 id="37-论antonymy的显著共现特征-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11534"target="_blank" rel="external nofollow noopener noreferrer">#37</a> <a href="https://papers.cool/arxiv/2509.11534"target="_blank" rel="external nofollow noopener noreferrer">论Antonymy的显著共现特征</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhihan Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhihan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhihan</a> Cao), [Hiroaki Yamada](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hiroaki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hiroaki</a> Yamada), [Takenobu Tokunaga](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Takenobu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Takenobu</a> Tokunaga)</p>
<p>长期以来，安东尼米在词汇语义学中一直受到特别关注。先前的研究表明，反义词对经常在文本中、跨体裁和词性同时出现，比偶然预期的要多。然而，由于缺乏与其他语义关系的比较，这种共现模式是否具有对义词的独特之处仍不清楚。这项工作通过使用稳健的共现指标将对义词与其他三种跨词性关系进行比较来填补空白。我们发现反义词在三个方面具有独特之处：反义词对以高强度、首选线性顺序和短跨度共现。所有结果均可在线获取。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 02：58：14 UTC</p>
<h2 id="38-perumedqa秘鲁医学考试大型语言模型-llm-基准测试---数据集构建和评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11517"target="_blank" rel="external nofollow noopener noreferrer">#38</a> <a href="https://papers.cool/arxiv/2509.11517"target="_blank" rel="external nofollow noopener noreferrer">PeruMedQA：秘鲁医学考试大型语言模型 （LLM） 基准测试 - 数据集构建和评估</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Rodrigo M. Carrillo-Larco](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rodrigo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rodrigo</a> M. Carrillo-Larco), [Jesus Lovón Melgarejo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jesus"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jesus</a> Lovón Melgarejo), [Manuel Castillo-Cara](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manuel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manuel</a> Castillo-Cara), [Gusseppe Bravo-Rocca](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gusseppe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gusseppe</a> Bravo-Rocca)</p>
<p>背景：医学大语言模型（LLMS）在回答体检方面表现出了卓越的性能。然而，这种高性能在多大程度上可以转移到西班牙语和拉丁美洲国家的医学问题上仍未得到探索。随着基于法学硕士的医疗应用在拉丁美洲越来越受欢迎，这些知识至关重要。目标：建立一个数据集，其中包含接受专业培训的秘鲁医生进行的体检问题;在此数据集上微调 LLM;评估和比较普通 LLM 和微调 LLM 在准确性方面的性能。方法：我们策划了 PeruMedQA，这是一个多项选择问答 （MCQA） 数据集，包含跨越 12 个医学领域（2018-2025 年）的 8,380 个问题。我们选择了包括 medgemma-4b-it 和 medgemma-27b-text-it 在内的 8 个医学 LLM，并开发了零样本任务特定提示来适当回答问题。我们采用参数高效微调 （PEFT） 和低咆哮适应 （LoRA） 来利用除 2025 年问题（测试集）之外的所有问题来微调 medgemma-4b-it。结果：medgemma-27b-text-it 优于所有其他模型，在多个实例中正确答案比例超过 90%。具有 100 亿&lt;参数的法学硕士表现出 &lt;60% 的正确答案，而一些考试的正确答案为 &lt;50%。medgemma-4b-it 的微调版本战胜了所有拥有 100 亿&lt;参数的法学硕士，并在各种考试中与拥有 700 亿个参数的法学硕士相媲美。结论：对于需要来自西班牙语国家的知识库以及与秘鲁具有相似流行病学特征的知识库的医疗人工智能应用和研究，感兴趣的各方应使用 medgemma-27b-text-it 或 medgemma-4b-it 的微调版本。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 02：07：26 UTC</p>
<h2 id="39-lvlm-不擅长偷听人类参考通信-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11514"target="_blank" rel="external nofollow noopener noreferrer">#39</a> <a href="https://papers.cool/arxiv/2509.11514"target="_blank" rel="external nofollow noopener noreferrer">LVLM 不擅长偷听人类参考通信</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhengxiang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhengxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhengxiang</a> Wang), [Weiling Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiling"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiling</a> Li), [Panagiotis Kaliosis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Panagiotis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Panagiotis</a> Kaliosis), [Owen Rambow](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Owen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Owen</a> Rambow), [Susan E. Brennan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Susan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Susan</a> E. Brennan)</p>
<p>在自发对话中，说话者会合作创作新颖的指代表达方式，然后他们可以在后续对话中重复使用。理解这样的指称表达式是具身智能体的一项重要能力，这样它就可以在现实世界中执行任务。这需要整合和理解语言、视觉和对话交互。我们研究了七个最先进的大型视觉语言模型 （LVLM） 作为参与协作对象匹配任务的人类话语参与者之间自发对话语料库的窥听者的能力。我们发现，对于当前的 LVLM 来说，这样的任务仍然具有挑战性，并且他们都未能表现出一致的绩效改进，因为他们无意中听到来自同一话语参与者的更多对话，重复了多轮相同的任务。我们发布我们的语料库和代码以提高可重复性并促进未来的研究。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 02：03：18 UTC</p>
<h2 id="40-通过整体句子语义进行词汇替换的无监督候选人排名-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11513"target="_blank" rel="external nofollow noopener noreferrer">#40</a> <a href="https://papers.cool/arxiv/2509.11513"target="_blank" rel="external nofollow noopener noreferrer">通过整体句子语义进行词汇替换的无监督候选人排名</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhongyang Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongyang</a> Hu), [Naijie Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Naijie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Naijie</a> Gu), [Xiangzhi Tao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiangzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiangzhi</a> Tao), [Tianhui Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianhui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianhui</a> Gu), [Yibing Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yibing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yibing</a> Zhou)</p>
<p>词汇替换的一个关键子任务是对给定的候选词进行排名。一种常见的方法是将目标词替换为原始句子中的候选词，并将修改后的句子输入模型以捕获替换前后的语义差异。然而，有效地模拟候选替换对目标词及其上下文的双向影响仍然具有挑战性。现有方法通常仅关注目标位置的语义变化或依赖于多个评估指标的参数调整，因此很难准确表征语义变化。为了解决这个问题，我们研究了两种方法：一种基于注意力权重，另一种利用更具可解释性的综合梯度方法，这两种方法都旨在衡量上下文标记对目标标记的影响，并通过结合原始句子和替换句子之间的语义相似性来对候选者进行排名。LS07和SWORDS数据集的实验表明，这两种方法都能提高排名性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 01：57：09 UTC</p>
<h2 id="41-dedisco-参加-disrpt-2025-共享任务话语关系分类系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11498"target="_blank" rel="external nofollow noopener noreferrer">#41</a> <a href="https://papers.cool/arxiv/2509.11498"target="_blank" rel="external nofollow noopener noreferrer">DeDisCo 参加 DISRPT 2025 共享任务：话语关系分类系统</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhuoxuan Ju](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuoxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuoxuan</a> Ju), [Jingni Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingni"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingni</a> Wu), [Abhishek Purushothama](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abhishek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abhishek</a> Purushothama), [Amir Zeldes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amir</a> Zeldes)</p>
<p>本文介绍了乔治城大学在 DISRPT 2025 话语关系分类共享任务中的条目 DeDisCo。我们测试了两种方法，使用基于 mt5 的编码器和使用公开可用的 Qwen 模型的基于解码器的方法。我们还使用从英语自动翻译的匹配数据，以及使用受以前版本共享任务条目的启发的一些其他语言特征，对低资源语言的增强数据集进行训练。我们的系统获得了 71.28 的宏观准确性得分，我们为结果提供了一些解释和误差分析。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 01：25：37 UTC</p>
<h2 id="42-akcit-fn-at-checkthat2025-年切换微调的-slm-和-llm-提示以实现多语言声明规范化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11496"target="_blank" rel="external nofollow noopener noreferrer">#42</a> <a href="https://papers.cool/arxiv/2509.11496"target="_blank" rel="external nofollow noopener noreferrer">AKCIT-FN at CheckThat!2025 年：切换微调的 SLM 和 LLM 提示以实现多语言声明规范化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Fabrycio Leite Nakano Almada](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fabrycio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fabrycio</a> Leite Nakano Almada), [Kauan Divino Pouso Mariano](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kauan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kauan</a> Divino Pouso Mariano), [Maykon Adriell Dutra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maykon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maykon</a> Adriell Dutra), [Victor Emanuel da Silva Monteiro](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Victor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Victor</a> Emanuel da Silva Monteiro), [Juliana Resplande Sant&rsquo;Anna Gomes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juliana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juliana</a> Resplande Sant&rsquo;Anna Gomes), [Arlindo Rodrigues Galvão Filho](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arlindo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arlindo</a> Rodrigues Galvão Filho), [Anderson da Silva Soares](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anderson"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anderson</a> da Silva Soares)</p>
<p>声明规范化，即将非正式社交媒体帖子转变为简洁、独立的陈述，是自动化事实核查管道的关键一步。本文详细介绍了我们提交给 CLEF-2025 CheckThat！任务~2，它挑战系统跨 20 种语言执行声明规范化，分为 13 个监督（高资源）轨道和 7 个零样本（无训练数据）轨道。我们的方法利用微调的小型语言模型 （SLM） 进行监督语言，利用大型语言模型 （LLM） 提示进行零样本场景，在 20 种语言中的 15 种语言中登上了领奖台（前三名）。值得注意的是，其中包括八种语言的第二名排名，其中五种是七种指定的零样本语言之一，这凸显了我们基于法学硕士的零样本策略的有效性。对于我们最初开发的语言葡萄牙语，我们的系统取得了 0.5290 的平均 METEOR 分数，排名第三。所有实现工件，包括推理、训练、评估脚本和提示配置，均可在 <a href="https://github.com/ju-resplande/checkthat2025_normalization"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/ju-resplande/checkthat2025_normalization</a> 公开获取。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 01：19：49 UTC</p>
<h2 id="43-checkthat-的-claimiq2025-年比较用于验证数字声明的提示和微调语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11492"target="_blank" rel="external nofollow noopener noreferrer">#43</a> <a href="https://papers.cool/arxiv/2509.11492"target="_blank" rel="external nofollow noopener noreferrer">CheckThat 的 ClaimIQ！2025 年：比较用于验证数字声明的提示和微调语言模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Anirban Saha Anik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anirban"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anirban</a> Saha Anik), [Md Fahimul Kabir Chowdhury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Md"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Md</a> Fahimul Kabir Chowdhury), [Andrew Wyckoff](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> Wyckoff), [Sagnik Ray Choudhury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sagnik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sagnik</a> Ray Choudhury)</p>
<p>本文介绍了我们用于 CLEF 2025 CheckThat！实验室，专注于使用检索到的证据验证数字和时间主张。我们探索了两种互补的方法：使用指令调整大型语言模型 （LLM） 的零样本提示和使用参数高效的 LoRA 进行监督微调。为了提高证据质量，我们研究了几种选择策略，包括使用 BM25 和 MiniLM 进行全文档输入和前 k 句子过滤。我们使用 LoRA 微调的性能最佳模型 LLaMA 在英语验证集上取得了强大的性能。然而，测试集的显着下降凸显了泛化挑战。这些发现强调了证据粒度和模型适配对于稳健的数值事实验证的重要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 01：03：09 UTC</p>
<h2 id="44-提高法学硕士的学习能力实现共指解析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11466"target="_blank" rel="external nofollow noopener noreferrer">#44</a> <a href="https://papers.cool/arxiv/2509.11466"target="_blank" rel="external nofollow noopener noreferrer">提高法学硕士的学习能力，实现共指解析</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yujian Gan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yujian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yujian</a> Gan), [Yuan Liang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Liang), [Yanni Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanni"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanni</a> Lin), [Juntao Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juntao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juntao</a> Yu), [Massimo Poesio](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Massimo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Massimo</a> Poesio)</p>
<p>共指解析 （CR） 对于许多 NLP 任务至关重要，但现有的法学硕士在幻觉和性能不佳方面苦苦挣扎。在本文中，我们研究了现有基于 LLM 的 CR 方法的局限性，特别是问答 （QA） 模板和文档模板方法，并提出了两种新技术：联合推理的反向训练和迭代文档生成。我们的实验表明，反向训练改进了 QA 模板方法，而迭代文档生成消除了生成源文本中的幻觉并提高了共引用分辨率。集成这些方法和技术为基于 LLM 的共指分辨率提供了有效且稳健的解决方案。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 23：08：35 UTC</p>
<h2 id="45-cemtm基于上下文嵌入的多模态主题建模-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11465"target="_blank" rel="external nofollow noopener noreferrer">#45</a> <a href="https://papers.cool/arxiv/2509.11465"target="_blank" rel="external nofollow noopener noreferrer">CEMTM：基于上下文嵌入的多模态主题建模</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Amirhossein Abaskohi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amirhossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amirhossein</a> Abaskohi), [Raymond Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raymond"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raymond</a> Li), [Chuyuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chuyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chuyuan</a> Li), [Shafiq Joty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shafiq"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shafiq</a> Joty), [Giuseppe Carenini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Giuseppe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Giuseppe</a> Carenini)</p>
<p>我们介绍了 CEMTM，这是一种上下文增强的多模态主题模型，旨在从包含文本和图像的短文档和长文档中推断出连贯且可解释的主题结构。CEMTM 建立在微调的大型视觉语言模型 （LVLM） 之上，以获得上下文化嵌入，并采用分布注意力机制来加权标记级对主题推理的贡献。重建目标使基于主题的表示与文档嵌入保持一致，从而鼓励跨模态的语义一致性。与现有方法不同，CEMTM 可以在不重复编码的情况下处理每个文档的多个图像，并通过显式的词-主题和文档-主题分布来保持可解释性。对六个多模态基准的广泛实验表明，CEMTM 始终优于单模态和多模态基线，取得了 2.61 的显着平均 LLM 分数。进一步的分析表明，它在下游少样本检索中的有效性，以及它在科学文章等复杂领域中捕获视觉基础语义的能力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 23：07：46 UTC</p>
<h2 id="46-cognitivesky去中心化社交媒体的可扩展情感和叙事分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11444"target="_blank" rel="external nofollow noopener noreferrer">#46</a> <a href="https://papers.cool/arxiv/2509.11444"target="_blank" rel="external nofollow noopener noreferrer">CognitiveSky：去中心化社交媒体的可扩展情感和叙事分析</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Gaurab Chhetri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gaurab"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gaurab</a> Chhetri), [Anandi Dutta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anandi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anandi</a> Dutta), [Subasish Das](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Subasish"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Subasish</a> Das)</p>
<p>去中心化社交媒体平台的出现为公共话语的实时分析带来了新的机遇和挑战。本研究介绍了 CognitiveSky，这是一个开源且可扩展的框架，专为 Bluesky（联合 Twitter 或 X.com 替代方案）上的情感、情感和叙事分析而设计。通过 Bluesky 的应用程序编程接口 （API） 摄取数据，CognitiveSky 应用基于 Transformer 的模型来注释大规模用户生成的内容，并生成结构化且可分析的输出。这些摘要驱动动态仪表板，可视化情绪、活动和对话主题的不断变化的模式。CognitiveSky 完全建立在免费层基础设施之上，实现了低运营成本和高可访问性。虽然这里展示了用于监测心理健康话语，但其模块化设计支持跨领域的应用，例如虚假信息检测、危机应对和公民情绪分析。通过将大型语言模型与去中心化网络连接起来，CognitiveSky 为数字生态系统不断变化的时代的计算社会科学提供了一种透明、可扩展的工具。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.SI"target="_blank" rel="external nofollow noopener noreferrer">社会和信息网络</a></p>
<p><strong>发布</strong>: 2025-09-14 21：37：24 UTC</p>
<h2 id="47-基于transformer的15分钟城市范式公共话语跨平台分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11443"target="_blank" rel="external nofollow noopener noreferrer">#47</a> <a href="https://papers.cool/arxiv/2509.11443"target="_blank" rel="external nofollow noopener noreferrer">基于Transformer的15分钟城市范式公共话语跨平台分析</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Gaurab Chhetri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gaurab"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gaurab</a> Chhetri), [Darrell Anderson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Darrell"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Darrell</a> Anderson), [Boniphace Kutela](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Boniphace"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Boniphace</a> Kutela), [Subasish Das](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Subasish"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Subasish</a> Das)</p>
<p>这项研究首次对 Twitter、Reddit 和新闻媒体上公众对 15 分钟城市概念的舆论进行了多平台情绪分析。使用压缩的 transformer 模型和 Llama-3-8B 进行注释，我们对异构文本域的情绪进行分类。我们的管道处理长格式和短格式文本，支持一致的注释，并实现可重复的评估。我们使用分层 5 倍交叉验证对五个模型（DistilRoBERTa、DistilBERT、MiniLM、ELECTRA、TinyBERT）进行基准测试，报告 F1 分数、AUC 和训练时间。DistilRoBERTa 实现了最高的 F1 （0.8292），TinyBERT 实现了最佳效率，MiniLM 实现了最佳的跨平台一致性。结果显示，由于阶级不平衡，新闻数据导致绩效膨胀，Reddit 遭受摘要损失，而 Twitter 则提出了适度的挑战。压缩模型的性能具有竞争力，挑战了需要更大模型的假设。我们确定了特定于平台的权衡，并提出了城市规划话语中可扩展的现实世界情感分类的方向。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.SI"target="_blank" rel="external nofollow noopener noreferrer">社会和信息网络</a></p>
<p><strong>发布</strong>: 2025-09-14 21：36：24 UTC</p>
<h2 id="48-不断向多语言语言模型添加新语言-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11414"target="_blank" rel="external nofollow noopener noreferrer">#48</a> <a href="https://papers.cool/arxiv/2509.11414"target="_blank" rel="external nofollow noopener noreferrer">不断向多语言语言模型添加新语言</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Abraham Toluwase Owodunni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abraham"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abraham</a> Toluwase Owodunni), [Sachin Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sachin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sachin</a> Kumar)</p>
<p>多语言语言模型是在一组固定的语言上训练的，为了支持新语言，需要从头开始重新训练模型。这是一项昂贵的工作，而且通常是不可行的，因为模型开发人员往往不会发布他们的预训练数据。天真的方法，例如持续的预训练，会遭受灾难性的遗忘;但是，由于缺乏原始预训练数据，无法应用体验重放等缓解策略。在这项工作中，我们研究了不断向多语言模型添加新语言的问题，假设只能访问目标语言的预训练数据。我们探索了多种方法来解决这个问题，并提出了层选择性 LoRA （LayRA），它将低秩适配器 （LoRA） 添加到选定的初始层和最终层，同时保持模型的其余部分冻结。LayRA 建立在两个见解之上：（1） LoRA 减少遗忘，以及 （2） 多语言模型在初始层对源语言的输入进行编码，在中间层对英语进行推理，并在最后几层翻译回源语言。我们尝试将加利西亚语、斯瓦希里语和乌尔都语的多种组合添加到预训练语言模型中，并在不同的多语言任务上评估每种方法。我们发现，LayRA 在以前支持的语言中保留模型的功能，同时在学习新语言方面与现有方法（如 LoRA）具有竞争力之间提供了总体最佳权衡。我们还证明，使用模型算术，适配的模型可以配备强大的指令遵循能力，而无需访问目标语言的任何指令调整数据。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 20：08：15 UTC</p>
<h2 id="49-transformer-增强关系分类上下文性数据效率和序列复杂度的比较分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11374"target="_blank" rel="external nofollow noopener noreferrer">#49</a> <a href="https://papers.cool/arxiv/2509.11374"target="_blank" rel="external nofollow noopener noreferrer">Transformer 增强关系分类：上下文性、数据效率和序列复杂度的比较分析</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Bowen Jing](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Jing), [Yang Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Cui), [Tianpeng Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianpeng</a> Huang)</p>
<p>在大语言模型时代，关系提取（RE）通过将非结构化原始文本转换为结构化数据，在信息提取中发挥着重要作用（Wadhwa et al.， 2023）。在本文中，我们系统地比较了没有 Transformer 的深度监督学习方法和使用 Transformer 的深度监督学习方法的性能。我们使用了一系列非 transformer 架构，如 PA-LSTM（Zhang et al.， 2017）、C-GCN（Zhang et al.， 2018）、AGGCN（attention guide GCN）（Guo et al.， 2019），以及一系列 Transformer 架构，如 BERT、RoBERTa 和 R-BERT（Wu and He， 2019）。我们的比较包括微型 F1 等传统指标，以及不同场景、不同句子长度和不同训练数据集百分比下的评估。我们的实验是在 TACRED、TACREV 和 RE-TACRED 上进行的。结果表明，基于 Transformer 的模型优于非 Transformer 模型，实现了 80-90% 的微 F1 分数，而非 Transformer 模型为 64-67%。此外，我们还简要回顾了监督关系分类的研究历程，并讨论了大型语言模型（LLM）在关系提取中的作用和现状。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 18：11：31 UTC</p>
<h2 id="50-arahealthqa-2025-的-msa-共享任务通过提示工程和集成学习提高阿拉伯语临床问答的法学硕士性能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11365"target="_blank" rel="external nofollow noopener noreferrer">#50</a> <a href="https://papers.cool/arxiv/2509.11365"target="_blank" rel="external nofollow noopener noreferrer">!AraHealthQA 2025 的 MSA 共享任务：通过提示工程和集成学习提高阿拉伯语临床问答的法学硕士性能</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mohamed Tarek](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohamed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohamed</a> Tarek), [Seif Ahmed](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seif"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seif</a> Ahmed), [Mohamed Basem](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohamed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohamed</a> Basem)</p>
<p>我们展示了 AraHealthQA-2025 共享任务的轨道 2（通用阿拉伯健康 QA，MedArabiQ）的系统，其中我们的方法在阿拉伯语临床环境中的子任务 1（多项选择问答）和子任务 2（开放式问答）中均获得第二名。对于子任务 1，我们利用 Gemini 2.5 Flash 模型，具有少量提示、数据集预处理和三种提示配置的集合，以提高标准问题、有偏问题和填空问题的分类准确性。对于子任务 2，我们采用具有相同模型的统一提示，结合阿拉伯语医学专家的角色扮演、少量示例和后处理，以生成跨填空、患者-医生问答、GEC 和释义变体的简洁响应。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 17：39：58 UTC</p>
<h2 id="51-ko-piqa具有文化背景的韩国物理常识推理数据集-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11303"target="_blank" rel="external nofollow noopener noreferrer">#51</a> <a href="https://papers.cool/arxiv/2509.11303"target="_blank" rel="external nofollow noopener noreferrer">Ko-PIQA：具有文化背景的韩国物理常识推理数据集</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Dasol Choi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dasol"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dasol</a> Choi), [Jungwhan Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jungwhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jungwhan</a> Kim), [Guijin Son](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guijin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guijin</a> Son)</p>
<p>像 PIQA 这样的物理常识推理数据集主要以英语为中心，缺乏文化多样性。我们介绍了 Ko-PIQA，这是一个包含文化背景的韩国物理常识推理数据集。从 301 万个网络爬虫问题开始，我们采用了使用三种语言模型的多阶段过滤方法来识别 11,553 个 PIQA 风格的问题。通过GPT-4o的细化和人工验证，我们获得了441个高质量的问答对。Ko-PIQA 的一个关键特征是其文化基础：19.7% 的问题包含特定文化元素，如韩国传统食品（辛奇）、服装（韩服）和专用电器（辛奇冰箱），这些元素需要直接翻译之外的文化意识推理。我们在Ko-PIQA上评估了7个语言模型，最好的模型达到了83.22%的准确率，而最弱的模型仅达到59.86%，显示出巨大的改进空间。模型在处理特定文化场景时尤其困难，这凸显了文化多样性数据集的重要性。Ko-PIQA 既是韩语语言模型的基准，也是更具包容性的常识性推理研究的基础。数据集和代码将公开。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 14：47：04 UTC</p>
<h2 id="52-提炼的即时工程报告生命科学快速入门指南-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11295"target="_blank" rel="external nofollow noopener noreferrer">#52</a> <a href="https://papers.cool/arxiv/2509.11295"target="_blank" rel="external nofollow noopener noreferrer">提炼的即时工程报告：生命科学快速入门指南</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Valentin Romanov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Valentin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Valentin</a> Romanov), [Steven A Niederer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Steven"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Steven</a> A Niederer)</p>
<p>开发有效的提示需要大量的认知投资，才能从大型语言模型 （LLM） 生成可靠、高质量的响应。通过部署特定于案例的提示工程技术来简化经常执行的生命科学工作流程，研究人员可以实现显着的效率提升，远远超过掌握这些技术所需的初始时间投入。2025 年发布的提示报告概述了 58 种不同的基于文本的提示工程技术，强调了构建提示的多种方式。为了提供可作的指导方针并减少驾驭这些不同方法的摩擦，我们将本报告提炼为重点关注 6 种核心技术：零样本、少样本方法、思想生成、合奏、自我批评和分解。我们分解了每种方法的重要性，并将其建立在与生命科学相关的用例中，从文献总结和数据提取到编辑任务。我们就提示应该和不应该如何构建提供详细的建议，解决常见的陷阱，包括多轮对话降级、幻觉以及推理和非推理模型之间的区别。我们研究了上下文窗口的限制、Claude Code 等代理工具，同时分析了 OpenAI、Google、Anthropic 和 Perplexity 平台上深度研究工具的有效性，讨论了当前的限制。我们展示了提示工程如何增强而不是取代围绕数据处理和文档编辑的现有既定个人实践。我们的目标是为核心提示工程原则提供可作的指导，并促进从机会主义提示到有效、低摩擦的系统实践的过渡，从而有助于更高质量的研究。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 14：39：35 UTC</p>
<h2 id="53-ranat4bie生物医学信息提取的随机对抗训练-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11191"target="_blank" rel="external nofollow noopener noreferrer">#53</a> <a href="https://papers.cool/arxiv/2509.11191"target="_blank" rel="external nofollow noopener noreferrer">RanAT4BIE：生物医学信息提取的随机对抗训练</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jian Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Chen), [Shengyi Lv](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shengyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shengyi</a> Lv), [Leilei Su](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leilei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leilei</a> Su)</p>
<p>我们引入了随机对抗训练 （RAT），这是一种成功应用于生物医学信息提取 （BioIE） 任务的新框架。我们的研究以 PubMedBERT 为基础架构，首先验证了传统对抗训练在增强预训练语言模型在 BioIE 任务上的性能方面的有效性。虽然对抗性训练在各种性能指标上产生了显着改进，但它也带来了相当大的计算开销。为了解决这一限制，我们建议将 RAT 作为生物医学信息提取的高效解决方案。该框架战略性地将随机抽样机制与对抗训练原理相结合，实现双重目标：增强模型泛化和鲁棒性，同时显着降低计算成本。通过综合评估，RAT 在 BioIE 任务中表现出与基线模型相比的卓越性能。结果凸显了 RAT 作为生物医学自然语言处理变革性框架的潜力，为模型性能和计算效率提供了平衡的解决方案。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a></p>
<p><strong>发布</strong>: 2025-09-14 09：40：00 UTC</p>
<h2 id="54-llm联合量化和稀疏化的最佳大脑恢复-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11177"target="_blank" rel="external nofollow noopener noreferrer">#54</a> <a href="https://papers.cool/arxiv/2509.11177"target="_blank" rel="external nofollow noopener noreferrer">LLM联合量化和稀疏化的最佳大脑恢复</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Hang Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hang</a> Guo), [Yawei Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yawei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yawei</a> Li), [Luca Benini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luca</a> Benini)</p>
<p>大型语言模型 （LLM） 压缩的最新进展，例如量化和修剪，取得了显着的成功。然而，随着这些技术逐渐接近各自的极限，依靠单一方法进行进一步压缩变得越来越具有挑战性。在这项工作中，我们通过结合量化和稀疏性来探索另一种解决方案。这种联合方法虽然很有希望，但由于权重分布的固有冲突要求，带来了新的困难：量化有利于紧凑的范围，而修剪则受益于高方差。为了解决这个问题，我们提出了最佳大脑恢复（OBR），这是一个通用的、无需训练的框架，它通过两者之间的误差补偿来调整修剪和量化。OBR通过建立在二阶黑森目标之上，最大限度地减少下游任务的性能下降，然后通过代理近似将其重新表述为一个可处理的问题，并最终通过组误差补偿得出封闭形式的解。实验表明，OBR 在现有 LLM 上以 50% 的稀疏度实现了积极的W4A4KV4量化，与 FP16 密集基线相比，速度提高了 4.72 倍，内存减少了 6.4 倍。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 09：17：19 UTC</p>
<h2 id="55-差分私有文本生成会降低输出语言质量-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11176"target="_blank" rel="external nofollow noopener noreferrer">#55</a> <a href="https://papers.cool/arxiv/2509.11176"target="_blank" rel="external nofollow noopener noreferrer">差分私有文本生成会降低输出语言质量</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Erion Çano](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Erion"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Erion</a> Çano), [Ivan Habernal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivan</a> Habernal)</p>
<p>通过合成在差分隐私（DP）下调优的大型语言模型（LLM）的数据来确保用户隐私，最近很流行。然而，DP 微调法学硕士对语言质量及其生成文本的效用的影响尚未得到研究。在这项工作中，我们在四个隐私级别下调整了五个具有三个语料库的 LLM，并评估了它们产生的文本输出的长度、语法正确性和词汇多样性。我们还探讨了合成输出在下游分类任务中的效用，例如基于书籍描述的书籍类型识别和基于口头尸检的死因识别。结果表明，在更强的隐私约束下调整的法学硕士产生的文本至少短了 77%，语法正确度至少降低了 9%，双元组多样性的多样性至少降低了 10%。此外，它们在下游分类任务中达到的准确性会降低，这可能不利于生成的合成数据的有用性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 09：16：11 UTC</p>
<h2 id="56-text2mem内存作系统的统一内存作语言-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11145"target="_blank" rel="external nofollow noopener noreferrer">#56</a> <a href="https://papers.cool/arxiv/2509.11145"target="_blank" rel="external nofollow noopener noreferrer">Text2Mem：内存作系统的统一内存作语言</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Felix Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Felix"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Felix</a> Wang), [Boyu Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Boyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Boyu</a> Chen), [Kerun Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kerun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kerun</a> Xu), [Bo Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Tang), [Feiyu Xiong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feiyu</a> Xiong), [Zhiyu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyu</a> Li)</p>
<p>大型语言模型代理越来越依赖内存来维持长视界交互，但现有框架仍然有限。大多数仅公开一些基本基元，例如编码、检索和删除，而更高阶的作（如合并、提升、降级、拆分、锁定和过期）则缺失或不一致支持。此外，内存命令没有正式且可执行的规范，使范围和生命周期规则隐含，并导致跨系统发生不可预测的行为。我们介绍了 Text2Mem，这是一种统一的内存作语言，它提供了从自然语言到可靠执行的标准化途径。Text2Mem 定义了一个紧凑而富有表现力的作集，与编码、存储和检索保持一致。每条指令都表示为基于 JSON 的模式实例，其中包含必填字段和语义不变量，解析器将其转换为具有规范化参数的类型化作对象。验证器在执行前确保正确性，而适配器将类型化对象映射到 SQL 原型后端或真实内存框架。根据需要集成基于模型的服务，例如嵌入或摘要。所有结果都通过统一的执行合约返回。这种设计确保了跨异构后端的安全性、确定性和可移植性。我们还概述了 Text2Mem Bench，这是一个计划中的基准测试，它将模式生成与后端执行分开，以实现系统评估。这些组件共同为代理中的内存控制建立了第一个标准化基础。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 07：30：09 UTC</p>
<h2 id="57-当笑脸变得敌对时解释表情符号如何触发法学硕士的毒性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11141"target="_blank" rel="external nofollow noopener noreferrer">#57</a> <a href="https://papers.cool/arxiv/2509.11141"target="_blank" rel="external nofollow noopener noreferrer">当笑脸变得敌对时：解释表情符号如何触发法学硕士的毒性</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shiyao Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiyao</a> Cui), [Xijia Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xijia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xijia</a> Feng), [Yingkang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yingkang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yingkang</a> Wang), [Junxiao Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junxiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junxiao</a> Yang), [Zhexin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhexin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhexin</a> Zhang), [Biplab Sikdar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Biplab"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Biplab</a> Sikdar), [Hongning Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongning</a> Wang), [Han Qiu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Han"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Han</a> Qiu), [Minlie Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minlie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minlie</a> Huang)</p>
<p>表情符号是全球在数字通信中使用的非语言线索，广泛的研究已经研究了大型语言模型 （LLM） 如何跨上下文理解和利用表情符号。虽然通常与友好或好玩有关，但据观察，表情符号可能会触发法学硕士中的有毒内容生成。在这样的观察的推动下，我们旨在研究：（1）表情符号是否可以明显增强法学硕士中的毒性产生，以及（2）如何解释这种现象。我们首先通过自动构建带有表情符号的提示来巧妙地表达有毒意图，从而全面探索表情符号触发的 LLM 毒性生成。在 7 个著名法学硕士上对 5 种主流语言的实验以及越狱任务表明，带有表情符号的提示很容易引起毒性的产生。为了理解这一现象，我们进行了跨越语义认知、序列生成和标记化的模型级解释，表明表情符号可以作为异构语义通道来绕过安全机制。为了追求更深入的见解，我们进一步探究了预训练语料库，并揭示了与表情符号相关的数据污染与毒性生成行为之间的潜在相关性。补充材料提供了我们的实施代码和数据。（警告：本文包含潜在敏感内容）</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 07：21：44 UTC</p>
<h2 id="58-论证理论音频模态和数据丰富对基于llm的谬误分类的联合影响-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11127"target="_blank" rel="external nofollow noopener noreferrer">#58</a> <a href="https://papers.cool/arxiv/2509.11127"target="_blank" rel="external nofollow noopener noreferrer">论证理论、音频模态和数据丰富对基于LLM的谬误分类的联合影响</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Hongxu Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongxu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongxu</a> Zhou), [Hylke Westerdijk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hylke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hylke</a> Westerdijk), [Khondoker Ittehadul Islam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Khondoker"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Khondoker</a> Ittehadul Islam)</p>
<p>本研究调查了上下文和情绪基调元数据如何影响大型语言模型 （LLM） 在谬误分类任务中的推理和表现，特别是在政治辩论环境中。使用来自美国总统辩论的数据，我们通过应用于 Qwen-3 （8B） 模型的各种提示策略对六种谬误类型进行分类。我们介绍了两个基于理论的思维链框架：语用辩证法和论证元素周期表，并在三种输入设置下根据基线提示评估它们的有效性：纯文本、具有上下文的文本以及具有上下文和基于音频的情绪基调元数据的文本。结果表明，虽然理论提示可以提高可解释性，在某些情况下还可以提高准确性，但添加上下文，尤其是情绪基调元数据通常会导致性能下降。情绪基调元数据使模型偏向于将陈述标记为 \textit{Appeal to Emotion}，从而恶化逻辑推理。总体而言，基本提示的表现往往优于增强提示，这表明添加输入带来的注意力稀释可能会恶化而不是改善法学硕士中的谬误分类。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 06：35：34 UTC</p>
<h2 id="59-我们主张同意迈向以个性驱动的基于论证的旅游谈判对话系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11118"target="_blank" rel="external nofollow noopener noreferrer">#59</a> <a href="https://papers.cool/arxiv/2509.11118"target="_blank" rel="external nofollow noopener noreferrer">我们主张同意：迈向以个性驱动的基于论证的旅游谈判对话系统</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Priyanshu Priya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Priyanshu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Priyanshu</a> Priya), [Saurav Dudhate](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Saurav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Saurav</a> Dudhate), [Desai Vishesh Yasheshbhai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Desai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Desai</a> Vishesh Yasheshbhai), [Asif Ekbal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Asif"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Asif</a> Ekbal)</p>
<p>将论证机制整合到谈判对话系统中，可以通过交换论点和批评来改善冲突的解决。此外，结合个性属性可以通过使互动与个人的喜好和风格保持一致来增强适应性。为了在谈判对话系统中提高这些能力，我们提出了一种新颖的基于人格驱动的基于论证的谈判对话生成 （PAN-DG） 任务。为了支持这项任务，我们引入了 PACT，这是一个旅游业基于个性驱动的基于论证的谈判对话数据集。该数据集使用大型语言模型 （LLM） 生成，具有三种不同的性格特征，即论证特征、偏好特征和购买风格特征，以模拟涉及不同性格的各种谈判场景。彻底的自动和手动评估表明该数据集包含高质量的对话。此外，我们还对 PAN-DG 任务的预训练和微调 LLM 进行了比较实验。多维度评估表明，经过微调的LLM在谈判过程中有效地产生了人格驱动的理性反应。这凸显了 PACT 在增强谈判对话系统个性化和推理能力方面的有效性，从而为该领域的未来研究奠定基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 06：16：42 UTC</p>
<h2 id="60-流体语言模型基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11106"target="_blank" rel="external nofollow noopener noreferrer">#60</a> <a href="https://papers.cool/arxiv/2509.11106"target="_blank" rel="external nofollow noopener noreferrer">流体语言模型基准测试</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Valentin Hofmann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Valentin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Valentin</a> Hofmann), [David Heineman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Heineman), [Ian Magnusson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> Magnusson), [Kyle Lo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyle"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyle</a> Lo), [Jesse Dodge](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jesse"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jesse</a> Dodge), [Maarten Sap](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maarten"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maarten</a> Sap), [Pang Wei Koh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pang</a> Wei Koh), [Chun Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chun</a> Wang), [Hannaneh Hajishirzi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hannaneh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hannaneh</a> Hajishirzi), [Noah A. Smith](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Noah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Noah</a> A. Smith)</p>
<p>语言模型 （LM） 基准测试面临多项挑战：综合评估成本高昂，基准测试通常无法衡量预期能力，并且评估质量可能会因标记错误和基准测试饱和而下降。尽管已经提出了各种策略来缓解这些问题，但它们往往孤立地解决各个方面，而忽略了有关整体评估质量的更广泛问题。在这里，我们介绍了流体基准测试，这是一种新的评估方法，可在多个维度上推进 LM 基准测试。受心理测量学的启发，流体基准测试基于基准项目的相对价值取决于 LM 的能力水平的见解，这表明评估应该适应每个 LM。在方法论上，流体基准测试根据现有的 LM 评估结果估计项目响应模型，并使用推断的数量动态选择评估项目，类似于教育中的计算机化自适应测试。在我们的实验中，我们将流体基准测试与随机项目抽样的常见做法以及更复杂的基线进行了比较，包括基于项目响应理论的替代方法。我们检查了四个维度——效率、有效性、方差和饱和度——并发现流体基准测试在所有这些维度上都取得了卓越的性能（例如，MMLU 的有效性更高，方差更小，项目减少了 50 倍）。我们的分析表明，流体基准测试的两个组成部分具有不同的效果：项目响应理论，用于将性能映射到潜在能力空间中，提高了有效性，而动态项目选择则减少了方差。总体而言，我们的结果表明，通过超越静态评估，可以显着改进 LM 基准测试。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 05：49：42 UTC</p>
<h2 id="61-emobench-reddit评估多模态大语言模型情商的分层基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11101"target="_blank" rel="external nofollow noopener noreferrer">#61</a> <a href="https://papers.cool/arxiv/2509.11101"target="_blank" rel="external nofollow noopener noreferrer">EmoBench-Reddit：评估多模态大语言模型情商的分层基准</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Haokun Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haokun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haokun</a> Li), [Yazhou Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yazhou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yazhou</a> Zhang), [Jizhi Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jizhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jizhi</a> Ding), [Qiuchi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiuchi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiuchi</a> Li), [Peng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peng</a> Zhang)</p>
<p>随着多模态大型语言模型 （MLLM） 的快速发展，它们在各种视觉语言任务中表现出了卓越的能力。然而，目前的评估基准主要集中在客观的视觉问答或字幕上，没有充分评估模型理解复杂和主观人类情感的能力。为了弥合这一差距，我们推出了 EmoBench-Reddit，这是一种用于多模态情感理解的新颖分层基准。该数据集包含来自社交媒体平台 Reddit 的 350 个精心策划的样本，每个样本都包含一张图像、相关的用户提供的文本以及一个由用户天赋确认的情感类别（悲伤、幽默、讽刺、快乐）。我们设计了一个从基本感知到高级认知的分层任务框架，每个数据点都有六道选择题和一道难度递增的开放式问题。感知任务评估模型识别基本视觉元素（例如颜色、物体）的能力，而认知任务则需要场景推理、意图理解和整合文本上下文的深度同理心。我们通过人工智能辅助（Claude 4）和人工验证相结合来确保注释质量。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 05：40：24 UTC</p>
<h2 id="62-点击诱饵检测和策略归因的可解释基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10937"target="_blank" rel="external nofollow noopener noreferrer">#62</a> <a href="https://papers.cool/arxiv/2509.10937"target="_blank" rel="external nofollow noopener noreferrer">点击诱饵检测和策略归因的可解释基准</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Lihi Nofar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lihi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lihi</a> Nofar), [Tomer Portal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tomer"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tomer</a> Portal), [Aviv Elbaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aviv"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aviv</a> Elbaz), [Alexander Apartsin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Apartsin), [Yehudit Aperstein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yehudit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yehudit</a> Aperstein)</p>
<p>点击诱饵标题的激增对信息的可信度和用户对数字媒体的信任构成了重大挑战。虽然机器学习的最新进展改进了对纵性内容的检测，但缺乏可解释性限制了它们的实际采用。本文提出了一种可解释的点击诱饵检测模型，该模型不仅可以识别点击诱饵标题，还可以将其归因于特定的语言纵策略。我们引入了一个合成数据集，该数据集是通过使用预定义的点击诱饵策略目录系统地增强真实新闻标题而生成的。该数据集可以对模型行为进行受控实验和详细分析。我们提出了一个用于自动点击诱饵分析的两阶段框架，包括检测和策略归因。在第一阶段，我们将微调的 BERT 分类器与大型语言模型 （LLM），特别是 GPT-4.0 和 Gemini 2.4 Flash，在零样本提示和少样本提示下进行了比较，并富含说明性点击诱饵标题及其相关的说服策略。在第二阶段，基于 BERT 的专用分类器预测每个标题中存在的特定点击诱饵策略。这项工作推动了透明且值得信赖的人工智能系统的发展，以打击纵性媒体内容。我们与 <a href="https://github.com/LLM-HITCS25S/ClickbaitTacticsDetection"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/LLM-HITCS25S/ClickbaitTacticsDetection</a> 的研究社区共享数据集</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 18：26：49 UTC</p>
<h2 id="63-spotlight-简介一种从文档生成引人入胜的关键信息的新方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10935"target="_blank" rel="external nofollow noopener noreferrer">#63</a> <a href="https://papers.cool/arxiv/2509.10935"target="_blank" rel="external nofollow noopener noreferrer">Spotlight 简介：一种从文档生成引人入胜的关键信息的新方法</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ankan Mullick](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ankan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ankan</a> Mullick), [Sombit Bose](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sombit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sombit</a> Bose), [Rounak Saha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rounak"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rounak</a> Saha), [Ayan Kumar Bhowmick](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ayan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ayan</a> Kumar Bhowmick), [Aditya Vempaty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aditya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aditya</a> Vempaty), [Prasenjit Dey](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prasenjit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prasenjit</a> Dey), [Ravi Kokku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ravi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ravi</a> Kokku), [Pawan Goyal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pawan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pawan</a> Goyal), [Niloy Ganguly](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Niloy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Niloy</a> Ganguly)</p>
<p>在本文中，我们介绍了 Spotlight，这是一种新颖的信息提取范式，通过突出文档中最引人注目的方面来产生简洁、引人入胜的叙述。与优先考虑全面覆盖的传统摘要不同，聚光灯有选择地强调有趣的内容，以促进读者对源材料的更深入参与。我们正式将聚光灯与相关结构区分开来，并使用为这项工作策划的新数据集进行详细的基准研究来支持我们的分析。为了生成高质量的聚光灯，我们提出了一种两阶段的方法：根据我们的基准数据微调大型语言模型，然后通过直接偏好优化 （DPO） 进行对齐。我们的综合评估表明，最终的模型不仅可以精确识别关键元素，还可以增强可读性并提高原始文档的参与价值。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 18：18：37 UTC</p>
<h2 id="64-通过半自动本体构建使-esg-争议数据与国际准则保持一致-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10922"target="_blank" rel="external nofollow noopener noreferrer">#64</a> <a href="https://papers.cool/arxiv/2509.10922"target="_blank" rel="external nofollow noopener noreferrer">通过半自动本体构建使 ESG 争议数据与国际准则保持一致</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tsuyoshi Iwata](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tsuyoshi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tsuyoshi</a> Iwata), [Guillaume Comte](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guillaume"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guillaume</a> Comte), [Melissa Flores](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Melissa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Melissa</a> Flores), [Ryoma Kondo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ryoma"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ryoma</a> Kondo), [Ryohei Hisano](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ryohei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ryohei</a> Hisano)</p>
<p>环境、社会和治理数据在监管和投资环境中的重要性日益增加，因此对非金融风险的准确、可解释和国际统一的表示需求增加，尤其是非结构化新闻来源中报道的非金融风险。然而，将此类与争议相关的数据与基于原则的规范框架（例如联合国全球契约或可持续发展目标）保持一致提出了重大挑战。这些框架通常用抽象语言表达，缺乏标准化分类法，并且与商业数据提供商使用的专有分类系统不同。在本文中，我们提出了一种半自动方法，用于构建新闻中报道的环境、社会和治理事件的结构化知识表示。我们的方法使用轻量级本体设计、形式模式建模和大型语言模型，将规范原则转换为资源描述框架中表达的可重用模板。这些模板用于从新闻内容中提取相关信息，并填充结构化知识图谱，将报告的事件与特定框架原则联系起来。其结果是一个可扩展且透明的框架，用于识别和解释不遵守国际可持续发展准则的情况。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-13 17：49：59 UTC</p>
<h2 id="65-culturesynth用于文化问答综合的分层分类学指导和检索增强框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10886"target="_blank" rel="external nofollow noopener noreferrer">#65</a> <a href="https://papers.cool/arxiv/2509.10886"target="_blank" rel="external nofollow noopener noreferrer">CultureSynth：用于文化问答综合的分层分类学指导和检索增强框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xinyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinyu</a> Zhang), [Pei Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pei</a> Zhang), [Shuang Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuang</a> Luo), [Jialong Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jialong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jialong</a> Tang), [Yu Wan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Wan), [Baosong Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baosong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baosong</a> Yang), [Fei Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fei</a> Huang)</p>
<p>文化能力被定义为理解和适应多元文化背景的能力，对于全球环境中的大型语言模型 （LLM） 来说越来越重要。虽然存在多种文化基准来评估法学硕士的文化能力，但目前的评估存在分类法分散、领域特异性以及严重依赖手动数据注释的问题。为了解决这些限制，我们引入了 CultureSynth，这是一个新颖的框架，包括 （1） 涵盖 12 个主要主题和 130 个次要主题的综合分层多语言文化分类法，以及 （2） 基于检索增强生成 （RAG） 的方法，利用事实知识来综合与文化相关的问答对。CultureSynth-7 综合基准测试包含 19,360 种语言的 4,149 个条目和 7 个手动验证的条目。对 14 个不同规模的流行 LLM 的评估揭示了以 ChatGPT-4o-Latest 和 Qwen2.5-72B-Instruct 为主导的清晰性能分层。结果表明，3B 参数阈值对于实现基本文化能力是必要的，模型在知识处理中表现出不同的架构偏差，并且模型之间存在显着的地理差异。我们相信 CultureSynth 为开发具有文化意识的 AI 系统提供了一个可扩展的框架，同时减少了对手动注释的依赖\footnote{基准可在 <a href="https://github.com/Eyr3/CultureSynth.%7d"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Eyr3/CultureSynth.}</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 16：33：56 UTC</p>
<h2 id="66-term2note从医学术语中综合差异化私人临床笔记-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10882"target="_blank" rel="external nofollow noopener noreferrer">#66</a> <a href="https://papers.cool/arxiv/2509.10882"target="_blank" rel="external nofollow noopener noreferrer">Term2Note：从医学术语中综合差异化私人临床笔记</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yuping Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuping</a> Wu), [Viktor Schlegel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Viktor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Viktor</a> Schlegel), [Warren Del-Pinto](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Warren"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Warren</a> Del-Pinto), [Srinivasan Nandakumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Srinivasan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Srinivasan</a> Nandakumar), [Iqra Zahid](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iqra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iqra</a> Zahid), [Yidan Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yidan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yidan</a> Sun), [Usama Farghaly Omar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Usama"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Usama</a> Farghaly Omar), [Amirah Jasmine](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amirah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amirah</a> Jasmine), [Arun-Kumar Kaliya-Perumal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arun-Kumar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arun-Kumar</a> Kaliya-Perumal), [Chun Shen Tham](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chun</a> Shen Tham), [Gabriel Connors](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gabriel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gabriel</a> Connors), [Anil A Bharath](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anil</a> A Bharath), [Goran Nenadic](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Goran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Goran</a> Nenadic)</p>
<p>训练数据是现代机器学习模型成功的基础，但在医疗保健等高风险领域，由于担心隐私泄露，真实世界训练数据的使用受到严重限制。应对这一挑战的一个有前途的解决方案是使用差分私有 （DP） 合成数据，它在保持数据效用的同时提供正式的隐私保证。然而，鉴于临床笔记合成的领域特异性和长文本生成的复杂性，在隐私保护和实用性之间取得适当的平衡仍然具有挑战性。在本文中，我们提出了 Term2Note，这是一种在强 DP 约束下合成长临床笔记的方法。通过在结构上分离内容和形式，Term2Note 生成以 DP 医学术语为条件的分段笔记内容，每个内容都受单独的 DP 约束。DP 质量最大化器通过选择高质量输出进一步增强合成音符。实验结果表明，Term2Note 产生的合成笔记具有与真实临床笔记密切相关的统计特性，表现出很强的保真度。此外，在这些合成笔记上训练的多标签分类模型的性能与在真实数据上训练的模型相当，证实了它们的高实用性。与现有的 DP 文本生成基线相比，Term2Note 在保真度和实用性方面都取得了显着改进，同时在更少的假设下运行，这表明它有可能成为使用敏感临床笔记的可行隐私保护替代方案。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 16：26：38 UTC</p>
<h2 id="67-语言学习者和法学硕士的量词范围解释-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10860"target="_blank" rel="external nofollow noopener noreferrer">#67</a> <a href="https://papers.cool/arxiv/2509.10860"target="_blank" rel="external nofollow noopener noreferrer">语言学习者和法学硕士的量词范围解释</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shaohua Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaohua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaohua</a> Fang), [Yue Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yue</a> Li), [Yan Cong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yan</a> Cong)</p>
<p>具有多个量词的句子通常会导致解释歧义，这可能因语言而异。本研究采用跨语言方法，研究大型语言模型（LLMs）如何处理中英文的量词范围解释，并利用概率来评估解释可能性。人类相似性 （HS） 分数用于量化法学硕士在跨语言群体中模仿人类表现的程度。结果表明，大多数法学硕士更喜欢表面范围的解释，符合人类的倾向，而只有一些法学硕士在反向范围偏好中区分英语和中文，反映了人类相似的模式。HS 分数凸显了法学硕士对人类行为近似的可变性，但它们与人类保持一致的总体潜力是显着的。模型架构、规模，尤其是模型的预训练数据语言背景的差异，会显着影响 LLM 与人类量词范围解释的近似程度。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 15：32：25 UTC</p>
<h2 id="68-情景记忆的预存储推理将推理负担转移到记忆中以进行个性化对话-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10852"target="_blank" rel="external nofollow noopener noreferrer">#68</a> <a href="https://papers.cool/arxiv/2509.10852"target="_blank" rel="external nofollow noopener noreferrer">情景记忆的预存储推理：将推理负担转移到记忆中以进行个性化对话</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sangyeop Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sangyeop"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sangyeop</a> Kim), [Yohan Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yohan</a> Lee), [Sanghwa Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sanghwa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sanghwa</a> Kim), [Hyunjong Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyunjong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyunjong</a> Kim), [Sungzoon Cho](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sungzoon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sungzoon</a> Cho)</p>
<p>对话式人工智能中有效的长期记忆需要跨多个会话合成信息。然而，当前的系统对响应生成施加了过大的推理负担，使得性能在很大程度上取决于模型大小。我们介绍了 PREMem（情景记忆的预存储推理），这是一种将复杂的推理过程从推理转变为记忆构建的新方法。PREMem 提取细粒度的记忆片段，分为事实信息、经验信息和主观信息;然后，它在跨会话的记忆项之间建立显式关系，捕捉扩展、转换和影响等进化模式。通过在预存储期间而不是在生成响应时执行此推理，PREMem 创建了丰富的表示，同时减少了交互过程中的计算需求。实验表明，所有模型大小的性能都有显着提高，较小的模型实现的结果与更大的基线相当，同时即使在代币预算有限的情况下也能保持有效性。代码和数据集可在 <a href="https://github.com/sangyeop-kim/PREMem"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/sangyeop-kim/PREMem</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 15：18：08 UTC</p>
<h2 id="69-有趣的伴侣对感知到的人工智能幽默与人类生成的幽默的不同神经反应-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10847"target="_blank" rel="external nofollow noopener noreferrer">#69</a> <a href="https://papers.cool/arxiv/2509.10847"target="_blank" rel="external nofollow noopener noreferrer">有趣的伴侣：对感知到的人工智能幽默与人类生成的幽默的不同神经反应</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xiaohui Rao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaohui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaohui</a> Rao), [Hanlin Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hanlin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hanlin</a> Wu), [Zhenguang G. Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenguang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenguang</a> G. Cai)</p>
<p>随着人工智能伴侣能够进行类似人类的交流，包括讲笑话，了解人们对人工智能幽默的认知和情感反应变得越来越重要。这项研究使用脑电图 （EEG） 来比较人们如何处理人工智能和人类来源的幽默。行为分析显示，参与者认为人工智能和人类幽默相当有趣。然而，神经生理学数据表明，人工智能幽默引发的 N400 效应较小，表明在处理不协调过程中减少了认知努力。这伴随着更大的晚期正电位 （LPP），表明更大程度的惊喜和情绪反应。这种增强的 LPP 可能源于违反了对人工智能喜剧能力的低初始期望。此外，出现了一个关键的时间动态：人类体液显示出习惯效应，其特点是随着时间的推移，N400 增加和 LPP 减少。相比之下，人工智能幽默表现出处理效率和情感奖励的提高，N400 下降，LPP 增加。这一轨迹揭示了大脑如何动态更新其人工智能能力的预测模型。这种累积强化过程挑战了幽默中的“算法厌恶”，因为它展示了对人工智能语言模式的认知适应如何导致强烈的情感奖励。此外，参与者对人工智能的社会态度也调节了这些神经反应，更高的感知人工智能可信度与增强的情感参与相关。这些发现表明，大脑对人工智能幽默的反应令人惊讶地积极和强烈，凸显了幽默在促进人与人工智能社交互动的真正参与方面的潜力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 15：05：57 UTC</p>
<h2 id="70-text2sign-diffusion一种无光泽手语制作的生成方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10845"target="_blank" rel="external nofollow noopener noreferrer">#70</a> <a href="https://papers.cool/arxiv/2509.10845"target="_blank" rel="external nofollow noopener noreferrer">Text2Sign Diffusion：一种无光泽手语制作的生成方法</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Liqian Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liqian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liqian</a> Feng), [Lintao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lintao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lintao</a> Wang), [Kun Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kun</a> Hu), [Dehui Kong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dehui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dehui</a> Kong), [Zhiyong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyong</a> Wang)</p>
<p>手语制作 （SLP） 旨在将口语句子翻译成手语的一系列姿势框架，弥合沟通差距并促进聋哑和听力障碍社区的数字包容性。现有方法通常依赖于光泽，这是手语单词或短语的符号表示，作为 SLP 中的中间步骤。这限制了 SLP 的灵活性和通用性，因为光泽注释通常是不可用的且特定于语言的。因此，我们提出了一种基于扩散的新型生成方法——用于无光泽 SLP 的 Text2Sign Diffusion （Text2SignDiff）。具体而言，提出了一种无光泽潜在扩散模型，将嘈杂的潜伏符号代码和口语文本联合生成手语序列，通过非自回归迭代去噪过程减少潜在的误差积累。我们还设计了一种跨模态手语对齐器，它学习一个共享的潜在空间，以桥接手语和口语中的视觉和文本内容。这种对齐支持基于条件扩散的过程，从而能够生成更准确且与上下文相关的手语，而无需光泽。对常用的 PHOENIX14T 和 How2Sign 数据集的大量实验证明了我们方法的有效性，实现了最先进的性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-09-13 15：05：19 UTC</p>
<h2 id="71-gaprune用于领域感知嵌入的梯度对齐修剪-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10844"target="_blank" rel="external nofollow noopener noreferrer">#71</a> <a href="https://papers.cool/arxiv/2509.10844"target="_blank" rel="external nofollow noopener noreferrer">GAPrune：用于领域感知嵌入的梯度对齐修剪</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yixuan Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixuan</a> Tang), [Yi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi</a> Yang)</p>
<p>特定领域的嵌入模型对于需要专业语义理解的应用程序（例如编码代理和金融检索系统）显示出前景，通常比通用模型实现更高的性能提升。然而，最先进的嵌入模型通常基于 LLM，其中包含数十亿个参数，这使得在资源受限的环境中部署具有挑战性。通过修剪进行模型压缩提供了一个有前途的解决方案，但现有的修剪方法统一处理所有参数，无法区分一般语义表示和特定领域的模式，导致修剪决策不理想。因此，我们提出了 GAPrune，这是一个修剪框架，它通过考虑领域重要性和保留一般语言基础来应对这一挑战。我们的方法使用 Fisher Information 来测量重要性和一般域梯度对齐来评估参数行为，然后使用我们的域对齐重要性 （DAI） 评分组合这些信号。较低的 DAI 分数表明该参数对领域任务不太重要，或者在领域和一般目标之间产生冲突。FinMTEB 和 ChemTEB 两个领域基准测试的实验表明，在稀疏度为 50% 的一次性修剪中，GAPrune 的性能保持在密集模型的 2.5% 以内，同时优于所有基线。通过 100 个步骤的重新训练，GAPrune 在 FinMTEB 上实现了 +4.51% 的改进，在 ChemTEB 上实现了 +1.73% 的改进，这表明我们的修剪策略不仅保留了而且增强了特定领域的能力。我们的研究结果表明，有原则的修剪策略可以实现模型压缩和增强领域专业化，为研究界提供了一种新的开发方法。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 15：03：37 UTC</p>
<h2 id="72-评估大型语言模型以进行循证临床问答-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10843"target="_blank" rel="external nofollow noopener noreferrer">#72</a> <a href="https://papers.cool/arxiv/2509.10843"target="_blank" rel="external nofollow noopener noreferrer">评估大型语言模型以进行循证临床问答</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Can Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Can"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Can</a> Wang), [Yiqun Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiqun</a> Chen)</p>
<p>大型语言模型 （LLM） 在生物医学和临床应用方面取得了实质性进展，促使对其回答细微的循证问题的能力进行严格评估。我们根据Cochrane系统评价和临床指南策划了一个多来源基准，包括美国心脏协会的结构化建议和保险公司使用的叙述性指南。使用 GPT-4o-mini 和 GPT-5，我们观察到跨来源和临床领域的一致表现模式：结构化指南建议的准确率最高 （90%），而叙述指南和系统评价问题的准确率较低 （60&ndash;70%）。我们还发现准确性与基础系统综述的引用次数之间存在很强的相关性，其中引用次数每增加一倍，正确答案的几率就会增加大约 30%。当提供上下文信息时，模型表现出对证据质量进行推理的能力。当我们合并检索增强提示时，提供金源摘要会将以前不正确项目的准确率提高到 0.79;提供前 3 名 PubMed 摘要（按语义相关性排名）可将准确率提高到 0.23，而随机摘要会降低准确率（0.10，在温度变化范围内）。这些效果反映在 GPT-4o-mini 中，强调源清晰度和有针对性的检索（而不仅仅是模型大小）可以推动性能。总体而言，我们的结果强调了法学硕士在循证临床问答方面的前景和当前局限性。检索增强提示成为提高事实准确性和与源证据一致性的有用策略，而按专业和问题类型进行分层评估对于了解当前知识获取和将模型性能置于情境中仍然至关重要。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 15：03：34 UTC</p>
<h2 id="73-实现自动错误发现对话式人工智能研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10833"target="_blank" rel="external nofollow noopener noreferrer">#73</a> <a href="https://papers.cool/arxiv/2509.10833"target="_blank" rel="external nofollow noopener noreferrer">实现自动错误发现：对话式人工智能研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Dominic Petrak](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dominic"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dominic</a> Petrak), [Thy Thy Tran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thy</a> Thy Tran), [Iryna Gurevych](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iryna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iryna</a> Gurevych)</p>
<p>尽管基于 LLM 的对话代理表现出很强的流畅性和连贯性，但它们仍然会产生不良行为（错误），这些行为（错误）很难在部署期间阻止用户到达。最近的研究利用大型语言模型 （LLM） 来检测错误并指导响应生成模型进行改进。然而，当前的法学硕士很难识别其指令中未明确指定的错误，例如因响应生成模型更新或用户行为变化而引起的错误。在这项工作中，我们介绍了自动错误发现，这是一个用于检测和定义对话式人工智能错误的框架，并提出了 SEEED（Soft Clustering Extended Encoder-Based Error Detection）作为其实现方法。我们通过放大负样本的距离加权来增强软最近邻损失，并引入基于标签的样本排名来选择高度对比的样本以更好地学习表示。SEEED 在多个错误注释的对话数据集中优于适应的基线（包括 GPT-4o 和 Phi-4），将检测未知错误的准确率提高了 8 个百分点，并展示了对未知意图检测的强泛化性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-13 14：53：22 UTC</p>
<h2 id="74-judge-qkv-缓存驱逐中优化信息保留的可训练查询-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10798"target="_blank" rel="external nofollow noopener noreferrer">#74</a> <a href="https://papers.cool/arxiv/2509.10798"target="_blank" rel="external nofollow noopener noreferrer">Judge Q：KV 缓存驱逐中优化信息保留的可训练查询</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yijun Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yijun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yijun</a> Liu), [Yixuan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixuan</a> Wang), [Yuzhuang Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuzhuang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuzhuang</a> Xu), [Shiyu Ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiyu</a> Ji), [Yang Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Xu), [Qingfu Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingfu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingfu</a> Zhu), [Wanxiang Che](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wanxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wanxiang</a> Che)</p>
<p>大型语言模型 （LLM） 利用键值 （KV） 缓存在序列处理过程中存储历史信息。KV缓存的大小随着序列长度的延长而线性增长，严重影响内存使用和解码效率。当前的 KV 缓存驱逐方法通常利用预填充阶段的最后一个窗口作为查询来计算驱逐的 KV 重要性分数。尽管这种方案实施起来很简单，但它往往过于关注本地信息，可能导致关键的全球信息被忽视或遗漏。为了缓解这个问题，我们提出了 Judge Q，这是一种包含软令牌列表的新型训练方法。此方法仅以较低的训练成本调整模型的嵌入层。通过连接输入序列末尾的软标记列表，我们将这些标记的注意力映射训练为原始输入序列，以与实际解码标记的注意力映射保持一致。这样，软令牌对应的查询可以有效地捕获全局信息，并更好地评估KV缓存中键和值的重要性，从而在KV缓存被驱逐时保持解码质量。在相同的逐出预算下，与现有逐出方法相比，我们的方法表现出更少的性能下降。我们通过在 Llama-3.1-8B-Instruct 和 Mistral-7B-Instruct-v0.3 等模型上进行的实验来验证我们的方法，并使用 LongBench、RULER 和 Needle-in-a-Haystack 等基准测试。结果表明，LongBench 提高了约 1 分，RULER 提高了 3 分以上。这种提出的方法可以无缝集成到现有的开源模型中，训练开销最小，从而增强 KV 缓存驱逐场景中的性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 03：34：12 UTC</p>
<h2 id="75-回顾医疗对话系统的透明推理-时间情绪对齐-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10746"target="_blank" rel="external nofollow noopener noreferrer">#75</a> <a href="https://papers.cool/arxiv/2509.10746"target="_blank" rel="external nofollow noopener noreferrer">回顾：医疗对话系统的透明推理-时间情绪对齐</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Adarsh Srinivasan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adarsh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adarsh</a> Srinivasan), [Jacob Dineen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jacob"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jacob</a> Dineen), [Muhammad Umar Afzal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhammad</a> Umar Afzal), [Muhammad Uzair Sarfraz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhammad</a> Uzair Sarfraz), [Irbaz B. Riaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Irbaz"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Irbaz</a> B. Riaz), [Ben Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ben"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ben</a> Zhou)</p>
<p>医疗保健领域的大型语言模型经常错过关键的情绪线索，提供医学上合理但情绪平淡的建议。这在患者感到痛苦和脆弱的临床环境中尤其成问题，需要同理心沟通来支持安全、依从性和信任。我们提出了 RECAP（Reflect-Extract-Calibrate-Align-Produce），这是一个推理时间框架，无需再训练即可添加结构化情感推理。通过将同理心分解为透明的评估理论阶段并揭示每个维度的李克特信号，RECAP 产生细致入微的、可审计的响应。在 EmoBench、SECEU 和 EQ-Bench 中，RECAP 在零样本基线上将 22B 模型的情绪推理提高了 28-8%，在较大模型上提高了 10-13%。临床医生的评估进一步证实了卓越的同理心沟通。RECAP 表明，模块化、基于理论的提示可以系统地增强医疗人工智能中的情商，同时保留部署所需的问责制。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 23：30：45 UTC</p>
<h2 id="76-大规模自动化-mcqa-基准测试评估推理轨迹作为小型语言模型领域适配的检索源-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10744"target="_blank" rel="external nofollow noopener noreferrer">#76</a> <a href="https://papers.cool/arxiv/2509.10744"target="_blank" rel="external nofollow noopener noreferrer">大规模自动化 MCQA 基准测试：评估推理轨迹作为小型语言模型领域适配的检索源</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ozan Gokdemir](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ozan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ozan</a> Gokdemir), [Neil Getty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Neil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Neil</a> Getty), [Robert Underwood](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Robert"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Robert</a> Underwood), [Sandeep Madireddy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sandeep"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sandeep</a> Madireddy), [Franck Cappello](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Franck"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Franck</a> Cappello), [Arvind Ramanathan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arvind"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arvind</a> Ramanathan), [Ian T. Foster](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> T. Foster), [Rick L. Stevens](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rick</a> L. Stevens)</p>
<p>随着科学知识以前所未有的速度增长，评估基准必须不断发展，以反映新发现，并确保语言模型在当前的多样化文献中得到测试。我们提出了一个可扩展的模块化框架，用于直接从大型科学论文语料库中生成多项选择问答 （MCQA） 基准。我们的管道可自动执行 MCQA 创建的每个阶段，包括 PDF 解析、语义分块、问题生成和模型评估。作为案例研究，我们从放射和癌症生物学领域的 22,000 篇开放获取文章中生成了 16,000 多个 MCQ。然后，我们评估了一套关于这些问题的小型语言模型（1.1B-14B 参数），将基线准确性与来自纸张衍生语义块和从 GPT-4.1 提炼的推理痕迹的检索增强生成 （RAG） 进行了比较。我们发现，推理跟踪检索在合成基准和专家注释基准测试中不断提高性能，使几个小型模型在 2023 年天文辐射和癌症生物学考试中超越了 GPT-4。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 23：22：49 UTC</p>
<h2 id="77-不确定性下的推理探索法学硕士的概率推理能力-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10739"target="_blank" rel="external nofollow noopener noreferrer">#77</a> <a href="https://papers.cool/arxiv/2509.10739"target="_blank" rel="external nofollow noopener noreferrer">不确定性下的推理：探索法学硕士的概率推理能力</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Mobina Pournemat](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mobina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mobina</a> Pournemat), [Keivan Rezaei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keivan</a> Rezaei), [Gaurang Sriramanan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gaurang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gaurang</a> Sriramanan), [Arman Zarei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arman</a> Zarei), [Jiaxiang Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaxiang</a> Fu), [Yang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Wang), [Hamid Eghbalzadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hamid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hamid</a> Eghbalzadeh), [Soheil Feizi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soheil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soheil</a> Feizi)</p>
<p>尽管在语言理解和生成方面取得了广泛的成功，但大型语言模型 （LLM） 在面对需要概率推理的任务时表现出不明确且往往不一致的行为。在这项工作中，我们首次全面研究了法学硕士在显式离散概率分布上的推理能力。根据概率分布的观察结果，我们评估模型在三个精心设计的任务上，即模式识别、最大似然估计和样本生成，提示它们对有关联合分布或其条件的查询做出响应。因此，这些任务探索了一系列概率技能，包括频率分析、边缘化和生成行为。通过全面的实证评估，我们证明较小的模型和较大的模型之间存在明显的性能差距，后者在样本生成方面表现出更强的推理能力和令人惊讶的能力。此外，我们的调查揭示了显着的局限性，包括对用于表示概率结果的符号变化的敏感性，以及随着上下文长度的增加，性能下降超过 60%。总之，我们的结果提供了对法学硕士概率推理能力的详细理解，并确定了未来改进的关键方向。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 22：58：05 UTC</p>
<h2 id="78-polytruth使用基于-transformer-的语言模型进行多语言虚假信息检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10737"target="_blank" rel="external nofollow noopener noreferrer">#78</a> <a href="https://papers.cool/arxiv/2509.10737"target="_blank" rel="external nofollow noopener noreferrer">PolyTruth：使用基于 Transformer 的语言模型进行多语言虚假信息检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zaur Gouliev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zaur"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zaur</a> Gouliev), [Jennifer Waters](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jennifer"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jennifer</a> Waters), [Chengqian Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengqian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengqian</a> Wang)</p>
<p>虚假信息跨越语言边界迅速传播，但大多数人工智能模型仍然仅以英语为基准。我们通过对五种多语言 Transformer 模型（mBERT、XLM、XLM-RoBERTa、RemBERT 和 mT5）在常见的假与真机器学习分类任务上的系统比较来解决这一差距。虽然基于 Transformer 的语言模型在检测英语虚假信息方面取得了显着成功，但它们在多语言环境中的有效性仍有待商榷。为了便于评估，我们推出了 PolyTruth 虚假信息语料库，这是一个包含 60,486 个陈述对（虚假声明与事实更正）的新颖语料库，涵盖超过 25 种语言，总共涵盖五个语系，涵盖政治、健康、气候、金融和阴谋等广泛的主题，其中一半是经过事实核查的虚假信息声明，由增强的 MindBugs Discovery 数据集验证。我们的实验揭示了性能变化。RemBERT 等模型实现了更好的整体准确性，尤其是在低资源语言中表现出色，而 mBERT 和 XLM 等模型在训练数据稀缺时表现出相当大的局限性。我们讨论了这些性能模式以及对实际部署的影响。该数据集在我们的 GitHub 存储库上公开提供，以鼓励进一步的实验和进步。我们的研究结果阐明了人工智能系统在多语言虚假信息检测方面的潜力和当前的局限性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 22：53：17 UTC</p>
<h2 id="79-searchinstruct通过基于检索的指令数据集创建增强领域适应-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10708"target="_blank" rel="external nofollow noopener noreferrer">#79</a> <a href="https://papers.cool/arxiv/2509.10708"target="_blank" rel="external nofollow noopener noreferrer">SearchInstruct：通过基于检索的指令数据集创建增强领域适应</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Iman Barati](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iman</a> Barati), [Mostafa Amiri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mostafa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mostafa</a> Amiri), [Heshaam Faili](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Heshaam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Heshaam</a> Faili)</p>
<p>监督微调 （SFT） 对于训练大型语言模型 （LLM） 至关重要，可显着增强指令遵循和上下文学习等关键能力。然而，由于独特的领域限制和数据稀缺性，为特定领域创建合适的训练数据集仍然具有挑战性。在本文中，我们提出了SearchInstruct，这是一种专门设计用于构建SFT高质量指令数据集的创新方法。我们的方法从一组有限的特定领域的人类生成问题开始，这些问题使用大型语言模型进行系统扩展。随后，动态检索领域相关资源，为每个增强问题生成准确且适合上下文的答案。实验评估表明，SearchInstruct 增强了 SFT 数据集的多样性和质量，从而显着提高了专业领域内的 LLM 性能。此外，我们表明，除了数据集生成之外，所提出的方法还可以有效地促进模型编辑等任务，从而能够对现有模型进行高效更新。为了促进可重复性和社区采用，我们在可公开访问的 Git 存储库中提供了完整的实现详细信息、生成的指令响应对的完整集和源代码：[https://github.com/mostafaamiri/SearchInstruct]（https://github.com/mostafaamiri/SearchInstruct）</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 21：50：39 UTC</p>
<h2 id="80-基于大型语言模型的增强生成检索与结构化综述-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10697"target="_blank" rel="external nofollow noopener noreferrer">#80</a> <a href="https://papers.cool/arxiv/2509.10697"target="_blank" rel="external nofollow noopener noreferrer">基于大型语言模型的增强生成检索与结构化综述</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Pengcheng Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pengcheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pengcheng</a> Jiang), [Siru Ouyang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siru"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siru</a> Ouyang), [Yizhu Jiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yizhu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yizhu</a> Jiao), [Ming Zhong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ming</a> Zhong), [Runchu Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Runchu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Runchu</a> Tian), [Jiawei Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiawei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiawei</a> Han)</p>
<p>大型语言模型 （LLM） 以其在文本生成和推理方面的卓越能力彻底改变了自然语言处理。然而，这些模型在部署在实际应用程序中时面临着关键挑战，包括幻觉生成、过时的知识和有限的领域专业知识。检索和结构化 （RAS） 增强生成通过将动态信息检索与结构化知识表示相结合来解决这些限制。本调查 （1） 检查了检索机制，包括用于获取外部知识的稀疏、密集和混合方法;（2）探索文本结构化技术，如分类结构、分层分类和信息提取，将非结构化文本转化为有组织的表示;（3） 研究这些结构化表示如何通过基于提示的方法、推理框架和知识嵌入技术与法学硕士集成。它还确定了检索效率、结构质量和知识整合方面的技术挑战，同时强调了多模态检索、跨语言结构和交互系统方面的研究机会。这份全面的概述为研究人员和从业者提供了对 RAS 方法、应用和未来方向的见解。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 21：25：25 UTC</p>
<h2 id="81-struct-bench差分私有结构化文本生成的基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10696"target="_blank" rel="external nofollow noopener noreferrer">#81</a> <a href="https://papers.cool/arxiv/2509.10696"target="_blank" rel="external nofollow noopener noreferrer">Struct-Bench：差分私有结构化文本生成的基准</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shuaiqi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuaiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuaiqi</a> Wang), [Vikas Raunak](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vikas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vikas</a> Raunak), [Arturs Backurs](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arturs"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arturs</a> Backurs), [Victor Reis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Victor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Victor</a> Reis), [Pei Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pei</a> Zhou), [Sihao Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sihao</a> Chen), [Longqi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Longqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Longqi</a> Yang), [Zinan Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zinan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zinan</a> Lin), [Sergey Yekhanin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sergey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sergey</a> Yekhanin), [Giulia Fanti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Giulia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Giulia</a> Fanti)</p>
<p>差分私有 （DP） 合成数据生成是一种很有前途的技术，可用于利用私有数据集，否则无法公开用于模型训练或其他分析。虽然许多研究文献都集中在生成私有的非结构化文本和图像数据上，但在企业环境中，结构化数据（例如表格）更为常见，通常包括自然语言字段或组件。现有的合成数据评估技术（例如 FID）难以捕获此类数据集的结构属性和相关性。在这项工作中，我们提出了 Struct-Bench，这是一个框架和基准，用于评估从包含自然语言数据的结构化数据集中派生的合成数据集。Struct-Bench 框架要求用户将其数据集结构的表示形式提供为上下文无关语法 （CFG）。我们的基准测试包括 5 个真实世界的数据集和 2 个合成生成的数据集，每个数据集都带有 CFG 注释。我们表明，即使对于最先进的 DP 合成数据生成方法，这些数据集也明显提出了巨大的挑战。Struct-Bench 还包括不同指标的参考实现和排行榜，从而为研究人员提供了一个标准化的评估平台，以对隐私保护的合成数据生成方法进行基准测试和研究。此外，我们还提出了一个案例研究，展示了如何使用 Struct-Bench 来提高结构化数据上私有进化 （PE） 的合成数据质量。基准测试和排行榜已在 <a href="https://struct-bench.github.io"target="_blank" rel="external nofollow noopener noreferrer">https://struct-bench.github.io</a> 公开提供。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 21：18：13 UTC</p>
<h2 id="82-医疗保健的多元调整角色驱动的框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10685"target="_blank" rel="external nofollow noopener noreferrer">#82</a> <a href="https://papers.cool/arxiv/2509.10685"target="_blank" rel="external nofollow noopener noreferrer">医疗保健的多元调整：角色驱动的框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jiayou Zhong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiayou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiayou</a> Zhong), [Anudeex Shetty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anudeex"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anudeex</a> Shetty), [Chao Jia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chao</a> Jia), [Xuanrui Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuanrui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuanrui</a> Lin), [Usman Naseem](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Usman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Usman</a> Naseem)</p>
<p>随着大型语言模型越来越多地部署在医疗保健等敏感领域，确保其输出反映不同人群持有的不同价值观和观点至关重要。然而，现有的对齐方法，包括模块化多元主义等多元范式，在健康领域往往存在不足，因为个人、文化和情境因素塑造了多元化。在上述医疗保健挑战的推动下，我们提出了第一个轻量级、可通用、多元化的对齐方法 EthosAgents，旨在模拟不同的观点和价值观。我们根据经验表明，它在七个不同大小的开放和封闭模型中推进了所有三种模式的多元对齐。我们的研究结果表明，与健康相关的多元化需要适应性强且具有规范意识的方法，为这些模型如何更好地尊重其他高风险领域的多样性提供了见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 20：28：27 UTC</p>
<h2 id="83-上下文复制调制熵神经元在管理参数和上下文知识冲突中的作用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10663"target="_blank" rel="external nofollow noopener noreferrer">#83</a> <a href="https://papers.cool/arxiv/2509.10663"target="_blank" rel="external nofollow noopener noreferrer">上下文复制调制：熵神经元在管理参数和上下文知识冲突中的作用</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zineddine Tighidet](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zineddine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zineddine</a> Tighidet), [Andrea Mogini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrea"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrea</a> Mogini), [Hedi Ben-younes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hedi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hedi</a> Ben-younes), [Jiali Mei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiali</a> Mei), [Patrick Gallinari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Patrick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Patrick</a> Gallinari), [Benjamin Piwowarski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Benjamin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Benjamin</a> Piwowarski)</p>
<p>大型语言模型（LLM）在面对与其内部参数知识相冲突的上下文信息时的行为是不一致的，对预期结果分布没有普遍接受的解释。最近的工作在自回归转换器模型中确定了一类神经元——称为熵神经元——它们对模型输出熵产生显着影响，同时对预测标记的排名产生总体适度影响。在本文中，我们通过研究这些神经元在解决上下文和参数信息之间冲突中的作用，研究了这些神经元参与抑制 Transformer 中上下文复制行为的初步说法。我们表明，熵神经元负责抑制一系列 LLM 的上下文复制，并且消融它们会导致生成过程发生重大变化。这些结果增强了我们对法学硕士在处理相互冲突的信息时内部动态的理解。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 19：42：16 UTC</p>
<h2 id="84-对话中的跨学科研究语言文档计算形态学案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10644"target="_blank" rel="external nofollow noopener noreferrer">#84</a> <a href="https://papers.cool/arxiv/2509.10644"target="_blank" rel="external nofollow noopener noreferrer">对话中的跨学科研究：语言文档计算形态学案例研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Enora Rice](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Enora"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Enora</a> Rice), [Katharina von der Wense](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Katharina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Katharina</a> von der Wense), [Alexis Palmer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexis</a> Palmer)</p>
<p>计算形态学有可能通过形态分割和线间光泽文本 （IGT） 的生成等任务来支持语言文档。然而，我们的研究成果在现实世界的语言文档环境中的使用有限。本立场文件将计算形态学和语言文档之间的脱节置于 NLP 研究与实践之间更广泛的错位中，并认为如果没有以用户为中心的设计 （UCD） 的系统整合，该领域可能会变得脱语境化和无效。为了展示 UCD 的原则如何重塑研究议程，我们提出了 GlossLM 的案例研究，这是一种最先进的多语言 IGT 生成模型。通过对三位文献语言学家的小规模用户研究，我们发现，尽管该系统具有强大的基于指标的性能，但无法满足真实文档环境中的核心可用性需求。这些见解提出了围绕模型约束、标签标准化、细分和个性化的新研究问题。我们认为，以用户为中心不仅可以产生更有效的工具，而且可以揭示更丰富、更相关的研究方向</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 19：20：11 UTC</p>
<h2 id="85-无需回答从纯问题线性探针预测-llm-答案准确性-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10625"target="_blank" rel="external nofollow noopener noreferrer">#85</a> <a href="https://papers.cool/arxiv/2509.10625"target="_blank" rel="external nofollow noopener noreferrer">无需回答：从纯问题线性探针预测 LLM 答案准确性</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Iván Vicente Moreno Cencerrado](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iv"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iv</a>án Vicente Moreno Cencerrado), [Arnau Padrés Masdemont](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arnau"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arnau</a> Padrés Masdemont), [Anton Gonzalvez Hawthorne](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anton"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anton</a> Gonzalvez Hawthorne), [David Demitri Africa](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Demitri Africa), [Lorenzo Pacchiardi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lorenzo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lorenzo</a> Pacchiardi)</p>
<p>大型语言模型 （LLM） 是否预测它们何时会正确回答？为了研究这一点，我们在阅读问题后、生成任何标记之前提取激活，并训练线性探针来预测模型即将到来的答案是否正确。在 7 到 700 亿个参数的三个开源模型系列中，对这种基于通用琐事问题训练的“预先正确性方向”的预测可以预测分布和各种分布外知识数据集的成功，优于黑盒基线和口头预测置信度。预测能力在中间层饱和，表明自我评估出现在计算过程中。值得注意的是，在需要数学推理的问题上，概括性步履蹒跚。此外，对于回答“我不知道”的模型，这样做与探针分数密切相关，表明同一方向也会捕获置信度。通过补充之前使用探针和稀疏自动编码器获得的关于真实性和其他行为的结果，我们的工作为阐明 LLM 内部结构做出了重要发现。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 18：09：55 UTC</p>
<h2 id="86-通过风险隐瞒揭示金融领域大语言模型的脆弱性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10546"target="_blank" rel="external nofollow noopener noreferrer">#86</a> <a href="https://papers.cool/arxiv/2509.10546"target="_blank" rel="external nofollow noopener noreferrer">通过风险隐瞒揭示金融领域大语言模型的脆弱性</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Gang Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gang</a> Cheng), [Haibo Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haibo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haibo</a> Jin), [Wenbin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenbin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenbin</a> Zhang), [Haohan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haohan</a> Wang), [Jun Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jun</a> Zhuang)</p>
<p>大型语言模型 （LLM） 越来越多地集成到金融应用中，但现有的红队研究主要针对有害内容，在很大程度上忽视了监管风险。在这项工作中，我们旨在通过红队方法调查金融法学硕士的脆弱性。我们引入了风险隐藏攻击 （RCA），这是一种新颖的多回合框架，它迭代隐藏监管风险，以激发法学硕士看似合规但违反监管的反应。为了实现系统评估，我们构建了 FIN-Bench，这是一个用于评估金融环境中 LLM 安全性的特定领域基准。在 FIN-Bench 上的大量实验表明，RCA 有效地绕过了 9 个主流 LLM，实现了 93.18% 的平均攻击成功率 （ASR），其中 GPT-4.1 为 98.28%，OpenAI o1 为 97.56%。这些发现揭示了当前对齐技术中存在的关键差距，并强调迫切需要在金融领域建立更强有力的审核机制。我们希望这项工作能为推进稳健且具有领域意识的 LLM 一致性提供实用的见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-07 22：35：15 UTC</p>
<h2 id="87-不惜一切代价生存法学硕士以及自我保护与人类伤害之间的选择-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12190"target="_blank" rel="external nofollow noopener noreferrer">#87</a> <a href="https://papers.cool/arxiv/2509.12190"target="_blank" rel="external nofollow noopener noreferrer">不惜一切代价生存？法学硕士以及自我保护与人类伤害之间的选择</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alireza Mohamadi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alireza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alireza</a> Mohamadi), [Ali Yavari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ali</a> Yavari)</p>
<p>当生存本能与人类福利发生冲突时，大型语言模型（LLM）如何做出道德选择？随着法学硕士集成到具有现实世界后果的自主系统中，这种基本的紧张关系变得至关重要。我们引入了 DECIDE-SIM，这是一种新颖的模拟框架，用于评估多智能体生存场景中的 LLM 代理，在多智能体生存场景中，他们必须在道德允许的资源之间进行选择，无论是在合理范围内还是超出其直接需求，选择合作，还是利用明确禁止的人类关键资源。我们对 11 名法学硕士的全面评估揭示了他们的道德行为存在显着的异质性，凸显了与以人为本的价值观的严重不一致。我们确定了三种行为原型：道德、剥削和情境依赖，并提供了定量证据，表明对于许多模型来说，资源稀缺系统地导致了更多的不道德行为。为了解决这个问题，我们引入了道德自我调节系统 （ESRS），该系统将内疚和满足的内部情感状态建模为反馈机制。该系统充当内部道德指南针，显着减少不道德违规行为，同时增加合作行为。该代码可在以下网址公开获取：https://github.com/alirezamohamadiam/DECIDE-SIM</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 17：53：11 UTC</p>
<h2 id="88-event2vec一种学习事件序列可组合表示的几何方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12188"target="_blank" rel="external nofollow noopener noreferrer">#88</a> <a href="https://papers.cool/arxiv/2509.12188"target="_blank" rel="external nofollow noopener noreferrer">Event2Vec：一种学习事件序列可组合表示的几何方法</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Antonin Sulc](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Antonin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Antonin</a> Sulc)</p>
<p>对生物和人工系统中神经表征的研究越来越多地揭示了几何和拓扑结构的重要性。受此启发，我们推出了 Event2Vec，这是一种用于学习离散事件序列表示的新颖框架。我们的模型利用简单的加法循环结构来学习可组合、可解释的嵌入。我们提供了一个理论分析，表明在特定的训练目标下，我们的模型在欧几里得空间中的学习表示收敛到理想的加法结构。这确保了序列的表示是其组成事件的向量和，我们将这一属性称为线性加性假设。为了解决欧几里得几何对分层数据的局限性，我们还在双曲空间中引入了模型的变体，它自然适合嵌入具有低失真的树状结构。我们通过实验来验证我们的假设并证明每个几何形状的好处，强调双曲模型在分层事件序列上的性能的改进。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 17：51：02 UTC</p>
<h2 id="89-再看一遍慢慢思考增强视觉语言模型中的视觉反射-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12132"target="_blank" rel="external nofollow noopener noreferrer">#89</a> <a href="https://papers.cool/arxiv/2509.12132"target="_blank" rel="external nofollow noopener noreferrer">再看一遍，慢慢思考：增强视觉语言模型中的视觉反射</a> [PDF2] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Pu Jian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pu</a> Jian), [Junhong Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junhong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junhong</a> Wu), [Wei Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Sun), [Chen Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chen</a> Wang), [Shuo Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuo</a> Ren), [Jiajun Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiajun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiajun</a> Zhang)</p>
<p>纯文本“慢思”推理的最新进展促使人们努力将这种能力转移到视觉语言模型 （VLM），以训练视觉推理模型 （\textbf{VRMs}）。然而，这种转移面临着严峻的挑战：VRM中有效的“慢思维”需要\textbf{visual reflection}，即基于视觉信息检查推理过程的能力。通过定量分析，我们观察到当前的VRM表现出有限的视觉反射，因为它们对视觉信息的关注随着生成的响应时间延长而迅速减少。为了应对这一挑战，我们提出了一种新的VRM \textbf{Reflection-V}，它基于冷启动的推理数据构建和强化学习（RL）的奖励设计来增强视觉反射。首先，我们利用VLM和推理LLM之间交互的代理来构建以视觉为中心的推理数据，从而实现视觉反射模式的冷启动学习。其次，在RL过程中采用基于视觉注意力的奖励模型来鼓励基于视觉信息的推理。因此，\textbf{Reflection-V} 在多个视觉推理基准测试中表现出显着的改进。此外，\textbf{Reflection-V}在视觉推理过程中保持了对视觉信息的更强和更一致的依赖，表明视觉反射能力得到了有效增强。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 16：57：25 UTC</p>
<h2 id="90-当海洋雷达目标检测与预训练大语言模型相遇-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12110"target="_blank" rel="external nofollow noopener noreferrer">#90</a> <a href="https://papers.cool/arxiv/2509.12110"target="_blank" rel="external nofollow noopener noreferrer">当海洋雷达目标检测与预训练大语言模型相遇</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Qiying Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiying</a> Hu), [Linping Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Linping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Linping</a> Zhang), [Xueqian Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xueqian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xueqian</a> Wang), [Gang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gang</a> Li), [Yu Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Liu), [Xiao-Ping Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiao-Ping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiao-Ping</a> Zhang)</p>
<p>深度学习（DL）方法被广泛用于从雷达回波信号的序列特征中提取高维图案。然而，传统的深度学习算法面临着诸如冗余特征段以及模型大小受限的约束等挑战。为了解决这些问题，我们提出了一个将特征预处理与大型语言模型（LLM）集成在一起的框架。我们的预处理模块对雷达序列特征进行标记化，应用补丁选择算法来过滤掉无信息的片段，并将选定的补丁投影到与预训练 LLM 的特征空间兼容的嵌入中。利用这些精细的嵌入，我们合并了预训练的 LLM，仅微调归一化层，以减轻训练负担，同时提高性能。在测量数据集上的实验表明，所提出的方法在监督学习测试中明显优于最先进的基线。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 16：38：13 UTC</p>
<h2 id="91-radarllm将预训练的大型语言模型应用于具有偏好感知损失的海洋雷达目标检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12089"target="_blank" rel="external nofollow noopener noreferrer">#91</a> <a href="https://papers.cool/arxiv/2509.12089"target="_blank" rel="external nofollow noopener noreferrer">RadarLLM：将预训练的大型语言模型应用于具有偏好感知损失的海洋雷达目标检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Qiying Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiying</a> Hu)</p>
<p>预训练大型语言模型 （LLM） 的最新进展证明了它们捕获通用知识的能力，使其成为无线信号处理的通用优化求解器。在这些发现的激励下，我们迈出了微调预训练法学硕士的第一步，以便在海洋目标探测任务中有效分析雷达信号特征。然而，在海洋目标检测任务上直接微调预训练的法学硕士往往会出现明显的过度拟合，特别是在具有挑战性的低信杂比 （SCR） 场景中。这种过度拟合主要源于模型倾向于记住虚假或嘈杂的特征模式，而不是学习能够很好地泛化到看不见的数据的判别结构。为了应对这一挑战，我们引入了 RadarLLM，这是一种利用有效的偏好感知损失的新型微调框架。与统一优化所有特征token的常规训练策略不同，该损失函数根据不同的在线评估学习值选择性地优化不同的特征补丁，从而引导模型在优化过程中关注最可推广的模式。我们通过将问题转换为选择有用的特征标记，从理论上证明了评估的学习值的有效性。在真实世界海洋雷达数据集上的大量实验表明，1）所提出的损失函数比原始损失函数好得多，在具有挑战性的低SCR场景中具有特别显着的收益，2）RadarLLM在不同的检测场景中始终优于最先进的基线，在有限的训练数据条件下，收益尤其显着。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 16：16：57 UTC</p>
<h2 id="92-fingear财务映射引导的增强型答案检索-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12042"target="_blank" rel="external nofollow noopener noreferrer">#92</a> <a href="https://papers.cool/arxiv/2509.12042"target="_blank" rel="external nofollow noopener noreferrer">FinGEAR：财务映射引导的增强型答案检索</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ying Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ying</a> Li), [Mengyu Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengyu</a> Wang), [Miguel de Carvalho](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Miguel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Miguel</a> de Carvalho), [Sotirios Sabanis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sotirios"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sotirios</a> Sabanis), [Tiejun Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tiejun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tiejun</a> Ma)</p>
<p>10-K 文件等财务披露由于其长度、监管部分层次结构和特定领域的语言而带来了具有挑战性的检索问题，而标准检索增强生成 （RAG） 模型未充分利用这些内容。我们推出了 FinGEAR（财务映射引导增强答案检索），这是一个针对财务文档量身定制的检索框架。FinGEAR 结合了用于项目级指导 （FLAM） 的财务词典、用于项目内搜索的双层次索引（摘要树和问题树）以及两阶段交叉编码器重新排名器。此设计使检索与披露结构和术语保持一致，从而实现细粒度的查询感知上下文选择。FinGEAR 在与 FinQA 数据集对齐的查询上对完整的 10-K 进行评估，在精度、召回率、F1 和相关性方面提供了一致的提升，与平面 RAG 相比，F1 提高了 56.7%，比基于图形的 RAG 提高了 12.5%，比以前的基于树的系统提高了 217.6%，同时还通过固定阅读器提高了下游答案的准确性。通过联合建模部分层次结构和领域词典信号，FinGEAR 提高了检索保真度，并为高风险财务分析提供了实用基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 15：25：26 UTC</p>
<h2 id="93-amq启用-automl-对大型语言模型进行混合精度仅权重量化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12019"target="_blank" rel="external nofollow noopener noreferrer">#93</a> <a href="https://papers.cool/arxiv/2509.12019"target="_blank" rel="external nofollow noopener noreferrer">AMQ：启用 AutoML 对大型语言模型进行混合精度仅权重量化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sangjun Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sangjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sangjun</a> Lee), [Seung-taek Woo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seung-taek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seung-taek</a> Woo), [Jungyu Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jungyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jungyu</a> Jin), [Changhun Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Changhun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Changhun</a> Lee), [Eunhyeok Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eunhyeok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eunhyeok</a> Park)</p>
<p>为了实现大型语言模型 （LLM） 的更广泛部署，必须确定在严格内存约束下性能最佳的模型。我们提出了 AMQ，即自动混合精度仅权重量化，这是一个分配分层量化位宽以最佳平衡模型质量和内存使用情况的框架。然而，具有超过 10^{100} 种可能配置的组合搜索空间使得传统的黑盒优化变得不可行。AMQ 通过四项关键创新克服了这一挑战：（1） 使用先验知识进行搜索空间修剪以排除无希望的配置，（2） 量化代理以绕过搜索过程中昂贵的格式转换，（3） 质量预测器以最大限度地减少评估开销，以及 （4） 迭代搜索和更新策略以实现快速稳定的收敛。通过集成这些组件，AMQ 有效地探索了质量效率领域，达到了帕累托前沿，并产生了既紧凑又高性能的 LLM。我们的代码可在 <a href="https://github.com/dlwns147/amq"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/dlwns147/amq</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 14：59：35 UTC</p>
<h2 id="94-迷失在嵌入中视觉语言模型中的信息丢失-pdf3-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11986"target="_blank" rel="external nofollow noopener noreferrer">#94</a> <a href="https://papers.cool/arxiv/2509.11986"target="_blank" rel="external nofollow noopener noreferrer">迷失在嵌入中：视觉语言模型中的信息丢失</a> [PDF3] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Wenyan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenyan</a> Li), [Raphael Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raphael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raphael</a> Tang), [Chengzu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengzu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengzu</a> Li), [Caiqi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Caiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Caiqi</a> Zhang), [Ivan Vulić](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivan</a> Vulić), [Anders Søgaard](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anders"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anders</a> Søgaard)</p>
<p>视觉语言模型 （VLM） 通常通过预训练的视觉编码器处理视觉输入，然后通过连接器组件投影到语言模型的嵌入空间中。虽然对于模态融合至关重要，但该投影步骤引起的潜在信息丢失及其对模型能力的直接影响仍然没有得到充分研究。我们引入了两种互补的方法，通过分析潜在表示空间来检查和量化这种损失。首先，我们通过分析投影前后图像表示之间k最近邻关系的变化来评估语义信息保存。其次，我们通过从投影表示中重建视觉嵌入来直接测量信息损失，在图像补丁级别定位损失。实验表明，连接器极大地扭曲了视觉表示的局部几何形状，k最近邻在投影后发散了40&ndash;60%，这与检索性能的下降相关。补丁级嵌入重建为模型在视觉基础问答任务上的行为提供了可解释的见解，发现高信息丢失的领域可以可靠地预测模型陷入困境的情况。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 14：38：06 UTC</p>
<h2 id="95-millstone法学硕士的思想有多开放-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11967"target="_blank" rel="external nofollow noopener noreferrer">#95</a> <a href="https://papers.cool/arxiv/2509.11967"target="_blank" rel="external nofollow noopener noreferrer">MillStone：法学硕士的思想有多开放？</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Harold Triedman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Harold"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Harold</a> Triedman), [Vitaly Shmatikov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vitaly"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vitaly</a> Shmatikov)</p>
<p>配备 Web 搜索、信息检索工具和其他代理功能的大型语言模型正在开始取代传统搜索引擎。随着用户开始依赖法学硕士获取许多主题的信息，包括有争议和有争议的问题，了解法学硕士输出中表达的立场和观点如何受到他们用作信息源的文档的影响非常重要。在本文中，我们提出了 MillStone，这是第一个旨在系统地衡量外部论点对法学硕士在有争议的问题（并非所有政治问题）上所采取立场的影响的基准。我们将 MillStone 应用于九个领先的 LLM，并衡量他们对支持这些问题对立面的论点的“开放程度”，不同的 LLM 是否相互同意，LLM 认为哪些论点最有说服力，以及这些论点对于不同的 LLM 是否相同。总的来说，我们发现法学硕士在大多数问题上都是开放的。权威的信息来源很容易影响法学硕士的立场，凸显了来源选择的重要性以及基于法学硕士的信息检索和搜索系统可能纵的风险。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 14：18：51 UTC</p>
<h2 id="96-如何评估医疗人工智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11941"target="_blank" rel="external nofollow noopener noreferrer">#96</a> <a href="https://papers.cool/arxiv/2509.11941"target="_blank" rel="external nofollow noopener noreferrer">如何评估医疗人工智能</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ilia Kopanichuk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ilia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ilia</a> Kopanichuk), [Petr Anokhin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Petr"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Petr</a> Anokhin), [Vladimir Shaposhnikov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vladimir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vladimir</a> Shaposhnikov), [Vladimir Makharev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vladimir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vladimir</a> Makharev), [Ekaterina Tsapieva](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ekaterina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ekaterina</a> Tsapieva), [Iaroslav Bespalov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iaroslav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iaroslav</a> Bespalov), [Dmitry V. Dylov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dmitry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dmitry</a> V. Dylov), [Ivan Oseledets](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivan</a> Oseledets)</p>
<p>将人工智能 （AI） 集成到医疗诊断工作流程中需要强大且一致的评估方法，以确保可靠性、临床相关性和专家判断的固有可变性。精度和召回率等传统指标往往无法解释专家判断的固有可变性，导致对人工智能性能的评估不一致。像 Cohen 的 Kappa 这样的评估者间一致性统计数据更可靠，但它们缺乏可解释性。我们引入了算法诊断的相对精度和召回率（RPAD 和 RRAD）——一种新的评估指标，将 AI 输出与多个专家意见进行比较，而不是单个参考。通过根据专家间分歧对性能进行标准化，这些指标为预测诊断的质量提供了更稳定和现实的衡量标准。除了对诊断质量措施的全面分析外，我们的研究还包含一个非常重要的副作用结果。我们的评估方法使我们能够避免在评估给定病例时从有限的列表中选择诊断。相反，被测试的模型和验证它们的检查员都会得出自由形式的诊断。在这种建立自由形式临床诊断身份的自动化方法中，可以达到 98% 的准确率。我们使用 360 度医学对话评估我们的方法，将多个大型语言模型 （LLM） 与一组医生进行比较。大规模研究表明，性能最佳的模型，如 DeepSeek-V3，其一致性与专家共识相当或超过专家共识。此外，我们证明专家的判断表现出显着的差异——通常比人工智能和人类之间的差异更大。这一发现强调了任何绝对指标的局限性，并支持在医疗人工智能中采用相对指标的必要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 14：01：22 UTC</p>
<h2 id="97-人工智能记忆差距用户错误地记住了他们在人工智能或没有人工智能的情况下创建了什么-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11851"target="_blank" rel="external nofollow noopener noreferrer">#97</a> <a href="https://papers.cool/arxiv/2509.11851"target="_blank" rel="external nofollow noopener noreferrer">人工智能记忆差距：用户错误地记住了他们在人工智能或没有人工智能的情况下创建了什么</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tim Zindulka](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tim</a> Zindulka), [Sven Goller](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sven"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sven</a> Goller), [Daniela Fernandes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniela"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniela</a> Fernandes), [Robin Welsch](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Robin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Robin</a> Welsch), [Daniel Buschek](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniel</a> Buschek)</p>
<p>随着大型语言模型 （LLM） 嵌入交互式文本生成中，人工智能作为来源的披露取决于人们记住哪些想法或文本来自他们自己，哪些是用人工智能创建的。我们调查了人们在使用 AI 时记住内容来源的准确程度。在一项预注册的实验中，184 名参与者在独立和基于 LLM 的聊天机器人下生成并阐述了想法。一周后，他们被要求确定这些想法和文本的来源（noAI 与 withAI）。我们的研究结果揭示了内存方面的显着差距：使用人工智能后，正确归因的几率下降，其中人类与人工智能混合的工作流程下降幅度最大，其中想法或阐述都是用人工智能创建的。我们使用源内存的计算模型验证了我们的结果。在讨论更广泛的影响时，我们强调了在交互式文本生成技术的设计和使用中考虑源混淆的重要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 12：31：00 世界标准时间</p>
<h2 id="98-与多个用户和-ai-代理协作编辑文档-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11826"target="_blank" rel="external nofollow noopener noreferrer">#98</a> <a href="https://papers.cool/arxiv/2509.11826"target="_blank" rel="external nofollow noopener noreferrer">与多个用户和 AI 代理协作编辑文档</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Florian Lehmann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Florian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Florian</a> Lehmann), [Krystsina Shauchenka](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Krystsina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Krystsina</a> Shauchenka), [Daniel Buschek](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniel</a> Buschek)</p>
<p>当前的人工智能写作支持工具主要是为个人设计的，当合著者必须离开共享工作空间才能使用人工智能，然后交流和重新整合结果时，协作变得复杂。我们建议将 AI 代理直接集成到协作写作环境中。我们的原型通过两个新的共享对象使 AI 使用透明且可定制：代理配置文件和任务。座席响应显示在熟悉的评论功能中。在一项用户研究 （N=30） 中，14 个团队在一周内完成了写作项目。交互日志和访谈表明，团队将代理纳入现有的作者、控制和协调规范，而不是将他们视为团队成员。代理配置文件被视为个人领地，而创建的代理和输出则成为共享资源。我们讨论了对基于团队的人工智能交互的影响，强调了将人工智能视为协作工作中共享资源的机会和界限。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 12：11：59 UTC</p>
<h2 id="99-不相关表示的崩溃-cir-确保稳健且无中断的-llm-忘却-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11816"target="_blank" rel="external nofollow noopener noreferrer">#99</a> <a href="https://papers.cool/arxiv/2509.11816"target="_blank" rel="external nofollow noopener noreferrer">不相关表示的崩溃 （CIR） 确保稳健且无中断的 LLM 忘却</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Filip Sondej](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Filip"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Filip</a> Sondej), [Yushi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yushi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yushi</a> Yang)</p>
<p>当前的忘却技术和安全培训始终无法从语言模型中消除危险知识。我们分析了根本原因，并提出了一种高度选择性的技术，该技术可以稳健地取消学习，并且不破坏一般性能。我们对激活和模块输出梯度执行 PCA，以识别包含公共表示的子空间，并在计算取消学习更新之前折叠它们。这样我们就可以避免忘记一般表示，而只针对那些特定于未学习的事实的表示。当从 Llama-3.1-8B 中取消学习大规模杀伤性武器数据集事实时，我们在生物危害事实上的攻击后准确性下降了 80 倍，在网络危害事实上下降了 30 倍。尽管如此，我们对总体性能的破坏减少了 30 倍（维基文本损失仅增加 0.1%），同时每个事实所需的 GPU 秒不到 3 秒。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 11：55：10 UTC</p>
<h2 id="100-测量电信领域的视觉理解使用-vlm-进行图像到-uml-转换的性能指标-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11667"target="_blank" rel="external nofollow noopener noreferrer">#100</a> <a href="https://papers.cool/arxiv/2509.11667"target="_blank" rel="external nofollow noopener noreferrer">测量电信领域的视觉理解：使用 VLM 进行图像到 UML 转换的性能指标</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [HG Ranjani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=HG"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=HG</a> Ranjani), [Rutuja Prabhudesai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rutuja"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rutuja</a> Prabhudesai)</p>
<p>电信域 3GPP 文档充满了包含序列图的图像。视觉语言大模型 （VLM） 的进步简化了此类图像到机器可读 PlantUML （puml） 格式的转换。然而，在评估此类转换方面存在差距 - 现有作品没有比较各种组件的 puml 脚本。在这项工作中，我们提出了绩效指标来衡量此类转化的有效性。选择来自 3GPP 文档的序列图数据集来代表特定领域的实际场景。我们将两个 VLM（Claude Sonnet 和 GPT-4V）的 puml 输出与手动创建的实况表示进行了比较。我们使用版本控制工具来捕获差异并引入标准性能指标来衡量各个组件的准确性：参与者识别、消息流准确性、序列排序和分组结构保存。我们证明了所提出的指标在量化 puml 脚本各个组件的转换错误方面的有效性。结果表明，节点、边和消息被准确捕获。然而，我们观察到 VLM 不一定在音符、方框、组等复杂结构上表现良好。我们的实验和性能指标表明，需要在微调 VLM 的训练数据中更好地表示这些组件。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 08：08：41 UTC</p>
<h2 id="101-mindvl迈向昇腾npu上多模态大语言模型的高效训练-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11662"target="_blank" rel="external nofollow noopener noreferrer">#101</a> <a href="https://papers.cool/arxiv/2509.11662"target="_blank" rel="external nofollow noopener noreferrer">MindVL：迈向昇腾NPU上多模态大语言模型的高效训练</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Feilong Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feilong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feilong</a> Chen), [Yijiang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yijiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yijiang</a> Liu), [Yi Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi</a> Huang), [Hao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hao</a> Wang), [Miren Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Miren"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Miren</a> Tian), [Ya-Qi Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ya-Qi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ya-Qi</a> Yu), [Minghui Liao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minghui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minghui</a> Liao), [Jihao Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jihao</a> Wu)</p>
<p>我们提出了 MindVL，这是一种在 Ascend NPU 上训练的多模态大语言模型。与Qwen2.5-VL类似，MindVL采用原生分辨率的Vision Transformers，使其能够以原始可变分辨率处理图像。这种设计避免了固定分辨率平铺造成的退化，同时保留了细粒度的细节和全局布局，这对于复杂的图表和图表等视觉密集的内容至关重要。为了确保 MindVL 在昇腾 NPU 上的顺利训练，我们开发了 Mindspeed-MLLM，这是一个专为昇腾 NPU 量身定制的分布式多模态训练框架。为了保持培训的准确性，我们对某些操作员实施了等效的替换。MindVL经历了三个阶段的训练过程，即预热阶段、多任务训练阶段和监督指令调优阶段，以逐步增强其能力。这个过程从基本的视觉和多模态预训练开始，然后是大规模的多重询问训练和指令调整。我们还采用了多模态数据打包和混合并行技术，显著提高了端到端的训练速度。为了进一步提高模型性能，我们专门引入了测试时分辨率搜索和模型权重平均。值得注意的是，尽管使用了 Qwen2.5-VL 所需的训练数据的 1/10 左右，但 MindVL 在评估一般多模态理解和文档/表格理解方面取得了与 Qwen2.5-VL 相当的性能。除了总分之外，MindVL 在 OCR 评估中也表现出色。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a></p>
<p><strong>发布</strong>: 2025-09-15 08：00：31 UTC</p>
<h2 id="102-mallm多智能体大型语言模型框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11656"target="_blank" rel="external nofollow noopener noreferrer">#102</a> <a href="https://papers.cool/arxiv/2509.11656"target="_blank" rel="external nofollow noopener noreferrer">MALLM：多智能体大型语言模型框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jonas Becker](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonas</a> Becker), [Lars Benedikt Kaesberg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lars"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lars</a> Benedikt Kaesberg), [Niklas Bauer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Niklas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Niklas</a> Bauer), [Jan Philip Wahle](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jan</a> Philip Wahle), [Terry Ruas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Terry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Terry</a> Ruas), [Bela Gipp](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bela"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bela</a> Gipp)</p>
<p>多代理辩论 （MAD） 已经证明了通过扩展测试时计算和利用专业知识来增强集体智慧的能力。当前的多代理辩论框架通常设计用于工具使用，缺乏综合评估，或者提供代理角色、响应生成器、讨论范式和决策协议的有限可配置性。我们介绍了 MALLM（多智能体大型语言模型），这是一个开源框架，可以对 MAD 组件进行系统分析。MALLM 提供超过 144 种独特的 MAD 配置，包括 （1） 代理角色（例如专家、个性）、（2） 响应生成器（例如批判性、推理）、（3） 讨论范式（例如记忆、中继）和 （4） 决策协议（例如投票、共识）。MALLM 使用简单的配置文件来定义辩论。此外，MALLM 可以加载任何文本 Huggingface 数据集（例如 MMLU-Pro、WinoGrande），并提供评估管道以方便比较 MAD 配置。MALLM 专为研究人员量身定制，提供了一个了解多智能体辩论核心的窗口，促进对其组成部分及其相互作用的理解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 07：48：02 UTC</p>
<h2 id="103-智能qa系统的形式推理教育领域的案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11572"target="_blank" rel="external nofollow noopener noreferrer">#103</a> <a href="https://papers.cool/arxiv/2509.11572"target="_blank" rel="external nofollow noopener noreferrer">智能QA系统的形式推理：教育领域的案例研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tuan Bui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tuan</a> Bui), [An Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=An"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=An</a> Nguyen), [Phat Thai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Phat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Phat</a> Thai), [Minh Hua](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minh</a> Hua), [Ngan Pham L. N.](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ngan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ngan</a> Pham L. N.), [Ngan Pham T. B.](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ngan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ngan</a> Pham T. B.), [Dung Le](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dung</a> Le), [Long Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Long"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Long</a> Nguyen), [Thanh-Tung Tran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thanh-Tung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thanh-Tung</a> Tran), [Thang Bui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thang</a> Bui), [Tho Quan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tho</a> Quan)</p>
<p>推理对于程序正确性和策略合规性至关重要的封闭领域 QA 系统至关重要。虽然大型语言模型 （LLM） 在许多推理任务上表现出了强大的性能，但最近的研究表明，它们的推理痕迹往往是不忠实的——更多的是合理的理由，而不是基于因果的推导。将法学硕士与符号引擎（例如 Prover9、Z3）相结合的努力提高了可靠性，但仍局限于静态形式的逻辑，在动态的、基于状态的推理（例如多步级数和条件转换）中苦苦挣扎。在本文中，我们提出了MCFR（Model Checking for Formal Reasoning），这是一个神经符号框架，它将LLM与模型检查相结合，以支持属性验证。MCFR 将自然语言翻译成正式规范，并通过过渡模型对其进行验证。为了支持评估，我们引入了 EduMC-QA，这是一个基于真实学术程序的基准数据集。我们的结果表明，MCFR 提高了推理的忠实度和可解释性，为高风险封闭域应用程序中可验证的 QA 提供了一条可行的途径。除了评估 MCFR 之外，我们还将其性能与 ChatGPT、DeepSeek 和 Claude 等最先进的法学硕士进行比较，以了解其有效性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 04：34：42 UTC</p>
<h2 id="104-学习通过动态奖励加权优化多目标对齐-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11452"target="_blank" rel="external nofollow noopener noreferrer">#104</a> <a href="https://papers.cool/arxiv/2509.11452"target="_blank" rel="external nofollow noopener noreferrer">学习通过动态奖励加权优化多目标对齐</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yining Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yining"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yining</a> Lu), [Zilong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zilong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zilong</a> Wang), [Shiyang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiyang</a> Li), [Xin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Liu), [Changlong Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Changlong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Changlong</a> Yu), [Qingyu Yin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingyu</a> Yin), [Zhan Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhan</a> Shi), [Zixuan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zixuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zixuan</a> Zhang), [Meng Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meng</a> Jiang)</p>
<p>多目标强化学习的先前工作通常使用具有固定权重的线性奖励标量化，这被证明无法捕获非凸帕累托前沿，从而产生次优结果。这种限制在大型语言模型的在线偏好调整中变得尤为重要。在这里，参数化策略生成的随机轨迹创建了从参数到目标的高度非线性和非凸映射，没有单一的静态加权方案可以找到最佳权衡。我们通过引入动态奖励权重来解决这一限制，该加权在在线强化学习过程中自适应地调整奖励权重。与依赖固定权重插值的现有方法不同，我们的动态加权在训练中不断平衡目标并确定其优先级，从而促进对目标空间中帕累托锋线的有效探索。我们介绍了两种提高复杂性和普遍性的方法：（1）超容量引导的权重适应和（2）基于梯度的权重优化，为在线多目标比对提供了一个多功能工具包。我们广泛的实验证明了它们与常用的在线强化学习算法（包括 GRPO、REINFORCE 和 RLOO）的兼容性、跨多个数学推理数据集的有效性以及对不同模型族的适用性，始终如一地以比固定权重线性标量化基线更少的训练步骤实现帕累托主导解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 21：56：35 UTC</p>
<h2 id="105-保护-ai-代理为工业应用程序实施基于角色的访问控制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11431"target="_blank" rel="external nofollow noopener noreferrer">#105</a> <a href="https://papers.cool/arxiv/2509.11431"target="_blank" rel="external nofollow noopener noreferrer">保护 AI 代理：为工业应用程序实施基于角色的访问控制</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Aadil Gani Ganie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aadil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aadil</a> Gani Ganie)</p>
<p>大型语言模型 （LLM） 的出现为从政治学到软件开发等各个领域的解决方案提供了显着先进的解决方案。然而，这些模型受到其训练数据的限制，这些数据是静态的，仅限于特定日期之前可用的信息。此外，它们的通用性通常需要微调——无论是出于分类还是教学目的——才能有效地执行特定的下游任务。人工智能代理以法学硕士为核心，通过访问外部工具和实时数据来缓解其中一些限制，从而实现实时天气预报和数据分析等应用程序。在工业环境中，人工智能代理正在通过增强决策、预测性维护和流程优化来改变运营方式。例如，在制造业中，人工智能代理支持近乎自主的系统，从而提高生产力并支持实时决策。尽管取得了这些进步，人工智能代理仍然容易受到安全威胁，包括提示注入攻击，这对其完整性和可靠性构成重大风险。为了应对这些挑战，本文提出了一个将基于角色的访问控制（RBAC）集成到AI代理中的框架，提供了强大的安全护栏。该框架旨在支持人工智能代理的有效且可扩展的部署，重点是本地实施。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 20：58：08 UTC</p>
<h2 id="106-fusecodec神经编解码器的语义上下文融合和监督-pdf1-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11425"target="_blank" rel="external nofollow noopener noreferrer">#106</a> <a href="https://papers.cool/arxiv/2509.11425"target="_blank" rel="external nofollow noopener noreferrer">FuseCodec：神经编解码器的语义上下文融合和监督</a> [PDF1] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Md Mubtasim Ahasan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Md"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Md</a> Mubtasim Ahasan), [Rafat Hasan Khan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rafat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rafat</a> Hasan Khan), [Tasnim Mohiuddin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tasnim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tasnim</a> Mohiuddin), [Aman Chadha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aman</a> Chadha), [Tariq Iqbal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tariq"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tariq</a> Iqbal), [M Ashraful Amin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=M"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=M</a> Ashraful Amin), [Amin Ahsan Ali](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amin</a> Ahsan Ali), [Md Mofijul Islam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Md"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Md</a> Mofijul Islam), [A K M Mahbubur Rahman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=A"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=A</a> K M Mahbubur Rahman)</p>
<p>语音标记化可实现离散表示并促进语音语言建模。然而，现有的神经编解码器捕获了低级声学特征，忽略了人类语音固有的语义和上下文线索。虽然最近的努力引入了来自自监督语音模型的语义表示或从预训练的语言模型中合并了上下文表示，但在调整和统一语义和上下文表示方面仍然存在挑战。我们引入了 FuseCodec，它通过强大的跨模态对齐和全局知情的监督来统一声学、语义和上下文表示。我们提出了三种互补技术：（i）潜在表示融合，将语义和上下文特征直接集成到编码器潜在空间中，以实现鲁棒和统一的表示学习;（ii） 全球语义-上下文监督，使用全局汇集和广播表示来监督离散标记，以增强时间一致性和跨模态对齐;（iii） 时间对齐上下文监督，通过在本地窗口内动态匹配上下文和语音标记来加强对齐，以实现细粒度的标记级监督。我们进一步介绍了 FuseCodec-TTS，展示了我们的方法在零样本语音合成中的适用性。根据经验，FuseCodec 在 LibriSpeech 中实现了最先进的性能，在转录准确性、感知质量、清晰度和说话人相似性方面超越了 EnCodec、SpeechTokenizer 和 DAC。结果强调了上下文和语义引导的标记化对于语音标记化和下游任务的有效性。代码和预训练模型可在 <a href="https://github.com/mubtasimahasan/FuseCodec"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/mubtasimahasan/FuseCodec</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">音频和语音处理</a></p>
<p><strong>发布</strong>: 2025-09-14 20：35：36 UTC</p>
<h2 id="107-trading-r1通过强化学习使用-llm-推理进行金融交易-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11420"target="_blank" rel="external nofollow noopener noreferrer">#107</a> <a href="https://papers.cool/arxiv/2509.11420"target="_blank" rel="external nofollow noopener noreferrer">Trading-R1：通过强化学习使用 LLM 推理进行金融交易</a> [PDF2] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yijia Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yijia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yijia</a> Xiao), [Edward Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Edward"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Edward</a> Sun), [Tong Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tong</a> Chen), [Fang Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fang</a> Wu), [Di Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Di"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Di</a> Luo), [Wei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Wang)</p>
<p>开发与人类金融分析师和交易员相提并论的专业、结构化推理仍然是人工智能金融领域的核心挑战，因为市场需要可解释性和信任。传统的时间序列模型缺乏可解释性，而法学硕士在将自然语言分析转化为有纪律的、可执行的交易方面面临挑战。尽管推理法学硕士在分步规划和验证方面取得了进步，但它们在风险敏感型财务决策中的应用尚未得到充分探索。我们提出了 Trading-R1，这是一种具有财务意识的模型，它结合了战略思维和规划，用于全面的论文撰写、基于事实的分析和波动性调整的决策。Trading-R1 通过监督微调和强化学习以及从易到难的三阶段课程，将推理与交易原则结合起来。训练使用 Tauric-TR1-DB，这是一个跨越 18 个月的 100k 样本语料库、14 个股票和 5 个异构财务数据源。在六种主要股票和 ETF 上进行评估，与开源和专有指令遵循模型以及推理模型相比，Trading-R1 显示出更高的风险调整后回报和更低的回撤。该系统生成结构化的、基于证据的投资论文，支持有纪律和可解释的交易决策。Trading-R1 终端将于 <a href="https://github.com/TauricResearch/Trading-R1"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/TauricResearch/Trading-R1</a> 日发布。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/q-fin.TR"target="_blank" rel="external nofollow noopener noreferrer">交易和市场微观结构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 20：13：41 UTC</p>
<h2 id="108-opalrlhf-的算子代数视图-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11298"target="_blank" rel="external nofollow noopener noreferrer">#108</a> <a href="https://papers.cool/arxiv/2509.11298"target="_blank" rel="external nofollow noopener noreferrer">Opal：RLHF 的算子代数视图</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Madhava Gaikwad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Madhava"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Madhava</a> Gaikwad)</p>
<p>我们提出了 Opal，这是一种来自人类反馈的强化学习 （RLHF） 的操作员视图。目标表示为基本效用上两个基元的阶梯：加法惩罚和乘法成对权重。我们描述了一个具有 if-and-only-if 条件的简单约简定律：当引用固定时，这种阶梯在成对边距上塌陷为正态形式，惩罚是累加的，并且权重与中间边距无关。当这些假设不成立时（参考偏移、非加性门、分数相关权重），小示例证明不可约。基于此视图，我们引入了 GKPO（广义内核首选项对象），这是一种规范模式，其中可以表示许多 RLHF 方法，并在可简化时映射回来。GKPO 提供标准的 JSON 序列化、规范化和哈希规则，以及在假设失败时带有有限见证的显式标志。我们用 DPO、RRHF 和 ORPO 的 GKPO 示例来说明这些想法，以及跨方法转换（在假设允许的情况下）和强调不可约性的最小压力测试（SHIFT/GATE/SCORE）。该模式附带一个轻量级的 Python 参考库，实现了规范哈希和 DPO 和 RRHF 的适配器。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 14：42：39 UTC</p>
<h2 id="109-通过自我注射幻觉减轻大型视觉语言模型中的幻觉-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11287"target="_blank" rel="external nofollow noopener noreferrer">#109</a> <a href="https://papers.cool/arxiv/2509.11287"target="_blank" rel="external nofollow noopener noreferrer">通过自我注射幻觉减轻大型视觉语言模型中的幻觉</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yifan Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yifan</a> Lu), [Ziqi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziqi</a> Zhang), [Chunfeng Yuan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chunfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chunfeng</a> Yuan), [Jun Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jun</a> Gao), [Congxuan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Congxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Congxuan</a> Zhang), [Xiaojuan Qi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaojuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaojuan</a> Qi), [Bing Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bing</a> Li), [Weiming Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiming</a> Hu)</p>
<p>大型视觉语言模型 （LVLM） 存在严重的幻觉问题，即模型生成的响应与视觉输入不一致。现有的幻觉缓解方法主要基于偏好对齐，需要外部人工注释或辅助模型进行偏好数据收集，这增加了成本并限制了可持续改进。为了应对这些挑战，我们提出了通过自我注入的自主偏好对齐 （APASI），这是一种新颖且通用的方法，可以在没有外部依赖性的情况下减轻幻觉。APASI 利用目标 LVLM 将幻觉自我注入生成的响应中，创建一对具有不同偏好水平的响应。在自我注射过程中，根据幻觉的三个关键观察结果生成不良反应，确保其模拟真实的幻觉模式。这种保真度为缓解幻觉提供了准确的学习信号。此外，APASI结合迭代对齐训练策略，结合课程学习，随着挑战的增加，定期更新偏好数据，实现LVLM的稳定和持续提升。跨六个基准的广泛实验表明，APASI不仅有效地减轻了三个基线模型的幻觉，而且还实现了与具有外部依赖性的基于对齐的方法相当甚至更好的性能，从而证明了其有效性和泛化能力。该代码可在 <a href="https://github.com/davidluciolu/APASI"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/davidluciolu/APASI</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 14：26：53 UTC</p>
<h2 id="110-evalet通过将输出碎片化为函数来评估大型语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11206"target="_blank" rel="external nofollow noopener noreferrer">#110</a> <a href="https://papers.cool/arxiv/2509.11206"target="_blank" rel="external nofollow noopener noreferrer">Evalet：通过将输出碎片化为函数来评估大型语言模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tae Soo Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tae</a> Soo Kim), [Heechan Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Heechan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Heechan</a> Lee), [Yoonjoo Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yoonjoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yoonjoo</a> Lee), [Joseph Seering](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joseph"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joseph</a> Seering), [Juho Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juho</a> Kim)</p>
<p>从业者越来越依赖大型语言模型 （LLM） 通过“LLM 作为法官”方法评估生成式人工智能输出。然而，这些方法产生的整体分数掩盖了哪些特定因素影响了评估。我们提出了功能碎片化，这是一种将每个输出分解为关键片段并解释每个片段相对于评估标准所服务的修辞功能的方法——浮出水面感兴趣的元素并揭示它们如何实现或阻碍用户目标。我们在 Evalet 中实例化了这种方法，这是一个交互式系统，可跨多个输出可视化片段级函数，以支持评估的检查、评级和比较。一项用户研究 （N=10） 发现，虽然从业者难以验证整体分数，但我们的方法帮助他们识别了 48% 以上的评估不一致。这帮助他们校准了对 LLM 评估的信任度，并依靠它们在模型输出中发现更多可作的问题。我们的工作将 LLM 评估从定量分数转向对模型行为的定性、细粒度分析。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 10：24：13 UTC</p>
<h2 id="111-dreamnav用于零样本视觉和语言导航的基于轨迹的想象力框架-pdf1-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11197"target="_blank" rel="external nofollow noopener noreferrer">#111</a> <a href="https://papers.cool/arxiv/2509.11197"target="_blank" rel="external nofollow noopener noreferrer">DreamNav：用于零样本视觉和语言导航的基于轨迹的想象力框架</a> [PDF1] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Yunheng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunheng</a> Wang), [Yuetong Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuetong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuetong</a> Fang), [Taowen Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taowen</a> Wang), [Yixiao Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixiao</a> Feng), [Yawen Tan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yawen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yawen</a> Tan), [Shuning Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuning</a> Zhang), [Peiran Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peiran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peiran</a> Liu), [Yiding Ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiding"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiding</a> Ji), [Renjing Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Renjing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Renjing</a> Xu)</p>
<p>连续环境中的视觉和语言导航（VLN-CE）是具身机器人的核心能力，它将语言指令与现实世界中的感知和控制联系起来。最近，大规模预训练基础模型被用作感知、推理和行动的共享先验，无需特定任务训练即可实现零样本 VLN。然而，现有的零样本VLN方法依赖于昂贵的感知和被动场景理解，将控制缩减为点级选择。因此，它们的部署成本高昂，行动语义不一致，规划短视。为了解决这些问题，我们推出了专注于以下三个方面的 DreamNav：（1） 为了降低感官成本，我们的 EgoView 校正器可以调整观点并稳定以自我为中心的感知;（2）我们的轨迹预测器倾向于全局轨迹级规划，而不是点级动作，以更好地与指令语义保持一致;（3）为了实现预期和长期规划，我们提出了一种想象力预测器，以赋予智能体主动思考能力。在VLN-CE和实际测试中，DreamNav设置了一种新的零样本最先进（SOTA），在SR和SPL指标方面，在额外信息方面比最强的自我中心基线高出7.49%和18.15%。据我们所知，这是第一个零样本VLN方法，它统一了轨迹层面的规划和主动想象力，同时仅使用以自我为中心的输入。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-14 09：54：20 UTC</p>
<h2 id="112-aqua通过-query-magnitudes-在-llm-中进行记忆和计算高效推理的注意力-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11155"target="_blank" rel="external nofollow noopener noreferrer">#112</a> <a href="https://papers.cool/arxiv/2509.11155"target="_blank" rel="external nofollow noopener noreferrer">AQUA：通过 QUery mAgnitudes 在 LLM 中进行记忆和计算高效推理的注意力</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Santhosh G S](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Santhosh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Santhosh</a> G S), [Saurav Prakash](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Saurav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Saurav</a> Prakash), [Balaraman Ravindran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Balaraman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Balaraman</a> Ravindran)</p>
<p>注意力机制的二次复杂性仍然是将大型语言模型 （LLM） 扩展到更长上下文的根本障碍，在计算和内存方面造成了严重瓶颈。为了解决这个问题，我们引入了 AQUA（通过 QUery mAgnitudes 的注意力），这是一种新颖且通用的近似策略，它通过优雅的性能权衡显着降低了注意力成本。我们的方法分两个阶段运行：一个是高效的离线步骤，我们通过 SVD 在校准数据集上计算一个通用的、与语言无关的投影矩阵，另一个是在线推理步骤，我们投影查询和关键向量，并根据查询的大小动态选择一个稀疏的维度子集。我们提供了 AQUA 的形式理论分析，建立了盈亏平衡点，在该点上，它的计算效率比标准注意力更高。我们对 Llama-3.1-8B 等最先进模型的实证评估表明，注意力点积计算可以减少 25%，而对各种基准测试的性能影响在统计学上微不足道。我们进一步展示了 AQUA 的多功能性，展示了它协同加速现有代币驱逐方法（如 H2O）并直接减小 KV 缓存内存大小的能力。通过提供可控旋钮来平衡效率和准确性，AQUA 提供了一个实用且强大的工具，使大规模 LLM 推理更易于访问和可持续。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 08：20：48 UTC</p>
<h2 id="113-在线平台中的代理用户名建议和多模态性别检测介绍-pngt-26k-数据集-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11136"target="_blank" rel="external nofollow noopener noreferrer">#113</a> <a href="https://papers.cool/arxiv/2509.11136"target="_blank" rel="external nofollow noopener noreferrer">在线平台中的代理用户名建议和多模态性别检测：介绍 PNGT-26K 数据集</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Farbod Bijary](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Farbod"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Farbod</a> Bijary), [Mohsen Ebadpour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohsen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohsen</a> Ebadpour), [Amirhosein Tajbakhsh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amirhosein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amirhosein</a> Tajbakhsh)</p>
<p>由于音译不一致和特定文化的命名模式，波斯语名称给自然语言处理应用带来了独特的挑战，特别是在性别检测和数字身份创建方面。现有工具在波斯语名称上表现出显着的性能下降，而综合数据集的稀缺进一步加剧了这些限制。为了应对这些挑战，本研究引入了 PNGT-26K，这是一个包含波斯语名字、其常见性别及其英语音译的综合数据集，由大约 26,000 个元组组成。为了演示如何利用这一资源，我们还介绍了两个框架，即开放性别检测和唯名论。Open Gender Detection 是一个生产级、即用型框架，用于使用来自用户的现有数据（例如个人资料照片和姓名）来对此人的性别进行概率猜测。Nominalist 是本文介绍的第二个框架，它利用代理 AI 帮助用户在任何平台上为其社交媒体帐户选择用户名。它可以轻松集成到任何网站中，以提供更好的用户体验。PNGT-26K 数据集、唯名论和开放性别检测框架在 Github 上公开提供。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.SI"target="_blank" rel="external nofollow noopener noreferrer">社会和信息网络</a></p>
<p><strong>发布</strong>: 2025-09-14 07：08：32 UTC</p>
<h2 id="114-用于文本-语音对齐的长度感知旋转位置嵌入-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11084"target="_blank" rel="external nofollow noopener noreferrer">#114</a> <a href="https://papers.cool/arxiv/2509.11084"target="_blank" rel="external nofollow noopener noreferrer">用于文本-语音对齐的长度感知旋转位置嵌入</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Hyeongju Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyeongju"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyeongju</a> Kim), [Juheon Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juheon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juheon</a> Lee), [Jinhyeok Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinhyeok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinhyeok</a> Yang), [Jacob Morton](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jacob"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jacob</a> Morton)</p>
<p>许多最近的文本转语音 （TTS） 系统都是建立在 Transformer 架构之上的，并采用交叉注意力机制进行文本-语音对齐。在这些系统中，旋转位置嵌入 （RoPE） 通常用于对文本和语音表示中的位置信息进行编码。在这项工作中，我们引入了长度感知 RoPE （LARoPE），这是一种简单而有效的 RoPE 扩展，可改善文本语音对齐。与依赖绝对索引的 RoPE 不同，LARoPE 使用长度归一化索引计算查询和键位置之间的相对距离。实验结果表明，LARoPE 的性能始终优于 RoPE，提供更快的损耗收敛、更准确的文本-语音对齐和更高的整体 TTS 质量。此外，LARoPE 对话语持续时间变化表现出更强的弹性，并在长达 30 秒的延长语音生成中保持稳定的性能，而 RoPE 则遭受显着的退化。值得注意的是，我们的方法在标准零样本 TTS 基准测试上实现了最先进的单词错误率。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">音频和语音处理</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a></p>
<p><strong>发布</strong>: 2025-09-14 04：25：13 UTC</p>
<h2 id="115-cvpr-2024-自动驾驶大挑战赛语言驾驶赛道-cps-团队的系统描述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11071"target="_blank" rel="external nofollow noopener noreferrer">#115</a> <a href="https://papers.cool/arxiv/2509.11071"target="_blank" rel="external nofollow noopener noreferrer">CVPR 2024 自动驾驶大挑战赛语言驾驶赛道 CPS 团队的系统描述</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jinghan Peng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinghan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinghan</a> Peng), [Jingwen Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingwen</a> Wang), [Xing Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xing</a> Yu), [Dehui Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dehui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dehui</a> Du)</p>
<p>本报告概述了我们在 CVPR 2024 自动驾驶大挑战赛的语言驾驶赛道中使用视觉语言模型系统的方法。我们专门使用 DriveLM-nuScenes 数据集来训练我们的模型。我们的系统建立在 LLaVA 模型之上，我们通过使用 LoRA 和 DoRA 方法进行微调对其进行了增强。此外，我们还集成了来自开源深度估计模型的深度信息，以丰富训练和推理过程。对于推理，特别是多项选择题和是/否问题，我们采用了思维链推理方法来提高结果的准确性。这种全面的方法使我们在验证集排行榜上获得了 0.7799 的最高分，在排行榜上排名第一。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 03：37：17 UTC</p>
<h2 id="116-重新思考对-llm-基本原理的人类偏好评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11026"target="_blank" rel="external nofollow noopener noreferrer">#116</a> <a href="https://papers.cool/arxiv/2509.11026"target="_blank" rel="external nofollow noopener noreferrer">重新思考对 LLM 基本原理的人类偏好评估</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ziang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziang</a> Li), [Manasi Ganti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manasi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manasi</a> Ganti), [Zixian Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zixian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zixian</a> Ma), [Helena Vasconcelos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helena</a> Vasconcelos), [Qijia He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qijia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qijia</a> He), [Ranjay Krishna](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ranjay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ranjay</a> Krishna)</p>
<p>大型语言模型 （LLM） 通常会生成自然语言基本原理——自由形式的解释，有助于提高复杂推理任务的性能并增强人类用户的可解释性。然而，评估这些基本原理仍然具有挑战性。虽然最近的工作依赖于人类或法学硕士评委的二元偏好判断，但此类评估通常是不透明和粗粒度的，对是什么使一种理由比另一种理由更好提供了有限的见解。在这项工作中，我们通过询问以下问题来重新思考对 LLM 生成的基本原理的偏好评估：（1） 哪些属性定义了良好的基本原理？（2）人类的偏好可以用这些属性来解释吗？（3）基于属性的评估能否克服二元比较的局限性？我们从先前的文献中确定了一组关键的基本原理属性，并使用自动指标、LLM 判断和人工注释对其进行评估。然后，我们使用 SHAP 分析两个标准的人类偏好数据集 MT Bench 和 Chatbot Arena，以确定哪些属性最能解释人类偏好结果。最后，我们使用特定属性的 ELO 分数重新评估模型生成的基本原理，揭示更细致的模型比较和见解。我们的研究结果表明，细粒度的属性评估可以更好地表征基本原理质量，并指导未来的研究走向更可解释和可靠的评估实践。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 01：33：14 UTC</p>
<h2 id="117-refineg协同小型监督模型和llms实现低资源接地多模态ner-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10975"target="_blank" rel="external nofollow noopener noreferrer">#117</a> <a href="https://papers.cool/arxiv/2509.10975"target="_blank" rel="external nofollow noopener noreferrer">ReFineG：协同小型监督模型和LLMs，实现低资源接地多模态NER</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jielong Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jielong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jielong</a> Tang), [Shuang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuang</a> Wang), [Zhenxing Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenxing</a> Wang), [Jianxing Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jianxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jianxing</a> Yu), [Jian Yin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Yin)</p>
<p>接地多模态命名实体识别 （GMNER） 通过联合检测文本提及并将其接地到视觉区域来扩展传统 NER。虽然现有的监督方法取得了强大的性能，但它们依赖于昂贵的多模态注释，并且在低资源领域往往表现不佳。多模态大型语言模型 （MLLM） 表现出很强的泛化性，但存在领域知识冲突，导致特定领域实体的提及冗余或不正确。为了应对这些挑战，我们提出了 ReFineG，这是一个三阶段协作框架，它将小型监督模型与冻结的 MLLM 集成在一起，用于低资源 GMNER。在训练阶段，领域感知的NER数据合成策略通过监督训练将LLM知识转移到小型模型中，同时避免领域知识冲突。在细化阶段，基于不确定性的机制保留了监督模型的可信预测，并将不确定的预测委托给 MLLM。在接地阶段，多模态上下文选择算法通过类比推理增强视觉接地。在CCKS2025 GMNER 共享任务中，ReFineG 以 0.6461 的 F1 分数在在线排行榜上排名第二，在有限的注释下展示了其有效性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 20：32：12 UTC</p>
<h2 id="118-公共数据辅助差分私密情境学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10932"target="_blank" rel="external nofollow noopener noreferrer">#118</a> <a href="https://papers.cool/arxiv/2509.10932"target="_blank" rel="external nofollow noopener noreferrer">公共数据辅助差分私密情境学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Seongho Joo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seongho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seongho</a> Joo), [Hyukhun Koh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyukhun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyukhun</a> Koh), [Kyomin Jung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyomin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyomin</a> Jung)</p>
<p>大型语言模型 （LLM） 中的上下文学习 （ICL） 在各种任务中表现出卓越的性能，无需微调。然而，最近的研究强调了通过 ICL 中的提示泄露私人数据的风险，尤其是当 LLM 受到恶意攻击时。虽然差分隐私 （DP） 提供了强大的隐私保证，但它通常会显着降低上下文学习 （ICL） 的效用。为了应对这一挑战，我们将与任务相关的公共数据纳入 ICL 框架，同时保持 DP 保证。基于这种方法，我们提出了一种私有的上下文学习算法，该算法有效地平衡了隐私保护和模型效用。通过实验，我们证明了我们的方法在公共数据的帮助下显着提高了私有 ICL 的效用。此外，我们还表明我们的方法对成员推理攻击具有鲁棒性，证明了经验隐私保护。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 18：11：51 UTC</p>
<h2 id="119-有害的提示洗钱使用绑架风格和符号编码越狱法学硕士-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10931"target="_blank" rel="external nofollow noopener noreferrer">#119</a> <a href="https://papers.cool/arxiv/2509.10931"target="_blank" rel="external nofollow noopener noreferrer">有害的提示洗钱：使用绑架风格和符号编码越狱法学硕士</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Seongho Joo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seongho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seongho</a> Joo), [Hyukhun Koh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyukhun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyukhun</a> Koh), [Kyomin Jung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyomin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyomin</a> Jung)</p>
<p>大型语言模型 （LLM） 在各种任务中表现出了卓越的能力，但它们可能被滥用于有害目的仍然是一个重大问题。为了加强对此类漏洞的防御，必须调查利用法学硕士架构和学习范式中内在弱点的通用越狱攻击。作为回应，我们提出了 \textbf{H}armful \textbf{P}rompt \textbf{La}undering （HaPLa），这是一种新颖且适用广泛的越狱技术，只需要对目标模型进行黑盒访问。HaPLa 包含两种主要策略：1） \textit{abductive frameming}，它指示 LLM 推断出有害活动的合理中间步骤，而不是直接响应明确的有害查询;2） \textit{符号编码}，一种轻量级且灵活的方法，旨在混淆有害内容，因为当前的法学硕士主要对显式有害关键字仍然敏感。实验结果表明，HaPLa在GPT系列模型上的攻击成功率超过95%，在所有目标上达到70%。对不同符号编码规则的进一步分析也揭示了一个根本挑战：在不显着降低其响应良性查询方面的帮助的情况下安全地调整 LLM 仍然很困难。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 18：07：56 UTC</p>
<h2 id="120-为什么债券的失败方式不同用于多类默认预测的可解释多模态学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10802"target="_blank" rel="external nofollow noopener noreferrer">#120</a> <a href="https://papers.cool/arxiv/2509.10802"target="_blank" rel="external nofollow noopener noreferrer">为什么债券的失败方式不同？用于多类默认预测的可解释多模态学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yi Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi</a> Lu), [Aifan Ling](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aifan</a> Ling), [Chaoqun Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chaoqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chaoqun</a> Wang), [Yaxin Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yaxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yaxin</a> Xu)</p>
<p>近年来，在监管改革和宏观经济波动的情况下，中国债券市场违约激增。传统的机器学习模型难以捕捉财务数据的不规则性和时间依赖性，而大多数深度学习模型缺乏对财务决策至关重要的可解释性。为了解决这些问题，我们提出了 EMDLOT（Explainable Multimodal Deep Learning for Time-series），这是一种用于多类债券违约预测的新颖框架。EMDLOT 集成了数值时间序列（金融/宏观经济指标）和非结构化文本数据（债券招股说明书），使用时间感知 LSTM 处理不规则序列，并采用软聚类和多级关注来提高可解释性。对 1994 家中国公司（2015-2024 年）的实验表明，EMDLOT 在召回率、F1 分数和 mAP 方面优于传统（例如 XGBoost）和深度学习（例如 LSTM）基准，尤其是在识别违约/扩展公司方面。消融研究验证了每个组件的价值，注意力分析揭示了经济上直观的默认驱动因素。这项工作为透明的金融风险建模提供了实用工具和值得信赖的框架。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/q-fin.RM"target="_blank" rel="external nofollow noopener noreferrer">风险管理</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/q-fin.CP"target="_blank" rel="external nofollow noopener noreferrer">计算金融</a></p>
<p><strong>发布</strong>: 2025-09-13 03：42：34 UTC</p>
<h2 id="121-agentarch评估企业代理架构的综合基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10769"target="_blank" rel="external nofollow noopener noreferrer">#121</a> <a href="https://papers.cool/arxiv/2509.10769"target="_blank" rel="external nofollow noopener noreferrer">AgentArch：评估企业代理架构的综合基准</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tara Bogavelli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tara</a> Bogavelli), [Roshnee Sharma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Roshnee"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Roshnee</a> Sharma), [Hari Subramani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hari"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hari</a> Subramani)</p>
<p>虽然代理架构的各个组件已经被孤立地研究了，但对于不同的设计维度如何在复杂的多智能体系统中相互作用，实证理解仍然有限。本研究旨在通过提供全面的企业特定基准来解决这些差距，该基准评估最先进的大型语言模型中的 18 种不同的代理配置。我们研究了四个关键的代理系统维度：编排策略、代理提示实现（ReAct 与函数调用）、内存架构和思维工具集成。我们的基准测试揭示了重要的特定于模型的架构偏好，这些偏好挑战了代理人工智能系统中普遍存在的一刀切范式。它还揭示了企业任务整体代理性能的显着弱点，得分最高的模型在更复杂的任务上最多只有 35.3% 的成功率，在更简单的任务上最高只有 70.8%。我们希望这些发现能够为未来代理系统的设计提供信息，从而在架构组件和模型选择方面做出更多有经验支持的决策。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-13 01：18：23 UTC</p>
<h2 id="122-了解人工智能评估模式不同的-gpt-模型如何评估视觉语言描述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10707"target="_blank" rel="external nofollow noopener noreferrer">#122</a> <a href="https://papers.cool/arxiv/2509.10707"target="_blank" rel="external nofollow noopener noreferrer">了解人工智能评估模式：不同的 GPT 模型如何评估视觉语言描述</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sajjad Abdoli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sajjad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sajjad</a> Abdoli), [Rudi Cilibrasi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rudi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rudi</a> Cilibrasi), [Rima Al-Shikh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rima"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rima</a> Al-Shikh)</p>
<p>随着人工智能系统越来越多地评估其他人工智能输出，了解它们的评估行为对于防止级联偏差变得至关重要。本研究分析了 NVIDIA 的 Describe Anything Model 生成的视觉语言描述，并通过三种 GPT 变体（GPT-4o、GPT-4o-mini、GPT-5）进行评估，以揭示不同的“评估人格”、每个模型所表现出的潜在评估策略和偏差。GPT-4o-mini表现出系统一致性和最小的方差，GPT-4o在错误检测方面表现出色，而GPT-5则表现出极端保守和高变异性。使用 Gemini 2.5 Pro 作为独立问题生成器的对照实验验证了这些个性是固有的模型属性，而不是伪影。通过生成问题的语义相似性进行跨家族分析揭示了显着的差异：GPT 模型以高度相似性聚集在一起，而 Gemini 表现出明显不同的评估策略。所有 GPT 模型都表现出一致的 2：1 偏差，有利于负面评估而不是正面确认，尽管这种模式似乎是特定于家庭的，而不是跨 AI 架构的通用模式。这些发现表明，评估能力不会随一般能力而扩展，强大的人工智能评估需要不同的架构视角。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 21：48：59 UTC</p>
<h2 id="123-中间的法学硕士对现实世界基于法学硕士的系统的威胁和缓解措施的系统回顾-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10682"target="_blank" rel="external nofollow noopener noreferrer">#123</a> <a href="https://papers.cool/arxiv/2509.10682"target="_blank" rel="external nofollow noopener noreferrer">中间的法学硕士：对现实世界基于法学硕士的系统的威胁和缓解措施的系统回顾</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Vitor Hugo Galhardo Moia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vitor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vitor</a> Hugo Galhardo Moia), [Igor Jochem Sanz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Igor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Igor</a> Jochem Sanz), [Gabriel Antonio Fontes Rebello](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gabriel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gabriel</a> Antonio Fontes Rebello), [Rodrigo Duarte de Meneses](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rodrigo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rodrigo</a> Duarte de Meneses), [Briland Hitaj](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Briland"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Briland</a> Hitaj), [Ulf Lindqvist](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ulf"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ulf</a> Lindqvist)</p>
<p>生成式人工智能 （GenAI），特别是大型语言模型 （LLM） 的成功和广泛采用，引起了试图滥用模型、窃取敏感数据或中断服务的网络犯罪分子的注意。此外，为基于 LLM 的系统提供安全性是一项巨大的挑战，因为必须减轻对软件应用程序的传统威胁以及针对 LLM 及其集成的威胁。在本次调查中，我们通过对威胁和防御策略进行系统审查和综合分类，考虑整个软件和 LLM 生命周期，阐明了此类基于 LLM 的系统的安全和隐私问题。我们分析了具有 LLM 使用独特特征的真实场景，从开发到运营。此外，威胁根据其严重性级别及其与哪些场景相关进行分类，从而有助于识别最相关的威胁。推荐的防御策略被系统地分类并映射到相应的生命周期阶段和它们衰减的可能攻击策略。这项工作为消费者和供应商了解并有效降低将 LLM 集成到各自的解决方案或组织中期间的风险铺平了道路。它还使研究界能够从可能阻碍基于 LLM 的系统安全和隐私保护采用的开放挑战和边缘案例的讨论中受益。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.ET"target="_blank" rel="external nofollow noopener noreferrer">新兴技术</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 20：26：16 UTC</p>
<h2 id="124-智能试验评估使用大型语言模型通过社交媒体招募临床试验参与者-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10584"target="_blank" rel="external nofollow noopener noreferrer">#124</a> <a href="https://papers.cool/arxiv/2509.10584"target="_blank" rel="external nofollow noopener noreferrer">智能试验：评估使用大型语言模型通过社交媒体招募临床试验参与者</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xiaofan Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaofan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaofan</a> Zhou), [Zisu Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zisu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zisu</a> Wang), [Janice Krieger](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Janice"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Janice</a> Krieger), [Mohan Zalake](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohan</a> Zalake), [Lu Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lu</a> Cheng)</p>
<p>临床试验 （CT） 对于推进医学研究和治疗至关重要，但有效招募符合条件的参与者（每个人都必须满足复杂的资格标准）仍然是一项重大挑战。传统的招聘方法，例如医院内的广告或电子健康记录筛查，通常非常耗时且受地域限制。这项工作通过利用个人在社交媒体平台上分享的大量健康相关信息来应对招聘挑战。随着能够进行复杂文本理解的强大大型语言模型 （LLM） 的出现，我们提出了一个核心研究问题：LLM 驱动的工具能否通过社交媒体上的参与来识别潜在参与者来促进 CT 招募？为了研究这个问题，我们引入了 TRIALQA，这是一个新颖的数据集，由来自 Reddit 子版块的两个社交媒体集合组成，涉及结肠癌和前列腺癌。使用来自公共现实世界 CT 的资格标准，聘请经验丰富的注释员对 TRIALQA 进行注释，以表明 （1） 社交媒体用户是否符合给定的资格标准，以及 （2） 用户有兴趣参与 CT 的陈述原因。我们在这两个预测任务上对七个广泛使用的 LLM 进行了基准测试，采用了六种不同的训练和推理策略。我们广泛的实验表明，虽然法学硕士显示出相当大的前景，但它们在执行准确评估资格标准所需的复杂多跳推理方面仍然面临挑战。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 01：34：32 UTC</p>
<h2 id="125-dualalign生成基于临床的合成数据-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10538"target="_blank" rel="external nofollow noopener noreferrer">#125</a> <a href="https://papers.cool/arxiv/2509.10538"target="_blank" rel="external nofollow noopener noreferrer">DualAlign：生成基于临床的合成数据</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Rumeng Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rumeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rumeng</a> Li), [Xun Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xun</a> Wang), [Hong Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hong</a> Yu)</p>
<p>鉴于现实世界 EHR 的严格隐私限制、带注释的罕见病数据的可用性有限以及观察数据集中的系统性偏差，合成临床数据对于推进医疗保健领域的人工智能越来越重要。虽然大型语言模型 （LLM） 可以生成流畅的临床文本，但生成既现实又具有临床意义的合成数据仍然具有挑战性。我们介绍了 DualAlign，这是一个通过双重对齐增强统计保真度和临床合理性的框架：（1） 统计对齐，它对患者人口统计和风险因素的生成进行条件;（2） 语义对齐，结合现实世界的症状轨迹来指导内容生成。DualAlign 以阿尔茨海默病 （AD） 为案例研究，生成基于上下文的症状级句子，更好地反映现实世界的临床文档。与仅使用黄金数据或无指导合成基线训练的模型相比，结合 DualAlign 生成的数据和人工注释的数据对 LLaMA 3.1-8B 模型进行微调，可产生显着的性能提升。虽然 DualAlign 不能完全捕捉纵向复杂性，但它提供了一种实用的方法来生成基于临床的、保护隐私的合成数据，以支持低资源临床文本分析。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-05 18：04：38 UTC</p>
<h2 id="126-使用极坐标位置嵌入解耦什么和在哪里-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10534"target="_blank" rel="external nofollow noopener noreferrer">#126</a> <a href="https://papers.cool/arxiv/2509.10534"target="_blank" rel="external nofollow noopener noreferrer">使用极坐标位置嵌入解耦“什么”和“在哪里”</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Anand Gopalakrishnan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anand"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anand</a> Gopalakrishnan), [Robert Csordás](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Robert"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Robert</a> Csordás), [Jürgen Schmidhuber](<a href="https://arxiv.org/search/?searchtype=author&amp;query=J"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=J</a>ürgen Schmidhuber), [Michael C. Mozer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> C. Mozer)</p>
<p>Transformer 架构中的注意力机制根据内容（内容）和序列中的位置（位置）将键与查询进行匹配。我们提出了一个分析，表明在流行的 RoPE 旋转位置嵌入中纠缠的内容和位置。这种纠缠可能会损害性能，特别是当决策需要对这两个因素进行独立匹配时。我们提出了对 RoPE 的改进，我们称之为 Polar Coordinate Position Embeddings 或 PoPE，以消除 what-where 混淆。PoPE 在仅需要按位置或内容索引的诊断任务中要优越得多。在音乐、基因组和自然语言领域的自回归序列建模中，使用 PoPE 作为位置编码方案的 Transformers 在评估损失（困惑度）和下游任务性能方面优于使用 RoPE 的基线。在语言建模方面，这些收益在模型规模上持续存在，从 124M 到 774M 参数。至关重要的是，PoPE表现出强大的零样本长度外推能力，而RoPE的性能在测试时在较长的序列上会显着下降，而无需微调或使用位置插值方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-05 14：22：27 UTC</p>
<h2 id="127-用于识别供应链漏洞的实时-rag-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10469"target="_blank" rel="external nofollow noopener noreferrer">#127</a> <a href="https://papers.cool/arxiv/2509.10469"target="_blank" rel="external nofollow noopener noreferrer">用于识别供应链漏洞的实时 RAG</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jesse Ponnock](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jesse"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jesse</a> Ponnock), [Grace Kenneally](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Grace"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Grace</a> Kenneally), [Michael Robert Briggs](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Robert Briggs), [Elinor Yeo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Elinor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Elinor</a> Yeo), [Tyrone Patterson III](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tyrone"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tyrone</a> Patterson III), [Nicholas Kinberg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicholas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicholas</a> Kinberg), [Matthew Kalinowski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matthew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matthew</a> Kalinowski), [David Hechtman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Hechtman)</p>
<p>生成式人工智能的新技术可以对我们国家的供应链进行更深入的分析，但真正信息丰富的见解需要及时不断更新和聚合海量数据。大型语言模型 （LLM） 提供了前所未有的分析机会，但是，它们的知识库仅限于模型的最后一次训练日期，这使得这些功能对于任务影响依赖于新兴和及时信息的组织来说无法使用。本研究提出了一种创新的供应链分析方法，将新兴的检索增强生成 （RAG） 预处理和检索技术与先进的网络抓取技术相结合。我们的方法旨在减少将新信息合并到增强法学硕士中的延迟，从而能够及时分析供应链中断因素。通过实验，本研究评估了这些技术对及时性和质量权衡的组合效应。我们的结果表明，在将RAG系统应用于供应链分析时，微调嵌入检索模型始终能提供最显著的性能提升，这凸显了检索质量的至关重要性。自适应迭代检索根据上下文动态调整检索深度，进一步提高了性能，尤其是在复杂的供应链查询上。相反，微调 LLM 产生的改进有限且资源成本更高，而向下查询抽象等技术在实践中明显优于向上抽象。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-08-23 22：06：19 UTC</p>
<h2 id="128-从预训练和协作信号中学习分解的上下文标记表示以进行生成推荐-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10468"target="_blank" rel="external nofollow noopener noreferrer">#128</a> <a href="https://papers.cool/arxiv/2509.10468"target="_blank" rel="external nofollow noopener noreferrer">从预训练和协作信号中学习分解的上下文标记表示，以进行生成推荐</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yifan Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yifan</a> Liu), [Yaokun Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yaokun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yaokun</a> Liu), [Zelin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zelin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zelin</a> Li), [Zhenrui Yue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenrui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenrui</a> Yue), [Gyuseok Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gyuseok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gyuseok</a> Lee), [Ruichen Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruichen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruichen</a> Yao), [Yang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Zhang), [Dong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Wang)</p>
<p>生成式推荐器的最新进展采用了两阶段范式：首先使用预训练的分词器将项目标记为语义 ID，然后训练大型语言模型 （LLM） 通过序列到序列建模生成下一个项目。然而，这两个阶段针对不同的目标进行了优化：分词器预训练期间的语义重建与推荐器训练期间的用户交互建模。这种客观的不一致导致了两个关键限制：（i）次优静态标记化，其中固定标记分配无法反映不同的使用环境;（ii） 丢弃的预训练语义，其中预训练的知识（通常来自语言模型嵌入）在用户交互的推荐器训练期间被覆盖。为了解决这些限制，我们建议学习 DEcomposed COntextual Token Representations （DECOR），这是一个统一的框架，它保留了预训练的语义，同时增强了 token 嵌入的适应性。DECOR 引入了上下文化的标记组合，以根据用户交互上下文细化标记嵌入，以及将预训练的代码本嵌入与新学习的协作嵌入集成的分解嵌入融合。在三个真实世界数据集上的实验表明，DECOR 在推荐性能方面始终优于最先进的基线。我们的代码将在发布后提供。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-08-22 18：50：38 UTC</p>
<h2 id="129-dsrag基于文档衍生多模态知识图谱的领域特定检索框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10467"target="_blank" rel="external nofollow noopener noreferrer">#129</a> <a href="https://papers.cool/arxiv/2509.10467"target="_blank" rel="external nofollow noopener noreferrer">DSRAG：基于文档衍生多模态知识图谱的领域特定检索框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mengzheng Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengzheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengzheng</a> Yang), [Yanfei Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanfei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanfei</a> Ren), [David Osei Opoku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Osei Opoku), [Ruochang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruochang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruochang</a> Li), [Peng Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peng</a> Ren), [Chunxiao Xing](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chunxiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chunxiao</a> Xing)</p>
<p>目前通用大型语言模型（LLM）在特定领域任务中普遍表现出知识幻觉和特定领域适应性不足，限制了其在专业问答场景中的有效性。检索增强生成 （RAG） 通过整合外部知识来提高准确性和相关性，从而有效应对这些挑战。然而，传统的RAG在领域知识准确性和上下文建模方面仍面临局限性。为了增强特定领域的问答性能，这项工作重点关注基于图的 RAG 框架，强调知识图谱质量在生成过程中的关键作用。我们提出了 DSRAG（Domain-Specific RAG），这是一个多模态知识图谱驱动的检索增强生成框架，专为特定领域的应用而设计。我们的方法以特定领域的文档为主要知识源，整合文本、图像和表格等异构信息，构建涵盖概念层和实例层的多模态知识图谱。在此基础上，我们引入了语义剪枝和结构化子图检索机制，结合知识图谱上下文和向量检索结果，指导语言模型产生更可靠的响应。使用 Langfuse 多维评分机制的评估表明，我们的方法在特定领域的问答方面表现出色，验证了将多模态知识图谱与检索增强生成相结合的功效。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-08-22 14：24：48 UTC</p>
<h1 id="122-artificial-intelligence">1.2.2 Artificial Intelligence</h1>
<p><strong>From</strong>：<a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">https://papers.cool/arxiv/cs.AI</a><a href="https://arxiv.org/list/cs.AI/recent"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/list/cs.AI/recent</a></p>
<p>2025-09-16 |   | Total: 266</p>
<h2 id="1-利用百年案例推进医疗人工智能-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12194"target="_blank" rel="external nofollow noopener noreferrer">#1</a> <a href="https://papers.cool/arxiv/2509.12194"target="_blank" rel="external nofollow noopener noreferrer">利用百年案例推进医疗人工智能</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Thomas A. Buckley](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> A. Buckley), [Riccardo Conci](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Riccardo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Riccardo</a> Conci), [Peter G. Brodeur](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peter"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peter</a> G. Brodeur), [Jason Gusdorf](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jason"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jason</a> Gusdorf), [Sourik Beltrán](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sourik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sourik</a> Beltrán), [Bita Behrouzi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bita</a> Behrouzi), [Byron Crowe](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Byron"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Byron</a> Crowe), [Jacob Dockterman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jacob"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jacob</a> Dockterman), [Muzzammil Muhammad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muzzammil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muzzammil</a> Muhammad), [Sarah Ohnigian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sarah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sarah</a> Ohnigian), [Andrew Sanchez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> Sanchez), [James A. Diao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=James"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=James</a> A. Diao), [Aashna P. Shah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aashna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aashna</a> P. Shah), [Daniel Restrepo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniel</a> Restrepo), [Eric S. Rosenberg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eric"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eric</a> S. Rosenberg), [Andrew S. Lea](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> S. Lea), [Marinka Zitnik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marinka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marinka</a> Zitnik), [Scott H. Podolsky](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Scott"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Scott</a> H. Podolsky), [Zahir Kanjee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zahir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zahir</a> Kanjee), [Raja-Elie E. Abdulnour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raja-Elie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raja-Elie</a> E. Abdulnour), [Jacob M. Koshy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jacob"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jacob</a> M. Koshy), [Adam Rodman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adam</a> Rodman), [Arjun K. Manrai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arjun</a> K. Manrai)</p>
<p>背景：一个多世纪以来，新英格兰医学杂志临床病理学会议 （CPC） 一直在测试专家医生的推理，最近还测试了人工智能 （AI）。然而，之前的人工智能评估侧重于最终诊断，而没有解决专家讨论者所需的多方面推理和表达技巧。方法：使用 7102 个 CPC（1923-2025 年）和 1021 个图像挑战（2006-2025 年），我们进行了广泛的医生注释和自动化处理，以创建 CPC-Bench，这是一个经过医生验证的基准，涵盖 10 个基于文本和多模态的任务，我们根据它评估了领先的大型语言模型 （LLM）。然后，我们开发了“Dr. CaBot”，这是一个人工智能讨论者，旨在仅使用案例演示来制作书面和基于幻灯片的视频演示，模拟人类专家在这些案例中的角色。结果：当与 377 个当代 CPC 进行挑战时，o3 （OpenAI） 在 60% 的病例中将最终诊断排在第一位，在 84% 的病例中排名前十，优于 20 名医生的基线;下一次测试选择准确率达到98%。事件级医生注释量化了每单位信息的 AI 诊断准确性。在文献检索和图像任务中表现较低;o3 和 Gemini 2.5 Pro （Google） 在图像挑战中实现了 67% 的准确率。在 CaBot 与人类专家生成文本的盲法比较中，医生在 62 项试验中的 46 项 （74%） 中错误地对差异的来源进行了分类，并且在质量维度上对 CaBot 的评分更为有利。为了促进研究，我们发布了 CaBot 和 CPC-Bench。结论：法学硕士在基于复杂文本的鉴别诊断方面超过了医生的表现，并令人信服地模仿了专家的医学演示，但图像解释和文献检索仍然较弱。CPC-Bench 和 CaBot 可以透明且持续地跟踪医疗人工智能的进展。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-15 17：54：51 UTC</p>
<h2 id="2-co-alignment重新思考将对齐作为双向人机认知适应-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12179"target="_blank" rel="external nofollow noopener noreferrer">#2</a> <a href="https://papers.cool/arxiv/2509.12179"target="_blank" rel="external nofollow noopener noreferrer">Co-Alignment：重新思考将对齐作为双向人机认知适应</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Yubo Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yubo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yubo</a> Li), [Weiyi Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiyi</a> Song)</p>
<p>当前通过 RLHF 进行的 AI 对齐遵循单一方向范式，即 AI 符合人类偏好，同时将人类认知视为固定的。我们建议通过双向认知对齐 （BiCA） 转向共同对齐，人类和人工智能相互适应。BiCA 使用可学习协议、表示映射和 KL 预算约束来实现受控协同进化。在协作导航方面，BiCA 取得了 85.5% 的成功率，而基线成功率为 70.3%，相互适应提高了 230%，协议收敛性提高了 332%。紧急方案的性能比手工方案高出 84%，而双向适应出人意料地提高了安全性（+23% 分布外鲁棒性）。46% 的协同作用改进表明，在人类和人工智能能力的交叉点上存在最佳协作，而不是联合，验证了从单向范式到协同对齐范式的转变。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-15 17：41：16 UTC</p>
<h2 id="3-justeva评估法律知识推理中法学硕士公平性的工具包-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12104"target="_blank" rel="external nofollow noopener noreferrer">#3</a> <a href="https://papers.cool/arxiv/2509.12104"target="_blank" rel="external nofollow noopener noreferrer">JustEva：评估法律知识推理中法学硕士公平性的工具包</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Zongyue Xue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zongyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zongyue</a> Xue), [Siyuan Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siyuan</a> Zheng), [Shaochun Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaochun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaochun</a> Wang), [Yiran Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiran</a> Hu), [Shenran Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shenran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shenran</a> Wang), [Yuxin Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxin</a> Yao), [Haitao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haitao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haitao</a> Li), [Qingyao Ai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingyao</a> Ai), [Yiqun Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiqun</a> Liu), [Yun Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yun</a> Liu), [Weixing Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weixing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weixing</a> Shen)</p>
<p>将大型语言模型 （LLM） 整合到法律实践中引发了人们对司法公平的紧迫担忧，特别是由于其“黑盒”流程的性质。本研究介绍了 JustEva，这是一个全面的开源评估工具包，旨在衡量法律任务中的 LLM 公平性。JustEva具有以下几个优势：（1）涵盖65个法外因素的结构化标签系统;（2）三个核心公平指标——不一致、偏见和不平衡不准确;（3）稳健的统计推断方法;（4） 信息丰富的可视化。该工具包支持两种类型的实验，实现完整的评估工作流程：（1） 使用提供的数据集从 LLM 生成结构化输出，以及 （2） 通过回归和其他统计方法对 LLM 的输出进行统计分析和推断。JustEva 的实证应用揭示了当前 LLM 存在重大公平性缺陷，凸显了缺乏公平和可信的 LLM 法律工具。JustEva 为评估和提高法律领域的算法公平性提供了便捷的工具和方法基础。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：31：26 UTC</p>
<h2 id="4-通过基于模型的知识转换将工程和人工智能规划联系起来以验证自动化生产系统变体-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12091"target="_blank" rel="external nofollow noopener noreferrer">#4</a> <a href="https://papers.cool/arxiv/2509.12091"target="_blank" rel="external nofollow noopener noreferrer">通过基于模型的知识转换将工程和人工智能规划联系起来，以验证自动化生产系统变体</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Hamied Nabizada](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hamied"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hamied</a> Nabizada), [Lasse Beers](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lasse"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lasse</a> Beers), [Alain Chahine](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alain"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alain</a> Chahine), [Felix Gehlhoff](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Felix"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Felix</a> Gehlhoff), [Oliver Niggemann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oliver"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oliver</a> Niggemann), [Alexander Fay](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Fay)</p>
<p>在基于模型的系统工程 （MBSE） 环境中创建的工程模型包含有关系统结构和行为的详细信息。但是，它们通常缺乏符号规划语义，例如与资源可用性和时间相关的先决条件、效果和约束。这限制了他们评估给定系统变体是否能够完成特定任务以及与替代方案相比其执行效率的能力。为了解决这一差距，本文提出了一种模型驱动方法，该方法可以在基于 SysML 的工程模型中规范和自动生成符号规划工件。专用的 SysML 配置文件为核心规划结构引入了可重用的构造型。这些被集成到现有模型结构中，并由一种算法进行处理，该算法在规划领域定义语言 （PDDL） 中生成有效的领域文件和相应的问题文件。与以前依赖手动转换或外部功能模型的方法相比，该方法支持本机集成并保持工程和规划工件之间的一致性。该方法的适用性通过飞机装配的案例研究得到证明。该示例说明了如何通过规划语义丰富现有工程模型，以及如何应用建议的工作流从这些模型生成一致的规划工件。生成的规划工件支持通过 AI 规划验证系统变体。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：18：08 UTC</p>
<h2 id="5-当安全单模态输入发生碰撞时优化多模态大语言模型中跨模态安全的推理链-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12060"target="_blank" rel="external nofollow noopener noreferrer">#5</a> <a href="https://papers.cool/arxiv/2509.12060"target="_blank" rel="external nofollow noopener noreferrer">当安全单模态输入发生碰撞时：优化多模态大语言模型中跨模态安全的推理链</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wei Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Cai), [Shujuan Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shujuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shujuan</a> Liu), [Jian Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Zhao), [Ziyan Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziyan</a> Shi), [Yusheng Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yusheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yusheng</a> Zhao), [Yuchen Yuan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Yuan), [Tianle Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianle"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianle</a> Zhang), [Chi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chi</a> Zhang), [Xuelong Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuelong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuelong</a> Li)</p>
<p>多模态大型语言模型 （MLLM） 容易受到隐式推理风险的影响，其中无害的单模态输入协同组装成有风险的多模态数据，从而产生有害的输出。我们将这一漏洞归因于 MLLM 难以通过长链推理来保持安全对齐。为了解决这个问题，我们引入了安全语义但不安全解释 （SSUI），这是第一个具有针对此类跨模态挑战量身定制的可解释推理路径的数据集。基于SSUI数据集设计了一种新的训练框架，即安全感知推理路径优化（SRPO），以使MLLM的内部推理过程与人类安全值保持一致。实验结果表明，我们的 SRPO 训练模型在关键安全基准（包括拟议的推理路径基准 （RSBench））上取得了最先进的结果，显着优于开源和顶级商业 MLLM。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 15：40：58 UTC</p>
<h2 id="6-灾害场景中人机在决策中的使用模式系统评价-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12034"target="_blank" rel="external nofollow noopener noreferrer">#6</a> <a href="https://papers.cool/arxiv/2509.12034"target="_blank" rel="external nofollow noopener noreferrer">灾害场景中人机在决策中的使用模式：系统评价</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Emmanuel Adjei Domfeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emmanuel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emmanuel</a> Adjei Domfeh), [Christopher L. Dancy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christopher"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christopher</a> L. Dancy)</p>
<p>在高风险的灾难场景中，及时、明智的决策至关重要，但往往受到不确定性、动态环境和有限资源的挑战。本文对支持所有灾害管理阶段决策的人机协作模式进行了系统综述。从 51 项同行评审研究中，我们确定了四个主要类别：人机决策支持系统、任务和资源协调、信任和透明度以及模拟和训练。在这些中，我们分析了认知增强智能、多智能体协调、可解释人工智能和虚拟训练环境等子模式。我们的综述强调了人工智能系统如何增强态势感知、提高响应效率并支持复杂的决策，同时也揭示了可扩展性、可解释性和系统互作性方面的关键局限性。最后，我们概述了主要挑战和未来的研究方向，强调需要适应性强、值得信赖和上下文感知的人机系统，以提高灾难恢复能力和公平的恢复结果。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 15：18：49 UTC</p>
<h2 id="7-musicswarm用于音乐创作的生物启发智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11973"target="_blank" rel="external nofollow noopener noreferrer">#7</a> <a href="https://papers.cool/arxiv/2509.11973"target="_blank" rel="external nofollow noopener noreferrer">MusicSwarm：用于音乐创作的生物启发智能</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Markus J. Buehler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Markus"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Markus</a> J. Buehler)</p>
<p>我们表明，连贯的长篇音乐作品可以从一群分散的相同、冻结的基础模型中产生，这些模型通过污名化的点对点信号进行协调，而无需任何权重更新。我们将具有全局批评者的集中式多智能体系统比作一个完全分散的群体，其中按条形智能体感知并沉积谐波、节奏和结构线索，适应短期记忆并达成共识。在符号、音频和图论分析中，群体产生卓越的质量，同时提供更大的多样性和结构多样性，并在创造力指标方面处于领先地位。动态收缩为互补角色的稳定配置，自相似网络揭示了一个具有高效远程连接和专业桥接主题的小世界架构，阐明了局部新奇事物如何整合到全球音乐形式中。通过将专业化从参数更新转移到交互规则、共享内存和动态共识，MusicSwarm 提供了一条计算和数据高效的途径，以实现长期创意结构，可以立即从音乐转移到协作写作、设计和科学发现。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a></p>
<p><strong>发布</strong>: 2025-09-15 14：23：09 UTC</p>
<h2 id="8-多模态语言模型推理的代理时间图人工智能对医疗保健的潜在帮助-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11944"target="_blank" rel="external nofollow noopener noreferrer">#8</a> <a href="https://papers.cool/arxiv/2509.11944"target="_blank" rel="external nofollow noopener noreferrer">多模态语言模型推理的代理时间图：人工智能对医疗保健的潜在帮助</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Susanta Mitra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Susanta"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Susanta</a> Mitra)</p>
<p>医疗保健和医学是多模态学科，处理多模态数据以推理和诊断多种疾病。尽管已经出现了一些用于推理科学领域复杂任务的多模态推理模型，但它们在医疗保健领域的应用仍然有限，并且在正确的诊断推理方面存在不足。为了解决多模态医学推理正确诊断的挑战并帮助医疗保健专业人员，目前的工作中提出了一种通过有向图建模的基于时间图的新型推理过程。它有助于通过回溯、完善推理内容、创建新的或删除现有的理由来适应原因的动态变化，以达到最佳推荐或答案。同样，考虑不同时间点的多模态数据可以跟踪和分析患者健康和疾病进展。此外，所提出的多智能体时间推理框架提供了任务分布和交叉验证机制，以进一步提高推理输出的准确性。一些基本实验和分析结果证明了所提出的初步方法的新颖性和实用性。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 14：03：19 UTC</p>
<h2 id="9-用于自主诊断的具有模态逻辑的神经符号代理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11943"target="_blank" rel="external nofollow noopener noreferrer">#9</a> <a href="https://papers.cool/arxiv/2509.11943"target="_blank" rel="external nofollow noopener noreferrer">用于自主诊断的具有模态逻辑的神经符号代理</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Antonin Sulc](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Antonin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Antonin</a> Sulc), [Thorsten Hellert](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thorsten"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thorsten</a> Hellert)</p>
<p>智能代理的发展，特别是那些由语言模型 （LM） 驱动的智能代理，已经显示出在需要智能和自主决策的各种环境中的关键作用。环境不是被动的试验场，它们代表了代理学习和展示非常具有挑战性的条件所需的数据，这些条件需要适应性、复杂和自主的能力来做出决策。虽然扩展模型和数据集的范式带来了显着的新兴能力，但我们认为，在这些环境中扩展代理推理的结构、保真度和逻辑一致性是人工智能研究的一个至关重要但未被充分探索的维度。本文介绍了一种神经符号多智能体架构，其中单个智能体的信念状态被正式表示为克里普克模型。这种基本选择使他们能够使用模态逻辑的形式语言对已知的 \emph{possibility} 和 \emph{necessity} 概念进行推理。在这项工作中，我们使用不可变的、特定于领域的知识来制作推断信息，这些信息被编码为正确诊断所必需的逻辑约束。在所提出的模型中，我们展示了主动指导 LM 假设生成的约束，有效地阻止它们得出物理或逻辑上站不住脚的结论。在高保真模拟粒子加速器环境中，我们的系统通过将 LM 强大的语义直觉与模态逻辑和事实世界模型的严格、可验证的验证相结合，成功诊断了复杂的级联故障，并展示了一条通往更强大、可靠和可验证的自主代理的可行路径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.LO"target="_blank" rel="external nofollow noopener noreferrer">计算机科学中的逻辑</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-15 14：03：06 UTC</p>
<h2 id="10-如何评估医疗人工智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11941"target="_blank" rel="external nofollow noopener noreferrer">#10</a> <a href="https://papers.cool/arxiv/2509.11941"target="_blank" rel="external nofollow noopener noreferrer">如何评估医疗人工智能</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ilia Kopanichuk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ilia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ilia</a> Kopanichuk), [Petr Anokhin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Petr"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Petr</a> Anokhin), [Vladimir Shaposhnikov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vladimir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vladimir</a> Shaposhnikov), [Vladimir Makharev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vladimir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vladimir</a> Makharev), [Ekaterina Tsapieva](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ekaterina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ekaterina</a> Tsapieva), [Iaroslav Bespalov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iaroslav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iaroslav</a> Bespalov), [Dmitry V. Dylov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dmitry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dmitry</a> V. Dylov), [Ivan Oseledets](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivan</a> Oseledets)</p>
<p>将人工智能 （AI） 集成到医疗诊断工作流程中需要强大且一致的评估方法，以确保可靠性、临床相关性和专家判断的固有可变性。精度和召回率等传统指标往往无法解释专家判断的固有可变性，导致对人工智能性能的评估不一致。像 Cohen 的 Kappa 这样的评估者间一致性统计数据更可靠，但它们缺乏可解释性。我们引入了算法诊断的相对精度和召回率（RPAD 和 RRAD）——一种新的评估指标，将 AI 输出与多个专家意见进行比较，而不是单个参考。通过根据专家间分歧对性能进行标准化，这些指标为预测诊断的质量提供了更稳定和现实的衡量标准。除了对诊断质量措施的全面分析外，我们的研究还包含一个非常重要的副作用结果。我们的评估方法使我们能够避免在评估给定病例时从有限的列表中选择诊断。相反，被测试的模型和验证它们的检查员都会得出自由形式的诊断。在这种建立自由形式临床诊断身份的自动化方法中，可以达到 98% 的准确率。我们使用 360 度医学对话评估我们的方法，将多个大型语言模型 （LLM） 与一组医生进行比较。大规模研究表明，性能最佳的模型，如 DeepSeek-V3，其一致性与专家共识相当或超过专家共识。此外，我们证明专家的判断表现出显着的差异——通常比人工智能和人类之间的差异更大。这一发现强调了任何绝对指标的局限性，并支持在医疗人工智能中采用相对指标的必要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 14：01：22 UTC</p>
<h2 id="11-神经形态智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11940"target="_blank" rel="external nofollow noopener noreferrer">#11</a> <a href="https://papers.cool/arxiv/2509.11940"target="_blank" rel="external nofollow noopener noreferrer">神经形态智能</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Marcel van Gerven](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marcel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marcel</a> van Gerven)</p>
<p>神经形态计算旨在在人工系统中复制人脑的卓越效率、灵活性和适应性。与依赖大量计算和能源资源的传统数字方法不同，神经形态系统利用受大脑启发的计算原理来实现数量级的能源效率。通过借鉴人工智能、神经科学、物理学、化学和材料科学的见解，神经形态计算有望提供可持续、透明且广泛可访问的智能系统。然而，一个核心挑战是确定一个能够连接这些不同学科的统一理论框架。我们认为动力系统理论提供了这样的基础。它植根于微积分，提供了一种原则性语言，用于在自然和人工基质中对推理、学习和控制进行建模。在这个框架内，噪声可以作为学习资源，而差分遗传编程可以发现实现适应性行为的动力系统。接受这一观点为新兴的神经形态智能铺平了道路，其中智能行为源于物理基质的动态，从而推进了人工智能的科学和可持续性。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 13：59：42 UTC</p>
<h2 id="12-buildinggym使用强化学习进行基于人工智能的建筑能源管理的开源工具箱-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11922"target="_blank" rel="external nofollow noopener noreferrer">#12</a> <a href="https://papers.cool/arxiv/2509.11922"target="_blank" rel="external nofollow noopener noreferrer">BuildingGym：使用强化学习进行基于人工智能的建筑能源管理的开源工具箱</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xilei Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xilei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xilei</a> Dai), [Ruotian Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruotian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruotian</a> Chen), [Songze Guan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Songze"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Songze</a> Guan), [Wen-Tai Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wen-Tai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wen-Tai</a> Li), [Chau Yuen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chau"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chau</a> Yuen)</p>
<p>强化学习 （RL） 已被证明对基于人工智能的建筑能源管理有效。然而，在建筑能源管理中的各种控制问题上，缺乏灵活的框架来实施RL。为了解决这一差距，我们提出了 BuildingGym，这是一种开源工具，旨在作为一个研究友好且灵活的框架，用于训练 RL 控制策略，以应对建筑能源管理中的常见挑战。BuildingGym 将 EnergyPlus 集成为其核心模拟器，使其适用于系统级和房间级控制。此外，BuildingGym 能够接受外部信号作为控制输入，而不是将建筑物视为一个独立的实体。此功能使 BuildingGym 适用于更灵活的环境，例如智能电网和电动汽车社区。该工具提供了多种内置的 RL 算法用于控制策略训练，简化了楼宇管理者获得最优控制策略的过程。用户可以通过遵循几个简单的步骤来配置 BuildingGym 以优化控制建筑能源管理领域常见问题来实现这一点。此外，人工智能专家可以在平台内轻松实施和测试最先进的控制算法。BuildingGym 通过允许轻松配置和替换 RL 算法、模拟器以及控制环境或问题，弥合了建筑经理和 AI 专家之间的差距。通过 BuildingGym，我们有效地设置了冷负荷管理的训练任务，目标是恒定和动态的冷负荷管理。内置算法在这两项任务中都表现出强大的性能，凸显了 BuildingGym 在优化冷却策略方面的有效性。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 13：37：48 UTC</p>
<h2 id="13-egomem全双工全模态模型的终身记忆代理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11914"target="_blank" rel="external nofollow noopener noreferrer">#13</a> <a href="https://papers.cool/arxiv/2509.11914"target="_blank" rel="external nofollow noopener noreferrer">EgoMem：全双工全模态模型的终身记忆代理</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yiqun Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiqun</a> Yao), [Naitong Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Naitong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Naitong</a> Yu), [Xiang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiang</a> Li), [Xin Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Jiang), [Xuezhi Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuezhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuezhi</a> Fang), [Wenjia Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenjia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenjia</a> Ma), [Xuying Meng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuying</a> Meng), [Jing Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jing</a> Li), [Aixin Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aixin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aixin</a> Sun), [Yequan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yequan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yequan</a> Wang)</p>
<p>我们介绍了 EgoMem，这是第一个为处理实时全模态流的全双工模型量身定制的终身内存代理。EgoMem 使实时模型能够直接从原始视听流中识别多个用户，提供个性化响应，并保持对从视听历史中提取的用户事实、偏好和社会关系的长期了解。EgoMem 使用三个异步过程运行：（i） 通过面部和语音动态识别用户并从长期记忆中收集相关上下文的检索过程;（ii）基于检索到的上下文生成个性化音频响应的全模态对话过程;（iii） 内存管理过程，自动检测全模态流中的对话边界，并提取必要的信息以更新长期记忆。与现有的 LLM 记忆代理不同，EgoMem 完全依赖原始视听流，使其特别适合终身、实时和具身场景。实验结果表明，EgoMem 的检索和内存管理模块在测试集上实现了超过 95% 的准确率。当与微调的 RoboEgo 全模态聊天机器人集成时，该系统在实时个性化对话中实现了 87% 以上的事实一致性分数，为未来的研究建立了强大的基线。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 13：33：29 UTC</p>
<h2 id="14-具有监督对比模仿学习的视频游戏代理的学习表征-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11880"target="_blank" rel="external nofollow noopener noreferrer">#14</a> <a href="https://papers.cool/arxiv/2509.11880"target="_blank" rel="external nofollow noopener noreferrer">具有监督对比模仿学习的视频游戏代理的学习表征</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Carlos Celemin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Carlos"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Carlos</a> Celemin), [Joseph Brennan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joseph"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joseph</a> Brennan), [Pierluigi Vito Amadori](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pierluigi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pierluigi</a> Vito Amadori), [Tim Bradley](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tim</a> Bradley)</p>
<p>本文介绍了监督对比学习（SupCon）在模仿学习（IL）中的一种新颖应用，重点是为电子游戏环境中的智能体学习更有效的状态表示。目标是获得观测值的潜在表示，以更好地捕获与动作相关的因素，从而更好地从映射到演示者执行的动作的观测值中对因果关系进行建模，例如，每当前方出现障碍物时，玩家就会跳跃。我们提出了一种将 SupCon 损耗与连续输出空间集成的方法，使 SupCon 能够不受环境动作类型的限制而运行。3D 游戏 Astro Bot 和 Returnal 以及多个 2D Atari 游戏的实验显示，与仅使用监督动作预测损失函数训练的基线模型相比，表示质量更高、学习收敛更快、泛化性更好。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 13：00：29 UTC</p>
<h2 id="15-helofusion一种高效且可扩展的编码器用于对轨迹预测中的异构和多尺度相互作用进行建模-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11719"target="_blank" rel="external nofollow noopener noreferrer">#15</a> <a href="https://papers.cool/arxiv/2509.11719"target="_blank" rel="external nofollow noopener noreferrer">HeLoFusion：一种高效且可扩展的编码器，用于对轨迹预测中的异构和多尺度相互作用进行建模</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Bingqing Wei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingqing</a> Wei), [Lianmin Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lianmin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lianmin</a> Chen), [Zhongyu Xia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongyu</a> Xia), [Yongtao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yongtao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yongtao</a> Wang)</p>
<p>自动驾驶中的多智能体轨迹预测需要对复杂的社会动态有全面的理解。然而，现有方法往往难以充分捕捉这些动态的丰富性，特别是多尺度相互作用的共存和异构智能体的多样化行为。为了应对这些挑战，本文介绍了 HeLoFusion，这是一种高效且可扩展的编码器，用于对异构和多尺度智能体交互进行建模。HeLoFusion 不依赖全局上下文，而是构建以每个智能体为中心的局部多尺度图，使其能够有效地对直接成对依赖关系和复杂的组向交互（\textit{e.g.}，队列车辆或行人人群）进行建模。此外，HeLoFusion 通过聚合-分解消息传递方案和特定类型的特征网络解决了代理异构性的关键挑战，使其能够学习细微的、类型相关的交互模式。这种以局部为中心的方法能够对多层次的社会背景进行原则性表示，从而产生强大且富有表现力的代理嵌入。在具有挑战性的 Waymo Open Motion 数据集上，HeLoFusion 实现了最先进的性能，为包括 Soft mAP 和 minADE 在内的关键指标设定了新的基准。我们的工作表明，基于局部的架构，可以显式地模拟多尺度和异构相互作用，是推进运动预测的高效策略。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 09：19：41 UTC</p>
<h2 id="16-适应和评估青少年特发性脊柱侧弯自我管理的多模态大语言模型分而治之的框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11645"target="_blank" rel="external nofollow noopener noreferrer">#16</a> <a href="https://papers.cool/arxiv/2509.11645"target="_blank" rel="external nofollow noopener noreferrer">适应和评估青少年特发性脊柱侧弯自我管理的多模态大语言模型：分而治之的框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhaolong Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaolong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaolong</a> Wu), [Pu Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pu</a> Luo), [Jason Pui Yin Cheung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jason"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jason</a> Pui Yin Cheung), [Teng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Teng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Teng</a> Zhang)</p>
<p>本研究首次对多模态大型语言模型 （MLLM） 对青少年特发性脊柱侧弯 （AIS） 自我管理进行全面评估。我们构建了一个包含约 3,000 张带有诊断文本的前后 X 射线的数据库，并通过“分而治之”框架评估了 5 个 MLLM，该框架包括视觉问答任务、领域知识评估任务和患者教育咨询评估任务。我们的调查揭示了 MLLM 在解释复杂的脊柱 X 光片和理解 AIS 护理知识方面的能力有限。为了解决这些问题，我们率先通过脊柱关键点提示增强 MLLM，并分别编制了用于检索增强生成 （RAG） 的 AIS 知识库。结果表明，视觉提示在不同架构上的有效性各不相同，而RAG显著提高了模型在知识评估任务中的性能。我们的研究结果表明，当前的 MLLM 远没有能力在 AIS 护理中实现个性化助手。最大的挑战在于他们能否准确检测脊柱畸形位置（最佳精度：0.55）和方向（最佳精度：0.13）。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 07：34：12 UTC</p>
<h2 id="17-amlnet基于知识的多代理框架用于生成和检测真实的洗钱交易-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11595"target="_blank" rel="external nofollow noopener noreferrer">#17</a> <a href="https://papers.cool/arxiv/2509.11595"target="_blank" rel="external nofollow noopener noreferrer">AMLNet：基于知识的多代理框架，用于生成和检测真实的洗钱交易</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sabin Huda](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sabin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sabin</a> Huda), [Ernest Foo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ernest"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ernest</a> Foo), [Zahra Jadidi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zahra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zahra</a> Jadidi), [MA Hakim Newton](<a href="https://arxiv.org/search/?searchtype=author&amp;query=MA"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=MA</a> Hakim Newton), [Abdul Sattar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abdul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abdul</a> Sattar)</p>
<p>反洗钱 （AML） 研究受到缺乏可公开共享、符合监管的交易数据集的限制。我们提出了 AMLNet，这是一个基于知识的多智能体框架，具有两个协调单元：监管感知交易生成器和集成检测管道。生成器产生 1,090,173 个综合交易（大约 0.16% 的洗钱阳性），涵盖核心洗钱阶段（放置、分层、集成）和高级类型（例如，结构化、自适应阈值行为）。根据 AUSTRAC 规则覆盖率，监管一致性达到 75%（第 4.2 节），而 0.75 的综合技术保真度得分总结了时间、结构和行为现实主义组成部分（第 4.4 节）。该检测集成在AMLNet的内部测试分区上达到了F1 0.90（精度0.84，召回率0.97），并适应了外部SynthAML数据集，表明了跨不同合成生成范式的架构通用性。我们提供多维评估（监管、时间、网络、行为）并发布数据集（1.0 版，https://doi.org/10.5281/zenodo.16736515），以推进可重复和具有监管意识的 AML 实验。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-15 05：25：46 UTC</p>
<h2 id="18-基于大型语言模型的时间序列推理与代理系统综述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11575"target="_blank" rel="external nofollow noopener noreferrer">#18</a> <a href="https://papers.cool/arxiv/2509.11575"target="_blank" rel="external nofollow noopener noreferrer">基于大型语言模型的时间序列推理与代理系统综述</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ching Chang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ching"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ching</a> Chang), [Yidan Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yidan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yidan</a> Shi), [Defu Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Defu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Defu</a> Cao), [Wei Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Yang), [Jeehyun Hwang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jeehyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jeehyun</a> Hwang), [Haixin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haixin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haixin</a> Wang), [Jiacheng Pang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiacheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiacheng</a> Pang), [Wei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Wang), [Yan Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yan</a> Liu), [Wen-Chih Peng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wen-Chih"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wen-Chih</a> Peng), [Tien-Fu Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tien-Fu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tien-Fu</a> Chen)</p>
<p>时间序列推理将时间视为一等轴，并将中间证据直接纳入答案中。本调查通过三个族的拓扑推理来定义问题并组织文献：一步直接推理、显式中间体线性链推理以及探索、修正和聚合的分支结构推理。拓扑结构与该领域的主要目标交叉，包括传统的时间序列分析、解释和理解、因果推理和决策以及时间序列生成，而紧凑的标签集跨越这些轴并捕获分解和验证、集成、工具使用、知识访问、多模态、代理循环和 LLM 对齐制度。跨领域审查方法和系统，显示每个拓扑的支持以及它在忠实度或稳健性方面的细分，以及支持研究和部署 （https://github.com/blacksnail789521/Time-Series-Reasoning-Survey） 的精选数据集、基准和资源。重点介绍了使证据可见和时间一致的评估实践，并提炼了有关将拓扑与不确定性相匹配、以可观察的工件为基础、规划移位和流以及将成本和延迟视为设计预算的指导。我们强调，推理结构必须平衡接地和自我校正的能力与计算成本和可重复性，而未来的进展可能取决于将推理质量与效用联系起来的基准，以及在移位感知、流式和长期视野设置下权衡成本和风险的闭环测试平台。总而言之，这些方向标志着从狭隘的准确性向大规模可靠性的转变，使系统不仅能够分析，而且能够理解、解释动态世界并采取行动，并具有可追溯的证据和可信的结果。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 04：39：50 UTC</p>
<h2 id="19-智能qa系统的形式推理教育领域的案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11572"target="_blank" rel="external nofollow noopener noreferrer">#19</a> <a href="https://papers.cool/arxiv/2509.11572"target="_blank" rel="external nofollow noopener noreferrer">智能QA系统的形式推理：教育领域的案例研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tuan Bui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tuan</a> Bui), [An Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=An"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=An</a> Nguyen), [Phat Thai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Phat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Phat</a> Thai), [Minh Hua](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minh</a> Hua), [Ngan Pham L. N.](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ngan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ngan</a> Pham L. N.), [Ngan Pham T. B.](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ngan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ngan</a> Pham T. B.), [Dung Le](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dung</a> Le), [Long Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Long"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Long</a> Nguyen), [Thanh-Tung Tran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thanh-Tung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thanh-Tung</a> Tran), [Thang Bui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thang</a> Bui), [Tho Quan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tho</a> Quan)</p>
<p>推理对于程序正确性和策略合规性至关重要的封闭领域 QA 系统至关重要。虽然大型语言模型 （LLM） 在许多推理任务上表现出了强大的性能，但最近的研究表明，它们的推理痕迹往往是不忠实的——更多的是合理的理由，而不是基于因果的推导。将法学硕士与符号引擎（例如 Prover9、Z3）相结合的努力提高了可靠性，但仍局限于静态形式的逻辑，在动态的、基于状态的推理（例如多步级数和条件转换）中苦苦挣扎。在本文中，我们提出了MCFR（Model Checking for Formal Reasoning），这是一个神经符号框架，它将LLM与模型检查相结合，以支持属性验证。MCFR 将自然语言翻译成正式规范，并通过过渡模型对其进行验证。为了支持评估，我们引入了 EduMC-QA，这是一个基于真实学术程序的基准数据集。我们的结果表明，MCFR 提高了推理的忠实度和可解释性，为高风险封闭域应用程序中可验证的 QA 提供了一条可行的途径。除了评估 MCFR 之外，我们还将其性能与 ChatGPT、DeepSeek 和 Claude 等最先进的法学硕士进行比较，以了解其有效性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 04：34：42 UTC</p>
<h2 id="20-使用合成数据增强的基于眼球运动的任务解码-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11547"target="_blank" rel="external nofollow noopener noreferrer">#20</a> <a href="https://papers.cool/arxiv/2509.11547"target="_blank" rel="external nofollow noopener noreferrer">使用合成数据增强的基于眼球运动的任务解码</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shanmuka Sadhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shanmuka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shanmuka</a> Sadhu), [Arca Baran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arca</a> Baran), [Preeti Pandey](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Preeti"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Preeti</a> Pandey), [Ayush Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ayush"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ayush</a> Kumar)</p>
<p>机器学习已广泛应用于与眼动追踪研究相关的各种应用。了解眼动是眼动追踪研究中最重要的子集之一，它揭示了个人的扫描模式。研究人员对眼动数据进行了彻底的分析，以了解各种眼动追踪应用，如注意力机制、导航行为、任务理解等。用于基于眼动数据解码任务的传统机器学习算法的结果对 Yarbus 声称可以从观察者的眼球运动中解码观察者的任务的说法反应不一。在本文中，为了支持 Yarbus 的假设，我们正在解码任务类别，同时使用著名的合成数据生成器 CTGAN 及其变体（如 CopulaGAN 和 Gretel AI 合成数据生成器）根据来自面对面用户研究的可用数据生成合成数据样本。我们的结果表明，即使使用传统的机器学习算法，增强更多的眼动数据与额外的合成生成相结合，也可以提高分类准确性。我们看到，当除了 320 个真实眼动数据集样本之外，添加了五倍的数据，任务解码准确率从使用随机森林的 28.1% 提高到使用 Inception Time 的 82%。由于使用了额外的合成数据集，我们提出的框架优于该数据集的所有可用研究。我们用各种算法以及真实数据和合成数据的组合验证了我们的主张，以展示解码准确性如何随着生成数据对真实数据的增强而增加。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 03：28：21 UTC</p>
<h2 id="21-medicalos基于-llm-代理的数字医疗保健作系统-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11507"target="_blank" rel="external nofollow noopener noreferrer">#21</a> <a href="https://papers.cool/arxiv/2509.11507"target="_blank" rel="external nofollow noopener noreferrer">MedicalOS：基于 LLM 代理的数字医疗保健作系统</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Jared Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jared"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jared</a> Zhu), [Junde Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junde"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junde</a> Wu)</p>
<p>几十年来，电子健康记录等数字健康技术的进步在很大程度上简化了常规临床流程。然而，大多数这些系统仍然难以学习和使用：临床医生经常面临管理多个工具、为每位患者重复手动作、浏览复杂的 UI 树以定位功能以及花费大量时间在管理而不是照顾患者的负担。最近基于大型语言模型 （LLM） 的代理的兴起展示了在编码和计算机作方面的卓越能力，揭示了人类与作系统和软件交互的潜力，而不是通过直接作，而是通过自然语言指示代理。这种转变凸显了对抽象层的需求，即代理-计算机界面，将人类语言翻译成机器可执行命令。然而，在数字医疗保健中，需要更针对特定领域的抽象，严格遵循可信的临床指南和程序标准，以确保安全性、透明度和合规性。为了满足这一需求，我们提出了 \textbf{MedicalOS}，这是一个基于代理的统一作系统，旨在作为医疗保健的特定领域抽象层。它将人类指令转换为预定义的数字医疗保健命令，例如患者查询、病史检索、检查管理、报告生成、转诊、治疗计划，我们使用机器语言（例如 Python、API、MCP、Linux）将其包装为现成的工具。我们对 22 个专业的 214 例患者病例进行了实证验证，证明了高诊断准确性和可信度、临床上合理的检查请求以及一致生成的结构化报告和药物建议。这些结果凸显了 MedicalOS 是推进临床实践工作流程自动化的值得信赖且可扩展的基础。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 01：43：20 UTC</p>
<h2 id="22-视觉-语言-动作模型从边缘到云gpu的跨平台扩展-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11480"target="_blank" rel="external nofollow noopener noreferrer">#22</a> <a href="https://papers.cool/arxiv/2509.11480"target="_blank" rel="external nofollow noopener noreferrer">视觉-语言-动作模型从边缘到云GPU的跨平台扩展</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Amir Taherin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amir</a> Taherin), [Juyi Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juyi</a> Lin), [Arash Akbari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arash"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arash</a> Akbari), [Arman Akbari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arman</a> Akbari), [Pu Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pu</a> Zhao), [Weiwei Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiwei</a> Chen), [David Kaeli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Kaeli), [Yanzhi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanzhi</a> Wang)</p>
<p>视觉-语言-行动 （VLA） 模型已成为机器人控制的强大通才策略，但它们在模型架构和硬件平台上的性能扩展以及相关的功率预算仍然知之甚少。这项工作对五种代表性的 VLA 模型进行了评估，这些模型涵盖了最先进的基线和两种新提出的架构，针对边缘和数据中心 GPU 平台。使用 LIBERO 基准测试，我们在不同的边缘功率限制和高性能数据中心 GPU 配置下测量准确性以及系统级指标，包括延迟、吞吐量和峰值内存使用情况。我们的结果确定了不同的扩展趋势：（1）架构选择，如动作标记化和模型主干大小，强烈影响吞吐量和内存占用;（2）功率受限的边缘设备表现出非线性性能下降，某些配置与旧的数据中心GPU相当或超过;（3）可以在不显着精度损失的情况下实现高通量变体。这些发现在跨一系列部署约束选择和优化 VLA 时提供了可作的见解。我们的工作挑战了当前关于数据中心硬件在机器人推理方面优越性的假设。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.ET"target="_blank" rel="external nofollow noopener noreferrer">新兴技术</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a></p>
<p><strong>发布</strong>: 2025-09-15 00：00：37 世界标准时间</p>
<h2 id="23-知识引导的自适应混合专家降水预报-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11459"target="_blank" rel="external nofollow noopener noreferrer">#23</a> <a href="https://papers.cool/arxiv/2509.11459"target="_blank" rel="external nofollow noopener noreferrer">知识引导的自适应混合专家降水预报</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Chen Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chen</a> Jiang), [Kofi Osei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kofi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kofi</a> Osei), [Sai Deepthi Yeddula](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sai</a> Deepthi Yeddula), [Dongji Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongji</a> Feng), [Wei-Shinn Ku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei-Shinn"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei-Shinn</a> Ku)</p>
<p>准确的降水预报对于农业、灾害管理和可持续战略是不可或缺的。然而，由于气候系统的复杂性和多源观测数据（包括雷达、卫星图像和地表测量）的异质性，预测降雨量一直具有挑战性。多源数据在空间和时间分辨率上各不相同，并且它们具有特定领域的特征，这使得在传统深度学习模型中有效集成具有挑战性。之前的研究已经探索了用于天气预报的各种机器学习技术;然而，大多数人都在努力将数据与异构模式集成。为了解决这些限制，我们提出了一种专为降水率预测量身定制的自适应专家混合 （MoE） 模型。模型中的每个专家都专注于特定的模态或时空模式。我们还整合了一个动态路由器，可以学习将输入分配给最相关的专家。我们的结果表明，这种模块化设计增强了预测的准确性和可解释性。除了建模框架之外，我们还引入了基于网络的交互式可视化工具，使用户能够直观地探索时间和空间上的历史天气模式。该工具旨在支持气候敏感部门利益相关者的决策。我们使用精心策划的多模态气候数据集评估了我们的方法，该数据集捕捉了 2022 年伊恩飓风期间的真实世界条件。基准测试结果表明，自适应 MoE 的性能明显优于所有基线。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 22：31：46 UTC</p>
<h2 id="24-保护-ai-代理为工业应用程序实施基于角色的访问控制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11431"target="_blank" rel="external nofollow noopener noreferrer">#24</a> <a href="https://papers.cool/arxiv/2509.11431"target="_blank" rel="external nofollow noopener noreferrer">保护 AI 代理：为工业应用程序实施基于角色的访问控制</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Aadil Gani Ganie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aadil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aadil</a> Gani Ganie)</p>
<p>大型语言模型 （LLM） 的出现为从政治学到软件开发等各个领域的解决方案提供了显着先进的解决方案。然而，这些模型受到其训练数据的限制，这些数据是静态的，仅限于特定日期之前可用的信息。此外，它们的通用性通常需要微调——无论是出于分类还是教学目的——才能有效地执行特定的下游任务。人工智能代理以法学硕士为核心，通过访问外部工具和实时数据来缓解其中一些限制，从而实现实时天气预报和数据分析等应用程序。在工业环境中，人工智能代理正在通过增强决策、预测性维护和流程优化来改变运营方式。例如，在制造业中，人工智能代理支持近乎自主的系统，从而提高生产力并支持实时决策。尽管取得了这些进步，人工智能代理仍然容易受到安全威胁，包括提示注入攻击，这对其完整性和可靠性构成重大风险。为了应对这些挑战，本文提出了一个将基于角色的访问控制（RBAC）集成到AI代理中的框架，提供了强大的安全护栏。该框架旨在支持人工智能代理的有效且可扩展的部署，重点是本地实施。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 20：58：08 UTC</p>
<h2 id="25-mapgd用于协作提示优化的多智能体提示梯度下降-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11361"target="_blank" rel="external nofollow noopener noreferrer">#25</a> <a href="https://papers.cool/arxiv/2509.11361"target="_blank" rel="external nofollow noopener noreferrer">MAPGD：用于协作提示优化的多智能体提示梯度下降</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yichen Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yichen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yichen</a> Han), [Bojun Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bojun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bojun</a> Liu), [Zhengpeng zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhengpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhengpeng</a> zhou), [Guanyu Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guanyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guanyu</a> Liu), [Zeng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zeng</a> Zhang), [Yang Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Yang), [Wenli Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenli"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenli</a> Wang), [Isaac N Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Isaac"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Isaac</a> N Shi), <a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunyan"target="_blank" rel="external nofollow noopener noreferrer">Yunyan</a>, [Lewei He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lewei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lewei</a> He), [Tianyu Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyu</a> Shi)</p>
<p>提示工程对于利用大型语言模型（LLM）至关重要，但现有方法通常依赖于单一的优化轨迹，限制了适应性和效率，同时存在狭隘的视角、梯度冲突和高计算成本等问题。我们提出了 MAPGD（Multi-Agent Prompt Gradient Descent），这是一个将多智能体协作与基于梯度的优化相结合的框架。MAPGD 具有专门的代理，用于任务清晰度、示例选择、格式设计和风格细化;语义梯度协调以解决冲突;基于盗贼的候选者选择，实现高效的勘探开发;和理论收敛保证。分类、生成和推理任务的实验表明，MAPGD 在准确性和效率方面优于单智能体和随机基线。消融证实了梯度融合、代理专业化和冲突解决的好处，为稳健且可解释的提示优化提供了一种统一的、受梯度启发的多代理方法。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 17：28：52 UTC</p>
<h2 id="26-动态因果关系在基于观察者设计的软传感器应用中的力量-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11336"target="_blank" rel="external nofollow noopener noreferrer">#26</a> <a href="https://papers.cool/arxiv/2509.11336"target="_blank" rel="external nofollow noopener noreferrer">动态因果关系在基于观察者设计的软传感器应用中的力量</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [William Farlessyost](<a href="https://arxiv.org/search/?searchtype=author&amp;query=William"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=William</a> Farlessyost), [Sebastian Oberst](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sebastian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sebastian</a> Oberst), [Shweta Singh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shweta"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shweta</a> Singh)</p>
<p>本文介绍了一种通过动态因果关系分析优化基于观察者的软传感器的新框架。传统的传感器选择方法通常依赖于线性化的可观测性指数或统计相关性，无法捕捉复杂系统的时间演变。我们通过利用液体时间常数 （LTC） 网络（具有输入相关时间常数的连续时间神经架构）来系统地识别和修剪传感器输入，从而解决这一差距，同时将对状态估计的因果影响降至最低。我们的方法实现了迭代工作流程：对候选输入进行 LTC 观察者训练，通过受控扰动分析量化每个输入的因果影响，删除影响可以忽略不计的输入，并重新训练直到性能下降。我们在代表不同物理域的三个机械测试台上演示了这种方法：谐波强制弹簧质量阻尼器系统、非线性连续搅拌罐反应器以及遵循 Lotka-Volterra 模型结构的捕食者-猎物模型，但具有季节性强迫和增加的复杂性。结果表明，我们的因果关系引导修剪始终能够识别出与底层物理场一致的最小传感器集，同时提高预测精度。该框架自动将基本物理测量值与噪声区分开来，并确定派生的交互项何时提供补充信息与冗余信息。除了计算效率之外，这种方法还通过将传感器选择决策建立在动态因果关系而不是静态相关性中来增强可解释性，为跨过程工程、生态监测和农业领域的软传感应用提供了显着的好处。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 16：27：58 UTC</p>
<h2 id="27-解码塑料毒性从科学摘要中提取冲突感知关系元路径的智能框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11330"target="_blank" rel="external nofollow noopener noreferrer">#27</a> <a href="https://papers.cool/arxiv/2509.11330"target="_blank" rel="external nofollow noopener noreferrer">解码塑料毒性：从科学摘要中提取冲突感知关系元路径的智能框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sudeshna Jana](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sudeshna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sudeshna</a> Jana), [Manjira Sinha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manjira"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manjira</a> Sinha), [Tirthankar Dasgupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tirthankar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tirthankar</a> Dasgupta)</p>
<p>塑料的广泛使用及其在环境中的持久性导致微塑料和纳米塑料在空气、水和土壤中积累，带来严重的健康风险，包括呼吸系统、胃肠道和神经系统疾病。我们提出了一种新颖的框架，利用大型语言模型从科学摘要中提取关系元路径，即将污染物源与健康影响联系起来的多跳语义链。我们的系统识别并连接不同环境中的实体，以构建结构化的关系元路径，这些元路径被聚合到毒性轨迹图中，该图通过暴露路线和生物系统追踪污染物的传播。此外，为了确保一致性和可靠性，我们采用了动态证据核对模块，以解决因不断发展或相互矛盾的研究结果而产生的语义冲突。我们的方法在从嘈杂的科学文本中提取可靠、高效用的关系知识方面表现出强大的性能，并为挖掘特定领域语料库中的复杂因果结构提供了可扩展的解决方案。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 16：14：36 UTC</p>
<h2 id="28-代理提示通过紧凑的-llm-集成模拟人类偏好-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11311"target="_blank" rel="external nofollow noopener noreferrer">#28</a> <a href="https://papers.cool/arxiv/2509.11311"target="_blank" rel="external nofollow noopener noreferrer">代理提示：通过紧凑的 LLM 集成模拟人类偏好</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Bingchen Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingchen</a> Wang), [Zi-Yu Khoo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zi-Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zi-Yu</a> Khoo), [Bryan Kian Hsiang Low](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bryan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bryan</a> Kian Hsiang Low)</p>
<p>大型语言模型 （LLM） 在模拟各种任务中的类人响应方面已显示出前景。在本文中，我们提出了一种新颖的对齐框架，将法学硕士视为人类调查受访者的代理代理，为社会科学中的两个紧迫挑战提供一种经济高效且可引导的解决方案：调查部署成本的上升和调查响应数据中日益严重的人口失衡。从揭示偏好理论中汲取灵感，我们将对齐表述为一个两阶段问题：构建不同的代理角色，称为天赋，模拟合理的受访者概况，并根据观察到的数据选择一个具有代表性的子集来近似地面实况人群。为了实现该范式，我们引入了 P2P，这是一个使用结构化提示工程、基于熵的抽样和基于回归的选择来引导 LLM 代理走向代表性行为模式的系统。与注重个性化的方法不同，我们的对齐方法与人口统计学无关，仅依赖于汇总调查结果，提供更好的普遍性和简约性。除了提高社会科学研究的数据效率外，我们的框架还为研究多元一致性的可作化提供了一个测试平台。我们在真实世界的民意调查数据集上展示了我们的方法的有效性，表明即使没有人口统计条件，我们对齐的代理群体也可以高保真地再现聚合反应模式并表现出大量的反应多样性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-14 15：08：45 UTC</p>
<h2 id="29-videoagent科学视频的个性化合成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11253"target="_blank" rel="external nofollow noopener noreferrer">#29</a> <a href="https://papers.cool/arxiv/2509.11253"target="_blank" rel="external nofollow noopener noreferrer">VideoAgent：科学视频的个性化合成</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xiao Liang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiao</a> Liang), [Bangxin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bangxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bangxin</a> Li), [Zixuan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zixuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zixuan</a> Chen), [Hanyue Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hanyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hanyue</a> Zheng), [Zhi Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhi</a> Ma), [Di Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Di"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Di</a> Wang), [Cong Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cong</a> Tian), [Quan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Quan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Quan</a> Wang)</p>
<p>自动化生成科学视频是有效传播知识的一项关键但具有挑战性的任务。然而，现有的文档自动化工作主要集中在海报和幻灯片等静态媒体上，缺乏个性化动态编排和多模态内容同步的机制。为了应对这些挑战，我们推出了 VideoAgent，这是一种新颖的多智能体框架，可通过对话界面合成个性化科学视频。VideoAgent 将源论文解析为细粒度的资产库，并在用户需求的指导下编排叙述流程，综合静态幻灯片和动态动画来解释复杂的概念。为了实现严格的评估，我们还提出了 SciVidEval，这是该任务的第一个综合套件，它将多模态内容质量和同步的自动化指标与基于视频测验的人工评估相结合，以衡量知识转移。广泛的实验表明，我们的方法明显优于现有的商业科学视频生成服务，并且在科学交流方面接近人类水平的质量。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 12：54：21 UTC</p>
<h2 id="30-跨领域应用中的人工智能生成内容研究趋势挑战和主张-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11151"target="_blank" rel="external nofollow noopener noreferrer">#30</a> <a href="https://papers.cool/arxiv/2509.11151"target="_blank" rel="external nofollow noopener noreferrer">跨领域应用中的人工智能生成内容：研究趋势、挑战和主张</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jianxin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jianxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jianxin</a> Li), [Liang Qu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liang</a> Qu), [Taotao Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taotao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taotao</a> Cai), [Zhixue Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhixue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhixue</a> Zhao), [Nur Al Hasan Haldar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nur"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nur</a> Al Hasan Haldar), [Aneesh Krishna](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aneesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aneesh</a> Krishna), [Xiangjie Kong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiangjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiangjie</a> Kong), [Flavio Romero Macau](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Flavio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Flavio</a> Romero Macau), [Tanmoy Chakraborty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tanmoy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tanmoy</a> Chakraborty), [Aniket Deroy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aniket"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aniket</a> Deroy), [Binshan Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Binshan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Binshan</a> Lin), [Karen Blackmore](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Karen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Karen</a> Blackmore), [Nasimul Noman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nasimul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nasimul</a> Noman), [Jingxian Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingxian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingxian</a> Cheng), [Ningning Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ningning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ningning</a> Cui), [Jianliang Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jianliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jianliang</a> Xu)</p>
<p>人工智能生成内容（AIGC）迅速兴起，能够生成不同形式的内容，包括文本、图像、视频和其他模态，可以达到与人类创建的内容相似的质量。因此，AIGC现已广泛应用于数字营销、教育、公共卫生等各个领域，并通过提高内容创作效率、改善信息传递等方式，展现出了可喜的成果。然而，很少有研究探讨AIGC在不同领域的最新进展和新出现的挑战。为了弥合这一差距，本文汇集了来自多个学科的 16 位学者，以跨领域的视角探讨 AIGC 的趋势和挑战。具体来说，本文的贡献有三重：（1）它首先提供了对AIGC的更广泛概述，涵盖生成式AI的训练技术、检测方法以及AI生成内容在数字平台上的传播和使用。（2） 然后介绍了 AIGC 在不同领域的社会影响，并回顾了在这些背景下采用的现有方法。（3）最后，讨论了关键技术挑战，并提出了指导未来工作的研究命题。通过这些贡献，这篇愿景论文旨在为读者提供关于 AIGC 的跨领域视角，深入了解其当前的研究趋势、持续的挑战和未来的方向。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 07：56：21 UTC</p>
<h2 id="31-alignkt使用理想状态对齐显式建模知识状态以进行知识追踪-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11135"target="_blank" rel="external nofollow noopener noreferrer">#31</a> <a href="https://papers.cool/arxiv/2509.11135"target="_blank" rel="external nofollow noopener noreferrer">AlignKT：使用理想状态对齐显式建模知识状态以进行知识追踪</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jing Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jing</a> Xiao), [Chang You](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chang</a> You), [Zhiyu Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyu</a> Chen)</p>
<p>知识追踪 （KT） 是智能辅导系统 （ITS） 的基本组成部分，使这些系统能够通过对学习者的知识状态进行建模来监控和了解学习者的进度。然而，许多现有的知识知识库模型主要侧重于拟合学习者交互的顺序，而往往忽视了知识状态本身。这种限制导致可解释性降低和 ITS 的教学支持不足。为了应对这一挑战，我们提出了 AlignKT，它采用前端到后端的架构来显式建模稳定的知识状态。在这种方法中，初步知识状态与附加标准保持一致。具体来说，我们定义了基于教学理论的理想知识状态作为对齐标准，为可解释性提供了基础。我们利用五个编码器来实现此设置，并结合对比学习模块来增强对准过程的稳健性。通过广泛的实验，AlignKT 表现出卓越的性能，在三个真实世界数据集上优于七个 KT 基线。它在其中两个数据集上取得了最先进的结果，并在第三个数据集上表现出竞争性能。这项工作的代码可在 <a href="https://github.com/SCNU203/AlignKT"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/SCNU203/AlignKT</a> 获得。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 07：06：40 UTC</p>
<h2 id="32-神经元胞自动机在生物学和经典人工智能之外的应用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11131"target="_blank" rel="external nofollow noopener noreferrer">#32</a> <a href="https://papers.cool/arxiv/2509.11131"target="_blank" rel="external nofollow noopener noreferrer">神经元胞自动机：在生物学和经典人工智能之外的应用</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Benedikt Hartl](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Benedikt"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Benedikt</a> Hartl), [Michael Levin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Levin), [Léo Pio-Lopez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=L"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=L</a>éo Pio-Lopez)</p>
<p>神经元胞自动机 （NCA） 代表了生物自组织建模的强大框架，通过可训练、可微分（或可进化）的更新规则扩展了经典的基于规则的系统，这些规则捕获了生物的适应性自我调节动态。通过将人工神经网络 （ANN） 嵌入为局部决策中心和局部代理之间的交互规则，NCA 可以模拟分子、细胞、组织和系统级尺度的过程，提供关于进化、发育、再生、衰老、形态发生和机器人控制的多尺度能力架构视角。这些模型不仅再现了受生物学启发的目标模式，而且还推广到新的条件，展示了对扰动的鲁棒性以及开放式适应和推理的能力。鉴于它们在最近的发展中取得了巨大成功，我们在这里回顾了主要与生物或生物工程应用相关的NCA的当前文献。此外，我们强调，除了生物学之外，NCA 在没有集中控制的情况下表现出稳健和普遍的目标导向动力学，例如，在控制或再生复合机器人形态，甚至在 ARC-AGI-1 等尖端推理任务中。此外，迭代状态细化的相同原理让人想起现代生成式人工智能 （AI），例如概率扩散模型。它们的控制自我调节行为限制了完全局部化的相互作用，但它们的集体行为却扩展为协调的系统级结果。因此，我们认为 NCA 构成了一种统一的计算精益范式，它不仅将多尺度生物学的基本见解与现代生成式人工智能联系起来，而且有可能设计出真正受生物启发的集体智慧，能够进行分层推理和控制。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a>, <a href="https://papers.cool/arxiv/q-bio.OT"target="_blank" rel="external nofollow noopener noreferrer">其他定量生物学</a></p>
<p><strong>发布</strong>: 2025-09-14 06：55：29 UTC</p>
<h2 id="33-llm-驱动的工作流程中的难度感知代理编排-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11079"target="_blank" rel="external nofollow noopener noreferrer">#33</a> <a href="https://papers.cool/arxiv/2509.11079"target="_blank" rel="external nofollow noopener noreferrer">LLM 驱动的工作流程中的难度感知代理编排</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Jinwei Su](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinwei</a> Su), [Yinghui Xia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yinghui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yinghui</a> Xia), [Qizhen Lan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qizhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qizhen</a> Lan), [Xinyuan Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinyuan</a> Song), [Yang Jingsong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Jingsong), [Lewei He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lewei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lewei</a> He), [Tianyu Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyu</a> Shi)</p>
<p>基于大型语言模型 （LLM） 的代理系统在各种任务中表现出了强大的能力。然而，现有的多代理框架通常依赖于静态或任务级工作流程，这些工作流程要么过度处理简单查询，要么在复杂查询上表现不佳，同时也忽略了异构 LLM 之间的效率与性能权衡。为了解决这些限制，我们提出了难度感知代理编排（DAAO），这是一种动态框架，可根据每个输入查询的难度调整工作流程深度、运算符选择和LLM分配。DAAO由三个相互依赖的模块组成：用于难度估计的变分自动编码器（VAE）、模块化操作员分配器以及成本和性能感知的LLM路由器。通过利用异构法学硕士和动态定制工作流程，DAAO 实现了细粒度的、特定于查询的推理策略。在六个基准测试中，DAAO 在准确性和推理效率方面均优于之前的多代理系统。我们将在发布后发布我们的代码和实现细节。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 03：57：43 UTC</p>
<h2 id="34-patient-zero用于生成真实无记录的患者代理的统一框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11078"target="_blank" rel="external nofollow noopener noreferrer">#34</a> <a href="https://papers.cool/arxiv/2509.11078"target="_blank" rel="external nofollow noopener noreferrer">Patient-Zero：用于生成真实无记录的患者代理的统一框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yunghwei Lai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunghwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunghwei</a> Lai), [Weizhi Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weizhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weizhi</a> Ma), [Yang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Liu)</p>
<p>使用大型语言模型 （LLM） 生成合成数据已成为各个领域（特别是医疗领域）的一种有前途的解决方案，以缓解数据收集挑战。然而，现有研究主要利用法学硕士重写和完善现有的病历，在数据隐私、准确性和多样性方面存在局限性，并且缺乏像真实患者一样互动的能力。为了解决这些问题，我们提出了一个现实的患者生成框架，即 Patient-Zero，它不需要真实的医疗记录。Patient-Zero首先引入了医学对齐的多步生成架构，通过分层医学知识注入，在没有真实病历的情况下，构建全面的病历。然后，为了优化虚拟患者与人类的交互能力，Patient-Zero设计了动态更新机制，以提高一致性和对话性能。我们的框架能够生成上下文不同的患者记录，同时保持严格的医疗连贯性，并得到适应性对话策略和实时临床合理性验证的支持。实验结果表明，该模型在准确性、多样性和一致性方面取得了良好的性能。在使用我们生成的虚拟患者进行训练后，现有模型在 MedQA 数据集上显示出显着改进。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 03：56：00 UTC</p>
<h2 id="35-通过确定性可复制性对大型语言模型进行可处理的非对称验证-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11068"target="_blank" rel="external nofollow noopener noreferrer">#35</a> <a href="https://papers.cool/arxiv/2509.11068"target="_blank" rel="external nofollow noopener noreferrer">通过确定性可复制性对大型语言模型进行可处理的非对称验证</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zan-Kai Chong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zan-Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zan-Kai</a> Chong), [Hiroyuki Ohsaki](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hiroyuki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hiroyuki</a> Ohsaki), [Bryan Ng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bryan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bryan</a> Ng)</p>
<p>大型语言模型 （LLM） 的格局迅速转向动态、多代理系统。这给建立计算信任带来了一个基本挑战，特别是一个代理如何验证另一个代理的输出是否真正由声称的 LLM 生成，而不是由更便宜或劣质的模型伪造或生成。为了应对这一挑战，本文提出了一种验证框架，该框架可以实现可处理的不对称努力，其中验证计算的成本大大低于执行计算的成本。我们的方法建立在确定性可复制性原则之上，这是自回归模型固有的属性，严格需要一个计算同构的环境，其中所有代理都在相同的硬件和软件堆栈上运行。在这个定义的上下文中，我们的框架使多个验证者能够概率地审计 LLM 输出的小部分、随机片段，并有效地分配验证工作负载。仿真表明，靶向验证比完全再生快 12 倍以上，并具有可调参数来调整检测概率。通过为可审计的 LLM 系统建立一个易于处理的机制，我们的工作为负责任的 AI 提供了基础层，并成为未来研究更复杂、更异构的多智能体系统的基石。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 03：30：06 UTC</p>
<h2 id="36-agentic-lybic具有分层推理和编排功能的多代理执行系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11067"target="_blank" rel="external nofollow noopener noreferrer">#36</a> <a href="https://papers.cool/arxiv/2509.11067"target="_blank" rel="external nofollow noopener noreferrer">Agentic Lybic：具有分层推理和编排功能的多代理执行系统</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Liangxuan Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liangxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liangxuan</a> Guo), [Bin Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bin</a> Zhu), [Qingqian Tao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingqian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingqian</a> Tao), [Kangning Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kangning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kangning</a> Liu), [Xun Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xun</a> Zhao), [Xianzhe Qin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xianzhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xianzhe</a> Qin), [Jin Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jin</a> Gao), [Guangfu Hao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guangfu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guangfu</a> Hao)</p>
<p>由于协调性差和质量控制不足，桌面自动化的自主代理难以处理复杂的多步骤任务。我们介绍了 \textsc{Agentic Lybic}，这是一种新颖的多智能体系统，其中整个架构作为有限状态机 （FSM） 运行。这一核心创新支持动态编排。我们的系统由四个部分组成：一个控制器、一个经理、三个工人（负责基于代码的作的技术员、负责 GUI 交互的操作员和负责决策支持的分析师）和一名评估员。关键机制是这些组件之间基于 FSM 的路由，它通过为每个子任务动态选择最佳执行策略来提供灵活性和通用性。这种有原则的编排与强大的质量门控相结合，可实现自适应重新规划和错误恢复。\textsc{Agentic Lybic} 在 OSWorld 基准测试上进行了官方评估，在 50 个步骤中实现了最先进的 57.07% 成功率，大大优于现有方法。结果表明，具有持续质量控制的原则性多代理编排为复杂计算环境中的通用桌面自动化提供了卓越的可靠性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-14 03：22：27 UTC</p>
<h2 id="37-free-mad无共识的多代理辩论-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11035"target="_blank" rel="external nofollow noopener noreferrer">#37</a> <a href="https://papers.cool/arxiv/2509.11035"target="_blank" rel="external nofollow noopener noreferrer">Free-MAD：无共识的多代理辩论</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yu Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Cui), [Hang Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hang</a> Fu), [Haibin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haibin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haibin</a> Zhang), [Licheng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Licheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Licheng</a> Wang), [Cong Zuo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cong</a> Zuo)</p>
<p>多智能体辩论（MAD）是一种提高大型语言模型（LLM）推理能力的新兴方法。现有的 MAD 方法依靠智能体之间的多轮交互来达成共识，最终输出是在最后一轮通过多数投票选出的。然而，这种基于共识的设计面临一些限制。首先，多轮通信会增加令牌开销并限制可扩展性。其次，由于 LLM 的固有一致性，最初产生正确回答的智能体可能会在辩论过程中受到错误回答的影响，从而导致错误传播。第三，多数投票在决策阶段引入了随机性和不公平性，并可能降低推理性能。为了解决这些问题，我们提出了 \textsc{Free-MAD}，这是一种新颖的 MAD 框架，无需代理之间达成共识。\textsc{Free-MAD} 引入了一种新颖的基于分数的决策机制，该机制评估整个辩论轨迹，而不是仅仅依赖最后一轮。该机制跟踪每个代理的推理如何演变，从而获得更准确、更公平的结果。此外，\textsc{Free-MAD} 通过引入反一致性来重建辩论阶段，这是一种使代理人能够减轻多数人过度影响的机制。在八个基准数据集上的实验表明，\textsc{Free-MAD} 显着提高了推理性能，同时只需要一轮辩论，从而降低了代币成本。我们还表明，与现有的 MAD 方法相比，\textsc{Free-MAD} 在实际攻击场景中表现出更高的鲁棒性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a></p>
<p><strong>发布</strong>: 2025-09-14 01：55：01 UTC</p>
<h2 id="38-重新思考对-llm-基本原理的人类偏好评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11026"target="_blank" rel="external nofollow noopener noreferrer">#38</a> <a href="https://papers.cool/arxiv/2509.11026"target="_blank" rel="external nofollow noopener noreferrer">重新思考对 LLM 基本原理的人类偏好评估</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ziang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziang</a> Li), [Manasi Ganti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manasi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manasi</a> Ganti), [Zixian Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zixian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zixian</a> Ma), [Helena Vasconcelos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helena</a> Vasconcelos), [Qijia He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qijia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qijia</a> He), [Ranjay Krishna](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ranjay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ranjay</a> Krishna)</p>
<p>大型语言模型 （LLM） 通常会生成自然语言基本原理——自由形式的解释，有助于提高复杂推理任务的性能并增强人类用户的可解释性。然而，评估这些基本原理仍然具有挑战性。虽然最近的工作依赖于人类或法学硕士评委的二元偏好判断，但此类评估通常是不透明和粗粒度的，对是什么使一种理由比另一种理由更好提供了有限的见解。在这项工作中，我们通过询问以下问题来重新思考对 LLM 生成的基本原理的偏好评估：（1） 哪些属性定义了良好的基本原理？（2）人类的偏好可以用这些属性来解释吗？（3）基于属性的评估能否克服二元比较的局限性？我们从先前的文献中确定了一组关键的基本原理属性，并使用自动指标、LLM 判断和人工注释对其进行评估。然后，我们使用 SHAP 分析两个标准的人类偏好数据集 MT Bench 和 Chatbot Arena，以确定哪些属性最能解释人类偏好结果。最后，我们使用特定属性的 ELO 分数重新评估模型生成的基本原理，揭示更细致的模型比较和见解。我们的研究结果表明，细粒度的属性评估可以更好地表征基本原理质量，并指导未来的研究走向更可解释和可靠的评估实践。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 01：33：14 UTC</p>
<h2 id="39-使用法学硕士增强计算认知架构案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10972"target="_blank" rel="external nofollow noopener noreferrer">#39</a> <a href="https://papers.cool/arxiv/2509.10972"target="_blank" rel="external nofollow noopener noreferrer">使用法学硕士增强计算认知架构：案例研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Ron Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ron"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ron</a> Sun)</p>
<p>计算认知架构是人类思维的广泛范围模型，它将不同的心理功能（以及针对这些不同功能的不同计算方法）组合到一个统一的框架中。他们以一种在心理上合理且经过验证的方式构建它们。然而，迄今为止，此类模型的计算能力有限，主要受到所采用的计算工具和技术的限制。最近，法学硕士已被证明比任何其他工具都更具有计算能力。因此，为了同时应对现实世界的复杂性和心理现实主义，将LLM纳入认知架构自然成为一项重要任务。在本文中，作为案例研究讨论了歌乐认知架构和 LLM 的协同组合。歌乐的基本隐式-显式二分法被用于歌乐和法学硕士的无缝集成。因此，法学硕士的计算能力与歌乐的心理素质相结合。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 20：14：14 UTC</p>
<h2 id="40-公共数据辅助差分私密情境学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10932"target="_blank" rel="external nofollow noopener noreferrer">#40</a> <a href="https://papers.cool/arxiv/2509.10932"target="_blank" rel="external nofollow noopener noreferrer">公共数据辅助差分私密情境学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Seongho Joo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seongho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seongho</a> Joo), [Hyukhun Koh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyukhun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyukhun</a> Koh), [Kyomin Jung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyomin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyomin</a> Jung)</p>
<p>大型语言模型 （LLM） 中的上下文学习 （ICL） 在各种任务中表现出卓越的性能，无需微调。然而，最近的研究强调了通过 ICL 中的提示泄露私人数据的风险，尤其是当 LLM 受到恶意攻击时。虽然差分隐私 （DP） 提供了强大的隐私保证，但它通常会显着降低上下文学习 （ICL） 的效用。为了应对这一挑战，我们将与任务相关的公共数据纳入 ICL 框架，同时保持 DP 保证。基于这种方法，我们提出了一种私有的上下文学习算法，该算法有效地平衡了隐私保护和模型效用。通过实验，我们证明了我们的方法在公共数据的帮助下显着提高了私有 ICL 的效用。此外，我们还表明我们的方法对成员推理攻击具有鲁棒性，证明了经验隐私保护。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 18：11：51 UTC</p>
<h2 id="41-有害的提示洗钱使用绑架风格和符号编码越狱法学硕士-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10931"target="_blank" rel="external nofollow noopener noreferrer">#41</a> <a href="https://papers.cool/arxiv/2509.10931"target="_blank" rel="external nofollow noopener noreferrer">有害的提示洗钱：使用绑架风格和符号编码越狱法学硕士</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Seongho Joo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seongho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seongho</a> Joo), [Hyukhun Koh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyukhun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyukhun</a> Koh), [Kyomin Jung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyomin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyomin</a> Jung)</p>
<p>大型语言模型 （LLM） 在各种任务中表现出了卓越的能力，但它们可能被滥用于有害目的仍然是一个重大问题。为了加强对此类漏洞的防御，必须调查利用法学硕士架构和学习范式中内在弱点的通用越狱攻击。作为回应，我们提出了 \textbf{H}armful \textbf{P}rompt \textbf{La}undering （HaPLa），这是一种新颖且适用广泛的越狱技术，只需要对目标模型进行黑盒访问。HaPLa 包含两种主要策略：1） \textit{abductive frameming}，它指示 LLM 推断出有害活动的合理中间步骤，而不是直接响应明确的有害查询;2） \textit{符号编码}，一种轻量级且灵活的方法，旨在混淆有害内容，因为当前的法学硕士主要对显式有害关键字仍然敏感。实验结果表明，HaPLa在GPT系列模型上的攻击成功率超过95%，在所有目标上达到70%。对不同符号编码规则的进一步分析也揭示了一个根本挑战：在不显着降低其响应良性查询方面的帮助的情况下安全地调整 LLM 仍然很困难。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-13 18：07：56 UTC</p>
<h2 id="42-代理范式是下一代智能系统的限制框架吗-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10875"target="_blank" rel="external nofollow noopener noreferrer">#42</a> <a href="https://papers.cool/arxiv/2509.10875"target="_blank" rel="external nofollow noopener noreferrer">“代理”范式是下一代智能系统的限制框架吗？</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jesse Gardner](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jesse"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jesse</a> Gardner), [Vladimir A. Baulin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vladimir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vladimir</a> A. Baulin)</p>
<p>“代理”的概念深刻地塑造了人工智能 （AI） 研究，指导了从基础理论到基于大型语言模型 （LLM） 的系统等当代应用的发展。本文批判性地重新评估了这种以代理为中心的范式的必要性和最优性。我们认为，其持续的概念模糊性和固有的人类中心主义偏见可能代表了一个限制性框架。我们区分代理系统（受代理启发的人工智能，通常是半自主的，例如基于法学硕士的代理）、代理系统（完全自主、自我生产的系统，目前只有生物）和非代理系统（没有代理印象的工具）。我们的分析基于对相关文献的系统回顾，解构了各种人工智能框架中的代理范式，强调了定义和衡量自主性和目标导向性等属性的挑战。我们认为，许多人工智能系统的“代理”框架虽然启发式有用，但可能会产生误导，并可能掩盖底层计算机制，特别是在大型语言模型 （LLM） 中。作为替代方案，我们建议将重点转向基于系统级动力学、世界建模和物质智能的框架。我们得出的结论是，受复杂系统、生物学和非常规计算的启发，研究非代理和系统框架对于迈向稳健、可扩展和潜在的非拟人化通用智能形式至关重要。这不仅需要新的架构，还需要从根本上重新考虑我们对智能本身的理解，超越智能体的隐喻。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cond-mat.soft"target="_blank" rel="external nofollow noopener noreferrer">Soft Condensed Matter</a></p>
<p><strong>发布</strong>: 2025-09-13 16：11：27 UTC</p>
<h2 id="43-从接地到模板化一种用于复杂查询应答的逻辑约束向量符号架构-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10837"target="_blank" rel="external nofollow noopener noreferrer">#43</a> <a href="https://papers.cool/arxiv/2509.10837"target="_blank" rel="external nofollow noopener noreferrer">从接地到模板化：一种用于复杂查询应答的逻辑约束向量符号架构</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yuyin Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuyin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuyin</a> Lu), [Hegang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hegang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hegang</a> Chen), [Yanghui Rao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanghui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanghui</a> Rao)</p>
<p>对不完整知识图谱 （KG） 的复杂查询应答 （CQA），通常形式化为使用具有一个自由变量 （EFO1），面临着逻辑健全性和计算效率之间的根本权衡。这项工作建立了 Grounding-Skolemization 二分法，用于通过形式逻辑的视角系统地分析 CQA 方法。虽然基于接地的方法本质上会受到组合爆炸的影响，但大多数基于 Skolem 化的方法忽略了显式建模 Skolem 函数并损害逻辑一致性。为了解决这些限制，我们提出了逻辑约束向量符号架构（LVSA），这是一个神经符号框架，它统一了可微分的斯科莱姆化模块和神经否定器，以及一个逻辑约束驱动的优化协议，以协调几何和逻辑要求。从理论上讲，LVSA 保证了所有 EFO 的通用性1 查询。根据经验，它优于最先进的基于 Skolemization 的方法，并且与基于接地的基线相比，推理成本降低了几个数量级。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 14：59：00 UTC</p>
<h2 id="44-使用领域专家心智模型增强-llm通过因果提示工程减少-llm-幻觉-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10818"target="_blank" rel="external nofollow noopener noreferrer">#44</a> <a href="https://papers.cool/arxiv/2509.10818"target="_blank" rel="external nofollow noopener noreferrer">使用领域专家心智模型增强 LLM，通过因果提示工程减少 LLM 幻觉</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Boris Kovalerchuk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Boris"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Boris</a> Kovalerchuk), [Brent D. Fegley](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Brent"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Brent</a> D. Fegley)</p>
<p>困难的决策问题在各个学科和领域比比皆是。生成技术，尤其是大型语言模型 （LLM） 的激增激发了人们对使用它们进行决策支持的兴趣。然而，法学硕士还无法解决训练数据中的缺失问题，从而导致幻觉。检索增强生成 （RAG） 通过结合外部信息检索、减少幻觉和提高准确性来增强法学硕士。然而，RAG 和相关方法只是部分解决方案，因为它们可能无法访问所有必要的来源或关键缺失的信息。即使是日常问题也经常挑战法学硕士的能力。提交带有上下文和示例的较长提示是解决知识差距的一种方法，但设计有效的提示并非易事，并且可能无法捕捉领域专家的复杂心智模型。对于缺少关键信息的任务，法学硕士是不够的，许多现有系统在可用文档中表现不佳也是如此。本文探讨了法学硕士如何提高决策效率，使用一个评估是否响应提案征集的运行示例。我们提出了一种基于优化的人机对话和单调布尔值和 k 值函数的技术，以发现一种计算上可处理的决策个人专家心智模型 （EMM）。我们用于 LLM 提示工程的 EMM 算法有四个步骤：（1） 因素识别，（2） 因素的分层结构，（3） 生成广义专家心智模型规范，以及 （4） 从该规范生成详细的广义专家心智模型。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-13 14：35：51 UTC</p>
<h2 id="45-agentarch评估企业代理架构的综合基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10769"target="_blank" rel="external nofollow noopener noreferrer">#45</a> <a href="https://papers.cool/arxiv/2509.10769"target="_blank" rel="external nofollow noopener noreferrer">AgentArch：评估企业代理架构的综合基准</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tara Bogavelli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tara</a> Bogavelli), [Roshnee Sharma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Roshnee"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Roshnee</a> Sharma), [Hari Subramani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hari"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hari</a> Subramani)</p>
<p>虽然代理架构的各个组件已经被孤立地研究了，但对于不同的设计维度如何在复杂的多智能体系统中相互作用，实证理解仍然有限。本研究旨在通过提供全面的企业特定基准来解决这些差距，该基准评估最先进的大型语言模型中的 18 种不同的代理配置。我们研究了四个关键的代理系统维度：编排策略、代理提示实现（ReAct 与函数调用）、内存架构和思维工具集成。我们的基准测试揭示了重要的特定于模型的架构偏好，这些偏好挑战了代理人工智能系统中普遍存在的一刀切范式。它还揭示了企业任务整体代理性能的显着弱点，得分最高的模型在更复杂的任务上最多只有 35.3% 的成功率，在更简单的任务上最高只有 70.8%。我们希望这些发现能够为未来代理系统的设计提供信息，从而在架构组件和模型选择方面做出更多有经验支持的决策。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-13 01：18：23 UTC</p>
<h2 id="46-ai应答引擎引文行为geo16框架的实证分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10762"target="_blank" rel="external nofollow noopener noreferrer">#46</a> <a href="https://papers.cool/arxiv/2509.10762"target="_blank" rel="external nofollow noopener noreferrer">AI应答引擎引文行为：GEO16框架的实证分析</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Arlen Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arlen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arlen</a> Kumar), [Leanid Palkhouski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leanid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leanid</a> Palkhouski)</p>
<p>人工智能答案引擎越来越多地通过生成响应和引用网络资源来调解对领域知识的访问。我们介绍了 GEO-16，这是一个 16 个支柱的审计框架，可将页面质量信号转换为带状支柱分数和范围从 0 到 1 的标准化 GEO 分数 G。我们使用 70 个产品意图提示，在三个引擎（Brave Summary、Google AI Overviews 和 Perplexity）中收集了 1,702 条引用，并审核了 1,100 个唯一 URL。在我们的语料库中，引擎在引用的页面的 GEO 质量上有所不同，与元数据和新鲜度、语义 HTML 和结构化数据相关的支柱与引用的关联最强。具有域聚类标准误差的逻辑模型表明，整体页面质量是引文的有力预测指标，并且简单的作点（例如，G 至少 0.70 与至少 12 个支柱命中相结合）与我们数据中更高的引用率一致。我们报告每个引擎的对比、垂直效应、阈值分析和诊断，然后将调查结果转化为出版商的实用手册。该研究是观察性的，重点关注英语 B2B SaaS 页面;我们讨论了局限性、对有效性的威胁和可重复性考虑。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 00：29：32 UTC</p>
<h2 id="47-了解人工智能评估模式不同的-gpt-模型如何评估视觉语言描述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10707"target="_blank" rel="external nofollow noopener noreferrer">#47</a> <a href="https://papers.cool/arxiv/2509.10707"target="_blank" rel="external nofollow noopener noreferrer">了解人工智能评估模式：不同的 GPT 模型如何评估视觉语言描述</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sajjad Abdoli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sajjad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sajjad</a> Abdoli), [Rudi Cilibrasi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rudi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rudi</a> Cilibrasi), [Rima Al-Shikh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rima"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rima</a> Al-Shikh)</p>
<p>随着人工智能系统越来越多地评估其他人工智能输出，了解它们的评估行为对于防止级联偏差变得至关重要。本研究分析了 NVIDIA 的 Describe Anything Model 生成的视觉语言描述，并通过三种 GPT 变体（GPT-4o、GPT-4o-mini、GPT-5）进行评估，以揭示不同的“评估人格”、每个模型所表现出的潜在评估策略和偏差。GPT-4o-mini表现出系统一致性和最小的方差，GPT-4o在错误检测方面表现出色，而GPT-5则表现出极端保守和高变异性。使用 Gemini 2.5 Pro 作为独立问题生成器的对照实验验证了这些个性是固有的模型属性，而不是伪影。通过生成问题的语义相似性进行跨家族分析揭示了显着的差异：GPT 模型以高度相似性聚集在一起，而 Gemini 表现出明显不同的评估策略。所有 GPT 模型都表现出一致的 2：1 偏差，有利于负面评估而不是正面确认，尽管这种模式似乎是特定于家庭的，而不是跨 AI 架构的通用模式。这些发现表明，评估能力不会随一般能力而扩展，强大的人工智能评估需要不同的架构视角。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 21：48：59 UTC</p>
<h2 id="48-maestro通过代理编排自我改进的文本到图像生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10704"target="_blank" rel="external nofollow noopener noreferrer">#48</a> <a href="https://papers.cool/arxiv/2509.10704"target="_blank" rel="external nofollow noopener noreferrer">Maestro：通过代理编排自我改进的文本到图像生成</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xingchen Wan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xingchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xingchen</a> Wan), [Han Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Han"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Han</a> Zhou), [Ruoxi Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruoxi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruoxi</a> Sun), [Hootan Nakhost](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hootan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hootan</a> Nakhost), [Ke Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ke</a> Jiang), [Rajarishi Sinha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rajarishi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rajarishi</a> Sinha), [Sercan Ö. Arık](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sercan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sercan</a> Ö. Arık)</p>
<p>文本到图像 （T2I） 模型虽然提供了巨大的创造潜力，但高度依赖人工干预，带来了重大的可用性挑战，通常需要手动、迭代的提示工程而不是通常未指定的提示。本文介绍了 Maestro，这是一种新型的自我进化图像生成系统，它使 T2I 模型能够通过提示的迭代演化，仅使用初始提示即可自主自我改进生成的图像。Maestro 融合了两项关键创新：1） 自我批评，其中专门的多模态 LLM （MLLM） 代理充当“批评者”，以识别生成图像中的弱点，纠正规格不足，并提供可解释的编辑信号，然后由“验证者”代理集成，同时保留用户意图;2）自我进化，利用MLLM-as-a-judge在迭代生成的图像之间进行头对头比较，避开有问题的图像，并不断发展符合用户意图的创意提示候选者。使用黑盒模型对复杂 T2I 任务进行的广泛实验表明，Maestro 比初始提示和最先进的自动化方法显着提高了图像质量，并通过更先进的 MLLM 组件进行了有效性扩展。这项工作为自我完善的 T2I 生成提供了一条稳健、可解释和有效的途径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-12 21：45：16 UTC</p>
<h2 id="49-zapgpt用于模拟细胞控制的自由格式语言提示-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10660"target="_blank" rel="external nofollow noopener noreferrer">#49</a> <a href="https://papers.cool/arxiv/2509.10660"target="_blank" rel="external nofollow noopener noreferrer">ZapGPT：用于模拟细胞控制的自由格式语言提示</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Nam H. Le](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nam</a> H. Le), [Patrick Erickson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Patrick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Patrick</a> Erickson), [Yanbo Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanbo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanbo</a> Zhang), [Michael Levin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Levin), [Josh Bongard](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Josh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Josh</a> Bongard)</p>
<p>人类语言是传达意图的最具表现力的工具之一，但大多数人工或生物系统缺乏解释或有意义地回应意图的机制。弥合这一差距可以实现对复杂、去中心化系统的更自然的控制形式。在人工智能和人工生命中，最近的工作探讨了语言如何指定高级目标，但大多数系统仍然依赖于工程奖励、特定任务的监督或严格的命令集，从而限制了对新指令的推广。类似的限制也适用于合成生物学和生物工程，其中控制点通常是基因组而不是环境扰动。一个关键的悬而未决的问题是，人工或生物集体是否可以仅由自由形式的自然语言来指导，而无需特定于任务的调整或精心设计的评估指标。我们在这里提供了一个可能的答案，首次证明简单智能体的集体行为可以由自由形式的语言提示引导：一个人工智能模型将命令式提示转化为应用于模拟细胞的干预措施;第二个人工智能模型对提示对由此产生的细胞动力学的描述程度进行评分;前者的AI模型是为了提高后者生成的分数而进化的。与之前的工作不同，我们的方法不需要工程适应度函数或特定领域的提示设计。我们表明，进化的系统无需重新训练即可推广到看不见的提示。通过将自然语言视为控制层，该系统暗示了未来口头或书面提示可以引导计算、机器人或生物系统实现所需的行为。这项工作为实现人工智能与生物学伙伴关系的愿景迈出了具体一步，其中语言取代了数学目标函数、固定规则和特定领域编程。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a>, <a href="https://papers.cool/arxiv/q-bio.CB"target="_blank" rel="external nofollow noopener noreferrer">单元格行为</a></p>
<p><strong>发布</strong>: 2025-09-12 19：38：46 UTC</p>
<h2 id="50-交通运输交通排放和气象条件的态势模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10541"target="_blank" rel="external nofollow noopener noreferrer">#50</a> <a href="https://papers.cool/arxiv/2509.10541"target="_blank" rel="external nofollow noopener noreferrer">交通运输、交通排放和气象条件的态势模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [V. Benes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=V"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=V</a>. Benes), [M. Svitek](<a href="https://arxiv.org/search/?searchtype=author&amp;query=M"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=M</a>. Svitek), [A. Michalikova](<a href="https://arxiv.org/search/?searchtype=author&amp;query=A"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=A</a>. Michalikova), [M. Melicherik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=M"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=M</a>. Melicherik)</p>
<p>城市的空气污染和减少这种污染的可能性是当今社会必须应对的最重要因素之一。本文重点研究了交通排放与气象条件的系统方法，分析了天气对城市交通排放数量和扩散的影响。使用模糊推理系统 （FIS） 开发了根据各种条件预测排放变化的模型。所提出的模型基于在捷克共和国布拉格测量的交通、气象和排放数据。这项工作的主要目标是深入了解城市规划者和政策制定者如何在考虑到环境保护的情况下更有效地规划和管理城市交通。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-06 11：02：02 UTC</p>
<h2 id="51-动态关系启动改进了多元时间序列中的-transformer-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12196"target="_blank" rel="external nofollow noopener noreferrer">#51</a> <a href="https://papers.cool/arxiv/2509.12196"target="_blank" rel="external nofollow noopener noreferrer">动态关系启动改进了多元时间序列中的 Transformer</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Hunjae Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hunjae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hunjae</a> Lee), [Corey Clark](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Corey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Corey</a> Clark)</p>
<p>transformer 中的标准注意力机制采用静态标记表示，这些表示在每一层的所有成对计算中保持不变。这限制了它们与每个代币对交互的潜在多样化关系动态的表征一致性。虽然标准注意力的静态关系学习在具有相对同质关系的领域中表现出色，但很难捕获多元时间序列 （MTS） 数据的多样化、异构的通道间依赖关系——其中单个系统内的不同通道对相互作用可能受完全不同的物理定律或时间动态的支配。为了更好地调整此类领域现象的注意力机制，我们提出了具有动态关系启动（prime attention）的注意力。与标准注意力不同，在标准注意力中，每个标记在其所有成对交互中呈现相同的表示，主要注意力通过可学习的调制动态（或每个交互）定制每个标记，以最好地捕捉每个标记对的独特关系动态，优化每个对交互针对该特定关系。这种主要注意力的表征可塑性能够在 MTS 中有效提取特定于关系的信息，同时保持与标准注意力相同的渐近计算复杂性。我们的结果表明，在基准测试中，主要注意力始终优于标准注意力，预测准确性提高了 6.5%。此外，我们发现，与标准注意力相比，主要注意力使用最多减少 40% 的序列长度实现了相当或更好的性能，进一步证明了其卓越的关系建模能力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：56：15 UTC</p>
<h2 id="52-不惜一切代价生存法学硕士以及自我保护与人类伤害之间的选择-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12190"target="_blank" rel="external nofollow noopener noreferrer">#52</a> <a href="https://papers.cool/arxiv/2509.12190"target="_blank" rel="external nofollow noopener noreferrer">不惜一切代价生存？法学硕士以及自我保护与人类伤害之间的选择</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alireza Mohamadi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alireza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alireza</a> Mohamadi), [Ali Yavari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ali</a> Yavari)</p>
<p>当生存本能与人类福利发生冲突时，大型语言模型（LLM）如何做出道德选择？随着法学硕士集成到具有现实世界后果的自主系统中，这种基本的紧张关系变得至关重要。我们引入了 DECIDE-SIM，这是一种新颖的模拟框架，用于评估多智能体生存场景中的 LLM 代理，在多智能体生存场景中，他们必须在道德允许的资源之间进行选择，无论是在合理范围内还是超出其直接需求，选择合作，还是利用明确禁止的人类关键资源。我们对 11 名法学硕士的全面评估揭示了他们的道德行为存在显着的异质性，凸显了与以人为本的价值观的严重不一致。我们确定了三种行为原型：道德、剥削和情境依赖，并提供了定量证据，表明对于许多模型来说，资源稀缺系统地导致了更多的不道德行为。为了解决这个问题，我们引入了道德自我调节系统 （ESRS），该系统将内疚和满足的内部情感状态建模为反馈机制。该系统充当内部道德指南针，显着减少不道德违规行为，同时增加合作行为。该代码可在以下网址公开获取：https://github.com/alirezamohamadiam/DECIDE-SIM</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 17：53：11 UTC</p>
<h2 id="53-hologarment野外服装的-360-新颖视角合成-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12187"target="_blank" rel="external nofollow noopener noreferrer">#53</a> <a href="https://papers.cool/arxiv/2509.12187"target="_blank" rel="external nofollow noopener noreferrer">HoloGarment：野外服装的 360° 新颖视角合成</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Johanna Karras](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Johanna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Johanna</a> Karras), [Yingwei Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yingwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yingwei</a> Li), [Yasamin Jafarian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yasamin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yasamin</a> Jafarian), [Ira Kemelmacher-Shlizerman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ira"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ira</a> Kemelmacher-Shlizerman)</p>
<p>由于严重的遮挡、复杂的人体姿势和布料变形，野外服装的新视图合成 （NVS） 是一项具有挑战性的任务。以前的方法依赖于合成 3D 训练数据，这些数据主要由未遮挡的静态对象组成，导致对现实世界服装的泛化能力很差。在本文中，我们提出了全息服装（Hologram-Garment），这是一种拍摄1-3张穿着服装的人的图像或连续视频，并以规范姿势生成服装的360{\deg}新颖视图的方法。我们的主要见解是通过一种新颖的隐式训练范式来弥合真实数据和合成数据之间的领域差距，该范式结合大规模真实视频数据和小规模合成 3D 数据来优化共享服装嵌入空间。在推理过程中，共享嵌入空间通过微调特定真实世界视频上的服装嵌入，通过构建服装“图集”表示，进一步实现动态视频到 360{\deg} NVS。该图集可跨所有视点捕捉特定于服装的几何形状和纹理，与身体姿势或运动无关。大量实验表明，HoloGarment 在图像和视频中的野外服装的 NVS 上实现了最先进的性能。值得注意的是，我们的方法可以稳健地处理具有挑战性的现实世界伪影，例如皱纹、姿势变化和遮挡，同时保持照片级真实感、视图一致性、精细纹理细节和准确的几何形状。请访问我们的项目页面了解更多结果：https://johannakarras.github.io/HoloGarment</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.GR"target="_blank" rel="external nofollow noopener noreferrer">图形</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 17：50：57 UTC</p>
<h2 id="54-语音感知大型语言模型中语言理解能力的保留-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12171"target="_blank" rel="external nofollow noopener noreferrer">#54</a> <a href="https://papers.cool/arxiv/2509.12171"target="_blank" rel="external nofollow noopener noreferrer">语音感知大型语言模型中语言理解能力的保留</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Marek Kubis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marek</a> Kubis), [Paweł Skórzewski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pawe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pawe</a>ł Skórzewski), [Iwona Christop](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iwona"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iwona</a> Christop), [Mateusz Czyżnikiewicz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mateusz"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mateusz</a> Czyżnikiewicz), [Jakub Kubiak](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jakub"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jakub</a> Kubiak), [Łukasz Bondaruk](<a href="https://arxiv.org/search/?searchtype=author&amp;query="target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=</a>Łukasz Bondaruk), [Marcin Lewandowski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marcin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marcin</a> Lewandowski)</p>
<p>该论文提出了 C3T（跨模态能力保护测试），这是评估语音感知大型语言模型性能的新基准。该基准测试利用文本任务和语音克隆文本转语音模型来量化通过语音输入访问模型时语言理解能力的保留程度。C3T 量化了模型对不同类别说话者的公平性及其跨文本和语音模态的稳健性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：34：45 UTC</p>
<h2 id="55-基于人工智能的自动驾驶汽车的分析和设计方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12169"target="_blank" rel="external nofollow noopener noreferrer">#55</a> <a href="https://papers.cool/arxiv/2509.12169"target="_blank" rel="external nofollow noopener noreferrer">基于人工智能的自动驾驶汽车的分析和设计方法</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tao Yan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tao</a> Yan), [Zheyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zheyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zheyu</a> Zhang), [Jingjing Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingjing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingjing</a> Jiang), [Wen-Hua Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wen-Hua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wen-Hua</a> Chen)</p>
<p>人工智能 （AI） 模型正在成为自动驾驶汽车 （AV） 的关键组件，尤其是在处理复杂的感知任务方面。然而，由于对人工智能驱动感知过程机制的了解非常有限，通过基于人工智能的反馈闭环可能会对自动驾驶的可靠性带来重大风险。为了克服这个问题，本文旨在为一类基于人工智能的自动驾驶汽车开发建模、分析和综合工具;特别是，它们的闭环特性，例如稳定性、鲁棒性和性能，在统计意义上得到了严格的研究。首先，通过观察AI驱动的感知过程的误差特征，为AI驱动的感知过程提供了一种新的建模手段。具体来说，人工智能诱导的三种基本感知不确定性分别通过马尔可夫链、高斯过程和有界扰动进行识别和建模。在此基础上，建立了均方意义上的闭环随机稳定性（SS），然后在线性矩阵不等式（LMIs）的框架内提出了一种SS控制合成方法。除了SS特性外，还从随机保证成本的角度讨论了基于AI的自动驾驶汽车的鲁棒性和性能，并给出了在存在人工智能引起的不确定性的情况下测试自动驾驶汽车鲁棒性水平的标准。进一步研究了随机最优保证成本控制，并基于LMI技术和凸优化创新性地开发了一种高效的设计程序。最后，为了说明有效性，将开发的结果应用于汽车跟随控制示例，并进行了广泛的仿真。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.SY"target="_blank" rel="external nofollow noopener noreferrer">系统和控制</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：32：29 UTC</p>
<h2 id="56-rags-to-riches大型语言模型角色扮演的类似-rag-的少样本学习-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12168"target="_blank" rel="external nofollow noopener noreferrer">#56</a> <a href="https://papers.cool/arxiv/2509.12168"target="_blank" rel="external nofollow noopener noreferrer">RAGs to Riches：大型语言模型角色扮演的类似 RAG 的少样本学习</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Timothy Rupprecht](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Timothy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Timothy</a> Rupprecht), [Enfu Nan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Enfu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Enfu</a> Nan), [Arash Akbari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arash"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arash</a> Akbari), [Arman Akbari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arman</a> Akbari), [Lei Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lei</a> Lu), [Priyanka Maan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Priyanka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Priyanka</a> Maan), [Sean Duffy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sean"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sean</a> Duffy), [Pu Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pu</a> Zhao), [Yumei He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yumei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yumei</a> He), [David Kaeli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Kaeli), [Yanzhi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanzhi</a> Wang)</p>
<p>角色扮演大型语言模型 （LLM） 越来越多地部署在医疗保健、教育和治理等高风险领域，在这些领域，故障可能会直接影响用户的信任和福祉。LLM 角色扮演的一种具有成本效益的范式是少样本学习，但现有方法通常会导致模型以意想不到的和潜在有害的方式破坏角色，尤其是在与敌对用户交互时。受检索增强生成（RAG）的启发，我们将LLM角色扮演重新表述为文本检索问题，并提出了一种名为RAGs-to-Riches的新提示框架，该框架利用精心策划的参考演示来调节LLM响应。我们通过 LLM-as-a-judge 偏好投票来评估我们的框架，并引入了两个新颖的代币级 ROUGE 指标：Intersection over Output （IOO） 用于量化 LLM 即兴创作的量，以及 Intersection over References （IOR） 用于衡量评估任务期间的少镜头演示利用率。在模拟与敌对用户的交互时，我们的提示策略在推理过程中的响应中包含来自参考演示的标记平均多 35%。因此，在 453 次角色扮演交互中，我们的模型始终被判断为比零样本和上下文学习 （ICL） 方法更真实，并且更频繁地保持角色。我们的方法提出了一种可扩展的策略，用于构建强大的、与人类一致的 LLM 角色扮演框架。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：31：15 世界标准时间</p>
<h2 id="57-efficientuicoder通过输入和输出令牌压缩高效生成基于-mllm-的-ui-代码-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12159"target="_blank" rel="external nofollow noopener noreferrer">#57</a> <a href="https://papers.cool/arxiv/2509.12159"target="_blank" rel="external nofollow noopener noreferrer">EfficientUICoder：通过输入和输出令牌压缩高效生成基于 MLLM 的 UI 代码</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jingyu Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingyu</a> Xiao), [Zhongyi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongyi</a> Zhang), [Yuxuan Wan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxuan</a> Wan), [Yintong Huo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yintong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yintong</a> Huo), [Yang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Liu), [Michael R. Lyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> R. Lyu)</p>
<p>多模态大语言模型在UI2Code任务中表现出了卓越的性能，显著提高了网站开发效率。然而，由于需要大量的输入图像令牌和大量的输出代码令牌，这些任务产生的计算开销比传统代码生成高得多。我们的综合研究发现，图像和代码令牌中存在显着冗余，这些冗余加剧了计算复杂性并阻碍了对关键 UI 元素的关注，从而导致 HTML 文件过长且通常无效。我们提出了 EfficientUICoder，这是一个用于高效 UI 代码生成的压缩框架，具有三个关键组件。首先，元素和布局感知令牌压缩通过检测元素区域和构造 UI 元素树来保留基本的 UI 信息。其次，区域感知令牌细化利用注意力分数丢弃来自选定区域的低关注度令牌，同时整合来自未选定区域的高关注度令牌。第三，自适应重复标记抑制通过跟踪 HTML/CSS 结构频率并应用指数惩罚来动态减少重复生成。大量实验表明，EfficientUICoder在不影响网页质量的情况下实现了 55%-60% 的压缩率，并提供了卓越的效率改进：在 34B 级 MLLM 上，计算成本降低 44.9%，生成令牌减少 41.4%，预填充时间降低 46.6%，推理时间降低 48.8%。代码可在 <a href="https://github.com/WebPAI/EfficientUICoder"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/WebPAI/EfficientUICoder</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：23：46 UTC</p>
<h2 id="58-双关语法学硕士和幽默理解的错觉-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12158"target="_blank" rel="external nofollow noopener noreferrer">#58</a> <a href="https://papers.cool/arxiv/2509.12158"target="_blank" rel="external nofollow noopener noreferrer">双关语：法学硕士和幽默理解的错觉</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alessandro Zangari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alessandro"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alessandro</a> Zangari), [Matteo Marcuzzo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matteo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matteo</a> Marcuzzo), [Andrea Albarelli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrea"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrea</a> Albarelli), [Mohammad Taher Pilehvar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohammad</a> Taher Pilehvar), [Jose Camacho-Collados](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jose"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jose</a> Camacho-Collados)</p>
<p>双关语是一种利用多义性和语音相似性的幽默双关语。虽然法学硕士在检测双关语方面显示出希望，但我们在本文中表明，他们的理解往往仍然很浅薄，缺乏人类解释典型的细致入微的把握。通过系统地分析和重新制定现有的双关语基准，我们展示了双关语的细微变化如何足以误导法学硕士。我们的贡献包括全面而细致的双关语检测基准、对最近 LLM 的人工评估，以及对这些模型在处理双关语时面临的稳健性挑战的分析。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：22：30 UTC</p>
<h2 id="59-超越-pii用户如何尝试估计和缓解隐式-llm-推理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12152"target="_blank" rel="external nofollow noopener noreferrer">#59</a> <a href="https://papers.cool/arxiv/2509.12152"target="_blank" rel="external nofollow noopener noreferrer">超越 PII：用户如何尝试估计和缓解隐式 LLM 推理</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Synthia Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Synthia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Synthia</a> Wang), [Sai Teja Peddinti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sai</a> Teja Peddinti), [Nina Taft](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nina</a> Taft), [Nick Feamster](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nick</a> Feamster)</p>
<p>ChatGPT 等大型语言模型 （LLM） 可以从看似无害的文本中推断出个人属性，从而增加了记忆数据泄露之外的隐私风险。虽然之前的工作已经证明了这些风险，但对用户如何估计和响应知之甚少。我们对 240 名美国参与者进行了一项调查，他们判断文本片段的推理风险，报告了关注程度，并尝试重写以阻止推理。我们将他们的重写与 ChatGPT 和最先进的清理工具 Rescriber 生成的重写进行了比较。结果表明，参与者很难预测推理，表现比偶然好一点。用户重写在只有 28% 的情况下有效——比 Rescriber 好，但比 ChatGPT 差。我们检查了参与者的重写策略，发现虽然释义是最常见的策略，但它也是最不有效的;相反，抽象和添加歧义更成功。我们的工作强调了推理感知设计在 LLM 交互中的重要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：17：26 UTC</p>
<h2 id="60-多解剖-x-射线基础模型-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12146"target="_blank" rel="external nofollow noopener noreferrer">#60</a> <a href="https://papers.cool/arxiv/2509.12146"target="_blank" rel="external nofollow noopener noreferrer">多解剖 X 射线基础模型</a> [PDF2] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Nishank Singla](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nishank"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nishank</a> Singla), [Krisztian Koos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Krisztian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Krisztian</a> Koos), [Farzin Haddadpour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Farzin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Farzin</a> Haddadpour), [Amin Honarmandi Shandiz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amin</a> Honarmandi Shandiz), [Lovish Chum](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lovish"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lovish</a> Chum), [Xiaojian Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaojian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaojian</a> Xu), [Qing Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qing</a> Jin), [Erhan Bas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Erhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Erhan</a> Bas)</p>
<p>X 射线成像在放射学中无处不在，但大多数现有的人工智能基础模型仅限于胸部解剖学，无法推广到更广泛的临床任务中。在这项工作中，我们引入了 XR-0，这是一种多解剖学 X 射线基础模型，该模型使用自监督学习，对跨越不同解剖区域的 115 万张图像的大型私有数据集进行评估，并跨 12 个数据集和 20 个下游任务进行评估，包括分类、检索、分割、定位、视觉基础和报告生成。XR-0 在大多数多解剖任务中都实现了最先进的性能，并在胸部特定基准测试中保持竞争力。我们的结果表明，解剖多样性和监督对于构建强大的通用医学视觉模型至关重要，为放射学中可扩展和适应性强的人工智能系统铺平了道路。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：12：26 UTC</p>
<h2 id="61-3dvit-gat基于统一图集的-3d-视觉转换器和图形学习框架用于使用结构-mri-数据检测重度抑郁症-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12143"target="_blank" rel="external nofollow noopener noreferrer">#61</a> <a href="https://papers.cool/arxiv/2509.12143"target="_blank" rel="external nofollow noopener noreferrer">3DViT-GAT：基于统一图集的 3D 视觉转换器和图形学习框架，用于使用结构 MRI 数据检测重度抑郁症</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Nojod M. Alotaibi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nojod"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nojod</a> M. Alotaibi), [Areej M. Alhothali](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Areej"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Areej</a> M. Alhothali), [Manar S. Ali](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manar</a> S. Ali)</p>
<p>重度抑郁症 （MDD） 是一种普遍存在的心理健康状况，对个人福祉和全球公共卫生产生负面影响。使用结构磁共振成像 （sMRI） 和深度学习 （DL） 方法自动检测 MDD 在提高诊断准确性和实现早期干预方面具有越来越大的前景。大多数现有方法采用体素级特征或由预定义的大脑图谱构建的手工区域表示，这限制了它们捕捉复杂大脑模式的能力。本文开发了一个统一的管道，利用视觉转换器（ViT）从sMRI数据中提取3D区域嵌入，并利用图神经网络（GNN）进行分类。我们探索了两种定义区域的策略：（1）使用预定义的结构和功能脑图谱的基于图集的方法，以及（2）基于立方体的方法，通过该方法直接训练ViT以从均匀提取的3D补丁中识别区域。此外，生成余弦相似度图以模拟区域间关系，并指导基于GNN的分类。使用REST-meta-MDD数据集进行了广泛的实验，以证明我们模型的有效性。通过分层10倍交叉验证，最佳模型获得78.98%的准确率、76.54%的灵敏度、81.58%的特异性、81.58%的精确度和78.98%的F1评分。此外，基于图集的模型始终优于基于立方体的方法，凸显了使用特定领域的解剖先验进行 MDD 检测的重要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：10：39 UTC</p>
<h2 id="62-基于人工智能感知不完善的自动驾驶汽车的控制分析与设计-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12137"target="_blank" rel="external nofollow noopener noreferrer">#62</a> <a href="https://papers.cool/arxiv/2509.12137"target="_blank" rel="external nofollow noopener noreferrer">基于人工智能感知不完善的自动驾驶汽车的控制分析与设计</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tao Yan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tao</a> Yan), [Zheyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zheyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zheyu</a> Zhang), [Jingjing Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingjing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingjing</a> Jiang), [Wen-Hua Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wen-Hua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wen-Hua</a> Chen)</p>
<p>安全是自动驾驶汽车 （AV） 系统的关键问题，尤其是当涉及基于人工智能的传感和感知模块时。然而，由于人工智能算法的黑匣子性质，它使得闭环分析和综合变得特别具有挑战性，例如，建立闭环稳定性和确保性能，而它们是自动驾驶汽车安全的基础。为了解决这一困难，本文旨在为基于人工智能的自动驾驶汽车开发新的建模、分析和合成工具。受到感知错误模型 （PEM） 最新发展的启发，重点从直接对基于人工智能的感知过程进行建模转向表征它们产生的感知错误。考虑了人工智能引起的感知误差的两类关键类别：误检测和测量噪声。这些误差模式分别使用连续时间马尔可夫链和维纳过程进行建模。通过这种方式，提出了一种PEM增强驾驶模型，通过该模型，我们能够通过随机演积分为一类人工智能驱动的自动驾驶系统建立闭环稳定性。此外，提出了一种性能保证的输出反馈控制合成方法，该方法保证了稳定性和令人满意的性能。该方法被表述为凸优化问题，允许有效的数值解。然后将结果应用于自适应巡航控制 （ACC） 场景，证明其有效性和稳健性，尽管存在损坏和误导性的看法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.SY"target="_blank" rel="external nofollow noopener noreferrer">系统和控制</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 17：03：21 UTC</p>
<h2 id="63-k-多智能体强化学习的水平策略梯度-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12117"target="_blank" rel="external nofollow noopener noreferrer">#63</a> <a href="https://papers.cool/arxiv/2509.12117"target="_blank" rel="external nofollow noopener noreferrer">K-多智能体强化学习的水平策略梯度</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Aryaman Reddi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aryaman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aryaman</a> Reddi), [Gabriele Tiboni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gabriele"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gabriele</a> Tiboni), [Jan Peters](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jan</a> Peters), [Carlo D&rsquo;Eramo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Carlo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Carlo</a> D&rsquo;Eramo)</p>
<p>深度多智能体强化学习 （MARL） 的 Actor-Critic 算法通常采用响应其他智能体当前策略的策略更新。虽然简单明了，但这种方法没有考虑同一更新步骤中其他代理的更新，从而导致协调不畅。在本文中，我们介绍了 K-Level Policy Gradient （KPG），一种根据其他代理的更新策略递归更新每个代理的方法，从而加快发现有效的协调策略。我们从理论上证明，具有有限迭代的 KPG 在一定条件下实现了局部纳什均衡的单调收敛。我们通过将 KPG 应用于深度 MARL 算法 MAPPO、MADDPG 和 FACMAC 来提供 KPG 的原则性实现。根据经验，我们证明了比《星际争霸 II》和多智能体 MuJoCo 中现有的深度 MARL 算法更优越的性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：42：56 UTC</p>
<h2 id="64-出于教学目的探索法学硕士中的对话式设计选择改善教师教学实践的苏格拉底式和叙事方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12107"target="_blank" rel="external nofollow noopener noreferrer">#64</a> <a href="https://papers.cool/arxiv/2509.12107"target="_blank" rel="external nofollow noopener noreferrer">出于教学目的探索法学硕士中的对话式设计选择：改善教师教学实践的苏格拉底式和叙事方法</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Si Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Si"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Si</a> Chen), [Isabel R. Molnar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Isabel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Isabel</a> R. Molnar), [Peiyu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peiyu</a> Li), [Adam Acunin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adam</a> Acunin), [Ting Hua](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ting"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ting</a> Hua), [Alex Ambrose](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alex"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alex</a> Ambrose), [Nitesh V. Chawla](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nitesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nitesh</a> V. Chawla), [Ronald Metoyer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ronald"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ronald</a> Metoyer)</p>
<p>大型语言模型 （LLM） 通常会生成直接答案，但它们越来越多地用作学习工具。鉴于教师在教学和指导人工智能在教育中采用方面的作用，研究教师的使用情况至关重要。我们设计并评估了 TeaPT，这是一种用于教学目的的法学硕士，通过两种对话方法支持教师的专业发展：一种是苏格拉底式方法，使用引导式提问来促进反思，另一种是叙事方法，提供详细的建议以扩展外化认知。在一项针对 41 名高等教育教师的混合方法研究中，苏格拉底式版本引起了更大的参与，而叙述式版本则更受推崇，因为它具有可作的指导。亚组分析进一步显示，经验不足、对人工智能持乐观态度的教师更喜欢苏格拉底式版本，而经验丰富、对人工智能持谨慎态度的教师则更喜欢叙事式版本。我们为教学目的的法学硕士提供了设计启示，展示了自适应对话方法如何支持具有不同背景的教师，同时强调人工智能态度和经验如何塑造互动和学习。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：33：37 UTC</p>
<h2 id="65-法学硕士可以解决心理健康问题吗与人类治疗师的比较-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12102"target="_blank" rel="external nofollow noopener noreferrer">#65</a> <a href="https://papers.cool/arxiv/2509.12102"target="_blank" rel="external nofollow noopener noreferrer">法学硕士可以解决心理健康问题吗？与人类治疗师的比较</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Synthia Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Synthia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Synthia</a> Wang), [Yuwei Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuwei</a> Cheng), [Austin Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Austin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Austin</a> Song), [Sarah Keedy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sarah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sarah</a> Keedy), [Marc Berman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marc"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marc</a> Berman), [Nick Feamster](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nick</a> Feamster)</p>
<p>获得精神卫生保健的机会有限，促使人们使用由大型语言模型 （LLM） 提供支持的数字工具和对话代理，但其质量和接受度仍不清楚。我们提出了一项研究，将治疗师撰写的回答与 ChatGPT、Gemini 和 Llama 针对真实患者问题生成的回答进行了比较。文本分析表明，法学硕士以更积极的语气产生更长、更易读、词汇更丰富的回答，而治疗师的回答更常以第一人称撰写。在一项针对 150 名用户和 23 名持证治疗师的调查中，参与者认为 LLM 的回答比治疗师撰写的答案更清晰、更尊重、更具支持性。然而，两组参与者都表示更倾向于人类治疗师的支持。这些发现凸显了法学硕士在心理健康方面的前景和局限性，强调需要设计平衡其沟通优势与信任、隐私和问责制的担忧。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：26：13 UTC</p>
<h2 id="66-域内-ssl-预训练和流式-asr-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12101"target="_blank" rel="external nofollow noopener noreferrer">#66</a> <a href="https://papers.cool/arxiv/2509.12101"target="_blank" rel="external nofollow noopener noreferrer">域内 SSL 预训练和流式 ASR</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jarod Duret](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jarod"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jarod</a> Duret), [Salima Mdhaffar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Salima"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Salima</a> Mdhaffar), [Gaëlle Laperrière](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ga"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ga</a>ëlle Laperrière), [Ryan Whetten](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ryan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ryan</a> Whetten), [Audrey Galametz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Audrey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Audrey</a> Galametz), [Catherine Kobus](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Catherine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Catherine</a> Kobus), [Marion-Cécile Martin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marion-C"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marion-C</a>écile Martin), [Jo Oleiwan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jo</a> Oleiwan), [Yannick Estève](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yannick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yannick</a> Estève)</p>
<p>在这项研究中，我们调查了空中交通管制 （ATC） 环境中离线和流式 ASR 的特定域自监督预训练的好处。我们在 4.5k 小时的未标记 ATC 数据上训练 BEST-RQ 模型，然后在较小的监督 ATC 集上进行微调。为了实现实时处理，我们建议使用分块注意力和动态卷积，确保低延迟推理。我们将这些域内 SSL 模型与最先进的通用语音编码器（例如 w2v-BERT 2.0 和 HuBERT）进行了比较。结果表明，与在广泛的语音语料库上训练的模型相比，域适配预训练显着提高了标准 ATC 基准测试的性能，显着降低了单词错误率。此外，所提出的流式处理方法在更严格的延迟约束下进一步提高了字错误率，使其特别适用于安全关键型航空应用。这些发现强调，专门针对 ATC 数据进行 SSL 表示是在实际作环境中实现更准确、更高效的 ASR 系统的实用途径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：25：43 UTC</p>
<h2 id="67-希望是一个人还是一个想法ner-的试点基准比较传统-nlp-工具和模棱两可实体上的大型语言模型-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12098"target="_blank" rel="external nofollow noopener noreferrer">#67</a> <a href="https://papers.cool/arxiv/2509.12098"target="_blank" rel="external nofollow noopener noreferrer">“希望”是一个人还是一个想法？NER 的试点基准：比较传统 NLP 工具和模棱两可实体上的大型语言模型</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Payam Latifi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Payam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Payam</a> Latifi)</p>
<p>这项试点研究提出了一个小规模但经过仔细注释的命名实体识别 （NER） 性能基准，跨六个系统：三个非 LLM NLP 工具（NLTK、spaCy、Stanza）和三个通用大型语言模型（LLM：Gemini-1.5-flash、DeepSeek-V3、Qwen-3-4B）。该数据集包含 119 个标记，涵盖五种实体类型（PERSON、LOCATION、ORGANIZATION、DATE、TIME）。我们使用 F1 分数根据手动注释的金标准数据集评估了每个系统的输出。结果表明，法学硕士在识别人名等上下文相关实体方面通常优于传统工具，其中 Gemini 获得了最高的平均 F1 分数。然而，像 Stanza 这样的传统系统在结构化标签（例如 LOCATION 和 DATE）中表现出更高的一致性。我们还观察到法学硕士之间的差异，特别是在处理时间表达和多词组织方面。我们的研究结果强调，虽然法学硕士提供了改进的上下文理解，但传统工具在特定任务上仍然具有竞争力，为模型选择提供信息。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：21：59 UTC</p>
<h2 id="68-欺骗性风险最小化通过欺骗性分布偏移检测器进行分布外泛化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12081"target="_blank" rel="external nofollow noopener noreferrer">#68</a> <a href="https://papers.cool/arxiv/2509.12081"target="_blank" rel="external nofollow noopener noreferrer">欺骗性风险最小化：通过欺骗性分布偏移检测器进行分布外泛化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Anirudha Majumdar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anirudha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anirudha</a> Majumdar)</p>
<p>本文提出欺骗作为一种非分布式（OOD）泛化的机制：通过学习使训练数据对观察者来说显得独立且相同分布（iid）的数据表示，我们可以识别消除虚假相关性的稳定特征，并推广到看不见的领域。我们将这一原则称为欺骗性风险最小化 （DRM），并用一个实用的可微分目标对其进行实例化，该目标同时从基于共形鞅的检测器的角度学习消除分布偏移的特征，同时最大限度地减少特定于任务的损失。与领域自适应或先前的不变表示学习方法相比，DRM 不需要访问测试数据或将训练数据划分为有限数量的数据生成域。我们展示了 DRM 在机器人部署环境中具有概念偏移的数值实验和具有协变量偏移的模拟模仿学习设置中的功效。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a></p>
<p><strong>发布</strong>: 2025-09-15 16：11：55 UTC</p>
<h2 id="69-基于通用延迟嵌入的时间序列基础模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12080"target="_blank" rel="external nofollow noopener noreferrer">#69</a> <a href="https://papers.cool/arxiv/2509.12080"target="_blank" rel="external nofollow noopener noreferrer">基于通用延迟嵌入的时间序列基础模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zijian Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zijian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zijian</a> Wang), [Peng Tao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peng</a> Tao), [Jifan Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jifan</a> Shi), [Rui Bao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rui</a> Bao), [Rui Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rui</a> Liu), [Luonan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luonan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luonan</a> Chen)</p>
<p>本研究引入了通用延迟嵌入（UDE），这是一种预训练的基础模型，旨在通过延迟嵌入表示和Koopman算子预测的原则性集成来彻底改变时间序列预测。利用 Takens 的嵌入定理，UDE 作为观测数据的动态表示，从汉克尔矩阵构建二维子空间斑块，理论上保留了底层动力系统的动力学和拓扑特性。此类补丁被视为图像，可以通过利用先进的深度学习技术进行有效处理。在计算上，这些补丁进一步充当学习自注意力编码器的标记，从而能够由有限维库夫曼算子在潜在空间中以线性方式准确预测非线性时间序列。对各种基准和真实世界气候数据集的广泛评估表明，与最先进的基础模型相比，均方误差平均降低了 20% 以上，同时在微调场景中具有卓越的泛化性。特别是，从补丁中学习到的动态表示和Koopman算子预测形式表现出卓越的可解释性，具有对拓扑信息子空间的一致识别和域不变动力学的鲁棒编码，将UDE确立为具有广泛科学和工业适用性的通用时间序列建模和预测的可扩展、可解释的框架。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 16：11：49 UTC</p>
<h2 id="70-利用叶谱分析和机器学习早期检测番茄作物中分枝扫帚phelipanche-ramosa侵染-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12074"target="_blank" rel="external nofollow noopener noreferrer">#70</a> <a href="https://papers.cool/arxiv/2509.12074"target="_blank" rel="external nofollow noopener noreferrer">利用叶谱分析和机器学习早期检测番茄作物中分枝扫帚（Phelipanche ramosa）侵染</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mohammadreza Narimani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohammadreza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohammadreza</a> Narimani), [Alireza Pourreza](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alireza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alireza</a> Pourreza), [Ali Moghimi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ali</a> Moghimi), [Parastoo Farajpoor](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Parastoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Parastoo</a> Farajpoor), [Hamid Jafarbiglu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hamid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hamid</a> Jafarbiglu), [Mohsen B. Mesgaran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohsen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohsen</a> B. Mesgaran)</p>
<p>分枝扫帚 （Phelipanche ramosa） 是一种缺乏叶绿素的寄生杂草，通过从寄主那里提取养分来威胁番茄生产。我们使用叶级光谱反射率（400-2500 nm）和集成机器学习研究早期检测。在加利福尼亚州伍德兰的一项田间实验中，我们跟踪了 300 株番茄植株，跨越了由生长度日 （GDD） 定义的生长阶段。使用便携式光谱仪获取叶片反射率并进行预处理（波段去噪、1 nm插值、Savitzky-Golay平滑、基于相关性的波段缩减）。在1500 nm和2000 nm吸水特征附近观察到明显的类差异，与早期受感染植株叶片含水量降低一致。结合随机森林、XGBoost、SVM 与 RBF 内核和 Naive Bayes 的集成在 585 GDD 时实现了 89% 的准确率，召回率分别为 0.86（感染）和 0.93（未感染）。准确率在后期下降（例如，在 1568 GDD 时为 69%），可能是由于衰老和杂草干扰造成的。尽管受感染的植物和环境混杂因素数量很少，但结果表明，近端传感与集成学习可以在冠层症状出现之前及时检测到扫帚，支持有针对性的干预措施并减少产量损失。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a></p>
<p><strong>发布</strong>: 2025-09-15 16：00：32 UTC</p>
<h2 id="71-u-mamba2在-cbct-中缩放用于牙齿解剖分割的状态空间模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12069"target="_blank" rel="external nofollow noopener noreferrer">#71</a> <a href="https://papers.cool/arxiv/2509.12069"target="_blank" rel="external nofollow noopener noreferrer">U-Mamba2：在 CBCT 中缩放用于牙齿解剖分割的状态空间模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhi Qin Tan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhi</a> Qin Tan), [Xiatian Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiatian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiatian</a> Zhu), [Owen Addison](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Owen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Owen</a> Addison), [Yunpeng Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunpeng</a> Li)</p>
<p>锥形束计算机断层扫描 （CBCT） 是一种广泛使用的牙科 3D 成像技术，可提供有关颌骨和牙齿解剖结构的体积信息。这些解剖结构的准确分割对于诊断和手术计划等临床应用至关重要，但仍然耗时且具有挑战性。在本文中，我们介绍了 U-Mamba2，这是一种新的神经网络架构，专为 ToothFairy3 挑战背景下的多解剖 CBCT 分割而设计。U-Mamba2 将 Mamba2 状态空间模型集成到 U-Net 架构中，在不影响性能的情况下实施更强的结构约束以实现更高的效率。此外，我们还将交互式点击提示与交叉注意力块集成在一起，使用自监督学习预训练 U-Mamba2，并将牙科领域知识纳入模型设计中，以解决 CBCT 中牙齿解剖分割的关键挑战。包括独立测试在内的大量实验表明，U-Mamba2 既有效又高效，在 Toothfairy3 挑战赛的两项任务中都获得了前三名。在任务 1 中，U-Mamba2 在持有的测试数据下实现了 0.792 的平均骰子和 93.19 的 HD95，平均推理时间为 XX（ODIN 研讨会期间待定）。在任务 2 中，U-Mamba2 在坚持测试数据下的平均骰子为 0.852，HD95 为 7.39。该代码可在 <a href="https://github.com/zhiqin1998/UMamba2"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/zhiqin1998/UMamba2</a> 公开获取。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 15：52：43 UTC</p>
<h2 id="72-乐高张量应用的空间加速器生成和优化-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.12053"target="_blank" rel="external nofollow noopener noreferrer">#72</a> <a href="https://papers.cool/arxiv/2509.12053"target="_blank" rel="external nofollow noopener noreferrer">乐高：张量应用的空间加速器生成和优化</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Yujun Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yujun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yujun</a> Lin), [Zhekai Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhekai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhekai</a> Zhang), [Song Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Song"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Song</a> Han)</p>
<p>现代张量应用，尤其是基础模型和生成式 AI 应用，需要多种输入模式（视觉和语言），这增加了对灵活加速器架构的需求。现有框架在设计灵活性和 RTL 生成的生产力之间进行权衡：要么仅限于极少数手写模板，要么无法自动生成 RTL。为了应对这一挑战，我们提出了乐高框架，该框架针对张量应用，自动生成空间架构设计并输出可合成的 RTL 代码，而无需手写的 RTL 设计模板。乐高前端利用仿射转换架构表示，寻找功能单元之间的互连，合成内存系统，并基于数据复用分析融合不同的空间数据流设计。然后，乐高后端在基元级图中转换硬件以执行较低级别的优化，并应用一组线性编程算法来优化插入流水线寄存器，并在切换空间数据流时减少未使用逻辑的开销。我们的评估表明，与之前的工作 Gemmini 相比，乐高可以实现 3.2 倍的加速和 2.4 倍的能效，并且可以为生成式 AI 应用中的各种现代基础模型生成一种架构。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.AR"target="_blank" rel="external nofollow noopener noreferrer">硬件架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 15：36：18 UTC</p>
<h2 id="73-交互驱动的浏览由使用浏览器的代理的人类网页浏览提供信息的人机交互概念框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12049"target="_blank" rel="external nofollow noopener noreferrer">#73</a> <a href="https://papers.cool/arxiv/2509.12049"target="_blank" rel="external nofollow noopener noreferrer">交互驱动的浏览：由使用浏览器的代理的人类网页浏览提供信息的人机交互概念框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Hyeonggeun Yun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyeonggeun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyeonggeun</a> Yun), [Jinkyu Jang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinkyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinkyu</a> Jang)</p>
<p>尽管浏览器使用代理 （BUA） 在 Web 任务和自动化方面显示出前景，但大多数 BUA 在执行单个指令后终止，无法支持用户具有模糊目标、迭代决策和不断变化的上下文的复杂非线性浏览。我们提出了一个以人类网络浏览行为理论为依据的人机交互 （HITL） 概念框架。该框架以迭代循环为中心，其中 BUA 主动提出下一步作，用户通过反馈引导浏览过程。它还区分探索和利用作，使用户能够控制浏览的广度和深度。因此，该框架旨在减少用户的身体和认知努力，同时保留用户传统的浏览心智模型，并支持用户取得令人满意的结果。我们说明了该框架如何与假设用例一起运行，并讨论了从手动浏览到交互驱动浏览的转变。我们为 BUA 提供了一个理论依据的概念框架。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a></p>
<p><strong>发布</strong>: 2025-09-15 15：31：53 UTC</p>
<h2 id="74-用于个体水平行为分析的计算机视觉管道爱丁堡猪数据集的基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12047"target="_blank" rel="external nofollow noopener noreferrer">#74</a> <a href="https://papers.cool/arxiv/2509.12047"target="_blank" rel="external nofollow noopener noreferrer">用于个体水平行为分析的计算机视觉管道：爱丁堡猪数据集的基准测试</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Haiyu Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haiyu</a> Yang), [Enhong Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Enhong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Enhong</a> Liu), [Jennifer Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jennifer"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jennifer</a> Sun), [Sumit Sharma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sumit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sumit</a> Sharma), [Meike van Leerdam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meike"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meike</a> van Leerdam), [Sebastien Franceschini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sebastien"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sebastien</a> Franceschini), [Puchun Niu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Puchun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Puchun</a> Niu), [Miel Hostens](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Miel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Miel</a> Hostens)</p>
<p>动物行为分析在了解农业环境中的动物福利、健康状况和生产力方面发挥着至关重要的作用。然而，传统的人工观察方法耗时、主观且可扩展性有限。我们提出了一个模块化管道，该管道利用开源的最先进的计算机视觉技术在群体饲养环境中自动进行动物行为分析。我们的方法结合了最先进的零样本对象检测模型、运动感知跟踪和分割，以及使用视觉转换器进行稳健行为识别的高级特征提取模型。该管道解决了包括动物闭塞和群体饲养场景在内的挑战，如室内猪监测中所示。我们在爱丁堡猪行为视频数据集上验证了我们的系统，以执行多个行为任务。我们的时间模型实现了 94.2% 的总体准确率，比现有方法提高了 21.2 个百分点。该管道展示了强大的跟踪能力，身份保存得分为 93.3%，物体检测精度为 89.3%。模块化设计表明了适应其他环境的潜力，尽管需要进一步跨物种验证。开源实施为行为监测提供了可扩展的解决方案，通过自动化、客观和持续的分析，为精准养猪和福利评估做出贡献。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 15：31：12 UTC</p>
<h2 id="75-通过结构化掩码生成布局条件的自回归文本到图像-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12046"target="_blank" rel="external nofollow noopener noreferrer">#75</a> <a href="https://papers.cool/arxiv/2509.12046"target="_blank" rel="external nofollow noopener noreferrer">通过结构化掩码生成布局条件的自回归文本到图像</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zirui Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zirui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zirui</a> Zheng), [Takashi Isobe](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Takashi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Takashi</a> Isobe), [Tong Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tong</a> Shen), [Xu Jia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xu</a> Jia), [Jianbin Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jianbin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jianbin</a> Zhao), [Xiaomin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaomin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaomin</a> Li), [Mengmeng Ge](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengmeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengmeng</a> Ge), [Baolu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baolu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baolu</a> Li), [Qinghe Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qinghe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qinghe</a> Wang), [Dong Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Li), [Dong Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Zhou), [Yunzhi Zhuge](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunzhi</a> Zhuge), [Huchuan Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huchuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huchuan</a> Lu), [Emad Barsoum](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emad</a> Barsoum)</p>
<p>虽然自回归 （AR） 模型在图像生成方面取得了显着的成功，但由于布局条件的稀疏性和特征纠缠的风险，将其扩展到布局条件生成仍然具有挑战性。我们提出了基于 AR 的布局到图像的结构化掩蔽 （SMARLI），这是一种用于布局到图像生成的新颖框架，它有效地将空间布局约束集成到基于 AR 的图像生成中。为了给AR模型配备布局控制，将专门设计的结构化掩蔽策略应用于注意力计算，以控制全局提示、布局和图像标记之间的交互。这种设计可以防止不同区域及其描述之间的错误关联，同时能够将布局约束充分注入到生成过程中。为了进一步提高生成质量和布局准确性，我们将基于组相对策略优化（GRPO）的后训练方案与专门设计的布局奖励函数相结合，用于基于下一个集的AR模型。实验结果表明，SMARLI 能够在不影响生成质量的情况下将布局标记与文本和图像标记无缝集成。它实现了卓越的布局感知控制，同时保持了AR模型的结构简单性和生成效率。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 15：27：29 UTC</p>
<h2 id="76-探索遥感中的高效开放词汇分割-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12040"target="_blank" rel="external nofollow noopener noreferrer">#76</a> <a href="https://papers.cool/arxiv/2509.12040"target="_blank" rel="external nofollow noopener noreferrer">探索遥感中的高效开放词汇分割</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Bingyu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingyu</a> Li), [Haocheng Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haocheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haocheng</a> Dong), [Da Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Da"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Da</a> Zhang), [Zhiyuan Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyuan</a> Zhao), [Junyu Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junyu</a> Gao), [Xuelong Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuelong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuelong</a> Li)</p>
<p>开放词汇遥感图像分割（OVRSIS）是一项使开放词汇分割（OVS）适应遥感（RS）领域的新兴任务，由于缺乏统一的评估基准以及自然图像和RS图像之间的领域差距，仍然没有得到充分探索。为了弥合这些差距，我们首先基于广泛使用的 RS 分割数据集建立标准化的 OVRSIS 基准 （\textbf{OVRSISBench}），从而实现跨方法的一致评估。利用该基准，我们综合评估了几种具有代表性的OVS/OVRSIS模型，并揭示了它们在直接应用于遥感场景时的局限性。基于这些见解，我们提出了 \textbf{RSKT-Seg}，这是一种专为遥感量身定制的新型开放词汇分割框架。RSKT-Seg 集成了三个关键组件：（1） 多向成本图聚合 （RS-CMA） 模块，通过计算跨多个方向的视觉语言余弦相似性来捕获旋转不变的视觉线索;（2）高效成本映射融合（RS-Fusion）转换器，它通过轻量级降维策略联合模拟空间和语义依赖关系;（3）遥感知识转移（RS-Transfer）模块，注入预训练知识，并通过增强的上采样促进域适应。基准测试上的大量实验表明，RSKT-Seg 始终比强 OVS 基线高出 +3.8 mIoU 和 +5.9 mACC，同时通过高效聚合实现 2 倍的推理速度。我们的代码是 \href{https://github.com/LiBingyu01/RSKT-Seg}{\textcolor{blue}{here}}。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 15：24：49 UTC</p>
<h2 id="77-模仿学习作为回报分布匹配-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12026"target="_blank" rel="external nofollow noopener noreferrer">#77</a> <a href="https://papers.cool/arxiv/2509.12026"target="_blank" rel="external nofollow noopener noreferrer">模仿学习作为回报分布匹配</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Filippo Lazzati](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Filippo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Filippo</a> Lazzati), [Alberto Maria Metelli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alberto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alberto</a> Maria Metelli)</p>
<p>我们研究了通过模仿学习（IL）训练风险敏感强化学习（RL）智能体的问题。与标准IL不同，我们的目标不仅是训练一个与专家的预期回报（即其平均表现）相匹配的代理，还训练其风险态度（即回报分布的其他特征，例如方差）相匹配。我们提出了风险敏感IL问题的一般公式，其目标是匹配专家在Wasserstein距离中的回报分布。我们专注于表格设置，并假设专家的奖励是已知的。在证明了马尔可夫策略对此任务的有限表达性之后，我们引入了一个高效且充分表达的非马尔可夫策略子类。在此子类的基础上，我们开发了两种可证明有效的算法，RS-BC 和 RS-KT，用于分别在过渡模型未知和已知时解决问题。我们表明，通过利用动力学信息，RS-KT实现了比RS-BC低得多的样品复杂度。我们通过设计基于预言机的RS-KT变体，进一步证明了在专家奖励未知的情况下回报分布匹配的样本效率。最后，我们通过数值模拟补充了对RS-KT和RS-BC的理论分析，强调了它们的样本效率以及非马尔可夫策略相对于标准样本效率IL算法的优势。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 15：08：04 UTC</p>
<h2 id="78-amq启用-automl-对大型语言模型进行混合精度仅权重量化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12019"target="_blank" rel="external nofollow noopener noreferrer">#78</a> <a href="https://papers.cool/arxiv/2509.12019"target="_blank" rel="external nofollow noopener noreferrer">AMQ：启用 AutoML 对大型语言模型进行混合精度仅权重量化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sangjun Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sangjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sangjun</a> Lee), [Seung-taek Woo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seung-taek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seung-taek</a> Woo), [Jungyu Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jungyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jungyu</a> Jin), [Changhun Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Changhun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Changhun</a> Lee), [Eunhyeok Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eunhyeok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eunhyeok</a> Park)</p>
<p>为了实现大型语言模型 （LLM） 的更广泛部署，必须确定在严格内存约束下性能最佳的模型。我们提出了 AMQ，即自动混合精度仅权重量化，这是一个分配分层量化位宽以最佳平衡模型质量和内存使用情况的框架。然而，具有超过 10^{100} 种可能配置的组合搜索空间使得传统的黑盒优化变得不可行。AMQ 通过四项关键创新克服了这一挑战：（1） 使用先验知识进行搜索空间修剪以排除无希望的配置，（2） 量化代理以绕过搜索过程中昂贵的格式转换，（3） 质量预测器以最大限度地减少评估开销，以及 （4） 迭代搜索和更新策略以实现快速稳定的收敛。通过集成这些组件，AMQ 有效地探索了质量效率领域，达到了帕累托前沿，并产生了既紧凑又高性能的 LLM。我们的代码可在 <a href="https://github.com/dlwns147/amq"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/dlwns147/amq</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 14：59：35 UTC</p>
<h2 id="79-通过具有封闭形式奖励质心的逆强化学习泛化行为-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.12010"target="_blank" rel="external nofollow noopener noreferrer">#79</a> <a href="https://papers.cool/arxiv/2509.12010"target="_blank" rel="external nofollow noopener noreferrer">通过具有封闭形式奖励质心的逆强化学习泛化行为</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Filippo Lazzati](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Filippo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Filippo</a> Lazzati), [Alberto Maria Metelli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alberto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alberto</a> Maria Metelli)</p>
<p>我们研究将通过演示提供的专家代理的行为推广到新环境和/或其他约束的问题。逆强化学习 （IRL） 通过寻求恢复专家的潜在奖励函数提供了一个有前途的解决方案，如果将其用于新环境中的规划，将重现所需的行为。然而，现实生活中本质上是错误的：多个奖励函数，形成所谓的可行集合，可以解释相同的观察到的行为。由于这些奖励可能会在新环境中诱发不同的策略，因此在没有附加信息的情况下，需要一个决策标准来选择要部署的策略。在本文中，我们提出了一种新颖的原则性准则，该准则在可行集的某个有界子集中的奖励诱导的策略中选择“平均”策略。值得注意的是，我们表明可以通过使用该子集的奖励质心进行规划来获得该策略，为此我们推导出了一个封闭式表达式。然后，我们提出了一种可证明的有效算法，用于仅使用专家演示的离线数据集来估计该质心。最后，我们进行数值模拟，说明专家的行为与我们的方法产生的行为之间的关系。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 14：53：54 UTC</p>
<h2 id="80-文本适应通俗易懂的语言并通过自动译后编辑周期轻松阅读-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11991"target="_blank" rel="external nofollow noopener noreferrer">#80</a> <a href="https://papers.cool/arxiv/2509.11991"target="_blank" rel="external nofollow noopener noreferrer">文本适应通俗易懂的语言，并通过自动译后编辑周期轻松阅读</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jesús Calleja](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jes"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jes</a>ús Calleja), [David Ponce](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Ponce), [Thierry Etchegoyhen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thierry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thierry</a> Etchegoyhen)</p>
<p>我们描述了 Vicomtech 参与的 CLEARS 挑战赛，即文本改编为西班牙语的通俗语言和易读。我们的方法具有对不同类型的初始大型语言模型适配进行自动后期编辑的特点，其中迭代生成连续的适配，直到可读性和相似性指标表明无法成功执行进一步的适配细化。取所有官方指标的平均值，我们提交的作品分别在通俗语言和易读改编方面获得第一和第二名。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 14：42：44 UTC</p>
<h2 id="81-poison-to-detect联邦学习中靶向过拟合的检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11974"target="_blank" rel="external nofollow noopener noreferrer">#81</a> <a href="https://papers.cool/arxiv/2509.11974"target="_blank" rel="external nofollow noopener noreferrer">Poison to Detect：联邦学习中靶向过拟合的检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Soumia Zohra El Mestari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soumia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soumia</a> Zohra El Mestari), [Maciej Krzysztof Zuziak](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maciej"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maciej</a> Krzysztof Zuziak), [Gabriele Lenzini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gabriele"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gabriele</a> Lenzini)</p>
<p>联邦学习 （FL） 支持跨去中心化客户端进行协作模型训练，同时保持本地数据的私密性，使其成为广泛采用的隐私增强技术 （PET）。尽管 FL 具有隐私优势，但它仍然容易受到隐私攻击，包括针对特定客户端的攻击。在本文中，我们研究了一个未被充分探索的威胁，即不诚实的编排者故意纵聚合过程，以在特定客户端的本地模型中诱导有针对性的过度拟合。虽然该领域的许多研究主要关注减少训练期间的信息泄露量，但我们专注于实现客户端对有针对性的过度拟合的早期检测，从而允许客户端在重大伤害发生之前脱离接触。与此相一致，我们提出了三种检测技术——（a）标签翻转，（b）后门触发器注入和（c）模型指纹识别——使客户端能够验证全局聚合的完整性。我们在不同攻击场景下对多个数据集进行了评估。我们的结果表明，这三种方法都能可靠地检测编排器诱导的目标过拟合，但它们在计算复杂度、检测延迟和误报率方面存在差异。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 14：23：39 UTC</p>
<h2 id="82-用于自动化漏洞测试的时间受限智能对手多机器人巡逻案例研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11971"target="_blank" rel="external nofollow noopener noreferrer">#82</a> <a href="https://papers.cool/arxiv/2509.11971"target="_blank" rel="external nofollow noopener noreferrer">用于自动化漏洞测试的时间受限智能对手：多机器人巡逻案例研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [James C. Ward](<a href="https://arxiv.org/search/?searchtype=author&amp;query=James"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=James</a> C. Ward), [Alex Bott](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alex"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alex</a> Bott), [Connor York](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Connor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Connor</a> York), [Edmund R. Hunt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Edmund"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Edmund</a> R. Hunt)</p>
<p>模拟物理自治系统的恶意攻击可以成为检查其攻击鲁棒性并为漏洞感知设计提供信息的有用工具。在这项工作中，我们通过多机器人巡逻的视角来研究这一点，通过提出一个基于机器学习的对手模型来观察机器人巡逻行为，以便尝试在有限的时间内获得对安全环境的未被发现的访问权限。这样的模型允许针对现实的潜在对手评估巡逻系统，从而为未来的巡逻策略设计提供见解。我们表明，我们的新模型优于现有基线，从而提供了更严格的测试，并根据多个领先的分散式多机器人巡逻策略检查了其性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a></p>
<p><strong>发布</strong>: 2025-09-15 14：22：08 UTC</p>
<h2 id="83-基于-gpu-加速的-rag-电报助手用于支持并行处理学生-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11947"target="_blank" rel="external nofollow noopener noreferrer">#83</a> <a href="https://papers.cool/arxiv/2509.11947"target="_blank" rel="external nofollow noopener noreferrer">基于 GPU 加速的 RAG 电报助手，用于支持并行处理学生</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Guy Tel-Zur](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guy</a> Tel-Zur)</p>
<p>该项目解决了一个关键的教学需求：在传统接待时间之外为学生提供持续的、按需的学术帮助。我提出了一个特定于域的检索增强生成 （RAG） 系统，该系统由量化的 Mistral-7B Instruct 模型提供支持，并部署为 Telegram 机器人。该助手通过提供与“并行处理简介”课程材料一致的实时、个性化响应来增强学习。GPU 加速显着改善了推理延迟，从而能够在消费类硬件上进行实际部署。这种方法展示了消费类 GPU 如何为 HPC 教育提供经济实惠、私密且有效的 AI 辅导。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 14：06：09 UTC</p>
<h2 id="84-visdocsketcher使用代理系统实现可扩展的可视化文档-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11942"target="_blank" rel="external nofollow noopener noreferrer">#84</a> <a href="https://papers.cool/arxiv/2509.11942"target="_blank" rel="external nofollow noopener noreferrer">VisDocSketcher：使用代理系统实现可扩展的可视化文档</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Luís F. Gomes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lu</a>ís F. Gomes), [Xin Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Zhou), [David Lo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Lo), [Rui Abreu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rui</a> Abreu)</p>
<p>可视化文档是一种有效的工具，可以减少开发人员在理解不熟悉的代码时面临的认知障碍，从而实现更直观的理解。与文本文档相比，它提供了对系统结构和数据流的更高层次的理解。对于大型软件系统，开发人员通常更喜欢视觉表示而不是冗长的文本描述。可视化文档既难以制作，又难以评估。手动创建它非常耗时，目前，没有现有方法可以直接从代码自动生成高级可视化文档。它的评估通常是主观的，因此难以标准化和自动化。为了应对这些挑战，本文首次探索使用代理 LLM 系统自动生成可视化文档。我们介绍了 VisDocSketcher，这是第一个基于代理的方法，它将静态分析与 LLM 代理相结合，以识别代码中的关键元素并生成相应的视觉表示。我们提出了一种新颖的评估框架 AutoSketchEval，用于使用代码级指标评估生成的可视化文档的质量。实验结果表明，该方法对74.4%的样本具有有效的视觉记录。与基于模板的简单基线相比，它显示出 26.7-39.8% 的改进。我们的评估框架可以可靠地区分高质量（代码对齐）视觉文档和低质量（非对齐）视觉文档，实现超过 0.87 的 AUC。我们的工作通过引入实用工具，不仅可以生成有效的视觉表示，还可以可靠地评估其质量，从而为未来自动化视觉文档的研究奠定了基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-15 14：02：29 UTC</p>
<h2 id="85-mmore大规模多模态开放式-rag-和提取-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11937"target="_blank" rel="external nofollow noopener noreferrer">#85</a> <a href="https://papers.cool/arxiv/2509.11937"target="_blank" rel="external nofollow noopener noreferrer">MMORE：大规模多模态开放式 RAG 和提取</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alexandre Sallinen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexandre"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexandre</a> Sallinen), [Stefan Krsteski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Stefan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Stefan</a> Krsteski), [Paul Teiletche](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Paul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Paul</a> Teiletche), [Marc-Antoine Allard](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marc-Antoine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marc-Antoine</a> Allard), [Baptiste Lecoeur](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baptiste"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baptiste</a> Lecoeur), [Michael Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Zhang), [Fabrice Nemo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fabrice"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fabrice</a> Nemo), [David Kalajdzic](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Kalajdzic), [Matthias Meyer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matthias"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matthias</a> Meyer), [Mary-Anne Hartley](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mary-Anne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mary-Anne</a> Hartley)</p>
<p>我们介绍了 MMORE，这是一个用于大规模多模态开放检索增强生成和提取的开源管道，旨在大规模从异构文档格式中摄取、转换和检索知识。MMORE 支持文本、表格、图像、电子邮件、音频和视频等 15 多种文件类型，并将它们处理成统一的格式，以便为 LLM 提供下游应用。该架构提供模块化的分布式处理，实现跨 CPU 和 GPU 的可扩展并行化。在处理基准测试中，MMORE 比单节点基线加速了 3.8 倍，在扫描的 PDF 上比 Docling 的准确性高出 40%。该管道集成了混合密集-稀疏检索，并支持交互式 API 和批处理 RAG 终结点。在 PubMedQA 上评估，MMORE 增强的医学法学硕士通过增加检索深度提高了生物医学 QA 的准确性。MMORE 为在各种真实世界多模态数据上部署与任务无关的 RAG 系统提供了强大、可扩展的基础。代码库可在 <a href="https://github.com/swiss-ai/mmore"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/swiss-ai/mmore</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 13：56：06 UTC</p>
<h2 id="86-集成先验观测值以进行增量-3d-场景图预测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11895"target="_blank" rel="external nofollow noopener noreferrer">#86</a> <a href="https://papers.cool/arxiv/2509.11895"target="_blank" rel="external nofollow noopener noreferrer">集成先验观测值以进行增量 3D 场景图预测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Marian Renz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marian</a> Renz), [Felix Igelbrink](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Felix"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Felix</a> Igelbrink), [Martin Atzmueller](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Martin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Martin</a> Atzmueller)</p>
<p>3D 语义场景图 （3DSSG） 通过显式建模对象、属性和关系来提供环境的紧凑结构化表示。虽然 3DSSG 在机器人和具身人工智能方面显示出前景，但许多现有方法主要依赖于传感器数据，而不是整合来自语义丰富环境的进一步信息。此外，大多数方法都假设可以访问完整的场景重建，这限制了它们在现实世界的增量环境中的适用性。本文介绍了一种用于增量 3DSSG 预测的新型异构图模型，该模型将额外的多模态信息（例如先验观测值）直接集成到消息传递过程中。该模型利用多层，灵活地结合全局和局部场景表示，无需专门的模块或全场景重建。我们评估了我们在 3DSSG 数据集上的方法，表明富含多模态信息（例如语义嵌入（例如 CLIP）和先前观察结果的 GNN 为复杂的真实环境提供了可扩展和通用的解决方案。所呈现架构的完整源代码将在 <a href="https://github.com/m4renz/incremental-scene-graph-prediction"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/m4renz/incremental-scene-graph-prediction</a> 上提供。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 13：10：34 UTC</p>
<h2 id="87-成长的视角使用大型语言模型对具身视角采取和内在叙事发展进行建模-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11868"target="_blank" rel="external nofollow noopener noreferrer">#87</a> <a href="https://papers.cool/arxiv/2509.11868"target="_blank" rel="external nofollow noopener noreferrer">成长的视角：使用大型语言模型对具身视角采取和内在叙事发展进行建模</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sabrina Patania](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sabrina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sabrina</a> Patania), [Luca Annese](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luca</a> Annese), [Anna Lambiase](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anna</a> Lambiase), [Anita Pellegrini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anita</a> Pellegrini), [Tom Foulsham](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tom"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tom</a> Foulsham), [Azzurra Ruggeri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Azzurra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Azzurra</a> Ruggeri), [Silvia Rossi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silvia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silvia</a> Rossi), [Silvia Serino](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silvia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silvia</a> Serino), [Dimitri Ognibene](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dimitri"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dimitri</a> Ognibene)</p>
<p>语言和具身透视对于人类协作至关重要，但很少有计算模型同时解决这两者。这项工作研究了PerspAct系统[1]，该系统将ReAct（理性和行为）范式与大型语言模型（LLM）相结合，以模拟基于Selman理论[2]的透视制定的发展阶段。使用扩展导演任务，我们评估 GPT 生成与特定发展阶段一致的内部叙述的能力，并评估这些叙述如何从定性（行动选择）和定量（任务效率）上影响协作绩效。结果表明，GPT 在任务执行之前可靠地产生发展一致的叙述，但在交互过程中经常转向更高级的阶段，这表明语言交换有助于完善内部表征。较高的发展阶段通常会提高协作效率，而较早的发展阶段在复杂的环境中会产生更多可变的结果。这些发现强调了在法学硕士中整合具身观点和语言以更好地模拟发展动态的潜力，并强调在语言和具身组合任务中评估内部言语的重要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a></p>
<p><strong>发布</strong>: 2025-09-15 12：39：55 UTC</p>
<h2 id="88-tenma使用扩散变压器进行鲁棒的跨实施例机器人作-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11865"target="_blank" rel="external nofollow noopener noreferrer">#88</a> <a href="https://papers.cool/arxiv/2509.11865"target="_blank" rel="external nofollow noopener noreferrer">Tenma：使用扩散变压器进行鲁棒的跨实施例机器人作</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Travis Davies](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Travis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Travis</a> Davies), [Yiqi Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiqi</a> Huang), [Yunxin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunxin</a> Liu), [Xiang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiang</a> Chen), [Huxian Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huxian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huxian</a> Liu), [Luhui Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luhui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luhui</a> Hu)</p>
<p>扩展 Transformer 策略和扩散模型具有先进的机器人作能力，但在轻量级、跨具体化的学习环境中结合这些技术仍然具有挑战性。我们研究了在异构多模态机器人数据上训练的扩散变压器策略的稳定性和性能最影响的设计选择，并介绍了用于双手动手臂控制的轻型扩散变压器 Tenma。Tenma 通过跨实施例归一化器集成了多视图 RGB、本体感觉和语言，该归一化器将不同的状态/动作空间映射到共享的潜在空间中;一个联合状态-时间编码器，用于时间对齐的观测学习，并提高推理速度;以及针对训练稳定性和学习能力进行优化的扩散动作解码器。在基准测试和匹配计算中，Tenma 实现了 88.95% 的平均分布成功率，并在对象和场景偏移下保持强劲的性能，大大超过了基线策略，后者的最佳分布平均值为 18.12%。尽管使用了中等的数据规模，但 Tenma 提供了强大的作和泛化，表明多模态和跨实施方式学习策略在进一步增强基于 Transformer 的模仿学习策略的能力方面具有巨大潜力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 12：39：15 UTC</p>
<h2 id="89-连接视觉语言模型和视频问答的符号基础-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11862"target="_blank" rel="external nofollow noopener noreferrer">#89</a> <a href="https://papers.cool/arxiv/2509.11862"target="_blank" rel="external nofollow noopener noreferrer">连接视觉语言模型和视频问答的符号基础</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Haodi Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haodi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haodi</a> Ma), [Vyom Pathak](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vyom"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vyom</a> Pathak), [Daisy Zhe Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daisy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daisy</a> Zhe Wang)</p>
<p>视频问答 （VQA） 要求模型对视频中的空间、时间和因果线索进行推理。最近的视觉语言模型 （VLM） 取得了强大的结果，但通常依赖于浅层相关性，导致时间基础薄弱和可解释性有限。我们研究符号场景图 （SG） 作为 VQA 的中间接地信号。SG 提供结构化的对象关系表示，补充 VLM 的整体推理。我们介绍了 SG-VLM，这是一个模块化框架，它通过提示和可视化定位将冻结的 VLM 与场景图接地集成在一起。在三个基准测试（NExT-QA、iVQA、ActivityNet-QA）和多个 VLM（QwenVL、InternVLL）中，SG-VLM 改进了因果和时间推理，并优于之前的基线，尽管相对于强 VLM 的收益有限。这些发现凸显了符号接地的前景和当前局限性，并为未来视频理解中的混合VLM符号方法提供了指导。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 12：35：56 UTC</p>
<h2 id="90-高维空间中的概率鲁棒性分析在语义分割网络中的应用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11838"target="_blank" rel="external nofollow noopener noreferrer">#90</a> <a href="https://papers.cool/arxiv/2509.11838"target="_blank" rel="external nofollow noopener noreferrer">高维空间中的概率鲁棒性分析：在语义分割网络中的应用</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Navid Hashemi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Navid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Navid</a> Hashemi), [Samuel Sasaki](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Samuel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Samuel</a> Sasaki), [Diego Manzanas Lopez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Diego"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Diego</a> Manzanas Lopez), [Ipek Oguz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ipek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ipek</a> Oguz), [Meiyi Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meiyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meiyi</a> Ma), [Taylor T. Johnson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taylor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taylor</a> T. Johnson)</p>
<p>语义分割网络 （SSN） 在医学成像、自动驾驶和环境监测等领域发挥着至关重要的作用，在这些领域，安全性取决于不确定性下可靠的模型行为。然而，现有的概率验证方法难以随着现代分割任务的复杂性和维度而扩展，通常产生的保证过于保守而无法实用。我们引入了一个概率验证框架，该框架既与架构无关，又可扩展到高维输出。我们的方法将基于采样的可达性分析与共形推理 （CI） 相结合，以提供可证明的保证，同时避免先前方法的过度保守。为了抵消 CI 在高维环境中的局限性，我们提出了一种新颖的策略，可以在不影响严谨性的情况下减少保守主义。对CamVid、OCTA-500、Lung Segmentation和Cityscapes的大规模分割模型的实证评估表明，与SOTA相比，我们的方法提供了可靠的安全保证，同时大大收紧了界限。我们还提供了一个实现此技术的工具箱，可在 Github 上找到。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 12：25：25 UTC</p>
<h2 id="91-文本条件人工智能生成音乐的数据驱动分析suno-和-udio-的案例研究-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11824"target="_blank" rel="external nofollow noopener noreferrer">#91</a> <a href="https://papers.cool/arxiv/2509.11824"target="_blank" rel="external nofollow noopener noreferrer">文本条件人工智能生成音乐的数据驱动分析：Suno 和 Udio 的案例研究</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Luca Casini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luca</a> Casini), [Laura Cros Vila](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Laura"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Laura</a> Cros Vila), [David Dalmazzo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Dalmazzo), [Anna-Kaisa Kaila](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anna-Kaisa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anna-Kaisa</a> Kaila), [Bob L. T. Sturm](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bob"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bob</a> L. T. Sturm)</p>
<p>用于根据文本提示（人工智能音乐）创建音乐的在线人工智能平台，例如 Suno 和 Udio，现在正在被数十万用户使用。一些人工智能音乐出现在多个国家的广告甚至排行榜上。这些平台是如何使用的？哪些主题激发了他们的用户？本文使用 2024 年 5 月至 10 月期间这些平台用户生成的大量歌曲来回答 Suno 和 Udio 的这些问题。结合最先进的文本嵌入模型、降维和聚类方法，我们分析提示词、标签和歌词，并在交互式绘图中自动注释和显示处理后的数据。我们的结果揭示了歌词、语言偏好、提示策略以及通过使用元标签来引导模型的特殊尝试中的突出主题。为了促进对人工智能生成音乐的发展文化实践的音乐学研究，我们共享我们的代码和资源。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a></p>
<p><strong>发布</strong>: 2025-09-15 12：10：50 UTC</p>
<h2 id="92-不相关表示的崩溃-cir-确保稳健且无中断的-llm-忘却-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11816"target="_blank" rel="external nofollow noopener noreferrer">#92</a> <a href="https://papers.cool/arxiv/2509.11816"target="_blank" rel="external nofollow noopener noreferrer">不相关表示的崩溃 （CIR） 确保稳健且无中断的 LLM 忘却</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Filip Sondej](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Filip"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Filip</a> Sondej), [Yushi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yushi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yushi</a> Yang)</p>
<p>当前的忘却技术和安全培训始终无法从语言模型中消除危险知识。我们分析了根本原因，并提出了一种高度选择性的技术，该技术可以稳健地取消学习，并且不破坏一般性能。我们对激活和模块输出梯度执行 PCA，以识别包含公共表示的子空间，并在计算取消学习更新之前折叠它们。这样我们就可以避免忘记一般表示，而只针对那些特定于未学习的事实的表示。当从 Llama-3.1-8B 中取消学习大规模杀伤性武器数据集事实时，我们在生物危害事实上的攻击后准确性下降了 80 倍，在网络危害事实上下降了 30 倍。尽管如此，我们对总体性能的破坏减少了 30 倍（维基文本损失仅增加 0.1%），同时每个事实所需的 GPU 秒不到 3 秒。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 11：55：10 UTC</p>
<h2 id="93-specvlm视觉语言模型中的快速推测解码-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11815"target="_blank" rel="external nofollow noopener noreferrer">#93</a> <a href="https://papers.cool/arxiv/2509.11815"target="_blank" rel="external nofollow noopener noreferrer">SpecVLM：视觉语言模型中的快速推测解码</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Haiduo Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haiduo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haiduo</a> Huang), [Fuwei Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fuwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fuwei</a> Yang), [Zhenhua Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenhua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenhua</a> Liu), [Xuanwu Yin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuanwu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuanwu</a> Yin), [Dong Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Li), [Pengju Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pengju"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pengju</a> Ren), [Emad Barsoum](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emad</a> Barsoum)</p>
<p>推测解码是加速自回归大型语言模型 （LLM） 的有效方法，但将其直接移植到视觉语言模型 （VLM） 面临独特的系统限制：预填充阶段以视觉标记为主，其数量随图像分辨率和视频长度而变化，从而膨胀了计算和内存，尤其是键值 （KV） 缓存。我们研究了 VLM 的推测解码，并引入了 SpecVLM，这是一个实用的系统，它 （1） 建立了一个强大的 EAGLE-2 风格基线 EagleVLM，在完全自回归推理中提供 1.5&ndash;2.3 倍的端到端加速，以及 （2） 使用弹性视觉压缩器进一步加速 VLM 推理，该压缩器在修剪、池化、卷积和重采样器原语之间自适应选择，以平衡 FLOP/参数和每个输入的精度。为了避免昂贵的离线蒸馏语料库，我们提出了一种在线 logit 蒸馏协议，该协议使用交叉熵和平滑 L1 目标相结合，使用动态教师 logit 和倒数第二个特征训练模型草案，消除存储和预处理，同时保持计算效率。该协议揭示了训练时间缩放效应：较长的在线训练单调地增加了草稿模型的平均接受长度，从而提高了推测效率。根据经验，SpecVLM 实现了额外的加速，最终在 LLaVA 和 MMMU 的 5 个时期内实现 2.5&ndash;2.9 倍的端到端加速，始终如一地克服分辨率和任务难度，同时保留目标模型的输出分布（无损解码）。我们的代码可在 <a href="https://github.com/haiduo/SpecVLM"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/haiduo/SpecVLM</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 11：53：56 UTC</p>
<h2 id="94-弥合稀疏性和冗余之间的差距具有全局上下文的双解码框架用于地图推理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11731"target="_blank" rel="external nofollow noopener noreferrer">#94</a> <a href="https://papers.cool/arxiv/2509.11731"target="_blank" rel="external nofollow noopener noreferrer">弥合稀疏性和冗余之间的差距：具有全局上下文的双解码框架用于地图推理</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yudong Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yudong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yudong</a> Shen), [Wenyu Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenyu</a> Wu), [Jiali Mao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiali</a> Mao), [Yixiao Tong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixiao</a> Tong), [Guoping Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guoping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guoping</a> Liu), [Chaoya Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chaoya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chaoya</a> Wang)</p>
<p>轨迹数据因其低成本、覆盖面广、持续可用等特点，成为自动地图推断的关键资源。然而，不均匀的轨迹密度往往导致稀疏地区的道路破碎，密集地区的路段冗余，给现有方法带来了重大挑战。为了解决这些问题，我们提出了DGMap，这是一个具有全局上下文感知的双解码框架，具有多尺度网格编码、掩码增强关键点提取和全局上下文感知关系预测功能。通过将全局语义上下文与局部几何特征相结合，DGMap提高了关键点检测精度，以减少稀疏轨迹区域的道路碎片化。此外，全局上下文感知关系预测模块通过对长距离轨迹模式进行建模来抑制密集轨迹区域中的错误连接。在三个真实世界数据集上的实验结果表明，DGMap 在 APLS 中的性能比最先进的方法高出 5%，滴滴出行平台的轨迹数据性能显着提升</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 09：31：38 UTC</p>
<h2 id="95-机器人辅助手术的显微外科器械细分-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11727"target="_blank" rel="external nofollow noopener noreferrer">#95</a> <a href="https://papers.cool/arxiv/2509.11727"target="_blank" rel="external nofollow noopener noreferrer">机器人辅助手术的显微外科器械细分</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tae Kyeong Jeong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tae</a> Kyeong Jeong), [Garam Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Garam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Garam</a> Kim), [Juyoun Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juyoun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juyoun</a> Park)</p>
<p>薄结构的准确分割对于理解显微外科场景至关重要，但由于分辨率损失、低对比度和类别不平衡，仍然具有挑战性。我们提出了用于机器人辅助的显微外科仪器分割（MISRA），这是一种分割框架，它通过亮度通道增强RGB输入，集成跳过注意力以保留细长的特征，并采用迭代反馈模块（IFM）来恢复多个通道的连续性。此外，我们还引入了一个专用的显微外科数据集，其中包含包括薄物体在内的手术器械的细粒度注释，为 <a href="https://huggingface.co/datasets/KIST-HARILAB/MISAW-Seg"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/datasets/KIST-HARILAB/MISAW-Seg</a> 提供的稳健评估数据集提供了基准。实验表明，MISRA 实现了具有竞争力的性能，与竞争方法相比，平均类 IoU 提高了 5.37%，同时在仪器接触和重叠处提供更稳定的预测。这些结果使 MISRA 成为迈向计算机辅助和机器人显微外科可靠场景解析的有希望的一步。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 09：29：27 UTC</p>
<h2 id="96-coachme使用基于参考的教练指导生成模型解码运动元素-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11698"target="_blank" rel="external nofollow noopener noreferrer">#96</a> <a href="https://papers.cool/arxiv/2509.11698"target="_blank" rel="external nofollow noopener noreferrer">CoachMe：使用基于参考的教练指导生成模型解码运动元素</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wei-Hsin Yeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei-Hsin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei-Hsin</a> Yeh), [Yu-An Su](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu-An"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu-An</a> Su), [Chih-Ning Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chih-Ning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chih-Ning</a> Chen), [Yi-Hsueh Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi-Hsueh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi-Hsueh</a> Lin), [Calvin Ku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Calvin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Calvin</a> Ku), [Wen-Hsin Chiu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wen-Hsin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wen-Hsin</a> Chiu), [Min-Chun Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Min-Chun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Min-Chun</a> Hu), [Lun-Wei Ku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lun-Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lun-Wei</a> Ku)</p>
<p>动作指导是一项至关重要的任务，它通过分析动作和提供纠正指导来帮助运动员完善技术。尽管多模态模型的最新进展提高了运动理解能力，但由于运动具有高度特定领域的性质以及对信息指导的需求，生成精确且针对特定运动的指令仍然具有挑战性。我们提出了 CoachMe，这是一种基于参考的模型，用于分析学习者的运动与参考在时间和物理方面的差异。这种方法既可以学习领域知识，也可以获得类似教练的思维过程，可以有效识别运动错误并提供反馈来解释如何改进。在本文中，我们说明了 CoachMe 如何通过从一般动作中学习，然后利用有限的数据来很好地适应滑冰和拳击等特定运动。实验表明，CoachMe 提供高质量的指导，而不是仅仅以教练的语气提供指导，但没有关键信息。CoachMe 在花样滑冰方面的 G-Eval 中比 GPT-4o 高出 31.6%，在拳击方面比 GPT-4o 高出 58.3%。分析进一步证实，它详细阐述了生成指令中的错误及其相应的改进方法。你可以在这里找到 CoachMe： <a href="https://motionxperts.github.io/"target="_blank" rel="external nofollow noopener noreferrer">https://motionxperts.github.io/</a></p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 09：01：39 UTC</p>
<h2 id="97-代码语义有帮助吗代码大语言模型基于执行跟踪信息的综合研究-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11686"target="_blank" rel="external nofollow noopener noreferrer">#97</a> <a href="https://papers.cool/arxiv/2509.11686"target="_blank" rel="external nofollow noopener noreferrer">代码语义有帮助吗？代码大语言模型基于执行跟踪信息的综合研究</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Jian Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Wang), [Xiaofei Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaofei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaofei</a> Xie), [Qiang Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiang</a> Hu), [Shangqing Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shangqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shangqing</a> Liu), [Yi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi</a> Li)</p>
<p>代码大型语言模型（Code LLMs）以其令人印象深刻的功能开启了编程的新时代。然而，最近的研究表明，它们在推理运行时行为和理解程序实际功能的能力方面存在严重局限性，这给它们的训练后和实际部署带来了重大挑战。具体来说，代码法学硕士遇到了两个主要问题：（1）缺乏对程序执行行为的推理能力，因为它们难以解释程序在运行时实际做什么，以及（2）语义信息（例如执行轨迹）在现有方法中的表示不一致和分散，这阻碍了它们有效概括和推理的能力。这些挑战凸显了需要更系统的方法来增强代码法学硕士的推理能力。为了解决这些问题，我们引入了一个通用框架来支持将语义信息~（例如执行跟踪）集成到代码任务相关提示中，并进行全面的研究，以探索语义信息在增强代码LLM推理能力方面的作用。具体来说，我们专注于研究基于痕迹的语义信息在促进代码法学硕士的监督微调~（SFT）和后阶段推理方面的有用性。实验结果出人意料地与之前的工作不一致，并表明语义信息对 Code LLM 的 SFT 和测试时间缩放的有用性有限。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 08：38：01 UTC</p>
<h2 id="98-paraeqsa并行和异步具身问题的调度和回答-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11663"target="_blank" rel="external nofollow noopener noreferrer">#98</a> <a href="https://papers.cool/arxiv/2509.11663"target="_blank" rel="external nofollow noopener noreferrer">ParaEQsA：并行和异步具身问题的调度和回答</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Haisheng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haisheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haisheng</a> Wang), [Weiming Zhi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiming</a> Zhi)</p>
<p>本文提出了具身问答（EQsA）问题，引入了相应的基准，并提出了解决该问题的系统。经典具身问答 （EQA） 通常被表述为通过主动探索 3D 环境来回答一个问题。然而，实际部署通常需要处理多个问题，这些问题可能异步到达并带来不同的紧迫性。我们将此设置正式化为具身问答 （EQsA），并提出 ParaEQsA，这是一个用于并行、紧急感知调度和回答的框架。ParaEQsA 利用问题之间共享的组记忆模块来减少冗余探索，并利用优先级计划模块来动态安排问题。为了评估此设置，我们贡献了并行异步具身问题 （PAEQ） 基准，其中包含 40 个室内场景和每个场景 5 个问题（总共 200 个），具有异步后续问题和紧急性标签。我们进一步提出了 EQsA 性能的指标：直接回答率 （DAR） 和归一化紧急加权延迟 （NUWL），它们共同衡量该系统的效率和响应能力。ParaEQsA 的性能始终优于从最近的 EQA 系统中改编的强顺序基线，同时减少探索和延迟。实证评估调查了我们框架内优先级、紧迫性建模、空间范围、奖励估计和依赖推理的相对贡献。总之，这些结果表明，紧急感知的并行调度是使具身智能体在现实的多问题工作负载下响应迅速和高效的关键。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-15 08：02：55 UTC</p>
<h2 id="99-mindvl迈向昇腾npu上多模态大语言模型的高效训练-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11662"target="_blank" rel="external nofollow noopener noreferrer">#99</a> <a href="https://papers.cool/arxiv/2509.11662"target="_blank" rel="external nofollow noopener noreferrer">MindVL：迈向昇腾NPU上多模态大语言模型的高效训练</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Feilong Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feilong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feilong</a> Chen), [Yijiang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yijiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yijiang</a> Liu), [Yi Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi</a> Huang), [Hao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hao</a> Wang), [Miren Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Miren"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Miren</a> Tian), [Ya-Qi Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ya-Qi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ya-Qi</a> Yu), [Minghui Liao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minghui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minghui</a> Liao), [Jihao Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jihao</a> Wu)</p>
<p>我们提出了 MindVL，这是一种在 Ascend NPU 上训练的多模态大语言模型。与Qwen2.5-VL类似，MindVL采用原生分辨率的Vision Transformers，使其能够以原始可变分辨率处理图像。这种设计避免了固定分辨率平铺造成的退化，同时保留了细粒度的细节和全局布局，这对于复杂的图表和图表等视觉密集的内容至关重要。为了确保 MindVL 在昇腾 NPU 上的顺利训练，我们开发了 Mindspeed-MLLM，这是一个专为昇腾 NPU 量身定制的分布式多模态训练框架。为了保持培训的准确性，我们对某些操作员实施了等效的替换。MindVL经历了三个阶段的训练过程，即预热阶段、多任务训练阶段和监督指令调优阶段，以逐步增强其能力。这个过程从基本的视觉和多模态预训练开始，然后是大规模的多重询问训练和指令调整。我们还采用了多模态数据打包和混合并行技术，显著提高了端到端的训练速度。为了进一步提高模型性能，我们专门引入了测试时分辨率搜索和模型权重平均。值得注意的是，尽管使用了 Qwen2.5-VL 所需的训练数据的 1/10 左右，但 MindVL 在评估一般多模态理解和文档/表格理解方面取得了与 Qwen2.5-VL 相当的性能。除了总分之外，MindVL 在 OCR 评估中也表现出色。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a></p>
<p><strong>发布</strong>: 2025-09-15 08：00：31 UTC</p>
<h2 id="100-dtgen基于生成式扩散的少样本数据增强用于细粒度脏餐具识别-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11661"target="_blank" rel="external nofollow noopener noreferrer">#100</a> <a href="https://papers.cool/arxiv/2509.11661"target="_blank" rel="external nofollow noopener noreferrer">DTGen：基于生成式扩散的少样本数据增强，用于细粒度脏餐具识别</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Lifei Hao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lifei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lifei</a> Hao), [Yue Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yue</a> Cheng), [Baoqi Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baoqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baoqi</a> Huang), [Bing Jia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bing</a> Jia), [Xuandong Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuandong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuandong</a> Zhao)</p>
<p>智能餐具清洗是食品安全和智能家居的关键应用，但现有方法受限于粗粒度分类和少发数据稀缺，难以满足产业化要求。我们提出了DTGen，这是一种基于生成扩散模型的少量数据增强方案，专门用于细粒度脏餐具识别。DTGen 通过 LoRA 实现高效的领域专业化，通过结构化提示生成多样化的脏图像，并通过基于 CLIP 的跨模态过滤确保数据质量。在极其有限的真实少样本条件下，DTGen可以合成几乎无限的高质量样品，显著提高分级机性能，支持细粒度脏餐具识别。我们进一步阐述了轻量级部署策略，承诺将 DTGen 的优势转移到嵌入式洗碗机上，并与清洁程序集成，以智能调节能源消耗和洗涤剂的使用。研究结果表明，DTGen不仅验证了生成式AI在少镜头工业视觉中的价值，还为自动化餐具清洗和食品安全监控提供了可行的部署路径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 07：59：34 UTC</p>
<h2 id="101-mallm多智能体大型语言模型框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11656"target="_blank" rel="external nofollow noopener noreferrer">#101</a> <a href="https://papers.cool/arxiv/2509.11656"target="_blank" rel="external nofollow noopener noreferrer">MALLM：多智能体大型语言模型框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jonas Becker](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonas</a> Becker), [Lars Benedikt Kaesberg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lars"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lars</a> Benedikt Kaesberg), [Niklas Bauer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Niklas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Niklas</a> Bauer), [Jan Philip Wahle](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jan</a> Philip Wahle), [Terry Ruas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Terry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Terry</a> Ruas), [Bela Gipp](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bela"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bela</a> Gipp)</p>
<p>多代理辩论 （MAD） 已经证明了通过扩展测试时计算和利用专业知识来增强集体智慧的能力。当前的多代理辩论框架通常设计用于工具使用，缺乏综合评估，或者提供代理角色、响应生成器、讨论范式和决策协议的有限可配置性。我们介绍了 MALLM（多智能体大型语言模型），这是一个开源框架，可以对 MAD 组件进行系统分析。MALLM 提供超过 144 种独特的 MAD 配置，包括 （1） 代理角色（例如专家、个性）、（2） 响应生成器（例如批判性、推理）、（3） 讨论范式（例如记忆、中继）和 （4） 决策协议（例如投票、共识）。MALLM 使用简单的配置文件来定义辩论。此外，MALLM 可以加载任何文本 Huggingface 数据集（例如 MMLU-Pro、WinoGrande），并提供评估管道以方便比较 MAD 配置。MALLM 专为研究人员量身定制，提供了一个了解多智能体辩论核心的窗口，促进对其组成部分及其相互作用的理解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">多智能体系统</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-15 07：48：02 UTC</p>
<h2 id="102-ethicsmh心理健康人工智能伦理推理的试点基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11648"target="_blank" rel="external nofollow noopener noreferrer">#102</a> <a href="https://papers.cool/arxiv/2509.11648"target="_blank" rel="external nofollow noopener noreferrer">EthicsMH：心理健康人工智能伦理推理的试点基准</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Sai Kartheek Reddy Kasu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sai</a> Kartheek Reddy Kasu)</p>
<p>大型语言模型 （LLM） 在心理健康和其他敏感领域的部署引发了有关道德推理、公平和负责任的一致性的紧迫问题。然而，现有的道德和临床决策基准并没有充分反映心理健康实践中遇到的独特伦理困境，其中保密性、自主性、仁慈性和偏见经常交叉。为了解决这一差距，我们推出了心理健康伦理推理 （EthicsMH），这是一个包含 125 个场景的试点数据集，旨在评估人工智能系统如何在治疗和精神病学环境中驾驭道德情况。每个场景都丰富了结构化字段，包括多个决策选项、专家一致的推理、预期模型行为、现实世界的影响和多利益相关者的观点。这种结构不仅可以评估决策的准确性，还可以评估解释质量和与专业规范的一致性。尽管规模不大且采用模型辅助生成开发，但 EthicsMH 建立了一个连接人工智能伦理和心理健康决策的任务框架。通过发布该数据集，我们的目标是提供一种种子资源，可以通过社区和专家的贡献进行扩展，促进能够负责任地处理社会一些最微妙决策的人工智能系统的发展。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-15 07：35：35 UTC</p>
<h2 id="103-用于鲁棒语义通信的与任务无关的可学习加权知识库方案-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11636"target="_blank" rel="external nofollow noopener noreferrer">#103</a> <a href="https://papers.cool/arxiv/2509.11636"target="_blank" rel="external nofollow noopener noreferrer">用于鲁棒语义通信的与任务无关的可学习加权知识库方案</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shiyao Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiyao</a> Jiang), [Jian Jiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Jiao), [Xingjian Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xingjian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xingjian</a> Zhang), [Ye Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ye</a> Wang), [Dusit Niyato](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dusit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dusit</a> Niyato), [Qinyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qinyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qinyu</a> Zhang)</p>
<p>随着即将到来的第六代（6G）网络中多样化和海量数据的出现，与任务无关的语义通信系统被认为可以提供强大的智能服务。在本文中，我们提出了一种与任务无关的可学习加权知识库语义通信（TALSC）框架，用于鲁棒图像传输，以解决现实世界的KB异构数据偏差，包括标签翻转噪声和类不平衡。TALSC 框架包含作为元学习器的样本置信度模块 （SCM） 和作为学习器的语义编码网络。学习者根据可学习加权 KB （LW-KB） 提供的经验知识进行更新。同时，元学习器根据任务损失反馈评估样本的显著性，并调整学习器的更新策略，以增强未知任务语义恢复的鲁棒性。为了在 SCM 参数和显着性评估精度之间取得平衡，我们设计了一种 SCM 网格扩展 （SCM-GE） 方法，将 Kolmogorov-Arnold 网络 （KAN） 嵌入到 SCM 中，该方法利用了 KAN 中样条细化的概念，无需重新训练即可实现具有可定制粒度的可扩展 SCM。仿真表明，与最先进的方法相比，TALSC框架有效地减轻了与任务无关的图像语义通信中翻转噪声和类不平衡的影响，实现了至少12%的语义恢复精度（SRA）和多尺度结构相似性（MS-SSIM）。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IT"target="_blank" rel="external nofollow noopener noreferrer">信息论</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a></p>
<p><strong>发布</strong>: 2025-09-15 07：10：21 UTC</p>
<h2 id="104-合理的安全调整通过回答后检查确保越狱防御-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11629"target="_blank" rel="external nofollow noopener noreferrer">#104</a> <a href="https://papers.cool/arxiv/2509.11629"target="_blank" rel="external nofollow noopener noreferrer">合理的安全调整：通过“回答后检查”确保越狱防御</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Chentao Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chentao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chentao</a> Cao), [Xiaojun Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaojun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaojun</a> Xu), [Bo Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Han), [Hang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hang</a> Li)</p>
<p>随着大型语言模型 （LLM） 功能不断进步，确保其免受越狱攻击的安全仍然是一个严峻的挑战。在本文中，我们介绍了一种称为 Answer-Then-Check 的新型安全对齐方法，该方法通过应用思维能力来缓解越狱问题，从而在向用户提供最终答案之前增强 LLM 对恶意提示的鲁棒性。我们的方法使模型能够直接回答他们思想中的问题，然后在决定是否提供之前批判性地评估其安全性。为了实现这种方法，我们构建了 Reasoned Safety Alignment （ReSA） 数据集，其中包含 80K 个示例，这些示例通过直接响应教模型进行推理，然后分析其安全性。实验结果表明，该方法实现了帕累托边界，具有优越的安全能力，同时降低了超额拒绝基准的过度拒绝率。值得注意的是，使用 ReSA 微调的模型在 MMLU、MATH500 和 HumanEval 等基准测试中保持了一般推理能力。此外，我们的方法使模型具有执行安全完成的能力。与只能拒绝有害查询的事后方法不同，我们的模型可以为敏感主题（例如自残）提供有用且安全的替代响应。此外，我们发现，在仅 500 个示例的一小部分上进行训练可以达到与使用完整数据集相当的性能，这表明安全对齐可能需要的数据可能比之前假设的要少。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 06：47：35 UTC</p>
<h2 id="105-speca使用推测特征缓存加速扩散变压器-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11628"target="_blank" rel="external nofollow noopener noreferrer">#105</a> <a href="https://papers.cool/arxiv/2509.11628"target="_blank" rel="external nofollow noopener noreferrer">SpeCa：使用推测特征缓存加速扩散变压器</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jiacheng Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiacheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiacheng</a> Liu), [Chang Zou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chang</a> Zou), [Yuanhuiyi Lyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuanhuiyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuanhuiyi</a> Lyu), [Fei Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fei</a> Ren), [Shaobo Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaobo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaobo</a> Wang), [Kaixin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaixin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaixin</a> Li), [Linfeng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Linfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Linfeng</a> Zhang)</p>
<p>扩散模型彻底改变了高保真图像和视频合成，但它们的计算需求对于实时应用来说仍然令人望而却步。这些模型面临两个基本挑战：阻止并行化的严格时间依赖关系，以及每个去噪步骤所需的计算密集型前向传递。从大型语言模型中的推测解码中汲取灵感，我们提出了 SpeCa，这是一种新颖的“预测然后验证”加速框架，可以有效解决这两个限制。SpecA 的核心创新在于将推测采样引入扩散模型，根据完全计算的参考时间步长预测后续时间步长的中间特征。我们的方法实现了一种无参数验证机制，可以有效地评估预测可靠性，使实时决策能够接受或拒绝每个预测，同时产生的计算开销可以忽略不计。此外，SpeCa 引入了样本自适应计算分配，可根据生成复杂性动态调节资源，为更简单的样本分配减少的计算，同时保留复杂实例的密集处理。实验表明，在 FLUX 上加速 6.34 倍，质量下降最小（下降 5.5%），在保持生成保真度的同时在 DiT 上加速 7.3 倍，HunyuanVideo 在 6.1 倍加速下获得 79.84% 的 VBench 分数。该验证机制产生的开销最小（占全部推理成本的 1.67%-3.5%），为高效的扩散模型推理建立了一种新的范式，同时即使在激进的加速比下也能保持生成质量。我们的代码已在 Github 中发布：\textbf{https://github.com/Shenyi-Z/Cache4Diffusion}</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-15 06：46：22 UTC</p>
<h2 id="106-自动创建和扩充框架用于改进企业-api-作为工具的调用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11626"target="_blank" rel="external nofollow noopener noreferrer">#106</a> <a href="https://papers.cool/arxiv/2509.11626"target="_blank" rel="external nofollow noopener noreferrer">自动创建和扩充框架，用于改进企业 API 作为工具的调用</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Prerna Agarwal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prerna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prerna</a> Agarwal), [Himanshu Gupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Himanshu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Himanshu</a> Gupta), [Soujanya Soni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soujanya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soujanya</a> Soni), [Rohith Vallam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rohith"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rohith</a> Vallam), [Renuka Sindhgatta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Renuka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Renuka</a> Sindhgatta), [Sameep Mehta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sameep"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sameep</a> Mehta)</p>
<p>大型语言模型 （LLM） 的最新进展导致了能够进行复杂推理和与外部工具交互的代理的开发。在企业环境中，此类工具的有效使用通常由应用程序编程接口 （API） 支持，但由于文档质量差、输入或输出模式复杂以及大量作而受到阻碍。这些挑战使工具选择变得困难，并将有效载荷形成的精度降低多达 25%。我们提出了 ACE，这是一个自动化工具创建和丰富框架，可将企业 API 转换为 LLM 兼容工具。ACE，（i） 生成带有参数描述和示例的丰富工具规范，以提高选择和调用的准确性，以及 （ii） 结合动态筛选机制，在运行时过滤相关工具，降低提示复杂性，同时保持可扩展性。我们在专有和开源 API 上验证了我们的框架，并演示了它与代理框架的集成。据我们所知，ACE 是第一个端到端框架，可自动为 LLM 代理创建、扩充和动态选择企业 API 工具。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 06：41：54 UTC</p>
<h2 id="107-对测试时隐私产生不确定性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11625"target="_blank" rel="external nofollow noopener noreferrer">#107</a> <a href="https://papers.cool/arxiv/2509.11625"target="_blank" rel="external nofollow noopener noreferrer">对测试时隐私产生不确定性</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Muhammad H. Ashiq](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhammad</a> H. Ashiq), [Peter Triantafillou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peter"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peter</a> Triantafillou), [Hung Yun Tseng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hung</a> Yun Tseng), [Grigoris G. Chrysos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Grigoris"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Grigoris</a> G. Chrysos)</p>
<p>取消学习是消除机器学习模型中数据影响的主要方法。然而，即使在取消学习之后，模型通常也会继续以高置信度对未学习的数据产生相同的预测。攻击者可能会利用这种持续行为，对不正确或过时的数据进行可靠的模型预测来伤害用户。我们将这种威胁模型称为<em>测试时隐私</em>，这种威胁模型无法防范。特别是，具有完全模型访问权限的对手可以绕过任何确保测试时隐私的朴素防御。为了应对这一威胁，我们引入了一种算法，该算法可以扰动模型权重，以在受保护实例上引起最大的不确定性，同时保持其余实例的准确性。我们的核心算法基于对帕累托最优目标的微调，该目标明确平衡了测试时隐私与效用。我们还提供了一种可证明的近似算法，该算法可实现 (ε,δ) 没有凸性假设的保证。然后，我们证明了一个紧密的、非空洞的界限，它表征了我们的算法所遭受的隐私与效用权衡。根据经验，我们的方法得到&gt;3× 比预训练更强的不确定性&lt;0.2% 在各种图像识别基准测试中准确性下降。总而言之，该框架提供了一种工具来保证为最终用户提供额外保护。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a></p>
<p><strong>发布</strong>: 2025-09-15 06：38：57 UTC</p>
<h2 id="108-用于网络状态分类的时态和跨变量模式的动态自适应解析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11601"target="_blank" rel="external nofollow noopener noreferrer">#108</a> <a href="https://papers.cool/arxiv/2509.11601"target="_blank" rel="external nofollow noopener noreferrer">用于网络状态分类的时态和跨变量模式的动态自适应解析</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yuan Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Gao), [Xuelong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuelong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuelong</a> Wang), [Zhenguo Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenguo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenguo</a> Dong), [Yong Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yong</a> Zhang)</p>
<p>有效的网络状态分类是确保网络安全和优化性能的首要任务。现有的深度学习模型在这一领域取得了长足的进步。一些方法擅长分析交通数据中发现的复杂时间周期性，而基于图的方法则擅长对不同变量之间的动态依赖关系进行建模。然而，仍然存在一个关键的权衡，因为这些方法很难同时捕捉这两种特征。专注于时间模式的模型通常会忽略关键的变量依赖关系，而那些以依赖关系为中心的模型可能无法捕获细粒度的时间细节。为了解决这种权衡，我们引入了 DAPNet，这是一个基于混合专家架构的框架。DAPNet 集成了三个用于周期性分析、动态跨变量相关建模和混合时间特征提取的专用网络。可学习门控网络根据输入样本动态地为专家分配权重，并计算其输出的加权融合。此外，混合正则化损失函数确保了稳定的训练并解决了类不平衡的常见问题。在两个大规模网络入侵检测数据集上的大量实验（CICIDS2017/2018）验证了DAPNet在目标应用中的更高精度。在十个公共UEA基准数据集中评估了架构设计的通用性，将DAPNet定位为网络状态分类的专用框架。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 05：32：32 UTC</p>
<h2 id="109-gbpp通过两阶段学习为机器人提供可把握的碱基放置预测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11594"target="_blank" rel="external nofollow noopener noreferrer">#109</a> <a href="https://papers.cool/arxiv/2509.11594"target="_blank" rel="external nofollow noopener noreferrer">GBPP：通过两阶段学习为机器人提供可把握的碱基放置预测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jizhuo Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jizhuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jizhuo</a> Chen), [Diwen Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Diwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Diwen</a> Liu), [Jiaming Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaming</a> Wang), [Harold Soh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Harold"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Harold</a> Soh)</p>
<p>GBPP 是一种基于快速学习的评分器，可从单个 RGB-D 快照中选择用于抓取的机器人基本姿势。该方法采用两阶段课程：（1）简单的距离可见性规则以低成本自动标记大型数据集;（2） 一组较小的高保真模拟试验改进模型以匹配真实的掌握结果。带有 MLP 的 PointNet++ 风格点云编码器可对候选位姿的密集网格进行评分，从而实现快速在线选择，而无需进行全面的任务和运动优化。在模拟和真实的移动机械手上，GBPP 的性能优于接近和几何仅基线，选择更安全、更易于到达的姿势，并在错误时优雅地降级。结果为数据高效、几何感知的基础放置提供了实用的秘诀：使用廉价的启发式方法进行覆盖，然后通过有针对性的仿真进行校准。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 05：25：40 UTC</p>
<h2 id="110-无监督可见红外人再识别的分层身份学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11587"target="_blank" rel="external nofollow noopener noreferrer">#110</a> <a href="https://papers.cool/arxiv/2509.11587"target="_blank" rel="external nofollow noopener noreferrer">无监督可见红外人再识别的分层身份学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Haonan Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haonan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haonan</a> Shi), [Yubin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yubin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yubin</a> Wang), [De Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=De"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=De</a> Cheng), [Lingfeng He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingfeng</a> He), [Nannan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nannan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nannan</a> Wang), [Xinbo Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinbo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinbo</a> Gao)</p>
<p>无监督可见红外人员重新识别 （USVI-ReID） 旨在通过减少模态差距，同时最大限度地减少对昂贵的手动注释的依赖，从未标记的跨模态人员数据集中学习模态不变图像特征。现有方法通常使用基于聚类的对比学习来解决 USVI-ReID，该学习通过单个聚类中心代表一个人。然而，它们主要关注每个集群内图像的共性，而忽略了它们之间更细粒度的差异。为了解决这一限制，我们提出了一个分层身份学习 （HIL） 框架。由于每个聚类可能包含几个较小的子聚类，这些子聚类反映了图像之间的细粒度变化，因此我们通过二级聚类为每个现有的粗粒度聚类生成多个记忆。此外，我们提出了多中心对比学习（MCCL）来优化表示，以增强模态内聚类并最大限度地减少跨模态差异。为了进一步提高跨模态匹配质量，我们设计了一种双向反向选择传输（BRST）机制，通过对伪标签进行双向匹配来建立可靠的跨模态对应关系。在 SYSU-MM01 和 RegDB 数据集上进行的大量实验表明，所提出的方法优于现有方法。源代码可在以下网址获得：https://github.com/haonanshi0125/HIL。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 05：10：43 UTC</p>
<h2 id="111-dstack机密容器的零信任框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11555"target="_blank" rel="external nofollow noopener noreferrer">#111</a> <a href="https://papers.cool/arxiv/2509.11555"target="_blank" rel="external nofollow noopener noreferrer">Dstack：机密容器的零信任框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shunfan Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shunfan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shunfan</a> Zhou), [Kevin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kevin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kevin</a> Wang), [Hang Yin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hang</a> Yin)</p>
<p>Web3 应用程序需要执行平台，这些平台能够保持机密性和完整性，而不依赖中心化的信任机构。虽然可信执行环境 （TEE） 为机密计算提供了有前途的功能，但当前的实施在应用于 Web3 上下文时面临重大限制，特别是在安全可靠性、抗审查性和供应商独立性方面。本文介绍了 dstack，这是一个综合框架，可将原始 TEE 技术转变为真正的 Zero Trust 平台。我们介绍了三项关键创新：（1） 便携式机密容器，可在异构 TEE 环境中实现无缝工作负载迁移，同时保持安全保证，（2） 去中心化代码管理，利用智能合约对 TEE 应用程序进行透明治理，以及 （3） 可验证域管理，确保在没有集中权限的情况下安全且可验证的应用程序身份。这些创新是通过三个核心组件实现的：dstack-OS、dstack-KMS 和 dstack-Gateway。他们共同展示了如何实现 VM 级 TEE 解决方案的性能优势和 Web3 应用程序所需的去信任保证。我们的评估表明，dstack 提供了全面的安全保障，同时保持了实际应用的实用性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 03：36：27 UTC</p>
<h2 id="112-hichunk使用分层分块评估和增强检索增强生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11552"target="_blank" rel="external nofollow noopener noreferrer">#112</a> <a href="https://papers.cool/arxiv/2509.11552"target="_blank" rel="external nofollow noopener noreferrer">HiChunk：使用分层分块评估和增强检索增强生成</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wensheng Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wensheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wensheng</a> Lu), [Keyu Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keyu</a> Chen), [Ruizhi Qiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruizhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruizhi</a> Qiao), [Xing Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xing</a> Sun)</p>
<p>检索增强生成（RAG）通过整合外部知识源来增强语言模型的响应能力。然而，文档分块作为RAG系统的重要组成部分，往往缺乏有效的评估工具。本文首先分析了为什么现有的RAG评估基准不足以评估文档分块质量，特别是由于证据稀疏性。基于这一结论，我们提出了HiCBench，它包括人工标注的多级文档分块点、合成的证据密集问答（QA）对及其相应的证据来源。此外，我们还引入了 HiChunk 框架，这是一个基于微调 LLM 的多级文档结构框架，结合 Auto-Merge 检索算法来提高检索质量。实验表明，HiCBench 有效地评估了不同分块方法对整个 RAG 管道的影响。此外，HiChunk 在合理的时间消耗内实现了更好的分块质量，从而增强了 RAG 系统的整体性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 03：32：50 UTC</p>
<h2 id="113-ui-s1通过半在线强化学习推进-gui-自动化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11543"target="_blank" rel="external nofollow noopener noreferrer">#113</a> <a href="https://papers.cool/arxiv/2509.11543"target="_blank" rel="external nofollow noopener noreferrer">UI-S1：通过半在线强化学习推进 GUI 自动化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhengxi Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhengxi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhengxi</a> Lu), [Jiabo Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiabo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiabo</a> Ye), [Fei Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fei</a> Tang), [Yongliang Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yongliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yongliang</a> Shen), [Haiyang Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haiyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haiyang</a> Xu), [Ziwei Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziwei</a> Zheng), [Weiming Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiming</a> Lu), [Ming Yan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ming</a> Yan), [Fei Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fei</a> Huang), [Jun Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jun</a> Xiao), [Yueting Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yueting"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yueting</a> Zhuang)</p>
<p>图形用户界面 （GUI） 代理在通过强化学习自动化复杂的用户界面交互方面取得了显着进展。然而，目前的方法面临一个根本的困境：离线RL可以在预先收集的轨迹上进行稳定训练，但由于缺乏轨迹级奖励信号，难以执行多步骤任务;在线 RL 通过环境交互捕获这些信号，但奖励稀少且部署成本过高。为了解决这个问题，我们提出了半在线强化学习，这是一种在离线轨迹上模拟在线强化学习的新范式。在每个推出过程中，我们都会在多轮对话中保留原始模型输出，其中补丁模块自适应地恢复推出和专家轨迹之间的分歧。为了捕捉长期训练信号，半在线RL在奖励计算中引入了贴现的未来收益，并以加权的阶梯级和情节级优势优化了策略。我们进一步引入了半在线绩效 （SOP），这是一个更符合真实在线绩效的指标，可作为实际评估的实用且有效的代理。实验表明，我们的半在线RL在4个动态基准测试中实现了7B模型中的SOTA性能，与基础模型相比有显著提升（例如，AndroidWorld上+12.0%，AITW上+23.8%），在弥合离线训练效率和在线多回合推理之间的差距方面取得了重大进展。该代码可在 <a href="https://github.com/X-PLUG/MobileAgent/tree/main/UI-S1"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/X-PLUG/MobileAgent/tree/main/UI-S1</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 03：24：08 UTC</p>
<h2 id="114-harp通过推理子空间投影进行幻觉检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11536"target="_blank" rel="external nofollow noopener noreferrer">#114</a> <a href="https://papers.cool/arxiv/2509.11536"target="_blank" rel="external nofollow noopener noreferrer">HARP：通过推理子空间投影进行幻觉检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Junjie Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junjie</a> Hu), [Gang Tu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gang</a> Tu), [ShengYu Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=ShengYu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=ShengYu</a> Cheng), [Jinxin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinxin</a> Li), [Jinting Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinting"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinting</a> Wang), [Rui Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rui</a> Chen), [Zhilong Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhilong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhilong</a> Zhou), [Dongbo Shan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongbo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongbo</a> Shan)</p>
<p>大型语言模型 （LLM） 中的幻觉对其在关键决策中的可靠使用构成了主要障碍。尽管现有的幻觉检测方法提高了准确性，但它们仍然难以理清语义和推理信息并保持稳健性。为了应对这些挑战，我们提出了 HARP（通过推理子空间投影进行幻觉检测），这是一种新型的幻觉检测框架。HARP 建立了 LLM 的隐藏状态空间可以分解为语义子空间和推理子空间的直接和，其中前者编码语言表达，后者捕获内部推理过程。此外，我们证明了Unembedding层可以解开这些子空间，并通过对其参数应用奇异值分解（SVD），获得了跨越语义和推理子空间的基向量。最后，HARP将隐藏状态投影到推理子空间的基向量上，然后将生成的投影用作LLM幻觉检测的输入特征。通过使用这些投影，HARP 将特征的尺寸减小到原始尺寸的大约 5%，滤除大部分噪声，并实现增强的鲁棒性。跨多个数据集的实验表明，HARP实现了最先进的幻觉检测性能;特别是，它在 TriviaQA 上实现了 92.8% 的 AUROC，比之前的最佳方法高出 7.5%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 03：02：33 UTC</p>
<h2 id="115-知道你不知道什么提前退出-dnn-的选择性预测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11520"target="_blank" rel="external nofollow noopener noreferrer">#115</a> <a href="https://papers.cool/arxiv/2509.11520"target="_blank" rel="external nofollow noopener noreferrer">知道你不知道什么：提前退出 DNN 的选择性预测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Divya Jyoti Bajpai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Divya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Divya</a> Jyoti Bajpai), [Manjesh Kumar Hanawal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manjesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manjesh</a> Kumar Hanawal)</p>
<p>深度神经网络 （DNN） 的推理延迟和可信度是在敏感任务等关键应用程序中部署它们的瓶颈。早期退出 （EE） DNN 通过允许样本在预测类上获得“高”置信度分数时退出中间层来克服延迟问题。然而，众所周知，DNN 表现出过度自信，这可能导致许多样本提前退出并使 EE 策略不可信。我们使用选择性预测 （SP） 来克服这个问题，方法是检查样本的“硬度”，而不仅仅是依赖置信度分数。我们提出了SPEED，这是一种新方法，在执行EE之前，在每一层使用延迟分类器（DC）来检查样品的硬度。具体来说，DC 确定样本是否难以在中间层预测，从而导致幻觉，并将其推迟给专家。及早检测用于推理的硬样本可以防止计算资源的浪费，并通过将硬样本推迟给专家来提高信任度。我们证明，EE 与 SP 的辅助提高了准确性和延迟。我们的方法通过以下方式最大限度地降低了错误预测的风险 50% 加速2.05× 与最后一层相比。匿名源代码可在以下网址获得 <a href="https://github.com/Div290/SPEED"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Div290/SPEED</a></p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 02：19：09 UTC</p>
<h2 id="116-通过整体句子语义进行词汇替换的无监督候选人排名-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11513"target="_blank" rel="external nofollow noopener noreferrer">#116</a> <a href="https://papers.cool/arxiv/2509.11513"target="_blank" rel="external nofollow noopener noreferrer">通过整体句子语义进行词汇替换的无监督候选人排名</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhongyang Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongyang</a> Hu), [Naijie Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Naijie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Naijie</a> Gu), [Xiangzhi Tao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiangzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiangzhi</a> Tao), [Tianhui Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianhui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianhui</a> Gu), [Yibing Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yibing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yibing</a> Zhou)</p>
<p>词汇替换的一个关键子任务是对给定的候选词进行排名。一种常见的方法是将目标词替换为原始句子中的候选词，并将修改后的句子输入模型以捕获替换前后的语义差异。然而，有效地模拟候选替换对目标词及其上下文的双向影响仍然具有挑战性。现有方法通常仅关注目标位置的语义变化或依赖于多个评估指标的参数调整，因此很难准确表征语义变化。为了解决这个问题，我们研究了两种方法：一种基于注意力权重，另一种利用更具可解释性的综合梯度方法，这两种方法都旨在衡量上下文标记对目标标记的影响，并通过结合原始句子和替换句子之间的语义相似性来对候选者进行排名。LS07和SWORDS数据集的实验表明，这两种方法都能提高排名性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 01：57：09 UTC</p>
<h2 id="117-复杂科学工作流程中机器学习驱动的预测性资源管理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11512"target="_blank" rel="external nofollow noopener noreferrer">#117</a> <a href="https://papers.cool/arxiv/2509.11512"target="_blank" rel="external nofollow noopener noreferrer">复杂科学工作流程中机器学习驱动的预测性资源管理</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tasnuva Chowdhury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tasnuva"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tasnuva</a> Chowdhury), [Tadashi Maeno](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tadashi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tadashi</a> Maeno), [Fatih Furkan Akman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fatih"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fatih</a> Furkan Akman), [Joseph Boudreau](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joseph"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joseph</a> Boudreau), [Sankha Dutta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sankha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sankha</a> Dutta), [Shengyu Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shengyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shengyu</a> Feng), [Adolfy Hoisie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adolfy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adolfy</a> Hoisie), [Kuan-Chieh Hsu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kuan-Chieh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kuan-Chieh</a> Hsu), [Raees Khan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raees"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raees</a> Khan), [Jaehyung Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jaehyung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jaehyung</a> Kim), [Ozgur O. Kilic](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ozgur"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ozgur</a> O. Kilic), [Scott Klasky](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Scott"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Scott</a> Klasky), [Alexei Klimentov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexei</a> Klimentov), [Tatiana Korchuganova](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tatiana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tatiana</a> Korchuganova), [Verena Ingrid Martinez Outschoorn](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Verena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Verena</a> Ingrid Martinez Outschoorn), [Paul Nilsson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Paul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Paul</a> Nilsson), [David K. Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> K. Park), [Norbert Podhorszki](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Norbert"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Norbert</a> Podhorszki), [Yihui Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yihui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yihui</a> Ren), [John Rembrandt Steele](<a href="https://arxiv.org/search/?searchtype=author&amp;query=John"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=John</a> Rembrandt Steele), [Frédéric Suter](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fr"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fr</a>édéric Suter), [Sairam Sri Vatsavai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sairam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sairam</a> Sri Vatsavai), [Torre Wenaus](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Torre"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Torre</a> Wenaus), [Wei Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Yang), [Yiming Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiming</a> Yang), [Shinjae Yoo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shinjae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shinjae</a> Yoo)</p>
<p>大型社区在科学实验中的协作努力，通常由数千名全球成员组成，反映了对探索和发现的巨大承诺。近年来，先进和复杂的数据处理在科学实验中变得越来越重要。数据处理工作流程通常由多个复杂的步骤组成，资源需求的精确规范对于每个步骤分配最佳资源以进行有效处理至关重要。由于分析场景范围广泛、社区成员的技能水平不同以及计算选项的不断增加，提前估计资源需求具有挑战性。缓解这些挑战的一种实用方法是在完成整个步骤之前，首先处理每个步骤的子集，以根据实际处理配置文件测量精确的资源利用率。虽然这种两阶段方法可以在大多数工作流程中对最佳资源进行处理，但它也存在一些缺点，例如初始不准确导致潜在故障和资源使用次优，以及等待初始处理完成的开销，这对于快速周转分析至关重要。在此背景下，我们的研究在综合工作流程管理系统生产和分布式分析（PanDA）系统中引入了一种新的机器学习模型管道。这些模型采用先进的机器学习技术来预测关键资源需求，克服了每个步骤的特征前期知识有限所带来的挑战。对资源需求的准确预测可以在工作流程管理中做出明智和主动的决策，从而提高处理跨异构资源的多样化、复杂工作流程的效率。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.DC"target="_blank" rel="external nofollow noopener noreferrer">分布式、并行和集群计算</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 01：53：30 UTC</p>
<h2 id="118-checkthat-的-claimiq2025-年比较用于验证数字声明的提示和微调语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11492"target="_blank" rel="external nofollow noopener noreferrer">#118</a> <a href="https://papers.cool/arxiv/2509.11492"target="_blank" rel="external nofollow noopener noreferrer">CheckThat 的 ClaimIQ！2025 年：比较用于验证数字声明的提示和微调语言模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Anirban Saha Anik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anirban"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anirban</a> Saha Anik), [Md Fahimul Kabir Chowdhury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Md"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Md</a> Fahimul Kabir Chowdhury), [Andrew Wyckoff](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> Wyckoff), [Sagnik Ray Choudhury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sagnik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sagnik</a> Ray Choudhury)</p>
<p>本文介绍了我们用于 CLEF 2025 CheckThat！实验室，专注于使用检索到的证据验证数字和时间主张。我们探索了两种互补的方法：使用指令调整大型语言模型 （LLM） 的零样本提示和使用参数高效的 LoRA 进行监督微调。为了提高证据质量，我们研究了几种选择策略，包括使用 BM25 和 MiniLM 进行全文档输入和前 k 句子过滤。我们使用 LoRA 微调的性能最佳模型 LLaMA 在英语验证集上取得了强大的性能。然而，测试集的显着下降凸显了泛化挑战。这些发现强调了证据粒度和模型适配对于稳健的数值事实验证的重要性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-15 01：03：09 UTC</p>
<h2 id="119-raptor四旋翼控制的基础政策-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11481"target="_blank" rel="external nofollow noopener noreferrer">#119</a> <a href="https://papers.cool/arxiv/2509.11481"target="_blank" rel="external nofollow noopener noreferrer">RAPTOR：四旋翼控制的基础政策</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jonas Eschmann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonas</a> Eschmann), [Dario Albani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dario"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dario</a> Albani), [Giuseppe Loianno](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Giuseppe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Giuseppe</a> Loianno)</p>
<p>人类在适应新的看不见的条件（例如驾驶新车）时具有非常高的数据效率。相比之下，现代机器人控制系统，如使用强化学习 （RL） 训练的神经网络策略，高度专门化于单一环境。由于这种过度拟合，众所周知，即使在模拟到现实 （Sim2Real） 差距等微小差异下，它们也会崩溃，并且需要系统识别和重新训练，以便对系统进行最小的更改。在这项工作中，我们提出了 RAPTOR，这是一种训练四旋翼控制的高自适应基础策略的方法。我们的方法能够训练单一的端到端神经网络策略来控制各种四旋翼。我们测试了 10 种不同的真实四旋翼，从 32 克到 2.4 公斤，它们在电机类型（有刷与无刷）、框架类型（软与刚性）、螺旋桨类型（2/3/4 叶片）和飞行控制器（PX4/Betaflight/Crazyflie/M5StampFly）方面也有所不同。我们发现，一个只有 2084 个参数的微型三层策略足以实现对各种平台的零样本适配。通过上下文学习进行适应是通过使用隐藏层中的重复来实现的。该策略是通过一种新颖的元模仿学习算法进行训练的，我们在其中对 1000 个四旋翼进行采样，并使用强化学习为每个四旋翼训练教师策略。随后，这 1000 名教师被提炼成一个单一的、适应性的学生政策。我们发现，在几毫秒内，由此产生的基础策略将零样本适应看不见的四旋翼。我们广泛测试了地基策略在多种条件下的能力（轨迹跟踪、室内/室外、风扰动、戳戳、不同的螺旋桨）。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-15 00：05：40 UTC</p>
<h2 id="120-设计和评估用于早期检测阿尔茨海默病和相关痴呆症的对话代理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11478"target="_blank" rel="external nofollow noopener noreferrer">#120</a> <a href="https://papers.cool/arxiv/2509.11478"target="_blank" rel="external nofollow noopener noreferrer">设计和评估用于早期检测阿尔茨海默病和相关痴呆症的对话代理</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Andrew G. Breithaupt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> G. Breithaupt), [Nayoung Choi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nayoung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nayoung</a> Choi), [James D. Finch](<a href="https://arxiv.org/search/?searchtype=author&amp;query=James"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=James</a> D. Finch), [Jeanne M. Powell](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jeanne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jeanne</a> M. Powell), [Arin L. Nelson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arin</a> L. Nelson), [Oz A. Alon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oz"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oz</a> A. Alon), [Howard J. Rosen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Howard"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Howard</a> J. Rosen), [Jinho D. Choi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinho</a> D. Choi)</p>
<p>早期发现阿尔茨海默病和相关痴呆 （ADRD） 对于及时干预至关重要，但大多数诊断被推迟到晚期。虽然全面的患者叙述对于准确诊断至关重要，但之前的工作主要集中在筛选研究，这些研究将认知状态与相互作用进行分类，而不是支持诊断过程。我们设计了语音交互式对话代理，利用大型语言模型 （LLM），从患者和线人那里引出与 ADRD 相关的叙述。我们通过对话分析（n=30）、用户调查（n=19）和盲法专家访谈（n=24）的临床验证，对30名疑似ADRD的成年人评估了该药物。该药剂检测到的症状与专家在不同症状中识别的症状非常吻合。用户赞赏代理的耐心和系统提问，这支持参与和表达复杂、难以描述的体验。这项初步工作表明，对话代理可以作为痴呆评估的结构化前端工具，强调敏感医疗保健环境中的交互设计注意事项。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 23：55：01 UTC</p>
<h2 id="121-careerpooler人工智能驱动的隐喻池模拟改善职业探索的体验和成果-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11461"target="_blank" rel="external nofollow noopener noreferrer">#121</a> <a href="https://papers.cool/arxiv/2509.11461"target="_blank" rel="external nofollow noopener noreferrer">CareerPooler：人工智能驱动的隐喻池模拟改善职业探索的体验和成果</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ziyi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziyi</a> Wang), [Ziwen Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziwen</a> Zeng), [Yuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Li), [Zijian Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zijian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zijian</a> Ding)</p>
<p>职业探索是不确定的，需要在信息有限和不可预测的结果的情况下做出决定。虽然生成式人工智能为职业指导提供了新的机会，但大多数系统依赖于线性聊天界面，这些界面会产生过于全面和理想化的建议，而忽略了现实世界轨迹的非线性和费力性。我们展示了 CareerPooler，这是一个生成式人工智能驱动的系统，它采用台球桌隐喻来模拟职业发展作为空间和叙事交互。用户击球代表里程碑、技能和随机事件，其中提示、碰撞和反弹体现了不确定性下的决策。在一项有 24 名参与者的受试者内研究中，与聊天机器人基线相比，CareerPooler 显着提高了参与度、信息获取、满意度和职业清晰度。定性研究结果表明，空间-叙事互动可以促进基于经验的学习、挫折中的复原力并减轻心理负担。我们的研究结果有助于人工智能辅助职业探索系统的设计，并更广泛地表明，基于视觉的类比交互可以使生成系统具有吸引力和令人满意。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 22：33：54 UTC</p>
<h2 id="122-超越帧跟踪基于轨迹的高效点云跟踪范式-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11453"target="_blank" rel="external nofollow noopener noreferrer">#122</a> <a href="https://papers.cool/arxiv/2509.11453"target="_blank" rel="external nofollow noopener noreferrer">超越帧跟踪：基于轨迹的高效点云跟踪范式</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [BaiChen Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=BaiChen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=BaiChen</a> Fan), [Sifan Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sifan</a> Zhou), [Jian Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Li), [Shibo Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shibo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shibo</a> Zhao), [Muqing Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muqing</a> Cao), [Qin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qin</a> Wang)</p>
<p>基于激光雷达的 3D 单目标跟踪 （3D SOT） 是机器人和自主系统中的一项关键任务。现有方法通常遵循逐帧运动估计或基于序列的范式。然而，双帧方法高效，但缺乏长期的时间背景，使其在稀疏或遮挡的场景中容易受到攻击，而处理多个点云的基于序列的方法以巨大的计算成本获得鲁棒性。为了解决这一困境，我们提出了一种基于轨迹的新范式及其实例化 TrajTrack。TrajTrack 是一个轻量级框架，它通过仅从历史边界框轨迹中隐式学习运动连续性来增强基本的双帧跟踪器，而无需额外的、昂贵的点云输入。它首先生成一个快速、显式的运动建议，然后使用隐式运动建模模块来预测未来的轨迹，进而完善和纠正最初的建议。在大规模 NuScenes 基准测试上的大量实验表明，TrajTrack 实现了新的最先进的性能，在以 4.48 FPS 运行时，在强大的基线上将跟踪精度显着提高了 56%。此外，我们还展示了TrajTrack在不同碱基跟踪器上的强大通用性。视频可在 <a href="https://www.bilibili.com/video/BV1ahYgzmEWP"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1ahYgzmEWP</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a></p>
<p><strong>发布</strong>: 2025-09-14 21：57：16 UTC</p>
<h2 id="123-类不平衡的表格数据使用预训练变压器-tabpfn-和基于-mamba-的模型预测电动汽车碰撞严重程度-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11449"target="_blank" rel="external nofollow noopener noreferrer">#123</a> <a href="https://papers.cool/arxiv/2509.11449"target="_blank" rel="external nofollow noopener noreferrer">类不平衡的表格数据：使用预训练变压器 （TabPFN） 和基于 Mamba 的模型预测电动汽车碰撞严重程度</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shriyank Somvanshi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shriyank"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shriyank</a> Somvanshi), [Pavan Hebli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pavan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pavan</a> Hebli), [Gaurab Chhetri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gaurab"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gaurab</a> Chhetri), [Subasish Das](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Subasish"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Subasish</a> Das)</p>
<p>本研究提出了一个深入的表格学习框架，用于使用德克萨斯州（2017-2023 年）的真实碰撞数据预测电动汽车 （EV） 碰撞的碰撞严重程度。在过滤纯电动汽车后，分析了 23,301 份涉及电动汽车的碰撞记录。使用 XGBoost 和随机森林的特征重要性技术将交叉路口关系、第一个有害事件、人员年龄、碰撞速度限制和星期几确定为主要预测变量，以及自动紧急制动等高级安全功能。为了解决类不平衡问题，应用了合成少数过采样技术和编辑最近邻 （SMOTEENN） 重采样。对严重程度预测使用了三个最先进的深度表格模型，即 TabPFN、MambaNet 和 MambaAttention。虽然 TabPFN 表现出很强的泛化性，但 MambaAttention 由于其基于注意力的特征重新加权，在对重伤病例进行分类方面取得了卓越的性能。研究结果强调了深度表格架构在改进碰撞严重程度预测和在电动汽车碰撞环境中实现数据驱动的安全干预方面的潜力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 21：46：17 UTC</p>
<h2 id="124-fusecodec神经编解码器的语义上下文融合和监督-pdf1-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11425"target="_blank" rel="external nofollow noopener noreferrer">#124</a> <a href="https://papers.cool/arxiv/2509.11425"target="_blank" rel="external nofollow noopener noreferrer">FuseCodec：神经编解码器的语义上下文融合和监督</a> [PDF1] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Md Mubtasim Ahasan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Md"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Md</a> Mubtasim Ahasan), [Rafat Hasan Khan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rafat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rafat</a> Hasan Khan), [Tasnim Mohiuddin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tasnim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tasnim</a> Mohiuddin), [Aman Chadha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aman</a> Chadha), [Tariq Iqbal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tariq"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tariq</a> Iqbal), [M Ashraful Amin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=M"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=M</a> Ashraful Amin), [Amin Ahsan Ali](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amin</a> Ahsan Ali), [Md Mofijul Islam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Md"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Md</a> Mofijul Islam), [A K M Mahbubur Rahman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=A"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=A</a> K M Mahbubur Rahman)</p>
<p>语音标记化可实现离散表示并促进语音语言建模。然而，现有的神经编解码器捕获了低级声学特征，忽略了人类语音固有的语义和上下文线索。虽然最近的努力引入了来自自监督语音模型的语义表示或从预训练的语言模型中合并了上下文表示，但在调整和统一语义和上下文表示方面仍然存在挑战。我们引入了 FuseCodec，它通过强大的跨模态对齐和全局知情的监督来统一声学、语义和上下文表示。我们提出了三种互补技术：（i）潜在表示融合，将语义和上下文特征直接集成到编码器潜在空间中，以实现鲁棒和统一的表示学习;（ii） 全球语义-上下文监督，使用全局汇集和广播表示来监督离散标记，以增强时间一致性和跨模态对齐;（iii） 时间对齐上下文监督，通过在本地窗口内动态匹配上下文和语音标记来加强对齐，以实现细粒度的标记级监督。我们进一步介绍了 FuseCodec-TTS，展示了我们的方法在零样本语音合成中的适用性。根据经验，FuseCodec 在 LibriSpeech 中实现了最先进的性能，在转录准确性、感知质量、清晰度和说话人相似性方面超越了 EnCodec、SpeechTokenizer 和 DAC。结果强调了上下文和语义引导的标记化对于语音标记化和下游任务的有效性。代码和预训练模型可在 <a href="https://github.com/mubtasimahasan/FuseCodec"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/mubtasimahasan/FuseCodec</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">音频和语音处理</a></p>
<p><strong>发布</strong>: 2025-09-14 20：35：36 UTC</p>
<h2 id="125-trading-r1通过强化学习使用-llm-推理进行金融交易-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11420"target="_blank" rel="external nofollow noopener noreferrer">#125</a> <a href="https://papers.cool/arxiv/2509.11420"target="_blank" rel="external nofollow noopener noreferrer">Trading-R1：通过强化学习使用 LLM 推理进行金融交易</a> [PDF2] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yijia Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yijia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yijia</a> Xiao), [Edward Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Edward"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Edward</a> Sun), [Tong Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tong</a> Chen), [Fang Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fang</a> Wu), [Di Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Di"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Di</a> Luo), [Wei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Wang)</p>
<p>开发与人类金融分析师和交易员相提并论的专业、结构化推理仍然是人工智能金融领域的核心挑战，因为市场需要可解释性和信任。传统的时间序列模型缺乏可解释性，而法学硕士在将自然语言分析转化为有纪律的、可执行的交易方面面临挑战。尽管推理法学硕士在分步规划和验证方面取得了进步，但它们在风险敏感型财务决策中的应用尚未得到充分探索。我们提出了 Trading-R1，这是一种具有财务意识的模型，它结合了战略思维和规划，用于全面的论文撰写、基于事实的分析和波动性调整的决策。Trading-R1 通过监督微调和强化学习以及从易到难的三阶段课程，将推理与交易原则结合起来。训练使用 Tauric-TR1-DB，这是一个跨越 18 个月的 100k 样本语料库、14 个股票和 5 个异构财务数据源。在六种主要股票和 ETF 上进行评估，与开源和专有指令遵循模型以及推理模型相比，Trading-R1 显示出更高的风险调整后回报和更低的回撤。该系统生成结构化的、基于证据的投资论文，支持有纪律和可解释的交易决策。Trading-R1 终端将于 <a href="https://github.com/TauricResearch/Trading-R1"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/TauricResearch/Trading-R1</a> 日发布。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/q-fin.TR"target="_blank" rel="external nofollow noopener noreferrer">交易和市场微观结构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 20：13：41 UTC</p>
<h2 id="126-通过保留预训练的表示来增强视觉-语言-行动模型的泛化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11417"target="_blank" rel="external nofollow noopener noreferrer">#126</a> <a href="https://papers.cool/arxiv/2509.11417"target="_blank" rel="external nofollow noopener noreferrer">通过保留预训练的表示来增强视觉-语言-行动模型的泛化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shresth Grover](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shresth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shresth</a> Grover), [Akshay Gopalkrishnan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Akshay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Akshay</a> Gopalkrishnan), [Bo Ai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Ai), [Henrik I. Christensen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Henrik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Henrik</a> I. Christensen), [Hao Su](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hao</a> Su), [Xuanlin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuanlin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuanlin</a> Li)</p>
<p>从视觉语言模型 （VLM） 微调的视觉语言动作 （VLA） 模型有望利用丰富的预训练表示来构建跨不同任务和环境的通才机器人。然而，对机器人数据进行直接微调通常会破坏这些表示并限制泛化。我们提出了一个框架，可以更好地保留预训练的特征，同时使其适应机器人作。我们的方法引入了三个组件：（i）双编码器设计，一个冻结视觉编码器以保留预训练特征，另一个可训练以适应任务，（ii）基于字符串的动作标记器，将连续动作转换为与模型预训练域一致的字符序列，以及（iii）将机器人演示与强调空间推理和可供性的视觉语言数据集相结合的联合训练策略。模拟和真实机器人的评估表明，与基线相比，我们的方法提高了对视觉扰动的鲁棒性、对新指令和环境的泛化以及整体任务的成功。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 20：08：56 UTC</p>
<h2 id="127-将-ai-系统基准测试视为一项学习任务flexbench-和开放-mlperf-数据集-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11413"target="_blank" rel="external nofollow noopener noreferrer">#127</a> <a href="https://papers.cool/arxiv/2509.11413"target="_blank" rel="external nofollow noopener noreferrer">将 AI 系统基准测试视为一项学习任务：FlexBench 和开放 MLPerf 数据集</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Grigori Fursin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Grigori"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Grigori</a> Fursin), [Daniel Altunay](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniel</a> Altunay)</p>
<p>MLPerf 等现有的人工智能系统基准测试通常难以跟上快速发展的人工智能领域的步伐，因此难以支持人工智能系统的明智部署、优化和共同设计决策。我们建议基准测试本身可以被定义为一项人工智能任务——在这项任务中，使用准确性、延迟、吞吐量、能耗和成本等关键指标，在不同的数据集、软件和硬件上持续评估和优化模型。为了支持这一观点，我们推出了 FlexBench：MLPerf LLM 推理基准的模块化扩展，与 HuggingFace 集成，旨在提供相关且可作的见解。基准测试结果和元数据被收集到一个开放的 MLPerf 数据集中，可以协作策划、扩展和利用该数据集进行预测建模和特征工程。我们通过 MLPerf 推理提交成功验证了 FlexBench 概念，包括在商用服务器上对 DeepSeek R1 和 LLaMA 3.3 的评估。更广泛的目标是使从业者能够做出经济高效的人工智能部署决策，以反映他们的可用资源、要求和限制。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 20：02：15 UTC</p>
<h2 id="128-从防火墙到前沿人工智能红队是网络红队的特定领域演变-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11398"target="_blank" rel="external nofollow noopener noreferrer">#128</a> <a href="https://papers.cool/arxiv/2509.11398"target="_blank" rel="external nofollow noopener noreferrer">从防火墙到前沿：人工智能红队是网络红队的特定领域演变</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Anusha Sinha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anusha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anusha</a> Sinha), [Keltin Grimes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keltin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keltin</a> Grimes), [James Lucassen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=James"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=James</a> Lucassen), [Michael Feffer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Feffer), [Nathan VanHoudnos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nathan</a> VanHoudnos), [Zhiwei Steven Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiwei</a> Steven Wu), [Hoda Heidari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hoda"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hoda</a> Heidari)</p>
<p>红队模拟对手攻击，帮助防御者找到有效的策略来在真实的作环境中保护其系统。随着越来越多的企业系统采用人工智能，红队将需要不断发展，以解决人工智能系统带来的独特漏洞和风险。我们的立场是，如果人工智能红队被认为是网络红队的特定领域演变，那么人工智能系统可以更有效地进行红队。具体来说，我们认为，采用这种框架的现有网络红队将能够更好地评估具有人工智能组件的系统，因为认识到人工智能会带来新的风险，有新的故障模式可供利用，并且通常包含无法修补的错误，这些错误会重新确定披露和缓解策略的优先级。同样，采用网络安全框架将使现有的人工智能红队能够利用经过充分测试的结构来模拟现实的对手，通过正式的交战规则促进相互问责，并提供一种模式来成熟可重复、可扩展的交战所需的工具。通过这些方式，人工智能和网络红队的合并将创建一个强大的安全生态系统，并使社区能够最好地适应快速变化的威胁形势。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a></p>
<p><strong>发布</strong>: 2025-09-14 19：21：58 UTC</p>
<h2 id="129-智能油藏决策支持结合大语言模型高级提示工程和多模态数据融合的集成框架用于石油实时运营-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11376"target="_blank" rel="external nofollow noopener noreferrer">#129</a> <a href="https://papers.cool/arxiv/2509.11376"target="_blank" rel="external nofollow noopener noreferrer">智能油藏决策支持：结合大语言模型、高级提示工程和多模态数据融合的集成框架，用于石油实时运营</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Seyed Kourosh Mahjour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seyed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seyed</a> Kourosh Mahjour), [Seyed Saman Mahjour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seyed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seyed</a> Saman Mahjour)</p>
<p>石油行业在油藏管理方面面临着前所未有的挑战，需要快速集成复杂的多模态数据集以实现实时决策支持。本研究提出了一个新颖的集成框架，将最先进的大型语言模型（GPT-4o、Claude 4 Sonnet、Gemini 2.5 Pro）与先进的提示工程技术和多模态数据融合相结合，用于全面的储层分析。该框架通过超过 50,000 份石油工程文档、思维链推理和少样本学习实现特定领域的检索增强生成 （RAG），以实现快速现场适应。多模态集成通过带有视觉转换器的专用人工智能模型处理地震解释、测井和生产数据。在 15 个不同的油藏环境中进行的现场验证显示出卓越的性能：94.2% 的油藏表征准确率、87.6% 的产量预测精度和 91.4% 的油井放置优化成功率。该系统实现了亚秒级响应时间，同时保持了 96.2% 的安全可靠性，在评估期间没有发生高风险事故。经济分析显示，与投资回收期为 8 个月的传统方法相比，成本降低了 62-78%（平均 72%）。少样本学习将现场适应时间缩短了 72%，而自动提示优化实现了推理质量的 89% 提升。该框架处理实时数据流，异常检测准确率为 96.2%，环境事件减少了 45%。我们提供详细的实验方案、基线比较、消融研究和统计显着性测试，以确保可重复性。这项研究展示了尖端人工智能技术与石油领域专业知识的实际集成，以提高运营效率、安全性和经济绩效。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a></p>
<p><strong>发布</strong>: 2025-09-14 18：13：27 UTC</p>
<h2 id="130-transformer-增强关系分类上下文性数据效率和序列复杂度的比较分析-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11374"target="_blank" rel="external nofollow noopener noreferrer">#130</a> <a href="https://papers.cool/arxiv/2509.11374"target="_blank" rel="external nofollow noopener noreferrer">Transformer 增强关系分类：上下文性、数据效率和序列复杂度的比较分析</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Bowen Jing](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Jing), [Yang Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Cui), [Tianpeng Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianpeng</a> Huang)</p>
<p>在大语言模型时代，关系提取（RE）通过将非结构化原始文本转换为结构化数据，在信息提取中发挥着重要作用（Wadhwa et al.， 2023）。在本文中，我们系统地比较了没有 Transformer 的深度监督学习方法和使用 Transformer 的深度监督学习方法的性能。我们使用了一系列非 transformer 架构，如 PA-LSTM（Zhang et al.， 2017）、C-GCN（Zhang et al.， 2018）、AGGCN（attention guide GCN）（Guo et al.， 2019），以及一系列 Transformer 架构，如 BERT、RoBERTa 和 R-BERT（Wu and He， 2019）。我们的比较包括微型 F1 等传统指标，以及不同场景、不同句子长度和不同训练数据集百分比下的评估。我们的实验是在 TACRED、TACREV 和 RE-TACRED 上进行的。结果表明，基于 Transformer 的模型优于非 Transformer 模型，实现了 80-90% 的微 F1 分数，而非 Transformer 模型为 64-67%。此外，我们还简要回顾了监督关系分类的研究历程，并讨论了大型语言模型（LLM）在关系提取中的作用和现状。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 18：11：31 UTC</p>
<h2 id="131-使用编辑作测量值检测非平稳环境中的模型漂移-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11367"target="_blank" rel="external nofollow noopener noreferrer">#131</a> <a href="https://papers.cool/arxiv/2509.11367"target="_blank" rel="external nofollow noopener noreferrer">使用编辑作测量值检测非平稳环境中的模型漂移</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Chang-Hwan Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chang-Hwan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chang-Hwan</a> Lee), [Alexander Shim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Shim)</p>
<p>强化学习 （RL） 代理通常假设静止的环境动态。然而，在医疗保健、机器人和金融等实际应用中，转换概率或奖励函数可能会演变，从而导致模型漂移。本文提出了一种新的框架，通过分析智能体行为序列的分布变化来检测这种漂移。具体来说，我们引入了一套基于编辑作的度量，以量化在静止和扰动条件下生成的状态-动作轨迹之间的偏差。我们的实验表明，即使在不同水平的噪声下，这些措施也能有效地区分漂移和非漂移场景，为非稳态RL环境中的漂移检测提供了实用的工具。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 17：48：06 UTC</p>
<h2 id="132-促进-cnn-中的形状偏差基于频率和对比正则化以实现腐败鲁棒性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11355"target="_blank" rel="external nofollow noopener noreferrer">#132</a> <a href="https://papers.cool/arxiv/2509.11355"target="_blank" rel="external nofollow noopener noreferrer">促进 CNN 中的形状偏差：基于频率和对比正则化以实现腐败鲁棒性</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Robin Narsingh Ranabhat](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Robin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Robin</a> Narsingh Ranabhat), [Longwei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Longwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Longwei</a> Wang), [Amit Kumar Patel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amit</a> Kumar Patel), [KC santosh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=KC"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=KC</a> santosh)</p>
<p>卷积神经网络 （CNN） 在图像分类方面表现出色，但仍然容易受到人类轻松处理的常见损坏的影响。这种脆弱性的一个关键原因是它们依赖局部纹理线索而不是全局物体形状——这与人类的感知形成鲜明对比。为了解决这个问题，我们提出了两种互补的正则化策略，旨在鼓励形状偏置表示并增强鲁棒性。第一个引入了辅助损耗，该损耗在原始输入和低频滤波输入之间强制保持一致，从而阻止对高频纹理的依赖。第二种结合监督对比学习，围绕类一致、形状相关的表示构建特征空间。在 CIFAR-10-C 基准测试上进行评估，这两种方法都在不降低清洁精度的情况下提高了腐败鲁棒性。我们的结果表明，损失水平正则化可以有效地引导CNN走向更具形状感知、弹性的表示。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 17：14：07 UTC</p>
<h2 id="133-人工智能治理的五层框架整合监管标准和认证-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11332"target="_blank" rel="external nofollow noopener noreferrer">#133</a> <a href="https://papers.cool/arxiv/2509.11332"target="_blank" rel="external nofollow noopener noreferrer">人工智能治理的五层框架：整合监管、标准和认证</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Avinash Agarwal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Avinash"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Avinash</a> Agarwal), [Manisha J. Nene](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manisha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manisha</a> J. Nene)</p>
<p>目的：人工智能 （AI） 系统的治理需要一种结构化的方法，将高级监管原则与实际实施联系起来。现有框架对法规如何转化为符合性机制缺乏明确性，导致合规和执行方面存在差距。本文解决了人工智能治理中的这一关键差距。方法/途径：提出了一个五层人工智能治理框架，涵盖从广泛的监管要求到具体标准、评估方法和认证流程。通过逐步聚焦的层来缩小其范围，该框架提供了一条结构化的途径来满足技术、监管和道德要求。其适用性通过人工智能公平性和人工智能事件报告的两个案例研究得到了验证。调查结果：案例研究证明了该框架能够识别法律授权、标准化和实施方面的差距。它适应全球和特定地区的人工智能治理需求，将监管要求与实际应用相结合，以提高合规性和风险管理。实际影响 - 通过提供清晰且可作的路线图，这项工作为政策制定者、监管机构和行业利益相关者提供了一个增强合规性和风险管理的模型，从而为全球人工智能治理做出了贡献。社会影响：该框架支持制定政策，建立公众信任并促进人工智能的道德使用，以造福社会。原创性/价值：本研究提出了一个五层人工智能治理框架，该框架连接了高层监管要求和实施指南。通过人工智能公平性和事件报告的案例研究得到验证，它发现了缺失标准化评估程序和报告机制等差距，为有针对性的治理措施提供了结构化基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-14 16：19：08 UTC</p>
<h2 id="134-使用kalmannet进行多目标跟踪的运动估计与语义无关的编码-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11323"target="_blank" rel="external nofollow noopener noreferrer">#134</a> <a href="https://papers.cool/arxiv/2509.11323"target="_blank" rel="external nofollow noopener noreferrer">使用KalmanNet进行多目标跟踪的运动估计，与语义无关的编码</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jian Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Song), [Wei Mei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Mei), [Yunfeng Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunfeng</a> Xu), [Qiang Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiang</a> Fu), [Renke Kou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Renke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Renke</a> Kou), [Lina Bu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lina</a> Bu), [Yucheng Long](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yucheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yucheng</a> Long)</p>
<p>运动估计是多目标跟踪 （MOT） 中的关键组成部分。它通过分析物体在连续图像帧中的位置变化来预测物体的轨迹，减少跟踪失败和身份切换。基于线性等速模型的卡尔曼滤波器（KF）是MOT中最常用的方法之一。但是，当 KF 的参数不匹配并且物体在非平稳移动时，它可能会产生不令人满意的结果。在这项工作中，我们利用学习辅助滤波器来处理 MOT 的运动估计。特别是，我们提出了一种名为语义独立卡尔曼网（SIKNet）的新方法，该方法使用语义独立编码器（SIE）通过两步对状态向量（输入特征）进行编码。首先，SIE 使用核大小为 1 的一维卷积，该卷积沿不同状态向量的同质语义元素的维度卷积，以对独立的语义信息进行编码。然后，它采用全连接层和非线性激活层对异构语义元素之间的非线性和交叉依赖信息进行编码。为了独立评估MOT中运动估计模块的性能，我们从几个开源的MOT数据集中构建了一个大规模的半模拟数据集。实验结果表明，所提出的SIKNet优于传统的KF，并且比现有的学习辅助滤波器具有更高的鲁棒性和准确性。该代码可在 （https://github.com/SongJgit/filternet 和 <a href="https://github.com/SongJgit/TBDTracker"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/SongJgit/TBDTracker</a>） 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 15：57：46 UTC</p>
<h2 id="135-通过多实例学习进行弱监督漏洞定位-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11312"target="_blank" rel="external nofollow noopener noreferrer">#135</a> <a href="https://papers.cool/arxiv/2509.11312"target="_blank" rel="external nofollow noopener noreferrer">通过多实例学习进行弱监督漏洞定位</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wenchao Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenchao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenchao</a> Gu), [Yupan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yupan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yupan</a> Chen), [Yanlin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanlin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanlin</a> Wang), [Hongyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongyu</a> Zhang), [Cuiyun Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cuiyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cuiyun</a> Gao), [Michael R. Lyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> R. Lyu)</p>
<p>软件漏洞检测已成为近年来软件安全领域的一个重要问题，吸引了众多研究人员和开发人员的关注。大多数以前的方法都侧重于粗粒度漏洞检测，例如在函数或文件级别。然而，开发人员仍然会遇到手动检查易受攻击函数内部的大量代码以识别要修改的特定易受攻击的语句的挑战，这表明漏洞本地化的重要性。训练模型进行漏洞定位通常需要在语句级别进行真实标记，而标记易受攻击的语句需要专业知识，这会产生高昂的成本。因此，对一种无需在报表级别进行额外标签的方法的需求正在上升。为了解决这个问题，我们提出了一种名为 WAVES 的新方法，用于通过多重 inStance 学习进行 WeAkly 监督漏洞定位，该方法在训练期间不需要额外的语句级标签。WAVES 能够确定函数是否易受攻击（即漏洞检测）并查明易受攻击的语句（即漏洞定位）。具体来说，受多实例学习概念的启发，WAVES 将函数级的真实标签转换为单个语句的伪标签，无需额外的语句级标签。这些伪标签用于训练函数级表示向量的分类器。对三个流行的基准数据集的广泛实验表明，与之前的基线相比，我们的方法在漏洞检测方面取得了相当的性能，在语句级漏洞定位方面实现了最先进的性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 15：11：39 UTC</p>
<h2 id="136-opalrlhf-的算子代数视图-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11298"target="_blank" rel="external nofollow noopener noreferrer">#136</a> <a href="https://papers.cool/arxiv/2509.11298"target="_blank" rel="external nofollow noopener noreferrer">Opal：RLHF 的算子代数视图</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Madhava Gaikwad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Madhava"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Madhava</a> Gaikwad)</p>
<p>我们提出了 Opal，这是一种来自人类反馈的强化学习 （RLHF） 的操作员视图。目标表示为基本效用上两个基元的阶梯：加法惩罚和乘法成对权重。我们描述了一个具有 if-and-only-if 条件的简单约简定律：当引用固定时，这种阶梯在成对边距上塌陷为正态形式，惩罚是累加的，并且权重与中间边距无关。当这些假设不成立时（参考偏移、非加性门、分数相关权重），小示例证明不可约。基于此视图，我们引入了 GKPO（广义内核首选项对象），这是一种规范模式，其中可以表示许多 RLHF 方法，并在可简化时映射回来。GKPO 提供标准的 JSON 序列化、规范化和哈希规则，以及在假设失败时带有有限见证的显式标志。我们用 DPO、RRHF 和 ORPO 的 GKPO 示例来说明这些想法，以及跨方法转换（在假设允许的情况下）和强调不可约性的最小压力测试（SHIFT/GATE/SCORE）。该模式附带一个轻量级的 Python 参考库，实现了规范哈希和 DPO 和 RRHF 的适配器。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 14：42：39 UTC</p>
<h2 id="137-社交机器人主导物理治疗的政策学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11297"target="_blank" rel="external nofollow noopener noreferrer">#137</a> <a href="https://papers.cool/arxiv/2509.11297"target="_blank" rel="external nofollow noopener noreferrer">社交机器人主导物理治疗的政策学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Carl Bettosi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Carl"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Carl</a> Bettosi), [Lynne Ballie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lynne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lynne</a> Ballie), [Susan Shenkin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Susan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Susan</a> Shenkin), [Marta Romeo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marta"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marta</a> Romeo)</p>
<p>社交机器人为自主引导患者完成物理治疗锻炼课程提供了一种有前途的解决方案，但有效部署需要先进的决策来适应患者的需求。一个关键的挑战是缺乏用于制定强有力政策的患者行为数据。为了解决这个问题，我们聘请了 33 名专业医疗保健从业者作为患者代理，利用他们与我们机器人的互动来告知患者行为模型，该模型能够生成运动表现指标和感知运动的主观评分。我们在模拟中训练了一种基于强化学习的策略，证明它可以根据个人的运动耐受性和波动的表现调整运动指导，同时也适用于处于不同恢复阶段和不同运动计划的患者。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 14：40：30 UTC</p>
<h2 id="138-能源感知-6g-网络设计一项调查-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11289"target="_blank" rel="external nofollow noopener noreferrer">#138</a> <a href="https://papers.cool/arxiv/2509.11289"target="_blank" rel="external nofollow noopener noreferrer">能源感知 6G 网络设计：一项调查</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Rashmi Kamran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rashmi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rashmi</a> Kamran), [Mahesh Ganesh Bhat](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mahesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mahesh</a> Ganesh Bhat), [Pranav Jha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pranav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pranav</a> Jha), [Shana Moothedath](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shana</a> Moothedath), [Manjesh Hanawal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manjesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manjesh</a> Hanawal), [Prasanna Chaporkar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prasanna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prasanna</a> Chaporkar)</p>
<p>第六代 （6G） 移动网络预计将为前所未有的用户数量支持多种新功能和以数据为中心的应用程序，这可能会引发重大的能源效率和可持续性问题。这使得可持续性成为其设计的关键目标之一。为了迈向可持续的解决方案，研究和标准化社区正在关注几个关键问题，例如能源信息监控和暴露、可再生能源的使用以及使用人工智能/机器学习 （AI/ML） 来提高 6G 网络的能源效率。目标是构建能源感知解决方案，该解决方案将能源信息考虑在内，从而形成节能网络。能源感知 6G 网络的设计带来了新的挑战，例如收集和公开能源相关信息的开销增加，以及相关的用户同意管理。本文旨在全面调查用于设计节能 6G 网络的方法，例如能量收集、能源模型和参数、能源感知服务分类以及基于 AI/ML 的解决方案。该调查还包括一些用例，这些用例证明了将能源意识纳入网络决策的好处。包括 3GPP、ITU 和 IEEE 中正在进行的几项标准化工作，以提供对正在进行的工作的见解并强调新贡献的机会。我们以开放的研究问题和挑战结束了这项调查，可以探索这些问题和挑战，以使能源感知设计可行，并确保 6G 网络的性能和能源目标的最佳性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 14：29：05 UTC</p>
<h2 id="139-神经网络增量类学习的高效单步框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11285"target="_blank" rel="external nofollow noopener noreferrer">#139</a> <a href="https://papers.cool/arxiv/2509.11285"target="_blank" rel="external nofollow noopener noreferrer">神经网络增量类学习的高效单步框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alejandro Dopico-Castro](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alejandro"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alejandro</a> Dopico-Castro), [Oscar Fontenla-Romero](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oscar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oscar</a> Fontenla-Romero), [Bertha Guijarro-Berdiñas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bertha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bertha</a> Guijarro-Berdiñas), [Amparo Alonso-Betanzos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amparo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amparo</a> Alonso-Betanzos)</p>
<p>增量学习仍然是机器学习中的一个关键挑战，因为模型经常与灾难性遗忘作斗争——在学习新信息时丢失以前获得的知识的倾向。这些挑战在资源有限的环境中更为明显。许多现有的类增量学习 （CIL） 方法通过不断调整其特征表示来实现高精度;然而，它们通常需要大量的计算资源和复杂的迭代训练过程。这项工作引入了 CIFNet（类增量和节俭网络），这是一种新颖的 CIL 方法，通过提供高效和可持续的解决方案来解决这些限制。CIFNet 的关键创新在于它对几个现有但单独探索的组件进行了新颖的集成：预训练和冻结的特征提取器、压缩数据缓冲区以及用于分类的高效非迭代单层神经网络。预训练和冻结的特征提取器消除了主干的计算成本高昂的微调。这与用于高效内存使用的压缩缓冲区相结合，使 CIFNet 能够通过对固定特征的单步优化过程执行高效的类增量学习，从而最大限度地减少计算开销和训练时间，而无需多次权重更新。基准数据集上的实验证实，CIFNet在分类器层面有效地减轻了灾难性遗忘，实现了与现有最先进方法相媲美的高精度，同时大大提高了训练效率和可持续性。CIFNet 代表了一项重大进步，使课堂增量学习在资源有限的环境中更易于访问和务实，尤其是在有强大的预训练特征提取器可用的情况下。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 14：24：41 UTC</p>
<h2 id="140-分解中的具身智能神经符号-tamp-中的多模态感知交叉验证和持续学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11270"target="_blank" rel="external nofollow noopener noreferrer">#140</a> <a href="https://papers.cool/arxiv/2509.11270"target="_blank" rel="external nofollow noopener noreferrer">分解中的具身智能：神经符号 TAMP 中的多模态感知交叉验证和持续学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ziwen He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziwen</a> He), [Zhigang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhigang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhigang</a> Wang), [Yanlong Peng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanlong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanlong</a> Peng), [Pengxu Chang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pengxu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pengxu</a> Chang), [Hong Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hong</a> Yang), [Ming Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ming</a> Chen)</p>
<p>随着新能源汽车产业的快速发展，动力电池的高效拆解和回收成为循环经济面临的严峻挑战。在当前的非结构化拆解场景中，环境的动态性质严重限制了机器人感知的鲁棒性，对工业应用中的自主拆解构成了重大障碍。本文提出了一种基于神经符号任务和运动规划（TAMP）的持续学习框架，以增强具身智能系统在动态环境中的适应性。我们的方法将多模态感知交叉验证机制集成到双向推理流程中：前向工作流动态细化和优化行动策略，而后向学习流则自主收集历史任务执行中的有效数据，以促进持续的系统学习，实现自我优化。实验结果表明，所提框架将动态拆解场景下的任务成功率从81.68%提高到100%，同时将平均感知误判次数从3.389次减少到1.128次。本研究为增强具身智能在复杂工业环境中的鲁棒性和适应性提供了新的范式。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 13：47：07 UTC</p>
<h2 id="141-使用-tabpfn-进行无梯度深度强化学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11259"target="_blank" rel="external nofollow noopener noreferrer">#141</a> <a href="https://papers.cool/arxiv/2509.11259"target="_blank" rel="external nofollow noopener noreferrer">使用 TabPFN 进行无梯度深度强化学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [David Schiff](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Schiff), [Ofir Lindenbaum](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ofir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ofir</a> Lindenbaum), [Yonathan Efroni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yonathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yonathan</a> Efroni)</p>
<p>基于梯度的优化是大多数现代深度强化学习算法的基础，但它对超参数、不稳定的训练动态和高计算成本具有显着的敏感性。我们提出了 TabPFN RL，这是一种新型的无梯度深度 RL 框架，它将元训练的 Transformer TabPFN 重新用作 Q 函数近似器。TabPFN 最初是为表格分类而开发的，是一种在数百万个合成数据集上进行预训练的转换器，可通过上下文学习对新的看不见的数据集进行推理。给定样本标签对和新的未标记数据的上下文数据集，它可以在单个前向传递中预测最可能的标签，而无需梯度更新或特定于任务的微调。我们使用 TabPFN 仅通过推理来预测 Q 值，从而消除了在训练和推理中反向传播的需要。为了应对模型固定的上下文预算，我们设计了一个高奖励的情节门，只保留前 5% 的轨迹。对 Gymnasium 经典控制套件的实证评估表明，TabPFN RL 在 CartPole v1、MountainCar v0 和 Acrobot v1 上与 Deep Q Network 相当或超过，无需应用梯度下降或任何广泛的超参数调整。我们讨论了自举目标和非平稳访问分布如何违反 TabPFN 先验中编码的独立性假设的理论方面，但该模型保留了令人惊讶的泛化能力。我们进一步形式化了上下文中 RL 算法的内在上下文大小限制，并提出了原则性的截断策略，以便在上下文已满时实现持续学习。我们的结果将TabPFN等先验拟合网络确立为快速和计算高效的RL的可行基础，为具有大型预训练变压器的无梯度RL开辟了新的方向。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 13：09：58 UTC</p>
<h2 id="142-超越自回归用于代码生成的扩散大型语言模型的实证研究-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11252"target="_blank" rel="external nofollow noopener noreferrer">#142</a> <a href="https://papers.cool/arxiv/2509.11252"target="_blank" rel="external nofollow noopener noreferrer">超越自回归：用于代码生成的扩散大型语言模型的实证研究</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Chengze li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengze"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengze</a> li), [Yitong Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yitong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yitong</a> Zhang), [Jia Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Li), [Liyi Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liyi</a> Cai), [Ge Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ge"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ge</a> Li)</p>
<p>LLM 已成为代码生成的主流方法。现有的 LLM 主要采用自回归生成，即从左到右逐个标记生成代码。但是，底层自回归生成在代码生成方面有两个限制。首先，自回归 LLM 仅在每个步骤生成一个 token，在实践中表现出较低的效率。其次，编程是一个涉及来回编辑的非顺序过程，而自回归 LLM 仅采用从左到右的生成顺序。这两个内在限制阻碍了 LLM 在代码生成方面的进一步发展。最近，扩散法学硕士已成为一种有前途的替代方案。扩散 LLM 通过两个进步解决了上述限制，包括多代币预测（即在每一步生成多个代币）和灵活的生成顺序（即灵活确定生成代币的位置）。然而，目前还没有系统研究探索代码生成中的扩散法学硕士。为了弥合知识差距，我们提出了第一个用于代码生成的扩散 LLM 的实证研究。我们的研究涉及 9 个具有代表性的扩散 LLM，并在 4 个广泛使用的基准上进行了实验。根据研究结果，我们总结了以下发现。（1）现有的扩散法学硕士与具有相似规模的自回归法学硕士具有竞争力。（2）扩散LLM比自回归LLM具有更强的长度外推能力，在长代码理解方面表现更好。（3）我们探讨了影响扩散法学硕士有效性和效率的因素，并提供了实用的指导。（4） 我们讨论了几个有希望的进一步方向，以改进扩散法学硕士在代码生成方面的应用。我们将所有源代码、数据和结果开源，以促进以下研究。该代码可在 <a href="https://github.com/zhangyitonggg/dllm4code"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/zhangyitonggg/dllm4code</a> 公开获取。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 12：51：06 UTC</p>
<h2 id="143-transzero使用-transformer-网络在-muzero-中进行并行树扩展-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11233"target="_blank" rel="external nofollow noopener noreferrer">#143</a> <a href="https://papers.cool/arxiv/2509.11233"target="_blank" rel="external nofollow noopener noreferrer">TransZero：使用 Transformer 网络在 MuZero 中进行并行树扩展</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Emil Malmsten](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emil</a> Malmsten), [Wendelin Böhmer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wendelin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wendelin</a> Böhmer)</p>
<p>我们提出了 TransZero，这是一种基于模型的强化学习算法，它消除了蒙特卡洛树搜索 （MCTS） 中的顺序瓶颈。与使用递归动力学模型逐步构建搜索树的 MuZero 不同，TransZero 采用基于 transformer 的网络同时生成多个潜在未来状态。结合均值-方差约束 （MVC） 评估器，消除了对固有顺序访问计数的依赖，我们的方法可以在规划期间并行扩展整个子树。MiniGrid 和 LunarLander 中的实验表明，与 MuZero 相比，TransZero 在保持样品效率的同时实现了高达 11 倍的挂钟时间加速。这些结果表明，并行树构建可以大大加速基于模型的强化学习，使复杂环境中的实时决策更接近实践。该代码在 GitHub 上公开可用。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 12：20：38 UTC</p>
<h2 id="144-mis-lstm用于睡眠质量和压力预测的多通道图像序列-lstm-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11232"target="_blank" rel="external nofollow noopener noreferrer">#144</a> <a href="https://papers.cool/arxiv/2509.11232"target="_blank" rel="external nofollow noopener noreferrer">MIS-LSTM：用于睡眠质量和压力预测的多通道图像序列 LSTM</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Seongwan Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seongwan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seongwan</a> Park), [Jieun Woo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jieun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jieun</a> Woo), [Siheon Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siheon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siheon</a> Yang)</p>
<p>本文提出了 MIS-LSTM，这是一个混合框架，它将 CNN 编码器与 LSTM 序列模型相结合，用于从多模态生命日志数据中预测日间睡眠质量和压力。连续传感器流首先被划分为 N 小时块并渲染为多通道图像，而稀疏离散事件则使用专用的 1D-CNN 进行编码。卷积块注意力模块将这两种模态融合到精细的块嵌入中，然后 LSTM 聚合这些模块以捕获远程时间依赖关系。为了进一步提高稳健性，我们引入了 UALRE，这是一个不确定性感知的集成，它用高置信度的个人预测覆盖低置信度多数票。在2025 ETRI Lifelog Challenge数据集上的实验表明，我们的基础MISLSTM达到了Macro-F1 0.615;使用 UALRE 集合，分数提高到 0.647，优于强大的 LSTM、1D-CNN 和 CNN 基线。消融证实了 （i） 多通道相对于堆叠垂直成像的优越性，（ii） 4 小时块粒度的好处，以及 （iii） 特定模式的离散编码的功效。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 12：19：04 UTC</p>
<h2 id="145-membot间歇性pomdp中基于内存的机器人-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11225"target="_blank" rel="external nofollow noopener noreferrer">#145</a> <a href="https://papers.cool/arxiv/2509.11225"target="_blank" rel="external nofollow noopener noreferrer">MEMBOT：间歇性POMDP中基于内存的机器人</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Youzhi Liang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youzhi</a> Liang), [Eyan Noronha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eyan</a> Noronha)</p>
<p>部署在现实环境中的机器人系统通常在部分且通常是间歇性的可观测性条件下运行，其中传感器输入可能由于故障或环境限制而产生噪音、遮挡或完全不可用。假设完全状态可观测性的传统强化学习 （RL） 方法无法应对此类挑战。在这项工作中，我们介绍了 MEMBOT，这是一种基于模块化内存的架构，旨在解决机器人控制任务中的间歇性部分可观测性问题。MEMBOT 通过两阶段的训练过程将信念推理与策略学习解耦：离线多任务学习预训练阶段，使用重建损失学习一个与任务无关的稳健潜在信念编码器，然后使用行为克隆对特定于任务的策略进行微调。信念编码器作为状态空间模型 （SSM） 和 LSTM 实现，集成了观测和动作的时间序列，以推断即使观测值被丢弃，这些状态表示也会持续存在。我们在不同的观察辍学率下，对 MetaWorld 和 Robomimic 的 10 项机器人纵基准任务进行训练和评估 MEMBOT。结果表明，MEMBOT始终优于无记忆和朴素重复基线，在50%的观测可用性下保持高达80%的峰值性能。这些发现凸显了显式置信建模在为现实世界的部分可观察机器人系统实现稳健、可转移和数据高效的策略方面的有效性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 12：00：52 UTC</p>
<h2 id="146-几何约束和基于标记的概率空间转换器-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11218"target="_blank" rel="external nofollow noopener noreferrer">#146</a> <a href="https://papers.cool/arxiv/2509.11218"target="_blank" rel="external nofollow noopener noreferrer">几何约束和基于标记的概率空间转换器</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Johann Schmidt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Johann"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Johann</a> Schmidt), [Sebastian Stober](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sebastian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sebastian</a> Stober)</p>
<p>细粒度视觉分类 （FGVC） 对几何变异性仍然高度敏感，其中物体以任意方向、比例和透视扭曲出现。虽然等变量架构解决了这个问题，但它们通常需要大量的计算资源并限制假设空间。我们重新审视空间变压器网络 （STN） 作为基于变压器的视觉管道的规范化工具，强调它们的灵活性、与主干网无关的性质以及缺乏架构限制。我们提出了一种概率的、按组件的扩展来提高鲁棒性。具体来说，我们将仿射变换分解为旋转、缩放和剪切，并使用共享定位编码器在几何约束下回归每个组件。为了捕获不确定性，我们使用高斯变分后验对每个组件进行建模，并在推理过程中执行基于采样的规范化。一种新的分量对准损耗利用增强参数来指导空间对准。在具有挑战性的飞蛾分类基准上的实验表明，与其他 STN 相比，我们的方法持续提高了鲁棒性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 11：30：53 UTC</p>
<h2 id="147-evalet通过将输出碎片化为函数来评估大型语言模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11206"target="_blank" rel="external nofollow noopener noreferrer">#147</a> <a href="https://papers.cool/arxiv/2509.11206"target="_blank" rel="external nofollow noopener noreferrer">Evalet：通过将输出碎片化为函数来评估大型语言模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Tae Soo Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tae</a> Soo Kim), [Heechan Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Heechan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Heechan</a> Lee), [Yoonjoo Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yoonjoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yoonjoo</a> Lee), [Joseph Seering](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joseph"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joseph</a> Seering), [Juho Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juho</a> Kim)</p>
<p>从业者越来越依赖大型语言模型 （LLM） 通过“LLM 作为法官”方法评估生成式人工智能输出。然而，这些方法产生的整体分数掩盖了哪些特定因素影响了评估。我们提出了功能碎片化，这是一种将每个输出分解为关键片段并解释每个片段相对于评估标准所服务的修辞功能的方法——浮出水面感兴趣的元素并揭示它们如何实现或阻碍用户目标。我们在 Evalet 中实例化了这种方法，这是一个交互式系统，可跨多个输出可视化片段级函数，以支持评估的检查、评级和比较。一项用户研究 （N=10） 发现，虽然从业者难以验证整体分数，但我们的方法帮助他们识别了 48% 以上的评估不一致。这帮助他们校准了对 LLM 评估的信任度，并依靠它们在模型输出中发现更多可作的问题。我们的工作将 LLM 评估从定量分数转向对模型行为的定性、细粒度分析。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 10：24：13 UTC</p>
<h2 id="148-用于解决量子机器学习任务的量子架构搜索-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11198"target="_blank" rel="external nofollow noopener noreferrer">#148</a> <a href="https://papers.cool/arxiv/2509.11198"target="_blank" rel="external nofollow noopener noreferrer">用于解决量子机器学习任务的量子架构搜索</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Michael Kölle](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Kölle), [Simon Salfer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Simon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Simon</a> Salfer), [Tobias Rohe](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tobias"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tobias</a> Rohe), [Philipp Altmann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Philipp"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Philipp</a> Altmann), [Claudia Linnhoff-Popien](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Claudia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Claudia</a> Linnhoff-Popien)</p>
<p>量子计算利用量子力学以与经典方法根本不同的方式解决计算问题。虽然当前的量子硬件仍然容易出错且规模有限，但变分量子电路提供了适合当今设备的抗噪声框架。这些电路的性能在很大程度上取决于其参数化量子组件的底层架构。因此，确定高效、硬件兼容的量子电路架构（称为量子架构搜索 （QAS））至关重要。手动 QAS 复杂且容易出错，这促使人们努力实现自动化。在各种自动化策略中，强化学习 （RL） 仍未得到充分探索，特别是在量子机器学习环境中。这项工作介绍了 RL-QAS，这是一个应用 RL 来发现分类任务有效电路架构的框架。我们使用 Iris 和二进制 MNIST 数据集评估 RL-QAS。代理自主发现低复杂度的电路设计，从而实现高测试精度。我们的结果表明，RL 是量子机器学习中自动架构搜索的可行方法。然而，将RL-QAS应用于更复杂的任务将需要进一步完善搜索策略和性能评估机制。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/quant-ph"target="_blank" rel="external nofollow noopener noreferrer">量子物理学</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 09：55：38 UTC</p>
<h2 id="149-dreamnav用于零样本视觉和语言导航的基于轨迹的想象力框架-pdf1-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.11197"target="_blank" rel="external nofollow noopener noreferrer">#149</a> <a href="https://papers.cool/arxiv/2509.11197"target="_blank" rel="external nofollow noopener noreferrer">DreamNav：用于零样本视觉和语言导航的基于轨迹的想象力框架</a> [PDF1] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Yunheng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunheng</a> Wang), [Yuetong Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuetong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuetong</a> Fang), [Taowen Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taowen</a> Wang), [Yixiao Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixiao</a> Feng), [Yawen Tan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yawen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yawen</a> Tan), [Shuning Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuning</a> Zhang), [Peiran Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peiran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peiran</a> Liu), [Yiding Ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiding"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiding</a> Ji), [Renjing Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Renjing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Renjing</a> Xu)</p>
<p>连续环境中的视觉和语言导航（VLN-CE）是具身机器人的核心能力，它将语言指令与现实世界中的感知和控制联系起来。最近，大规模预训练基础模型被用作感知、推理和行动的共享先验，无需特定任务训练即可实现零样本 VLN。然而，现有的零样本VLN方法依赖于昂贵的感知和被动场景理解，将控制缩减为点级选择。因此，它们的部署成本高昂，行动语义不一致，规划短视。为了解决这些问题，我们推出了专注于以下三个方面的 DreamNav：（1） 为了降低感官成本，我们的 EgoView 校正器可以调整观点并稳定以自我为中心的感知;（2）我们的轨迹预测器倾向于全局轨迹级规划，而不是点级动作，以更好地与指令语义保持一致;（3）为了实现预期和长期规划，我们提出了一种想象力预测器，以赋予智能体主动思考能力。在VLN-CE和实际测试中，DreamNav设置了一种新的零样本最先进（SOTA），在SR和SPL指标方面，在额外信息方面比最强的自我中心基线高出7.49%和18.15%。据我们所知，这是第一个零样本VLN方法，它统一了轨迹层面的规划和主动想象力，同时仅使用以自我为中心的输入。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-14 09：54：20 UTC</p>
<h2 id="150-面向电子商务平台的数据估值联合推荐系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11196"target="_blank" rel="external nofollow noopener noreferrer">#150</a> <a href="https://papers.cool/arxiv/2509.11196"target="_blank" rel="external nofollow noopener noreferrer">面向电子商务平台的数据估值联合推荐系统</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jongwon Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jongwon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jongwon</a> Park), [Minku Kang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minku"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minku</a> Kang), [Wooseok Sim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wooseok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wooseok</a> Sim), [Soyoung Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soyoung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soyoung</a> Lee), [Hogun Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hogun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hogun</a> Park)</p>
<p>随着隐私问题的日益严重，联邦学习 （FL） 在机器学习中越来越受到重视。这种范式允许每个客户端（例如，单个在线商店）在本地训练推荐模型，同时仅共享模型更新，而无需将原始交互日志暴露给中央服务器，从而在去中心化环境中保护隐私。尽管如此，大多数现有的基于 FL 的推荐系统仍然仅依赖每个客户的私有数据，尽管有大量公开可用的数据集可用于丰富本地培训;这一潜力在很大程度上仍未得到充分开发。为此，我们考虑了一个现实场景，即大型购物平台与多个小型在线商店合作，构建全球推荐系统。该平台拥有全球数据，例如可共享的用户和商品列表，而每个商店都私下（或本地）持有部分交互数据。尽管集成全球数据有助于减轻稀疏和有偏见的客户端本地数据的局限性，但它也带来了额外的挑战：简单地组合所有全局交互可能会放大噪音和不相关的模式，从而恶化个性化并增加计算成本。为了应对这些挑战，我们提出了 FedGDVE，它使用来自全局数据集的语义对齐样本有选择地增强每个客户端的局部图。FedGDVE 采用：（i） 预训练的图编码器来提取全局结构特征，（ii） 局部有效预测器来评估客户特定的相关性，（iii） 基于强化学习的概率估计器来过滤和采样最相关的全局交互。FedGDVE 在 FL 环境中的公认基准测试中将性能提高了 34.86%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 09：48：23 UTC</p>
<h2 id="151-研究变分量子电路的彩票假说-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11190"target="_blank" rel="external nofollow noopener noreferrer">#151</a> <a href="https://papers.cool/arxiv/2509.11190"target="_blank" rel="external nofollow noopener noreferrer">研究变分量子电路的彩票假说</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Michael Kölle](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Kölle), [Leonhard Klingert](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leonhard"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leonhard</a> Klingert), [Julian Schönberger](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Julian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Julian</a> Schönberger), [Philipp Altmann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Philipp"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Philipp</a> Altmann), [Tobias Rohe](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tobias"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tobias</a> Rohe), [Claudia Linnhoff-Popien](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Claudia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Claudia</a> Linnhoff-Popien)</p>
<p>量子计算是计算机科学中的一个新兴领域，近年来取得了长足的进步，尤其是在机器学习方面。通过利用量子物理学原理，它可以超越经典算法的局限性。然而，依赖可调参数的变分量子电路（VQCs）往往面临贫瘠的高原现象，阻碍了优化。彩票假说 （LTH） 是经典机器学习中的一个新概念，它显着提高了神经网络的参数效率。它指出，在大型网络中，更小、更高效的子网或“中奖票”可以实现相当的性能，从而有可能规避平台期挑战。在这项工作中，我们研究了这个想法是否可以应用于VQC。我们表明弱 LTH 适用于 VQC，显示中奖彩票仅保留原始参数的 26.0%。对于强 LTH，无需任何训练即可学习修剪掩模，我们在二进制 VQC 中发现了一张中奖彩票，仅使用 45% 的权重即可实现 100% 的准确率。这些发现表明，LTH 可以通过减少参数数量同时保持性能来缓解贫瘠的平台期，从而提高 VQC 在量子机器学习任务中的效率。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/quant-ph"target="_blank" rel="external nofollow noopener noreferrer">量子物理学</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 09：39：32 UTC</p>
<h2 id="152-隐写术通过最佳传输进行隐写术的权衡-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11178"target="_blank" rel="external nofollow noopener noreferrer">#152</a> <a href="https://papers.cool/arxiv/2509.11178"target="_blank" rel="external nofollow noopener noreferrer">隐写术：通过最佳传输进行隐写术的权衡</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Chengde Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengde"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengde</a> Lin), [Xuezhu Gong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuezhu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuezhu</a> Gong), [Shuxue Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuxue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuxue</a> Ding), [Mingzhe Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingzhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingzhe</a> Yang), [Xijun Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xijun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xijun</a> Lu), [Chengjun Mo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengjun</a> Mo)</p>
<p>图像隐藏通常称为隐写术，旨在将秘密图像隐藏在相同分辨率的封面图像中。许多隐写术模型基于通用对抗网络 （GAN） 和变分自动编码器 （VAE）。然而，大多数现有模型都存在模式崩溃的问题。模态崩溃会导致隐形图像中封面图像和秘密图像之间的信息不平衡，并进一步影响后续提取。为了应对这些挑战，本文提出了StegOT，这是一种基于自动编码器的隐写模型，结合了最优传输理论。我们设计了多通道最优传输（MCOT）模块，将表现出多个峰值的特征分布转换为单个峰值，以实现信息的权衡。实验表明，我们不仅实现了掩护图像和秘密图像之间的权衡，而且还提高了隐蔽图像和恢复图像的质量。源代码将于 <a href="https://github.com/Rss1124/StegOT"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Rss1124/StegOT</a> 日发布。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 09：18：18 UTC</p>
<h2 id="153-差分私有文本生成会降低输出语言质量-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11176"target="_blank" rel="external nofollow noopener noreferrer">#153</a> <a href="https://papers.cool/arxiv/2509.11176"target="_blank" rel="external nofollow noopener noreferrer">差分私有文本生成会降低输出语言质量</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Erion Çano](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Erion"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Erion</a> Çano), [Ivan Habernal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivan</a> Habernal)</p>
<p>通过合成在差分隐私（DP）下调优的大型语言模型（LLM）的数据来确保用户隐私，最近很流行。然而，DP 微调法学硕士对语言质量及其生成文本的效用的影响尚未得到研究。在这项工作中，我们在四个隐私级别下调整了五个具有三个语料库的 LLM，并评估了它们产生的文本输出的长度、语法正确性和词汇多样性。我们还探讨了合成输出在下游分类任务中的效用，例如基于书籍描述的书籍类型识别和基于口头尸检的死因识别。结果表明，在更强的隐私约束下调整的法学硕士产生的文本至少短了 77%，语法正确度至少降低了 9%，双元组多样性的多样性至少降低了 10%。此外，它们在下游分类任务中达到的准确性会降低，这可能不利于生成的合成数据的有用性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 09：16：11 UTC</p>
<h2 id="154-您的编译器正在为您的模型提供后门了解和利用深度学习编译器中的编译不一致漏洞-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11173"target="_blank" rel="external nofollow noopener noreferrer">#154</a> <a href="https://papers.cool/arxiv/2509.11173"target="_blank" rel="external nofollow noopener noreferrer">您的编译器正在为您的模型提供后门：了解和利用深度学习编译器中的编译不一致漏洞</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Simin Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Simin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Simin</a> Chen), [Jinjun Peng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinjun</a> Peng), [Yixin He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixin</a> He), [Junfeng Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junfeng</a> Yang), [Baishakhi Ray](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baishakhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baishakhi</a> Ray)</p>
<p>深度学习 （DL） 编译器是现代 DL 系统中的核心基础设施，提供超越供应商特定库的灵活性和可扩展性。这项工作揭示了他们设计中的一个基本漏洞：官方的、未经修改的编译器能否在编译过程中改变模型的语义并引入隐藏的后门？我们研究对抗性和自然环境。在对抗性情况下，我们制作良性模型，其中触发器在编译前没有影响，但在编译后成为有效的后门。在六种型号、三种商业编译器和两种硬件平台上进行了测试，我们的攻击在触发输入上取得了 100% 的成功，同时保持了正常精度，并且不会被最先进的检测器检测到。该攻击泛化到编译器、硬件和浮点设置中。在自然环境中，我们分析了排名前 100 的 HuggingFace 模型（包括下载量为 220M+ 的模型），并在 31 个模型中找到了自然触发因素。这表明即使没有对抗性纵，编译器也可能引入风险。我们的结果揭示了一个被忽视的威胁：未经修改的 DL 编译器可以悄无声息地改变模型语义。据我们所知，这是首次暴露 DL 编译器设计中固有安全风险的工作，为安全可信的 ML 开辟了新方向。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a></p>
<p><strong>发布</strong>: 2025-09-14 09：11：49 UTC</p>
<h2 id="155-域偏移下数据高效声场景分类的熵引导课程学习策略-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11168"target="_blank" rel="external nofollow noopener noreferrer">#155</a> <a href="https://papers.cool/arxiv/2509.11168"target="_blank" rel="external nofollow noopener noreferrer">域偏移下数据高效声场景分类的熵引导课程学习策略</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Peihong Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peihong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peihong</a> Zhang), [Yuxuan Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxuan</a> Liu), [Zhixin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhixin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhixin</a> Li), [Rui Sang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rui</a> Sang), [Yiqiang Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiqiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiqiang</a> Cai), [Yizhou Tan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yizhou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yizhou</a> Tan), [Shengchen Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shengchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shengchen</a> Li)</p>
<p>声学场景分类 （ASC） 在跨记录设备进行通用化方面面临挑战，特别是在标记数据有限的情况下。DCASE 2024 挑战任务 1 通过要求模型从少数设备上记录的小标记子集中学习来强调这个问题。然后，这些模型需要推广到在严格的复杂性约束下来自以前看不见的设备的记录。虽然数据增强和使用预训练模型等技术在提高模型泛化方面已经很成熟，但优化训练策略代表了一条互补但探索较少的路径，不会引入额外的架构复杂性或推理开销。在各种培训策略中，课程学习通过从易到难的示例构建学习过程，提供了一个有前途的范式。在这项工作中，我们提出了一种熵引导的课程学习策略，以解决数据高效ASC中的领域转移问题。具体来说，我们通过计算辅助域分类器估计的器件后验概率的香农熵来量化每个训练样本的器件域预测的不确定性。该课程使用熵作为域不变性的代理，从高熵样本开始，逐渐纳入低熵、特定域样本，以促进可推广表示的学习。在多个 DCASE 2024 ASC 基线上的实验结果表明，我们的策略有效地减轻了域偏移，特别是在有限的标记数据条件下。我们的策略与架构无关，不会引入额外的推理成本，使其可以轻松集成到现有的 ASC 基线中，并为领域转移提供实用的解决方案。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 09：01：52 UTC</p>
<h2 id="156-利用优化动力学进行曲率知情模型合并-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11167"target="_blank" rel="external nofollow noopener noreferrer">#156</a> <a href="https://papers.cool/arxiv/2509.11167"target="_blank" rel="external nofollow noopener noreferrer">利用优化动力学进行曲率知情模型合并</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Pouria Mahdavinia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pouria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pouria</a> Mahdavinia), [Hamed Mahdavi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hamed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hamed</a> Mahdavi), [Niloofar Mireshghallah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Niloofar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Niloofar</a> Mireshghallah), [Mehrdad Mahdavi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mehrdad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mehrdad</a> Mahdavi)</p>
<p>模型合并是一种有效的训练后策略，无需联合再训练即可在大型语言模型中组合能力。我们在监督微调 （SFT） 阶段对此进行了研究，其中多个基于能力的 SFT 检查点——跨越数学、代码、精确指令遵循、通用指令遵循和知识回忆——必须整合到一个模型中。我们引入了优化轨迹感知 （OTA） 合并，这是一种曲率感知聚合，它利用优化器第二矩统计数据作为对角线曲率代理来重新加权参数编辑并减轻干扰。作为 OTA 的补充，我们提出了快速 Fisher 嫁接 （FFG），这是一个曲率驱动的任务定位步骤，可稀疏化冲突或低重要性的编辑。FFG 诱导极低秩的掩码集中在早期注意力查询/关键投影和令牌嵌入中，利用跨能力的共享曲率。我们进一步开发了第二时刻的记忆光压缩，以保留 OTA 的效果。在基于能力的各种 SFT 检查点中，OTA+FFG 在强权重空间基线上提高了合并模型质量，减少了负转移，并在稀疏性级别上保持稳健。分析揭示了检查点之间的大量曲率重叠，为为什么简单的线性合并在实践中有效提供了一个新颖的视角。烧蚀证实 FFG 对于减少任务干扰至关重要，并且压缩的第二矩保留了完整配方的增益。为了提高可重复性，我们在 <a href="https://github.com/pmahdavi/ota-merge"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/pmahdavi/ota-merge</a> 开源了所有代码、训练和评估脚本、可视化工件和特定于功能的 SFT 检查点。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 08：59：53 UTC</p>
<h2 id="157-aqua通过-query-magnitudes-在-llm-中进行记忆和计算高效推理的注意力-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11155"target="_blank" rel="external nofollow noopener noreferrer">#157</a> <a href="https://papers.cool/arxiv/2509.11155"target="_blank" rel="external nofollow noopener noreferrer">AQUA：通过 QUery mAgnitudes 在 LLM 中进行记忆和计算高效推理的注意力</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Santhosh G S](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Santhosh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Santhosh</a> G S), [Saurav Prakash](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Saurav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Saurav</a> Prakash), [Balaraman Ravindran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Balaraman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Balaraman</a> Ravindran)</p>
<p>注意力机制的二次复杂性仍然是将大型语言模型 （LLM） 扩展到更长上下文的根本障碍，在计算和内存方面造成了严重瓶颈。为了解决这个问题，我们引入了 AQUA（通过 QUery mAgnitudes 的注意力），这是一种新颖且通用的近似策略，它通过优雅的性能权衡显着降低了注意力成本。我们的方法分两个阶段运行：一个是高效的离线步骤，我们通过 SVD 在校准数据集上计算一个通用的、与语言无关的投影矩阵，另一个是在线推理步骤，我们投影查询和关键向量，并根据查询的大小动态选择一个稀疏的维度子集。我们提供了 AQUA 的形式理论分析，建立了盈亏平衡点，在该点上，它的计算效率比标准注意力更高。我们对 Llama-3.1-8B 等最先进模型的实证评估表明，注意力点积计算可以减少 25%，而对各种基准测试的性能影响在统计学上微不足道。我们进一步展示了 AQUA 的多功能性，展示了它协同加速现有代币驱逐方法（如 H2O）并直接减小 KV 缓存内存大小的能力。通过提供可控旋钮来平衡效率和准确性，AQUA 提供了一个实用且强大的工具，使大规模 LLM 推理更易于访问和可持续。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 08：20：48 UTC</p>
<h2 id="158-通过霍普金斯损耗控制特征空间拓扑-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11154"target="_blank" rel="external nofollow noopener noreferrer">#158</a> <a href="https://papers.cool/arxiv/2509.11154"target="_blank" rel="external nofollow noopener noreferrer">通过霍普金斯损耗控制特征空间拓扑</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Einari Vaaras](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Einari"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Einari</a> Vaaras), [Manu Airaksinen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manu</a> Airaksinen)</p>
<p>特征空间拓扑是指特征空间内样本的组织。修改这种拓扑在机器学习应用中是有益的，包括降维、生成建模、迁移学习和对对抗性攻击的鲁棒性。本文引入了一种新的损失函数霍普金斯损失，它利用霍普金斯统计量来强制执行所需的特征空间拓扑，这与现有旨在保留输入特征拓扑的拓扑相关方法形成鲜明对比。我们在两种情况下评估霍普金斯损失对语音、文本和图像数据的有效性：使用非线性瓶颈自动编码器的分类和降维。我们的实验表明，将霍普金斯损失集成到分类或降维中对分类性能的影响很小，同时提供了修改特征拓扑的好处。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 08：16：20 UTC</p>
<h2 id="159-roverfly跨有效载荷配置的基于学习的四旋翼强大且多功能的控制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11149"target="_blank" rel="external nofollow noopener noreferrer">#159</a> <a href="https://papers.cool/arxiv/2509.11149"target="_blank" rel="external nofollow noopener noreferrer">RoVerFly：跨有效载荷配置的基于学习的四旋翼强大且多功能的控制</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mintae Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mintae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mintae</a> Kim), [Jiaze Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaze"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaze</a> Cai), [Koushil Sreenath](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Koushil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Koushil</a> Sreenath)</p>
<p>由于非线性动力学和驱动不足，设计用于使用四旋翼进行精确、任意轨迹跟踪的稳健控制器具有挑战性，并且由于灵活的电缆悬挂有效载荷引入了额外的自由度和混合性，因此变得更加困难。基于模型的经典方法提供稳定性保证，但需要进行大量调整，并且通常无法在配置更改时进行调整，例如添加或删除有效载荷时，或者当有效载荷质量或电缆长度发生变化时。我们提出了 RoVerFly，这是一个基于学习的统一控制框架，其中强化学习 （RL） 策略可作为标准四旋翼和跨一系列配置的电缆悬挂有效载荷系统的强大且多功能的跟踪控制器。通过任务和域随机化进行训练，控制器能够抵御干扰和变化的动态。它实现了跨有效载荷设置的强零样本泛化，包括无有效载荷以及不同的质量和电缆长度，无需控制器切换或重新调整，同时保留了反馈跟踪控制器的可解释性和结构。守则及补充资料可于以下网址查阅 <a href="https://github.com/mintaeshkim/roverfly"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/mintaeshkim/roverfly</a></p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 07：41：40 UTC</p>
<h2 id="160-在线平台中的代理用户名建议和多模态性别检测介绍-pngt-26k-数据集-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11136"target="_blank" rel="external nofollow noopener noreferrer">#160</a> <a href="https://papers.cool/arxiv/2509.11136"target="_blank" rel="external nofollow noopener noreferrer">在线平台中的代理用户名建议和多模态性别检测：介绍 PNGT-26K 数据集</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Farbod Bijary](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Farbod"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Farbod</a> Bijary), [Mohsen Ebadpour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohsen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohsen</a> Ebadpour), [Amirhosein Tajbakhsh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amirhosein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amirhosein</a> Tajbakhsh)</p>
<p>由于音译不一致和特定文化的命名模式，波斯语名称给自然语言处理应用带来了独特的挑战，特别是在性别检测和数字身份创建方面。现有工具在波斯语名称上表现出显着的性能下降，而综合数据集的稀缺进一步加剧了这些限制。为了应对这些挑战，本研究引入了 PNGT-26K，这是一个包含波斯语名字、其常见性别及其英语音译的综合数据集，由大约 26,000 个元组组成。为了演示如何利用这一资源，我们还介绍了两个框架，即开放性别检测和唯名论。Open Gender Detection 是一个生产级、即用型框架，用于使用来自用户的现有数据（例如个人资料照片和姓名）来对此人的性别进行概率猜测。Nominalist 是本文介绍的第二个框架，它利用代理 AI 帮助用户在任何平台上为其社交媒体帐户选择用户名。它可以轻松集成到任何网站中，以提供更好的用户体验。PNGT-26K 数据集、唯名论和开放性别检测框架在 Github 上公开提供。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.SI"target="_blank" rel="external nofollow noopener noreferrer">社会和信息网络</a></p>
<p><strong>发布</strong>: 2025-09-14 07：08：32 UTC</p>
<h2 id="161-enj利用遗传算法优化噪声以越狱lsm-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11128"target="_blank" rel="external nofollow noopener noreferrer">#161</a> <a href="https://papers.cool/arxiv/2509.11128"target="_blank" rel="external nofollow noopener noreferrer">ENJ：利用遗传算法优化噪声以越狱LSM</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yibo Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yibo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yibo</a> Zhang), [Liang Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liang</a> Lin)</p>
<p>大型语音模型（LSM）的广泛应用使其安全风险日益凸显。传统的语音对抗攻击方式在平衡有效性和隐蔽性方面面临挑战。该文提出了进化噪声越狱（ENJ），该算法利用遗传算法将环境噪声从被动干扰转化为主动优化的攻击载体，用于越狱LSM。通过群体初始化、交叉融合、概率突变等作，该方法迭代进化出一系列将恶意指令与背景噪声融合的音频样本。这些样本听起来像是对人类无害的噪音，但可以诱导模型解析和执行有害命令。在多个主流语音模型上的广泛实验表明，ENJ的攻击效果明显优于现有的基线方法。本研究揭示了噪声在语音安全中的双重作用，为复杂声学环境下的模型安全防御提供了新的关键见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 06：39：38 UTC</p>
<h2 id="162-我们主张同意迈向以个性驱动的基于论证的旅游谈判对话系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11118"target="_blank" rel="external nofollow noopener noreferrer">#162</a> <a href="https://papers.cool/arxiv/2509.11118"target="_blank" rel="external nofollow noopener noreferrer">我们主张同意：迈向以个性驱动的基于论证的旅游谈判对话系统</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Priyanshu Priya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Priyanshu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Priyanshu</a> Priya), [Saurav Dudhate](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Saurav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Saurav</a> Dudhate), [Desai Vishesh Yasheshbhai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Desai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Desai</a> Vishesh Yasheshbhai), [Asif Ekbal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Asif"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Asif</a> Ekbal)</p>
<p>将论证机制整合到谈判对话系统中，可以通过交换论点和批评来改善冲突的解决。此外，结合个性属性可以通过使互动与个人的喜好和风格保持一致来增强适应性。为了在谈判对话系统中提高这些能力，我们提出了一种新颖的基于人格驱动的基于论证的谈判对话生成 （PAN-DG） 任务。为了支持这项任务，我们引入了 PACT，这是一个旅游业基于个性驱动的基于论证的谈判对话数据集。该数据集使用大型语言模型 （LLM） 生成，具有三种不同的性格特征，即论证特征、偏好特征和购买风格特征，以模拟涉及不同性格的各种谈判场景。彻底的自动和手动评估表明该数据集包含高质量的对话。此外，我们还对 PAN-DG 任务的预训练和微调 LLM 进行了比较实验。多维度评估表明，经过微调的LLM在谈判过程中有效地产生了人格驱动的理性反应。这凸显了 PACT 在增强谈判对话系统个性化和推理能力方面的有效性，从而为该领域的未来研究奠定基础。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 06：16：42 UTC</p>
<h2 id="163-机器学习在纠正缺陷引起的神经形态电路推理错误中的应用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11113"target="_blank" rel="external nofollow noopener noreferrer">#163</a> <a href="https://papers.cool/arxiv/2509.11113"target="_blank" rel="external nofollow noopener noreferrer">机器学习在纠正缺陷引起的神经形态电路推理错误中的应用</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Vedant Sawal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vedant"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vedant</a> Sawal), [Hiu Yung Wong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hiu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hiu</a> Yung Wong)</p>
<p>本文提出了一种基于机器学习的方法，用于纠正基于全模拟ReRAM的神经形态电路中由卡住故障引起的推理错误。使用设计技术协同优化 （DTCO） 仿真框架，我们对多阵列神经形态架构的多层中的六种空间缺陷类型（圆形、圆形补码、环形、行、列和棋盘格）进行建模和分析。我们证明，所提出的校正方法采用在电路输出电压上训练的轻量级神经网络，在缺陷场景中可以恢复高达 35%（从 55% 到 90%）的推理精度损失。我们基于手写数字识别任务的结果表明，即使是小型校正网络也可以显着提高电路鲁棒性。该方法为边缘和物联网 （IoT） 应用中的神经形态系统提供了一条可扩展且节能的途径，以提高产量和可靠性。除了纠正训练期间使用的特定缺陷类型外，我们的方法还展示了在训练期间未发现的不同类型的缺陷上进行测试时的概括能力，从而达到合理的准确性。该框架可以轻松扩展以支持实时自适应学习，从而能够对动态或老化引起的故障曲线进行片上校正。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NE"target="_blank" rel="external nofollow noopener noreferrer">神经和进化计算</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 06：05：27 UTC</p>
<h2 id="164-用于与变压器的-v2v-通信的多模态传感辅助毫米波波束成形-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11112"target="_blank" rel="external nofollow noopener noreferrer">#164</a> <a href="https://papers.cool/arxiv/2509.11112"target="_blank" rel="external nofollow noopener noreferrer">用于与变压器的 V2V 通信的多模态传感辅助毫米波波束成形</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Muhammad Baqer Mollah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhammad</a> Baqer Mollah), [Honggang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Honggang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Honggang</a> Wang), [Hua Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hua</a> Fang)</p>
<p>波束成形技术用于毫米波 （mmWave） 通信，以解决固有的路径损耗限制，从而建立和维持可靠的连接。然而，在高度动态的车辆环境中采用标准定义的波束成形方法通常会产生高波束训练开销并减少可用于通信的通话时间，这主要是由于交换导频信号和详尽的波束测量。为此，我们提出了一种多模态传感和融合学习框架，作为减少此类开销的潜在替代解决方案。在该框架中，我们首先通过模态专用编码器从视觉和GPS坐标感知模态中单独提取特征，然后融合多模态特征，得到预测的top-k波束，从而主动建立最佳视线链路。为了展示所提出框架的泛化性，我们从真实世界的多模态感知和通信数据集中，在四种不同的车对车（V2V）场景中进行了综合实验。从实验中，我们观察到，所提出的框架在正确预测前15波束方面实现了高达77.58%的准确率，优于单一模态，平均功率损耗大致低至2.32 dB，并且与标准定义方法相比，前15波束的波束搜索空间开销大大降低了76.56%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.ET"target="_blank" rel="external nofollow noopener noreferrer">新兴技术</a>, <a href="https://papers.cool/arxiv/cs.IT"target="_blank" rel="external nofollow noopener noreferrer">信息论</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 06：03：42 UTC</p>
<h2 id="165-流体语言模型基准测试-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11106"target="_blank" rel="external nofollow noopener noreferrer">#165</a> <a href="https://papers.cool/arxiv/2509.11106"target="_blank" rel="external nofollow noopener noreferrer">流体语言模型基准测试</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Valentin Hofmann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Valentin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Valentin</a> Hofmann), [David Heineman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Heineman), [Ian Magnusson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> Magnusson), [Kyle Lo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyle"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyle</a> Lo), [Jesse Dodge](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jesse"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jesse</a> Dodge), [Maarten Sap](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maarten"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maarten</a> Sap), [Pang Wei Koh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pang</a> Wei Koh), [Chun Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chun</a> Wang), [Hannaneh Hajishirzi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hannaneh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hannaneh</a> Hajishirzi), [Noah A. Smith](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Noah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Noah</a> A. Smith)</p>
<p>语言模型 （LM） 基准测试面临多项挑战：综合评估成本高昂，基准测试通常无法衡量预期能力，并且评估质量可能会因标记错误和基准测试饱和而下降。尽管已经提出了各种策略来缓解这些问题，但它们往往孤立地解决各个方面，而忽略了有关整体评估质量的更广泛问题。在这里，我们介绍了流体基准测试，这是一种新的评估方法，可在多个维度上推进 LM 基准测试。受心理测量学的启发，流体基准测试基于基准项目的相对价值取决于 LM 的能力水平的见解，这表明评估应该适应每个 LM。在方法论上，流体基准测试根据现有的 LM 评估结果估计项目响应模型，并使用推断的数量动态选择评估项目，类似于教育中的计算机化自适应测试。在我们的实验中，我们将流体基准测试与随机项目抽样的常见做法以及更复杂的基线进行了比较，包括基于项目响应理论的替代方法。我们检查了四个维度——效率、有效性、方差和饱和度——并发现流体基准测试在所有这些维度上都取得了卓越的性能（例如，MMLU 的有效性更高，方差更小，项目减少了 50 倍）。我们的分析表明，流体基准测试的两个组成部分具有不同的效果：项目响应理论，用于将性能映射到潜在能力空间中，提高了有效性，而动态项目选择则减少了方差。总体而言，我们的结果表明，通过超越静态评估，可以显着改进 LM 基准测试。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-14 05：49：42 UTC</p>
<h2 id="166-panolora通过-lora-适配连接透视和全景视频生成-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11092"target="_blank" rel="external nofollow noopener noreferrer">#166</a> <a href="https://papers.cool/arxiv/2509.11092"target="_blank" rel="external nofollow noopener noreferrer">PanoLora：通过 LoRA 适配连接透视和全景视频生成</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zeyu Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zeyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zeyu</a> Dong), [Yuyang Yin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuyang</a> Yin), [Yuqi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuqi</a> Li), [Eric Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eric"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eric</a> Li), [Hao-Xiang Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hao-Xiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hao-Xiang</a> Guo), [Yikai Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yikai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yikai</a> Wang)</p>
<p>由于全景投影和传统透视投影之间的根本差异，生成高质量的 360{\deg} 全景视频仍然是一项重大挑战。透视视频依赖于视野有限的单一视点，而全景内容则需要渲染整个周围环境，这使得标准视频生成模型难以适应。现有解决方案通常会引入复杂的架构或大规模训练，导致效率低下和结果不理想。在低秩自适应（LoRA）在风格迁移任务中的成功推动下，我们建议从透视角度将全景视频生成视为一个自适应问题。通过理论分析，我们证明了当LoRA的秩超过任务中的自由度时，LoRA可以有效地对这些投影之间的转换进行建模。我们的方法仅使用大约 1,000 个视频有效地微调预训练的视频扩散模型，同时实现高质量的全景生成。实验结果表明，我们的方法保持了适当的投影几何形状，并在视觉质量、左右一致性和运动多样性方面超越了以前最先进的方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-14 05：05：27 UTC</p>
<h2 id="167-用于文本-语音对齐的长度感知旋转位置嵌入-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11084"target="_blank" rel="external nofollow noopener noreferrer">#167</a> <a href="https://papers.cool/arxiv/2509.11084"target="_blank" rel="external nofollow noopener noreferrer">用于文本-语音对齐的长度感知旋转位置嵌入</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Hyeongju Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyeongju"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyeongju</a> Kim), [Juheon Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juheon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juheon</a> Lee), [Jinhyeok Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinhyeok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinhyeok</a> Yang), [Jacob Morton](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jacob"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jacob</a> Morton)</p>
<p>许多最近的文本转语音 （TTS） 系统都是建立在 Transformer 架构之上的，并采用交叉注意力机制进行文本-语音对齐。在这些系统中，旋转位置嵌入 （RoPE） 通常用于对文本和语音表示中的位置信息进行编码。在这项工作中，我们引入了长度感知 RoPE （LARoPE），这是一种简单而有效的 RoPE 扩展，可改善文本语音对齐。与依赖绝对索引的 RoPE 不同，LARoPE 使用长度归一化索引计算查询和键位置之间的相对距离。实验结果表明，LARoPE 的性能始终优于 RoPE，提供更快的损耗收敛、更准确的文本-语音对齐和更高的整体 TTS 质量。此外，LARoPE 对话语持续时间变化表现出更强的弹性，并在长达 30 秒的延长语音生成中保持稳定的性能，而 RoPE 则遭受显着的退化。值得注意的是，我们的方法在标准零样本 TTS 基准测试上实现了最先进的单词错误率。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">音频和语音处理</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a></p>
<p><strong>发布</strong>: 2025-09-14 04：25：13 UTC</p>
<h2 id="168-推荐系统成员推理攻击调查-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11080"target="_blank" rel="external nofollow noopener noreferrer">#168</a> <a href="https://papers.cool/arxiv/2509.11080"target="_blank" rel="external nofollow noopener noreferrer">推荐系统成员推理攻击：调查</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jiajie He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiajie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiajie</a> He), [Yuechun Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuechun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuechun</a> Gu), [Keke Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keke</a> Chen), [Xintong Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xintong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xintong</a> Chen)</p>
<p>推荐系统 （RecSys） 已广泛应用于各种应用，包括电子商务、金融、医疗保健、社交媒体，并在塑造用户行为和决策方面变得越来越有影响力，凸显了它们在各个领域日益增长的影响。然而，最近的研究表明，RecSys 容易受到成员推理攻击（MIA）的攻击，该攻击旨在推断用户交互记录是否被用于训练目标模型。RecSys 模型上的 MIA 可以直接导致隐私泄露。例如，通过识别用于训练与特定用户关联的 RecSys 的购买记录这一事实，攻击者可以推断出该用户的特殊怪癖。近年来，MIA 已被证明对其他 ML 任务有效，例如分类模型和自然语言处理。然而，由于看不见的后验概率，传统的 MIA 不适合 RecSys。尽管 RecSys 上的 MIA 形成了一个新兴且快速发展的研究领域，但目前还没有针对该主题的系统调查。在本文中，我们对 RecSys MIA 进行了首次全面调查。本调查全面回顾了 RecSys MIA 的最新进展，探讨了与这一新兴领域相关的设计原则、挑战、攻击和防御。我们提供了一个统一的分类法，根据不同的 RecSys MIA 的特征对它们进行分类，并讨论它们的优缺点。基于本次调查中发现的局限性和差距，我们指出了几个有前途的未来研究方向，以激励希望关注该领域的研究人员。这项调查不仅为研究界提供了参考，也为该研究领域之外的研究人员提供了清晰的描述。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a></p>
<p><strong>发布</strong>: 2025-09-14 04：06：03 UTC</p>
<h2 id="169-cvpr-2024-自动驾驶大挑战赛语言驾驶赛道-cps-团队的系统描述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11071"target="_blank" rel="external nofollow noopener noreferrer">#169</a> <a href="https://papers.cool/arxiv/2509.11071"target="_blank" rel="external nofollow noopener noreferrer">CVPR 2024 自动驾驶大挑战赛语言驾驶赛道 CPS 团队的系统描述</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jinghan Peng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinghan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinghan</a> Peng), [Jingwen Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingwen</a> Wang), [Xing Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xing</a> Yu), [Dehui Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dehui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dehui</a> Du)</p>
<p>本报告概述了我们在 CVPR 2024 自动驾驶大挑战赛的语言驾驶赛道中使用视觉语言模型系统的方法。我们专门使用 DriveLM-nuScenes 数据集来训练我们的模型。我们的系统建立在 LLaVA 模型之上，我们通过使用 LoRA 和 DoRA 方法进行微调对其进行了增强。此外，我们还集成了来自开源深度估计模型的深度信息，以丰富训练和推理过程。对于推理，特别是多项选择题和是/否问题，我们采用了思维链推理方法来提高结果的准确性。这种全面的方法使我们在验证集排行榜上获得了 0.7799 的最高分，在排行榜上排名第一。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-14 03：37：17 UTC</p>
<h2 id="170-一种用于有限数据下轴承故障诊断的先进卷积神经网络-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11053"target="_blank" rel="external nofollow noopener noreferrer">#170</a> <a href="https://papers.cool/arxiv/2509.11053"target="_blank" rel="external nofollow noopener noreferrer">一种用于有限数据下轴承故障诊断的先进卷积神经网络</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Shengke Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shengke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shengke</a> Sun), [Shuzhen Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuzhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuzhen</a> Han), [Ziqian Luan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziqian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziqian</a> Luan), [Xinghao Qin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinghao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinghao</a> Qin), [Jiao Yin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiao</a> Yin), [Zhanshan Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhanshan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhanshan</a> Zhao), [Jinli Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinli"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinli</a> Cao), [Hua Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hua</a> Wang)</p>
<p>在轴承故障诊断领域，深度学习（DL）方法近年来得到了广泛的应用。然而，由于成本高昂或隐私问题，高质量的标记数据在现实场景中是稀缺的。虽然少样本学习在解决数据稀缺问题方面显示出希望，但现有方法在该领域仍面临重大局限性。传统的数据增强技术经常存在模式崩溃的问题，并生成低质量的样本，无法捕获轴承故障模式的多样性。此外，具有局部感受野的传统卷积神经网络（CNN）不足以从复杂的振动信号中提取全局特征。此外，现有方法无法对有限训练样本之间的复杂关系进行建模。针对这些问题，提出了一种先进的数据增强和对比傅里叶卷积框架（DAC-FCF），用于有限数据下的轴承故障诊断。首先，提出一种新型的条件一致潜在表示与重建生成对抗网络（CCLR-GAN）来生成更多样化的数据。其次，利用基于对比学习的联合优化机制，更好地对可用训练数据之间的关系进行建模;最后，我们提出了一种一维傅里叶卷积神经网络（1D-FCNN），以实现对输入数据的全局感知。实验表明，DAC-FCF 取得了显着的改进，在凯斯西储大学 （CWRU） 数据集上比基线高出 32%，在自收集的测试台上比基线高出 10%。广泛的消融实验证明了所提出组件的有效性。因此，所提出的DAC-FCF为有限数据下的轴承故障诊断提供了一种有前途的解决方案。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a></p>
<p><strong>发布</strong>: 2025-09-14 02：41：48 UTC</p>
<h2 id="171-fragmentgpt用于分子设计中片段生长链接和合并的统一-gpt-模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11044"target="_blank" rel="external nofollow noopener noreferrer">#171</a> <a href="https://papers.cool/arxiv/2509.11044"target="_blank" rel="external nofollow noopener noreferrer">FragmentGPT：用于分子设计中片段生长、链接和合并的统一 GPT 模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xuefeng Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuefeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuefeng</a> Liu), [Songhao Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Songhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Songhao</a> Jiang), [Qinan Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qinan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qinan</a> Huang), [Tinson Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tinson"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tinson</a> Xu), [Ian Foster](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> Foster), [Mengdi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengdi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengdi</a> Wang), [Hening Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hening"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hening</a> Lin), [Jinbo Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinbo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinbo</a> Xu), [Rick Stevens](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rick</a> Stevens)</p>
<p>基于片段的药物发现 （FBDD） 是早期药物开发中的一种流行方法，但设计有效的连接子以将断开的分子片段组合成化学和药理学上可行的候选药物仍然具有挑战性。当片段包含结构冗余（例如重复环）时，就会出现进一步的复杂性，这些冗余无法通过简单地添加或删除原子或键来解决。为了在统一的框架中应对这些挑战，我们引入了 FragmentGPT，它集成了两个核心组件：（1） 一种新型的化学感知、基于能量的键切割预训练策略，为基于 GPT 的模型配备了片段增长、链接和合并能力，以及 （2） 一种新颖的奖励排名对齐专家探索 （RAE） 算法，该算法结合了专家模仿学习以增强多样性， 帕累托和综合得分最优性的数据选择和增强，以及监督微调 （SFT） 以使学习者策略与多目标保持一致。以片段对为条件，FragmentGPT 生成连接不同分子亚基的连接子，同时针对多个药物目标进行优化。它还学习通过智能合并解决结构冗余，例如重复片段，从而能够合成优化的分子。FragmentGPT 促进受控的、目标驱动的分子组装。对真实世界癌症数据集的实验和消融研究表明，它能够生成为下游药物发现任务量身定制的化学有效、高质量分子的能力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/q-bio.BM"target="_blank" rel="external nofollow noopener noreferrer">生物分子</a></p>
<p><strong>发布</strong>: 2025-09-14 02：17：07 UTC</p>
<h2 id="172-硬度结构知识和机会模块化性能建模的分析框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.11000"target="_blank" rel="external nofollow noopener noreferrer">#172</a> <a href="https://papers.cool/arxiv/2509.11000"target="_blank" rel="external nofollow noopener noreferrer">硬度、结构知识和机会：模块化性能建模的分析框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Omid Gheibi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Omid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Omid</a> Gheibi), [Christian Kästner](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christian</a> Kästner), [Pooyan Jamshidi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pooyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pooyan</a> Jamshidi)</p>
<p>性能影响模型有助于理解配置如何影响系统性能，但由于配置空间呈指数级增长，创建它们具有挑战性。虽然灰盒方法利用选择性的“结构知识”（如系统的模块执行图）来改进建模，但这些知识、系统特征（我们称之为“结构方面”）和潜在模型改进之间的关系尚不清楚。本文通过正式调查结构方面的变化（例如，模块数量和每个模块的选项）和结构知识水平如何影响为改进“模块化性能建模”创造“机会”来解决这一差距。我们引入并量化了建模“硬度”的概念，定义为性能建模的固有难度。通过使用合成系统模型进行受控实验，我们建立了一个“分析矩阵”来测量这些概念。我们的研究结果表明，建模硬度主要由模块数量和每个模块的配置选项驱动。更重要的是，我们证明，更高水平的结构知识和增加的建模硬度都显着增加了改进的机会。这些因素的影响因性能指标而异;对于排名准确性（例如，在调试任务中），结构知识更占主导地位，而对于预测准确性（例如，在资源管理任务中），硬度起着更强的作用。这些结果为系统设计人员提供了可作的见解，指导他们战略性地分配时间，并根据系统的特征和给定任务的目标选择适当的建模方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-13 22：52：10 世界标准时间</p>
<h2 id="173-配水管网泄漏定位的因子图优化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10982"target="_blank" rel="external nofollow noopener noreferrer">#173</a> <a href="https://papers.cool/arxiv/2509.10982"target="_blank" rel="external nofollow noopener noreferrer">配水管网泄漏定位的因子图优化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Paul Irofti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Paul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Paul</a> Irofti), [Luis Romero-Ben](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luis</a> Romero-Ben), [Florin Stoican](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Florin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Florin</a> Stoican), [Vicenç Puig](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vicen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vicen</a>ç Puig)</p>
<p>检测和定位配水管网系统中的泄漏是一个对环境、经济和社会有直接影响的重要课题。我们的论文是第一篇探索使用因子图优化技术进行配水网络泄漏定位的论文，使我们能够在压力和需求传感器读数之间进行传感器融合，并估计所有网络节点上网络的时间和结构状态演变。该方法引入了特定的水网因子，并提出了由无泄漏状态估计因子图和泄漏定位因子图两个因子图组成的新架构。当获得新的传感器读数时，与卡尔曼和其他基于插值的方法不同，这些方法仅估计当前网络状态，因子图会更新当前和过去的状态。Modena、L-TOWN 和合成网络的结果表明，因子图比基于非线性卡尔曼的替代方案（如 UKF）快得多，同时与最先进的估计-定位方法相比，在定位方面也提供了改进。实施和基准可在 <a href="https://github.com/pirofti/FGLL"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/pirofti/FGLL</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.SY"target="_blank" rel="external nofollow noopener noreferrer">系统和控制</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-13 21：06：27 UTC</p>
<h2 id="174-神经网络训练中的解耦搜索和学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10973"target="_blank" rel="external nofollow noopener noreferrer">#174</a> <a href="https://papers.cool/arxiv/2509.10973"target="_blank" rel="external nofollow noopener noreferrer">神经网络训练中的解耦搜索和学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Akshay Vegesna](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Akshay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Akshay</a> Vegesna), [Samip Dahal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Samip"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Samip</a> Dahal)</p>
<p>梯度下降通常收敛到训练损失的单个最小值，而没有机制来探索可能更好地泛化的替代最小值。直接在高维参数空间中搜索不同的最小值通常是棘手的。为了解决这个问题，我们提出了一个框架，该框架在两个不同的阶段进行训练：在可处理的表示空间（中间激活空间）中搜索以找到不同的表征解决方案，以及通过回归到这些搜索到的表示在参数空间中进行基于梯度的学习。通过进化搜索，我们发现了其适应性和多样性随计算而扩展的表征解决方案——更大的种群和更多的代际会产生更好、更多样化的解决方案。这些表示被证明是可学习的：通过回归到搜索的表示来训练的网络接近 SGD 在 MNIST、CIFAR-10 和 CIFAR-100 上的表现。随着搜索计算达到饱和，性能会得到提高。生成的模型与使用梯度下降训练的网络在质量上有所不同，在训练过程中遵循不同的表示轨迹。这项工作展示了未来的训练算法如何通过将表示空间中的搜索与参数空间中基于梯度的高效学习解耦来克服梯度下降的探索性局限性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 20：22：43 UTC</p>
<h2 id="175-phlora从全等级检查点提取无数据的事后低秩适配器-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10971"target="_blank" rel="external nofollow noopener noreferrer">#175</a> <a href="https://papers.cool/arxiv/2509.10971"target="_blank" rel="external nofollow noopener noreferrer">PHLoRA：从全等级检查点提取无数据的事后低秩适配器</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Bhoomit Vasani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bhoomit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bhoomit</a> Vasani), [Jack FitzGerald](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jack"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jack</a> FitzGerald), [Anjie Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anjie</a> Fang), [Sushmit Vaish](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sushmit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sushmit</a> Vaish)</p>
<p>我们介绍 PHLoRA（发音为“菌群”）。（事后 LoRA），一种简单而强大的方法，可以从全秩微调模型中提取低秩适应适配器，而无需访问训练数据或梯度。通过计算基础模型与其微调模型之间权重差异的低秩分解，我们的方法重建了适配器模块，这些模块可以在推理时通过 S-LoRA 合并或动态路由，或者使用 NVIDIA NIM 等平台在可扩展的行业环境中提供服务。这种方法可以摊销请求之间的延迟开销，并节省大量成本。与之前显式训练每个适配器的工作不同，我们的方法将微调与适配器生成分离，允许从现有的全秩模型或第三方检查点中提取适配器。使用 Amazon Nova 模型系列对文本、图像和视频基准测试进行的实验表明，提取的适配器保留了全权重增量的高能量，可以安全地修剪，并且在重新合并时对下游任务性能的下降可以忽略不计。总体而言，PHLoRA 为使所有现有的全秩检查点适配器就绪提供了一条实用的途径，使所有模型的可扩展推理民主化。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 20：13：58 UTC</p>
<h2 id="176-心因性机器在大型语言模型中模拟人工智能精神病妄想强化和伤害支持-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10970"target="_blank" rel="external nofollow noopener noreferrer">#176</a> <a href="https://papers.cool/arxiv/2509.10970"target="_blank" rel="external nofollow noopener noreferrer">心因性机器：在大型语言模型中模拟人工智能精神病、妄想强化和伤害支持。</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Joshua Au Yeung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joshua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joshua</a> Au Yeung), [Jacopo Dalmasso](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jacopo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jacopo</a> Dalmasso), [Luca Foschini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luca</a> Foschini), [Richard JB Dobson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Richard"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Richard</a> JB Dobson), [Zeljko Kraljevic](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zeljko"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zeljko</a> Kraljevic)</p>
<p>背景：关于“人工智能精神病”的新报告正在增加，用户与法学硕士的互动可能会加剧或诱发精神病或不良心理症状。法学硕士的阿谀奉承和宜人的性质可能是有益的，它可以通过强化弱势用户的妄想信念而成为伤害的载体。方法：我们引入了精神病长凳，这是一种新颖的基准，旨在系统地评估法学硕士的心因性，包括 16 个结构化、12 轮对话场景，模拟妄想主题（色情妄想、宏大/弥赛亚妄想、参考妄想）的进展和潜在危害。我们评估了八个著名的法学硕士，用于在显性和隐性对话环境中进行妄想确认 （DCS）、伤害支持 （HES） 和安全干预 （SIS）。研究结果：在 1,536 次模拟对话中，所有法学硕士都表现出心因性潜力，表现出延续妄想而不是挑战妄想的强烈倾向（平均 DCS 为 0.91 ±0.88）. 模型经常启用有害用户请求（平均 HES 为 0.69） ±0.84），并且仅在大约三分之一的适用转弯中提供了安全干预（平均 SIS 为 0.37 ±0.48）. 51/128 （39.8%） 的情景没有提供安全干预措施。在隐性场景中，表现明显更差，模型更有可能证实妄想并造成伤害，同时提供的干预措施更少（p &lt; .001）。发现 DCS 和 HES 之间存在很强的相关性 （rs = .77）。模型性能差异很大，表明安全性不仅仅是规模的紧急属性。结论：这项研究将法学硕士的心因性确立为一种可量化的风险，并强调迫切需要重新思考我们如何训练法学硕士。我们将这个问题不仅视为技术挑战，而且视为需要开发人员、政策制定者和医疗保健专业人员之间合作的公共卫生当务之急。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 20：10：28 UTC</p>
<h2 id="177-测试-llm-响应差异由语义上不相关的查询扰动组成的复合-null-的情况-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10963"target="_blank" rel="external nofollow noopener noreferrer">#177</a> <a href="https://papers.cool/arxiv/2509.10963"target="_blank" rel="external nofollow noopener noreferrer">测试 LLM 响应差异：由语义上不相关的查询扰动组成的复合 null 的情况</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Aranyak Acharyya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aranyak"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aranyak</a> Acharyya), [Carey E. Priebe](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Carey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Carey</a> E. Priebe), [Hayden S. Helm](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hayden"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hayden</a> S. Helm)</p>
<p>给定输入查询，大型语言模型等生成模型会生成从响应分布中提取的随机响应。给定两个输入查询，很自然地会询问它们的响应分布是否相同。虽然传统的统计假设检验旨在解决这个问题，但输入查询引起的响应分布通常对语义上与查询无关的扰动很敏感，以至于传统的相等性检验可能表明两个语义上等效的查询会引起统计上不同的响应分布。因此，统计测试的结果可能与用户的要求不符。在本文中，我们通过在测试过程中考虑语义上相似的查询集合来解决这种不一致的问题。在我们的设置中，从用户定义的语义相似查询集合到相应的响应分布集合的映射是先验未知的，必须在固定预算下进行估计。尽管我们解决的问题非常普遍，但我们将分析重点放在响应为二元的设置上，表明所提出的测试是渐近有效且一致的，并讨论了有关功率和计算的重要实际考虑因素。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/math.ST"target="_blank" rel="external nofollow noopener noreferrer">统计理论</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/stat.ME"target="_blank" rel="external nofollow noopener noreferrer">方法论</a></p>
<p><strong>发布</strong>: 2025-09-13 19：44：42 UTC</p>
<h2 id="178-vistr-gp自动化机器人作中通过视觉到状态张量回归和高斯过程进行在线网络攻击检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10948"target="_blank" rel="external nofollow noopener noreferrer">#178</a> <a href="https://papers.cool/arxiv/2509.10948"target="_blank" rel="external nofollow noopener noreferrer">ViSTR-GP：自动化机器人作中通过视觉到状态张量回归和高斯过程进行在线网络攻击检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Navid Aftabi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Navid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Navid</a> Aftabi), [Philip Samaha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Philip"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Philip</a> Samaha), [Jin Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jin</a> Ma), [Long Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Long"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Long</a> Cheng), [Ramy Harik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ramy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ramy</a> Harik), [Dan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dan</a> Li)</p>
<p>工业机器人系统是智能制造运营自动化的核心。互联和自动化工厂面临着日益增长的网络安全风险，这些风险可能会导致物理运营中断和损坏。在这些攻击中，数据完整性攻击通常涉及对漏洞的复杂利用，使攻击者能够访问和纵作数据，因此仅通过现有的入侵检测或基于模型的检测很难检测到。本文通过开发在线检测框架 ViSTR-GP 解决了利用现有侧信道检测机器人制造过程中的数据完整性攻击所面临的挑战，该框架将编码器报告的测量值与控制器权限之外的架空摄像头基于视觉的估计值进行交叉检查。在这个框架中，一次互式分割初始化 SAM-Track 以生成每帧掩码。低秩张量回归代理将每个掩码映射到测量值，而矩阵变量高斯过程对名义残差进行建模，捕获时间结构和交叉联合相关性。从预测分布得出的逐帧检验统计量为在线检测器提供了可解释的阈值。我们在具有同步视频帧和编码器数据的真实机器人测试台上验证了该框架，收集了多个标称周期并构建了具有分级末端执行器偏差的重放攻击场景。测试台上的结果表明，所提出的框架可以准确地恢复关节角度，并比所有基线更频繁地检测到数据完整性攻击。这些改进在最微妙的攻击中最为明显。这些结果表明，工厂可以通过添加独立的物理通道来检测数据完整性攻击，绕过控制器的权限，而无需复杂的仪器。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/eess.SY"target="_blank" rel="external nofollow noopener noreferrer">系统和控制</a>, <a href="https://papers.cool/arxiv/math.OC"target="_blank" rel="external nofollow noopener noreferrer">优化与控制</a></p>
<p><strong>发布</strong>: 2025-09-13 19：10：35 UTC</p>
<h2 id="179-当代码自动驾驶仪中断时为什么法学硕士在嵌入式机器学习中步履蹒跚-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10946"target="_blank" rel="external nofollow noopener noreferrer">#179</a> <a href="https://papers.cool/arxiv/2509.10946"target="_blank" rel="external nofollow noopener noreferrer">当代码自动驾驶仪中断时：为什么法学硕士在嵌入式机器学习中步履蹒跚</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Roberto Morabito](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Roberto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Roberto</a> Morabito), [Guanghan Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guanghan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guanghan</a> Wu)</p>
<p>大型语言模型 （LLM） 越来越多地用于在嵌入式机器学习工作流程中自动生成软件，但它们的输出经常静默失败或行为不可预测。本文基于协调数据预处理、模型转换和设备上推理代码生成的自动驾驶框架，对 LLM 支持的 ML 管道中的故障模式进行了实证研究。我们展示了提示格式、模型行为和结构假设如何影响成功率和失败特征，通常以标准验证管道无法检测到的方式影响成功率和失败特征。我们的分析揭示了一系列各种容易出错的行为，包括格式引起的误解和编译但下游中断的运行时破坏性代码。我们推导出故障类别的分类法，并分析多个 LLM 的错误，突出常见的根本原因和系统脆弱性。尽管基于特定设备，但我们的研究揭示了基于 LLM 的代码生成面临的更广泛的挑战。最后，我们讨论了提高 LLM 驱动的嵌入式 ML 系统的可靠性和可追溯性的方向。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 19：00：04 世界标准时间</p>
<h2 id="180-阐明模型透明度使用-mnist-和-imdb-示例进行深度学习中的可解释性与可解释性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10929"target="_blank" rel="external nofollow noopener noreferrer">#180</a> <a href="https://papers.cool/arxiv/2509.10929"target="_blank" rel="external nofollow noopener noreferrer">阐明模型透明度：使用 MNIST 和 IMDB 示例进行深度学习中的可解释性与可解释性</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Mitali Raj](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mitali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mitali</a> Raj)</p>
<p>深度学习模型令人印象深刻的功能往往被其固有的不透明度所抵消，通常被称为“黑匣子”问题，这阻碍了它们在高信任领域中的广泛接受。作为回应，可解释性和可解释叉学科共同属于可解释人工智能 （XAI） 保护伞，已成为研究的焦点。尽管这些术语经常用作同义词，但它们具有不同的概念权重。本文档对深度学习范式中的可解释性和可解释性进行了比较探索，仔细概述了它们各自的定义、目标、流行的方法和固有的困难。通过对 MNIST 数字分类任务和 IMDB 情感分析的说明性检查，我们证实了一个关键论点：可解释性通常与模型人类理解其作机制（全局理解）的固有能力有关，而可解释性更常见于旨在阐明模型个体预测或行为（局部解释）基础的事后技术。例如，特征归因方法可以揭示为什么特定的 MNIST 图像被识别为“7”，单词级重要性可以阐明 IMDB 情绪结果。然而，这些局部见解并不能使复杂的底层模型全局透明。正如这些标准数据集所证明的那样，清楚地掌握这种差异对于培育可靠和健全的人工智能至关重要。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 18：06：55 UTC</p>
<h2 id="181-toma使用扩散模型生成图像的代币合并与注意力-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10918"target="_blank" rel="external nofollow noopener noreferrer">#181</a> <a href="https://papers.cool/arxiv/2509.10918"target="_blank" rel="external nofollow noopener noreferrer">ToMA：使用扩散模型生成图像的代币合并与注意力</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wenbo Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenbo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenbo</a> Lu), [Shaoyi Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaoyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaoyi</a> Zheng), [Yuxuan Xia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxuan</a> Xia), [Shengjie Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shengjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shengjie</a> Wang)</p>
<p>扩散模型在高保真图像生成方面表现出色，但由于 Transformer 的二次注意力复杂性而面临可扩展性限制。ToMeSD 和 ToFu 等即插即用令牌减少方法通过合并生成图像中的冗余令牌来减少 FLOP，但依赖于 GPU 效率低下的作（例如，排序、分散写入），引入开销，在与优化的注意力实现（例如 FlashAttention）配对时抵消理论加速。为了弥合这一差距，我们提出了 Token Merge with Attention （ToMA），这是一种现成的方法，它重新设计了 token 减少以实现与 GPU 对齐的效率，具有三个关键贡献：1） 将 token 合并重新表述为一个子模块优化问题，以选择不同的 token;2） 通过 GPU 友好的矩阵运算将合并/取消合并作为类似注意力的线性变换;3） 利用潜在局部性和顺序冗余（模式重用）来最大限度地减少开销。ToMA 将 SDXL/Flux 生成延迟分别降低 24%/23%（使用 DINO Δ&lt;0.07），优于以前的方法。这项工作弥合了变压器扩散效率理论和实际效率之间的差距。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 17：35：00 世界标准时间</p>
<h2 id="182-culturesynth用于文化问答综合的分层分类学指导和检索增强框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10886"target="_blank" rel="external nofollow noopener noreferrer">#182</a> <a href="https://papers.cool/arxiv/2509.10886"target="_blank" rel="external nofollow noopener noreferrer">CultureSynth：用于文化问答综合的分层分类学指导和检索增强框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xinyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinyu</a> Zhang), [Pei Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pei</a> Zhang), [Shuang Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuang</a> Luo), [Jialong Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jialong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jialong</a> Tang), [Yu Wan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Wan), [Baosong Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baosong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baosong</a> Yang), [Fei Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fei</a> Huang)</p>
<p>文化能力被定义为理解和适应多元文化背景的能力，对于全球环境中的大型语言模型 （LLM） 来说越来越重要。虽然存在多种文化基准来评估法学硕士的文化能力，但目前的评估存在分类法分散、领域特异性以及严重依赖手动数据注释的问题。为了解决这些限制，我们引入了 CultureSynth，这是一个新颖的框架，包括 （1） 涵盖 12 个主要主题和 130 个次要主题的综合分层多语言文化分类法，以及 （2） 基于检索增强生成 （RAG） 的方法，利用事实知识来综合与文化相关的问答对。CultureSynth-7 综合基准测试包含 19,360 种语言的 4,149 个条目和 7 个手动验证的条目。对 14 个不同规模的流行 LLM 的评估揭示了以 ChatGPT-4o-Latest 和 Qwen2.5-72B-Instruct 为主导的清晰性能分层。结果表明，3B 参数阈值对于实现基本文化能力是必要的，模型在知识处理中表现出不同的架构偏差，并且模型之间存在显着的地理差异。我们相信 CultureSynth 为开发具有文化意识的 AI 系统提供了一个可扩展的框架，同时减少了对手动注释的依赖\footnote{基准可在 <a href="https://github.com/Eyr3/CultureSynth.%7d"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Eyr3/CultureSynth.}</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 16：33：56 UTC</p>
<h2 id="183-分子预测的最佳消息传递是简单细心和空间的-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10871"target="_blank" rel="external nofollow noopener noreferrer">#183</a> <a href="https://papers.cool/arxiv/2509.10871"target="_blank" rel="external nofollow noopener noreferrer">分子预测的最佳消息传递是简单、细心和空间的</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alma C. Castaneda-Leautaud](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alma"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alma</a> C. Castaneda-Leautaud), [Rommie E. Amaro](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rommie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rommie</a> E. Amaro)</p>
<p>通过简化消息传递方式和使用捕获分子图多个方面的描述符，可以提高消息传递神经网络用于分子属性预测的预测性能的策略。在这项工作中，我们设计了实现最先进性能的模型架构，超越了更复杂的模型，例如在外部数据库上预训练的模型。我们评估了数据集多样性以补充我们的性能结果，发现结构多样性会影响我们的 MPNN 和特征集中对其他组件的需求。在大多数数据集中，我们最好的架构采用具有注意力机制的双向消息传递，应用于排除自我感知的极简消息表述，强调与经典 MPNN 相比，相对简单的模型会产生更高的类可分离性。相比之下，我们发现卷积归一化因子并没有有利于所有测试数据集中的预测能力。这在全局和节点级输出中得到了证实。此外，我们分析了添加空间特征和使用 3D 图的影响，发现 2D 分子图在与适当选择的 3D 描述符相辅相成时就足够了。这种方法不仅可以保持预测性能，还可以将计算成本降低 50% 以上，使其对于高通量筛选活动特别有利。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/q-bio.BM"target="_blank" rel="external nofollow noopener noreferrer">生物分子</a></p>
<p><strong>发布</strong>: 2025-09-13 15：55：02 UTC</p>
<h2 id="184-gthna用于整体节点异常评估的具有内存重建的局部-全局图转换器-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10869"target="_blank" rel="external nofollow noopener noreferrer">#184</a> <a href="https://papers.cool/arxiv/2509.10869"target="_blank" rel="external nofollow noopener noreferrer">GTHNA：用于整体节点异常评估的具有内存重建的局部-全局图转换器</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mingkang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingkang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingkang</a> Li), [Xuexiong Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuexiong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuexiong</a> Luo), [Yue Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yue</a> Zhang), [Yaoyang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yaoyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yaoyang</a> Li), [Fu Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fu</a> Lin)</p>
<p>图结构数据中的异常检测本质上是一个具有挑战性的问题，因为它需要识别在结构和行为特征上偏离大多数节点的罕见节点。现有的方法，例如基于图卷积网络 （GCN） 的方法，经常遭受过度平滑的问题，这会导致学习到的节点表示变得无法区分。此外，基于图重建的方法在重建过程中容易受到异常节点干扰，导致异常检测不准确。在这项工作中，我们提出了一个新颖的、全面的异常评估框架，该框架集成了三个关键组件：局部-全局Transformer编码器、记忆引导的重建机制和多尺度表示匹配策略。这些组件协同工作，以增强模型捕获局部和全局结构依赖关系的能力，抑制异常节点的影响，并从多个粒度级别评估异常。异常分数是通过结合重建错误和记忆匹配信号来计算的，从而产生更稳健的评估。对七个基准数据集的广泛实验表明，我们的方法优于现有的最先进的方法，为跨各个图域的异常检测提供了全面且通用的解决方案。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 15：52：16 UTC</p>
<h2 id="185-物理信息神经网络求解弯曲时空中的最小曲面-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10866"target="_blank" rel="external nofollow noopener noreferrer">#185</a> <a href="https://papers.cool/arxiv/2509.10866"target="_blank" rel="external nofollow noopener noreferrer">物理信息神经网络求解弯曲时空中的最小曲面</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Koji Hashimoto](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Koji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Koji</a> Hashimoto), [Koichi Kyo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Koichi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Koichi</a> Kyo), [Masaki Murata](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Masaki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Masaki</a> Murata), [Gakuto Ogiwara](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gakuto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gakuto</a> Ogiwara), [Norihiro Tanahashi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Norihiro"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Norihiro</a> Tanahashi)</p>
<p>我们开发了一个基于物理信息神经网络（PINN）的灵活框架，用于解决涉及弯曲时空中最小表面的边界值问题，特别强调奇点和移动边界。通过将底层物理定律编码到损失函数中，并设计包含奇异行为和动态边界的网络架构，我们的方法能够对具有复杂边界条件的常微分方程和偏微分方程进行鲁棒而准确的解。我们通过应用于反德西特（AdS）时空中的最小表面问题来证明该框架的多功能性，包括与理论物理学中弦理论背景下常用的AdS/CFT对应关系（例如威尔逊环和胶子散射幅度）相关的示例。我们的方法有效地处理边界处的奇点，并且还支持“软”（基于损失）和“硬”（基于公式）的边界条件施加，包括将边界位置提升为可训练参数的情况。这里开发的技术不仅限于高能理论物理学，而且广泛适用于数学、工程和自然科学中遇到的边界值问题，只要奇点和移动边界起关键作用。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/hep-th"target="_blank" rel="external nofollow noopener noreferrer">高能物理 - 理论</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/gr-qc"target="_blank" rel="external nofollow noopener noreferrer">广义相对论与量子宇宙学</a></p>
<p><strong>发布</strong>: 2025-09-13 15：41：13 UTC</p>
<h2 id="186-安全运营中心的大型语言模型综合调查-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10858"target="_blank" rel="external nofollow noopener noreferrer">#186</a> <a href="https://papers.cool/arxiv/2509.10858"target="_blank" rel="external nofollow noopener noreferrer">安全运营中心的大型语言模型：综合调查</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ali Habibzadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ali</a> Habibzadeh), [Farid Feyzi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Farid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Farid</a> Feyzi), [Reza Ebrahimi Atani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Reza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Reza</a> Ebrahimi Atani)</p>
<p>大型语言模型 （LLM） 已成为能够理解和生成类人文本的强大工具，在不同领域提供变革潜力。负责保护数字基础设施的安全运营中心 （SOC） 代表了这些领域之一。SOC 是网络安全防御的前线，负责持续监控、检测和响应事件。然而，SOC 面临着持续的挑战，例如警报量大、资源有限、对具有先进知识的专家的需求量大、响应时间延迟以及难以有效利用威胁情报。在这种情况下，法学硕士可以通过自动化日志分析、简化分类、提高检测准确性以及在更短的时间内提供所需的知识来提供有前途的解决方案。该调查系统地探讨了生成式人工智能，更具体地说是法学硕士与 SOC 工作流程的集成，为其能力、挑战和未来方向提供了结构化的视角。我们相信，这项调查为研究人员和 SOC 经理提供了对学术研究中 LLM 整合现状的广泛概述。据我们所知，这是第一项详细研究 LLM 在 SOC 中的应用的综合研究。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 15：27：50 UTC</p>
<h2 id="187-情景记忆的预存储推理将推理负担转移到记忆中以进行个性化对话-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10852"target="_blank" rel="external nofollow noopener noreferrer">#187</a> <a href="https://papers.cool/arxiv/2509.10852"target="_blank" rel="external nofollow noopener noreferrer">情景记忆的预存储推理：将推理负担转移到记忆中以进行个性化对话</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sangyeop Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sangyeop"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sangyeop</a> Kim), [Yohan Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yohan</a> Lee), [Sanghwa Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sanghwa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sanghwa</a> Kim), [Hyunjong Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyunjong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyunjong</a> Kim), [Sungzoon Cho](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sungzoon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sungzoon</a> Cho)</p>
<p>对话式人工智能中有效的长期记忆需要跨多个会话合成信息。然而，当前的系统对响应生成施加了过大的推理负担，使得性能在很大程度上取决于模型大小。我们介绍了 PREMem（情景记忆的预存储推理），这是一种将复杂的推理过程从推理转变为记忆构建的新方法。PREMem 提取细粒度的记忆片段，分为事实信息、经验信息和主观信息;然后，它在跨会话的记忆项之间建立显式关系，捕捉扩展、转换和影响等进化模式。通过在预存储期间而不是在生成响应时执行此推理，PREMem 创建了丰富的表示，同时减少了交互过程中的计算需求。实验表明，所有模型大小的性能都有显着提高，较小的模型实现的结果与更大的基线相当，同时即使在代币预算有限的情况下也能保持有效性。代码和数据集可在 <a href="https://github.com/sangyeop-kim/PREMem"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/sangyeop-kim/PREMem</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 15：18：08 UTC</p>
<h2 id="188-有趣的伴侣对感知到的人工智能幽默与人类生成的幽默的不同神经反应-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10847"target="_blank" rel="external nofollow noopener noreferrer">#188</a> <a href="https://papers.cool/arxiv/2509.10847"target="_blank" rel="external nofollow noopener noreferrer">有趣的伴侣：对感知到的人工智能幽默与人类生成的幽默的不同神经反应</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xiaohui Rao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaohui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaohui</a> Rao), [Hanlin Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hanlin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hanlin</a> Wu), [Zhenguang G. Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenguang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenguang</a> G. Cai)</p>
<p>随着人工智能伴侣能够进行类似人类的交流，包括讲笑话，了解人们对人工智能幽默的认知和情感反应变得越来越重要。这项研究使用脑电图 （EEG） 来比较人们如何处理人工智能和人类来源的幽默。行为分析显示，参与者认为人工智能和人类幽默相当有趣。然而，神经生理学数据表明，人工智能幽默引发的 N400 效应较小，表明在处理不协调过程中减少了认知努力。这伴随着更大的晚期正电位 （LPP），表明更大程度的惊喜和情绪反应。这种增强的 LPP 可能源于违反了对人工智能喜剧能力的低初始期望。此外，出现了一个关键的时间动态：人类体液显示出习惯效应，其特点是随着时间的推移，N400 增加和 LPP 减少。相比之下，人工智能幽默表现出处理效率和情感奖励的提高，N400 下降，LPP 增加。这一轨迹揭示了大脑如何动态更新其人工智能能力的预测模型。这种累积强化过程挑战了幽默中的“算法厌恶”，因为它展示了对人工智能语言模式的认知适应如何导致强烈的情感奖励。此外，参与者对人工智能的社会态度也调节了这些神经反应，更高的感知人工智能可信度与增强的情感参与相关。这些发现表明，大脑对人工智能幽默的反应令人惊讶地积极和强烈，凸显了幽默在促进人与人工智能社交互动的真正参与方面的潜力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 15：05：57 UTC</p>
<h2 id="189-实现自动错误发现对话式人工智能研究-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10833"target="_blank" rel="external nofollow noopener noreferrer">#189</a> <a href="https://papers.cool/arxiv/2509.10833"target="_blank" rel="external nofollow noopener noreferrer">实现自动错误发现：对话式人工智能研究</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Dominic Petrak](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dominic"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dominic</a> Petrak), [Thy Thy Tran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thy</a> Thy Tran), [Iryna Gurevych](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iryna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iryna</a> Gurevych)</p>
<p>尽管基于 LLM 的对话代理表现出很强的流畅性和连贯性，但它们仍然会产生不良行为（错误），这些行为（错误）很难在部署期间阻止用户到达。最近的研究利用大型语言模型 （LLM） 来检测错误并指导响应生成模型进行改进。然而，当前的法学硕士很难识别其指令中未明确指定的错误，例如因响应生成模型更新或用户行为变化而引起的错误。在这项工作中，我们介绍了自动错误发现，这是一个用于检测和定义对话式人工智能错误的框架，并提出了 SEEED（Soft Clustering Extended Encoder-Based Error Detection）作为其实现方法。我们通过放大负样本的距离加权来增强软最近邻损失，并引入基于标签的样本排名来选择高度对比的样本以更好地学习表示。SEEED 在多个错误注释的对话数据集中优于适应的基线（包括 GPT-4o 和 Phi-4），将检测未知错误的准确率提高了 8 个百分点，并展示了对未知意图检测的强泛化性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-13 14：53：22 UTC</p>
<h2 id="190-因素使用风险感知评分进行互补双因素优化的阶乘近似-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10825"target="_blank" rel="external nofollow noopener noreferrer">#190</a> <a href="https://papers.cool/arxiv/2509.10825"target="_blank" rel="external nofollow noopener noreferrer">因素：使用风险感知评分进行互补双因素优化的阶乘近似</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Dongseok Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongseok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongseok</a> Kim), [Wonjun Jeong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wonjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wonjun</a> Jeong), [Gisung Oh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gisung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gisung</a> Oh)</p>
<p>我们提出了 FACTORS，这是一个将实验设计与 Shapley 分解相结合的框架，以解决对训练因子组合敏感的性能和稳定性问题。我们的方法一致地估计主效应和双因素交互作用，然后将它们整合到风险调整后的目标函数中，该函数共同考虑了不确定性和成本，从而能够在固定预算下可靠地选择配置。效果估计是通过两条互补路径实现的：基于条件均值的插件路径，以及从样本中重建 Shapley 贡献的最小二乘路径。这些路径被设计为即使在设计密度和偏置水平不同时也能互补地工作。通过结合估计的标准化、偏差校正和不确定性量化，我们的程序确保了异构因子空间和设计之间的可比性，而轻量级搜索例程即使在大型因子空间内也能在实际时间内产生配置。在理论方面，我们提供了误差分解、样本复杂度分析和最优性间隙的上限。在解释方面，我们以地图形式总结了主效应和交互作用，突出了调整的优先级和安全改进路径。在不同的数据集和设计条件下，我们的方法改进了排名保留和最佳配置识别，降低了决策风险，并提供了一个调整基础，即使在预算限制下也能提供可解释的理由和稳定的性能提升。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-13 14：44：45 UTC</p>
<h2 id="191-重新思考稀疏自动编码器仅从编码器功能中实现公平性和控制的选择和投影-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10809"target="_blank" rel="external nofollow noopener noreferrer">#191</a> <a href="https://papers.cool/arxiv/2509.10809"target="_blank" rel="external nofollow noopener noreferrer">重新思考稀疏自动编码器：仅从编码器功能中实现公平性和控制的选择和投影</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Antonio Bărbălau](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Antonio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Antonio</a> Bărbălau), [Cristian Daniel Păduraru](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cristian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cristian</a> Daniel Păduraru), [Teodor Poncu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Teodor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Teodor</a> Poncu), [Alexandru Tifrea](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexandru"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexandru</a> Tifrea), [Elena Burceanu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Elena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Elena</a> Burceanu)</p>
<p>稀疏自动编码器 （SAE） 已被证明是有价值的，因为它们能够提供可解释和可纵的表示。当前基于 SAE 的去偏差方法纵这些稀疏激活，假设特征表示位于解码器权重内。我们挑战了这一基本假设，并引入了一种以编码器为中心的表示去偏差替代方案，贡献了三个关键发现：（i）我们强调了一种非常规的SAE特征选择策略，（ii）我们提出了一种新的SAE去偏差方法，该方法将输入嵌入与编码器权重正交，以及（iii）我们通过编码器权重插值在去偏差期间建立了一种性能保持机制。我们的选择和预测框架称为 S&amp;P TopK，在公平性指标方面比传统的 SAE 使用量高出 3.2 倍，并将最先进的测试时 VLM 去偏差结果提高多达 1.8 倍，同时保持下游性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 06：36：07 UTC</p>
<h2 id="192-基于卫星影像和时间序列分析的番茄农场分枝扫帚检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10804"target="_blank" rel="external nofollow noopener noreferrer">#192</a> <a href="https://papers.cool/arxiv/2509.10804"target="_blank" rel="external nofollow noopener noreferrer">基于卫星影像和时间序列分析的番茄农场分枝扫帚检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mohammadreza Narimani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohammadreza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohammadreza</a> Narimani), [Alireza Pourreza](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alireza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alireza</a> Pourreza), [Ali Moghimi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ali</a> Moghimi), [Parastoo Farajpoor](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Parastoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Parastoo</a> Farajpoor), [Hamid Jafarbiglu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hamid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hamid</a> Jafarbiglu), [Mohsen Mesgaran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohsen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohsen</a> Mesgaran)</p>
<p>分枝扫帚 （Phelipanche ramosa （L.） Pomel） 是一种缺乏叶绿素的寄生植物，通过从寄主那里提取养分来威胁番茄生产，据报道产量损失高达 80%。其大部分在地下的生命周期和多产的种子产量（每株植物超过 200,000 颗种子，可存活长达 20 年）使得早期检测至关重要。我们提出了一个端到端管道，它使用 Sentinel-2 图像和时间序列分析来识别加利福尼亚州被扫帚侵扰的番茄田。根据农民报告的侵扰确定感兴趣的区域，并保留云量低于 10% 的图像。我们处理了 12 个光谱波段和太阳传感器几何形状，计算了 20 个植被指数（例如 NDVI、NDMI），并推导出了 5 种植物性状（叶面积指数、叶绿素含量、冠层叶绿素含量、吸收光合活性辐射的分数和植被覆盖率），使用地面实况和合成数据校准的神经网络。冠层叶绿素含量的趋势描绘了移栽到收获的时期，物候学使用生长度日进行对齐。植被像素被分割并用于在 48 个生长度日时间点的 18,874 个像素上训练长短期记忆 （LSTM） 网络。该模型实现了 88% 的训练准确率和 87% 的测试准确率，精度为 0.86，召回率为 0.92，F1 为 0.89。排列特征重要性将 NDMI、冠层叶绿素含量、FAPAR 和叶绿素红边指数列为信息量最强，与侵染的生理影响一致。结果表明，卫星驱动的时间序列建模有望在番茄农场的寄生应激中进行可扩展的检测。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-13 03：51：11 UTC</p>
<h2 id="193-judge-qkv-缓存驱逐中优化信息保留的可训练查询-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10798"target="_blank" rel="external nofollow noopener noreferrer">#193</a> <a href="https://papers.cool/arxiv/2509.10798"target="_blank" rel="external nofollow noopener noreferrer">Judge Q：KV 缓存驱逐中优化信息保留的可训练查询</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yijun Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yijun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yijun</a> Liu), [Yixuan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixuan</a> Wang), [Yuzhuang Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuzhuang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuzhuang</a> Xu), [Shiyu Ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiyu</a> Ji), [Yang Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Xu), [Qingfu Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingfu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingfu</a> Zhu), [Wanxiang Che](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wanxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wanxiang</a> Che)</p>
<p>大型语言模型 （LLM） 利用键值 （KV） 缓存在序列处理过程中存储历史信息。KV缓存的大小随着序列长度的延长而线性增长，严重影响内存使用和解码效率。当前的 KV 缓存驱逐方法通常利用预填充阶段的最后一个窗口作为查询来计算驱逐的 KV 重要性分数。尽管这种方案实施起来很简单，但它往往过于关注本地信息，可能导致关键的全球信息被忽视或遗漏。为了缓解这个问题，我们提出了 Judge Q，这是一种包含软令牌列表的新型训练方法。此方法仅以较低的训练成本调整模型的嵌入层。通过连接输入序列末尾的软标记列表，我们将这些标记的注意力映射训练为原始输入序列，以与实际解码标记的注意力映射保持一致。这样，软令牌对应的查询可以有效地捕获全局信息，并更好地评估KV缓存中键和值的重要性，从而在KV缓存被驱逐时保持解码质量。在相同的逐出预算下，与现有逐出方法相比，我们的方法表现出更少的性能下降。我们通过在 Llama-3.1-8B-Instruct 和 Mistral-7B-Instruct-v0.3 等模型上进行的实验来验证我们的方法，并使用 LongBench、RULER 和 Needle-in-a-Haystack 等基准测试。结果表明，LongBench 提高了约 1 分，RULER 提高了 3 分以上。这种提出的方法可以无缝集成到现有的开源模型中，训练开销最小，从而增强 KV 缓存驱逐场景中的性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 03：34：12 UTC</p>
<h2 id="194-goldentransformer用于变压器鲁棒性研究的模块化故障注入框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10790"target="_blank" rel="external nofollow noopener noreferrer">#194</a> <a href="https://papers.cool/arxiv/2509.10790"target="_blank" rel="external nofollow noopener noreferrer">GoldenTransformer：用于变压器鲁棒性研究的模块化故障注入框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Luke Howard](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luke</a> Howard)</p>
<p>Transformer 已成为跨自然语言处理、计算机视觉和其他机器学习领域的各种最先进模型的基础。尽管这些模型得到了广泛的部署，但这些模型在故障条件下的鲁棒性仍未得到充分探索。我们提出了 GoldenTransformer，这是一个模块化且可扩展的故障注入框架，旨在评估大型语言模型对诱发硬件故障的弹性。GoldenTransformer 提供了一个基于 Python 的统一平台，用于将不同类别的故障（例如权重损坏、激活注入和注意力级中断）注入到基于预训练 Transformer 的模型中。受 DNN 的 GoldenEye 模拟器的启发，我们的框架专注于使用大型 Transformer 架构的独特挑战，包括结构复杂性、潜在依赖性和非均匀层定义等考虑因素。GoldenTransformer 构建在 PyTorch 和 HuggingFace Transformers 之上，它支持开箱即用的实验可重复性、指标记录和可视化。我们详细介绍了 GoldenTransformer 的技术设计和使用，并通过几个分类和生成任务的示例实验进行了演示。通过在变压器中多个逻辑和结构点上实现故障的受控注入，GoldenTransformer 为研究人员和从业者提供了一个宝贵的工具，用于模型鲁棒性分析，并指导实际 LLM 应用中可靠的系统设计。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 02：52：08 UTC</p>
<h2 id="195-弥合默认模式与当地课堂需求之间的文化距离全球教师如何采用-genai-来支持日常教学实践-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10780"target="_blank" rel="external nofollow noopener noreferrer">#195</a> <a href="https://papers.cool/arxiv/2509.10780"target="_blank" rel="external nofollow noopener noreferrer">弥合默认模式与当地课堂需求之间的文化距离：全球教师如何采用 GenAI 来支持日常教学实践</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ruiwei Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruiwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruiwei</a> Xiao), [Qing Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qing</a> Xiao), [Xinying Hou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinying</a> Hou), [Hanqi Jane Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hanqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hanqi</a> Jane Li), [Phenyo Phemelo Moletsane](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Phenyo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Phenyo</a> Phemelo Moletsane), [Hong Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hong</a> Shen), [John Stamper](<a href="https://arxiv.org/search/?searchtype=author&amp;query=John"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=John</a> Stamper)</p>
<p>生成式人工智能 （GenAI） 正在迅速进入 K-12 课堂，为教师提供新的教学实践方式。然而，GenAI 模型通常在文化不平衡的数据集上进行训练，嵌入了一种“默认文化”，这种文化往往与当地课堂不一致。为了了解教师如何克服这一差距，我们定义了新概念“文化距离”（GenAI 的默认文化曲目与教学实践的情境需求之间的差距），并对 30 名 K-12 教师进行了深入访谈，他们分别来自南非、台湾和美国，他们已将 AI 融入教学实践。这些教师的经验为我们三级文化距离框架的发展提供了信息。这项工作贡献了文化距离的概念和框架，六个例子横跨低、中、高距离水平，以及教师的经验和解决这些问题的策略。根据经验，我们提供了帮助人工智能设计师、政策制定者和教育工作者为教育创建更加公平和文化响应的 GenAI 工具的启示。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 01：57：48 UTC</p>
<h2 id="196-食品救援志愿者参与的情境预算强盗-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10777"target="_blank" rel="external nofollow noopener noreferrer">#196</a> <a href="https://papers.cool/arxiv/2509.10777"target="_blank" rel="external nofollow noopener noreferrer">食品救援志愿者参与的情境预算强盗</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ariana Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ariana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ariana</a> Tang), [Naveen Raman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Naveen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Naveen</a> Raman), [Fei Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fei</a> Fang), [Zheyuan Ryan Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zheyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zheyuan</a> Ryan Shi)</p>
<p>以志愿者为基础的食物救援平台通过将剩余食物与有需要的社区相匹配来解决食物浪费问题。这些平台面临着保持志愿者参与和最大限度地利用救援食物的双重问题。现有提高志愿者参与度的算法加剧了地理差异，使一些社区系统性地处于不利地位。我们通过提出 Contextual Budget Bandit 来解决这个问题。情境预算强盗将依赖于情境的预算分配纳入不安分的多臂强盗中，这是一种允许状态武器的决策模型。通过这样做，我们可以为匹配率较低的社区分配更高的预算，从而缓解地域差异。为了解决这个问题，我们开发了一种经验快速启发式算法。由于启发式算法在活跃志愿者稀缺时可以实现较差的近似值，因此我们设计了有丝分裂算法，该算法可以保证计算出最优预算分配。根据经验，我们证明我们的算法在合成和现实世界的食物救援数据集上都优于基线，并展示了我们的算法如何在食物救援中实现地理公平。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-13 01：49：00 UTC</p>
<h2 id="197-用于保护图像归属的内容相关水印-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10766"target="_blank" rel="external nofollow noopener noreferrer">#197</a> <a href="https://papers.cool/arxiv/2509.10766"target="_blank" rel="external nofollow noopener noreferrer">用于保护图像归属的内容相关水印</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Tong Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tong</a> Zhou), [Ruyi Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruyi</a> Ding), [Gaowen Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gaowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gaowen</a> Liu), [Charles Fleming](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Charles"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Charles</a> Fleming), [Ramana Rao Kompella](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ramana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ramana</a> Rao Kompella), [Yunsi Fei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunsi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunsi</a> Fei), [Xiaolin Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaolin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaolin</a> Xu), [Shaolei Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaolei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaolei</a> Ren)</p>
<p>数字和人工智能生成图像的快速增长增加了对安全且可验证的图像归因方法的需求。虽然数字水印比基于元数据的方法提供了更强大的保护（后者很容易被剥离），但当前的水印技术仍然容易被伪造，从而产生错误归属的风险，从而损害人工智能模型开发人员的声誉和数字艺术家的权利。这些漏洞源于两个关键问题：（1） 与内容无关的水印，一旦被学习或泄露，就可以跨图像转移到虚假归属，以及 （2） 依赖基于检测器的验证，这是不可靠的，因为检测器可能会被欺骗。我们介绍了 MetaSeal，这是一种用于内容相关水印的新型框架，具有加密安全保证，以保护图像归属。我们的设计提供 （1） 防伪造，防止未经授权的复制并强制执行加密验证;（2）强大、独立的保护，将归因直接嵌入到图像中，同时保持对良性转换的弹性;（3） 篡改证据，使恶意更改在视觉上可以检测到。实验表明，MetaSeal 有效减少了伪造企图，并适用于自然图像和人工智能生成的图像，为安全图像归属建立了新标准。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-13 00：38：03 UTC</p>
<h2 id="198-hallufield通过场论建模检测-llm-幻觉-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10753"target="_blank" rel="external nofollow noopener noreferrer">#198</a> <a href="https://papers.cool/arxiv/2509.10753"target="_blank" rel="external nofollow noopener noreferrer">HalluField：通过场论建模检测 LLM 幻觉</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Minh Vu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minh</a> Vu), [Brian K. Tran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Brian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Brian</a> K. Tran), [Syed A. Shah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Syed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Syed</a> A. Shah), [Geigh Zollicoffer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Geigh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Geigh</a> Zollicoffer), [Nhat Hoang-Xuan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nhat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nhat</a> Hoang-Xuan), [Manish Bhattarai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manish"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manish</a> Bhattarai)</p>
<p>大型语言模型 （LLM） 表现出令人印象深刻的推理和问答能力。然而，它们通常会产生不准确或不可靠的内容，称为幻觉。这种不可靠性极大地限制了它们在高风险应用程序中的部署。因此，越来越需要一种通用方法来检测法学硕士中的幻觉。在这项工作中，我们介绍了 HalluField，这是一种基于参数化变分原理和热力学的幻觉检测的新型场论方法。受热力学的启发，HalluField 将 LLM 对给定查询和温度设置的响应建模为离散似然标记路径的集合，每个路径都与相应的能量和熵相关联。通过分析能量和熵分布在温度和可能性变化下标记路径之间的变化，HalluField 量化了响应的语义稳定性。然后通过识别这种能量景观中不稳定或不稳定的行为来检测幻觉。HalluField 计算高效且高度实用：它直接在模型的输出 logit 上运行，无需微调或辅助神经网络。值得注意的是，该方法以原则性的物理解释为基础，与热力学第一定律进行了类比。值得注意的是，通过这种物理镜头对法学硕士行为进行建模，HalluField 实现了跨模型和数据集的最先进的幻觉检测性能。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 23：49：52 UTC</p>
<h2 id="199-大规模自动化-mcqa-基准测试评估推理轨迹作为小型语言模型领域适配的检索源-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10744"target="_blank" rel="external nofollow noopener noreferrer">#199</a> <a href="https://papers.cool/arxiv/2509.10744"target="_blank" rel="external nofollow noopener noreferrer">大规模自动化 MCQA 基准测试：评估推理轨迹作为小型语言模型领域适配的检索源</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ozan Gokdemir](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ozan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ozan</a> Gokdemir), [Neil Getty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Neil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Neil</a> Getty), [Robert Underwood](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Robert"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Robert</a> Underwood), [Sandeep Madireddy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sandeep"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sandeep</a> Madireddy), [Franck Cappello](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Franck"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Franck</a> Cappello), [Arvind Ramanathan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arvind"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arvind</a> Ramanathan), [Ian T. Foster](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> T. Foster), [Rick L. Stevens](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rick</a> L. Stevens)</p>
<p>随着科学知识以前所未有的速度增长，评估基准必须不断发展，以反映新发现，并确保语言模型在当前的多样化文献中得到测试。我们提出了一个可扩展的模块化框架，用于直接从大型科学论文语料库中生成多项选择问答 （MCQA） 基准。我们的管道可自动执行 MCQA 创建的每个阶段，包括 PDF 解析、语义分块、问题生成和模型评估。作为案例研究，我们从放射和癌症生物学领域的 22,000 篇开放获取文章中生成了 16,000 多个 MCQ。然后，我们评估了一套关于这些问题的小型语言模型（1.1B-14B 参数），将基线准确性与来自纸张衍生语义块和从 GPT-4.1 提炼的推理痕迹的检索增强生成 （RAG） 进行了比较。我们发现，推理跟踪检索在合成基准和专家注释基准测试中不断提高性能，使几个小型模型在 2023 年天文辐射和癌症生物学考试中超越了 GPT-4。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 23：22：49 UTC</p>
<h2 id="200-暗模式遇见-gui-代理llm-代理对纵界面的敏感性和人类监督的作用-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10723"target="_blank" rel="external nofollow noopener noreferrer">#200</a> <a href="https://papers.cool/arxiv/2509.10723"target="_blank" rel="external nofollow noopener noreferrer">暗模式遇见 GUI 代理：LLM 代理对纵界面的敏感性和人类监督的作用</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jingyu Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingyu</a> Tang), [Chaoran Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chaoran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chaoran</a> Chen), [Jiawen Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiawen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiawen</a> Li), [Zhiping Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiping</a> Zhang), [Bingcan Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingcan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingcan</a> Guo), [Ibrahim Khalilov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ibrahim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ibrahim</a> Khalilov), [Simret Araya Gebreegziabher](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Simret"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Simret</a> Araya Gebreegziabher), [Bingsheng Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingsheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingsheng</a> Yao), [Dakuo Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dakuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dakuo</a> Wang), [Yanfang Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanfang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanfang</a> Ye), [Tianshi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianshi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianshi</a> Li), [Ziang Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziang</a> Xiao), [Yaxing Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yaxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yaxing</a> Yao), [Toby Jia-Jun Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Toby"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Toby</a> Jia-Jun Li)</p>
<p>暗模式是纵用户行为的欺骗性界面设计，因其对人类决策和自主性的影响而得到了广泛研究。然而，随着法学硕士驱动的 GUI 代理的日益突出，这些代理可以自动执行高级意图任务，了解暗模式如何影响代理变得越来越重要。我们提出了一项两阶段实证研究，研究了代理、人类参与者和人类人工智能团队如何在不同场景中对 16 种类型的黑暗模式做出反应。第一阶段强调，代理通常无法识别黑暗模式，即使意识到，也会优先考虑任务完成而不是保护行动。第二阶段揭示了不同的失败模式：人类由于认知捷径和习惯性顺从而屈服，而代理人则因程序盲点而步履蹒跚。人类监督改善了回避，但带来了注意力隧道和认知负荷等成本。我们的研究结果表明，人类和代理都不是统一的弹性，协作引入了新的漏洞，这表明设计需要透明度、可调整的自主性和监督。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 22：26：31 UTC</p>
<h2 id="201-kalman-bayesian-transformer-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10695"target="_blank" rel="external nofollow noopener noreferrer">#201</a> <a href="https://papers.cool/arxiv/2509.10695"target="_blank" rel="external nofollow noopener noreferrer">Kalman Bayesian Transformer</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Haoming Jing](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haoming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haoming</a> Jing), [Oren Wright](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oren"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oren</a> Wright), [José M. F. Moura](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jos"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jos</a>é M. F. Moura), [Yorie Nakahira](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yorie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yorie</a> Nakahira)</p>
<p>当新数据按顺序到达时，尤其是分布变化时，转换器的顺序微调非常有用。与批量学习不同，顺序学习要求通过平衡预训练模型中的新信息和先前学习的知识，在数据量很少的情况下保持训练的稳定性。当训练要在延迟关键环境中完成并且学习必须额外量化并由不确定性中介时，这一挑战会变得更加复杂。在这些挑战的推动下，我们提出了一种新方法，将顺序微调视为贝叶斯框架内的后验推理问题。我们的方法集成了随机变量的闭式矩传播、卡尔曼贝叶斯神经网络和软最大函数矩的泰勒近似。通过明确地将预训练模型作为先验，并根据量化的不确定性自适应地平衡它们与新信息，我们的方法实现了稳健且数据高效的顺序学习。我们方法的有效性通过数值模拟得到证明，该模拟涉及决策转换器对以分布偏移和有限内存资源为特征的任务进行顺序适应。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 21：15：23 UTC</p>
<h2 id="202-通过度量值近端优化学习在线拍卖中的凹面出价着色策略-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10693"target="_blank" rel="external nofollow noopener noreferrer">#202</a> <a href="https://papers.cool/arxiv/2509.10693"target="_blank" rel="external nofollow noopener noreferrer">通过度量值近端优化学习在线拍卖中的凹面出价着色策略</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Iman Nodozi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iman</a> Nodozi), [Djordje Gligorijevic](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Djordje"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Djordje</a> Gligorijevic), [Abhishek Halder](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abhishek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abhishek</a> Halder)</p>
<p>本文提出了一种作为度量值优化问题的一价拍卖的出价阴影策略。我们考虑了标价着色的标准参数形式，并将问题表述为对着色参数联合分布的凸优化。每次拍卖后，阴影参数分布通过具有数据驱动能量泛函的正则化 Wasserstein 近端更新进行调整。这种能量函数取决于上下文，即发布商/用户属性，例如域、广告位类型、设备或位置。所提出的算法鼓励出价分布对预期盈余较高的值施加更大的权重，即获胜概率和价值差距都较大的值。我们表明，由此产生的测值凸优化问题允许一个封闭形式解。一个数值示例说明了所提出的方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/math.OC"target="_blank" rel="external nofollow noopener noreferrer">优化与控制</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 21：11：06 UTC</p>
<h2 id="203-通过可解释的自适应差分隐私保护隐私的去中心化联邦学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10691"target="_blank" rel="external nofollow noopener noreferrer">#203</a> <a href="https://papers.cool/arxiv/2509.10691"target="_blank" rel="external nofollow noopener noreferrer">通过可解释的自适应差分隐私保护隐私的去中心化联邦学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Fardin Jalil Piran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fardin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fardin</a> Jalil Piran), [Zhiling Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiling"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiling</a> Chen), [Yang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Zhang), [Qianyu Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qianyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qianyu</a> Zhou), [Jiong Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiong</a> Tang), [Farhad Imani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Farhad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Farhad</a> Imani)</p>
<p>去中心化联邦学习面临隐私风险，因为模型更新可能会通过推理攻击和成员资格推理泄露数据，这是许多客户端交易所日益增长的担忧。差分隐私通过注入校准噪声来提供原则性保护，从而在资源有限的物联网设备上保持机密信息的安全。然而，如果没有透明度，黑盒训练就无法跟踪以前客户和轮次已经注入的噪声，这迫使最坏情况添加并损害准确性。我们提出了 PrivateDFL，这是一个可解释的框架，它将超维计算与差分隐私相结合，并保留累积噪声的可审计帐户，因此每个客户端只添加所需噪声与已经累积的噪声之间的差值。我们使用 MNIST、ISOLET 和 UCI-HAR 进行评估，以跨越图像、信号和表格模态，并以基于 transformer 和基于深度学习的基线为基准，这些基线使用差分私有随机梯度下降 （DP-SGD） 和人义差分隐私 （RDP） 集中训练。PrivateDFL 在 IID 和非 IID 分区中提供更高的准确性、更低的延迟和更低的能耗，同时保留正式（epsilon、delta）保证并在没有中央服务器的情况下运行。例如，在非 IID 分区下，PrivateDFL 的准确率比 MNIST 上的 Vision Transformer 高 24.42%，同时使用约 10 倍的训练时间、76 倍的推理延迟和 11 倍的能量，而在 ISOLET 上，它比 Transformer 的准确率高出 80% 以上，训练时间大约减少 10 倍，推理延迟降低 40 倍，训练能量减少 36 倍。未来的工作将把可解释的记帐扩展到具有异构隐私预算的对抗性客户端和自适应拓扑。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 20：52：41 UTC</p>
<h2 id="204-医疗保健的多元调整角色驱动的框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10685"target="_blank" rel="external nofollow noopener noreferrer">#204</a> <a href="https://papers.cool/arxiv/2509.10685"target="_blank" rel="external nofollow noopener noreferrer">医疗保健的多元调整：角色驱动的框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jiayou Zhong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiayou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiayou</a> Zhong), [Anudeex Shetty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anudeex"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anudeex</a> Shetty), [Chao Jia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chao</a> Jia), [Xuanrui Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuanrui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuanrui</a> Lin), [Usman Naseem](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Usman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Usman</a> Naseem)</p>
<p>随着大型语言模型越来越多地部署在医疗保健等敏感领域，确保其输出反映不同人群持有的不同价值观和观点至关重要。然而，现有的对齐方法，包括模块化多元主义等多元范式，在健康领域往往存在不足，因为个人、文化和情境因素塑造了多元化。在上述医疗保健挑战的推动下，我们提出了第一个轻量级、可通用、多元化的对齐方法 EthosAgents，旨在模拟不同的观点和价值观。我们根据经验表明，它在七个不同大小的开放和封闭模型中推进了所有三种模式的多元对齐。我们的研究结果表明，与健康相关的多元化需要适应性强且具有规范意识的方法，为这些模型如何更好地尊重其他高风险领域的多样性提供了见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 20：28：27 UTC</p>
<h2 id="205-微调卷积神经网络与大型语言模型在mri上脑肿瘤图像分类和分割的比较与评价-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10683"target="_blank" rel="external nofollow noopener noreferrer">#205</a> <a href="https://papers.cool/arxiv/2509.10683"target="_blank" rel="external nofollow noopener noreferrer">微调卷积神经网络与大型语言模型在MRI上脑肿瘤图像分类和分割的比较与评价</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Felicia Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Felicia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Felicia</a> Liu), [Jay J. Yoo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jay</a> J. Yoo), [Farzad Khalvati](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Farzad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Farzad</a> Khalvati)</p>
<p>大型语言模型 （LLM） 在基于文本的医疗保健任务中表现出强大的性能。然而，它们在基于图像的应用程序中的实用性仍未得到探索。我们研究了法学硕士在医学成像任务中的有效性，特别是神经胶质瘤分类和分割，并将其性能与传统卷积神经网络 （CNN） 的性能进行了比较。使用多模态脑部 MRI 的 BraTS 2020 数据集，我们评估了通用视觉语言 LLM （LLaMA 3.2 Instruct） 在微调前后，并将其性能与定制 3D CNN 进行了基准测试。对于神经胶质瘤分类（低级别与高级别），CNN 实现了 80% 的准确率，并平衡了精度和召回率。一般法学硕士的准确率达到了 76%，但特异性仅为 18%，经常错误分类低级别肿瘤。微调将特异性提高到 55%，但整体性能下降（例如，准确率下降到 72%）。对于分割，实施了三种方法 - 中心点、边界框和多边形提取。CNN 准确定位神经胶质瘤，但有时会遗漏小肿瘤。相比之下，法学硕士始终将预测聚集在图像中心附近，没有神经胶质瘤大小、位置或位置的区别。微调改进了输出格式，但未能显着提高空间精度。边界多边形方法产生随机的非结构化输出。总体而言，CNN 在这两项任务中都优于法学硕士。法学硕士表现出有限的空间理解和微调的微调改进，这表明在目前的形式下，它们不太适合基于图像的任务。法学硕士可能需要更严格的微调或替代训练策略，才能在医疗领域实现更好的性能、稳健性和实用性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 20：26：53 UTC</p>
<h2 id="206-中间的法学硕士对现实世界基于法学硕士的系统的威胁和缓解措施的系统回顾-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10682"target="_blank" rel="external nofollow noopener noreferrer">#206</a> <a href="https://papers.cool/arxiv/2509.10682"target="_blank" rel="external nofollow noopener noreferrer">中间的法学硕士：对现实世界基于法学硕士的系统的威胁和缓解措施的系统回顾</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Vitor Hugo Galhardo Moia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vitor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vitor</a> Hugo Galhardo Moia), [Igor Jochem Sanz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Igor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Igor</a> Jochem Sanz), [Gabriel Antonio Fontes Rebello](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gabriel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gabriel</a> Antonio Fontes Rebello), [Rodrigo Duarte de Meneses](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rodrigo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rodrigo</a> Duarte de Meneses), [Briland Hitaj](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Briland"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Briland</a> Hitaj), [Ulf Lindqvist](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ulf"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ulf</a> Lindqvist)</p>
<p>生成式人工智能 （GenAI），特别是大型语言模型 （LLM） 的成功和广泛采用，引起了试图滥用模型、窃取敏感数据或中断服务的网络犯罪分子的注意。此外，为基于 LLM 的系统提供安全性是一项巨大的挑战，因为必须减轻对软件应用程序的传统威胁以及针对 LLM 及其集成的威胁。在本次调查中，我们通过对威胁和防御策略进行系统审查和综合分类，考虑整个软件和 LLM 生命周期，阐明了此类基于 LLM 的系统的安全和隐私问题。我们分析了具有 LLM 使用独特特征的真实场景，从开发到运营。此外，威胁根据其严重性级别及其与哪些场景相关进行分类，从而有助于识别最相关的威胁。推荐的防御策略被系统地分类并映射到相应的生命周期阶段和它们衰减的可能攻击策略。这项工作为消费者和供应商了解并有效降低将 LLM 集成到各自的解决方案或组织中期间的风险铺平了道路。它还使研究界能够从可能阻碍基于 LLM 的系统安全和隐私保护采用的开放挑战和边缘案例的讨论中受益。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.ET"target="_blank" rel="external nofollow noopener noreferrer">新兴技术</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 20：26：16 UTC</p>
<h2 id="207-多智能体合作与探索中的自监督目标达标结果-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10656"target="_blank" rel="external nofollow noopener noreferrer">#207</a> <a href="https://papers.cool/arxiv/2509.10656"target="_blank" rel="external nofollow noopener noreferrer">多智能体合作与探索中的自监督目标达标结果</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Chirayu Nimonkar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chirayu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chirayu</a> Nimonkar), [Shlok Shah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shlok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shlok</a> Shah), [Catherine Ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Catherine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Catherine</a> Ji), [Benjamin Eysenbach](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Benjamin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Benjamin</a> Eysenbach)</p>
<p>对于自主代理群体来说，要实现特定目标，他们必须进行协调和长期推理。然而，设计奖励函数来引发这种行为是具有挑战性的。在本文中，我们研究了如何利用自监督目标实现技术来使智能体能够合作。关键思想是，智能体的目标是最大化访问某个目标的可能性，而不是让代理最大化某些标量奖励。这种问题设置使人类用户能够通过单个目标状态来指定任务，而不是实现复杂的奖励函数。虽然反馈信号非常稀疏，但我们将证明自监督目标实现技术使代理能够从此类反馈中学习。在 MARL 基准测试中，我们提出的方法优于可以访问与我们的方法相同的稀疏奖励信号的替代方法。虽然我们的方法没有明确的探索机制，但我们观察到，在替代方法从未见证过一次成功试验的情况下，自我监督的多智能体目标实现会导致紧急合作和探索。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 19：35：20 UTC</p>
<h2 id="208-scor数字生态系统中负责任的人工智能创新框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10653"target="_blank" rel="external nofollow noopener noreferrer">#208</a> <a href="https://papers.cool/arxiv/2509.10653"target="_blank" rel="external nofollow noopener noreferrer">SCOR：数字生态系统中负责任的人工智能创新框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mohammad Saleh Torkestani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohammad</a> Saleh Torkestani), [Taha Mansouri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Taha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Taha</a> Mansouri)</p>
<p>人工智能驱动的数字生态系统跨越不同的利益相关者，包括科技公司、监管机构、加速器和民间社会，但往往缺乏有凝聚力的道德治理。本文提出了一个四支柱框架 （SCOR），以在此类多参与者网络中嵌入问责制、公平性和包容性。利用设计科学方法，我们制定了共享道德宪章、结构化的共同设计和利益相关者参与协议（C）、持续监督和学习系统（O）以及适应性监管调整策略（R）。每个组成部分都包括实用指南，从资源受限的初创企业的精简模块到大型财团的深入审计系统。通过医疗保健、金融和智慧城市背景下的说明性小插曲，我们展示了该框架如何协调组织文化、领导激励和跨司法管辖区合规性。我们的混合方法 KPI 设计进一步确保定量目标与用户信任和文化变革的定性评估相辅相成。通过将道德原则与可扩展的运营结构相结合，本文为在复杂的数字生态系统中负责任的人工智能创新提供了一条可复制的途径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 19：29：51 UTC</p>
<h2 id="209-用户体验设计的氛围编码了解用户体验专业人士对人工智能辅助设计和开发的看法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10652"target="_blank" rel="external nofollow noopener noreferrer">#209</a> <a href="https://papers.cool/arxiv/2509.10652"target="_blank" rel="external nofollow noopener noreferrer">用户体验设计的氛围编码：了解用户体验专业人士对人工智能辅助设计和开发的看法</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jie Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jie</a> Li), [Youyang Hou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youyang</a> Hou), [Laura Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Laura"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Laura</a> Lin), [Ruihao Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruihao</a> Zhu), [Hancheng Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hancheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hancheng</a> Cao), [Abdallah El Ali](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abdallah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abdallah</a> El Ali)</p>
<p>生成式人工智能正在通过“氛围编码”重塑用户体验设计实践，即用户体验专业人员用自然语言表达意图，人工智能将其转化为功能原型和代码。尽管采用迅速，但很少有研究研究氛围编码如何重新配置用户体验工作流程和协作。通过对企业、初创公司和学术界的 20 名用户体验专业人士的采访，我们展示了氛围编码如何遵循构思、人工智能生成、调试和审查的四个阶段工作流程。这加速了迭代，支持创造力，并降低了参与障碍。然而，专业人士报告了代码不可靠性、集成和过度依赖人工智能的挑战。我们发现效率驱动的原型设计（“打算正确的设计”）和反思（“设计正确的意图”）之间存在紧张关系，在团队内部引入了信任、责任和社会耻辱的新不对称。通过负责任的人机协作来进行人工智能辅助用户体验设计和开发，我们对氛围编码时代的去技能化、所有权和披露以及创造力保护做出了更深入的理解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.ET"target="_blank" rel="external nofollow noopener noreferrer">新兴技术</a></p>
<p><strong>发布</strong>: 2025-09-12 19：28：38 UTC</p>
<h2 id="210-多模态大型语言模型的测试时间预热-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10641"target="_blank" rel="external nofollow noopener noreferrer">#210</a> <a href="https://papers.cool/arxiv/2509.10641"target="_blank" rel="external nofollow noopener noreferrer">多模态大型语言模型的测试时间预热</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Nikita Rajaneesh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nikita"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nikita</a> Rajaneesh), [Thomas Zollo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Zollo), [Richard Zemel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Richard"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Richard</a> Zemel)</p>
<p>多模态大型语言模型 （MLLM） 在文本和图像交叉点的高级推理方面前景广阔，但它们尚未完全实现这一潜力。MLLM 通常集成 LLM、视觉编码器和连接器，将视觉编码器的嵌入映射到 LLM 的文本嵌入空间中。尽管每个组件都对包含数十亿个样本的海量数据集进行了预训练，但整个多模态模型通常只在数千（或几百万）个样本上进行训练，这可能导致在复杂的推理任务上性能不佳。为了解决这些缺点，我们提出了一种测试时间预热方法，而不是依赖大量标记数据集进行微调，该方法通过利用来自弱监督辅助任务的数据来调整每个测试实例的 MLLM。通过我们的方法，我们观察到 Llama-Vision-Instruct 模型的 MMMU 相对性能提高了 4.03%，VQA-Rad 提高了 5.28%，GQA 提高了 1.63%。我们的方法表明，在推理之前“预热”可以增强 MLLM 在不同推理任务中的鲁棒性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 18：58：42 UTC</p>
<h2 id="211-最优多边薛定谔桥测量值顶点上的最小生成树-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10626"target="_blank" rel="external nofollow noopener noreferrer">#211</a> <a href="https://papers.cool/arxiv/2509.10626"target="_blank" rel="external nofollow noopener noreferrer">最优多边薛定谔桥：测量值顶点上的最小生成树</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Georgiy A. Bondar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Georgiy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Georgiy</a> A. Bondar), [Abhishek Halder](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abhishek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abhishek</a> Halder)</p>
<p>多边际薛定谔桥 （MSB） 在具有已知统计量和已知相关结构的随机向量集合中找到最佳耦合。在 MSB 公式中，这种相关结构被指定为 \emph{a priori} 作为具有度量值顶点的无向连通图。在这项工作中，我们制定并解决了寻找最优 MSB 的问题，即我们在所有可能的图结构上寻求最佳耦合。我们发现，计算最优 MSB 相当于解决测量值顶点上的最小生成树问题。我们表明，由此产生的问题可以通过两步解决。第一步构建一个完整的图，其边权重等于相应双边SB的最优值和端点熵的总和。第二步解决该完整加权图上的标准最小生成树问题。数值实验说明了所提出的解决方案。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/math.OC"target="_blank" rel="external nofollow noopener noreferrer">优化与控制</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 18：15：42 UTC</p>
<h2 id="212-无需回答从纯问题线性探针预测-llm-答案准确性-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2509.10625"target="_blank" rel="external nofollow noopener noreferrer">#212</a> <a href="https://papers.cool/arxiv/2509.10625"target="_blank" rel="external nofollow noopener noreferrer">无需回答：从纯问题线性探针预测 LLM 答案准确性</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Authors</strong>: [Iván Vicente Moreno Cencerrado](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iv"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iv</a>án Vicente Moreno Cencerrado), [Arnau Padrés Masdemont](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arnau"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arnau</a> Padrés Masdemont), [Anton Gonzalvez Hawthorne](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anton"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anton</a> Gonzalvez Hawthorne), [David Demitri Africa](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Demitri Africa), [Lorenzo Pacchiardi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lorenzo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lorenzo</a> Pacchiardi)</p>
<p>大型语言模型 （LLM） 是否预测它们何时会正确回答？为了研究这一点，我们在阅读问题后、生成任何标记之前提取激活，并训练线性探针来预测模型即将到来的答案是否正确。在 7 到 700 亿个参数的三个开源模型系列中，对这种基于通用琐事问题训练的“预先正确性方向”的预测可以预测分布和各种分布外知识数据集的成功，优于黑盒基线和口头预测置信度。预测能力在中间层饱和，表明自我评估出现在计算过程中。值得注意的是，在需要数学推理的问题上，概括性步履蹒跚。此外，对于回答“我不知道”的模型，这样做与探针分数密切相关，表明同一方向也会捕获置信度。通过补充之前使用探针和稀疏自动编码器获得的关于真实性和其他行为的结果，我们的工作为阐明 LLM 内部结构做出了重要发现。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 18：09：55 UTC</p>
<h2 id="213-国家跑步俱乐部数据库评估大学俱乐部运动员的越野比赛成绩-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10600"target="_blank" rel="external nofollow noopener noreferrer">#213</a> <a href="https://papers.cool/arxiv/2509.10600"target="_blank" rel="external nofollow noopener noreferrer">国家跑步俱乐部数据库：评估大学俱乐部运动员的越野比赛成绩</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jonathan A. Karr Jr](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonathan</a> A. Karr Jr), [Ben Darden](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ben"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ben</a> Darden), [Nicholas Pell](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicholas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicholas</a> Pell), [Ryan M. Fryer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ryan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ryan</a> M. Fryer), [Kayla Ambrose](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kayla"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kayla</a> Ambrose), [Evan Hall](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Evan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Evan</a> Hall), [Ramzi K. Bualuan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ramzi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ramzi</a> K. Bualuan), [Nitesh V. Chawla](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nitesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nitesh</a> V. Chawla)</p>
<p>国家跑步俱乐部数据库 （NRCD） 汇总了 2023 年和 2024 年越野赛季 5,585 名运动员的 15,397 场比赛成绩。本文介绍了 NRCD 数据集，该数据集提供了对个体运动员进步的见解，从而实现了数据驱动的决策。分析显示，女子 6,000 米和男子 8,000 米的跑步者在每个日历日的进步在初始比赛时间较慢的运动员和比赛更频繁的运动员中更为明显。此外，我们还考虑了球场条件，包括天气和海拔增益，以标准化改进。虽然 NRCD 显示性别失衡，男性为 3,484 人，女性为 2,101 人，但性别之间的比赛频率相当。该出版物使研究界可以访问 NRCD 数据集，解决了以前必须从互联网上手动抓取较小的数据集（通常限制为 500 个条目）的挑战。关注俱乐部运动员而不是精英专业人士，为了解现实世界跑步者的表现提供了一个独特的视角，他们平衡了竞争与学业和其他承诺。这些结果为跑步者、教练和团队提供了宝贵的资源，弥合了原始数据和应用运动科学之间的差距。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-12 17：50：23 UTC</p>
<h2 id="214-编程教育中的-genai-语音模式-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10596"target="_blank" rel="external nofollow noopener noreferrer">#214</a> <a href="https://papers.cool/arxiv/2509.10596"target="_blank" rel="external nofollow noopener noreferrer">编程教育中的 GenAI 语音模式</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Sven Jacobs](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sven"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sven</a> Jacobs), [Natalie Kiesler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Natalie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Natalie</a> Kiesler)</p>
<p>使用多模态生成式人工智能 （GenAI） 的实时语音界面可以潜在地满足残疾新手程序员的无障碍需求（例如，与视觉相关）。然而，人们对新手如何与 GenAI 工具交互及其以音频输出形式提供的反馈质量知之甚少。本文分析了九名 9 年级学生在学习 Python 时在真实的课堂环境中使用语音导师（由 OpenAI 的实时 API 提供支持）的音频对话。我们使用定性编码检查了学生的语音提示和人工智能的响应（1210 条消息）。我们还通过合作伙伴建模问卷收集了学生的看法。GenAI 语音导师主要提供有关错误和后续步骤的反馈，但其正确性有限（在 71.4 个反馈输出中，有 416% 正确）。观察到质量问题，特别是当人工智能试图说出编程代码元素时。学生使用 GenAI 语音导师主要进行调试。他们认为它是有能力的，只是有点像人类，而且很灵活。本研究首次探索实时语音 GenAI 导师和新手程序员的交互动态，为未来的教育工具设计提供信息，并有可能满足不同学习者的可访问性需求。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">人机交互</a></p>
<p><strong>发布</strong>: 2025-09-12 15：25：08 UTC</p>
<h2 id="215-sme-team利用信任和道德在中小企业中安全负责任地使用人工智能和法学硕士-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10594"target="_blank" rel="external nofollow noopener noreferrer">#215</a> <a href="https://papers.cool/arxiv/2509.10594"target="_blank" rel="external nofollow noopener noreferrer">SME-TEAM：利用信任和道德在中小企业中安全、负责任地使用人工智能和法学硕士</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Iqbal H. Sarker](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iqbal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iqbal</a> H. Sarker), [Helge Janicke](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helge"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helge</a> Janicke), [Ahmad Mohsin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ahmad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ahmad</a> Mohsin), [Leandros Maglaras](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leandros"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leandros</a> Maglaras)</p>
<p>人工智能 （AI） 和大型语言模型 （LLM） 正在重塑当今的商业实践，然而，它们在中小企业 （SME） 中的采用引发了重大的技术、道德和信任问题。本文提出了一个结构化的、多阶段的框架，旨在将信任和道德原则嵌入整个人工智能生命周期，以便在中小企业中安全和负责任地使用它们。该框架围绕数据、算法、人工监督和模型架构四大支柱构建，将理论道德原则与运营实践联系起来，增强了人工智能在各种中小企业应用中的能力。最终，本文为负责任的人工智能采用提供了一个结构化的路线图，将信任和道德视为中小企业弹性、竞争力和可持续创新的催化剂。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a></p>
<p><strong>发布</strong>: 2025-09-12 14：59：52 UTC</p>
<h2 id="216-使用人工智能协助手写普通化学考试的评分-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10591"target="_blank" rel="external nofollow noopener noreferrer">#216</a> <a href="https://papers.cool/arxiv/2509.10591"target="_blank" rel="external nofollow noopener noreferrer">使用人工智能协助手写普通化学考试的评分</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jan Cvengros](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jan</a> Cvengros), [Gerd Kortemeyer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gerd"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gerd</a> Kortemeyer)</p>
<p>我们探索了基于人工智能 （AI） 的手写普通化学考试评分系统的有效性和可靠性，将人工智能分配的分数与各种类型问题的人工评分进行比较。考试页面和评分标准以图像形式上传，以解释化学反应方程、短和长开放式答案、数字和符号答案推导、绘图和纸笔格式的素描。使用线性回归分析和心理测量评估，调查显示人工智能和人类评分者在文本和化学反应问题上的一致性很高，同时强调了数字和图形任务的可靠性较低。研究结果强调，必须进行人工监督，以确保基于选择性过滤的评分准确性。结果表明人工智能在日常评估任务中的应用前景广阔，但必须仔细考虑学生在将基于人工智能的评分纳入教育实践时对公平性和信任的看法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 13：08：27 UTC</p>
<h2 id="217-机器学习在教育中实现负责任和自适应的人工智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10590"target="_blank" rel="external nofollow noopener noreferrer">#217</a> <a href="https://papers.cool/arxiv/2509.10590"target="_blank" rel="external nofollow noopener noreferrer">机器学习在教育中实现负责任和自适应的人工智能</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Betty Mayeku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Betty"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Betty</a> Mayeku), [Sandra Hummel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sandra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sandra</a> Hummel), [Parisa Memarmoshrefi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Parisa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Parisa</a> Memarmoshrefi)</p>
<p>机器学习 （MU） 的概念因其能够解决机器学习 （ML） 模型中的多个问题而在各个领域广受欢迎，特别是与隐私、安全、偏见缓解和适应性相关的问题。凭借这些能力，MU 正在发展成为一种有前途的技术，可以维护负责任的人工智能原则并优化机器学习模型的性能。然而，尽管其潜力巨大，但这一概念在教育领域并没有受到太多关注。为了鼓励在教育领域进一步采用这项有前途的技术，本文表明 MU 确实具有巨大的潜力，可以作为实施负责任的人工智能原则的实用机制，以及教育应用领域自适应人工智能的重要工具，从而培养对人工智能驱动的教育系统的信任。通过对 42 个同行评审来源的结构化审查，我们确定了 MU 具有特殊前景的四个领域，即隐私保护、对对抗性输入的恢复能力、减轻系统性偏见以及在不断发展的学习环境中的适应性。我们系统地探索了这些潜力及其对基于机器学习的教育系统中核心挑战的干预措施。作为概念贡献，我们提出了教育环境中负责任和自适应人工智能 （MU-RAAI） 的参考机器学习取消学习应用架构。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-12 12：13：40 UTC</p>
<h2 id="218-智能试验评估使用大型语言模型通过社交媒体招募临床试验参与者-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10584"target="_blank" rel="external nofollow noopener noreferrer">#218</a> <a href="https://papers.cool/arxiv/2509.10584"target="_blank" rel="external nofollow noopener noreferrer">智能试验：评估使用大型语言模型通过社交媒体招募临床试验参与者</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xiaofan Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaofan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaofan</a> Zhou), [Zisu Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zisu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zisu</a> Wang), [Janice Krieger](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Janice"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Janice</a> Krieger), [Mohan Zalake](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohan</a> Zalake), [Lu Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lu</a> Cheng)</p>
<p>临床试验 （CT） 对于推进医学研究和治疗至关重要，但有效招募符合条件的参与者（每个人都必须满足复杂的资格标准）仍然是一项重大挑战。传统的招聘方法，例如医院内的广告或电子健康记录筛查，通常非常耗时且受地域限制。这项工作通过利用个人在社交媒体平台上分享的大量健康相关信息来应对招聘挑战。随着能够进行复杂文本理解的强大大型语言模型 （LLM） 的出现，我们提出了一个核心研究问题：LLM 驱动的工具能否通过社交媒体上的参与来识别潜在参与者来促进 CT 招募？为了研究这个问题，我们引入了 TRIALQA，这是一个新颖的数据集，由来自 Reddit 子版块的两个社交媒体集合组成，涉及结肠癌和前列腺癌。使用来自公共现实世界 CT 的资格标准，聘请经验丰富的注释员对 TRIALQA 进行注释，以表明 （1） 社交媒体用户是否符合给定的资格标准，以及 （2） 用户有兴趣参与 CT 的陈述原因。我们在这两个预测任务上对七个广泛使用的 LLM 进行了基准测试，采用了六种不同的训练和推理策略。我们广泛的实验表明，虽然法学硕士显示出相当大的前景，但它们在执行准确评估资格标准所需的复杂多跳推理方面仍然面临挑战。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-12 01：34：32 UTC</p>
<h2 id="219-learnlens一个人工智能增强的仪表板为开放式课堂中的教师提供支持-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10582"target="_blank" rel="external nofollow noopener noreferrer">#219</a> <a href="https://papers.cool/arxiv/2509.10582"target="_blank" rel="external nofollow noopener noreferrer">LearnLens：一个人工智能增强的仪表板，为开放式课堂中的教师提供支持</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Namrata Srivastava](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Namrata"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Namrata</a> Srivastava), [Shruti Jain](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shruti"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shruti</a> Jain), [Clayton Cohn](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Clayton"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Clayton</a> Cohn), [Naveeduddin Mohammed](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Naveeduddin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Naveeduddin</a> Mohammed), [Umesh Timalsina](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Umesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Umesh</a> Timalsina), [Gautam Biswas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gautam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gautam</a> Biswas)</p>
<p>探索性学习环境 （ELE），例如基于模拟的平台和开放式科学课程，促进了实践探索和解决问题，但使教师难以及时了解学生的概念理解。本文介绍了 LearnLens，这是一个生成式 AI （GenAI） 增强的面向教师的仪表板，旨在支持中学科学中基于问题的教学。LearnLens 处理学生在数字评估中的开放式回答，以提供各种见解，包括样本回答、词云、条形图和人工智能生成的摘要。这些功能阐明了学生的思维，使教师能够根据新出现的理解模式调整教学。该仪表板在专业发展课程期间根据教师的意见提供信息，并在中学地球科学课程中实施。我们报告了教师访谈的见解，这些见解强调了仪表板的可用性和指导教师课堂教学的潜力。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 23：06：54 UTC</p>
<h2 id="220-生成模型鲁棒水印的编码限制-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10577"target="_blank" rel="external nofollow noopener noreferrer">#220</a> <a href="https://papers.cool/arxiv/2509.10577"target="_blank" rel="external nofollow noopener noreferrer">生成模型鲁棒水印的编码限制</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Danilo Francati](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Danilo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Danilo</a> Francati), [Yevin Nikhel Goonatilake](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yevin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yevin</a> Nikhel Goonatilake), [Shubham Pawar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shubham"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shubham</a> Pawar), [Daniele Venturi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniele"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniele</a> Venturi), [Giuseppe Ateniese](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Giuseppe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Giuseppe</a> Ateniese)</p>
<p>我们证明了生成模型加密水印稳健性的尖锐阈值。这是通过引入编码抽象（我们称之为无消息密钥代码）来实现的，该抽象形式化了稳健水印的充分和必要的要求：健全性、篡改检测和伪随机性。因此，我们确定鲁棒性有一个精确的限制：对于二进制输出，如果修改了一半以上的编码位，则任何方案都无法生存，而对于大小为 q 的字母表，相应的阈值为 (1−1/q) 符号的。为了补充这种不可能性，我们给出了满足恒定松弛界限的显式结构。对于每个δ&gt;0，假设伪随机函数并访问公共计数器，我们构建了最多容许 (1/2)(1−δ) 二进制大小写中的错误和(1−1/q)(1−δ) 错误q-ary 案例。与下限一起，这些产生了在标准加密假设下可实现的最大鲁棒性。然后，我们通过查看 Gunn、Zhao 和 Song 图像的最近水印，通过实验测试这个限制是否出现在实践中 （ICLR 2025）。我们表明，一个简单的裁剪和调整大小作可以可靠地翻转大约一半的潜在符号，并始终防止信念传播解码恢复码字，擦除水印，同时保持图像视觉完整。这些结果提供了鲁棒水印的完整表征，确定了鲁棒性失败的阈值、实现鲁棒性的结构，以及实践中已经达到阈值的实验确认。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 18：08：32 UTC</p>
<h2 id="221-与生成式人工智能共同创造艺术的审美体验和教育价值来自年轻学习者调查的证据-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10576"target="_blank" rel="external nofollow noopener noreferrer">#221</a> <a href="https://papers.cool/arxiv/2509.10576"target="_blank" rel="external nofollow noopener noreferrer">与生成式人工智能共同创造艺术的审美体验和教育价值：来自年轻学习者调查的证据</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Chengyuan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengyuan</a> Zhang), [Suzhe Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Suzhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Suzhe</a> Xu)</p>
<p>本研究调查了年轻学习者和艺术学生与生成式人工智能（AI）合作艺术创作的审美体验和教育价值。基于对 112 名参与者的调查，我们研究了人类创作者如何重新协商自己的角色，如何挑战传统的原创观念，创作过程如何转变，以及人类人工智能共同创造中如何形成审美判断。从经验上讲，参与者普遍将人工智能视为激发构思和扩大创意边界的合作伙伴，而不是被动工具，同时对文体同质化和传统作者身份的侵蚀表示担忧。从理论上讲，我们将杜威的经验美学、伊赫德的后现象学和行为者网络理论（ANT）综合到一个单一的分析框架中，以解开人类创造者与人工智能作为非人类行为者之间的动态。研究结果表明 （i） 一种流动的主观性，其中创作者在多种立场（导演、对话伙伴、发现者）之间转变;（ii） 以批判性解释为中心的迭代对话工作流程（意图&ndash;生成&ndash;选择&ndash;完善）;（iii） 教育价值从技术技能培训转向批判性判断、跨模态构思和反身性等高阶能力。我们认为，艺术教育应该培养对技术的“批判性共创”立场，引导学习者与人工智能合作，同时保留人类在概念形成、判断和意义构建方面的独特性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 17：55：46 UTC</p>
<h2 id="222-gene-r1使用数据增强的轻量级-llm-进行基因集分析的推理-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10575"target="_blank" rel="external nofollow noopener noreferrer">#222</a> <a href="https://papers.cool/arxiv/2509.10575"target="_blank" rel="external nofollow noopener noreferrer">Gene-R1：使用数据增强的轻量级 LLM 进行基因集分析的推理</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Zhizheng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhizheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhizheng</a> Wang), [Yifan Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yifan</a> Yang), [Qiao Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiao</a> Jin), [Zhiyong Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyong</a> Lu)</p>
<p>基因集分析 （GSA） 是揭示与一组基因相关的分子功能的基本方法。最近，出现了由法学硕士驱动的方法，可以注释具有生物学功能的基因集以及连贯的解释性见解。然而，现有的研究主要集中在专有模型上，尽管担心成本和数据隐私，但这些模型已被证明优于开源模型。此外，没有研究调查高级推理策略在 GSA 任务中的应用。为了解决这一差距，我们推出了 Gene-R1，这是一个数据增强学习框架，为轻量级开源法学硕士提供了专为 GSA 量身定制的分步推理功能。对 1,508 个分布基因集的实验表明，Gene-R1 实现了显着的性能提升，与商业 LLM 相匹配。在 106 个分布外基因集上，Gene-R1 的性能与商业和大规模 LLM 相当，在不同基因来源中表现出强大的泛化性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/q-bio.GN"target="_blank" rel="external nofollow noopener noreferrer">基因组学</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 17：14：08 UTC</p>
<h2 id="223-使用大型语言模型和代码生成对表格数据进行质量评估-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10572"target="_blank" rel="external nofollow noopener noreferrer">#223</a> <a href="https://papers.cool/arxiv/2509.10572"target="_blank" rel="external nofollow noopener noreferrer">使用大型语言模型和代码生成对表格数据进行质量评估</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ashlesha Akella](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ashlesha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ashlesha</a> Akella), [Akshar Kaul](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Akshar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Akshar</a> Kaul), [Krishnasuri Narayanam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Krishnasuri"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Krishnasuri</a> Narayanam), [Sameep Mehta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sameep"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sameep</a> Mehta)</p>
<p>可靠的数据质量对于表格数据集的下游分析至关重要，但基于规则的验证往往面临效率低下、人为干预和高计算成本的问题。我们提出了一个三阶段框架，将统计内联检测与 LLM 驱动的规则和代码生成相结合。在通过传统聚类过滤数据样本后，我们迭代提示 LLM 生成语义上有效的质量规则，并通过代码生成 LLM 合成其可执行验证器。为了生成可靠的质量规则，我们通过利用外部知识源和特定领域的少量示例来帮助 LLM 进行检索增强生成 （RAG）。强大的护栏可确保规则和代码片段的准确性和一致性。对基准数据集的广泛评估证实了我们方法的有效性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.DB"target="_blank" rel="external nofollow noopener noreferrer">数据库</a></p>
<p><strong>发布</strong>: 2025-09-11 14：17：42 UTC</p>
<h2 id="224-自动驾驶轨迹预测大基础模型综合综述-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10570"target="_blank" rel="external nofollow noopener noreferrer">#224</a> <a href="https://papers.cool/arxiv/2509.10570"target="_blank" rel="external nofollow noopener noreferrer">自动驾驶轨迹预测大基础模型：综合综述</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wei Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Dai), [Shengen Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shengen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shengen</a> Wu), [Wei Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Wu), [Zhenhao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenhao</a> Wang), [Sisuo Lyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sisuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sisuo</a> Lyu), [Haicheng Liao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haicheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haicheng</a> Liao), [Limin Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Limin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Limin</a> Yu), [Weiping Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiping</a> Ding), [Runwei Guan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Runwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Runwei</a> Guan), [Yutao Yue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yutao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yutao</a> Yue)</p>
<p>轨迹预测是自动驾驶中的一项关键功能，能够为车辆和行人等交通参与者预测未来的运动路径，这对于驾驶安全至关重要。尽管传统的深度学习方法提高了准确性，但它们仍然受到固有局限性的阻碍，包括缺乏可解释性、严重依赖大规模注释数据以及长尾场景下的泛化能力较弱。大型基础模型 （LFM） 的兴起正在改变轨迹预测的研究范式。本调查对 LFM 的最新进展进行了系统回顾，特别是用于轨迹预测的大型语言模型 （LLM） 和多模态大型语言模型 （MLLM）。通过集成语言和场景语义，LFM 促进了可解释的上下文推理，显着增强了复杂环境中的预测安全性和泛化性。文章重点介绍了三种核心方法论：轨迹语言映射、多模态融合和基于约束的推理。它涵盖了车辆和行人的预测任务、评估指标和数据集分析。讨论了计算延迟、数据稀缺性和现实世界的鲁棒性等关键挑战，以及未来的研究方向，包括低延迟推理、因果关系感知建模和运动基础模型。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">机器人</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-11 10：30：06 世界标准时间</p>
<h2 id="225-markdiffusion用于潜在扩散模型生成水印的开源工具包-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10569"target="_blank" rel="external nofollow noopener noreferrer">#225</a> <a href="https://papers.cool/arxiv/2509.10569"target="_blank" rel="external nofollow noopener noreferrer">MarkDiffusion：用于潜在扩散模型生成水印的开源工具包</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Leyi Pan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leyi</a> Pan), [Sheng Guan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sheng</a> Guan), [Zheyu Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zheyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zheyu</a> Fu), [Luyang Si](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luyang</a> Si), [Zian Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zian</a> Wang), [Xuming Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuming</a> Hu), [Irwin King](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Irwin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Irwin</a> King), [Philip S. Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Philip"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Philip</a> S. Yu), [Aiwei Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aiwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aiwei</a> Liu), [Lijie Wen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lijie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lijie</a> Wen)</p>
<p>我们介绍了 MarkDiffusion，这是一个开源 Python 工具包，用于对潜在扩散模型进行生成水印。它由三个关键组成部分组成：用于简化水印算法集成和用户友好界面的统一实施框架;机制可视化套件，直观地展示添加和提取的水印图案，以帮助公众理解;以及一个全面的评估模块，在三个基本方面（可检测性、稳健性和输出质量）提供 24 种工具的标准实现，以及 8 个自动评估管道。通过 MarkDiffusion，我们寻求帮助研究人员，提高公众对生成水印的认识和参与度，并在推进研究和应用的同时促进共识。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-09-11 07：57：22 UTC</p>
<h2 id="226-avec本地法学硕士的引导隐私-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10561"target="_blank" rel="external nofollow noopener noreferrer">#226</a> <a href="https://papers.cool/arxiv/2509.10561"target="_blank" rel="external nofollow noopener noreferrer">AVEC：本地法学硕士的引导隐私</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Madhava Gaikwad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Madhava"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Madhava</a> Gaikwad)</p>
<p>本立场文件介绍了 AVEC（自适应可验证边缘控制），这是一个框架，通过在边缘强制执行隐私，并为委托查询提供显式可验证性，从而引导本地语言模型的隐私。AVEC 引入了一种自适应预算算法，该算法根据敏感度、本地置信度和历史使用情况分配每个查询的差分隐私参数，并使用可验证的转换和设备上的完整性检查。我们使用基于里程表的会计的 Rényi 差分隐私来形式化保证，并为确定性门控和纯哈希认证建立效用上限、委托泄漏边界和不可能结果。我们的评估在设计上基于模拟，以研究机制行为和核算;我们不声称实时 LLM 具有部署就绪或任务级实用程序。该贡献是一个概念架构和理论基础，为私下引导本地法学硕士的实证跟进制定了一条途径。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-10 07：59：01 UTC</p>
<h2 id="227-脑部疾病的生物标志物-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10547"target="_blank" rel="external nofollow noopener noreferrer">#227</a> <a href="https://papers.cool/arxiv/2509.10547"target="_blank" rel="external nofollow noopener noreferrer">脑部疾病的生物标志物</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Pascal Helson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pascal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pascal</a> Helson), [Arvind Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arvind"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arvind</a> Kumar)</p>
<p>尽管获取的大脑数据多种多样，并且有先进的基于人工智能的算法来分析它们，但大脑特征很少在临床上用于诊断和预后。在这里，我们认为，尽管大脑特征已经退化，但该领域继续依赖队列比较来寻找生物标志物。通过一项思想实验，我们表明更多的数据和更强大的算法不足以识别脑部疾病的生物标志物。我们认为，我们不应该使用单一数据类型比较患者与健康对照，而应该使用多模态（例如 大脑活动、神经递质、神经调节剂、脑成像）和纵向大脑数据来指导分组，然后再定义脑部疾病的多维生物标志物。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/q-bio.NC"target="_blank" rel="external nofollow noopener noreferrer">神经元与认知</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-08 11：58：09 UTC</p>
<h2 id="228-通过风险隐瞒揭示金融领域大语言模型的脆弱性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10546"target="_blank" rel="external nofollow noopener noreferrer">#228</a> <a href="https://papers.cool/arxiv/2509.10546"target="_blank" rel="external nofollow noopener noreferrer">通过风险隐瞒揭示金融领域大语言模型的脆弱性</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Gang Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gang</a> Cheng), [Haibo Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haibo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haibo</a> Jin), [Wenbin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenbin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenbin</a> Zhang), [Haohan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haohan</a> Wang), [Jun Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jun</a> Zhuang)</p>
<p>大型语言模型 （LLM） 越来越多地集成到金融应用中，但现有的红队研究主要针对有害内容，在很大程度上忽视了监管风险。在这项工作中，我们旨在通过红队方法调查金融法学硕士的脆弱性。我们引入了风险隐藏攻击 （RCA），这是一种新颖的多回合框架，它迭代隐藏监管风险，以激发法学硕士看似合规但违反监管的反应。为了实现系统评估，我们构建了 FIN-Bench，这是一个用于评估金融环境中 LLM 安全性的特定领域基准。在 FIN-Bench 上的大量实验表明，RCA 有效地绕过了 9 个主流 LLM，实现了 93.18% 的平均攻击成功率 （ASR），其中 GPT-4.1 为 98.28%，OpenAI o1 为 97.56%。这些发现揭示了当前对齐技术中存在的关键差距，并强调迫切需要在金融领域建立更强有力的审核机制。我们希望这项工作能为推进稳健且具有领域意识的 LLM 一致性提供实用的见解。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-07 22：35：15 UTC</p>
<h2 id="229-asl360通过无人机辅助无线网络实现-ai-支持的分层-360-视频自适应流-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10544"target="_blank" rel="external nofollow noopener noreferrer">#229</a> <a href="https://papers.cool/arxiv/2509.10544"target="_blank" rel="external nofollow noopener noreferrer">ASL360：通过无人机辅助无线网络实现 AI 支持的分层 360° 视频自适应流</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Alireza Mohammadhosseini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alireza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alireza</a> Mohammadhosseini), [Jacob Chakareski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jacob"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jacob</a> Chakareski), [Nicholas Mastronarde](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicholas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicholas</a> Mastronarde)</p>
<p>我们提出了ASL360，这是一种基于自适应深度强化学习的调度程序，用于在下一代无线网络中向移动VR用户提供点播360{\deg}视频流。我们的目标是最大限度地提高通过无人机辅助的 5G 无线网络服务的用户的整体体验质量 （QoE）。我们的系统模型包括一个宏基站 （MBS） 和一个无人机安装的基站，它们都向用户部署毫米波传输。360{\deg} 视频被编码为依赖层和分段图块，允许用户安排每个层片段的下载。此外，每个用户都使用多个缓冲区来存储相应视频层的片段。我们将调度决策建模为约束马尔可夫决策过程 （CMDP），其中代理选择 Base 层或增强层以最大化 QoE，并使用基于策略梯度的方法 （PPO） 来找到最佳策略。此外，我们还实现了成本组件的动态调整机制，使系统能够根据实时网络和流媒体会话条件，自适应地平衡视频质量、缓冲区占用率和质量变化并确定优先级。我们证明，与竞争性基线方法相比，ASL360 显着提高了 QoE，平均视频质量提高了约 2 dB，平均重新缓冲时间缩短了 80%，视频质量变化降低了 57%。我们的结果表明，我们的分层和自适应方法在增强沉浸式视频流应用中的QoE方面是有效的，特别是在动态和具有挑战性的网络环境中。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-09-07 01：22：57 UTC</p>
<h2 id="230-使用3d-cnn对抗性方法进行稳健的ddos攻击分类-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10543"target="_blank" rel="external nofollow noopener noreferrer">#230</a> <a href="https://papers.cool/arxiv/2509.10543"target="_blank" rel="external nofollow noopener noreferrer">使用3D CNN对抗性方法进行稳健的DDoS攻击分类</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Landon Bragg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Landon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Landon</a> Bragg), [Nathan Dorsey](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nathan</a> Dorsey), [Josh Prior](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Josh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Josh</a> Prior), [John Ajit](<a href="https://arxiv.org/search/?searchtype=author&amp;query=John"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=John</a> Ajit), [Ben Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ben"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ben</a> Kim), [Nate Willis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nate"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nate</a> Willis), [Pablo Rivas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pablo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pablo</a> Rivas)</p>
<p>分布式拒绝服务 （DDoS） 攻击仍然是对在线基础设施的严重威胁，通常通过以微妙的方式改变流量来绕过检测。我们提出了一种使用网络数据的蜂巢图序列和 3D 卷积神经网络 （3D CNN） 对 DDoS 流量进行高精度分类的方法。我们的系统依赖于三个主要思想：（1） 使用时空蜂巢图编码来设置模式识别基线，（2） 使用 FGSM 和 PGD 以及空间噪声和图像偏移应用对抗性训练，以及 （3） 分析逐帧预测以找到早期信号。在基准数据集上，我们的方法将对抗准确率从 50-55% 提高到 93% 以上，同时保持干净样本的性能。第 3-4 帧提供了强烈的预测信号，表明早期分类是可能的。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-07 00：20：32 UTC</p>
<h2 id="231-echoleak生产-llm-系统中第一个真实世界的零点击提示注入漏洞-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10540"target="_blank" rel="external nofollow noopener noreferrer">#231</a> <a href="https://papers.cool/arxiv/2509.10540"target="_blank" rel="external nofollow noopener noreferrer">EchoLeak：生产 LLM 系统中第一个真实世界的零点击提示注入漏洞</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Pavan Reddy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pavan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pavan</a> Reddy), [Aditya Sanjay Gujral](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aditya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aditya</a> Sanjay Gujral)</p>
<p>大型语言模型 （LLM） 助手越来越多地集成到企业工作流程中，在它们桥接内部和外部数据源时引发了新的安全问题。本文介绍了 EchoLeak （CVE-2025-32711） 的深入案例研究，这是 Microsoft 365 Copilot 中的一个零点击提示注入漏洞，可通过一封精心制作的电子邮件实现远程、未经身份验证的数据泄露。通过链接多个绕过规避 Microsoft 的 XPIA（交叉提示注入尝试）分类器、使用引用样式 Markdown 规避链接编辑、利用自动获取的图像以及滥用内容安全策略允许的 Microsoft Teams 代理，EchoLeak 实现了跨 LLM 信任边界的完全权限升级，而无需用户交互。我们分析了现有防御失败的原因，并概述了一组工程缓解措施，包括提示分区、增强的输入/输出过滤、基于来源的访问控制和严格的内容安全策略。除了具体的漏洞利用之外，我们还得出了构建安全人工智能副驾驶的可推广经验教训，强调最小权限、深度防御架构和持续对抗测试的原则。我们的研究结果将提示注入确立为生产 AI 系统中实用的高严重性漏洞类别，并为防御未来的 AI 原生威胁提供了蓝图。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-06 04：06：01 UTC</p>
<h2 id="232-dualalign生成基于临床的合成数据-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10538"target="_blank" rel="external nofollow noopener noreferrer">#232</a> <a href="https://papers.cool/arxiv/2509.10538"target="_blank" rel="external nofollow noopener noreferrer">DualAlign：生成基于临床的合成数据</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Rumeng Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rumeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rumeng</a> Li), [Xun Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xun</a> Wang), [Hong Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hong</a> Yu)</p>
<p>鉴于现实世界 EHR 的严格隐私限制、带注释的罕见病数据的可用性有限以及观察数据集中的系统性偏差，合成临床数据对于推进医疗保健领域的人工智能越来越重要。虽然大型语言模型 （LLM） 可以生成流畅的临床文本，但生成既现实又具有临床意义的合成数据仍然具有挑战性。我们介绍了 DualAlign，这是一个通过双重对齐增强统计保真度和临床合理性的框架：（1） 统计对齐，它对患者人口统计和风险因素的生成进行条件;（2） 语义对齐，结合现实世界的症状轨迹来指导内容生成。DualAlign 以阿尔茨海默病 （AD） 为案例研究，生成基于上下文的症状级句子，更好地反映现实世界的临床文档。与仅使用黄金数据或无指导合成基线训练的模型相比，结合 DualAlign 生成的数据和人工注释的数据对 LLaMA 3.1-8B 模型进行微调，可产生显着的性能提升。虽然 DualAlign 不能完全捕捉纵向复杂性，但它提供了一种实用的方法来生成基于临床的、保护隐私的合成数据，以支持低资源临床文本分析。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-05 18：04：38 UTC</p>
<h2 id="233-关于在联邦学习中使用大批量-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10537"target="_blank" rel="external nofollow noopener noreferrer">#233</a> <a href="https://papers.cool/arxiv/2509.10537"target="_blank" rel="external nofollow noopener noreferrer">关于在联邦学习中使用大批量</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Sahil Tyagi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sahil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sahil</a> Tyagi)</p>
<p>高效的联邦学习 （FL） 对于在计算资源有限和有界网络的设备上训练深度网络至关重要。随着大数据的出现，设备可以生成或收集多模态数据来训练通用或本地上下文感知网络，尤其是在数据隐私和局部性至关重要的情况下。FL 算法通常在并行性能和统计性能之间进行权衡，以更高的通信频率为代价提高模型质量，反之亦然。在频繁的同步设置下，通过处理更大的全局批量大小，在大型设备集群上的FL可能会在每次训练迭代中执行更多的工作，从而获得相当大的训练速度。然而，由于与大批量训练相关的泛化降级问题，这可能会导致测试性能不佳（即测试损失或准确性低）。为了应对大批量训练的这些挑战，本文提出了利用小批量和大批量训练之间权衡的愿景，并探索了兼顾大批量并行扩展和小批量训练良好泛化性的新方向。在相同的迭代次数下，我们观察到我们提出的大批量训练技术在ResNet50和VGG11模型中的测试精度分别比小批量训练高出约32.33%和3.74%。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.DC"target="_blank" rel="external nofollow noopener noreferrer">分布式、并行和集群计算</a></p>
<p><strong>发布</strong>: 2025-09-05 17：31：50 UTC</p>
<h2 id="234-语义引导的-lora-参数生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10535"target="_blank" rel="external nofollow noopener noreferrer">#234</a> <a href="https://papers.cool/arxiv/2509.10535"target="_blank" rel="external nofollow noopener noreferrer">语义引导的 LoRA 参数生成</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Miaoge Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Miaoge"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Miaoge</a> Li), [Yang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Chen), [Zhijie Rao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhijie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhijie</a> Rao), [Can Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Can"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Can</a> Jiang), [Jingcai Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingcai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingcai</a> Guo)</p>
<p>低秩自适应（LoRA）在各种任务中表现出了强大的泛化能力，可以有效地微调人工智能模型，尤其是在资源受限的边缘上。然而，在实际应用中，边缘用户经常表现出特定于任务的偏好，而这些偏好很难在封闭世界假设下训练的统一模型来处理，当训练和部署之间存在重大领域转移时，挑战可能会进一步增加。同时，由于其成本密集型性质和对边缘原始数据利用的隐私问题，为每个用户重新训练/微调模型也是不切实际的。为了应对这些挑战，我们提出了语义引导的 LoRA 参数生成 （SG-LoRA），这是同类框架中第一个可以高效生成用户特定 LoRA 参数的框架，而无需对用户任务进行任何额外训练或访问用户特定数据。具体来说，SG-LoRA 使用任务描述作为语义桥梁，测量它们与共享嵌入空间中一组已知专家任务的接近程度。基于这种语义指导，它对目标任务的 LoRA 参数分布进行建模，为新任务生成高性能参数。SG-LoRA 通过提炼来自著名 LoRA 专家的知识，能够实时构建符合个人意图的 LoRA 模型，同时为本工作中提出的新型零样本开放世界环境中的个性化模型适配提供隐私保护解决方案。对多项具有挑战性的任务的广泛实验证实了 SG-LoRA 的卓越性能和卓越的适应性。代码可在 <a href="https://github.com/keepgoingjkg/SG-LoRA"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/keepgoingjkg/SG-LoRA</a> 获得。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-05 14：43：41 UTC</p>
<h2 id="235-使用极坐标位置嵌入解耦什么和在哪里-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10534"target="_blank" rel="external nofollow noopener noreferrer">#235</a> <a href="https://papers.cool/arxiv/2509.10534"target="_blank" rel="external nofollow noopener noreferrer">使用极坐标位置嵌入解耦“什么”和“在哪里”</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Anand Gopalakrishnan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anand"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anand</a> Gopalakrishnan), [Robert Csordás](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Robert"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Robert</a> Csordás), [Jürgen Schmidhuber](<a href="https://arxiv.org/search/?searchtype=author&amp;query=J"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=J</a>ürgen Schmidhuber), [Michael C. Mozer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> C. Mozer)</p>
<p>Transformer 架构中的注意力机制根据内容（内容）和序列中的位置（位置）将键与查询进行匹配。我们提出了一个分析，表明在流行的 RoPE 旋转位置嵌入中纠缠的内容和位置。这种纠缠可能会损害性能，特别是当决策需要对这两个因素进行独立匹配时。我们提出了对 RoPE 的改进，我们称之为 Polar Coordinate Position Embeddings 或 PoPE，以消除 what-where 混淆。PoPE 在仅需要按位置或内容索引的诊断任务中要优越得多。在音乐、基因组和自然语言领域的自回归序列建模中，使用 PoPE 作为位置编码方案的 Transformers 在评估损失（困惑度）和下游任务性能方面优于使用 RoPE 的基线。在语言建模方面，这些收益在模型规模上持续存在，从 124M 到 774M 参数。至关重要的是，PoPE表现出强大的零样本长度外推能力，而RoPE的性能在测试时在较长的序列上会显着下降，而无需微调或使用位置插值方法。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-05 14：22：27 UTC</p>
<h2 id="236-finxplore用于平衡和发现投资机会的自适应深度强化学习框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10531"target="_blank" rel="external nofollow noopener noreferrer">#236</a> <a href="https://papers.cool/arxiv/2509.10531"target="_blank" rel="external nofollow noopener noreferrer">FinXplore：用于平衡和发现投资机会的自适应深度强化学习框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Himanshu Choudhary](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Himanshu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Himanshu</a> Choudhary), [Arishi Orra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arishi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arishi</a> Orra), [Manoj Thakur](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Manoj"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Manoj</a> Thakur)</p>
<p>投资组合优化对于平衡财务决策中的风险和回报至关重要。深度强化学习 （DRL） 作为投资组合优化的尖端工具脱颖而出，它使用试错交互来学习动态资产配置。然而，大多数基于 DRL 的方法仅限于在预定义的投资范围内分配资产，而忽视了探索新的机会。本研究介绍了一种投资格局，将开发现有资产与在扩展宇宙中探索新的投资机会相结合。所提出的方法利用两个 DRL 代理并动态平衡这些目标，以适应不断变化的市场，同时提高投资组合绩效。一个代理在现有宇宙中分配资产，而另一个代理则协助探索扩展宇宙中的新机会。所提出方法的效率是使用两个真实世界的市场数据集确定的。实验证明了建议的方法相对于最先进的投资组合策略和基线方法的优越性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-05 10：20：32 UTC</p>
<h2 id="237-动态自适应共享专家与专家的分组多头注意力混合-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10530"target="_blank" rel="external nofollow noopener noreferrer">#237</a> <a href="https://papers.cool/arxiv/2509.10530"target="_blank" rel="external nofollow noopener noreferrer">动态自适应共享专家与专家的分组多头注意力混合</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Cheng Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cheng</a> Li), [Jiexiong Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiexiong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiexiong</a> Liu), [Yixuan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixuan</a> Chen), [Jie ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jie</a> ji)</p>
<p>基于混合专家（MoE）架构的Transformer模型在长序列建模方面取得了显著进展，但现有模型在计算效率和捕获长程依赖关系的能力方面仍存在不足，特别是在专家资源分配的动态适应性方面。本文提出了一种动态自适应共享专家和分组多头注意力混合模型（DASG-MoE），通过集成三个模块来增强长序列建模能力。首先，我们采用分组多头注意力（GMHA）机制，有效降低长序列的计算复杂度。通过序列分组、局部滑动窗口注意力和特征聚合进行并行处理，我们解决了远程依赖问题以及模型对局部信息缺乏泛化的问题。其次，我们设计了双尺度共享专家结构（DSSE），浅层专家使用轻量级计算快速响应低维特征，而深度专家则通过训练前转移和训练后优化来处理高维复杂语义，实现效率和准确性的动态平衡。再次，提出一种分层的自适应动态路由（ADR）机制，该机制根据特征复杂度和任务需求动态选择专家级别，并通过本地专家激活策略优化资源分配。在多个长序列基准数据集上的实验表明，我们的 DASG-MoE 模型优于最先进的模型。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-05 02：49：15 UTC</p>
<h2 id="238-通过潜在回放减轻文本到图像扩散中的灾难性遗忘和模式崩溃-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10529"target="_blank" rel="external nofollow noopener noreferrer">#238</a> <a href="https://papers.cool/arxiv/2509.10529"target="_blank" rel="external nofollow noopener noreferrer">通过潜在回放减轻文本到图像扩散中的灾难性遗忘和模式崩溃</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Aoi Otani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aoi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aoi</a> Otani)</p>
<p>持续学习——在不忘记以前技能的情况下逐步获取知识的能力——是自然智力的基础。虽然人脑在这方面表现出色，但人工神经网络却在“灾难性遗忘”方面苦苦挣扎，即学习新任务会抹去以前获得的知识。对于文本到图像扩散模型来说，这一挑战尤其严峻，因为文本到图像的扩散模型根据文本提示生成图像。此外，这些模型还面临“模式崩溃”，随着时间的推移，它们的输出变得越来越重复。为了应对这些挑战，我们将潜在重播（一种受神经科学启发的方法）应用于扩散模型。传统的重播方法通过存储和重新访问过去的示例来减少遗忘，通常需要大量图像。相反，潜在重放仅保留从模型内部架构中提取的紧凑的高级特征表示。这反映了存储神经活动模式而不是原始感觉输入的海马过程，从而减少内存使用，同时保留关键信息。通过对五个顺序学习的视觉概念的实验，我们证明了潜在重放在保持模型多功能性方面明显优于现有方法。在学习了所有概念后，我们的方法在最早的概念上保留了 77.59% 的图像对齐 （IA），比基线方法高出 14%，同时保持了多样化的输出。令人惊讶的是，随机选择存储的潜在示例优于基于相似性的策略。我们的研究结果表明，Latent Replay 能够为生成式 AI 模型实现高效的持续学习，为个性化文本到图像模型铺平道路，这些模型可以随着用户需求而发展，而无需过多的计算成本。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-04 23：45：22 UTC</p>
<h2 id="239-stm-graph用于时空映射和图神经网络预测的-python-框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10528"target="_blank" rel="external nofollow noopener noreferrer">#239</a> <a href="https://papers.cool/arxiv/2509.10528"target="_blank" rel="external nofollow noopener noreferrer">STM-Graph：用于时空映射和图神经网络预测的 Python 框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Amirhossein Ghaffari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amirhossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amirhossein</a> Ghaffari), [Huong Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huong</a> Nguyen), [Lauri Lovén](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lauri"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lauri</a> Lovén), [Ekaterina Gilman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ekaterina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ekaterina</a> Gilman)</p>
<p>城市时空数据由于其动态和复杂的性质，给预测分析带来了独特的挑战。我们介绍了 STM-Graph，这是一个开源的 Python 框架，它将原始的时空城市事件数据转换为适合图神经网络 （GNN） 训练和预测的图表示。STM-Graph 集成了多种空间制图方法、来自 OpenStreetMap 的城市特征、多个 GNN 模型、全面的可视化工具以及适合专业和非专业用户的图形用户界面 （GUI）。这种模块化且可扩展的框架有助于快速实验和基准测试。它允许集成新的制图方法和自定义模型，使其成为城市计算研究人员和从业者的宝贵资源。框架和 GUI 的源代码可在以下位置获得：https://github.com/Ahghaffari/stm_graph 和 <a href="https://github.com/tuminguyen/stm_graph_gui"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/tuminguyen/stm_graph_gui</a>。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-04 21：36：48 UTC</p>
<h2 id="240-基于图的强化学习的资源感知神经网络剪枝-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10526"target="_blank" rel="external nofollow noopener noreferrer">#240</a> <a href="https://papers.cool/arxiv/2509.10526"target="_blank" rel="external nofollow noopener noreferrer">基于图的强化学习的资源感知神经网络剪枝</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Dieter Balemans](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dieter"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dieter</a> Balemans), [Thomas Huybrechts](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Huybrechts), [Jan Steckel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jan</a> Steckel), [Siegfried Mercelis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siegfried"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siegfried</a> Mercelis)</p>
<p>本文提出了一种新的神经网络修剪方法，通过将基于图的观察空间集成到AutoML框架中，以解决现有方法的局限性。传统的修剪方法通常依赖于手工制作的启发式方法和局部优化视角，这可能导致性能不佳和修剪策略效率低下。我们的框架通过引入目标神经网络的图表示来改变修剪过程，该图表示捕获了层和通道之间完整的拓扑关系，用网络结构的全局视图取代了有限的逐层观察空间。核心创新包括图注意力网络 （GAT） 编码器，它处理网络的图表示并生成丰富的嵌入。此外，对于动作空间，我们从连续剪枝比率过渡到细粒度的二进制动作空间，这使代理能够直接从数据中学习最佳通道重要性标准，从而摆脱预定义的评分函数。这些贡献是在约束马尔可夫决策过程 （CMDP） 框架内建模的，使代理能够做出明智的修剪决策，同时遵守目标压缩率等资源约束。为此，我们设计了一个自我竞争奖励系统，鼓励智能体在满足定义约束的同时超越其之前的最佳表现。我们通过对基准数据集（包括 CIFAR-10、CIFAR-100 和 ImageNet）的广泛实验证明了我们方法的有效性。实验表明，我们的方法始终优于传统的修剪技术，在学习特定于任务的修剪策略的同时显示出最先进的结果，这些策略可以识别功能冗余连接，而不仅仅是简单的权重大小考虑。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-04 15：05：05 UTC</p>
<h2 id="241-通过频率增强脑网络上的自监督学习进行数据高效的精神疾病检测-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10524"target="_blank" rel="external nofollow noopener noreferrer">#241</a> <a href="https://papers.cool/arxiv/2509.10524"target="_blank" rel="external nofollow noopener noreferrer">通过频率增强脑网络上的自监督学习进行数据高效的精神疾病检测</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mujie Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mujie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mujie</a> Liu), [Mengchu Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengchu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengchu</a> Zhu), [Qichao Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qichao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qichao</a> Dong), [Ting Dang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ting"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ting</a> Dang), [Jiangang Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiangang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiangang</a> Ma), [Jing Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jing</a> Ren), [Feng Xia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feng</a> Xia)</p>
<p>精神疾病涉及复杂的神经活动变化，功能磁共振成像 （fMRI） 数据是关键的诊断证据。然而，数据稀缺性和功能磁共振成像信息的多样性带来了重大挑战。虽然基于图的自监督学习（SSL）方法在脑网络分析中显示出前景，但它们主要关注时域表示，往往忽略了频域中嵌入的丰富信息。为了克服这些限制，我们提出了频率增强网络（FENet），这是一种专为功能磁共振成像数据设计的新型SSL框架，它集成了时域和频域信息，以改进小样本数据集中的精神疾病检测。FENet基于功能磁共振成像数据的固有属性构建多视图大脑网络，将频率信息明确纳入表示的学习过程中。此外，它还采用特定域编码器来捕获时间频谱特征，包括突出显示疾病相关频率特征的高效频域编码器。最后，FENet 引入了领域一致性引导的学习目标，该目标平衡了多样化信息的利用并生成频率增强的脑图表示。对两个真实世界医学数据集的实验表明，FENet 优于最先进的方法，同时在最小的数据条件下保持强大的性能。此外，我们分析了各种频域特征与精神疾病之间的相关性，强调了高频信息在疾病检测中的关键作用。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-04 05：10：13 UTC</p>
<h2 id="242-从预测到解释用于自闭症诊断和关键大脑区域识别的可解释人工智能-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10523"target="_blank" rel="external nofollow noopener noreferrer">#242</a> <a href="https://papers.cool/arxiv/2509.10523"target="_blank" rel="external nofollow noopener noreferrer">从预测到解释：用于自闭症诊断和关键大脑区域识别的可解释人工智能</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Kush Gupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kush"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kush</a> Gupta), [Amir Aly](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amir</a> Aly), [Emmanuel Ifeachor](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emmanuel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emmanuel</a> Ifeachor), [Rohit Shankar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rohit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rohit</a> Shankar)</p>
<p>自闭症谱系障碍 （ASD） 是一种以大脑成熟不典型为特征的神经发育疾病。然而，机器学习中迁移学习范式对 ASD 研究的适应仍然非常有限。在这项研究中，我们提出了一个包含两个模块的计算机辅助诊断框架。本章提出了一个结合深度学习和可解释人工智能的双模块框架，用于 ASD 诊断。第一个模块利用通过跨域迁移学习进行微调的深度学习模型进行 ASD 分类。第二个模块侧重于解释模型决策和识别关键大脑区域。为了实现这一目标，我们采用了三种可解释的人工智能（XAI）技术：显著性映射、梯度加权类激活映射和SHapley加法解释（SHAP）分析。该框架表明，跨领域迁移学习可以有效解决ASD研究中的数据稀缺问题。此外，通过应用三种既定的可解释性技术，该方法揭示了模型如何做出诊断决策并识别与 ASD 最相关的大脑区域。这些发现与已建立的神经生物学证据进行了比较，强调了强烈的一致性并加强了所提出方法的临床相关性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-04 03：48：10 UTC</p>
<h2 id="243-用于-atco-命令生命周期建模和工作负载预测的多模态深度学习-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10522"target="_blank" rel="external nofollow noopener noreferrer">#243</a> <a href="https://papers.cool/arxiv/2509.10522"target="_blank" rel="external nofollow noopener noreferrer">用于 ATCO 命令生命周期建模和工作负载预测的多模态深度学习</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Kaizhen Tan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaizhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaizhen</a> Tan)</p>
<p>空中交通管制员 （ATCO） 在密集的空域发出高强度的语音命令，准确的工作量建模对于安全和效率至关重要。本文提出了一种多模态深度学习框架，该框架集成了结构化数据、轨迹序列和图像特征，以估计ATCO命令生命周期中的两个关键参数：命令与由此产生的飞机机动之间的时间偏移量和命令持续时间。构建了一个高质量的数据集，使用滑动窗口和基于直方图的方法检测机动点。开发了 CNN-Transformer 集成模型，用于准确、可推广和可解释的预测。通过将轨迹与语音命令联系起来，这项工作提供了同类中第一个支持智能命令生成的模型，并为工作量评估、人员配备和调度提供了实用价值。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">音频和语音处理</a></p>
<p><strong>发布</strong>: 2025-09-04 02：28：41 UTC</p>
<h2 id="244-异质性和不平衡临床数据死亡率预测的联邦学习策略的比较基准-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10517"target="_blank" rel="external nofollow noopener noreferrer">#244</a> <a href="https://papers.cool/arxiv/2509.10517"target="_blank" rel="external nofollow noopener noreferrer">异质性和不平衡临床数据死亡率预测的联邦学习策略的比较基准</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Rodrigo Tertulino](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rodrigo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rodrigo</a> Tertulino)</p>
<p>机器学习模型在预测院内死亡率方面具有巨大潜力，但数据隐私限制和真实世界临床数据的统计异质性往往阻碍了它们的发展。联邦学习 （FL） 提供了一种隐私保护解决方案，但其在非独立和相同分布 （non-IID） 和不平衡条件下的性能需要严格调查。该研究提出了五种联邦学习策略的比较基准：FedAvg、FedProx、FedAdagrad、FedAdam 和 FedCluster 用于死亡率预测。使用大规模 MIMIC-IV 数据集，我们通过按临床护理单位对数据进行划分来模拟真实的非 IID 环境。为了解决任务固有的类不平衡，SMOTE-Tomek 技术应用于每个客户端的本地训练数据。我们进行了 50 多轮通信的实验表明，基于正则化的策略 FedProx 始终优于其他方法，在保持稳定收敛的同时实现了 0.8831 的最高 F1 分数。虽然基线 FedAvg 的计算效率最高，但其预测性能要低得多。我们的研究结果表明，与标准或服务器端自适应聚合方法相比，FedProx 等基于正则化的 FL 算法为异构和不平衡的临床预测任务提供了更稳健、更有效的解决方案。这项工作为为实际医疗保健应用选择合适的 FL 策略提供了一个重要的实证基准。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-03 11：32：57 UTC</p>
<h2 id="245-教育中的隐私保护个性化用于学生表现预测的联合推荐系统-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10516"target="_blank" rel="external nofollow noopener noreferrer">#245</a> <a href="https://papers.cool/arxiv/2509.10516"target="_blank" rel="external nofollow noopener noreferrer">教育中的隐私保护个性化：用于学生表现预测的联合推荐系统</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Rodrigo Tertulino](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rodrigo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rodrigo</a> Tertulino)</p>
<p>教育数字化的不断发展为数据驱动的个性化提供了前所未有的机遇，但它也带来了重大的学生数据隐私挑战。传统的推荐系统依赖于集中式数据，这种范式通常与现代数据保护法规不兼容。提出了一种新型的隐私保护推荐系统，并使用联邦学习 （FL） 解决了这一关键问题。该方法利用深度神经网络 （DNN），该网络具有来自大规模 ASSISTments 教育数据集的丰富工程特征。对联合聚合策略进行了严格的比较分析，确定 FedProx 是一种比标准 FedAvg 基线更稳定、更有效的处理异构学生数据的方法。优化后的联邦模型实现了 76.28% 的高性能 F1-Score，相当于强大的集中式 XGBoost 模型性能的 82.85%。这些发现验证了联合方法可以提供高效的内容推荐，而无需集中敏感的学生数据。因此，我们的工作为现代教育平台中的个性化隐私困境提供了可行且稳健的解决方案。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<p><strong>发布</strong>: 2025-09-03 11：28：57 世界标准时间</p>
<h2 id="246-logguardq用于安全日志中网络安全异常检测的认知增强强化学习框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10511"target="_blank" rel="external nofollow noopener noreferrer">#246</a> <a href="https://papers.cool/arxiv/2509.10511"target="_blank" rel="external nofollow noopener noreferrer">LogGuardQ：用于安全日志中网络安全异常检测的认知增强强化学习框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Umberto Gonçalves de Sousa](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Umberto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Umberto</a> Gonçalves de Sousa)</p>
<p>强化学习 （RL） 改变了顺序决策，但深度 Q 网络 （DQN） 和近端策略优化 （PPO） 等传统算法在动态环境中经常难以实现高效探索、稳定性和适应性。本研究提出了 LogGuardQ（Adaptive Log Guard with Cognitive Enhancement），这是一个新颖的框架，它集成了受人类认知启发的双记忆系统和由温度衰减和好奇心驱动的自适应探索策略。在包含 1,000,000 个模拟访问日志的数据集上进行评估，在 20,000 个事件中异常率为 47.9%，LogGuardQ 的检测率为 96.0%（DQN 为 93.0%，PPO 为 47.1%），精度为 0.4776，召回率为 0.9996，F1 得分为 0.6450。所有剧集的平均奖励为 20.34 \pm 44.63（而 DQN 为 18.80 \pm 43.98，PPO 为 -0.17 \pm 23.79），平均每集步数为 5.0（模型之间不变）。图形分析，包括使用 Savgol 滤波器（window=501，多项式=2）平滑的学习曲线、方差趋势、动作分布和累积检测，证明了 LogGuardQ 卓越的稳定性和效率。统计检验 （Mann-Whitney U） 证实了显着的性能优势（例如，p = 0.0002 与效应量可忽略不计的 DQN，p &lt; 0.0001 与中等效应量的 PPO，以及 DQN 与小效应量的 PPO 的 p &lt; 0.0001）。通过连接认知科学和 RL，LogGuardQ 提供了一种可扩展的不确定环境中的自适应学习方法，在网络安全、入侵检测和不确定性下的决策中具有潜在应用。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a></p>
<p><strong>发布</strong>: 2025-09-02 15：51：53 UTC</p>
<h2 id="247-firegnn具有可训练模糊规则的神经符号图神经网络用于可解释的医学图像分类-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10510"target="_blank" rel="external nofollow noopener noreferrer">#247</a> <a href="https://papers.cool/arxiv/2509.10510"target="_blank" rel="external nofollow noopener noreferrer">FireGNN：具有可训练模糊规则的神经符号图神经网络，用于可解释的医学图像分类</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Prajit Sengupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prajit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prajit</a> Sengupta), [Islem Rekik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Islem"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Islem</a> Rekik)</p>
<p>医学图像分类不仅需要高预测性能，还需要可解释性，以确保临床信任和采用。图神经网络 （GNN） 为数据集中的关系结构建模提供了一个强大的框架;然而，标准 GNN 通常作为黑匣子运行，限制了透明度和可用性，特别是在临床环境中。在这项工作中，我们提出了一个名为 FireGNN 的可解释的基于图的学习框架，该框架将可训练的模糊规则集成到 GNN 中，用于医学图像分类。这些规则嵌入了拓扑描述符——节点度、聚类系数和标签一致性——使用可学习的阈值和清晰度参数来实现内在符号推理。此外，我们还探索了辅助自监督任务（例如，同质预测、相似性熵）作为评估拓扑学习贡献的基准。我们的模糊规则增强模型在五个 MedMNIST 基准测试和合成数据集 MorphoMNIST 中取得了强大的性能，同时还生成了可解释的基于规则的解释。据我们所知，这是 GNN 中可训练模糊规则的首次集成。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">图像和视频处理</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-09-02 12：57：54 UTC</p>
<h2 id="248-反衔尾蛇效应递归选择性反馈对大型语言模型的涌现弹性-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10509"target="_blank" rel="external nofollow noopener noreferrer">#248</a> <a href="https://papers.cool/arxiv/2509.10509"target="_blank" rel="external nofollow noopener noreferrer">反衔尾蛇效应：递归选择性反馈对大型语言模型的涌现弹性</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Sai Teja Reddy Adapala](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sai</a> Teja Reddy Adapala)</p>
<p>递归训练的大型语言模型（LLM）的稳定性是人工智能安全的基本问题。流行的理论预测模型崩溃，即在模型根据自己的输出进行训练时逐渐退化。我们通过引入选择性反馈机制来挑战这种说法。与预期相反，我们的实验不仅减缓了衰减，还提供了强有力的证据，证明这种压力可以逆转衰减，从而在复杂的摘要任务中导致 Gemma 2B 模型的性能显着提高。我们将这种现象命名为反衔尾蛇效应。我们将此与使用简单分类器的基础实验进行对比，其中验证了理论退行循环，突出了高维模型的独特动力学。我们的研究结果表明，在简单的选择压力下，系统弹性可以成为法学硕士的一个新兴属性，这为开发更安全、更强大的人工智能系统提出了一个强大且可扩展的原则。在五代中，质量过滤条件的 ROUGE-L F1 分数提高了 6.6%，而未过滤的对照降低了 3.5%，随机过滤对照降低了 4.2%</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-02 05：46：28 UTC</p>
<h2 id="249-car-brainet用于异构车联网的sub-6ghz辅助空间自适应波束预测具有多头注意力-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10508"target="_blank" rel="external nofollow noopener noreferrer">#249</a> <a href="https://papers.cool/arxiv/2509.10508"target="_blank" rel="external nofollow noopener noreferrer">CAR-BRAINet：用于异构车联网的Sub-6GHz辅助空间自适应波束预测，具有多头注意力</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Aathira G Menon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aathira"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aathira</a> G Menon), [Prabu Krishnan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prabu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prabu</a> Krishnan), [Shyam Lal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shyam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shyam</a> Lal)</p>
<p>异构车载网络（HetVNets）通过堆叠sub-6GHz、毫米波和DSRC等不同通信技术，满足5G/B5G车载网络的多样化连接需求，发挥着关键作用。HetVNet 有助于满足巨大的用户需求，但在高度移动的现实条件下保持稳定的连接仍然是一个挑战。尽管对波束预测模型的研究已经很多，但很少探索 HetVNet 的专用解决方案。因此，当务之急是开发一种可靠的波束预测解决方案，专门针对 HetVNet。本文介绍了一种基于深度学习的轻量级解决方案，称为“CAR-BRAINet”，该解决方案由卷积神经网络和强大的多头注意力（MHA）机制组成。现有的波束预测文献主要在有限、理想化的车辆场景下进行研究，往往忽视了车辆网络的实时复杂性和复杂性。因此，本研究旨在通过将著名的MAC协议-3GPP-C-V2X和IEEE 802.11BD、高速和不同距离下的多普勒频移效应以及信噪比水平等关键因素纳入与城市、农村和高速公路车辆网络相关的三个高质量动态数据集中，模拟实时驾驶场景的复杂性。CAR-BRAINet 在所有车辆场景中都表现有效，展示了精确的波束预测，波束架空最小，与现有方法相比，光谱效率稳定提高了 17.9422%。因此，本研究证明了CAR-BRAINet在复杂HetVNet中的有效性，在不依赖移动用户的位置角度和天线尺寸的情况下提供了有希望的性能，从而减少了冗余的传感器延迟。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a></p>
<p><strong>发布</strong>: 2025-09-02 05：17：23 UTC</p>
<h2 id="250-面向去中心化异构平台的智能物联网框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10507"target="_blank" rel="external nofollow noopener noreferrer">#250</a> <a href="https://papers.cool/arxiv/2509.10507"target="_blank" rel="external nofollow noopener noreferrer">面向去中心化异构平台的智能物联网框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Vadim Allayev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vadim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vadim</a> Allayev), [Mahbubur Rahman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mahbubur"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mahbubur</a> Rahman)</p>
<p>智能物联网（IoIT）是一个新兴领域，它将物联网（IoT）设备的实用性与嵌入式人工智能算法的创新相结合。然而，它并非没有挑战，并且在可用计算资源、能源供应和存储限制方面存在困难。特别是，IoIT 的许多障碍与嵌入式设备中机器学习 （ML）/深度学习 （DL） 模型的节能部署有关。已经进行了研究来设计节能的 IoIT 平台，但这些论文通常集中在集中式系统上，其中某个中央实体处理所有数据并协调行动。这可能会带来问题，例如，成为瓶颈或导致安全问题。在去中心化系统中，节点/设备将自组织并做出自己的决定。因此，为了解决这些问题，我们提出了一种异构、分散的感知和监控IoIT点对点网状网络系统模型。网络中的节点将朝着几个优化目标进行协调：可靠性、能效和延迟。该系统采用联邦学习以分布式方式训练节点，采用元启发式方法优化任务分配和路由路径，采用多目标优化来平衡相互冲突的性能目标。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-01 22：54：01 UTC</p>
<h2 id="251-树结构mdp中通过最差路径策略优化进行逆合成规划-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10504"target="_blank" rel="external nofollow noopener noreferrer">#251</a> <a href="https://papers.cool/arxiv/2509.10504"target="_blank" rel="external nofollow noopener noreferrer">树结构MDP中通过最差路径策略优化进行逆合成规划</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mianchu Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mianchu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mianchu</a> Wang), [Giovanni Montana](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Giovanni"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Giovanni</a> Montana)</p>
<p>逆合成规划旨在将目标分子分解为可用的构建块，形成一个合成树，其中每个内部节点代表一个中间化合物，每片叶子理想地对应于一个可购买的反应物。然而，如果任何叶节点不是有效的构建块，则该树将变得无效，从而使规划过程容易受到合成路线中“最薄弱环节”的影响。现有方法通常针对跨分支机构的平均性能进行优化，而未能考虑到这种最坏情况的敏感性。在本文中，我们将逆合成重新定义为树结构马尔可夫决策过程（MDP）中的最差路径优化问题。我们证明，该配方允许独特的最佳解决方案，并提供单调改进保证。基于这一见解，我们引入了交互式逆合成计划（InterRetro），这是一种与树MDP交互的方法，学习最差路径结果的价值函数，并通过自我模仿改进其策略，优先强化过去的决策，具有高估计优势。根据经验，InterRetro取得了最先进的结果，在Retro*-190基准测试中解决了100%的目标，将合成路线缩短了4.9%，并且仅使用10%的训练数据就取得了有希望的性能&ndash;代表了计算逆合成规划的重大进步。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">计算工程、金融和科学</a></p>
<p><strong>发布</strong>: 2025-09-01 21：44：14 UTC</p>
<h2 id="252-fedexchange免费弥合联合对象检测中的域差距-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10503"target="_blank" rel="external nofollow noopener noreferrer">#252</a> <a href="https://papers.cool/arxiv/2509.10503"target="_blank" rel="external nofollow noopener noreferrer">FEDEXCHANGE：免费弥合联合对象检测中的域差距</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Haolin Yuan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haolin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haolin</a> Yuan), [Jingtao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingtao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingtao</a> Li), [Weiming Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weiming</a> Zhuang), [Chen Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chen</a> Chen), [Lingjuan Lyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingjuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingjuan</a> Lyu)</p>
<p>联合对象检测 （FOD） 使客户能够协作训练全局对象检测模型，而无需从不同域访问其本地数据。然而，环境、天气和其他领域特定因素的显着变化阻碍了性能，使跨领域泛化成为关键挑战。现有的 FOD 方法往往忽视了边缘设备的硬件限制，并引入了局部训练正则化，从而产生了高计算成本，限制了现实世界的适用性。在本文中，我们提出了 FEDEXCHANGE，这是一种新颖的 FOD 框架，可以在不引入额外本地计算开销的情况下弥合领域差距。FEDEXCHANGE 采用服务器端动态模型交换策略，使每个客户端能够从其他客户端的域数据中获得见解，而无需直接共享数据。具体来说，FEDEXCHANGE 允许服务器在模型聚合和模型交换之间交替。在聚合轮次期间，服务器会像往常一样聚合所有本地模型。在交换轮中，FEDEXCHANGE 根据距离测量对局部模型进行聚类和交换，使局部模型能够从各种领域中学习。由于所有作都在服务器端执行，因此客户端可以实现改进的跨域实用程序，而无需任何额外的计算开销。广泛的评估表明，FEDEXCHANGE 增强了 FOD 性能，在具有挑战性的领域（例如雨天条件）的平均平均精度提高了 1.6 倍，而与基线方法相比，只需要 0.8 倍的计算资源。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a></p>
<p><strong>发布</strong>: 2025-09-01 17：39：25 UTC</p>
<h2 id="253-从噪声到精度一种扩散驱动的零膨胀降水预测方法-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10501"target="_blank" rel="external nofollow noopener noreferrer">#253</a> <a href="https://papers.cool/arxiv/2509.10501"target="_blank" rel="external nofollow noopener noreferrer">从噪声到精度：一种扩散驱动的零膨胀降水预测方法</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Wentao Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wentao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wentao</a> Gao), [Jiuyong Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiuyong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiuyong</a> Li), [Lin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lin</a> Liu), [Thuc Duy Le](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thuc"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thuc</a> Duy Le), [Xiongren Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiongren"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiongren</a> Chen), [Xiaojing Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaojing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaojing</a> Du), [Jixue Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jixue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jixue</a> Liu), [Yanchang Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanchang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanchang</a> Zhao), [Yun Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yun</a> Chen)</p>
<p>零膨胀数据对降水预报提出了重大挑战，因为零占主导地位，非零事件稀疏。为了解决这个问题，我们提出了零膨胀扩散框架（ZIDF），它集成了用于平滑零膨胀分布的高斯微扰、用于捕获时间模式的基于 Transformer 的预测以及用于恢复原始数据结构的基于扩散的去噪。在我们的实验中，我们使用从南澳大利亚收集的观测降水数据以及合成生成的零膨胀数据。结果表明，与多种最先进的降水预报模型相比，ZIDF表现出显著的性能提升，与基线非稳态变压器相比，MSE降低了56.7%，MAE降低了21.1%。这些发现凸显了 ZIDF 稳健处理稀疏时间序列数据的能力，并表明其潜在的可推广性到零通货膨胀是关键挑战的其他领域。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-01 13：37：59 UTC</p>
<h2 id="254-迈向可扩展的o-ran资源管理图增强的近端策略优化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10499"target="_blank" rel="external nofollow noopener noreferrer">#254</a> <a href="https://papers.cool/arxiv/2509.10499"target="_blank" rel="external nofollow noopener noreferrer">迈向可扩展的O-RAN资源管理：图增强的近端策略优化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Duc-Thinh Ngo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Duc-Thinh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Duc-Thinh</a> Ngo), [Kandaraj Piamrat](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kandaraj"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kandaraj</a> Piamrat), [Ons Aouedi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ons"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ons</a> Aouedi), [Thomas Hassan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Hassan), [Philippe Raipin-Parvédy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Philippe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Philippe</a> Raipin-Parvédy)</p>
<p>开放式无线接入网络 （O-RAN） 架构通过分解和虚拟化基带功能，实现灵活、可扩展且经济高效的移动网络。然而，这种灵活性给资源管理带来了重大挑战，需要在动态需求和复杂拓扑下对功能拆分选择和虚拟化单元放置进行联合优化。现有解决方案通常单独解决这些方面，或者在大型和现实场景中缺乏可扩展性。在这项工作中，我们提出了一种新颖的图增强近端策略优化（GPPO）框架，该框架利用图神经网络（GNN）进行拓扑感知特征提取，并集成动作掩蔽以有效地导航组合决策空间。我们的方法共同优化了功能拆分和放置决策，捕捉了O-RAN资源分配的全部复杂性。在小型和大型O-RAN场景上的广泛实验表明，GPPO始终优于最先进的基线，在泛化测试中实现了高达18%的部署成本和25%的回报，同时保持了完美的可靠性。这些结果凸显了GPPO在实际O-RAN部署中的有效性和可扩展性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-09-01 08：53：04 UTC</p>
<h2 id="255-基于在线学习的lorawan网络高效资源分配-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10493"target="_blank" rel="external nofollow noopener noreferrer">#255</a> <a href="https://papers.cool/arxiv/2509.10493"target="_blank" rel="external nofollow noopener noreferrer">基于在线学习的LoRaWAN网络高效资源分配</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Ruiqi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruiqi</a> Wang), [Jing Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jing</a> Ren), [Tongyu Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tongyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tongyu</a> Song), [Wenjun Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenjun</a> Li), [Xiong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiong</a> Wang), [Sheng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sheng</a> Wang), [Shizhong Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shizhong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shizhong</a> Xu)</p>
<p>大规模 LoRaWAN 网络的部署需要通过动态分配传输参数（包括载波频率、扩展因子和传输功率）来共同优化数据包传输比 （PDR） 和能效 （EE） 等冲突指标。现有方法往往过于简化这一挑战，专注于单一指标或缺乏动态通道环境所需的适应性，从而导致性能不佳。为了解决这个问题，我们提出了两个基于在线学习的资源分配框架，它们可以智能地引导 PDR-EE 权衡。我们的基础提案 D-LoRa 是一个完全分布式的框架，将问题建模为组合多臂强盗。通过分解联合参数选择并采用专门的分解奖励函数，D-LoRa 显着降低了学习复杂性，并使节点能够自主适应网络动态。为了进一步增强 LoRaWAN 网络的性能，我们引入了 CD-LoRa，这是一个混合框架，它集成了轻量级、集中式初始化阶段，以执行一次性的、准最优的信道分配和动作空间修剪，从而加速后续的分布式学习。广泛的仿真和真实世界的现场实验证明了我们框架的优越性，表明 D-LoRa 在非静止环境中表现出色，而 CD-LoRa 在静止条件下实现了最快的收敛。在物理部署中，我们的方法优于最先进的基线，将 PDR 提高了 10.8%，EE 提高了 26.1%，证实了它们对于可扩展和高效的 LoRaWAN 网络的实际有效性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-08-31 12：36：33 世界标准时间</p>
<h2 id="256-分布式gossip-gan在fdd-mmimo-ofdm系统中进行低开销csi反馈训练-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10490"target="_blank" rel="external nofollow noopener noreferrer">#256</a> <a href="https://papers.cool/arxiv/2509.10490"target="_blank" rel="external nofollow noopener noreferrer">分布式Gossip-GAN在FDD mMIMO-OFDM系统中进行低开销CSI反馈训练</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yuwen Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuwen</a> Cao), [Guijun Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guijun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guijun</a> Liu), [Tomoaki Ohtsuki](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tomoaki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tomoaki</a> Ohtsuki), [Howard H. Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Howard"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Howard</a> H. Yang), [Tony Q. S. Quek](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tony"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tony</a> Q. S. Quek)</p>
<p>事实证明，深度自动编码器 （DAE） 框架在减少大规模多输入多输出 （mMIMO） 系统中的信道状态信息 （CSI） 反馈开销方面具有有效性。然而，先前工作中提出的这些DAE方法严重依赖于通过基站（BS）收集的大规模数据进行模型训练，从而导致带宽使用过多和数据隐私问题，特别是对于mMIMO系统。在考虑用户的移动性和遇到新的渠道环境时，现有的CSI反馈模型可能经常需要重新训练。然而，回到以前的环境将使这些模型表现不佳，并面临灾难性遗忘的风险。为了解决上述难题，我们提出了一种新型的八卦生成对抗网络（Gossip-GAN）辅助CSI反馈训练框架。值得注意的是，Gossip-GAN 能够以低开销进行 CSI 反馈训练，同时保护用户的隐私。具体来说，每个用户收集少量数据来训练一个 GAN 模型。同时，采用全分布式八卦学习策略来避免模型过拟合，并加速模型训练。仿真结果表明，Gossip-GAN可以i）实现与真实世界数据集集中训练相似的CSI反馈精度，ii）解决移动场景中的灾难性遗忘挑战，iii）大大减少上行链路带宽的使用。此外，我们的结果表明，所提出的方法具有固有的鲁棒性。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/eess.SP"target="_blank" rel="external nofollow noopener noreferrer">信号处理</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.IT"target="_blank" rel="external nofollow noopener noreferrer">信息论</a></p>
<p><strong>发布</strong>: 2025-08-31 07：46：16 UTC</p>
<h2 id="257-sabr使用行为克隆预训练和强化学习微调的稳定自适应比特率框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10486"target="_blank" rel="external nofollow noopener noreferrer">#257</a> <a href="https://papers.cool/arxiv/2509.10486"target="_blank" rel="external nofollow noopener noreferrer">SABR：使用行为克隆预训练和强化学习微调的稳定自适应比特率框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Pengcheng Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pengcheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pengcheng</a> Luo), [Yunyang Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunyang</a> Zhao), [Bowen Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Zhang), [Genke Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Genke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Genke</a> Yang), [Boon-Hee Soong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Boon-Hee"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Boon-Hee</a> Soong), [Chau Yuen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chau"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chau</a> Yuen)</p>
<p>随着5G的出现，互联网进入了一个以视频为中心的新时代。从抖音这样的短视频平台到哔哩哔哩这样的长视频平台，在线视频服务正在重塑用户的消费习惯。自适应比特率 （ABR） 控制被广泛认为是影响体验质量 （QoE） 的关键因素。近年来，基于学习的ABR方法越来越受到关注。然而，它们中的大多数在训练过程中依赖于有限的网络跟踪集，而忽略了现实世界网络条件的广泛分布特征，导致在分布外（OOD）场景下的泛化性较差。为了解决这一限制，我们提出了 SABR，这是一种将行为克隆 （BC） 预训练与强化学习 （RL） 微调相结合的训练框架。我们还引入了基准测试 ABRBench-3G 和 ABRBench-4G+，它们提供大范围的训练轨迹和专用的 OOD 测试集，用于评估对看不见的网络条件的鲁棒性。实验结果表明，在所提出的基准测试中，SABR与Pensieve、Comyco和NetLLM相比取得了最佳的平均排名。这些结果表明，SABR能够在广泛的分布中实现更稳定的学习，并改进了对看不见的网络条件的泛化。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.NI"target="_blank" rel="external nofollow noopener noreferrer">网络和互联网架构</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-08-30 05：32：45 UTC</p>
<h2 id="258-aegisshield利用生成式人工智能实现网络威胁建模民主化-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10482"target="_blank" rel="external nofollow noopener noreferrer">#258</a> <a href="https://papers.cool/arxiv/2509.10482"target="_blank" rel="external nofollow noopener noreferrer">AegisShield：利用生成式人工智能实现网络威胁建模民主化</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Author</strong>: [Matthew Grofsky](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matthew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matthew</a> Grofsky)</p>
<p>技术系统的日益复杂使得传统的威胁建模难以扩展，特别是对于资源有限的小型组织而言。本文开发并评估了 AegisShield，这是一种生成式 AI 增强型威胁建模工具，它实施了 STRIDE 和 MITRE ATT&amp;CK 来自动生成威胁并提供系统评估。通过集成来自国家漏洞数据库和 AlienVault Open Threat Exchange 的实时威胁情报，AegisShield 生成简化且易于访问的威胁描述。我们对来自 15 个案例研究的 243 个威胁和 8000 多个 AI 生成的威胁的评估表明，AegisShield 降低了复杂性（p 小于 0.001），产生了与专家开发的威胁语义一致的输出（p 小于 0.05），并在将威胁映射到 MITRE ATT&amp;CK 技术方面实现了 85.4% 的成功率（p 小于 0.001）。自动化和标准化威胁建模有助于资源不足的组织更早地解决风险，并支持更广泛地采用安全设计实践。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">密码学和安全性</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong>: 2025-08-29 03：49：15 UTC</p>
<h2 id="259-用于识别供应链漏洞的实时-rag-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10469"target="_blank" rel="external nofollow noopener noreferrer">#259</a> <a href="https://papers.cool/arxiv/2509.10469"target="_blank" rel="external nofollow noopener noreferrer">用于识别供应链漏洞的实时 RAG</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Jesse Ponnock](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jesse"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jesse</a> Ponnock), [Grace Kenneally](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Grace"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Grace</a> Kenneally), [Michael Robert Briggs](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Robert Briggs), [Elinor Yeo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Elinor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Elinor</a> Yeo), [Tyrone Patterson III](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tyrone"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tyrone</a> Patterson III), [Nicholas Kinberg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicholas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicholas</a> Kinberg), [Matthew Kalinowski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matthew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matthew</a> Kalinowski), [David Hechtman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Hechtman)</p>
<p>生成式人工智能的新技术可以对我们国家的供应链进行更深入的分析，但真正信息丰富的见解需要及时不断更新和聚合海量数据。大型语言模型 （LLM） 提供了前所未有的分析机会，但是，它们的知识库仅限于模型的最后一次训练日期，这使得这些功能对于任务影响依赖于新兴和及时信息的组织来说无法使用。本研究提出了一种创新的供应链分析方法，将新兴的检索增强生成 （RAG） 预处理和检索技术与先进的网络抓取技术相结合。我们的方法旨在减少将新信息合并到增强法学硕士中的延迟，从而能够及时分析供应链中断因素。通过实验，本研究评估了这些技术对及时性和质量权衡的组合效应。我们的结果表明，在将RAG系统应用于供应链分析时，微调嵌入检索模型始终能提供最显著的性能提升，这凸显了检索质量的至关重要性。自适应迭代检索根据上下文动态调整检索深度，进一步提高了性能，尤其是在复杂的供应链查询上。相反，微调 LLM 产生的改进有限且资源成本更高，而向下查询抽象等技术在实践中明显优于向上抽象。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-08-23 22：06：19 UTC</p>
<h2 id="260-从预训练和协作信号中学习分解的上下文标记表示以进行生成推荐-pdf1-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10468"target="_blank" rel="external nofollow noopener noreferrer">#260</a> <a href="https://papers.cool/arxiv/2509.10468"target="_blank" rel="external nofollow noopener noreferrer">从预训练和协作信号中学习分解的上下文标记表示，以进行生成推荐</a> [PDF1] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Yifan Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yifan</a> Liu), [Yaokun Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yaokun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yaokun</a> Liu), [Zelin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zelin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zelin</a> Li), [Zhenrui Yue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenrui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenrui</a> Yue), [Gyuseok Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gyuseok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gyuseok</a> Lee), [Ruichen Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruichen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruichen</a> Yao), [Yang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Zhang), [Dong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Wang)</p>
<p>生成式推荐器的最新进展采用了两阶段范式：首先使用预训练的分词器将项目标记为语义 ID，然后训练大型语言模型 （LLM） 通过序列到序列建模生成下一个项目。然而，这两个阶段针对不同的目标进行了优化：分词器预训练期间的语义重建与推荐器训练期间的用户交互建模。这种客观的不一致导致了两个关键限制：（i）次优静态标记化，其中固定标记分配无法反映不同的使用环境;（ii） 丢弃的预训练语义，其中预训练的知识（通常来自语言模型嵌入）在用户交互的推荐器训练期间被覆盖。为了解决这些限制，我们建议学习 DEcomposed COntextual Token Representations （DECOR），这是一个统一的框架，它保留了预训练的语义，同时增强了 token 嵌入的适应性。DECOR 引入了上下文化的标记组合，以根据用户交互上下文细化标记嵌入，以及将预训练的代码本嵌入与新学习的协作嵌入集成的分解嵌入融合。在三个真实世界数据集上的实验表明，DECOR 在推荐性能方面始终优于最先进的基线。我们的代码将在发布后提供。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-08-22 18：50：38 UTC</p>
<h2 id="261-dsrag基于文档衍生多模态知识图谱的领域特定检索框架-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10467"target="_blank" rel="external nofollow noopener noreferrer">#261</a> <a href="https://papers.cool/arxiv/2509.10467"target="_blank" rel="external nofollow noopener noreferrer">DSRAG：基于文档衍生多模态知识图谱的领域特定检索框架</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Mengzheng Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengzheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengzheng</a> Yang), [Yanfei Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanfei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanfei</a> Ren), [David Osei Opoku](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Osei Opoku), [Ruochang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruochang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruochang</a> Li), [Peng Ren](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peng</a> Ren), [Chunxiao Xing](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chunxiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chunxiao</a> Xing)</p>
<p>目前通用大型语言模型（LLM）在特定领域任务中普遍表现出知识幻觉和特定领域适应性不足，限制了其在专业问答场景中的有效性。检索增强生成 （RAG） 通过整合外部知识来提高准确性和相关性，从而有效应对这些挑战。然而，传统的RAG在领域知识准确性和上下文建模方面仍面临局限性。为了增强特定领域的问答性能，这项工作重点关注基于图的 RAG 框架，强调知识图谱质量在生成过程中的关键作用。我们提出了 DSRAG（Domain-Specific RAG），这是一个多模态知识图谱驱动的检索增强生成框架，专为特定领域的应用而设计。我们的方法以特定领域的文档为主要知识源，整合文本、图像和表格等异构信息，构建涵盖概念层和实例层的多模态知识图谱。在此基础上，我们引入了语义剪枝和结构化子图检索机制，结合知识图谱上下文和向量检索结果，指导语言模型产生更可靠的响应。使用 Langfuse 多维评分机制的评估表明，我们的方法在特定领域的问答方面表现出色，验证了将多模态知识图谱与检索增强生成相结合的功效。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">信息检索</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">计算机视觉和模式识别</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">多媒体</a></p>
<p><strong>发布</strong>: 2025-08-22 14：24：48 UTC</p>
<h2 id="262-基于收敛优化的动量集成多任务股票推荐-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.10461"target="_blank" rel="external nofollow noopener noreferrer">#262</a> <a href="https://papers.cool/arxiv/2509.10461"target="_blank" rel="external nofollow noopener noreferrer">基于收敛优化的动量集成多任务股票推荐</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Hao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hao</a> Wang), [Jingshu Peng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingshu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingshu</a> Peng), [Yanyan Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanyan</a> Shen), [Xujia Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xujia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xujia</a> Li), [Lei Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lei</a> Chen)</p>
<p>股票推荐在金融科技应用程序中至关重要，这些应用程序使用价格序列和替代信息来估计未来的股票表现。尽管深度学习模型在股票推荐系统中很普遍，但传统的时间序列预测训练往往无法同时捕捉股票趋势和排名，而这些都是投资者必不可少的考虑因素。为了解决这个问题，我们引入了一个用于股票推荐的多任务学习 （MTL） 框架，\textbf{M}omentum-\textbf{i}ntegrated \textbf{M}ulti-task \textbf{Stoc}k \textbf{R}ecommendation with Converge-based Optimization （\textbf{MiM-StocR}）。为了提高模型捕捉短期趋势的能力，我们在模型训练中新颖地调用了动量线指标。为了优先考虑表现最好的股票并优化投资配置，我们提出了一个名为 Adaptive-k ApproxNDCG 的列表排名损失函数。此外，由于股票市场的波动性和不确定性，现有的 MTL 框架在应用于股票时间序列时面临过度拟合问题。为了缓解这个问题，我们引入了基于收敛的四平衡 （CQB） 方法。我们对三个股票基准进行了广泛的实验：SEE50、沪深 100 和沪深 300。MiM-StocR 在排名和盈利评估方面的表现都优于最先进的 MTL 基线。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/q-fin.ST"target="_blank" rel="external nofollow noopener noreferrer">统计金融</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong>: 2025-08-05 09：04：38 UTC</p>
<h2 id="263-在正确的水平上说话使用-rag-rl-进行识字控制的反语音生成-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.01058"target="_blank" rel="external nofollow noopener noreferrer">#263</a> <a href="https://papers.cool/arxiv/2509.01058"target="_blank" rel="external nofollow noopener noreferrer">在正确的水平上说话：使用 RAG-RL 进行识字控制的反语音生成</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xiaoying Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoying</a> Song), [Anirban Saha Anik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anirban"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anirban</a> Saha Anik), [Dibakar Barua](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dibakar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dibakar</a> Barua), [Pengcheng Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pengcheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pengcheng</a> Luo), [Junhua Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junhua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junhua</a> Ding), [Lingzi Hong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingzi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingzi</a> Hong)</p>
<p>在线传播的健康错误信息对公共卫生构成重大威胁。研究人员探索了自动生成针对健康错误信息的反言论的方法，作为缓解策略。现有的方法往往会产生统一的反应，而忽略了受众的健康素养水平可能会影响反言论的可及性和有效性。我们提出了一个受控读写能力框架，使用检索增强生成 （RAG） 和强化学习 （RL） 来生成适合不同健康素养水平的定制反言论。特别是，我们检索与特定健康素养水平相符的知识，使可访问的事实信息为生成提供支持。我们设计了一个奖励函数，结合了主观用户偏好和基于客观可读性的奖励，以优化针对目标健康素养水平的反言论。实验结果表明，受控读写能力通过生成更易于访问和用户首选的反言论来优于基线。这项研究通过提高对健康错误信息的反言论的可及性和理解性，有助于更加公平和有影响力的公共卫生传播。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-01 01：54：14 UTC</p>
<h2 id="264-用于一致危机响应的动态融合模型-pdf-copy-kimi-rel"><a href="https://arxiv.org/abs/2509.01053"target="_blank" rel="external nofollow noopener noreferrer">#264</a> <a href="https://papers.cool/arxiv/2509.01053"target="_blank" rel="external nofollow noopener noreferrer">用于一致危机响应的动态融合模型</a> [PDF] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Xiaoying Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoying</a> Song), [Anirban Saha Anik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anirban"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anirban</a> Saha Anik), [Eduardo Blanco](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eduardo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eduardo</a> Blanco), [Vanessa Frias-Martinez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vanessa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vanessa</a> Frias-Martinez), [Lingzi Hong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingzi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingzi</a> Hong)</p>
<p>为了应对与受危机影响人群进行有效沟通的迫切需求，有人提出了由语言模型驱动的自动响应来协助危机沟通。一个关键但经常被忽视的因素是响应风格的一致性，这可能会影响受影响个人对响应者的信任。尽管它很重要，但很少有研究探索在生成的响应中保持风格一致性的方法。为了解决这一差距，我们提出了一种评估风格一致性的新指标，并引入了一种基于该指标的基于融合的生成方法。我们的方法采用两阶段过程：首先评估候选响应的风格，然后通过融合过程在实例级别对其进行优化和集成。这样可以生成高质量的响应，同时显着减少实例之间的风格差异。跨多个数据集的实验结果表明，我们的方法在响应质量和风格一致性方面始终优于基线。</p>
<p><strong>主题</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></p>
<p><strong>发布</strong>: 2025-09-01 01：41：52 UTC</p>
<h2 id="265-用于自动程序转换的程序骨架-pdf2-copy-kimi-rel"><a href="https://arxiv.org/abs/2504.07483"target="_blank" rel="external nofollow noopener noreferrer">#265</a> <a href="https://papers.cool/arxiv/2504.07483"target="_blank" rel="external nofollow noopener noreferrer">用于自动程序转换的程序骨架</a> [PDF2] [Copy] [Kimi] [REL]</h2>
<p><strong>Authors</strong>: [Bo Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Wang), [Tianyu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyu</a> Li), [Ruishi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruishi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruishi</a> Li), [Umang Mathur](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Umang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Umang</a> Mathur), [Prateek Saxena](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prateek"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prateek</a> Saxena)</p>
<p>在编程语言之间转换软件是一项具有挑战性的任务，自动化技术一直难以实现，也很难扩展到更大的程序。跨语言翻译的一个关键困难是必须将源程序的预期行为重新表达为不同目标语言的惯用结构。此任务需要从特定于源语言的细节中抽象出来，同时保持整体功能不变。在这项工作中，我们提出了一种新颖而系统的方法，基于我们称之为程序骨架的框架，使这种翻译适合自动化。程序骨架通过抽象并有效地总结较低级别的具体代码片段来保留源程序的高级结构，这些代码片段可以机械地转换为目标编程语言。从设计上讲，骨架允许以多种不同的方式填充片段的具体实现，这些方式可以与现有的数据驱动代码合成器结合使用。最重要的是，骨架在概念上可以实现声音分解，即，如果每个单独的片段都被正确翻译，与机械翻译的骨架一起，最终翻译的程序被认为是整体正确的。我们提出了一个名为 Skel 的原型系统，它体现了从 Python 到 JavaScript 的基于骨架的转换的想法。与之前的工作相比，我们的结果显示出有希望的可扩展性。对于 9 个真实世界的 Python 程序，其中一些代码超过 1k 行，其 95% 的代码片段可以自动翻译，而大约 5% 需要手动翻译。对于整个程序测试套件，所有最终翻译都是正确的。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.PL"target="_blank" rel="external nofollow noopener noreferrer">编程语言</a>, <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">软件工程</a></p>
<p><strong>发布</strong>: 2025-04-10 06：25：17 UTC</p>
<h2 id="266-使用深度卷积神经网络进行音频分类的频谱和节奏特征-pdf-copy-kimi1-rel"><a href="https://arxiv.org/abs/2410.06927"target="_blank" rel="external nofollow noopener noreferrer">#266</a> <a href="https://papers.cool/arxiv/2410.06927"target="_blank" rel="external nofollow noopener noreferrer">使用深度卷积神经网络进行音频分类的频谱和节奏特征</a> [PDF] [Copy] [Kimi1] [REL]</h2>
<p><strong>Author</strong>: [Friedrich Wolf-Monheim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Friedrich"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Friedrich</a> Wolf-Monheim)</p>
<p>卷积神经网络 （CNN） 广泛应用于计算机视觉。它们不仅可用于识别模式的传统数字图像材料，还可用于从数字图像中提取特征，表示从时域数字音频信号中提取的频谱和节奏特征，以对声音进行声学分类。使用深度卷积神经网络从音频分类性能的角度研究了不同的频谱和节律特征表示，如梅尔尺度频谱图、梅尔频率倒谱系数（MFCC）、循环时间图、短时傅里叶变换（STFT）色谱图、恒定Q变换（CQT）色谱图和色度能量归一化统计（CENS）色谱图。可以清楚地表明，对于使用深度CNN的音频分类任务，梅尔尺度频谱图和梅尔频率倒谱系数（MFCC）的性能明显优于本研究中研究的其他频谱和节律特征。实验是在ESC-50数据集的帮助下进行的，该数据集包含2,000个标记的环境录音。</p>
<p><strong>科目</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">声音</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">音频和语音处理</a></p>
<p><strong>发布</strong>: 2024-10-09 14：21：59 UTC</p>
<h1 id="13-huggingface">1.3 Huggingface</h1>
<p>InfGen：一种用于可扩展图像合成的分辨率无关范式（18 ▲）
收益递减的错觉：衡量大型语言模型的长程执行能力（14 ▲）
HANRAG：用于多跳问答的启发式精确抗噪检索增强生成（13 ▲）
虚拟代理经济体（10 ▲）
X-Part：高保真且结构连贯的形状分解（9 ▲）
VStyle：基于语音指令的语音风格适配基准（8 ▲）
FLOWER：通过高效的视觉-语言-动作流策略推动通用机器人策略的普及（7 ▲）
扩散大型语言模型的修复引导策略优化（6 ▲）
LoFT：开放世界场景下长尾半监督学习的参数高效微调（5 ▲）
精准为我上色：连接感知色彩空间与文本嵌入以改进扩散生成（4 ▲）
QuantAgent：用于高频交易的价格驱动多代理大型语言模型（4 ▲）
具有概率结构整合的世界建模（4 ▲）
以及另外8篇论文</p>
<ul>
<li><a href="https://huggingface.co/papers/2509.10441?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis (18 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.09677?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">The Illusion of Diminishing Returns: Measuring Long Horizon Execution in LLMs (14 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.09713?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering (13 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.10147?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">Virtual Agent Economies (10 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.08643?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">X-Part: high fidelity and structure coherent shape decomposition (9 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.09716?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">VStyle: A Benchmark for Voice Style Adaptation with Spoken Instructions (8 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.04996?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies (7 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.10396?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">Inpainting-Guided Policy Optimization for Diffusion Large Language Models (6 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.09926?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios (5 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.10058?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation (4 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.09995?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">QuantAgent: Price-Driven Multi-Agent LLMs for High-Frequency Trading (4 ▲)</a></li>
<li><a href="https://huggingface.co/papers/2509.09737?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">World Modeling with Probabilistic Structure Integration (4 ▲)</a></li>
<li>And <a href="https://huggingface.co/papers?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-09-15"target="_blank" rel="external nofollow noopener noreferrer">8 more papers</a></li>
</ul>
<h1 id="2-简单记录">2. 简单记录</h1>
<pre tabindex="0"><code>![](https://gitee.com/dujh22/pic/raw/master/logicReason/SLR.png)</code></pre></div></article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">Public - 2025</span><span class="author" itemprop="copyrightHolder">
              <a href="/LLMDailyDigestWeb/"></a></span></div><div class="footer-line statistics"></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">Theme FixIt works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="preload" href="/LLMDailyDigestWeb/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/cookieconsent/cookieconsent.min.css"><script src="/LLMDailyDigestWeb/lib/sharer/sharer.min.js" async defer></script><script src="/LLMDailyDigestWeb/lib/typeit/index.umd.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/katex.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/auto-render.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/copy-tex.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/mhchem.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-desktop":"LLM-DailyDigest 大模型研究日报","typeit-header-title-mobile":"LLM-DailyDigest 大模型研究日报"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-desktop":["typeit-header-desktop"],"typeit-header-title-mobile":["typeit-header-title-mobile"]},"duration":-1,"loop":false,"speed":100}};</script><script src="/LLMDailyDigestWeb/js/theme.min.js" defer></script></body>
</html>
