<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head><script src="/LLMDailyDigestWeb/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=LLMDailyDigestWeb/livereload" data-no-instant defer></script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>2025-08-15ç§‘ç ”è¿½æ–° - LLM-DailyDigest</title><meta name="author" content="">
<meta name="author-link" content="">
<meta name="description" content="2025-08-15ç§‘ç ”è¿½æ–°
2025-08-14 19:39:40 Thursday ~ 2025-08-15 19:37:11 Friday
1. æºæ•°æ®
1.1 å…¬ä¼—å·
1.1.1 é‡å­ä½

æ··å…ƒ3Dä¸–ç•Œæ¨¡å‹1.0 liteç‰ˆæœ¬å‘å¸ƒï¼Œæ¶ˆè´¹çº§æ˜¾å¡å°±èƒ½è·‘
æ¨¡ä»¿äººç±»æ¨ç†ä¿®æ­£è¿‡ç¨‹ï¼Œé˜¶è·ƒæ˜Ÿè¾°æå‡ºå½¢å¼åŒ–è¯æ˜æ–°èŒƒå¼ | å¼€æº
ç¬‘æ­»ï¼Œäººå½¢æœºå™¨äººè¿åŠ¨ä¼šå…¨æ˜¯é¬¼ç•œååœºé¢ï¼è¿™é”…ç²¥å¤§å®¶æ¥è¶ä¹±å–äº†å§
å›½å®¶çº§AIåˆ›æ–°åº”ç”¨èµ›äº‹æ€ç–¯äº†ï¼è¶…200ä¸‡å…ƒå¥–é‡‘æ± &#43;å…¨åœºæ™¯èµ›é“ï¼Œå†²çº¿å›¢é˜Ÿé€Ÿæ¥
è°·æ­Œç‰ˆå°é’¢ç‚®å¼€æºï¼0.27Bå¤§æ¨¡å‹ï¼Œ4ä¸ªæ³¨æ„åŠ›å¤´ï¼Œä¸“ä¸ºç»ˆç«¯è€Œç”Ÿ
GPT-5è¶…è¶Šäººç±»åŒ»ç”Ÿï¼æ¨ç†èƒ½åŠ›æ¯”ä¸“å®¶é«˜å‡º24%ï¼Œç†è§£åŠ›å¼º29%
é¦–ä¸ªå¼€æºå¤šæ¨¡æ€Deep Researchæ™ºèƒ½ä½“ï¼Œè¶…è¶Šå¤šä¸ªé—­æºæ–¹æ¡ˆ
OpenAIåäººéœ²å¤´å°±è¢«å°æ‰æŒ–ï¼95ååŒ—å¤§æ ¡å‹1ä¸ªæœˆå‰ä¸Šç›´æ’­ï¼Œä»Šå¤©å·²æ˜¯Metaäºº
å®æµ‹Perplexity Proå¹³æ›¿æ¨¡å‹ï¼Œå…è´¹å¼€æºä»…4B

1.1.2 æœºå™¨ä¹‹å¿ƒ

ä¸€å¥è¯æå®šå¤šä»»åŠ¡å‡ºè¡Œï¼Œé«˜å¾·ç”¨ç©ºé—´æ™ºèƒ½é‡æ–°å®šä¹‰åœ°å›¾
GPT-5ã€Grok 4ã€o3 Proéƒ½é›¶åˆ†ï¼Œå²ä¸Šæœ€éš¾AIè¯„æµ‹åŸºå‡†æ¢å®ƒäº†
è°·æ­Œå¼€æºGemma 3 270Mï¼Œæ€§èƒ½è¶…è¶ŠQwen 2.5åŒçº§æ¨¡å‹
è¿½å‰§ä¸æ–­ç½‘ï¼Œå¯èƒ½èƒŒåæœ‰ä¸ªAIåœ¨åŠ ç­ï¼Œæ•…éšœè¯Šæ–­å‡†åº¦ç ´91.79%
Metaè§†è§‰åŸºåº§DINOv3ç‹è€…å½’æ¥ï¼šè‡ªç›‘ç£é¦–æ¬¡å…¨é¢è¶…è¶Šå¼±ç›‘ç£ï¼Œå•†ç”¨å¼€æº
å¤šçªè§¦ç¥ç»å…ƒæ¨¡å‹é—®ä¸–ï¼Œå›½å†…å›¢é˜Ÿæ‰“é€ ç±»è„‘è®¡ç®—æ–°å¼•æ“ï¼Œç™»ä¸Šã€Šè‡ªç„¶Â·é€šè®¯ã€‹
æ‰å…‹ä¼¯æ ¼çœ‹OpenAIç›´æ’­æŒ–äººï¼ŒåŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…åŠ å…¥Meta
AI æ¨¡ç‰¹æ—¶ä»£åˆ°æ¥ï¼šå­—èŠ‚xæ¸…åæ¨å‡ºå•†ç”¨çº§è§†é¢‘æ¢è£…æ¨¡å‹DreamVVTï¼Œä¿çœŸåº¦æ˜¾è‘—é¢†å…ˆSOTA

1.1.3 æ–°æ™ºå…ƒ

æ ¸å¿ƒæ¨¡å‹è¢«æ›è’¸é¦DeepSeekï¼Ÿå‰å¥³å‹ä¸€çº¸æ§è¯‰ï¼Œæ›å‡ºæ¬§ç‰ˆOpenAIå¡Œæˆ¿çœŸç›¸ï¼
æ‰“å¼€é«˜å¾·çš„ç†ç”±åˆå¤šä¸€æ¡ï¼å…¨çƒé¦–ä¸ªã€Œéœ€æ±‚é“¾æ™ºèƒ½è°ƒåº¦ã€AIåœ°å›¾ä¸Šçº¿
åä¸‹17äº¿å›¾ç‰‡ï¼ŒMetaæœ€å¼ºå·¨å…½DINOv3å¼€æºï¼é‡æ–°å®šä¹‰CVå¤©èŠ±æ¿
AIæ­£åœ¨æç©ºå¤§è„‘ï¼Œæ€æƒ³æ²¦ä¸ºæ®‹åºŸï¼æœªæ¥åªåˆ†AIçš„ã€Œä¸»äººã€å’Œã€Œå¥´éš¶ã€
åŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…Cä½å‡ºé•œï¼Œå°æ‰çœ‹OpenAIç›´æ’­å¤ºäººï¼1äº¿åˆ€è–ªé…¬å…‰é€Ÿè¢«ç­¾
OpenAIæ³¢å…°åŒé›„ï¼šGPTä¸æ˜¯å¶ç„¶ï¼å†å¿†å¥¥ç‰¹æ›¼è¢«é€å½“å¤©å®å†µ
Cohereèèµ„36äº¿ï¼ŒAMDè‹±ä¼Ÿè¾¾éƒ½æŠ•äº†ï¼å‰Metaç ”ç©¶å‰¯æ€»è£å‡ºä»»é¦–å¸­AIå®˜

1.1.4 AGI Hunt

Claude Code æ¨å‡ºå­¦ä¹ æ¨¡å¼ï¼Œæ¯”ChatGPTæ›´æ¿€è¿›ï¼šç”šè‡³èƒ½ç»™ä½ å¸ƒç½®ä½œä¸šâ€¦â€¦
GPT-5æ­£ä»¥o3çš„ä¸‰å€é€Ÿåº¦æ‰“å®å¯æ¢¦ï¼Œç°å·²æŠµè¾¾å† å†›ä¹‹è·¯ï¼Œç›´æ’­è¿›è¡Œä¸­

1.1.5 å…¶ä»–

Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models https://arxiv.org/abs/2508.09874
ğŸŒˆ Multi-Step Reasoning with Large Language Models, a Survey https://arxiv.org/abs/2407.11511

1.2 Arxiv
1.2.1 Computation and Language
Fromï¼šhttps:// /arxiv/cs.CL" /><meta name="keywords" content='Hugo, FixIt' />
  <meta itemprop="name" content="2025-08-15ç§‘ç ”è¿½æ–°">
  <meta itemprop="description" content="2025-08-15ç§‘ç ”è¿½æ–° 2025-08-14 19:39:40 Thursday ~ 2025-08-15 19:37:11 Friday
1. æºæ•°æ® 1.1 å…¬ä¼—å· 1.1.1 é‡å­ä½ æ··å…ƒ3Dä¸–ç•Œæ¨¡å‹1.0 liteç‰ˆæœ¬å‘å¸ƒï¼Œæ¶ˆè´¹çº§æ˜¾å¡å°±èƒ½è·‘ æ¨¡ä»¿äººç±»æ¨ç†ä¿®æ­£è¿‡ç¨‹ï¼Œé˜¶è·ƒæ˜Ÿè¾°æå‡ºå½¢å¼åŒ–è¯æ˜æ–°èŒƒå¼ | å¼€æº ç¬‘æ­»ï¼Œäººå½¢æœºå™¨äººè¿åŠ¨ä¼šå…¨æ˜¯é¬¼ç•œååœºé¢ï¼è¿™é”…ç²¥å¤§å®¶æ¥è¶ä¹±å–äº†å§ å›½å®¶çº§AIåˆ›æ–°åº”ç”¨èµ›äº‹æ€ç–¯äº†ï¼è¶…200ä¸‡å…ƒå¥–é‡‘æ± &#43;å…¨åœºæ™¯èµ›é“ï¼Œå†²çº¿å›¢é˜Ÿé€Ÿæ¥ è°·æ­Œç‰ˆå°é’¢ç‚®å¼€æºï¼0.27Bå¤§æ¨¡å‹ï¼Œ4ä¸ªæ³¨æ„åŠ›å¤´ï¼Œä¸“ä¸ºç»ˆç«¯è€Œç”Ÿ GPT-5è¶…è¶Šäººç±»åŒ»ç”Ÿï¼æ¨ç†èƒ½åŠ›æ¯”ä¸“å®¶é«˜å‡º24%ï¼Œç†è§£åŠ›å¼º29% é¦–ä¸ªå¼€æºå¤šæ¨¡æ€Deep Researchæ™ºèƒ½ä½“ï¼Œè¶…è¶Šå¤šä¸ªé—­æºæ–¹æ¡ˆ OpenAIåäººéœ²å¤´å°±è¢«å°æ‰æŒ–ï¼95ååŒ—å¤§æ ¡å‹1ä¸ªæœˆå‰ä¸Šç›´æ’­ï¼Œä»Šå¤©å·²æ˜¯Metaäºº å®æµ‹Perplexity Proå¹³æ›¿æ¨¡å‹ï¼Œå…è´¹å¼€æºä»…4B 1.1.2 æœºå™¨ä¹‹å¿ƒ ä¸€å¥è¯æå®šå¤šä»»åŠ¡å‡ºè¡Œï¼Œé«˜å¾·ç”¨ç©ºé—´æ™ºèƒ½é‡æ–°å®šä¹‰åœ°å›¾ GPT-5ã€Grok 4ã€o3 Proéƒ½é›¶åˆ†ï¼Œå²ä¸Šæœ€éš¾AIè¯„æµ‹åŸºå‡†æ¢å®ƒäº† è°·æ­Œå¼€æºGemma 3 270Mï¼Œæ€§èƒ½è¶…è¶ŠQwen 2.5åŒçº§æ¨¡å‹ è¿½å‰§ä¸æ–­ç½‘ï¼Œå¯èƒ½èƒŒåæœ‰ä¸ªAIåœ¨åŠ ç­ï¼Œæ•…éšœè¯Šæ–­å‡†åº¦ç ´91.79% Metaè§†è§‰åŸºåº§DINOv3ç‹è€…å½’æ¥ï¼šè‡ªç›‘ç£é¦–æ¬¡å…¨é¢è¶…è¶Šå¼±ç›‘ç£ï¼Œå•†ç”¨å¼€æº å¤šçªè§¦ç¥ç»å…ƒæ¨¡å‹é—®ä¸–ï¼Œå›½å†…å›¢é˜Ÿæ‰“é€ ç±»è„‘è®¡ç®—æ–°å¼•æ“ï¼Œç™»ä¸Šã€Šè‡ªç„¶Â·é€šè®¯ã€‹ æ‰å…‹ä¼¯æ ¼çœ‹OpenAIç›´æ’­æŒ–äººï¼ŒåŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…åŠ å…¥Meta AI æ¨¡ç‰¹æ—¶ä»£åˆ°æ¥ï¼šå­—èŠ‚xæ¸…åæ¨å‡ºå•†ç”¨çº§è§†é¢‘æ¢è£…æ¨¡å‹DreamVVTï¼Œä¿çœŸåº¦æ˜¾è‘—é¢†å…ˆSOTA 1.1.3 æ–°æ™ºå…ƒ æ ¸å¿ƒæ¨¡å‹è¢«æ›è’¸é¦DeepSeekï¼Ÿå‰å¥³å‹ä¸€çº¸æ§è¯‰ï¼Œæ›å‡ºæ¬§ç‰ˆOpenAIå¡Œæˆ¿çœŸç›¸ï¼ æ‰“å¼€é«˜å¾·çš„ç†ç”±åˆå¤šä¸€æ¡ï¼å…¨çƒé¦–ä¸ªã€Œéœ€æ±‚é“¾æ™ºèƒ½è°ƒåº¦ã€AIåœ°å›¾ä¸Šçº¿ åä¸‹17äº¿å›¾ç‰‡ï¼ŒMetaæœ€å¼ºå·¨å…½DINOv3å¼€æºï¼é‡æ–°å®šä¹‰CVå¤©èŠ±æ¿ AIæ­£åœ¨æç©ºå¤§è„‘ï¼Œæ€æƒ³æ²¦ä¸ºæ®‹åºŸï¼æœªæ¥åªåˆ†AIçš„ã€Œä¸»äººã€å’Œã€Œå¥´éš¶ã€ åŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…Cä½å‡ºé•œï¼Œå°æ‰çœ‹OpenAIç›´æ’­å¤ºäººï¼1äº¿åˆ€è–ªé…¬å…‰é€Ÿè¢«ç­¾ OpenAIæ³¢å…°åŒé›„ï¼šGPTä¸æ˜¯å¶ç„¶ï¼å†å¿†å¥¥ç‰¹æ›¼è¢«é€å½“å¤©å®å†µ Cohereèèµ„36äº¿ï¼ŒAMDè‹±ä¼Ÿè¾¾éƒ½æŠ•äº†ï¼å‰Metaç ”ç©¶å‰¯æ€»è£å‡ºä»»é¦–å¸­AIå®˜ 1.1.4 AGI Hunt Claude Code æ¨å‡ºå­¦ä¹ æ¨¡å¼ï¼Œæ¯”ChatGPTæ›´æ¿€è¿›ï¼šç”šè‡³èƒ½ç»™ä½ å¸ƒç½®ä½œä¸šâ€¦â€¦ GPT-5æ­£ä»¥o3çš„ä¸‰å€é€Ÿåº¦æ‰“å®å¯æ¢¦ï¼Œç°å·²æŠµè¾¾å† å†›ä¹‹è·¯ï¼Œç›´æ’­è¿›è¡Œä¸­ 1.1.5 å…¶ä»– Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models https://arxiv.org/abs/2508.09874 ğŸŒˆ Multi-Step Reasoning with Large Language Models, a Survey https://arxiv.org/abs/2407.11511 1.2 Arxiv 1.2.1 Computation and Language Fromï¼šhttps:// /arxiv/cs.CL">
  <meta itemprop="datePublished" content="2025-08-15T00:00:00+08:00">
  <meta itemprop="dateModified" content="2025-08-15T00:00:00+08:00">
  <meta itemprop="wordCount" content="59409"><meta property="og:url" content="http://localhost:1313/LLMDailyDigestWeb/updates/2025-08-15/">
  <meta property="og:site_name" content="LLM-DailyDigest">
  <meta property="og:title" content="2025-08-15ç§‘ç ”è¿½æ–°">
  <meta property="og:description" content="2025-08-15ç§‘ç ”è¿½æ–° 2025-08-14 19:39:40 Thursday ~ 2025-08-15 19:37:11 Friday
1. æºæ•°æ® 1.1 å…¬ä¼—å· 1.1.1 é‡å­ä½ æ··å…ƒ3Dä¸–ç•Œæ¨¡å‹1.0 liteç‰ˆæœ¬å‘å¸ƒï¼Œæ¶ˆè´¹çº§æ˜¾å¡å°±èƒ½è·‘ æ¨¡ä»¿äººç±»æ¨ç†ä¿®æ­£è¿‡ç¨‹ï¼Œé˜¶è·ƒæ˜Ÿè¾°æå‡ºå½¢å¼åŒ–è¯æ˜æ–°èŒƒå¼ | å¼€æº ç¬‘æ­»ï¼Œäººå½¢æœºå™¨äººè¿åŠ¨ä¼šå…¨æ˜¯é¬¼ç•œååœºé¢ï¼è¿™é”…ç²¥å¤§å®¶æ¥è¶ä¹±å–äº†å§ å›½å®¶çº§AIåˆ›æ–°åº”ç”¨èµ›äº‹æ€ç–¯äº†ï¼è¶…200ä¸‡å…ƒå¥–é‡‘æ± &#43;å…¨åœºæ™¯èµ›é“ï¼Œå†²çº¿å›¢é˜Ÿé€Ÿæ¥ è°·æ­Œç‰ˆå°é’¢ç‚®å¼€æºï¼0.27Bå¤§æ¨¡å‹ï¼Œ4ä¸ªæ³¨æ„åŠ›å¤´ï¼Œä¸“ä¸ºç»ˆç«¯è€Œç”Ÿ GPT-5è¶…è¶Šäººç±»åŒ»ç”Ÿï¼æ¨ç†èƒ½åŠ›æ¯”ä¸“å®¶é«˜å‡º24%ï¼Œç†è§£åŠ›å¼º29% é¦–ä¸ªå¼€æºå¤šæ¨¡æ€Deep Researchæ™ºèƒ½ä½“ï¼Œè¶…è¶Šå¤šä¸ªé—­æºæ–¹æ¡ˆ OpenAIåäººéœ²å¤´å°±è¢«å°æ‰æŒ–ï¼95ååŒ—å¤§æ ¡å‹1ä¸ªæœˆå‰ä¸Šç›´æ’­ï¼Œä»Šå¤©å·²æ˜¯Metaäºº å®æµ‹Perplexity Proå¹³æ›¿æ¨¡å‹ï¼Œå…è´¹å¼€æºä»…4B 1.1.2 æœºå™¨ä¹‹å¿ƒ ä¸€å¥è¯æå®šå¤šä»»åŠ¡å‡ºè¡Œï¼Œé«˜å¾·ç”¨ç©ºé—´æ™ºèƒ½é‡æ–°å®šä¹‰åœ°å›¾ GPT-5ã€Grok 4ã€o3 Proéƒ½é›¶åˆ†ï¼Œå²ä¸Šæœ€éš¾AIè¯„æµ‹åŸºå‡†æ¢å®ƒäº† è°·æ­Œå¼€æºGemma 3 270Mï¼Œæ€§èƒ½è¶…è¶ŠQwen 2.5åŒçº§æ¨¡å‹ è¿½å‰§ä¸æ–­ç½‘ï¼Œå¯èƒ½èƒŒåæœ‰ä¸ªAIåœ¨åŠ ç­ï¼Œæ•…éšœè¯Šæ–­å‡†åº¦ç ´91.79% Metaè§†è§‰åŸºåº§DINOv3ç‹è€…å½’æ¥ï¼šè‡ªç›‘ç£é¦–æ¬¡å…¨é¢è¶…è¶Šå¼±ç›‘ç£ï¼Œå•†ç”¨å¼€æº å¤šçªè§¦ç¥ç»å…ƒæ¨¡å‹é—®ä¸–ï¼Œå›½å†…å›¢é˜Ÿæ‰“é€ ç±»è„‘è®¡ç®—æ–°å¼•æ“ï¼Œç™»ä¸Šã€Šè‡ªç„¶Â·é€šè®¯ã€‹ æ‰å…‹ä¼¯æ ¼çœ‹OpenAIç›´æ’­æŒ–äººï¼ŒåŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…åŠ å…¥Meta AI æ¨¡ç‰¹æ—¶ä»£åˆ°æ¥ï¼šå­—èŠ‚xæ¸…åæ¨å‡ºå•†ç”¨çº§è§†é¢‘æ¢è£…æ¨¡å‹DreamVVTï¼Œä¿çœŸåº¦æ˜¾è‘—é¢†å…ˆSOTA 1.1.3 æ–°æ™ºå…ƒ æ ¸å¿ƒæ¨¡å‹è¢«æ›è’¸é¦DeepSeekï¼Ÿå‰å¥³å‹ä¸€çº¸æ§è¯‰ï¼Œæ›å‡ºæ¬§ç‰ˆOpenAIå¡Œæˆ¿çœŸç›¸ï¼ æ‰“å¼€é«˜å¾·çš„ç†ç”±åˆå¤šä¸€æ¡ï¼å…¨çƒé¦–ä¸ªã€Œéœ€æ±‚é“¾æ™ºèƒ½è°ƒåº¦ã€AIåœ°å›¾ä¸Šçº¿ åä¸‹17äº¿å›¾ç‰‡ï¼ŒMetaæœ€å¼ºå·¨å…½DINOv3å¼€æºï¼é‡æ–°å®šä¹‰CVå¤©èŠ±æ¿ AIæ­£åœ¨æç©ºå¤§è„‘ï¼Œæ€æƒ³æ²¦ä¸ºæ®‹åºŸï¼æœªæ¥åªåˆ†AIçš„ã€Œä¸»äººã€å’Œã€Œå¥´éš¶ã€ åŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…Cä½å‡ºé•œï¼Œå°æ‰çœ‹OpenAIç›´æ’­å¤ºäººï¼1äº¿åˆ€è–ªé…¬å…‰é€Ÿè¢«ç­¾ OpenAIæ³¢å…°åŒé›„ï¼šGPTä¸æ˜¯å¶ç„¶ï¼å†å¿†å¥¥ç‰¹æ›¼è¢«é€å½“å¤©å®å†µ Cohereèèµ„36äº¿ï¼ŒAMDè‹±ä¼Ÿè¾¾éƒ½æŠ•äº†ï¼å‰Metaç ”ç©¶å‰¯æ€»è£å‡ºä»»é¦–å¸­AIå®˜ 1.1.4 AGI Hunt Claude Code æ¨å‡ºå­¦ä¹ æ¨¡å¼ï¼Œæ¯”ChatGPTæ›´æ¿€è¿›ï¼šç”šè‡³èƒ½ç»™ä½ å¸ƒç½®ä½œä¸šâ€¦â€¦ GPT-5æ­£ä»¥o3çš„ä¸‰å€é€Ÿåº¦æ‰“å®å¯æ¢¦ï¼Œç°å·²æŠµè¾¾å† å†›ä¹‹è·¯ï¼Œç›´æ’­è¿›è¡Œä¸­ 1.1.5 å…¶ä»– Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models https://arxiv.org/abs/2508.09874 ğŸŒˆ Multi-Step Reasoning with Large Language Models, a Survey https://arxiv.org/abs/2407.11511 1.2 Arxiv 1.2.1 Computation and Language Fromï¼šhttps:// /arxiv/cs.CL">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="updates">
    <meta property="article:published_time" content="2025-08-15T00:00:00+08:00">
    <meta property="article:modified_time" content="2025-08-15T00:00:00+08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="2025-08-15ç§‘ç ”è¿½æ–°">
  <meta name="twitter:description" content="2025-08-15ç§‘ç ”è¿½æ–° 2025-08-14 19:39:40 Thursday ~ 2025-08-15 19:37:11 Friday
1. æºæ•°æ® 1.1 å…¬ä¼—å· 1.1.1 é‡å­ä½ æ··å…ƒ3Dä¸–ç•Œæ¨¡å‹1.0 liteç‰ˆæœ¬å‘å¸ƒï¼Œæ¶ˆè´¹çº§æ˜¾å¡å°±èƒ½è·‘ æ¨¡ä»¿äººç±»æ¨ç†ä¿®æ­£è¿‡ç¨‹ï¼Œé˜¶è·ƒæ˜Ÿè¾°æå‡ºå½¢å¼åŒ–è¯æ˜æ–°èŒƒå¼ | å¼€æº ç¬‘æ­»ï¼Œäººå½¢æœºå™¨äººè¿åŠ¨ä¼šå…¨æ˜¯é¬¼ç•œååœºé¢ï¼è¿™é”…ç²¥å¤§å®¶æ¥è¶ä¹±å–äº†å§ å›½å®¶çº§AIåˆ›æ–°åº”ç”¨èµ›äº‹æ€ç–¯äº†ï¼è¶…200ä¸‡å…ƒå¥–é‡‘æ± &#43;å…¨åœºæ™¯èµ›é“ï¼Œå†²çº¿å›¢é˜Ÿé€Ÿæ¥ è°·æ­Œç‰ˆå°é’¢ç‚®å¼€æºï¼0.27Bå¤§æ¨¡å‹ï¼Œ4ä¸ªæ³¨æ„åŠ›å¤´ï¼Œä¸“ä¸ºç»ˆç«¯è€Œç”Ÿ GPT-5è¶…è¶Šäººç±»åŒ»ç”Ÿï¼æ¨ç†èƒ½åŠ›æ¯”ä¸“å®¶é«˜å‡º24%ï¼Œç†è§£åŠ›å¼º29% é¦–ä¸ªå¼€æºå¤šæ¨¡æ€Deep Researchæ™ºèƒ½ä½“ï¼Œè¶…è¶Šå¤šä¸ªé—­æºæ–¹æ¡ˆ OpenAIåäººéœ²å¤´å°±è¢«å°æ‰æŒ–ï¼95ååŒ—å¤§æ ¡å‹1ä¸ªæœˆå‰ä¸Šç›´æ’­ï¼Œä»Šå¤©å·²æ˜¯Metaäºº å®æµ‹Perplexity Proå¹³æ›¿æ¨¡å‹ï¼Œå…è´¹å¼€æºä»…4B 1.1.2 æœºå™¨ä¹‹å¿ƒ ä¸€å¥è¯æå®šå¤šä»»åŠ¡å‡ºè¡Œï¼Œé«˜å¾·ç”¨ç©ºé—´æ™ºèƒ½é‡æ–°å®šä¹‰åœ°å›¾ GPT-5ã€Grok 4ã€o3 Proéƒ½é›¶åˆ†ï¼Œå²ä¸Šæœ€éš¾AIè¯„æµ‹åŸºå‡†æ¢å®ƒäº† è°·æ­Œå¼€æºGemma 3 270Mï¼Œæ€§èƒ½è¶…è¶ŠQwen 2.5åŒçº§æ¨¡å‹ è¿½å‰§ä¸æ–­ç½‘ï¼Œå¯èƒ½èƒŒåæœ‰ä¸ªAIåœ¨åŠ ç­ï¼Œæ•…éšœè¯Šæ–­å‡†åº¦ç ´91.79% Metaè§†è§‰åŸºåº§DINOv3ç‹è€…å½’æ¥ï¼šè‡ªç›‘ç£é¦–æ¬¡å…¨é¢è¶…è¶Šå¼±ç›‘ç£ï¼Œå•†ç”¨å¼€æº å¤šçªè§¦ç¥ç»å…ƒæ¨¡å‹é—®ä¸–ï¼Œå›½å†…å›¢é˜Ÿæ‰“é€ ç±»è„‘è®¡ç®—æ–°å¼•æ“ï¼Œç™»ä¸Šã€Šè‡ªç„¶Â·é€šè®¯ã€‹ æ‰å…‹ä¼¯æ ¼çœ‹OpenAIç›´æ’­æŒ–äººï¼ŒåŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…åŠ å…¥Meta AI æ¨¡ç‰¹æ—¶ä»£åˆ°æ¥ï¼šå­—èŠ‚xæ¸…åæ¨å‡ºå•†ç”¨çº§è§†é¢‘æ¢è£…æ¨¡å‹DreamVVTï¼Œä¿çœŸåº¦æ˜¾è‘—é¢†å…ˆSOTA 1.1.3 æ–°æ™ºå…ƒ æ ¸å¿ƒæ¨¡å‹è¢«æ›è’¸é¦DeepSeekï¼Ÿå‰å¥³å‹ä¸€çº¸æ§è¯‰ï¼Œæ›å‡ºæ¬§ç‰ˆOpenAIå¡Œæˆ¿çœŸç›¸ï¼ æ‰“å¼€é«˜å¾·çš„ç†ç”±åˆå¤šä¸€æ¡ï¼å…¨çƒé¦–ä¸ªã€Œéœ€æ±‚é“¾æ™ºèƒ½è°ƒåº¦ã€AIåœ°å›¾ä¸Šçº¿ åä¸‹17äº¿å›¾ç‰‡ï¼ŒMetaæœ€å¼ºå·¨å…½DINOv3å¼€æºï¼é‡æ–°å®šä¹‰CVå¤©èŠ±æ¿ AIæ­£åœ¨æç©ºå¤§è„‘ï¼Œæ€æƒ³æ²¦ä¸ºæ®‹åºŸï¼æœªæ¥åªåˆ†AIçš„ã€Œä¸»äººã€å’Œã€Œå¥´éš¶ã€ åŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…Cä½å‡ºé•œï¼Œå°æ‰çœ‹OpenAIç›´æ’­å¤ºäººï¼1äº¿åˆ€è–ªé…¬å…‰é€Ÿè¢«ç­¾ OpenAIæ³¢å…°åŒé›„ï¼šGPTä¸æ˜¯å¶ç„¶ï¼å†å¿†å¥¥ç‰¹æ›¼è¢«é€å½“å¤©å®å†µ Cohereèèµ„36äº¿ï¼ŒAMDè‹±ä¼Ÿè¾¾éƒ½æŠ•äº†ï¼å‰Metaç ”ç©¶å‰¯æ€»è£å‡ºä»»é¦–å¸­AIå®˜ 1.1.4 AGI Hunt Claude Code æ¨å‡ºå­¦ä¹ æ¨¡å¼ï¼Œæ¯”ChatGPTæ›´æ¿€è¿›ï¼šç”šè‡³èƒ½ç»™ä½ å¸ƒç½®ä½œä¸šâ€¦â€¦ GPT-5æ­£ä»¥o3çš„ä¸‰å€é€Ÿåº¦æ‰“å®å¯æ¢¦ï¼Œç°å·²æŠµè¾¾å† å†›ä¹‹è·¯ï¼Œç›´æ’­è¿›è¡Œä¸­ 1.1.5 å…¶ä»– Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models https://arxiv.org/abs/2508.09874 ğŸŒˆ Multi-Step Reasoning with Large Language Models, a Survey https://arxiv.org/abs/2407.11511 1.2 Arxiv 1.2.1 Computation and Language Fromï¼šhttps:// /arxiv/cs.CL">
<meta name="application-name" content="LLM-DailyDigest">
<meta name="apple-mobile-web-app-title" content="LLM-DailyDigest"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-08-15/" /><link rel="prev" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-08-14/" /><link rel="next" href="http://localhost:1313/LLMDailyDigestWeb/updates/2025-08-16/" /><link rel="stylesheet" href="/LLMDailyDigestWeb/css/style.min.css"><link rel="preload" href="/LLMDailyDigestWeb/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/LLMDailyDigestWeb/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "2025-08-15ç§‘ç ”è¿½æ–°",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "http:\/\/localhost:1313\/LLMDailyDigestWeb\/updates\/2025-08-15\/"
    },"genre": "updates","wordcount":  59409 ,
    "url": "http:\/\/localhost:1313\/LLMDailyDigestWeb\/updates\/2025-08-15\/","datePublished": "2025-08-15T00:00:00+08:00","dateModified": "2025-08-15T00:00:00+08:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "Author"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/LLMDailyDigestWeb/" title="LLM-DailyDigest"><img loading="lazy" src="/LLMDailyDigestWeb/fixit.svg" data-title="LLM-DailyDigest" data-alt="LLM-DailyDigest" class="logo" style="background: url(/LLMDailyDigestWeb/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-desktop" class="typeit"></span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/posts/llmdailydigest"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> è¯¦æƒ…</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/resources/"
                
                
              >èµ„æº</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/topic/"
                
                
              >ä¸»é¢˜</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/updates/"
                
                
              >æ—¥æŠ¥</a></li><li class="menu-item delimiter"></li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/LLMDailyDigestWeb/" title="LLM-DailyDigest"><img loading="lazy" src="/LLMDailyDigestWeb/fixit.svg" data-title="/LLMDailyDigestWeb/fixit.svg" data-alt="/LLMDailyDigestWeb/fixit.svg" class="logo" style="background: url(/LLMDailyDigestWeb/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-title-mobile" class="typeit"></span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/posts/llmdailydigest"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> è¯¦æƒ…</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/resources/"
                  
                  
                >èµ„æº</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/topic/"
                  
                  
                >ä¸»é¢˜</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/updates/"
                  
                  
                >æ—¥æŠ¥</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><main class="container"><aside class="toc" id="toc-auto"><h2 class="toc-title">Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom">
    </aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span>2025-08-15ç§‘ç ”è¿½æ–°</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      </span></span></div>
      <div class="post-meta-line"><span title="published on 2025-08-15 00:00:00"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden="true"></i><time datetime="2025-08-15">2025-08-15</time></span>&nbsp;<span title="Updated on 2025-08-15 00:00:00"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden="true"></i><time datetime="2025-08-15">2025-08-15</time></span>&nbsp;<span title="59409 words"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>About 59500 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>279 minutes</span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" data-kept="false">
        <div class="details-summary toc-title">
          <span>Contents</span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#1-a-survey-on-diffusion-language-models--1-å…³äºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç»¼è¿°"><a href="https://arxiv.org/abs/2508.10875">#1</a> <a href="https://papers.cool/arxiv/2508.10875">A Survey on Diffusion Language Models</a>  #1 å…³äºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç»¼è¿°</a></li>
    <li><a href="#2-ssrl-self-search-reinforcement-learning"><a href="https://arxiv.org/abs/2508.10874">#2</a> <a href="https://papers.cool/arxiv/2508.10874">SSRL: Self-Search Reinforcement Learning</a></a></li>
    <li><a href="#3-from-black-box-to-transparency-enhancing-automated-interpreting-assessment-with-explainable-ai-in-college-classrooms--3-ä»é»‘ç®±åˆ°é€æ˜åœ¨å¤§å­¦è¯¾å ‚ä¸­å€ŸåŠ©å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºè‡ªåŠ¨å£è¯‘è¯„ä¼°"><a href="https://arxiv.org/abs/2508.10860">#3</a> <a href="https://papers.cool/arxiv/2508.10860">From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms</a>  #3 ä»é»‘ç®±åˆ°é€æ˜ï¼šåœ¨å¤§å­¦è¯¾å ‚ä¸­å€ŸåŠ©å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºè‡ªåŠ¨å£è¯‘è¯„ä¼°</a></li>
    <li><a href="#4-psyche-r1-towards-reliable-psychological-llms-through-unified-empathy-expertise-and-reasoning--4-psyche-r1é€šè¿‡ç»Ÿä¸€çš„åŒç†å¿ƒä¸“ä¸šæ€§ä¸æ¨ç†è¿ˆå‘å¯é çš„å¿ƒç†å­¦-llms"><a href="https://arxiv.org/abs/2508.10848">#4</a> <a href="https://papers.cool/arxiv/2508.10848">Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning</a>  #4 Psyche-R1ï¼šé€šè¿‡ç»Ÿä¸€çš„åŒç†å¿ƒã€ä¸“ä¸šæ€§ä¸æ¨ç†ï¼Œè¿ˆå‘å¯é çš„å¿ƒç†å­¦ LLMs</a></li>
    <li><a href="#5-reinforced-language-models-for-sequential-decision-making--5-å¼ºåŒ–è¯­è¨€æ¨¡å‹ç”¨äºåºè´¯å†³ç­–åˆ¶å®š"><a href="https://arxiv.org/abs/2508.10839">#5</a> <a href="https://papers.cool/arxiv/2508.10839">Reinforced Language Models for Sequential Decision Making</a>  #5 å¼ºåŒ–è¯­è¨€æ¨¡å‹ç”¨äºåºè´¯å†³ç­–åˆ¶å®š</a></li>
    <li><a href="#6-beyond-34not-novel-enough34-enriching-scholarly-critique-with-llm-assisted-feedback--6-è¶…è¶Šåˆ›æ–°æ€§ä¸è¶³é€šè¿‡-llm-è¾…åŠ©åé¦ˆä¸°å¯Œå­¦æœ¯è¯„å®¡æ‰¹è¯„"><a href="https://arxiv.org/abs/2508.10795">#6</a> <a href="https://papers.cool/arxiv/2508.10795">Beyond &quot;Not Novel Enough&quot;: Enriching Scholarly Critique with LLM-Assisted Feedback</a>  #6 è¶…è¶Šâ€œåˆ›æ–°æ€§ä¸è¶³â€ï¼šé€šè¿‡ LLM è¾…åŠ©åé¦ˆä¸°å¯Œå­¦æœ¯è¯„å®¡æ‰¹è¯„</a></li>
    <li><a href="#7-thinking-inside-the-mask-in-place-prompting-in-diffusion-llms--7-æ€è€ƒåœ¨æ©ç ä¹‹å†…æ‰©æ•£-llm-ä¸­çš„åŸä½æç¤ºin-place-prompting"><a href="https://arxiv.org/abs/2508.10736">#7</a> <a href="https://papers.cool/arxiv/2508.10736">Thinking Inside the Mask: In-Place Prompting in Diffusion LLMs</a>  #7 æ€è€ƒåœ¨æ©ç ä¹‹å†…ï¼šæ‰©æ•£ LLM ä¸­çš„åŸä½æç¤ºï¼ˆIn-Place Promptingï¼‰</a></li>
    <li><a href="#8-learning-from-natural-language-feedback-for-personalized-question-answering--8-ä»è‡ªç„¶è¯­è¨€åé¦ˆä¸­å­¦ä¹ ä»¥å®ç°ä¸ªæ€§åŒ–é—®ç­”"><a href="https://arxiv.org/abs/2508.10695">#8</a> <a href="https://papers.cool/arxiv/2508.10695">Learning from Natural Language Feedback for Personalized Question Answering</a>  #8 ä»è‡ªç„¶è¯­è¨€åé¦ˆä¸­å­¦ä¹ ä»¥å®ç°ä¸ªæ€§åŒ–é—®ç­”</a></li>
    <li><a href="#9-continuous-bangla-sign-language-translation-mitigating-the-expense-of-gloss-annotation-with-the-assistance-of-graph--9-è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘åœ¨å›¾æ¨¡å‹è¾…åŠ©ä¸‹ç¼“è§£é€è¯æ³¨é‡Šçš„é«˜æ˜‚æˆæœ¬"><a href="https://arxiv.org/abs/2508.10687">#9</a> <a href="https://papers.cool/arxiv/2508.10687">Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph</a>  #9 è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘ï¼šåœ¨å›¾æ¨¡å‹è¾…åŠ©ä¸‹ç¼“è§£é€è¯æ³¨é‡Šçš„é«˜æ˜‚æˆæœ¬</a></li>
    <li><a href="#10-neural-machine-translation-for-coptic-french-strategies-for-low-resource-ancient-languages--10-ç§‘æ™®ç‰¹è¯­æ³•è¯­ç¥ç»æœºå™¨ç¿»è¯‘é’ˆå¯¹èµ„æºç¨€ç¼ºå¤ä»£è¯­è¨€çš„ç­–ç•¥"><a href="https://arxiv.org/abs/2508.10683">#10</a> <a href="https://papers.cool/arxiv/2508.10683">Neural Machine Translation for Coptic-French: Strategies for Low-Resource Ancient Languages</a>  #10 ç§‘æ™®ç‰¹è¯­â€”æ³•è¯­ç¥ç»æœºå™¨ç¿»è¯‘ï¼šé’ˆå¯¹èµ„æºç¨€ç¼ºå¤ä»£è¯­è¨€çš„ç­–ç•¥</a></li>
    <li><a href="#11-edif-a-european-deep-inference-fabric-for-remote-interpretability-of-llm"><a href="https://arxiv.org/abs/2508.10553">#11</a> <a href="https://papers.cool/arxiv/2508.10553">eDIF: A European Deep Inference Fabric for Remote Interpretability of LLM</a></a></li>
    <li><a href="#12-when-language-overrules-revealing-text-dominance-in-multimodal-large-language-models--12-å½“è¯­è¨€å ä¸Šé£æ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡æœ¬ä¸»å¯¼æ€§"><a href="https://arxiv.org/abs/2508.10552">#12</a> <a href="https://papers.cool/arxiv/2508.10552">When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models</a>  #12 å½“è¯­è¨€å ä¸Šé£ï¼šæ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡æœ¬ä¸»å¯¼æ€§</a></li>
    <li><a href="#13-when-explainability-meets-privacy-an-investigation-at-the-intersection-of-post-hoc-explainability-and-differential-privacy-in-the-context-of-natural-language-processing--13-å¯è§£é‡Šæ€§é‡ä¸Šéšç§åœ¨è‡ªç„¶è¯­è¨€å¤„ç†èƒŒæ™¯ä¸‹å¯¹äº‹åå¯è§£é‡Šæ€§ä¸å·®åˆ†éšç§äº¤æ±‡å¤„çš„æ¢ç©¶"><a href="https://arxiv.org/abs/2508.10482">#13</a> <a href="https://papers.cool/arxiv/2508.10482">When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing</a>  #13 å¯è§£é‡Šæ€§é‡ä¸Šéšç§ï¼šåœ¨è‡ªç„¶è¯­è¨€å¤„ç†èƒŒæ™¯ä¸‹å¯¹äº‹åå¯è§£é‡Šæ€§ä¸å·®åˆ†éšç§äº¤æ±‡å¤„çš„æ¢ç©¶</a></li>
    <li><a href="#14-difar-enhancing-multimodal-misinformation-detection-with-diverse-factual-and-relevant-rationales--14-difaré€šè¿‡å¤šæ ·äº‹å®æ€§å’Œç›¸å…³æ€§ç†ç”±æå‡å¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10444">#14</a> <a href="https://papers.cool/arxiv/2508.10444">DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales</a>  #14 DiFaRï¼šé€šè¿‡å¤šæ ·ã€äº‹å®æ€§å’Œç›¸å…³æ€§ç†ç”±æå‡å¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹</a></li>
    <li><a href="#15-computational-economics-in-large-language-models-exploring-model-behavior-and-incentive-design-under-resource-constraints--15-åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è®¡ç®—ç»æµå­¦åœ¨èµ„æºçº¦æŸä¸‹æ¢ç´¢æ¨¡å‹è¡Œä¸ºä¸æ¿€åŠ±è®¾è®¡"><a href="https://arxiv.org/abs/2508.10426">#15</a> <a href="https://papers.cool/arxiv/2508.10426">Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints</a>  #15 åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è®¡ç®—ç»æµå­¦ï¼šåœ¨èµ„æºçº¦æŸä¸‹æ¢ç´¢æ¨¡å‹è¡Œä¸ºä¸æ¿€åŠ±è®¾è®¡</a></li>
    <li><a href="#16-evaluating-llms-on-chinese-idiom-translation--16-åœ¨æ±‰è¯­æˆè¯­ç¿»è¯‘ä¸Šè¯„ä¼°-llms"><a href="https://arxiv.org/abs/2508.10421">#16</a> <a href="https://papers.cool/arxiv/2508.10421">Evaluating LLMs on Chinese Idiom Translation</a>  #16 åœ¨æ±‰è¯­æˆè¯­ç¿»è¯‘ä¸Šè¯„ä¼° LLMs</a></li>
    <li><a href="#17-comorag-a-cognitive-inspired-memory-organized-rag-for-stateful-long-narrative-reasoning--17-comoragä¸€ç§å—è®¤çŸ¥å¯å‘çš„è®°å¿†ç»„ç»‡-ragç”¨äºæœ‰çŠ¶æ€çš„é•¿ç¯‡å™äº‹æ¨ç†"><a href="https://arxiv.org/abs/2508.10419">#17</a> <a href="https://papers.cool/arxiv/2508.10419">ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning</a>  #17 ComoRAGï¼šä¸€ç§å—è®¤çŸ¥å¯å‘çš„è®°å¿†ç»„ç»‡ RAGï¼Œç”¨äºæœ‰çŠ¶æ€çš„é•¿ç¯‡å™äº‹æ¨ç†</a></li>
    <li><a href="#18-layer-wise-perturbations-via-sparse-autoencoders-for-adversarial-text-generation--18-é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œé€å±‚æ‰°åŠ¨ä»¥ç”Ÿæˆå¯¹æŠ—æ–‡æœ¬"><a href="https://arxiv.org/abs/2508.10404">#18</a> <a href="https://papers.cool/arxiv/2508.10404">Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation</a>  #18 é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œé€å±‚æ‰°åŠ¨ä»¥ç”Ÿæˆå¯¹æŠ—æ–‡æœ¬</a></li>
    <li><a href="#19-jailbreaking-commercial-black-box-llms-with-explicitly-harmful-prompts--19-ä½¿ç”¨æ˜ç¡®æœ‰å®³æç¤ºå¯¹å•†ä¸šé»‘ç›’-llms-è¿›è¡Œè¶Šç‹±"><a href="https://arxiv.org/abs/2508.10390">#19</a> <a href="https://papers.cool/arxiv/2508.10390">Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts</a>  #19 ä½¿ç”¨æ˜ç¡®æœ‰å®³æç¤ºå¯¹å•†ä¸šé»‘ç›’ LLMs è¿›è¡Œè¶Šç‹±</a></li>
    <li><a href="#20-improving-generative-cross-lingual-aspect-based-sentiment-analysis-with-constrained-decoding--20-ä½¿ç”¨å—é™è§£ç æ”¹è¿›ç”Ÿæˆå¼è·¨è¯­è¨€åŸºäºæ–¹é¢çš„æƒ…æ„Ÿåˆ†æ"><a href="https://arxiv.org/abs/2508.10369">#20</a> <a href="https://papers.cool/arxiv/2508.10369">Improving Generative Cross-lingual Aspect-Based Sentiment Analysis with Constrained Decoding</a>  #20 ä½¿ç”¨å—é™è§£ç æ”¹è¿›ç”Ÿæˆå¼è·¨è¯­è¨€åŸºäºæ–¹é¢çš„æƒ…æ„Ÿåˆ†æ</a></li>
    <li><a href="#21-large-language-models-for-summarizing-czech-historical-documents-and-beyond--21-ç”¨äºæ€»ç»“æ·å…‹å†å²æ–‡çŒ®åŠå…¶å®ƒå†…å®¹çš„å¤§å‹è¯­è¨€æ¨¡å‹"><a href="https://arxiv.org/abs/2508.10368">#21</a> <a href="https://papers.cool/arxiv/2508.10368">Large Language Models for Summarizing Czech Historical Documents and Beyond</a>  #21 ç”¨äºæ€»ç»“æ·å…‹å†å²æ–‡çŒ®åŠå…¶å®ƒå†…å®¹çš„å¤§å‹è¯­è¨€æ¨¡å‹</a></li>
    <li><a href="#22-advancing-cross-lingual-aspect-based-sentiment-analysis-with-llms-and-constrained-decoding-for-sequence-to-sequence-models--22-ä½¿ç”¨-llms-å’Œå¯¹åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„çº¦æŸè§£ç æ¨è¿›è·¨è¯­è¨€ç»†ç²’åº¦æƒ…æ„Ÿåˆ†æ-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10366">#22</a> <a href="https://papers.cool/arxiv/2508.10366">Advancing Cross-lingual Aspect-Based Sentiment Analysis with LLMs and Constrained Decoding for Sequence-to-Sequence Models</a>  #22 ä½¿ç”¨ LLMs å’Œå¯¹åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„çº¦æŸè§£ç æ¨è¿›è·¨è¯­è¨€ç»†ç²’åº¦æƒ…æ„Ÿåˆ†æ [PDF ] [Copy] [Kimi ] [REL]</a></li>
    <li><a href="#23-making-qwen3-think-in-korean-with-reinforcement-learning--23-ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®©-qwen3-ç”¨éŸ©è¯­æ€è€ƒ"><a href="https://arxiv.org/abs/2508.10355">#23</a> <a href="https://papers.cool/arxiv/2508.10355">Making Qwen3 Think in Korean with Reinforcement Learning</a>  #23 ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®© Qwen3 ç”¨éŸ©è¯­æ€è€ƒ</a></li>
    <li><a href="#24-cross-prompt-encoder-for-low-performing-languages--24-è·¨æç¤ºç¼–ç å™¨ç”¨äºè¡¨ç°æ¬ ä½³çš„è¯­è¨€"><a href="https://arxiv.org/abs/2508.10352">#24</a> <a href="https://papers.cool/arxiv/2508.10352">Cross-Prompt Encoder for Low-Performing Languages</a>  #24 è·¨æç¤ºç¼–ç å™¨ç”¨äºè¡¨ç°æ¬ ä½³çš„è¯­è¨€</a></li>
    <li><a href="#25-beyond-semantic-understanding-preserving-collaborative-frequency-components-in-llm-based-recommendation--25-è¶…è¶Šè¯­ä¹‰ç†è§£åœ¨åŸºäº-llm-çš„æ¨èä¸­ä¿ç•™ååŒé¢‘ç‡åˆ†é‡"><a href="https://arxiv.org/abs/2508.10312">#25</a> <a href="https://papers.cool/arxiv/2508.10312">Beyond Semantic Understanding: Preserving Collaborative Frequency Components in LLM-based Recommendation</a>  #25 è¶…è¶Šè¯­ä¹‰ç†è§£ï¼šåœ¨åŸºäº LLM çš„æ¨èä¸­ä¿ç•™ååŒé¢‘ç‡åˆ†é‡</a></li>
    <li><a href="#26-from-surface-to-semantics-semantic-structure-parsing-for-table-centric-document-analysis--26-ä»è¡¨é¢åˆ°è¯­ä¹‰é¢å‘è¡¨æ ¼çš„æ–‡æ¡£åˆ†æçš„è¯­ä¹‰ç»“æ„è§£æ"><a href="https://arxiv.org/abs/2508.10311">#26</a> <a href="https://papers.cool/arxiv/2508.10311">From Surface to Semantics: Semantic Structure Parsing for Table-Centric Document Analysis</a>  #26 ä»è¡¨é¢åˆ°è¯­ä¹‰ï¼šé¢å‘è¡¨æ ¼çš„æ–‡æ¡£åˆ†æçš„è¯­ä¹‰ç»“æ„è§£æ</a></li>
    <li><a href="#27-reviewrl-towards-automated-scientific-review-with-rl--27-reviewrlè¿ˆå‘åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç§‘å­¦å®¡ç¨¿"><a href="https://arxiv.org/abs/2508.10308">#27</a> <a href="https://papers.cool/arxiv/2508.10308">ReviewRL: Towards Automated Scientific Review with RL</a>  #27 ReviewRLï¼šè¿ˆå‘åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç§‘å­¦å®¡ç¨¿</a></li>
    <li><a href="#28-yet-another-algorithmic-bias-a-discursive-analysis-of-large-language-models-reinforcing-dominant-discourses-on-gender-and-race--28-åˆä¸€ç§ç®—æ³•åè§å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ€§åˆ«ä¸ç§æ—è¯è¯­ä¸Šå¼ºåŒ–ä¸»å¯¼è¯è¯­çš„è®ºè¿°åˆ†æ"><a href="https://arxiv.org/abs/2508.10304">#28</a> <a href="https://papers.cool/arxiv/2508.10304">Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race</a>  #28 åˆä¸€ç§ç®—æ³•åè§ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ€§åˆ«ä¸ç§æ—è¯è¯­ä¸Šå¼ºåŒ–ä¸»å¯¼è¯è¯­çš„è®ºè¿°åˆ†æ</a></li>
    <li><a href="#29-inductive-bias-extraction-and-matching-for-llm-prompts--29-å½’çº³åç½®æå–ä¸åŒ¹é…ç”¨äº-llm-æç¤º"><a href="https://arxiv.org/abs/2508.10295">#29</a> <a href="https://papers.cool/arxiv/2508.10295">Inductive Bias Extraction and Matching for LLM Prompts</a>  #29 å½’çº³åç½®æå–ä¸åŒ¹é…ç”¨äº LLM æç¤º</a></li>
    <li><a href="#30-a-computational-approach-to-analyzing-language-change-and-variation-in-the-constructed-language-toki-pona--30-ä¸€ç§ç”¨äºåˆ†ææ„é€ è¯­è¨€-toki-pona-ä¸­è¯­è¨€å˜åŒ–ä¸å˜å¼‚çš„è®¡ç®—æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10246">#30</a> <a href="https://papers.cool/arxiv/2508.10246">A Computational Approach to Analyzing Language Change and Variation in the Constructed Language Toki Pona</a>  #30 ä¸€ç§ç”¨äºåˆ†ææ„é€ è¯­è¨€ Toki Pona ä¸­è¯­è¨€å˜åŒ–ä¸å˜å¼‚çš„è®¡ç®—æ–¹æ³•</a></li>
    <li><a href="#31-using-large-language-models-to-measure-symptom-severity-in-patients-at-risk-for-schizophrenia--31-ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æœ‰ç²¾ç¥åˆ†è£‚ç—‡é£é™©æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦"><a href="https://arxiv.org/abs/2508.10226">#31</a> <a href="https://papers.cool/arxiv/2508.10226">Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia</a>  #31 ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æœ‰ç²¾ç¥åˆ†è£‚ç—‡é£é™©æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦</a></li>
    <li><a href="#32-understanding-textual-emotion-through-emoji-prediction--32-é€šè¿‡è¡¨æƒ…ç¬¦å·é¢„æµ‹ç†è§£æ–‡æœ¬æƒ…æ„Ÿ"><a href="https://arxiv.org/abs/2508.10222">#32</a> <a href="https://papers.cool/arxiv/2508.10222">Understanding Textual Emotion Through Emoji Prediction</a>  #32 é€šè¿‡è¡¨æƒ…ç¬¦å·é¢„æµ‹ç†è§£æ–‡æœ¬æƒ…æ„Ÿ</a></li>
    <li><a href="#33-prompt-response-semantic-divergence-metrics-for-faithfulness-hallucination-and-misalignment-detection-in-large-language-models--33-ç”¨äºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ£€æµ‹å¿ å®æ€§å¹»è§‰å’Œä¸å¯¹é½çš„æç¤º-å“åº”è¯­ä¹‰åå·®åº¦é‡-pdf--copy-kimi-1--rel"><a href="https://arxiv.org/abs/2508.10192">#33</a> <a href="https://papers.cool/arxiv/2508.10192">Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models</a>  #33 ç”¨äºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ£€æµ‹å¿ å®æ€§å¹»è§‰å’Œä¸å¯¹é½çš„æç¤º-å“åº”è¯­ä¹‰åå·®åº¦é‡ [PDF ] [Copy] [Kimi 1 ] [REL]</a></li>
    <li><a href="#34-pakbbq-a-culturally-adapted-bias-benchmark-for-qa--34-pakbbqä¸€ä¸ªé’ˆå¯¹é—®ç­”çš„æ–‡åŒ–é€‚é…åè§åŸºå‡†"><a href="https://arxiv.org/abs/2508.10186">#34</a> <a href="https://papers.cool/arxiv/2508.10186">PakBBQ: A Culturally Adapted Bias Benchmark for QA</a>  #34 PakBBQï¼šä¸€ä¸ªé’ˆå¯¹é—®ç­”çš„æ–‡åŒ–é€‚é…åè§åŸºå‡†</a></li>
    <li><a href="#35-efficient-forward-only-data-valuation-for-pretrained-llms-and-vlms--35-é¢å‘é¢„è®­ç»ƒ-llms-å’Œ-vlms-çš„é«˜æ•ˆä»…å‰å‘æ•°æ®ä¼°å€¼"><a href="https://arxiv.org/abs/2508.10180">#35</a> <a href="https://papers.cool/arxiv/2508.10180">Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs</a>  #35 é¢å‘é¢„è®­ç»ƒ LLMs å’Œ VLMs çš„é«˜æ•ˆä»…å‰å‘æ•°æ®ä¼°å€¼</a></li>
    <li><a href="#36-estimating-machine-translation-difficulty--36-ä¼°è®¡æœºå™¨ç¿»è¯‘éš¾åº¦"><a href="https://arxiv.org/abs/2508.10175">#36</a> <a href="https://papers.cool/arxiv/2508.10175">Estimating Machine Translation Difficulty</a>  #36 ä¼°è®¡æœºå™¨ç¿»è¯‘éš¾åº¦</a></li>
    <li><a href="#37-laajmeter-a-framework-for-laaj-evaluation--37-laajmeterç”¨äº-laaj-è¯„ä¼°çš„æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10161">#37</a> <a href="https://papers.cool/arxiv/2508.10161">LaajMeter: A Framework for LaaJ Evaluation</a>  #37 LaajMeterï¼šç”¨äº LaaJ è¯„ä¼°çš„æ¡†æ¶</a></li>
    <li><a href="#38-multi-turn-puzzles-evaluating-interactive-reasoning-and-strategic-dialogue-in-llms--38-å¤šå›åˆè°œé¢˜è¯„ä¼°-llms-ä¸­çš„äº¤äº’å¼æ¨ç†ä¸ç­–ç•¥æ€§å¯¹è¯"><a href="https://arxiv.org/abs/2508.10142">#38</a> <a href="https://papers.cool/arxiv/2508.10142">Multi-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs</a>  #38 å¤šå›åˆè°œé¢˜ï¼šè¯„ä¼° LLMs ä¸­çš„äº¤äº’å¼æ¨ç†ä¸ç­–ç•¥æ€§å¯¹è¯</a></li>
    <li><a href="#39-mscore-a-multilingual-and-scalable-benchmark-for-skill-based-commonsense-reasoning--39mscoreä¸€ä¸ª-m-å¤šè¯­ä¸”å¯æ‰©å±•çš„åŸºå‡†ç”¨äº-s-åŸºäºæŠ€èƒ½çš„-co-æ— æ„ä¹‰-re-æ¨ç†"><a href="https://arxiv.org/abs/2508.10137">#39</a> <a href="https://papers.cool/arxiv/2508.10137">mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning</a>  #39mSCoReï¼šä¸€ä¸ª M å¤šè¯­ä¸”å¯æ‰©å±•çš„åŸºå‡†ï¼Œç”¨äº S åŸºäºæŠ€èƒ½çš„ Co æ— æ„ä¹‰ Re æ¨ç†</a></li>
    <li><a href="#40-reflect-then-learn-active-prompting-for-information-extraction-guided-by-introspective-confusion"><a href="https://arxiv.org/abs/2508.10036">#40</a> <a href="https://papers.cool/arxiv/2508.10036">Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion</a></a></li>
    <li><a href="#41-the-cost-of-thinking-increased-jailbreak-risk-in-large-language-models--41-æ€è€ƒçš„ä»£ä»·å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¢åŠ çš„è¶Šç‹±é£é™©"><a href="https://arxiv.org/abs/2508.10032">#41</a> <a href="https://papers.cool/arxiv/2508.10032">The Cost of Thinking: Increased Jailbreak Risk in Large Language Models</a>  #41 æ€è€ƒçš„ä»£ä»·ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¢åŠ çš„è¶Šç‹±é£é™©</a></li>
    <li><a href="#42-inference-aware-prompt-optimization-for-aligning-black-box-large-language-models--42-é¢å‘æ¨ç†çš„æç¤ºä¼˜åŒ–ç”¨äºå¯¹é½é»‘ç®±å¤§å‹è¯­è¨€æ¨¡å‹"><a href="https://arxiv.org/abs/2508.10030">#42</a> <a href="https://papers.cool/arxiv/2508.10030">Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models</a>  #42 é¢å‘æ¨ç†çš„æç¤ºä¼˜åŒ–ç”¨äºå¯¹é½é»‘ç®±å¤§å‹è¯­è¨€æ¨¡å‹</a></li>
    <li><a href="#43-latent-fusion-jailbreak-blending-harmful-and-harmless-representations-to-elicit-unsafe-llm-outputs--43-æ½œåœ¨èåˆè¶Šç‹±æ··åˆæœ‰å®³ä¸æ— å®³è¡¨ç¤ºä»¥è¯±å‘ä¸å®‰å…¨çš„-llm-è¾“å‡º"><a href="https://arxiv.org/abs/2508.10029">#43</a> <a href="https://papers.cool/arxiv/2508.10029">Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs</a>  #43 æ½œåœ¨èåˆè¶Šç‹±ï¼šæ··åˆæœ‰å®³ä¸æ— å®³è¡¨ç¤ºä»¥è¯±å‘ä¸å®‰å…¨çš„ LLM è¾“å‡º</a></li>
    <li><a href="#44-pref-reference-free-evaluation-of-personalised-text-generation-in-llms--44-é¦–é€‰é¡¹åœ¨-llms-ä¸­å¯¹ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆçš„æ— å‚è€ƒè¯„ä¼°"><a href="https://arxiv.org/abs/2508.10028">#44</a> <a href="https://papers.cool/arxiv/2508.10028">PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs</a>  #44 é¦–é€‰é¡¹ï¼šåœ¨ LLMs ä¸­å¯¹ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆçš„æ— å‚è€ƒè¯„ä¼°</a></li>
    <li><a href="#45-llmcare-alzheimer39s-detection-via-transformer-models-enhanced-by-llm-generated-synthetic-data--45-llmcareé€šè¿‡ç”±-llm-ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºçš„-transformer-æ¨¡å‹è¿›è¡Œé˜¿å°”èŒ¨æµ·é»˜ç—‡æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10027">#45</a> <a href="https://papers.cool/arxiv/2508.10027">LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data</a>  #45 LLMCAREï¼šé€šè¿‡ç”± LLM ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºçš„ Transformer æ¨¡å‹è¿›è¡Œé˜¿å°”èŒ¨æµ·é»˜ç—‡æ£€æµ‹</a></li>
    <li><a href="#46-saber-switchable-and-balanced-training-for-efficient-llm-reasoning--46-saber-å¯åˆ‡æ¢ä¸å¹³è¡¡è®­ç»ƒä»¥å®ç°é«˜æ•ˆ-llm-æ¨ç†-pdf-5--copy-kimi-2--rel"><a href="https://arxiv.org/abs/2508.10026">#46</a> <a href="https://papers.cool/arxiv/2508.10026">SABER: Switchable and Balanced Training for Efficient LLM Reasoning</a>  #46 SABER: å¯åˆ‡æ¢ä¸å¹³è¡¡è®­ç»ƒä»¥å®ç°é«˜æ•ˆ LLM æ¨ç† [PDF 5 ] [Copy] [Kimi 2 ] [REL]</a></li>
    <li><a href="#47-detecting-and-explaining-postpartum-depression-in-real-time-with-generative-artificial-intelligence--47-ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®æ—¶æ£€æµ‹å¹¶è§£é‡Šäº§åæŠ‘éƒç—‡"><a href="https://arxiv.org/abs/2508.10025">#47</a> <a href="https://papers.cool/arxiv/2508.10025">Detecting and explaining postpartum depression in real-time with generative artificial intelligence</a>  #47 ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®æ—¶æ£€æµ‹å¹¶è§£é‡Šäº§åæŠ‘éƒç—‡</a></li>
    <li><a href="#48-rttc-reward-guided-collaborative-test-time-compute--48-rttcåŸºäºå¥–åŠ±å¼•å¯¼çš„åä½œæµ‹è¯•æ—¶è®¡ç®—"><a href="https://arxiv.org/abs/2508.10024">#48</a> <a href="https://papers.cool/arxiv/2508.10024">RTTC: Reward-Guided Collaborative Test-Time Compute</a>  #48 RTTCï¼šåŸºäºå¥–åŠ±å¼•å¯¼çš„åä½œæµ‹è¯•æ—¶è®¡ç®—</a></li>
    <li><a href="#49-conformal-p-value-in-multiple-choice-question-answering-tasks-with-provable-risk-control--49-åœ¨å¸¦æœ‰å¯è¯æ˜é£é™©æ§åˆ¶çš„å¤šé¡¹é€‰æ‹©é¢˜å›ç­”ä»»åŠ¡ä¸­çš„ç¬¦åˆæ€§-p-å€¼"><a href="https://arxiv.org/abs/2508.10022">#49</a> <a href="https://papers.cool/arxiv/2508.10022">Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control</a>  #49 åœ¨å¸¦æœ‰å¯è¯æ˜é£é™©æ§åˆ¶çš„å¤šé¡¹é€‰æ‹©é¢˜å›ç­”ä»»åŠ¡ä¸­çš„ç¬¦åˆæ€§ P å€¼</a></li>
    <li><a href="#50-latte-learning-aligned-transactions-and-textual-embeddings-for-bank-clients--50-latteä¸ºé“¶è¡Œå®¢æˆ·å­¦ä¹ å¯¹é½çš„äº¤æ˜“å’Œæ–‡æœ¬åµŒå…¥"><a href="https://arxiv.org/abs/2508.10021">#50</a> <a href="https://papers.cool/arxiv/2508.10021">LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients</a>  #50 LATTEï¼šä¸ºé“¶è¡Œå®¢æˆ·å­¦ä¹ å¯¹é½çš„äº¤æ˜“å’Œæ–‡æœ¬åµŒå…¥</a></li>
    <li><a href="#51-fedcot-communication-efficient-federated-reasoning-enhancement-for-large-language-models--51-fedcoté¢å‘å¤§è¯­è¨€æ¨¡å‹çš„é€šä¿¡é«˜æ•ˆè”é‚¦æ¨ç†å¢å¼º"><a href="https://arxiv.org/abs/2508.10020">#51</a> <a href="https://papers.cool/arxiv/2508.10020">FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models</a>  #51 FedCoTï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„é€šä¿¡é«˜æ•ˆè”é‚¦æ¨ç†å¢å¼º</a></li>
    <li><a href="#52-decoupling-understanding-from-reasoning-via-problem-space-mapping-for-small-scale-model-reasoning--52-é€šè¿‡é—®é¢˜ç©ºé—´æ˜ å°„å°†ç†è§£ä¸æ¨ç†è§£è€¦ä»¥ç”¨äºå°è§„æ¨¡æ¨¡å‹æ¨ç†"><a href="https://arxiv.org/abs/2508.10019">#52</a> <a href="https://papers.cool/arxiv/2508.10019">Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning</a>  #52 é€šè¿‡é—®é¢˜ç©ºé—´æ˜ å°„å°†ç†è§£ä¸æ¨ç†è§£è€¦ä»¥ç”¨äºå°è§„æ¨¡æ¨¡å‹æ¨ç†</a></li>
    <li><a href="#53-a-rose-by-any-other-name-would-smell-as-sweet-categorical-homotopy-theory-for-large-language-models--53-åå­—ä¸åŒç«ç‘°ä¾æ—§èŠ¬èŠ³é¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„èŒƒç•´åŒä¼¦è®º"><a href="https://arxiv.org/abs/2508.10018">#53</a> <a href="https://papers.cool/arxiv/2508.10018">A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models</a>  #53 åå­—ä¸åŒç«ç‘°ä¾æ—§èŠ¬èŠ³ï¼šé¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„èŒƒç•´åŒä¼¦è®º</a></li>
    <li><a href="#54-training-free-multimodal-large-language-model-orchestration--54-æ— éœ€è®­ç»ƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç¼–æ’"><a href="https://arxiv.org/abs/2508.10016">#54</a> <a href="https://papers.cool/arxiv/2508.10016">Training-Free Multimodal Large Language Model Orchestration</a>  #54 æ— éœ€è®­ç»ƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç¼–æ’</a></li>
    <li><a href="#55-realtalk-cn-a-realistic-chinese-speech-text-dialogue-benchmark-with-cross-modal-interaction-analysis--55-realtalk-cnä¸€ä¸ªå¸¦æœ‰è·¨æ¨¡æ€äº¤äº’åˆ†æçš„çœŸå®ä¸­æ–‡è¯­éŸ³-æ–‡æœ¬å¯¹è¯åŸºå‡†"><a href="https://arxiv.org/abs/2508.10015">#55</a> <a href="https://papers.cool/arxiv/2508.10015">RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal Interaction Analysis</a>  #55 RealTalk-CNï¼šä¸€ä¸ªå¸¦æœ‰è·¨æ¨¡æ€äº¤äº’åˆ†æçš„çœŸå®ä¸­æ–‡è¯­éŸ³-æ–‡æœ¬å¯¹è¯åŸºå‡†</a></li>
    <li><a href="#56-personaeval-are-llm-evaluators-human-enough-to-judge-role-play--56-personaevalllm-è¯„ä¼°è€…åœ¨åˆ¤æ–­è§’è‰²æ‰®æ¼”æ—¶è¶³å¤Ÿåƒäººç±»å—"><a href="https://arxiv.org/abs/2508.10014">#56</a> <a href="https://papers.cool/arxiv/2508.10014">PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?</a>  #56 PersonaEvalï¼šLLM è¯„ä¼°è€…åœ¨åˆ¤æ–­è§’è‰²æ‰®æ¼”æ—¶è¶³å¤Ÿåƒäººç±»å—ï¼Ÿ</a></li>
    <li><a href="#57-semantic-bridge-universal-multi-hop-question-generation-via-amr-driven-graph-synthesis--57-è¯­ä¹‰æ¡¥æ¢é€šè¿‡åŸºäº-amr-çš„å›¾åˆæˆå®ç°é€šç”¨å¤šè·³é—®é¢˜ç”Ÿæˆ-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10013">#57</a> <a href="https://papers.cool/arxiv/2508.10013">Semantic Bridge: Universal Multi-Hop Question Generation via AMR-Driven Graph Synthesis</a>  #57 è¯­ä¹‰æ¡¥æ¢ï¼šé€šè¿‡åŸºäº AMR çš„å›¾åˆæˆå®ç°é€šç”¨å¤šè·³é—®é¢˜ç”Ÿæˆ [PDF ] [Copy] [Kimi ] [REL]</a></li>
    <li><a href="#58-guided-navigation-in-knowledge-dense-environments-structured-semantic-exploration-with-guidance-graphs--58-åœ¨çŸ¥è¯†å¯†é›†å‹ç¯å¢ƒä¸­çš„å¼•å¯¼å¼å¯¼èˆªå¸¦æœ‰å¼•å¯¼å›¾çš„ç»“æ„åŒ–è¯­ä¹‰æ¢ç´¢"><a href="https://arxiv.org/abs/2508.10012">#58</a> <a href="https://papers.cool/arxiv/2508.10012">Guided Navigation in Knowledge-Dense Environments: Structured Semantic Exploration with Guidance Graphs</a>  #58 åœ¨çŸ¥è¯†å¯†é›†å‹ç¯å¢ƒä¸­çš„å¼•å¯¼å¼å¯¼èˆªï¼šå¸¦æœ‰å¼•å¯¼å›¾çš„ç»“æ„åŒ–è¯­ä¹‰æ¢ç´¢</a></li>
    <li><a href="#59-evaluation-of-gpt-based-large-language-generative-ai-models-as-study-aids-for-the-national-licensure-examination-for-registered-dietitians-in-japan--59-å°†åŸºäº-gpt-çš„å¤§å‹è¯­è¨€ç”Ÿæˆå‹äººå·¥æ™ºèƒ½æ¨¡å‹ä½œä¸ºæ—¥æœ¬æ³¨å†Œè¥å…»å¸ˆå›½å®¶æ‰§ç…§è€ƒè¯•å­¦ä¹ è¾…åŠ©å·¥å…·çš„è¯„ä¼°"><a href="https://arxiv.org/abs/2508.10011">#59</a> <a href="https://papers.cool/arxiv/2508.10011">Evaluation of GPT-based large language generative AI models as study aids for the national licensure examination for registered dietitians in Japan</a>  #59 å°†åŸºäº GPT çš„å¤§å‹è¯­è¨€ç”Ÿæˆå‹äººå·¥æ™ºèƒ½æ¨¡å‹ä½œä¸ºæ—¥æœ¬æ³¨å†Œè¥å…»å¸ˆå›½å®¶æ‰§ç…§è€ƒè¯•å­¦ä¹ è¾…åŠ©å·¥å…·çš„è¯„ä¼°</a></li>
    <li><a href="#60-an-audit-and-analysis-of-llm-assisted-health-misinformation-jailbreaks-against-llms--60-åŸºäº-llm-è¾…åŠ©çš„é’ˆå¯¹-llm-çš„å¥åº·é”™è¯¯ä¿¡æ¯è¶Šç‹±æ”»å‡»çš„å®¡è®¡ä¸åˆ†æ"><a href="https://arxiv.org/abs/2508.10010">#60</a> <a href="https://papers.cool/arxiv/2508.10010">An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs</a>  #60 åŸºäº LLM è¾…åŠ©çš„é’ˆå¯¹ LLM çš„å¥åº·é”™è¯¯ä¿¡æ¯è¶Šç‹±æ”»å‡»çš„å®¡è®¡ä¸åˆ†æ</a></li>
    <li><a href="#61-beyond-hard-sharing-efficient-multi-task-speech-to-text-modeling-with-supervised-mixture-of-experts--61-è¶…è¶Šç¡¬å…±äº«ä½¿ç”¨ç›‘ç£ä¸“å®¶æ··åˆçš„é«˜æ•ˆå¤šä»»åŠ¡è¯­éŸ³åˆ°æ–‡æœ¬å»ºæ¨¡"><a href="https://arxiv.org/abs/2508.10009">#61</a> <a href="https://papers.cool/arxiv/2508.10009">Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts</a>  #61 è¶…è¶Šç¡¬å…±äº«ï¼šä½¿ç”¨ç›‘ç£ä¸“å®¶æ··åˆçš„é«˜æ•ˆå¤šä»»åŠ¡è¯­éŸ³åˆ°æ–‡æœ¬å»ºæ¨¡</a></li>
    <li><a href="#62-multidimensional-classification-of-posts-for-online-course-discussion-forum-curation--62-ç”¨äºåœ¨çº¿è¯¾ç¨‹è®¨è®ºåŒºç­–åˆ’çš„å¸–å­å¤šç»´åˆ†ç±»"><a href="https://arxiv.org/abs/2508.10008">#62</a> <a href="https://papers.cool/arxiv/2508.10008">Multidimensional classification of posts for online course discussion forum curation</a>  #62 ç”¨äºåœ¨çº¿è¯¾ç¨‹è®¨è®ºåŒºç­–åˆ’çš„å¸–å­å¤šç»´åˆ†ç±»</a></li>
    <li><a href="#63-automated-scoring-of-the-ambiguous-intentions-hostility-questionnaire-using-fine-tuned-large-language-models--63-ä½¿ç”¨å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹å¯¹æ¨¡ç³Šæ„å›¾æ•Œæ„é—®å·è¿›è¡Œè‡ªåŠ¨è¯„åˆ†"><a href="https://arxiv.org/abs/2508.10007">#63</a> <a href="https://papers.cool/arxiv/2508.10007">Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models</a>  #63 ä½¿ç”¨å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹å¯¹æ¨¡ç³Šæ„å›¾æ•Œæ„é—®å·è¿›è¡Œè‡ªåŠ¨è¯„åˆ†</a></li>
    <li><a href="#64-from-answers-to-questions-eqgbench-for-evaluating-llms39-educational-question-generation--64-ä»ç­”æ¡ˆåˆ°é—®é¢˜ç”¨äºè¯„ä¼°-llms-æ•™è‚²æ€§é—®é¢˜ç”Ÿæˆçš„-eqgbench"><a href="https://arxiv.org/abs/2508.10005">#64</a> <a href="https://papers.cool/arxiv/2508.10005">From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation</a>  #64 ä»ç­”æ¡ˆåˆ°é—®é¢˜ï¼šç”¨äºè¯„ä¼° LLMs æ•™è‚²æ€§é—®é¢˜ç”Ÿæˆçš„ EQGBench</a></li>
    <li><a href="#65-user-perception-of-attention-visualizations-effects-on-interpretability-across-evidence-based-medical-documents--65-ç”¨æˆ·å¯¹æ³¨æ„åŠ›å¯è§†åŒ–çš„æ„ŸçŸ¥åœ¨åŸºäºè¯æ®çš„åŒ»å­¦æ–‡æ¡£ä¸­å¯¹å¯è§£é‡Šæ€§çš„å½±å“"><a href="https://arxiv.org/abs/2508.10004">#65</a> <a href="https://papers.cool/arxiv/2508.10004">User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents</a>  #65 ç”¨æˆ·å¯¹æ³¨æ„åŠ›å¯è§†åŒ–çš„æ„ŸçŸ¥ï¼šåœ¨åŸºäºè¯æ®çš„åŒ»å­¦æ–‡æ¡£ä¸­å¯¹å¯è§£é‡Šæ€§çš„å½±å“</a></li>
    <li><a href="#66-semantic-structure-in-large-language-model-embeddings--66-å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­çš„è¯­ä¹‰ç»“æ„"><a href="https://arxiv.org/abs/2508.10003">#66</a> <a href="https://papers.cool/arxiv/2508.10003">Semantic Structure in Large Language Model Embeddings</a>  #66 å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­çš„è¯­ä¹‰ç»“æ„</a></li>
    <li><a href="#67-hifactmix-a-code-mixed-benchmark-and-graph-aware-model-for-evidencebased-political-claim-verification-in-hinglish--67-hifactmixç”¨äºå°è‹±æ··åˆè¯­hinglishè¯æ®å‹æ”¿æ²»å£°æ˜éªŒè¯çš„ä»£ç æ··åˆåŸºå‡†ä¸å›¾æ„ŸçŸ¥æ¨¡å‹-pdf--å¤åˆ¶-kimi--å…³ç³»"><a href="https://arxiv.org/abs/2508.10001">#67</a> <a href="https://papers.cool/arxiv/2508.10001">HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish</a>  #67 HiFACTMixï¼šç”¨äºå°è‹±æ··åˆè¯­ï¼ˆHinglishï¼‰è¯æ®å‹æ”¿æ²»å£°æ˜éªŒè¯çš„ä»£ç æ··åˆåŸºå‡†ä¸å›¾æ„ŸçŸ¥æ¨¡å‹ [PDF ] [å¤åˆ¶] [Kimi ] [å…³ç³»]</a></li>
    <li><a href="#68-autogets-knowledge-based-automated-generation-of-text-synthetics-for-improving-text-classification--68-autogetsåŸºäºçŸ¥è¯†çš„è‡ªåŠ¨åŒ–æ–‡æœ¬åˆæˆç”Ÿæˆä»¥æ”¹å–„æ–‡æœ¬åˆ†ç±»"><a href="https://arxiv.org/abs/2508.10000">#68</a> <a href="https://papers.cool/arxiv/2508.10000">AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification</a>  #68 AutoGeTSï¼šåŸºäºçŸ¥è¯†çš„è‡ªåŠ¨åŒ–æ–‡æœ¬åˆæˆç”Ÿæˆä»¥æ”¹å–„æ–‡æœ¬åˆ†ç±»</a></li>
    <li><a href="#69-xfacta-contemporary-real-world-dataset-and-evaluation-for-multimodal-misinformation-detection-with-multimodal-llms--69-xfactaç”¨äºå¤šæ¨¡æ€-llms-çš„å½“ä»£ç°å®ä¸–ç•Œå¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹æ•°æ®é›†ä¸è¯„ä¼°"><a href="https://arxiv.org/abs/2508.09999">#69</a> <a href="https://papers.cool/arxiv/2508.09999">XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs</a>  #69 XFactaï¼šç”¨äºå¤šæ¨¡æ€ LLMs çš„å½“ä»£ç°å®ä¸–ç•Œå¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹æ•°æ®é›†ä¸è¯„ä¼°</a></li>
    <li><a href="#70-intima-a-benchmark-for-human-ai-companionship-behavior--70-intimaç”¨äºäººæœºåä½œè¡Œä¸ºçš„åŸºå‡†"><a href="https://arxiv.org/abs/2508.09998">#70</a> <a href="https://papers.cool/arxiv/2508.09998">INTIMA: A Benchmark for Human-AI Companionship Behavior</a>  #70 INTIMAï¼šç”¨äºäººæœºåä½œè¡Œä¸ºçš„åŸºå‡†</a></li>
    <li><a href="#71-thematic-and-task-based-categorization-of-k-12-genai-usages-with-hierarchical-topic-modeling--71-ä½¿ç”¨åˆ†å±‚ä¸»é¢˜å»ºæ¨¡å¯¹-k-12-ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä½¿ç”¨çš„ä¸»é¢˜ä¸åŸºäºä»»åŠ¡çš„åˆ†ç±»"><a href="https://arxiv.org/abs/2508.09997">#71</a> <a href="https://papers.cool/arxiv/2508.09997">Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling</a>  #71 ä½¿ç”¨åˆ†å±‚ä¸»é¢˜å»ºæ¨¡å¯¹ K-12 ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä½¿ç”¨çš„ä¸»é¢˜ä¸åŸºäºä»»åŠ¡çš„åˆ†ç±»</a></li>
    <li><a href="#72-a-transparent-fairness-evaluation-protocol-for-open-source-language-model-benchmarking-on-the-blockchain--72-ä¸€ä¸ªç”¨äºåœ¨åŒºå—é“¾ä¸Šå¯¹å¼€æºè¯­è¨€æ¨¡å‹åŸºå‡†è¿›è¡Œé€æ˜å…¬å¹³æ€§è¯„ä¼°çš„åè®®"><a href="https://arxiv.org/abs/2508.09993">#72</a> <a href="https://papers.cool/arxiv/2508.09993">A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain</a>  #72 ä¸€ä¸ªç”¨äºåœ¨åŒºå—é“¾ä¸Šå¯¹å¼€æºè¯­è¨€æ¨¡å‹åŸºå‡†è¿›è¡Œé€æ˜å…¬å¹³æ€§è¯„ä¼°çš„åè®®</a></li>
    <li><a href="#73-bridging-ai-innovation-and-healthcare-needs-lessons-learned-from-incorporating-modern-nlp-at-the-bc-cancer-registry--73-åœ¨äººå·¥æ™ºèƒ½åˆ›æ–°ä¸åŒ»ç–—éœ€æ±‚ä¹‹é—´æ¶æ¡¥åœ¨-bc-ç™Œç—‡ç™»è®°å¤„å¼•å…¥ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»éªŒæ•™è®­"><a href="https://arxiv.org/abs/2508.09991">#73</a> <a href="https://papers.cool/arxiv/2508.09991">Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry</a>  #73 åœ¨äººå·¥æ™ºèƒ½åˆ›æ–°ä¸åŒ»ç–—éœ€æ±‚ä¹‹é—´æ¶æ¡¥ï¼šåœ¨ BC ç™Œç—‡ç™»è®°å¤„å¼•å…¥ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»éªŒæ•™è®­</a></li>
    <li><a href="#74-searching-for-privacy-risks-in-llm-agents-via-simulation--74-é€šè¿‡æ¨¡æ‹Ÿåœ¨-llm-agent-ä¸­å¯»æ‰¾éšç§é£é™©"><a href="https://arxiv.org/abs/2508.10880">#74</a> <a href="https://papers.cool/arxiv/2508.10880">Searching for Privacy Risks in LLM Agents via Simulation</a>  #74 é€šè¿‡æ¨¡æ‹Ÿåœ¨ LLM Agent ä¸­å¯»æ‰¾éšç§é£é™©</a></li>
    <li><a href="#75-memory-augmented-transformers-a-systematic-review-from-neuroscience-principles-to-technical-solutions--75-è®°å¿†å¢å¼ºå‹å˜å‹å™¨ä»ç¥ç»ç§‘å­¦åŸç†åˆ°æŠ€æœ¯è§£å†³æ–¹æ¡ˆçš„ç³»ç»Ÿç»¼è¿°"><a href="https://arxiv.org/abs/2508.10824">#75</a> <a href="https://papers.cool/arxiv/2508.10824">Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions</a>  #75 è®°å¿†å¢å¼ºå‹å˜å‹å™¨ï¼šä»ç¥ç»ç§‘å­¦åŸç†åˆ°æŠ€æœ¯è§£å†³æ–¹æ¡ˆçš„ç³»ç»Ÿç»¼è¿°</a></li>
    <li><a href="#76-passk-training-for-adaptively-balancing-exploration-and-exploitation-of-large-reasoning-models--76-passk-è®­ç»ƒç”¨äºè‡ªé€‚åº”å¹³è¡¡å¤§è§„æ¨¡æ¨ç†æ¨¡å‹çš„æ¢ç´¢ä¸åˆ©ç”¨"><a href="https://arxiv.org/abs/2508.10751">#76</a> <a href="https://papers.cool/arxiv/2508.10751">Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models</a>  #76 Pass@k è®­ç»ƒç”¨äºè‡ªé€‚åº”å¹³è¡¡å¤§è§„æ¨¡æ¨ç†æ¨¡å‹çš„æ¢ç´¢ä¸åˆ©ç”¨</a></li>
    <li><a href="#77-stabilizing-long-term-multi-turn-reinforcement-learning-with-gated-rewards--77-ä½¿ç”¨é—¨æ§å¥–åŠ±ç¨³å®šé•¿æœŸå¤šå›åˆå¼ºåŒ–å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10548">#77</a> <a href="https://papers.cool/arxiv/2508.10548">Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards</a>  #77 ä½¿ç”¨é—¨æ§å¥–åŠ±ç¨³å®šé•¿æœŸå¤šå›åˆå¼ºåŒ–å­¦ä¹ </a></li>
    <li><a href="#78-improving-value-based-process-verifier-via-low-cost-variance-reduction"><a href="https://arxiv.org/abs/2508.10539">#78</a> <a href="https://papers.cool/arxiv/2508.10539">Improving Value-based Process Verifier via Low-Cost Variance Reduction</a></a></li>
    <li><a href="#79-diversity-first-quality-later-a-two-stage-assumption-for-language-model-alignment--79-å¤šæ ·æ€§ä¼˜å…ˆè´¨é‡é åè¯­è¨€æ¨¡å‹å¯¹é½çš„ä¸¤é˜¶æ®µå‡è®¾"><a href="https://arxiv.org/abs/2508.10530">#79</a> <a href="https://papers.cool/arxiv/2508.10530">Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment</a>  #79 å¤šæ ·æ€§ä¼˜å…ˆï¼Œè´¨é‡é åï¼šè¯­è¨€æ¨¡å‹å¯¹é½çš„ä¸¤é˜¶æ®µå‡è®¾</a></li>
    <li><a href="#80-reverse-physician-ai-relationship-full-process-clinical-diagnosis-driven-by-a-large-language-model--80-é¢ å€’çš„åŒ»å¸ˆäººå·¥æ™ºèƒ½å…³ç³»ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­"><a href="https://arxiv.org/abs/2508.10492">#80</a> <a href="https://papers.cool/arxiv/2508.10492">Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model</a>  #80 é¢ å€’çš„åŒ»å¸ˆâ€”äººå·¥æ™ºèƒ½å…³ç³»ï¼šç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­</a></li>
    <li><a href="#81-correctnav-self-correction-flywheel-empowers-vision-language-action-navigation-model--81-correctnavè‡ªæˆ‘çº æ­£é£è½®èµ‹èƒ½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨å¯¼èˆªæ¨¡å‹"><a href="https://arxiv.org/abs/2508.10416">#81</a> <a href="https://papers.cool/arxiv/2508.10416">CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model</a>  #81 CorrectNavï¼šè‡ªæˆ‘çº æ­£é£è½®èµ‹èƒ½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨å¯¼èˆªæ¨¡å‹</a></li>
    <li><a href="#82-improving-ocr-for-historical-texts-of-multiple-languages--82-æå‡å¤šè¯­è¨€å†å²æ–‡æœ¬-ocr-çš„æ•ˆæœ"><a href="https://arxiv.org/abs/2508.10356">#82</a> <a href="https://papers.cool/arxiv/2508.10356">Improving OCR for Historical Texts of Multiple Languages</a>  #82 æå‡å¤šè¯­è¨€å†å²æ–‡æœ¬ OCR çš„æ•ˆæœ</a></li>
    <li><a href="#83-personalized-real-time-jargon-support-for-online-meetings--83-ä¸ºåœ¨çº¿ä¼šè®®æä¾›ä¸ªæ€§åŒ–å®æ—¶è¡Œè¯æ”¯æŒ"><a href="https://arxiv.org/abs/2508.10239">#83</a> <a href="https://papers.cool/arxiv/2508.10239">Personalized Real-time Jargon Support for Online Meetings</a>  #83 ä¸ºåœ¨çº¿ä¼šè®®æä¾›ä¸ªæ€§åŒ–å®æ—¶è¡Œè¯æ”¯æŒ</a></li>
    <li><a href="#84-nested-reft-efficient-reinforcement-learning-for-large-language-model-fine-tuning-via-off-policy-rollouts--84-nested-refté€šè¿‡ç¦»ç­–ç•¥å›æ»šå®ç°å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å¾®è°ƒçš„é«˜æ•ˆå¼ºåŒ–å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10123">#84</a> <a href="https://papers.cool/arxiv/2508.10123">Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts</a>  #84 Nested-ReFTï¼šé€šè¿‡ç¦»ç­–ç•¥å›æ»šå®ç°å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å¾®è°ƒçš„é«˜æ•ˆå¼ºåŒ–å­¦ä¹ </a></li>
    <li><a href="#85-amazon-nova-ai-challenge---85-äºšé©¬é€Š-nova-ai-æŒ‘æˆ˜èµ›--å¯ä¿¡-aiæ¨è¿›å®‰å…¨çš„-ai-è¾…åŠ©è½¯ä»¶å¼€å‘"><a href="https://arxiv.org/abs/2508.10108">#85</a> <a href="https://papers.cool/arxiv/2508.10108">Amazon Nova AI Challenge &ndash; Trusted AI: Advancing secure, AI-assisted software development</a>  #85 äºšé©¬é€Š Nova AI æŒ‘æˆ˜èµ› &ndash; å¯ä¿¡ AIï¼šæ¨è¿›å®‰å…¨çš„ AI è¾…åŠ©è½¯ä»¶å¼€å‘</a></li>
    <li><a href="#86-saracoder-orchestrating-semantic-and-structural-cues-for-profit-oriented-repository-level-code-completion--86-saracoderä¸ºåˆ©æ¶¦å¯¼å‘çš„ä»“åº“çº§ä»£ç è¡¥å…¨åè°ƒè¯­ä¹‰ä¸ç»“æ„çº¿ç´¢-pdf-2--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10068">#86</a> <a href="https://papers.cool/arxiv/2508.10068">SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion</a>  #86 SaraCoderï¼šä¸ºåˆ©æ¶¦å¯¼å‘çš„ä»“åº“çº§ä»£ç è¡¥å…¨åè°ƒè¯­ä¹‰ä¸ç»“æ„çº¿ç´¢ [PDF 2 ] [Copy] [Kimi ] [REL]</a></li>
    <li><a href="#87-large-language-models-show-signs-of-alignment-with-human-neurocognition-during-abstract-reasoning--87-å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­æ˜¾ç¤ºå‡ºä¸äººç±»ç¥ç»è®¤çŸ¥ä¸€è‡´çš„è¿¹è±¡"><a href="https://arxiv.org/abs/2508.10057">#87</a> <a href="https://papers.cool/arxiv/2508.10057">Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning</a>  #87 å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­æ˜¾ç¤ºå‡ºä¸äººç±»ç¥ç»è®¤çŸ¥ä¸€è‡´çš„è¿¹è±¡</a></li>
    <li><a href="#88-context-misleads-llms-the-role-of-context-filtering-in-maintaining-safe-alignment-of-llms--88-ä¸Šä¸‹æ–‡è¯¯å¯¼-llmsä¸Šä¸‹æ–‡è¿‡æ»¤åœ¨ç»´æŒ-llms-å®‰å…¨å¯¹é½ä¸­çš„ä½œç”¨-pdf-1--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10031">#88</a> <a href="https://papers.cool/arxiv/2508.10031">Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs</a>  #88 ä¸Šä¸‹æ–‡è¯¯å¯¼ LLMsï¼šä¸Šä¸‹æ–‡è¿‡æ»¤åœ¨ç»´æŒ LLMs å®‰å…¨å¯¹é½ä¸­çš„ä½œç”¨ [PDF 1 ] [Copy] [Kimi ] [REL]</a></li>
    <li><a href="#89-personalized-product-search-ranking-a-multi-task-learning-approach-with-tabular-and-non-tabular-data--89-ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•"><a href="https://arxiv.org/abs/2508.09636">#89</a> <a href="https://papers.cool/arxiv/2508.09636">Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data</a>  #89 ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åï¼šä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•</a></li>
  </ul>

  <ul>
    <li><a href="#1-who-benefits-from-ai-explanations-towards-accessible-and-interpretable-systems--1-è°ä»äººå·¥æ™ºèƒ½è§£é‡Šä¸­å—ç›Šè¿ˆå‘å¯è®¿é—®ä¸”å¯è§£é‡Šçš„ç³»ç»Ÿ"><a href="https://arxiv.org/abs/2508.10806">#1</a> <a href="https://papers.cool/arxiv/2508.10806">Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems</a>  #1 è°ä»äººå·¥æ™ºèƒ½è§£é‡Šä¸­å—ç›Šï¼Ÿè¿ˆå‘å¯è®¿é—®ä¸”å¯è§£é‡Šçš„ç³»ç»Ÿ</a></li>
    <li><a href="#2-the-knowledge-reasoning-dissociation-fundamental-limitations-of-llms-in-clinical-natural-language-inference--2-çŸ¥è¯†-æ¨ç†åˆ†ç¦»llms-åœ¨ä¸´åºŠè‡ªç„¶è¯­è¨€æ¨ç†ä¸­çš„åŸºæœ¬å±€é™æ€§"><a href="https://arxiv.org/abs/2508.10777">#2</a> <a href="https://papers.cool/arxiv/2508.10777">The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference</a>  #2 çŸ¥è¯†-æ¨ç†åˆ†ç¦»ï¼šLLMs åœ¨ä¸´åºŠè‡ªç„¶è¯­è¨€æ¨ç†ä¸­çš„åŸºæœ¬å±€é™æ€§</a></li>
    <li><a href="#3-modeling-human-responses-to-multimodal-ai-content--3-å¯¹å¤šæ¨¡æ€-ai-å†…å®¹ä¸­äººç±»ååº”çš„å»ºæ¨¡"><a href="https://arxiv.org/abs/2508.10769">#3</a> <a href="https://papers.cool/arxiv/2508.10769">Modeling Human Responses to Multimodal AI Content</a>  #3 å¯¹å¤šæ¨¡æ€ AI å†…å®¹ä¸­äººç±»ååº”çš„å»ºæ¨¡</a></li>
    <li><a href="#4-scaling-up-without-fading-out-goal-aware-sparse-gnn-for-rl-based-generalized-planning"><a href="https://arxiv.org/abs/2508.10747">#4</a> <a href="https://papers.cool/arxiv/2508.10747">Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning</a></a></li>
    <li><a href="#5-agentic-design-review-system"><a href="https://arxiv.org/abs/2508.10745">#5</a> <a href="https://papers.cool/arxiv/2508.10745">Agentic Design Review System</a></a></li>
    <li><a href="#6-genom-ontology-matching-with-description-generation-and-large-language-model--6-genomä½¿ç”¨æè¿°ç”Ÿæˆå’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æœ¬ä½“åŒ¹é…"><a href="https://arxiv.org/abs/2508.10703">#6</a> <a href="https://papers.cool/arxiv/2508.10703">GenOM: Ontology Matching with Description Generation and Large Language Model</a>  #6 GenOMï¼šä½¿ç”¨æè¿°ç”Ÿæˆå’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æœ¬ä½“åŒ¹é…</a></li>
    <li><a href="#7-step-stepwise-curriculum-learning-for-context-knowledge-fusion-in-conversational-recommendation--7-stepç”¨äºå¯¹è¯å¼æ¨èä¸­ä¸Šä¸‹æ–‡ä¸çŸ¥è¯†èåˆçš„åˆ†æ­¥è¯¾ç¨‹å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10669">#7</a> <a href="https://papers.cool/arxiv/2508.10669">STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation</a>  #7 STEPï¼šç”¨äºå¯¹è¯å¼æ¨èä¸­ä¸Šä¸‹æ–‡ä¸çŸ¥è¯†èåˆçš„åˆ†æ­¥è¯¾ç¨‹å­¦ä¹ </a></li>
    <li><a href="#8-msrs-adaptive-multi-subspace-representation-steering-for-attribute-alignment-in-large-language-models--8-msrsç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹å±æ€§å¯¹é½çš„è‡ªé€‚åº”å¤šå­ç©ºé—´è¡¨ç¤ºå¼•å¯¼"><a href="https://arxiv.org/abs/2508.10599">#8</a> <a href="https://papers.cool/arxiv/2508.10599">MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models</a>  #8 MSRSï¼šç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹å±æ€§å¯¹é½çš„è‡ªé€‚åº”å¤šå­ç©ºé—´è¡¨ç¤ºå¼•å¯¼</a></li>
    <li><a href="#9-improving-value-based-process-verifier-via-low-cost-variance-reduction--9-é€šè¿‡ä½æˆæœ¬æ–¹å·®å‡å°‘æ”¹è¿›åŸºäºä»·å€¼çš„è¿‡ç¨‹éªŒè¯å™¨"><a href="https://arxiv.org/abs/2508.10539">#9</a> <a href="https://papers.cool/arxiv/2508.10539">Improving Value-based Process Verifier via Low-Cost Variance Reduction</a>  #9 é€šè¿‡ä½æˆæœ¬æ–¹å·®å‡å°‘æ”¹è¿›åŸºäºä»·å€¼çš„è¿‡ç¨‹éªŒè¯å™¨</a></li>
    <li><a href="#10-diversity-first-quality-later-a-two-stage-assumption-for-language-model-alignment--10-å¤šæ ·æ€§ä¼˜å…ˆè´¨é‡éšåä¸€ç§ç”¨äºè¯­è¨€æ¨¡å‹å¯¹é½çš„ä¸¤é˜¶æ®µå‡è®¾"><a href="https://arxiv.org/abs/2508.10530">#10</a> <a href="https://papers.cool/arxiv/2508.10530">Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment</a>  #10 å¤šæ ·æ€§ä¼˜å…ˆï¼Œè´¨é‡éšåï¼šä¸€ç§ç”¨äºè¯­è¨€æ¨¡å‹å¯¹é½çš„ä¸¤é˜¶æ®µå‡è®¾</a></li>
    <li><a href="#11-pass-probabilistic-agentic-supernet-sampling-for-interpretable-and-adaptive-chest-x-ray-reasoning--11-é€šè¿‡æ¦‚ç‡åŒ–èƒ½åŠ¨è¶…ç½‘ç»œé‡‡æ ·å®ç°å¯è§£é‡Šä¸”è‡ªé€‚åº”çš„èƒ¸ç‰‡æ¨ç†"><a href="https://arxiv.org/abs/2508.10501">#11</a> <a href="https://papers.cool/arxiv/2508.10501">PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning</a>  #11 é€šè¿‡æ¦‚ç‡åŒ–èƒ½åŠ¨è¶…ç½‘ç»œé‡‡æ ·å®ç°å¯è§£é‡Šä¸”è‡ªé€‚åº”çš„èƒ¸ç‰‡æ¨ç†</a></li>
    <li><a href="#12-reverse-physician-ai-relationship-full-process-clinical-diagnosis-driven-by-a-large-language-model--12-é¢ å€’çš„åŒ»ç”Ÿai-å…³ç³»ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­"><a href="https://arxiv.org/abs/2508.10492">#12</a> <a href="https://papers.cool/arxiv/2508.10492">Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model</a>  #12 é¢ å€’çš„åŒ»ç”Ÿâ€”AI å…³ç³»ï¼šç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­</a></li>
    <li><a href="#13-seq-gpt-llm-assisted-spatial-query-via-example--13-seq-gpté€šè¿‡ç¤ºä¾‹çš„-llm-è¾…åŠ©ç©ºé—´æŸ¥è¯¢"><a href="https://arxiv.org/abs/2508.10486">#13</a> <a href="https://papers.cool/arxiv/2508.10486">SEQ-GPT: LLM-assisted Spatial Query via Example</a>  #13 SEQ-GPTï¼šé€šè¿‡ç¤ºä¾‹çš„ LLM è¾…åŠ©ç©ºé—´æŸ¥è¯¢</a></li>
    <li><a href="#14-firesparql-a-llm-based-framework-for-sparql-query-generation-over-scholarly-knowledge-graphs--14-firesparqlä¸€ç§åŸºäº-llm-çš„åœ¨å­¦æœ¯çŸ¥è¯†å›¾è°±ä¸Šç”Ÿæˆ-sparql-æŸ¥è¯¢çš„æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10467">#14</a> <a href="https://papers.cool/arxiv/2508.10467">FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs</a>  #14 FIRESPARQLï¼šä¸€ç§åŸºäº LLM çš„åœ¨å­¦æœ¯çŸ¥è¯†å›¾è°±ä¸Šç”Ÿæˆ SPARQL æŸ¥è¯¢çš„æ¡†æ¶</a></li>
    <li><a href="#15-we-math-20-a-versatile-mathbook-system-for-incentivizing-visual-mathematical-reasoning"><a href="https://arxiv.org/abs/2508.10433">#15</a> <a href="https://papers.cool/arxiv/2508.10433">We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning</a></a></li>
    <li><a href="#16-mm-food-100k-a-100000-sample-multimodal-food-intelligence-dataset-with-verifiable-provenance--16-mm-food-100kä¸€ä¸ªå…·æœ‰å¯éªŒè¯æ¥æºçš„-100000-æ ·æœ¬å¤šæ¨¡æ€é£Ÿå“æ™ºèƒ½æ•°æ®é›†"><a href="https://arxiv.org/abs/2508.10429">#16</a> <a href="https://papers.cool/arxiv/2508.10429">MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance</a>  #16 MM-Food-100Kï¼šä¸€ä¸ªå…·æœ‰å¯éªŒè¯æ¥æºçš„ 100,000 æ ·æœ¬å¤šæ¨¡æ€é£Ÿå“æ™ºèƒ½æ•°æ®é›†</a></li>
    <li><a href="#17-hiref-leveraging-hierarchical-ontology-and-network-refinement-for-robust-medication-recommendation--17-hirefåˆ©ç”¨åˆ†å±‚æœ¬ä½“ä¸ç½‘ç»œç²¾ç‚¼å®ç°é²æ£’çš„ç”¨è¯æ¨è"><a href="https://arxiv.org/abs/2508.10425">#17</a> <a href="https://papers.cool/arxiv/2508.10425">HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation</a>  #17 HiRefï¼šåˆ©ç”¨åˆ†å±‚æœ¬ä½“ä¸ç½‘ç»œç²¾ç‚¼å®ç°é²æ£’çš„ç”¨è¯æ¨è</a></li>
    <li><a href="#18-leanrag-knowledge-graph-based-generation-with-semantic-aggregation-and-hierarchical-retrieval--18-leanragåŸºäºçŸ¥è¯†å›¾è°±çš„ç”Ÿæˆå…·æœ‰è¯­ä¹‰èšåˆä¸åˆ†å±‚æ£€ç´¢"><a href="https://arxiv.org/abs/2508.10391">#18</a> <a href="https://papers.cool/arxiv/2508.10391">LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval</a>  #18 LeanRAGï¼šåŸºäºçŸ¥è¯†å›¾è°±çš„ç”Ÿæˆï¼Œå…·æœ‰è¯­ä¹‰èšåˆä¸åˆ†å±‚æ£€ç´¢</a></li>
    <li><a href="#19-what-to-ask-next-probing-the-imaginative-reasoning-of-llms-with-turtlesoup-puzzles--19-æ¥ä¸‹æ¥è¯¥é—®ä»€ä¹ˆç”¨-turtlesoup-è°œé¢˜æ¢ç´¢-llms-çš„æƒ³è±¡æ€§æ¨ç†"><a href="https://arxiv.org/abs/2508.10358">#19</a> <a href="https://papers.cool/arxiv/2508.10358">What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles</a>  #19 æ¥ä¸‹æ¥è¯¥é—®ä»€ä¹ˆï¼Ÿç”¨ TurtleSoup è°œé¢˜æ¢ç´¢ LLMs çš„æƒ³è±¡æ€§æ¨ç†</a></li>
    <li><a href="#20-multi-agent-trust-region-policy-optimisation-a-joint-constraint-approach--20-å¤šæ™ºèƒ½ä½“ä¿¡ä»»åŸŸç­–ç•¥ä¼˜åŒ–ä¸€ç§è”åˆçº¦æŸæ–¹æ³•"><a href="https://arxiv.org/abs/2508.10340">#20</a> <a href="https://papers.cool/arxiv/2508.10340">Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach</a>  #20 å¤šæ™ºèƒ½ä½“ä¿¡ä»»åŸŸç­–ç•¥ä¼˜åŒ–ï¼šä¸€ç§è”åˆçº¦æŸæ–¹æ³•</a></li>
    <li><a href="#21-a-curriculum-learning-approach-to-reinforcement-learning-leveraging-rag-for-multimodal-question-answering--21-ä¸€ç§é¢å‘å¼ºåŒ–å­¦ä¹ çš„è¯¾ç¨‹å­¦ä¹ æ–¹æ³•åœ¨å¤šæ¨¡æ€é—®ç­”ä¸­åˆ©ç”¨-rag"><a href="https://arxiv.org/abs/2508.10337">#21</a> <a href="https://papers.cool/arxiv/2508.10337">A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering</a>  #21 ä¸€ç§é¢å‘å¼ºåŒ–å­¦ä¹ çš„è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ï¼šåœ¨å¤šæ¨¡æ€é—®ç­”ä¸­åˆ©ç”¨ RAG</a></li>
    <li><a href="#22-promoting-efficient-reasoning-with-verifiable-stepwise-reward--22-é€šè¿‡å¯éªŒè¯çš„é€æ­¥å¥–åŠ±ä¿ƒè¿›é«˜æ•ˆæ¨ç†"><a href="https://arxiv.org/abs/2508.10293">#22</a> <a href="https://papers.cool/arxiv/2508.10293">Promoting Efficient Reasoning with Verifiable Stepwise Reward</a>  #22 é€šè¿‡å¯éªŒè¯çš„é€æ­¥å¥–åŠ±ä¿ƒè¿›é«˜æ•ˆæ¨ç†</a></li>
    <li><a href="#23-why-cannot-large-language-models-ever-make-true-correct-reasoning--23-ä¸ºä»€ä¹ˆå¤§å‹è¯­è¨€æ¨¡å‹æ°¸è¿œæ— æ³•åšå‡ºçœŸæ­£æ­£ç¡®çš„æ¨ç†"><a href="https://arxiv.org/abs/2508.10265">#23</a> <a href="https://papers.cool/arxiv/2508.10265">Why Cannot Large Language Models Ever Make True Correct Reasoning?</a>  #23 ä¸ºä»€ä¹ˆå¤§å‹è¯­è¨€æ¨¡å‹æ°¸è¿œæ— æ³•åšå‡ºçœŸæ­£æ­£ç¡®çš„æ¨ç†ï¼Ÿ</a></li>
    <li><a href="#24-extending-the-entropic-potential-of-events-for-uncertainty-quantification-and-decision-making-in-artificial-intelligence--24-æ‰©å±•äº‹ä»¶çš„ç†µåŠ¿ä»¥ç”¨äºä¸ç¡®å®šæ€§é‡åŒ–å’Œäººå·¥æ™ºèƒ½ä¸­çš„å†³ç­–åˆ¶å®š"><a href="https://arxiv.org/abs/2508.10241">#24</a> <a href="https://papers.cool/arxiv/2508.10241">Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence</a>  #24 æ‰©å±•äº‹ä»¶çš„ç†µåŠ¿ä»¥ç”¨äºä¸ç¡®å®šæ€§é‡åŒ–å’Œäººå·¥æ™ºèƒ½ä¸­çš„å†³ç­–åˆ¶å®š</a></li>
    <li><a href="#25-kompeteai-accelerated-autonomous-multi-agent-system-for-end-to-end-pipeline-generation-for-machine-learning-problems--25-kompeteaiç”¨äºæœºå™¨å­¦ä¹ é—®é¢˜ç«¯åˆ°ç«¯ç®¡é“ç”Ÿæˆçš„åŠ é€Ÿè‡ªä¸»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ"><a href="https://arxiv.org/abs/2508.10177">#25</a> <a href="https://papers.cool/arxiv/2508.10177">KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems</a>  #25 KompeteAIï¼šç”¨äºæœºå™¨å­¦ä¹ é—®é¢˜ç«¯åˆ°ç«¯ç®¡é“ç”Ÿæˆçš„åŠ é€Ÿè‡ªä¸»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ</a></li>
    <li><a href="#26-pruning-long-chain-of-thought-of-large-reasoning-models-via-small-scale-preference-optimization--26-é€šè¿‡å°è§„æ¨¡åå¥½ä¼˜åŒ–è£å‰ªå¤§å‹æ¨ç†æ¨¡å‹çš„é•¿é“¾å¼æ€ç»´chain-of-thought"><a href="https://arxiv.org/abs/2508.10164">#26</a> <a href="https://papers.cool/arxiv/2508.10164">Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization</a>  #26 é€šè¿‡å°è§„æ¨¡åå¥½ä¼˜åŒ–è£å‰ªå¤§å‹æ¨ç†æ¨¡å‹çš„é•¿é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰</a></li>
    <li><a href="#27-improving-and-evaluating-open-deep-research-agents--27-æå‡ä¸è¯„ä¼°å¼€æ”¾å¼æ·±åº¦ç ”ç©¶ä»£ç†"><a href="https://arxiv.org/abs/2508.10152">#27</a> <a href="https://papers.cool/arxiv/2508.10152">Improving and Evaluating Open Deep Research Agents</a>  #27 æå‡ä¸è¯„ä¼°å¼€æ”¾å¼æ·±åº¦ç ”ç©¶ä»£ç†</a></li>
    <li><a href="#28-agentic-ai-frameworks-architectures-protocols-and-design-challenges--28-å…·ä»£ç†æ€§çš„äººå·¥æ™ºèƒ½æ¡†æ¶ä½“ç³»ç»“æ„åè®®ä¸è®¾è®¡æŒ‘æˆ˜"><a href="https://arxiv.org/abs/2508.10146">#28</a> <a href="https://papers.cool/arxiv/2508.10146">Agentic AI Frameworks: Architectures, Protocols, and Design Challenges</a>  #28 å…·ä»£ç†æ€§çš„äººå·¥æ™ºèƒ½æ¡†æ¶ï¼šä½“ç³»ç»“æ„ã€åè®®ä¸è®¾è®¡æŒ‘æˆ˜</a></li>
    <li><a href="#29-mcp-orchestrated-multi-agent-system-for-automated-disinformation-detection--29-mcp-åè°ƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç”¨äºè‡ªåŠ¨åŒ–è™šå‡ä¿¡æ¯æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10143">#29</a> <a href="https://papers.cool/arxiv/2508.10143">MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection</a>  #29 MCP åè°ƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç”¨äºè‡ªåŠ¨åŒ–è™šå‡ä¿¡æ¯æ£€æµ‹</a></li>
    <li><a href="#30-amazon-nova-ai-challenge---30-äºšé©¬é€Š-nova-ai-æŒ‘æˆ˜èµ›--å¯ä¿¡-aiæ¨è¿›å®‰å…¨çš„-ai-è¾…åŠ©è½¯ä»¶å¼€å‘"><a href="https://arxiv.org/abs/2508.10108">#30</a> <a href="https://papers.cool/arxiv/2508.10108">Amazon Nova AI Challenge &ndash; Trusted AI: Advancing secure, AI-assisted software development</a>  #30 äºšé©¬é€Š Nova AI æŒ‘æˆ˜èµ› &ndash; å¯ä¿¡ AIï¼šæ¨è¿›å®‰å…¨çš„ AI è¾…åŠ©è½¯ä»¶å¼€å‘</a></li>
    <li><a href="#31-a-survey-of-optimization-modeling-meets-llms-progress-and-future-directions--31-ä¼˜åŒ–å»ºæ¨¡ä¸-llms-ç›¸é‡çš„ç»¼è¿°è¿›å±•ä¸æœªæ¥æ–¹å‘"><a href="https://arxiv.org/abs/2508.10047">#31</a> <a href="https://papers.cool/arxiv/2508.10047">A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions</a>  #31 ä¼˜åŒ–å»ºæ¨¡ä¸ LLMs ç›¸é‡çš„ç»¼è¿°ï¼šè¿›å±•ä¸æœªæ¥æ–¹å‘</a></li>
    <li><a href="#32-empirical-investigation-into-configuring-echo-state-networks-for-representative-benchmark-problem-domains--32-å¯¹é…ç½®å›å£°çŠ¶æ€ç½‘ç»œä»¥é€‚åº”å…·æœ‰ä»£è¡¨æ€§çš„åŸºå‡†é—®é¢˜é¢†åŸŸçš„å®è¯ç ”ç©¶"><a href="https://arxiv.org/abs/2508.10887">#32</a> <a href="https://papers.cool/arxiv/2508.10887">Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains</a>  #32 å¯¹é…ç½®å›å£°çŠ¶æ€ç½‘ç»œä»¥é€‚åº”å…·æœ‰ä»£è¡¨æ€§çš„åŸºå‡†é—®é¢˜é¢†åŸŸçš„å®è¯ç ”ç©¶</a></li>
    <li><a href="#33-tooncomposer-streamlining-cartoon-production-with-generative-post-keyframing--33-tooncomposeré€šè¿‡ç”Ÿæˆå¼å…³é”®å¸§åæœŸç®€åŒ–å¡é€šåˆ¶ä½œ"><a href="https://arxiv.org/abs/2508.10881">#33</a> <a href="https://papers.cool/arxiv/2508.10881">ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing</a>  #33 ToonComposerï¼šé€šè¿‡ç”Ÿæˆå¼å…³é”®å¸§åæœŸç®€åŒ–å¡é€šåˆ¶ä½œ</a></li>
    <li><a href="#34-searching-for-privacy-risks-in-llm-agents-via-simulation--34-é€šè¿‡æ¨¡æ‹Ÿåœ¨-llm-agents-ä¸­æœç´¢éšç§é£é™©"><a href="https://arxiv.org/abs/2508.10880">#34</a> <a href="https://papers.cool/arxiv/2508.10880">Searching for Privacy Risks in LLM Agents via Simulation</a>  #34 é€šè¿‡æ¨¡æ‹Ÿåœ¨ LLM agents ä¸­æœç´¢éšç§é£é™©</a></li>
    <li><a href="#35-a-survey-on-diffusion-language-models--35-å…³äºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç»¼è¿°"><a href="https://arxiv.org/abs/2508.10875">#35</a> <a href="https://papers.cool/arxiv/2508.10875">A Survey on Diffusion Language Models</a>  #35 å…³äºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç»¼è¿°</a></li>
    <li><a href="#36-tle-based-a2c-agent-for-terrestrial-coverage-orbital-path-planning--36-åŸºäº-tle-çš„-a2c-æ™ºèƒ½ä½“ç”¨äºåœ°é¢è¦†ç›–è½¨é“è·¯å¾„è§„åˆ’"><a href="https://arxiv.org/abs/2508.10872">#36</a> <a href="https://papers.cool/arxiv/2508.10872">TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning</a>  #36 åŸºäº TLE çš„ A2C æ™ºèƒ½ä½“ç”¨äºåœ°é¢è¦†ç›–è½¨é“è·¯å¾„è§„åˆ’</a></li>
    <li><a href="#37-medico-2025-visual-question-answering-for-gastrointestinal-imaging--37-medico-2025ç”¨äºèƒƒè‚ é“æˆåƒçš„è§†è§‰é—®ç­”"><a href="https://arxiv.org/abs/2508.10869">#37</a> <a href="https://papers.cool/arxiv/2508.10869">Medico 2025: Visual Question Answering for Gastrointestinal Imaging</a>  #37 Medico 2025ï¼šç”¨äºèƒƒè‚ é“æˆåƒçš„è§†è§‰é—®ç­”</a></li>
    <li><a href="#38-performance-of-gpt-5-in-brain-tumor-mri-reasoning--38-gpt-5-åœ¨è„‘è‚¿ç˜¤-mri-æ¨ç†ä¸­çš„è¡¨ç°"><a href="https://arxiv.org/abs/2508.10865">#38</a> <a href="https://papers.cool/arxiv/2508.10865">Performance of GPT-5 in Brain Tumor MRI Reasoning</a>  #38 GPT-5 åœ¨è„‘è‚¿ç˜¤ MRI æ¨ç†ä¸­çš„è¡¨ç°</a></li>
    <li><a href="#39-from-black-box-to-transparency-enhancing-automated-interpreting-assessment-with-explainable-ai-in-college-classrooms--39-ä»é»‘ç®±åˆ°é€æ˜åœ¨å¤§å­¦è¯¾å ‚ä¸­ç”¨å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºè‡ªåŠ¨å£è¯‘è¯„ä¼°"><a href="https://arxiv.org/abs/2508.10860">#39</a> <a href="https://papers.cool/arxiv/2508.10860">From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms</a>  #39 ä»é»‘ç®±åˆ°é€æ˜ï¼šåœ¨å¤§å­¦è¯¾å ‚ä¸­ç”¨å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºè‡ªåŠ¨å£è¯‘è¯„ä¼°</a></li>
    <li><a href="#40-reinforced-language-models-for-sequential-decision-making--40-å¼ºåŒ–è¯­è¨€æ¨¡å‹ç”¨äºåºåˆ—å†³ç­–åˆ¶å®š"><a href="https://arxiv.org/abs/2508.10839">#40</a> <a href="https://papers.cool/arxiv/2508.10839">Reinforced Language Models for Sequential Decision Making</a>  #40 å¼ºåŒ–è¯­è¨€æ¨¡å‹ç”¨äºåºåˆ—å†³ç­–åˆ¶å®š</a></li>
    <li><a href="#41-a-multimodal-neural-network-for-recognizing-subjective-self-disclosure-towards-social-robots--41-ä¸€ç§ç”¨äºè¯†åˆ«å¯¹ç¤¾äº¤æœºå™¨äººä¸»è§‚è‡ªæˆ‘æŠ«éœ²çš„å¤šæ¨¡æ€ç¥ç»ç½‘ç»œ"><a href="https://arxiv.org/abs/2508.10828">#41</a> <a href="https://papers.cool/arxiv/2508.10828">A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots</a>  #41 ä¸€ç§ç”¨äºè¯†åˆ«å¯¹ç¤¾äº¤æœºå™¨äººä¸»è§‚è‡ªæˆ‘æŠ«éœ²çš„å¤šæ¨¡æ€ç¥ç»ç½‘ç»œ</a></li>
    <li><a href="#42-the-set-perceptual-factors-framework-towards-assured-perception-for-autonomous-systems--42-set-æ„ŸçŸ¥å› ç´ æ¡†æ¶è¿ˆå‘è‡ªä¸»ç³»ç»Ÿçš„å¯é æ„ŸçŸ¥"><a href="https://arxiv.org/abs/2508.10798">#42</a> <a href="https://papers.cool/arxiv/2508.10798">The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems</a>  #42 ã€ŠSET æ„ŸçŸ¥å› ç´ æ¡†æ¶ï¼šè¿ˆå‘è‡ªä¸»ç³»ç»Ÿçš„å¯é æ„ŸçŸ¥ã€‹</a></li>
    <li><a href="#43-enhancing-fairness-in-autoencoders-for-node-level-graph-anomaly-detection--43-åœ¨ç”¨äºèŠ‚ç‚¹çº§å›¾å¼‚å¸¸æ£€æµ‹çš„è‡ªç¼–ç å™¨ä¸­æå‡å…¬å¹³æ€§"><a href="https://arxiv.org/abs/2508.10785">#43</a> <a href="https://papers.cool/arxiv/2508.10785">Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection</a>  #43 åœ¨ç”¨äºèŠ‚ç‚¹çº§å›¾å¼‚å¸¸æ£€æµ‹çš„è‡ªç¼–ç å™¨ä¸­æå‡å…¬å¹³æ€§</a></li>
    <li><a href="#44-ultra-high-definition-reference-based-landmark-image-super-resolution-with-generative-diffusion-prior--44-åŸºäºå‚è€ƒçš„è¶…é«˜æ¸…åœ°æ ‡å›¾åƒè¶…åˆ†è¾¨ç‡é‡‡ç”¨ç”Ÿæˆæ‰©æ•£å…ˆéªŒ"><a href="https://arxiv.org/abs/2508.10779">#44</a> <a href="https://papers.cool/arxiv/2508.10779">Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior</a>  #44 åŸºäºå‚è€ƒçš„è¶…é«˜æ¸…åœ°æ ‡å›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œé‡‡ç”¨ç”Ÿæˆæ‰©æ•£å…ˆéªŒ</a></li>
    <li><a href="#45-estimating-covariance-for-global-minimum-variance-portfolio-a-decision-focused-learning-approach--45-ä¼°è®¡å…¨å±€æœ€å°æ–¹å·®ç»„åˆçš„åæ–¹å·®ä¸€ç§ä»¥å†³ç­–ä¸ºä¸­å¿ƒçš„å­¦ä¹ æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10776">#45</a> <a href="https://papers.cool/arxiv/2508.10776">Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach</a>  #45 ä¼°è®¡å…¨å±€æœ€å°æ–¹å·®ç»„åˆçš„åæ–¹å·®ï¼šä¸€ç§ä»¥å†³ç­–ä¸ºä¸­å¿ƒçš„å­¦ä¹ æ–¹æ³•</a></li>
    <li><a href="#46-video-blade-block-sparse-attention-meets-step-distillation-for-efficient-video-generation--46-video-bladeå—ç¨€ç–æ³¨æ„åŠ›é‡ä¸Šæ­¥è’¸é¦ä»¥å®ç°é«˜æ•ˆè§†é¢‘ç”Ÿæˆ"><a href="https://arxiv.org/abs/2508.10774">#46</a> <a href="https://papers.cool/arxiv/2508.10774">Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation</a>  #46 Video-BLADEï¼šå—ç¨€ç–æ³¨æ„åŠ›é‡ä¸Šæ­¥è’¸é¦ä»¥å®ç°é«˜æ•ˆè§†é¢‘ç”Ÿæˆ</a></li>
    <li><a href="#47-aegis-authenticity-evaluation-benchmark-for-ai-generated-video-sequences--47-aegisç”¨äº-ai-ç”Ÿæˆè§†é¢‘åºåˆ—çœŸå®æ€§è¯„ä¼°çš„åŸºå‡†"><a href="https://arxiv.org/abs/2508.10771">#47</a> <a href="https://papers.cool/arxiv/2508.10771">AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences</a>  #47 AEGISï¼šç”¨äº AI ç”Ÿæˆè§†é¢‘åºåˆ—çœŸå®æ€§è¯„ä¼°çš„åŸºå‡†</a></li>
    <li><a href="#48-frogent-an-end-to-end-full-process-drug-design-agent--48-frogentä¸€ä¸ªç«¯åˆ°ç«¯å…¨æµç¨‹è¯ç‰©è®¾è®¡ä»£ç†"><a href="https://arxiv.org/abs/2508.10760">#48</a> <a href="https://papers.cool/arxiv/2508.10760">FROGENT: An End-to-End Full-process Drug Design Agent</a>  #48 FROGENTï¼šä¸€ä¸ªç«¯åˆ°ç«¯å…¨æµç¨‹è¯ç‰©è®¾è®¡ä»£ç†</a></li>
    <li><a href="#49-natively-trainable-sparse-attention-for-hierarchical-point-cloud-datasets--49-åŸç”Ÿå¯è®­ç»ƒç¨€ç–æ³¨æ„åŠ›ç”¨äºåˆ†å±‚ç‚¹äº‘æ•°æ®é›†"><a href="https://arxiv.org/abs/2508.10758">#49</a> <a href="https://papers.cool/arxiv/2508.10758">Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets</a>  #49 åŸç”Ÿå¯è®­ç»ƒç¨€ç–æ³¨æ„åŠ›ç”¨äºåˆ†å±‚ç‚¹äº‘æ•°æ®é›†</a></li>
    <li><a href="#50-passk-training-for-adaptively-balancing-exploration-and-exploitation-of-large-reasoning-models--50-åœ¨é€‚åº”æ€§å¹³è¡¡å¤§å‹æ¨ç†æ¨¡å‹çš„æ¢ç´¢ä¸åˆ©ç”¨æ–¹é¢è¿›è¡Œçš„-passk-è®­ç»ƒ-pdf-13--copy-kimi-10--rel"><a href="https://arxiv.org/abs/2508.10751">#50</a> <a href="https://papers.cool/arxiv/2508.10751">Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models</a>  #50 åœ¨é€‚åº”æ€§å¹³è¡¡å¤§å‹æ¨ç†æ¨¡å‹çš„æ¢ç´¢ä¸åˆ©ç”¨æ–¹é¢è¿›è¡Œçš„ Pass@k è®­ç»ƒ [PDF 13 ] [Copy] [Kimi 10 ] [REL]</a></li>
    <li><a href="#51-apfl-analytic-personalized-federated-learning-via-dual-stream-least-squares--51-apflé€šè¿‡åŒæµæœ€å°äºŒä¹˜çš„è§£æä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10732">#51</a> <a href="https://papers.cool/arxiv/2508.10732">APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares</a>  #51 APFLï¼šé€šè¿‡åŒæµæœ€å°äºŒä¹˜çš„è§£æä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ </a></li>
    <li><a href="#52-egocross-benchmarking-multimodal-large-language-models-for-cross-domain-egocentric-video-question-answering--52-egocrossç”¨äºè·¨é¢†åŸŸç¬¬ä¸€äººç§°è§†é¢‘é—®ç­”çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•"><a href="https://arxiv.org/abs/2508.10729">#52</a> <a href="https://papers.cool/arxiv/2508.10729">EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering</a>  #52 EgoCrossï¼šç”¨äºè·¨é¢†åŸŸç¬¬ä¸€äººç§°è§†é¢‘é—®ç­”çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•</a></li>
    <li><a href="#53-electromagnetic-simulations-of-antennas-on-gpus-for-machine-learning-applications--53-ç”¨äºæœºå™¨å­¦ä¹ åº”ç”¨çš„-gpu-å¤©çº¿ç”µç£ä»¿çœŸ"><a href="https://arxiv.org/abs/2508.10713">#53</a> <a href="https://papers.cool/arxiv/2508.10713">Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications</a>  #53 ç”¨äºæœºå™¨å­¦ä¹ åº”ç”¨çš„ GPU å¤©çº¿ç”µç£ä»¿çœŸ</a></li>
    <li><a href="#54-refn-a-reinforcement-learning-from-network-framework-against-1-dayn-day-exploitations--54-refnä¸€ç§é’ˆå¯¹-1-å¤©å¤šå¤©åˆ©ç”¨çš„æ¥è‡ªç½‘ç»œçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10701">#54</a> <a href="https://papers.cool/arxiv/2508.10701">REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations</a>  #54 REFNï¼šä¸€ç§é’ˆå¯¹ 1 å¤©/å¤šå¤©åˆ©ç”¨çš„æ¥è‡ªç½‘ç»œçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶</a></li>
    <li><a href="#55-learning-from-natural-language-feedback-for-personalized-question-answering--55-ä»è‡ªç„¶è¯­è¨€åé¦ˆä¸­å­¦ä¹ ä»¥å®ç°ä¸ªæ€§åŒ–é—®ç­”"><a href="https://arxiv.org/abs/2508.10695">#55</a> <a href="https://papers.cool/arxiv/2508.10695">Learning from Natural Language Feedback for Personalized Question Answering</a>  #55 ä»è‡ªç„¶è¯­è¨€åé¦ˆä¸­å­¦ä¹ ä»¥å®ç°ä¸ªæ€§åŒ–é—®ç­”</a></li>
    <li><a href="#56-continuous-bangla-sign-language-translation-mitigating-the-expense-of-gloss-annotation-with-the-assistance-of-graph--56-è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘åœ¨å›¾ç»“æ„è¾…åŠ©ä¸‹ç¼“è§£æ³¨é‡Šæ‰‹è¯­è¯æ±‡glossæˆæœ¬"><a href="https://arxiv.org/abs/2508.10687">#56</a> <a href="https://papers.cool/arxiv/2508.10687">Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph</a>  #56 è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘ï¼šåœ¨å›¾ç»“æ„è¾…åŠ©ä¸‹ç¼“è§£æ³¨é‡Šæ‰‹è¯­è¯æ±‡ï¼ˆglossï¼‰æˆæœ¬</a></li>
    <li><a href="#57-hybrid-generative-fusion-for-efficient-and-privacy-preserving-face-recognition-dataset-generation--57-æ··åˆç”Ÿæˆèåˆç”¨äºé«˜æ•ˆä¸”éšç§ä¿æŠ¤çš„äººè„¸è¯†åˆ«æ•°æ®é›†ç”Ÿæˆ"><a href="https://arxiv.org/abs/2508.10672">#57</a> <a href="https://papers.cool/arxiv/2508.10672">Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation</a>  #57 æ··åˆç”Ÿæˆèåˆç”¨äºé«˜æ•ˆä¸”éšç§ä¿æŠ¤çš„äººè„¸è¯†åˆ«æ•°æ®é›†ç”Ÿæˆ</a></li>
    <li><a href="#58-addressvlm-cross-view-alignment-tuning-for-image-address-localization-using-large-vision-language-models--58-addressvlmç”¨äºå›¾åƒåœ°å€å®šä½çš„å¤§å‹è§†å¬è¯­è¨€æ¨¡å‹çš„è·¨è§†å›¾å¯¹é½å¾®è°ƒ"><a href="https://arxiv.org/abs/2508.10667">#58</a> <a href="https://papers.cool/arxiv/2508.10667">AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models</a>  #58 AddressVLMï¼šç”¨äºå›¾åƒåœ°å€å®šä½çš„å¤§å‹è§†å¬è¯­è¨€æ¨¡å‹çš„è·¨è§†å›¾å¯¹é½å¾®è°ƒ</a></li>
    <li><a href="#59-deep-learning-in-classical-and-quantum-physics--59-ç»å…¸ä¸é‡å­ç‰©ç†ä¸­çš„æ·±åº¦å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10666">#59</a> <a href="https://papers.cool/arxiv/2508.10666">Deep Learning in Classical and Quantum Physics</a>  #59 ç»å…¸ä¸é‡å­ç‰©ç†ä¸­çš„æ·±åº¦å­¦ä¹ </a></li>
    <li><a href="#60-serial-over-parallel-learning-continual-unification-for-multi-modal-visual-object-tracking-and-benchmarking--60-ä¸²è¡Œèƒœè¿‡å¹¶è¡Œä¸ºå¤šæ¨¡æ€è§†è§‰ç›®æ ‡è·Ÿè¸ªå­¦ä¹ æŒç»­ç»Ÿä¸€ä¸åŸºå‡†è¯„ä¼°"><a href="https://arxiv.org/abs/2508.10655">#60</a> <a href="https://papers.cool/arxiv/2508.10655">Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking</a>  #60 ä¸²è¡Œèƒœè¿‡å¹¶è¡Œï¼šä¸ºå¤šæ¨¡æ€è§†è§‰ç›®æ ‡è·Ÿè¸ªå­¦ä¹ æŒç»­ç»Ÿä¸€ä¸åŸºå‡†è¯„ä¼°</a></li>
    <li><a href="#61-sphenic-topology-informed-multi-view-clustering-for-spatial-transcriptomics--61-sphenic-åŸºäºæ‹“æ‰‘ä¿¡æ¯çš„ç©ºé—´è½¬å½•ç»„å¤šè§†å›¾èšç±»"><a href="https://arxiv.org/abs/2508.10646">#61</a> <a href="https://papers.cool/arxiv/2508.10646">SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics</a>  #61 SPHENIC: åŸºäºæ‹“æ‰‘ä¿¡æ¯çš„ç©ºé—´è½¬å½•ç»„å¤šè§†å›¾èšç±»</a></li>
    <li><a href="#62-fourier-guided-attention-upsampling-for-image-super-resolution--62-å‚…é‡Œå¶å¼•å¯¼æ³¨æ„åŠ›ä¸Šé‡‡æ ·ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡"><a href="https://arxiv.org/abs/2508.10616">#62</a> <a href="https://papers.cool/arxiv/2508.10616">Fourier-Guided Attention Upsampling for Image Super-Resolution</a>  #62 å‚…é‡Œå¶å¼•å¯¼æ³¨æ„åŠ›ä¸Šé‡‡æ ·ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡</a></li>
    <li><a href="#63-on-spectral-properties-of-gradient-based-explanation-methods--63-å…³äºåŸºäºæ¢¯åº¦çš„è§£é‡Šæ–¹æ³•çš„è°±æ€§è´¨"><a href="https://arxiv.org/abs/2508.10595">#63</a> <a href="https://papers.cool/arxiv/2508.10595">On Spectral Properties of Gradient-based Explanation Methods</a>  #63 å…³äºåŸºäºæ¢¯åº¦çš„è§£é‡Šæ–¹æ³•çš„è°±æ€§è´¨</a></li>
    <li><a href="#64-freegad-a-training-free-yet-effective-approach-for-graph-anomaly-detection--64-freegadä¸€ç§æ— éœ€è®­ç»ƒä½†æœ‰æ•ˆçš„å›¾å¼‚å¸¸æ£€æµ‹æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10594">#64</a> <a href="https://papers.cool/arxiv/2508.10594">FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection</a>  #64 FreeGADï¼šä¸€ç§æ— éœ€è®­ç»ƒä½†æœ‰æ•ˆçš„å›¾å¼‚å¸¸æ£€æµ‹æ–¹æ³•</a></li>
    <li><a href="#65-fake-speech-wild-detecting-deepfake-speech-on-social-media-platform--65-å‡è¯­ç‹‚æ½®åœ¨ç¤¾äº¤åª’ä½“å¹³å°ä¸Šæ£€æµ‹è¯­éŸ³æ·±åº¦ä¼ªé€ "><a href="https://arxiv.org/abs/2508.10559">#65</a> <a href="https://papers.cool/arxiv/2508.10559">Fake Speech Wild: Detecting Deepfake Speech on Social Media Platform</a>  #65 å‡è¯­ç‹‚æ½®ï¼šåœ¨ç¤¾äº¤åª’ä½“å¹³å°ä¸Šæ£€æµ‹è¯­éŸ³æ·±åº¦ä¼ªé€ </a></li>
    <li><a href="#66-ptqat-a-hybrid-parameter-efficient-quantization-algorithm-for-3d-perception-tasks--66-ptqatä¸€ç§ç”¨äºä¸‰ç»´æ„ŸçŸ¥ä»»åŠ¡çš„æ··åˆå‚æ•°é«˜æ•ˆé‡åŒ–ç®—æ³•"><a href="https://arxiv.org/abs/2508.10557">#66</a> <a href="https://papers.cool/arxiv/2508.10557">PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks</a>  #66 PTQATï¼šä¸€ç§ç”¨äºä¸‰ç»´æ„ŸçŸ¥ä»»åŠ¡çš„æ··åˆå‚æ•°é«˜æ•ˆé‡åŒ–ç®—æ³•</a></li>
    <li><a href="#67-retrieval-augmented-prompt-for-ood-detection--67-ç”¨äº-ood-æ£€æµ‹çš„æ£€ç´¢å¢å¼ºæç¤º"><a href="https://arxiv.org/abs/2508.10556">#67</a> <a href="https://papers.cool/arxiv/2508.10556">Retrieval-Augmented Prompt for OOD Detection</a>  #67 ç”¨äº OOD æ£€æµ‹çš„æ£€ç´¢å¢å¼ºæç¤º</a></li>
    <li><a href="#68-when-language-overrules-revealing-text-dominance-in-multimodal-large-language-models--68-å½“è¯­è¨€å ä¸Šé£æ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ–‡æœ¬çš„ä¸»å¯¼åœ°ä½"><a href="https://arxiv.org/abs/2508.10552">#68</a> <a href="https://papers.cool/arxiv/2508.10552">When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models</a>  #68 å½“è¯­è¨€å ä¸Šé£ï¼šæ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ–‡æœ¬çš„ä¸»å¯¼åœ°ä½</a></li>
    <li><a href="#69-stabilizing-long-term-multi-turn-reinforcement-learning-with-gated-rewards--69-ç”¨é—¨æ§å¥–åŠ±ç¨³å®šé•¿æœŸå¤šè½®å¼ºåŒ–å­¦ä¹ -pdf-3--copy-kimi-1--rel"><a href="https://arxiv.org/abs/2508.10548">#69</a> <a href="https://papers.cool/arxiv/2508.10548">Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards</a>  #69 ç”¨é—¨æ§å¥–åŠ±ç¨³å®šé•¿æœŸå¤šè½®å¼ºåŒ–å­¦ä¹  [PDF 3 ] [Copy] [Kimi 1 ] [REL]</a></li>
    <li><a href="#70-med-glip-advancing-medical-language-image-pre-training-with-large-scale-grounded-dataset--70-med-glipé€šè¿‡å¤§è§„æ¨¡å¸¦å®šä½æ•°æ®é›†æ¨è¿›åŒ»å­¦è¯­è¨€-å›¾åƒé¢„è®­ç»ƒ"><a href="https://arxiv.org/abs/2508.10528">#70</a> <a href="https://papers.cool/arxiv/2508.10528">Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset</a>  #70 Med-GLIPï¼šé€šè¿‡å¤§è§„æ¨¡å¸¦å®šä½æ•°æ®é›†æ¨è¿›åŒ»å­¦è¯­è¨€-å›¾åƒé¢„è®­ç»ƒ</a></li>
    <li><a href="#71-multi-sample-anti-aliasing-and-constrained-optimization-for-3d-gaussian-splatting--71-å¤šæ ·æœ¬æŠ—é”¯é½¿ä¸å—çº¦æŸä¼˜åŒ–ç”¨äºä¸‰ç»´é«˜æ–¯ç‚¹æ¸²æŸ“"><a href="https://arxiv.org/abs/2508.10507">#71</a> <a href="https://papers.cool/arxiv/2508.10507">Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting</a>  #71 å¤šæ ·æœ¬æŠ—é”¯é½¿ä¸å—çº¦æŸä¼˜åŒ–ç”¨äºä¸‰ç»´é«˜æ–¯ç‚¹æ¸²æŸ“</a></li>
    <li><a href="#72-advances-in-logic-based-entity-resolution-enhancing-aspen-with-local-merges-and-optimality-criteria--72-åŸºäºé€»è¾‘çš„å®ä½“æ¶ˆè§£è¿›å±•é€šè¿‡å±€éƒ¨åˆå¹¶å’Œæœ€ä¼˜æ€§å‡†åˆ™å¢å¼º-aspen"><a href="https://arxiv.org/abs/2508.10504">#72</a> <a href="https://papers.cool/arxiv/2508.10504">Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria</a>  #72 åŸºäºé€»è¾‘çš„å®ä½“æ¶ˆè§£è¿›å±•ï¼šé€šè¿‡å±€éƒ¨åˆå¹¶å’Œæœ€ä¼˜æ€§å‡†åˆ™å¢å¼º ASPEN</a></li>
    <li><a href="#73-a-unified-multi-agent-framework-for-universal-multimodal-understanding-and-generation--73-ä¸€ä¸ªç”¨äºé€šç”¨å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ™ºèƒ½ä½“æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10494">#73</a> <a href="https://papers.cool/arxiv/2508.10494">A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation</a>  #73 ä¸€ä¸ªç”¨äºé€šç”¨å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ™ºèƒ½ä½“æ¡†æ¶</a></li>
    <li><a href="#74-contrastive-ecoc-learning-output-codes-for-adversarial-defense--74-contrastive-ecocä¸ºå¯¹æŠ—æ€§é˜²å¾¡å­¦ä¹ è¾“å‡ºç "><a href="https://arxiv.org/abs/2508.10491">#74</a> <a href="https://papers.cool/arxiv/2508.10491">Contrastive ECOC: Learning Output Codes for Adversarial Defense</a>  #74 Contrastive ECOCï¼šä¸ºå¯¹æŠ—æ€§é˜²å¾¡å­¦ä¹ è¾“å‡ºç </a></li>
    <li><a href="#75-on-the-complexity-faithfulness-trade-off-of-gradient-based-explanations--75-å…³äºåŸºäºæ¢¯åº¦çš„è§£é‡Šçš„å¤æ‚æ€§-å¿ å®æ€§æƒè¡¡-pdf--å‰¯æœ¬-kimi--rel"><a href="https://arxiv.org/abs/2508.10490">#75</a> <a href="https://papers.cool/arxiv/2508.10490">On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations</a>  #75 å…³äºåŸºäºæ¢¯åº¦çš„è§£é‡Šçš„å¤æ‚æ€§-å¿ å®æ€§æƒè¡¡ [PDF ] [å‰¯æœ¬] [Kimi ] [REL]</a></li>
    <li><a href="#76-pinet-optimizing-hard-constrained-neural-networks-with-orthogonal-projection-layers--76-pinetä½¿ç”¨æ­£äº¤æŠ•å½±å±‚ä¼˜åŒ–ç¡¬çº¦æŸç¥ç»ç½‘ç»œ-pdf--copy-kimi-1--rel"><a href="https://arxiv.org/abs/2508.10480">#76</a> <a href="https://papers.cool/arxiv/2508.10480">Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers</a>  #76 Pinetï¼šä½¿ç”¨æ­£äº¤æŠ•å½±å±‚ä¼˜åŒ–ç¡¬çº¦æŸç¥ç»ç½‘ç»œ [PDF ] [Copy] [Kimi 1 ] [REL]</a></li>
    <li><a href="#77-enhanced-sparse-point-cloud-data-processing-for-privacy-aware-human-action-recognition--77-å¢å¼ºçš„ç¨€ç–ç‚¹äº‘æ•°æ®å¤„ç†ç”¨äºæ³¨é‡éšç§çš„äººä½“åŠ¨ä½œè¯†åˆ«"><a href="https://arxiv.org/abs/2508.10469">#77</a> <a href="https://papers.cool/arxiv/2508.10469">Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition</a>  #77 å¢å¼ºçš„ç¨€ç–ç‚¹äº‘æ•°æ®å¤„ç†ç”¨äºæ³¨é‡éšç§çš„äººä½“åŠ¨ä½œè¯†åˆ«</a></li>
    <li><a href="#78-x-node-self-explanation-is-all-we-need--78-x-nodeè‡ªæˆ‘è§£é‡Šå°±æ˜¯æˆ‘ä»¬æ‰€éœ€çš„ä¸€åˆ‡"><a href="https://arxiv.org/abs/2508.10461">#78</a> <a href="https://papers.cool/arxiv/2508.10461">X-Node: Self-Explanation is All We Need</a>  #78 X-Nodeï¼šè‡ªæˆ‘è§£é‡Šå°±æ˜¯æˆ‘ä»¬æ‰€éœ€çš„ä¸€åˆ‡</a></li>
    <li><a href="#79-realac-a-domain-agnostic-framework-for-realistic-and-actionable-counterfactual-explanations--79-realac-ä¸€ä¸ªé¢†åŸŸæ— å…³çš„æ¡†æ¶ç”¨äºç”ŸæˆçœŸå®ä¸”å¯æ“ä½œçš„åäº‹å®è§£é‡Š-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10455">#79</a> <a href="https://papers.cool/arxiv/2508.10455">RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations</a>  #79 RealAC: ä¸€ä¸ªé¢†åŸŸæ— å…³çš„æ¡†æ¶ï¼Œç”¨äºç”ŸæˆçœŸå®ä¸”å¯æ“ä½œçš„åäº‹å®è§£é‡Š [PDF ] [Copy] [Kimi ] [REL]</a></li>
    <li><a href="#80-alternating-approach-putt-models-for-multi-stage-speech-enhancement--80-äº¤æ›¿ä¸Šåœº-æ¨æ†æ¨¡å‹ç”¨äºå¤šé˜¶æ®µè¯­éŸ³å¢å¼º"><a href="https://arxiv.org/abs/2508.10436">#80</a> <a href="https://papers.cool/arxiv/2508.10436">Alternating Approach-Putt Models for Multi-Stage Speech Enhancement</a>  #80 äº¤æ›¿â€œä¸Šåœº-æ¨æ†â€æ¨¡å‹ç”¨äºå¤šé˜¶æ®µè¯­éŸ³å¢å¼º</a></li>
    <li><a href="#81-unpacking-the-implicit-norm-dynamics-of-sharpness-aware-minimization-in-tensorized-models--81-è§£æ„å¼ é‡åŒ–æ¨¡å‹ä¸­é”åº¦æ„ŸçŸ¥æœ€å°åŒ–çš„éšå«èŒƒæ•°åŠ¨åŠ›å­¦"><a href="https://arxiv.org/abs/2508.10435">#81</a> <a href="https://papers.cool/arxiv/2508.10435">Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models</a>  #81 è§£æ„å¼ é‡åŒ–æ¨¡å‹ä¸­é”åº¦æ„ŸçŸ¥æœ€å°åŒ–çš„éšå«èŒƒæ•°åŠ¨åŠ›å­¦</a></li>
    <li><a href="#82-mash-cooperative-heterogeneous-multi-agent-reinforcement-learning-for-single-humanoid-robot-locomotion--82-mashç”¨äºå•äººå½¢æœºå™¨äººè¡Œèµ°çš„åä½œå¼‚è´¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10423">#82</a> <a href="https://papers.cool/arxiv/2508.10423">MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion</a>  #82 MASHï¼šç”¨äºå•äººå½¢æœºå™¨äººè¡Œèµ°çš„åä½œå¼‚è´¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ </a></li>
    <li><a href="#83-comorag-a-cognitive-inspired-memory-organized-rag-for-stateful-long-narrative-reasoning--83-comoragä¸€ç§å—è®¤çŸ¥å¯å‘çš„è®°å¿†ç»„ç»‡å¼-ragç”¨äºæœ‰çŠ¶æ€çš„é•¿å™äº‹æ¨ç†"><a href="https://arxiv.org/abs/2508.10419">#83</a> <a href="https://papers.cool/arxiv/2508.10419">ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning</a>  #83 ComoRAGï¼šä¸€ç§å—è®¤çŸ¥å¯å‘çš„è®°å¿†ç»„ç»‡å¼ RAGï¼Œç”¨äºæœ‰çŠ¶æ€çš„é•¿å™äº‹æ¨ç†</a></li>
    <li><a href="#84-correctnav-self-correction-flywheel-empowers-vision-language-action-navigation-model--84-correctnavè‡ªæˆ‘ä¿®æ­£é£è½®èµ‹èƒ½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨å¯¼èˆªæ¨¡å‹"><a href="https://arxiv.org/abs/2508.10416">#84</a> <a href="https://papers.cool/arxiv/2508.10416">CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model</a>  #84 CorrectNavï¼šè‡ªæˆ‘ä¿®æ­£é£è½®èµ‹èƒ½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨å¯¼èˆªæ¨¡å‹</a></li>
    <li><a href="#85-mcp2osc-parametric-control-by-natural-language--85-mcp2oscé€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œå‚æ•°åŒ–æ§åˆ¶"><a href="https://arxiv.org/abs/2508.10414">#85</a> <a href="https://papers.cool/arxiv/2508.10414">MCP2OSC: Parametric Control by Natural Language</a>  #85 MCP2OSCï¼šé€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œå‚æ•°åŒ–æ§åˆ¶</a></li>
    <li><a href="#86-analogseeker-an-open-source-foundation-language-model-for-analog-circuit-design--86-analogseekerä¸€ä¸ªç”¨äºæ¨¡æ‹Ÿç”µè·¯è®¾è®¡çš„å¼€æºåŸºç¡€è¯­è¨€æ¨¡å‹"><a href="https://arxiv.org/abs/2508.10409">#86</a> <a href="https://papers.cool/arxiv/2508.10409">AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design</a>  #86 AnalogSeekerï¼šä¸€ä¸ªç”¨äºæ¨¡æ‹Ÿç”µè·¯è®¾è®¡çš„å¼€æºåŸºç¡€è¯­è¨€æ¨¡å‹</a></li>
    <li><a href="#87-layer-wise-perturbations-via-sparse-autoencoders-for-adversarial-text-generation--87-é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œé€å±‚æ‰°åŠ¨ä»¥ç”¨äºå¯¹æŠ—æ€§æ–‡æœ¬ç”Ÿæˆ"><a href="https://arxiv.org/abs/2508.10404">#87</a> <a href="https://papers.cool/arxiv/2508.10404">Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation</a>  #87 é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œé€å±‚æ‰°åŠ¨ä»¥ç”¨äºå¯¹æŠ—æ€§æ–‡æœ¬ç”Ÿæˆ</a></li>
    <li><a href="#88-pq-daf-pose-driven-quality-controlled-data-augmentation-for-data-scarce-driver-distraction-detection--88-pq-dafåŸºäºå§¿æ€çš„è´¨é‡å¯æ§æ•°æ®å¢å¼ºç”¨äºæ•°æ®ç¨€ç¼ºçš„é©¾é©¶å‘˜åˆ†å¿ƒæ£€æµ‹"><a href="https://arxiv.org/abs/2508.10397">#88</a> <a href="https://papers.cool/arxiv/2508.10397">PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection</a>  #88 PQ-DAFï¼šåŸºäºå§¿æ€çš„è´¨é‡å¯æ§æ•°æ®å¢å¼ºç”¨äºæ•°æ®ç¨€ç¼ºçš„é©¾é©¶å‘˜åˆ†å¿ƒæ£€æµ‹</a></li>
    <li><a href="#89-unlocking-robust-semantic-segmentation-performance-via-label-only-elastic-deformations-against-implicit-label-noise--89-é€šè¿‡ä»…æ ‡ç­¾çš„å¼¹æ€§å½¢å˜å¯¹æŠ—éšå«æ ‡ç­¾å™ªå£°ä»¥è§£é”ç¨³å¥è¯­ä¹‰åˆ†å‰²æ€§èƒ½"><a href="https://arxiv.org/abs/2508.10383">#89</a> <a href="https://papers.cool/arxiv/2508.10383">Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise</a>  #89 é€šè¿‡ä»…æ ‡ç­¾çš„å¼¹æ€§å½¢å˜å¯¹æŠ—éšå«æ ‡ç­¾å™ªå£°ä»¥è§£é”ç¨³å¥è¯­ä¹‰åˆ†å‰²æ€§èƒ½</a></li>
    <li><a href="#90-emamba-efficient-acceleration-framework-for-mamba-models-in-edge-computing--90-emambaé¢å‘è¾¹ç¼˜è®¡ç®—çš„-mamba-æ¨¡å‹é«˜æ•ˆåŠ é€Ÿæ¡†æ¶"><a href="https://arxiv.org/abs/2508.10370">#90</a> <a href="https://papers.cool/arxiv/2508.10370">eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing</a>  #90 eMambaï¼šé¢å‘è¾¹ç¼˜è®¡ç®—çš„ Mamba æ¨¡å‹é«˜æ•ˆåŠ é€Ÿæ¡†æ¶</a></li>
    <li><a href="#91-welfare-centric-clustering--91-ä»¥ç¦åˆ©ä¸ºä¸­å¿ƒçš„èšç±»"><a href="https://arxiv.org/abs/2508.10345">#91</a> <a href="https://papers.cool/arxiv/2508.10345">Welfare-Centric Clustering</a>  #91 ä»¥ç¦åˆ©ä¸ºä¸­å¿ƒçš„èšç±»</a></li>
    <li><a href="#92-layer-wise-analysis-of-self-supervised-representations-for-age-and-gender-classification-in-children39s-speech--92-é¢å‘å„¿ç«¥è¯­éŸ³å¹´é¾„å’Œæ€§åˆ«åˆ†ç±»çš„è‡ªç›‘ç£è¡¨ç¤ºçš„é€å±‚åˆ†æ"><a href="https://arxiv.org/abs/2508.10332">#92</a> <a href="https://papers.cool/arxiv/2508.10332">Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech</a>  #92 é¢å‘å„¿ç«¥è¯­éŸ³å¹´é¾„å’Œæ€§åˆ«åˆ†ç±»çš„è‡ªç›‘ç£è¡¨ç¤ºçš„é€å±‚åˆ†æ</a></li>
    <li><a href="#93-a-vision-language-pre-training-model-guided-approach-for-mitigating-backdoor-attacks-in-federated-learning--93-ä¸€ç§ç”±è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹æŒ‡å¯¼çš„è”é‚¦å­¦ä¹ åé—¨æ”»å‡»ç¼“è§£æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10315">#93</a> <a href="https://papers.cool/arxiv/2508.10315">A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning</a>  #93 ä¸€ç§ç”±è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹æŒ‡å¯¼çš„è”é‚¦å­¦ä¹ åé—¨æ”»å‡»ç¼“è§£æ–¹æ³•</a></li>
    <li><a href="#94-reviewrl-towards-automated-scientific-review-with-rl--94-reviewrlè¿ˆå‘ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç§‘å­¦è¯„å®¡"><a href="https://arxiv.org/abs/2508.10308">#94</a> <a href="https://papers.cool/arxiv/2508.10308">ReviewRL: Towards Automated Scientific Review with RL</a>  #94 ReviewRLï¼šè¿ˆå‘ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç§‘å­¦è¯„å®¡</a></li>
    <li><a href="#95-yet-another-algorithmic-bias-a-discursive-analysis-of-large-language-models-reinforcing-dominant-discourses-on-gender-and-race--95-åˆä¸€ä¾‹ç®—æ³•åè§å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åŠ å¼ºå…³äºæ€§åˆ«ä¸ç§æ—æ”¯é…æ€§è¯è¯­çš„è®ºè¿°åˆ†æ-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10304">#95</a> <a href="https://papers.cool/arxiv/2508.10304">Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race</a>  #95 åˆä¸€ä¾‹ç®—æ³•åè§ï¼šå¯¹å¤§å‹è¯­è¨€æ¨¡å‹åŠ å¼ºå…³äºæ€§åˆ«ä¸ç§æ—æ”¯é…æ€§è¯è¯­çš„è®ºè¿°åˆ†æ [PDF ] [Copy] [Kimi ] [REL]</a></li>
    <li><a href="#96-pose-robust-calibration-strategy-for-point-of-gaze-estimation-on-mobile-phones--96-é¢å‘æ‰‹æœºè§†çº¿ç‚¹ä¼°è®¡çš„å§¿æ€é²æ£’æ ¡å‡†ç­–ç•¥"><a href="https://arxiv.org/abs/2508.10268">#96</a> <a href="https://papers.cool/arxiv/2508.10268">Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones</a>  #96 é¢å‘æ‰‹æœºè§†çº¿ç‚¹ä¼°è®¡çš„å§¿æ€é²æ£’æ ¡å‡†ç­–ç•¥</a></li>
    <li><a href="#97-mrfd-multi-region-fusion-decoding-with-self-consistency-for-mitigating-hallucinations-in-lvlms--97-mrfdå…·æœ‰è‡ªæ´½æ€§çš„å¤šåŒºåŸŸèåˆè§£ç ä»¥å‡è½»å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹lvlmsä¸­çš„è™šæ„é—®é¢˜"><a href="https://arxiv.org/abs/2508.10264">#97</a> <a href="https://papers.cool/arxiv/2508.10264">MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs</a>  #97 MRFDï¼šå…·æœ‰è‡ªæ´½æ€§çš„å¤šåŒºåŸŸèåˆè§£ç ä»¥å‡è½»å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰ä¸­çš„è™šæ„é—®é¢˜</a></li>
    <li><a href="#98-dinomotion-advanced-robust-tissue-motion-tracking-with-dinov2-in-2d-cine-mri-guided-radiotherapy--98-dinomotionåœ¨-2d-cine-mri-å¼•å¯¼æ”¾ç–—ä¸­ä½¿ç”¨-dinov2-è¿›è¡Œå…ˆè¿›çš„ç¨³å¥ç»„ç»‡è¿åŠ¨è·Ÿè¸ª"><a href="https://arxiv.org/abs/2508.10260">#98</a> <a href="https://papers.cool/arxiv/2508.10260">DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy</a>  #98 DINOMotionï¼šåœ¨ 2D Cine MRI å¼•å¯¼æ”¾ç–—ä¸­ä½¿ç”¨ DINOv2 è¿›è¡Œå…ˆè¿›çš„ç¨³å¥ç»„ç»‡è¿åŠ¨è·Ÿè¸ª</a></li>
    <li><a href="#99-facilitating-longitudinal-interaction-studies-of-ai-systems--99-ä¿ƒè¿›äººå·¥æ™ºèƒ½ç³»ç»Ÿçºµå‘äº¤äº’ç ”ç©¶"><a href="https://arxiv.org/abs/2508.10252">#99</a> <a href="https://papers.cool/arxiv/2508.10252">Facilitating Longitudinal Interaction Studies of AI Systems</a>  #99 ä¿ƒè¿›äººå·¥æ™ºèƒ½ç³»ç»Ÿçºµå‘äº¤äº’ç ”ç©¶</a></li>
    <li><a href="#100-no-free-lunch-from-audio-pretraining-in-bioacoustics-a-benchmark-study-of-embeddings--100-æ¥è‡ªéŸ³é¢‘é¢„è®­ç»ƒåœ¨ç”Ÿç‰©å£°å­¦ä¸­å¹¶éä¸‡èƒ½åµŒå…¥åŸºå‡†ç ”ç©¶"><a href="https://arxiv.org/abs/2508.10230">#100</a> <a href="https://papers.cool/arxiv/2508.10230">No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings</a>  #100 æ¥è‡ªéŸ³é¢‘é¢„è®­ç»ƒåœ¨ç”Ÿç‰©å£°å­¦ä¸­å¹¶éä¸‡èƒ½ï¼šåµŒå…¥åŸºå‡†ç ”ç©¶</a></li>
    <li><a href="#101-using-large-language-models-to-measure-symptom-severity-in-patients-at-risk-for-schizophrenia--101-ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æœ‰ç²¾ç¥åˆ†è£‚ç—‡é£é™©æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦"><a href="https://arxiv.org/abs/2508.10226">#101</a> <a href="https://papers.cool/arxiv/2508.10226">Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia</a>  #101 ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æœ‰ç²¾ç¥åˆ†è£‚ç—‡é£é™©æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦</a></li>
    <li><a href="#102-understanding-textual-emotion-through-emoji-prediction--102-é€šè¿‡è¡¨æƒ…ç¬¦å·é¢„æµ‹ç†è§£æ–‡æœ¬æƒ…ç»ª"><a href="https://arxiv.org/abs/2508.10222">#102</a> <a href="https://papers.cool/arxiv/2508.10222">Understanding Textual Emotion Through Emoji Prediction</a>  #102 é€šè¿‡è¡¨æƒ…ç¬¦å·é¢„æµ‹ç†è§£æ–‡æœ¬æƒ…ç»ª</a></li>
    <li><a href="#103-an-explainable-ai-based-approach-for-monitoring-animal-health--103-åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½çš„åŠ¨ç‰©å¥åº·ç›‘æµ‹æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10210">#103</a> <a href="https://papers.cool/arxiv/2508.10210">An Explainable AI based approach for Monitoring Animal Health</a>  #103 åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½çš„åŠ¨ç‰©å¥åº·ç›‘æµ‹æ–¹æ³•</a></li>
    <li><a href="#104-catnet-a-geometric-deep-learning-approach-for-cat-bond-spread-prediction-in-the-primary-market--104-catnetä¸€ç§ç”¨äºåˆçº§å¸‚åœº-cat-å€ºåˆ¸åˆ©å·®é¢„æµ‹çš„å‡ ä½•æ·±åº¦å­¦ä¹ æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10208">#104</a> <a href="https://papers.cool/arxiv/2508.10208">CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market</a>  #104 CATNetï¼šä¸€ç§ç”¨äºåˆçº§å¸‚åœº CAT å€ºåˆ¸åˆ©å·®é¢„æµ‹çš„å‡ ä½•æ·±åº¦å­¦ä¹ æ–¹æ³•</a></li>
    <li><a href="#105-prompt-response-semantic-divergence-metrics-for-faithfulness-hallucination-and-misalignment-detection-in-large-language-models--105-æç¤º-å“åº”è¯­ä¹‰åç¦»åº¦é‡ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¿ å®æ€§å¹»è§‰å’Œä¸å¯¹é½æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10192">#105</a> <a href="https://papers.cool/arxiv/2508.10192">Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models</a>  #105 æç¤º-å“åº”è¯­ä¹‰åç¦»åº¦é‡ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¿ å®æ€§å¹»è§‰å’Œä¸å¯¹é½æ£€æµ‹</a></li>
    <li><a href="#106-pakbbq-a-culturally-adapted-bias-benchmark-for-qa--106-pakbbqé’ˆå¯¹é—®ç­”çš„æ–‡åŒ–é€‚é…åè§åŸºå‡†"><a href="https://arxiv.org/abs/2508.10186">#106</a> <a href="https://papers.cool/arxiv/2508.10186">PakBBQ: A Culturally Adapted Bias Benchmark for QA</a>  #106 PakBBQï¼šé’ˆå¯¹é—®ç­”çš„æ–‡åŒ–é€‚é…åè§åŸºå‡†</a></li>
    <li><a href="#107-laajmeter-a-framework-for-laaj-evaluation--107-laajmeterç”¨äº-laaj-è¯„ä¼°çš„æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10161">#107</a> <a href="https://papers.cool/arxiv/2508.10161">LaajMeter: A Framework for LaaJ Evaluation</a>  #107 LaajMeterï¼šç”¨äº LaaJ è¯„ä¼°çš„æ¡†æ¶</a></li>
    <li><a href="#108-improving-watermelon-citrullus-lanatus-disease-classification-with-generative-artificial-intelligence-genai-based-synthetic-and-real-field-images-via-a-custom-efficientnetv2-l-model--108-ä½¿ç”¨åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½genaiçš„åˆæˆä¸çœŸå®ç”°é—´å›¾åƒé€šè¿‡å®šåˆ¶-efficientnetv2-l-æ¨¡å‹æ”¹è¿›è¥¿ç“œcitrullus-lanatusç—…å®³åˆ†ç±»"><a href="https://arxiv.org/abs/2508.10156">#108</a> <a href="https://papers.cool/arxiv/2508.10156">Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model</a>  #108 ä½¿ç”¨åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenAIï¼‰çš„åˆæˆä¸çœŸå®ç”°é—´å›¾åƒé€šè¿‡å®šåˆ¶ EfficientNetV2-L æ¨¡å‹æ”¹è¿›è¥¿ç“œï¼ˆCitrullus lanatusï¼‰ç—…å®³åˆ†ç±»</a></li>
    <li><a href="#109-out-of-distribution-detection-using-counterfactual-distance--109-ä½¿ç”¨åäº‹å®è·ç¦»çš„åˆ†å¸ƒå¤–æ£€æµ‹-pdf-1--å¤åˆ¶-kimi--å…³è”"><a href="https://arxiv.org/abs/2508.10148">#109</a> <a href="https://papers.cool/arxiv/2508.10148">Out-of-Distribution Detection using Counterfactual Distance</a>  #109 ä½¿ç”¨åäº‹å®è·ç¦»çš„åˆ†å¸ƒå¤–æ£€æµ‹ [PDF 1 ] [å¤åˆ¶] [Kimi ] [å…³è”]</a></li>
    <li><a href="#110-retf-semisl-semi-supervised-learning-for-neural-collapse-in-temporal-data--110-retf-semislç”¨äºæ—¶é—´æ•°æ®ä¸­ç¥ç»å¡Œç¼©çš„åŠç›‘ç£å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10147">#110</a> <a href="https://papers.cool/arxiv/2508.10147">rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data</a>  #110 rETF-semiSLï¼šç”¨äºæ—¶é—´æ•°æ®ä¸­ç¥ç»å¡Œç¼©çš„åŠç›‘ç£å­¦ä¹ </a></li>
    <li><a href="#111-mscore-a-multilingual-and-scalable-benchmark-for-skill-based-commonsense-reasoning--111mscoreä¸€ä¸ª-m-å¤šè¯­ç§ä¸”å¯æ‰©å±•çš„åŸºå‡†ç”¨äº-s-åŸºäºæŠ€èƒ½çš„-co-æ— æ„ä¹‰-re-æ¨ç†"><a href="https://arxiv.org/abs/2508.10137">#111</a> <a href="https://papers.cool/arxiv/2508.10137">mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning</a>  #111mSCoReï¼šä¸€ä¸ª M å¤šè¯­ç§ä¸”å¯æ‰©å±•çš„åŸºå‡†ï¼Œç”¨äº S åŸºäºæŠ€èƒ½çš„ Co æ— æ„ä¹‰ Re æ¨ç†</a></li>
    <li><a href="#112-nested-reft-efficient-reinforcement-learning-for-large-language-model-fine-tuning-via-off-policy-rollouts--112-åµŒå¥—-refté€šè¿‡ç¦»ç­–ç•¥å›åˆå®ç°é¢å‘å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒçš„é«˜æ•ˆå¼ºåŒ–å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10123">#112</a> <a href="https://papers.cool/arxiv/2508.10123">Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts</a>  #112 åµŒå¥—-ReFTï¼šé€šè¿‡ç¦»ç­–ç•¥å›åˆå®ç°é¢å‘å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒçš„é«˜æ•ˆå¼ºåŒ–å­¦ä¹ </a></li>
    <li><a href="#113-less-is-more-learning-graph-tasks-with-just-llms--113-å°‘å³æ˜¯å¤šä»…ç”¨-llms-å­¦ä¹ å›¾ä»»åŠ¡"><a href="https://arxiv.org/abs/2508.10115">#113</a> <a href="https://papers.cool/arxiv/2508.10115">Less is More: Learning Graph Tasks with Just LLMs</a>  #113 å°‘å³æ˜¯å¤šï¼šä»…ç”¨ LLMs å­¦ä¹ å›¾ä»»åŠ¡</a></li>
    <li><a href="#114-empowering-morphing-attack-detection-using-interpretable-image-text-foundation-model--114-ä½¿ç”¨å¯è§£é‡Šçš„å›¾åƒ-æ–‡æœ¬åŸºç¡€æ¨¡å‹å¢å¼ºå˜å½¢æ”»å‡»æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10110">#114</a> <a href="https://papers.cool/arxiv/2508.10110">Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model</a>  #114 ä½¿ç”¨å¯è§£é‡Šçš„å›¾åƒ-æ–‡æœ¬åŸºç¡€æ¨¡å‹å¢å¼ºå˜å½¢æ”»å‡»æ£€æµ‹</a></li>
    <li><a href="#115-advancing-data-equity-practitioner-responsibility-and-accountability-in-nlp-data-practices--115-æ¨è¿›æ•°æ®å…¬å¹³ä»ä¸šè€…åœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ•°æ®å®è·µä¸­çš„è´£ä»»ä¸é—®è´£"><a href="https://arxiv.org/abs/2508.10071">#115</a> <a href="https://papers.cool/arxiv/2508.10071">Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices</a>  #115 æ¨è¿›æ•°æ®å…¬å¹³ï¼šä»ä¸šè€…åœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ•°æ®å®è·µä¸­çš„è´£ä»»ä¸é—®è´£</a></li>
    <li><a href="#116-large-language-models-show-signs-of-alignment-with-human-neurocognition-during-abstract-reasoning--116-å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­è¡¨ç°å‡ºä¸äººç±»ç¥ç»è®¤çŸ¥ä¸€è‡´çš„è¿¹è±¡"><a href="https://arxiv.org/abs/2508.10057">#116</a> <a href="https://papers.cool/arxiv/2508.10057">Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning</a>  #116 å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­è¡¨ç°å‡ºä¸äººç±»ç¥ç»è®¤çŸ¥ä¸€è‡´çš„è¿¹è±¡</a></li>
    <li><a href="#117-netmoniai-an-agentic-ai-framework-for-network-security--monitoring--117-netmoniaiä¸€ä¸ªç”¨äºç½‘ç»œå®‰å…¨ä¸ç›‘æ§çš„è‡ªä¸»æ™ºèƒ½ä½“-ai-æ¡†æ¶-pdf--copy-kimi-1--rel"><a href="https://arxiv.org/abs/2508.10052">#117</a> <a href="https://papers.cool/arxiv/2508.10052">NetMoniAI: An Agentic AI Framework for Network Security &amp; Monitoring</a>  #117 NetMoniAIï¼šä¸€ä¸ªç”¨äºç½‘ç»œå®‰å…¨ä¸ç›‘æ§çš„è‡ªä¸»æ™ºèƒ½ä½“ AI æ¡†æ¶ [PDF ] [Copy] [Kimi 1 ] [REL]</a></li>
    <li><a href="#118-legal-zero-days-a-novel-risk-vector-for-advanced-ai-systems--118-åˆæ³•é›¶æ—¥æ¼æ´é¢å‘é«˜çº§äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ–°å‹é£é™©å‘é‡"><a href="https://arxiv.org/abs/2508.10050">#118</a> <a href="https://papers.cool/arxiv/2508.10050">Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems</a>  #118 åˆæ³•é›¶æ—¥æ¼æ´ï¼šé¢å‘é«˜çº§äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ–°å‹é£é™©å‘é‡</a></li>
    <li><a href="#119-sabia-an-ai-powered-tool-for-detecting-opioid-related-behaviors-on-social-media--119-sabiaä¸€ç§ç”¨äºæ£€æµ‹ç¤¾äº¤åª’ä½“ä¸Šä¸é˜¿ç‰‡ç±»è¯ç‰©ç›¸å…³è¡Œä¸ºçš„-ai-å·¥å…·"><a href="https://arxiv.org/abs/2508.10046">#119</a> <a href="https://papers.cool/arxiv/2508.10046">SABIA: An AI-Powered Tool for Detecting Opioid-Related Behaviors on Social Media</a>  #119 SABIAï¼šä¸€ç§ç”¨äºæ£€æµ‹ç¤¾äº¤åª’ä½“ä¸Šä¸é˜¿ç‰‡ç±»è¯ç‰©ç›¸å…³è¡Œä¸ºçš„ AI å·¥å…·</a></li>
    <li><a href="#120-generative-ai-for-cybersecurity-of-energy-management-systems-methods-challenges-and-future-directions--120-é¢å‘èƒ½æºç®¡ç†ç³»ç»Ÿç½‘ç»œå®‰å…¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ–¹æ³•æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘"><a href="https://arxiv.org/abs/2508.10044">#120</a> <a href="https://papers.cool/arxiv/2508.10044">Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions</a>  #120 é¢å‘èƒ½æºç®¡ç†ç³»ç»Ÿç½‘ç»œå®‰å…¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šæ–¹æ³•ã€æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘</a></li>
    <li><a href="#121-securing-agentic-ai-threat-modeling-and-risk-analysis-for-network-monitoring-agentic-ai-system--121-ä¿éšœå…·å¤‡ä»£ç†èƒ½åŠ›çš„äººå·¥æ™ºèƒ½é’ˆå¯¹ç½‘ç»œç›‘æ§ä»£ç†å¼äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¨èƒå»ºæ¨¡ä¸é£é™©åˆ†æ"><a href="https://arxiv.org/abs/2508.10043">#121</a> <a href="https://papers.cool/arxiv/2508.10043">Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System</a>  #121 ä¿éšœå…·å¤‡ä»£ç†èƒ½åŠ›çš„äººå·¥æ™ºèƒ½ï¼šé’ˆå¯¹ç½‘ç»œç›‘æ§ä»£ç†å¼äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¨èƒå»ºæ¨¡ä¸é£é™©åˆ†æ</a></li>
    <li><a href="#122-fidelis-blockchain-enabled-protection-against-poisoning-attacks-in-federated-learning--122-fidelisåŸºäºåŒºå—é“¾çš„è”é‚¦å­¦ä¹ ä¸­å¯¹æŠ—æŠ•æ¯’æ”»å‡»çš„ä¿æŠ¤"><a href="https://arxiv.org/abs/2508.10042">#122</a> <a href="https://papers.cool/arxiv/2508.10042">FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning</a>  #122 FIDELISï¼šåŸºäºåŒºå—é“¾çš„è”é‚¦å­¦ä¹ ä¸­å¯¹æŠ—æŠ•æ¯’æ”»å‡»çš„ä¿æŠ¤</a></li>
    <li><a href="#123-exploring-content-and-social-connections-of-fake-news-with-explainable-text-and-graph-learning--123-ä½¿ç”¨å¯è§£é‡Šçš„æ–‡æœ¬å’Œå›¾å­¦ä¹ æ¢ç´¢å‡æ–°é—»çš„å†…å®¹ä¸ç¤¾äº¤å…³ç³»"><a href="https://arxiv.org/abs/2508.10040">#123</a> <a href="https://papers.cool/arxiv/2508.10040">Exploring Content and Social Connections of Fake News with Explainable Text and Graph Learning</a>  #123 ä½¿ç”¨å¯è§£é‡Šçš„æ–‡æœ¬å’Œå›¾å­¦ä¹ æ¢ç´¢å‡æ–°é—»çš„å†…å®¹ä¸ç¤¾äº¤å…³ç³»</a></li>
    <li><a href="#124-multi-task-adversarial-attacks-against-black-box-model-with-few-shot-queries--124-é’ˆå¯¹é»‘ç®±æ¨¡å‹çš„å°‘æ ·æœ¬æŸ¥è¯¢å¤šä»»åŠ¡å¯¹æŠ—æ”»å‡»"><a href="https://arxiv.org/abs/2508.10039">#124</a> <a href="https://papers.cool/arxiv/2508.10039">Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries</a>  #124 é’ˆå¯¹é»‘ç®±æ¨¡å‹çš„å°‘æ ·æœ¬æŸ¥è¯¢å¤šä»»åŠ¡å¯¹æŠ—æ”»å‡»</a></li>
    <li><a href="#125-certifiably-robust-malware-detectors-by-design--125-é€šè¿‡è®¾è®¡å®ç°å¯éªŒè¯é²æ£’çš„æ¶æ„è½¯ä»¶æ£€æµ‹å™¨"><a href="https://arxiv.org/abs/2508.10038">#125</a> <a href="https://papers.cool/arxiv/2508.10038">Certifiably robust malware detectors by design</a>  #125 é€šè¿‡è®¾è®¡å®ç°å¯éªŒè¯é²æ£’çš„æ¶æ„è½¯ä»¶æ£€æµ‹å™¨</a></li>
    <li><a href="#126-reflect-then-learn-active-prompting-for-information-extraction-guided-by-introspective-confusion--126-å…ˆåæ€åå­¦ä¹ ç”±å†…çœæ€§å›°æƒ‘å¼•å¯¼çš„ä¿¡æ¯æŠ½å–ä¸»åŠ¨æç¤º"><a href="https://arxiv.org/abs/2508.10036">#126</a> <a href="https://papers.cool/arxiv/2508.10036">Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion</a>  #126 å…ˆåæ€åå­¦ä¹ ï¼šç”±å†…çœæ€§å›°æƒ‘å¼•å¯¼çš„ä¿¡æ¯æŠ½å–ä¸»åŠ¨æç¤º</a></li>
    <li><a href="#127-jet-image-tagging-using-deep-learning-an-ensemble-model--127-å–·æ°”æœºå›¾åƒæ ‡æ³¨ä½¿ç”¨æ·±åº¦å­¦ä¹ ä¸€ç§é›†æˆæ¨¡å‹"><a href="https://arxiv.org/abs/2508.10034">#127</a> <a href="https://papers.cool/arxiv/2508.10034">Jet Image Tagging Using Deep Learning: An Ensemble Model</a>  #127 å–·æ°”æœºå›¾åƒæ ‡æ³¨ä½¿ç”¨æ·±åº¦å­¦ä¹ ï¼šä¸€ç§é›†æˆæ¨¡å‹</a></li>
    <li><a href="#128-cognitive-cybersecurity-for-artificial-intelligence-guardrail-engineering-with-ccs-7--128-é¢å‘äººå·¥æ™ºèƒ½çš„è®¤çŸ¥ç½‘ç»œå®‰å…¨ä½¿ç”¨-ccs-7-çš„æŠ¤æ å·¥ç¨‹"><a href="https://arxiv.org/abs/2508.10033">#128</a> <a href="https://papers.cool/arxiv/2508.10033">Cognitive Cybersecurity for Artificial Intelligence: Guardrail Engineering with CCS-7</a>  #128 é¢å‘äººå·¥æ™ºèƒ½çš„è®¤çŸ¥ç½‘ç»œå®‰å…¨ï¼šä½¿ç”¨ CCS-7 çš„æŠ¤æ å·¥ç¨‹</a></li>
    <li><a href="#129-the-cost-of-thinking-increased-jailbreak-risk-in-large-language-models--129-æ€è€ƒçš„ä»£ä»·å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¶Šç‹±é£é™©çš„å¢åŠ "><a href="https://arxiv.org/abs/2508.10032">#129</a> <a href="https://papers.cool/arxiv/2508.10032">The Cost of Thinking: Increased Jailbreak Risk in Large Language Models</a>  #129 æ€è€ƒçš„ä»£ä»·ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¶Šç‹±é£é™©çš„å¢åŠ </a></li>
    <li><a href="#130-context-misleads-llms-the-role-of-context-filtering-in-maintaining-safe-alignment-of-llms--130-ä¸Šä¸‹æ–‡è¯¯å¯¼-llmsä¸Šä¸‹æ–‡è¿‡æ»¤åœ¨ç»´æŒ-llms-å®‰å…¨å¯¹é½ä¸­çš„ä½œç”¨"><a href="https://arxiv.org/abs/2508.10031">#130</a> <a href="https://papers.cool/arxiv/2508.10031">Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs</a>  #130 ä¸Šä¸‹æ–‡è¯¯å¯¼ LLMsï¼šä¸Šä¸‹æ–‡è¿‡æ»¤åœ¨ç»´æŒ LLMs å®‰å…¨å¯¹é½ä¸­çš„ä½œç”¨</a></li>
    <li><a href="#131-inference-aware-prompt-optimization-for-aligning-black-box-large-language-models--131-é¢å‘æ¨ç†çš„æç¤ºä¼˜åŒ–ä»¥å¯¹é½é»‘ç›’å¤§å‹è¯­è¨€æ¨¡å‹"><a href="https://arxiv.org/abs/2508.10030">#131</a> <a href="https://papers.cool/arxiv/2508.10030">Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models</a>  #131 é¢å‘æ¨ç†çš„æç¤ºä¼˜åŒ–ä»¥å¯¹é½é»‘ç›’å¤§å‹è¯­è¨€æ¨¡å‹</a></li>
    <li><a href="#132-latent-fusion-jailbreak-blending-harmful-and-harmless-representations-to-elicit-unsafe-llm-outputs--132-æ½œåœ¨èåˆè¶Šç‹±æ··åˆæœ‰å®³ä¸æ— å®³è¡¨å¾ä»¥å¼•å‡ºä¸å®‰å…¨çš„-llm-è¾“å‡º"><a href="https://arxiv.org/abs/2508.10029">#132</a> <a href="https://papers.cool/arxiv/2508.10029">Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs</a>  #132 æ½œåœ¨èåˆè¶Šç‹±ï¼šæ··åˆæœ‰å®³ä¸æ— å®³è¡¨å¾ä»¥å¼•å‡ºä¸å®‰å…¨çš„ LLM è¾“å‡º</a></li>
    <li><a href="#133-pref-reference-free-evaluation-of-personalised-text-generation-in-llms--133-åå¥½åœ¨-llms-ä¸­å¯¹ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆè¿›è¡Œæ— å‚è€ƒè¯„ä¼°"><a href="https://arxiv.org/abs/2508.10028">#133</a> <a href="https://papers.cool/arxiv/2508.10028">PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs</a>  #133 åå¥½ï¼šåœ¨ LLMs ä¸­å¯¹ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆè¿›è¡Œæ— å‚è€ƒè¯„ä¼°</a></li>
    <li><a href="#134-llmcare-alzheimer39s-detection-via-transformer-models-enhanced-by-llm-generated-synthetic-data--134-llmcareé€šè¿‡ç”±-llm-ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºçš„-transformer-æ¨¡å‹è¿›è¡Œé˜¿å°”èŒ¨æµ·é»˜ç—‡æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10027">#134</a> <a href="https://papers.cool/arxiv/2508.10027">LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data</a>  #134 LLMCAREï¼šé€šè¿‡ç”± LLM ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºçš„ Transformer æ¨¡å‹è¿›è¡Œé˜¿å°”èŒ¨æµ·é»˜ç—‡æ£€æµ‹</a></li>
    <li><a href="#135-saber-switchable-and-balanced-training-for-efficient-llm-reasoning--135-saber-å¯åˆ‡æ¢ä¸”å¹³è¡¡çš„è®­ç»ƒä»¥å®ç°é«˜æ•ˆçš„-llm-æ¨ç†-pdf-5--copy-kimi-2--rel"><a href="https://arxiv.org/abs/2508.10026">#135</a> <a href="https://papers.cool/arxiv/2508.10026">SABER: Switchable and Balanced Training for Efficient LLM Reasoning</a>  #135 SABER: å¯åˆ‡æ¢ä¸”å¹³è¡¡çš„è®­ç»ƒä»¥å®ç°é«˜æ•ˆçš„ LLM æ¨ç† [PDF 5 ] [Copy] [Kimi 2 ] [REL]</a></li>
    <li><a href="#136-detecting-and-explaining-postpartum-depression-in-real-time-with-generative-artificial-intelligence--136-ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®æ—¶æ£€æµ‹å¹¶è§£é‡Šäº§åæŠ‘éƒç—‡"><a href="https://arxiv.org/abs/2508.10025">#136</a> <a href="https://papers.cool/arxiv/2508.10025">Detecting and explaining postpartum depression in real-time with generative artificial intelligence</a>  #136 ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®æ—¶æ£€æµ‹å¹¶è§£é‡Šäº§åæŠ‘éƒç—‡</a></li>
    <li><a href="#137-rttc-reward-guided-collaborative-test-time-compute--137-rttcä»¥å¥–åŠ±ä¸ºå¯¼å‘çš„åä½œå¼æµ‹è¯•æ—¶è®¡ç®—-pdf-1--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10024">#137</a> <a href="https://papers.cool/arxiv/2508.10024">RTTC: Reward-Guided Collaborative Test-Time Compute</a>  #137 RTTCï¼šä»¥å¥–åŠ±ä¸ºå¯¼å‘çš„åä½œå¼æµ‹è¯•æ—¶è®¡ç®— [PDF 1 ] [Copy] [Kimi ] [REL]</a></li>
    <li><a href="#138-conformal-p-value-in-multiple-choice-question-answering-tasks-with-provable-risk-control--138-åœ¨å…·æœ‰å¯è¯æ˜é£é™©æ§åˆ¶çš„å¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ä»»åŠ¡ä¸­çš„ç¬¦åˆæ€§-p-å€¼"><a href="https://arxiv.org/abs/2508.10022">#138</a> <a href="https://papers.cool/arxiv/2508.10022">Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control</a>  #138 åœ¨å…·æœ‰å¯è¯æ˜é£é™©æ§åˆ¶çš„å¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ä»»åŠ¡ä¸­çš„ç¬¦åˆæ€§ P å€¼</a></li>
    <li><a href="#139-latte-learning-aligned-transactions-and-textual-embeddings-for-bank-clients--139-latteä¸ºé“¶è¡Œå®¢æˆ·å­¦ä¹ å¯¹é½çš„äº¤æ˜“ä¸æ–‡æœ¬åµŒå…¥"><a href="https://arxiv.org/abs/2508.10021">#139</a> <a href="https://papers.cool/arxiv/2508.10021">LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients</a>  #139 LATTEï¼šä¸ºé“¶è¡Œå®¢æˆ·å­¦ä¹ å¯¹é½çš„äº¤æ˜“ä¸æ–‡æœ¬åµŒå…¥</a></li>
    <li><a href="#140-fedcot-communication-efficient-federated-reasoning-enhancement-for-large-language-models--140-fedcoté¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„é€šä¿¡é«˜æ•ˆè”é‚¦æ¨ç†å¢å¼º"><a href="https://arxiv.org/abs/2508.10020">#140</a> <a href="https://papers.cool/arxiv/2508.10020">FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models</a>  #140 FedCoTï¼šé¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„é€šä¿¡é«˜æ•ˆè”é‚¦æ¨ç†å¢å¼º</a></li>
    <li><a href="#141-decoupling-understanding-from-reasoning-via-problem-space-mapping-for-small-scale-model-reasoning--141-é€šè¿‡é—®é¢˜ç©ºé—´æ˜ å°„å°†ç†è§£ä¸æ¨ç†è§£è€¦ä»¥ç”¨äºå°è§„æ¨¡æ¨¡å‹æ¨ç†"><a href="https://arxiv.org/abs/2508.10019">#141</a> <a href="https://papers.cool/arxiv/2508.10019">Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning</a>  #141 é€šè¿‡é—®é¢˜ç©ºé—´æ˜ å°„å°†ç†è§£ä¸æ¨ç†è§£è€¦ä»¥ç”¨äºå°è§„æ¨¡æ¨¡å‹æ¨ç†</a></li>
    <li><a href="#142-a-rose-by-any-other-name-would-smell-as-sweet-categorical-homotopy-theory-for-large-language-models--142-æ— è®ºä½•åçš„ç«ç‘°é—»èµ·æ¥éƒ½ä¸€æ ·é¦™é¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„èŒƒç•´åŒä¼¦è®º"><a href="https://arxiv.org/abs/2508.10018">#142</a> <a href="https://papers.cool/arxiv/2508.10018">A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models</a>  #142 æ— è®ºä½•åçš„ç«ç‘°é—»èµ·æ¥éƒ½ä¸€æ ·é¦™ï¼šé¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„èŒƒç•´åŒä¼¦è®º</a></li>
    <li><a href="#143-a-robust-pipeline-for-differentially-private-federated-learning-on-imbalanced-clinical-data-using-smotetomek-and-fedprox--143-ä½¿ç”¨-smotetomek-å’Œ-fedprox-åœ¨ä¸å¹³è¡¡ä¸´åºŠæ•°æ®ä¸Šå®ç°å·®åˆ†éšç§è”é‚¦å­¦ä¹ çš„é²æ£’æµç¨‹"><a href="https://arxiv.org/abs/2508.10017">#143</a> <a href="https://papers.cool/arxiv/2508.10017">A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx</a>  #143 ä½¿ç”¨ SMOTETomek å’Œ FedProx åœ¨ä¸å¹³è¡¡ä¸´åºŠæ•°æ®ä¸Šå®ç°å·®åˆ†éšç§è”é‚¦å­¦ä¹ çš„é²æ£’æµç¨‹</a></li>
    <li><a href="#144-beyond-hard-sharing-efficient-multi-task-speech-to-text-modeling-with-supervised-mixture-of-experts--144-è¶…è¶Šç¡¬æ€§å…±äº«ä½¿ç”¨ç›‘ç£ä¸“å®¶æ··åˆçš„é«˜æ•ˆå¤šä»»åŠ¡è¯­éŸ³è½¬æ–‡æœ¬å»ºæ¨¡"><a href="https://arxiv.org/abs/2508.10009">#144</a> <a href="https://papers.cool/arxiv/2508.10009">Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts</a>  #144 è¶…è¶Šç¡¬æ€§å…±äº«ï¼šä½¿ç”¨ç›‘ç£ä¸“å®¶æ··åˆçš„é«˜æ•ˆå¤šä»»åŠ¡è¯­éŸ³è½¬æ–‡æœ¬å»ºæ¨¡</a></li>
    <li><a href="#145-from-answers-to-questions-eqgbench-for-evaluating-llms39-educational-question-generation"><a href="https://arxiv.org/abs/2508.10005">#145</a> <a href="https://papers.cool/arxiv/2508.10005">From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation</a></a></li>
    <li><a href="#146-user-perception-of-attention-visualizations-effects-on-interpretability-across-evidence-based-medical-documents--146-æ³¨æ„åŠ›å¯è§†åŒ–çš„ç”¨æˆ·æ„ŸçŸ¥åŸºäºè¯æ®çš„åŒ»å­¦æ–‡æ¡£ä¸­å¯¹å¯è§£é‡Šæ€§çš„å½±å“"><a href="https://arxiv.org/abs/2508.10004">#146</a> <a href="https://papers.cool/arxiv/2508.10004">User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents</a>  #146 æ³¨æ„åŠ›å¯è§†åŒ–çš„ç”¨æˆ·æ„ŸçŸ¥ï¼šåŸºäºè¯æ®çš„åŒ»å­¦æ–‡æ¡£ä¸­å¯¹å¯è§£é‡Šæ€§çš„å½±å“</a></li>
    <li><a href="#147-semantic-structure-in-large-language-model-embeddings--147-å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­çš„è¯­ä¹‰ç»“æ„"><a href="https://arxiv.org/abs/2508.10003">#147</a> <a href="https://papers.cool/arxiv/2508.10003">Semantic Structure in Large Language Model Embeddings</a>  #147 å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­çš„è¯­ä¹‰ç»“æ„</a></li>
    <li><a href="#148-hifactmix-a-code-mixed-benchmark-and-graph-aware-model-for-evidencebased-political-claim-verification-in-hinglish--148-hifactmixä¸€ä¸ªç”¨äºå°åœ°è‹±æ··åˆhinglishè¯æ®å‹æ”¿æ²»ä¸»å¼ éªŒè¯çš„ä»£ç æ··åˆåŸºå‡†ä¸å›¾æ„ŸçŸ¥æ¨¡å‹-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10001">#148</a> <a href="https://papers.cool/arxiv/2508.10001">HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish</a>  #148 HiFACTMixï¼šä¸€ä¸ªç”¨äºå°åœ°è‹±æ··åˆï¼ˆHinglishï¼‰è¯æ®å‹æ”¿æ²»ä¸»å¼ éªŒè¯çš„ä»£ç æ··åˆåŸºå‡†ä¸å›¾æ„ŸçŸ¥æ¨¡å‹ [PDF ] [Copy] [Kimi ] [REL]</a></li>
    <li><a href="#149-intima-a-benchmark-for-human-ai-companionship-behavior--149-intimaç”¨äºäººæœºä¼´ä¾£è¡Œä¸ºçš„åŸºå‡†æµ‹è¯•"><a href="https://arxiv.org/abs/2508.09998">#149</a> <a href="https://papers.cool/arxiv/2508.09998">INTIMA: A Benchmark for Human-AI Companionship Behavior</a>  #149 INTIMAï¼šç”¨äºäººæœºä¼´ä¾£è¡Œä¸ºçš„åŸºå‡†æµ‹è¯•</a></li>
    <li><a href="#150-openfpl-an-open-source-forecasting-method-rivaling-state-of-the-art-fantasy-premier-league-services--150-openfplä¸€ä¸ªå¯ä¸æœ€å…ˆè¿›çš„-fantasy-premier-league-æœåŠ¡åª²ç¾çš„å¼€æºé¢„æµ‹æ–¹æ³•"><a href="https://arxiv.org/abs/2508.09992">#150</a> <a href="https://papers.cool/arxiv/2508.09992">OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services</a>  #150 OpenFPLï¼šä¸€ä¸ªå¯ä¸æœ€å…ˆè¿›çš„ Fantasy Premier League æœåŠ¡åª²ç¾çš„å¼€æºé¢„æµ‹æ–¹æ³•</a></li>
    <li><a href="#151-bridging-ai-innovation-and-healthcare-needs-lessons-learned-from-incorporating-modern-nlp-at-the-bc-cancer-registry--151-åœ¨äººå·¥æ™ºèƒ½åˆ›æ–°ä¸åŒ»ç–—éœ€æ±‚ä¹‹é—´æ¶æ¡¥åœ¨å‘è¯—çœç™Œç—‡ç™»è®°å¤„å¼•å…¥ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»éªŒæ•™è®­"><a href="https://arxiv.org/abs/2508.09991">#151</a> <a href="https://papers.cool/arxiv/2508.09991">Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry</a>  #151 åœ¨äººå·¥æ™ºèƒ½åˆ›æ–°ä¸åŒ»ç–—éœ€æ±‚ä¹‹é—´æ¶æ¡¥ï¼šåœ¨å‘è¯—çœç™Œç—‡ç™»è®°å¤„å¼•å…¥ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»éªŒæ•™è®­</a></li>
    <li><a href="#152-personalized-product-search-ranking-a-multi-task-learning-approach-with-tabular-and-non-tabular-data--152-ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åºä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•"><a href="https://arxiv.org/abs/2508.09636">#152</a> <a href="https://papers.cool/arxiv/2508.09636">Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data</a>  #152 ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åºï¼šä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•</a></li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h1 id="2025-08-15ç§‘ç ”è¿½æ–°">2025-08-15ç§‘ç ”è¿½æ–°</h1>
<p>2025-08-14 19:39:40 Thursday ~ 2025-08-15 19:37:11 Friday</p>
<h1 id="1-æºæ•°æ®">1. æºæ•°æ®</h1>
<h1 id="11-å…¬ä¼—å·">1.1 å…¬ä¼—å·</h1>
<h1 id="111-é‡å­ä½">1.1.1 é‡å­ä½</h1>
<ol>
<li><a href="https://mp.weixin.qq.com/s/KmLNYmH62-hgix70C_86Rg"target="_blank" rel="external nofollow noopener noreferrer">æ··å…ƒ3Dä¸–ç•Œæ¨¡å‹1.0 liteç‰ˆæœ¬å‘å¸ƒï¼Œæ¶ˆè´¹çº§æ˜¾å¡å°±èƒ½è·‘</a></li>
<li><a href="https://mp.weixin.qq.com/s/if5yJybrsYG5DhYRrS4oCA"target="_blank" rel="external nofollow noopener noreferrer">æ¨¡ä»¿äººç±»æ¨ç†ä¿®æ­£è¿‡ç¨‹ï¼Œé˜¶è·ƒæ˜Ÿè¾°æå‡ºå½¢å¼åŒ–è¯æ˜æ–°èŒƒå¼ | å¼€æº</a></li>
<li><a href="https://mp.weixin.qq.com/s/aNbIV7sa7G-97axStFtE7Q"target="_blank" rel="external nofollow noopener noreferrer">ç¬‘æ­»ï¼Œäººå½¢æœºå™¨äººè¿åŠ¨ä¼šå…¨æ˜¯é¬¼ç•œååœºé¢ï¼è¿™é”…ç²¥å¤§å®¶æ¥è¶ä¹±å–äº†å§</a></li>
<li><a href="https://mp.weixin.qq.com/s/OZwPStQT4AXUqbJMLOVN6A"target="_blank" rel="external nofollow noopener noreferrer">å›½å®¶çº§AIåˆ›æ–°åº”ç”¨èµ›äº‹æ€ç–¯äº†ï¼è¶…200ä¸‡å…ƒå¥–é‡‘æ± +å…¨åœºæ™¯èµ›é“ï¼Œå†²çº¿å›¢é˜Ÿé€Ÿæ¥</a></li>
<li><a href="https://mp.weixin.qq.com/s/UY7h2ZC_oeefrH_hWSKcag"target="_blank" rel="external nofollow noopener noreferrer">è°·æ­Œç‰ˆå°é’¢ç‚®å¼€æºï¼0.27Bå¤§æ¨¡å‹ï¼Œ4ä¸ªæ³¨æ„åŠ›å¤´ï¼Œä¸“ä¸ºç»ˆç«¯è€Œç”Ÿ</a></li>
<li><a href="https://mp.weixin.qq.com/s/gfM7kMxSt9Cs7Ark8gaOcA"target="_blank" rel="external nofollow noopener noreferrer">GPT-5è¶…è¶Šäººç±»åŒ»ç”Ÿï¼æ¨ç†èƒ½åŠ›æ¯”ä¸“å®¶é«˜å‡º24%ï¼Œç†è§£åŠ›å¼º29%</a></li>
<li><a href="https://mp.weixin.qq.com/s/3gzb5QcJ8AO-1EDeECUFlQ"target="_blank" rel="external nofollow noopener noreferrer">é¦–ä¸ªå¼€æºå¤šæ¨¡æ€Deep Researchæ™ºèƒ½ä½“ï¼Œè¶…è¶Šå¤šä¸ªé—­æºæ–¹æ¡ˆ</a></li>
<li><a href="https://mp.weixin.qq.com/s/j-H7ZZUCesMimwzMw0xeIw"target="_blank" rel="external nofollow noopener noreferrer">OpenAIåäººéœ²å¤´å°±è¢«å°æ‰æŒ–ï¼95ååŒ—å¤§æ ¡å‹1ä¸ªæœˆå‰ä¸Šç›´æ’­ï¼Œä»Šå¤©å·²æ˜¯Metaäºº</a></li>
<li><a href="https://mp.weixin.qq.com/s/SvjtUE1IH1fV2kPmR2oCdQ"target="_blank" rel="external nofollow noopener noreferrer">å®æµ‹Perplexity Proå¹³æ›¿æ¨¡å‹ï¼Œå…è´¹å¼€æºä»…4B</a></li>
</ol>
<h1 id="112-æœºå™¨ä¹‹å¿ƒ">1.1.2 æœºå™¨ä¹‹å¿ƒ</h1>
<ol>
<li><a href="https://mp.weixin.qq.com/s/ht0vOaGxQC9MunBVk3VE1g"target="_blank" rel="external nofollow noopener noreferrer">ä¸€å¥è¯æå®šå¤šä»»åŠ¡å‡ºè¡Œï¼Œé«˜å¾·ç”¨ç©ºé—´æ™ºèƒ½é‡æ–°å®šä¹‰åœ°å›¾</a></li>
<li><a href="https://mp.weixin.qq.com/s/cyOJ_Id606REj97nCXYqhg"target="_blank" rel="external nofollow noopener noreferrer">GPT-5ã€Grok 4ã€o3 Proéƒ½é›¶åˆ†ï¼Œå²ä¸Šæœ€éš¾AIè¯„æµ‹åŸºå‡†æ¢å®ƒäº†</a></li>
<li><a href="https://mp.weixin.qq.com/s/IH64apP7SmHVCwHKfTGOsQ"target="_blank" rel="external nofollow noopener noreferrer">è°·æ­Œå¼€æºGemma 3 270Mï¼Œæ€§èƒ½è¶…è¶ŠQwen 2.5åŒçº§æ¨¡å‹</a></li>
<li><a href="https://mp.weixin.qq.com/s/EW73QGDT45uu2i_RHeNeNA"target="_blank" rel="external nofollow noopener noreferrer">è¿½å‰§ä¸æ–­ç½‘ï¼Œå¯èƒ½èƒŒåæœ‰ä¸ªAIåœ¨åŠ ç­ï¼Œæ•…éšœè¯Šæ–­å‡†åº¦ç ´91.79%</a></li>
<li><a href="https://mp.weixin.qq.com/s/IG5OaG05O_-Ce9o7KkzKLg"target="_blank" rel="external nofollow noopener noreferrer">Metaè§†è§‰åŸºåº§DINOv3ç‹è€…å½’æ¥ï¼šè‡ªç›‘ç£é¦–æ¬¡å…¨é¢è¶…è¶Šå¼±ç›‘ç£ï¼Œå•†ç”¨å¼€æº</a></li>
<li><a href="https://mp.weixin.qq.com/s/_qjKWCnDL--rTod03KUdoA"target="_blank" rel="external nofollow noopener noreferrer">å¤šçªè§¦ç¥ç»å…ƒæ¨¡å‹é—®ä¸–ï¼Œå›½å†…å›¢é˜Ÿæ‰“é€ ç±»è„‘è®¡ç®—æ–°å¼•æ“ï¼Œç™»ä¸Šã€Šè‡ªç„¶Â·é€šè®¯ã€‹</a></li>
<li><a href="https://mp.weixin.qq.com/s/kD9LQ4eyRURkPzMKBaXJ0A"target="_blank" rel="external nofollow noopener noreferrer">æ‰å…‹ä¼¯æ ¼çœ‹OpenAIç›´æ’­æŒ–äººï¼ŒåŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…åŠ å…¥Meta</a></li>
<li><a href="https://mp.weixin.qq.com/s/VaCrLFSk_0XdaB8_voI8nQ"target="_blank" rel="external nofollow noopener noreferrer">AI æ¨¡ç‰¹æ—¶ä»£åˆ°æ¥ï¼šå­—èŠ‚xæ¸…åæ¨å‡ºå•†ç”¨çº§è§†é¢‘æ¢è£…æ¨¡å‹DreamVVTï¼Œä¿çœŸåº¦æ˜¾è‘—é¢†å…ˆSOTA</a></li>
</ol>
<h1 id="113-æ–°æ™ºå…ƒ">1.1.3 æ–°æ™ºå…ƒ</h1>
<ol>
<li><a href="https://mp.weixin.qq.com/s/oTN5bnaEO0kGW1E1f99IPQ"target="_blank" rel="external nofollow noopener noreferrer">æ ¸å¿ƒæ¨¡å‹è¢«æ›è’¸é¦DeepSeekï¼Ÿå‰å¥³å‹ä¸€çº¸æ§è¯‰ï¼Œæ›å‡ºæ¬§ç‰ˆOpenAIå¡Œæˆ¿çœŸç›¸ï¼</a></li>
<li><a href="https://mp.weixin.qq.com/s/6BieJQ2E0ExfMiClpRlSug"target="_blank" rel="external nofollow noopener noreferrer">æ‰“å¼€é«˜å¾·çš„ç†ç”±åˆå¤šä¸€æ¡ï¼å…¨çƒé¦–ä¸ªã€Œéœ€æ±‚é“¾æ™ºèƒ½è°ƒåº¦ã€AIåœ°å›¾ä¸Šçº¿</a></li>
<li><a href="https://mp.weixin.qq.com/s/pfk5Ft5wCPAT9WlKuqrwWA"target="_blank" rel="external nofollow noopener noreferrer">åä¸‹17äº¿å›¾ç‰‡ï¼ŒMetaæœ€å¼ºå·¨å…½DINOv3å¼€æºï¼é‡æ–°å®šä¹‰CVå¤©èŠ±æ¿</a></li>
<li><a href="https://mp.weixin.qq.com/s/lnQadnWGZUTZBbeQhc0nlg"target="_blank" rel="external nofollow noopener noreferrer">AIæ­£åœ¨æç©ºå¤§è„‘ï¼Œæ€æƒ³æ²¦ä¸ºæ®‹åºŸï¼æœªæ¥åªåˆ†AIçš„ã€Œä¸»äººã€å’Œã€Œå¥´éš¶ã€</a></li>
<li><a href="https://mp.weixin.qq.com/s/nFTWvB8ncSr0-yCjlG6kgg"target="_blank" rel="external nofollow noopener noreferrer">åŒ—å¤§æ ¡å‹å­™ä¹‹æ¸…Cä½å‡ºé•œï¼Œå°æ‰çœ‹OpenAIç›´æ’­å¤ºäººï¼1äº¿åˆ€è–ªé…¬å…‰é€Ÿè¢«ç­¾</a></li>
<li><a href="https://mp.weixin.qq.com/s/eCojesd9Ne1UMOa2tGCybw"target="_blank" rel="external nofollow noopener noreferrer">OpenAIæ³¢å…°åŒé›„ï¼šGPTä¸æ˜¯å¶ç„¶ï¼å†å¿†å¥¥ç‰¹æ›¼è¢«é€å½“å¤©å®å†µ</a></li>
<li><a href="https://mp.weixin.qq.com/s/v0LRUpsV4chNNi5t3IrzjA"target="_blank" rel="external nofollow noopener noreferrer">Cohereèèµ„36äº¿ï¼ŒAMDè‹±ä¼Ÿè¾¾éƒ½æŠ•äº†ï¼å‰Metaç ”ç©¶å‰¯æ€»è£å‡ºä»»é¦–å¸­AIå®˜</a></li>
</ol>
<h1 id="114-agi-hunt">1.1.4 AGI Hunt</h1>
<ol>
<li><a href="https://mp.weixin.qq.com/s/-l2KEHodfpgeDC_bmnxcMw"target="_blank" rel="external nofollow noopener noreferrer">Claude Code æ¨å‡ºå­¦ä¹ æ¨¡å¼ï¼Œæ¯”ChatGPTæ›´æ¿€è¿›ï¼šç”šè‡³èƒ½ç»™ä½ å¸ƒç½®ä½œä¸šâ€¦â€¦</a></li>
<li><a href="https://mp.weixin.qq.com/s/MIRF4RXxuUTLaSYuR5IW6w"target="_blank" rel="external nofollow noopener noreferrer">GPT-5æ­£ä»¥o3çš„ä¸‰å€é€Ÿåº¦æ‰“å®å¯æ¢¦ï¼Œç°å·²æŠµè¾¾å† å†›ä¹‹è·¯ï¼Œç›´æ’­è¿›è¡Œä¸­</a></li>
</ol>
<h1 id="115-å…¶ä»–">1.1.5 å…¶ä»–</h1>
<ol>
<li>Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models <a href="https://arxiv.org/abs/2508.09874"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2508.09874</a></li>
<li>ğŸŒˆ Multi-Step Reasoning with Large Language Models, a Survey <a href="https://arxiv.org/abs/2407.11511"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2407.11511</a></li>
</ol>
<h1 id="12-arxiv">1.2 Arxiv</h1>
<h1 id="121-computation-and-language">1.2.1 Computation and Language</h1>
<p><strong>Fromï¼š</strong><a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">https:// /arxiv/cs.CL</a></p>
<p>Fromï¼šhttps://arxiv.org/list/cs.CL/recent
2025-08-15 | | æ€»è®¡ï¼š89</p>
<h2 id="1-a-survey-on-diffusion-language-models--1-å…³äºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç»¼è¿°"><a href="https://arxiv.org/abs/2508.10875"target="_blank" rel="external nofollow noopener noreferrer">#1</a> <a href="https://papers.cool/arxiv/2508.10875"target="_blank" rel="external nofollow noopener noreferrer">A Survey on Diffusion Language Models</a>  #1 å…³äºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç»¼è¿°</h2>
<p><strong>Authors</strong>: [Tianyi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyi</a> Li), [Mingda Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingda"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingda</a> Chen), [Bowei Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowei</a> Guo), [Zhiqiang Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiqiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiqiang</a> Shen)
ä½œè€…ï¼šTianyi Liï¼ŒMingda Chenï¼ŒBowei Guoï¼ŒZhiqiang Shen</p>
<p>Diffusion Language Models (DLMs) are rapidly emerging as a powerful and promising alternative to the dominant autoregressive (AR) paradigm. By generating tokens in parallel through an iterative denoising process, DLMs possess inherent advantages in reducing inference latency and capturing bidirectional context, thereby enabling fine-grained control over the generation process. While achieving a several-fold speed-up, recent advancements have allowed DLMs to show performance comparable to their autoregressive counterparts, making them a compelling choice for various natural language processing tasks. In this survey, we provide a holistic overview of the current DLM landscape. We trace its evolution and relationship with other paradigms, such as autoregressive and masked language models, and cover both foundational principles and state-of-the-art models. Our work offers an up-to-date, comprehensive taxonomy and an in-depth analysis of current techniques, from pre-training strategies to advanced post-training methods. Another contribution of this survey is a thorough review of DLM inference strategies and optimizations, including improvements in decoding parallelism, caching mechanisms, and generation quality. We also highlight the latest approaches to multimodal extensions of DLMs and delineate their applications across various practical scenarios. Furthermore, our discussion addresses the limitations and challenges of DLMs, including efficiency, long-sequence handling, and infrastructure requirements, while outlining future research directions to sustain progress in this rapidly evolving field. Project GitHub is available at <a href="https://github.com/VILA-Lab/Awesome-DLMs"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/VILA-Lab/Awesome-DLMs</a>.
æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDLMsï¼‰æ­£åœ¨è¿…é€Ÿå´›èµ·ï¼Œæˆä¸ºå¯¹ä¸»å¯¼çš„è‡ªå›å½’ï¼ˆARï¼‰èŒƒå¼çš„å¼ºå¤§ä¸”æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡åœ¨è¿­ä»£å»å™ªè¿‡ç¨‹ä¸­å¹¶è¡Œç”Ÿæˆæ ‡è®°ï¼Œæ‰©æ•£è¯­è¨€æ¨¡å‹åœ¨é™ä½æ¨ç†å»¶è¿Ÿå’Œæ•æ‰åŒå‘ä¸Šä¸‹æ–‡æ–¹é¢å…·æœ‰å›ºæœ‰ä¼˜åŠ¿ï¼Œä»è€Œå®ç°å¯¹ç”Ÿæˆè¿‡ç¨‹çš„ç»†ç²’åº¦æ§åˆ¶ã€‚åœ¨å®ç°æ•°å€åŠ é€Ÿçš„åŒæ—¶ï¼Œè¿‘æœŸè¿›å±•å·²ä½¿æ‰©æ•£è¯­è¨€æ¨¡å‹å±•ç°å‡ºå¯ä¸è‡ªå›å½’æ¨¡å‹åª²ç¾çš„æ€§èƒ½ï¼Œä½¿å…¶æˆä¸ºå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„æœ‰åŠ›é€‰æ‹©ã€‚åœ¨æœ¬ç»¼è¿°ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†å½“å‰æ‰©æ•£è¯­è¨€æ¨¡å‹æ ¼å±€çš„æ•´ä½“æ¦‚è§ˆã€‚æˆ‘ä»¬è¿½æº¯äº†å…¶æ¼”å˜åŠä¸å…¶ä»–èŒƒå¼ï¼ˆå¦‚è‡ªå›å½’å’Œæ©ç è¯­è¨€æ¨¡å‹ï¼‰çš„å…³ç³»ï¼Œå¹¶æ¶µç›–äº†åŸºç¡€åŸç†å’Œæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„å·¥ä½œæä¾›äº†ä¸€ä¸ªæœ€æ–°çš„ã€å…¨é¢çš„åˆ†ç±»æ³•ï¼Œå¹¶å¯¹ä»é¢„è®­ç»ƒç­–ç•¥åˆ°é«˜çº§åè®­ç»ƒæ–¹æ³•çš„å½“å‰æŠ€æœ¯è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ æœ¬ç»¼è¿°çš„å¦ä¸€é¡¹è´¡çŒ®æ˜¯å¯¹ DLM æ¨ç†ç­–ç•¥å’Œä¼˜åŒ–æ‰‹æ®µçš„å…¨é¢å›é¡¾ï¼ŒåŒ…æ‹¬è§£ç å¹¶è¡Œæ€§ã€ç¼“å­˜æœºåˆ¶å’Œç”Ÿæˆè´¨é‡æ–¹é¢çš„æ”¹è¿›ã€‚æˆ‘ä»¬è¿˜å¼ºè°ƒäº† DLM å¤šæ¨¡æ€æ‰©å±•çš„æœ€æ–°æ–¹æ³•ï¼Œå¹¶é˜æ˜äº†å®ƒä»¬åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„è®¨è®ºè¿˜æ¶‰åŠ DLM çš„å±€é™æ€§å’ŒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•ˆç‡ã€é•¿åºåˆ—å¤„ç†å’ŒåŸºç¡€è®¾æ–½éœ€æ±‚ï¼ŒåŒæ—¶æ¦‚è¿°äº†ä¿æŒè¯¥å¿«é€Ÿå‘å±•é¢†åŸŸè¿›å±•çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚é¡¹ç›® GitHub åœ°å€ä¸º <a href="https://github.com/VILA-Lab/Awesome-DLMs"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/VILA-Lab/Awesome-DLMs</a>ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 17:47:22 UTC
å‘å¸ƒï¼š2025-08-14 17:47:22 UTC</p>
<h2 id="2-ssrl-self-search-reinforcement-learning"><a href="https://arxiv.org/abs/2508.10874"target="_blank" rel="external nofollow noopener noreferrer">#2</a> <a href="https://papers.cool/arxiv/2508.10874"target="_blank" rel="external nofollow noopener noreferrer">SSRL: Self-Search Reinforcement Learning</a></h2>
<p><strong>Authors</strong>: [Yuchen Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Fan), [Kaiyan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaiyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaiyan</a> Zhang), [Heng Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Heng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Heng</a> Zhou), [Yuxin Zuo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxin</a> Zuo), [Yanxu Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanxu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanxu</a> Chen), [Yu Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Fu), [Xinwei Long](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinwei</a> Long), [Xuekai Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuekai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuekai</a> Zhu), [Che Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Che"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Che</a> Jiang), [Yuchen Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Zhang), [Li Kang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Li"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Li</a> Kang), [Gang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gang</a> Chen), [Cheng Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cheng</a> Huang), [Zhizhou He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhizhou"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhizhou</a> He), [Bingning Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bingning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bingning</a> Wang), [Lei Bai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lei</a> Bai), [Ning Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ning</a> Ding), [Bowen Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Zhou)
ä½œè€…ï¼šYuchen Fan, Kaiyan Zhang, Heng Zhou, Yuxin Zuo, Yanxu Chen, Yu Fu, Xinwei Long, Xuekai Zhu, Che Jiang, Yuchen Zhang, Li Kang, Gang Chen, Cheng Huang, Zhizhou He, Bingning Wang, Lei Bai, Ning Ding, Bowen Zhou</p>
<p>We investigate the potential of large language models (LLMs) to serve as efficient simulators for agentic search tasks in reinforcement learning (RL), thereby reducing dependence on costly interactions with external search engines. To this end, we first quantify the intrinsic search capability of LLMs via structured prompting and repeated sampling, which we term Self-Search. Our results reveal that LLMs exhibit strong scaling behavior with respect to the inference budget, achieving high pass@k on question-answering benchmarks, including the challenging BrowseComp task. Building on these observations, we introduce Self-Search RL (SSRL), which enhances LLMs&rsquo; Self-Search capability through format-based and rule-based rewards. SSRL enables models to iteratively refine their knowledge utilization internally, without requiring access to external tools. Empirical evaluations demonstrate that SSRL-trained policy models provide a cost-effective and stable environment for search-driven RL training, reducing reliance on external search engines and facilitating robust sim-to-real transfer. We draw the following conclusions: 1) LLMs possess world knowledge that can be effectively elicited to achieve high performance; 2) SSRL demonstrates the potential of leveraging internal knowledge to reduce hallucination; 3) SSRL-trained models integrate seamlessly with external search engines without additional effort. Our findings highlight the potential of LLMs to support more scalable RL agent training.
æˆ‘ä»¬ç ”ç©¶äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸­å…·ä»£ç†æ€§çš„æœç´¢ä»»åŠ¡çš„é«˜æ•ˆæ¨¡æ‹Ÿå™¨çš„æ½œåŠ›ï¼Œä»è€Œå‡å°‘å¯¹æ˜‚è´µçš„å¤–éƒ¨æœç´¢å¼•æ“äº¤äº’çš„ä¾èµ–ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆé€šè¿‡ç»“æ„åŒ–æç¤ºå’Œé‡å¤é‡‡æ ·æ¥é‡åŒ– LLMs çš„å†…åœ¨æœç´¢èƒ½åŠ›ï¼Œç§°ä¹‹ä¸ºè‡ªæˆ‘æœç´¢ï¼ˆSelf-Searchï¼‰ã€‚æˆ‘ä»¬çš„ç»“æœæ˜¾ç¤ºï¼ŒLLMs åœ¨æ¨ç†é¢„ç®—æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—çš„å°ºåº¦æ•ˆåº”ï¼Œåœ¨é—®ç­”åŸºå‡†ä¸Šè¾¾åˆ°è¾ƒé«˜çš„ pass@kï¼ŒåŒ…æ‹¬å…·æœ‰æŒ‘æˆ˜æ€§çš„ BrowseComp ä»»åŠ¡ã€‚åŸºäºè¿™äº›è§‚å¯Ÿï¼Œæˆ‘ä»¬å¼•å…¥äº†è‡ªæˆ‘æœç´¢å¼ºåŒ–å­¦ä¹ ï¼ˆSelf-Search RLï¼ŒSSRLï¼‰ï¼Œé€šè¿‡åŸºäºæ ¼å¼å’ŒåŸºäºè§„åˆ™çš„å¥–åŠ±æ¥å¢å¼º LLMs çš„è‡ªæˆ‘æœç´¢èƒ½åŠ›ã€‚SSRL ä½¿æ¨¡å‹èƒ½å¤Ÿåœ¨å†…éƒ¨è¿­ä»£åœ°æ”¹è¿›å…¶çŸ¥è¯†åˆ©ç”¨ï¼Œè€Œæ— éœ€è®¿é—®å¤–éƒ¨å·¥å…·ã€‚å®è¯è¯„ä¼°è¡¨æ˜ï¼Œç» SSRL è®­ç»ƒçš„ç­–ç•¥æ¨¡å‹ä¸ºåŸºäºæœç´¢çš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæä¾›äº†å…·æœ‰æˆæœ¬æ•ˆç›Šä¸”ç¨³å®šçš„ç¯å¢ƒï¼Œå‡å°‘äº†å¯¹å¤–éƒ¨æœç´¢å¼•æ“çš„ä¾èµ–å¹¶ä¿ƒè¿›äº†ç¨³å¥çš„ä»¿çœŸåˆ°ç°å®è¿ç§»ã€‚ æˆ‘ä»¬å¾—å‡ºä»¥ä¸‹ç»“è®ºï¼š1ï¼‰LLMs æ‹¥æœ‰å¯è¢«æœ‰æ•ˆå¼•å¯¼ä»¥å®ç°é«˜æ€§èƒ½çš„ä¸–ç•ŒçŸ¥è¯†ï¼›2ï¼‰SSRL å±•ç¤ºäº†åˆ©ç”¨å†…éƒ¨çŸ¥è¯†å‡å°‘å¹»è§‰çš„æ½œåŠ›ï¼›3ï¼‰ç» SSRL è®­ç»ƒçš„æ¨¡å‹èƒ½å¤Ÿæ— é¢å¤–åŠªåŠ›åœ°ä¸å¤–éƒ¨æœç´¢å¼•æ“æ— ç¼é›†æˆã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœçªæ˜¾äº† LLMs åœ¨æ”¯æŒæ›´å…·å¯æ‰©å±•æ€§çš„å¼ºåŒ–å­¦ä¹ ä»£ç†è®­ç»ƒæ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 17:46:01 UTC
å‘å¸ƒï¼š2025-08-14 17:46:01 UTC</p>
<h2 id="3-from-black-box-to-transparency-enhancing-automated-interpreting-assessment-with-explainable-ai-in-college-classrooms--3-ä»é»‘ç®±åˆ°é€æ˜åœ¨å¤§å­¦è¯¾å ‚ä¸­å€ŸåŠ©å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºè‡ªåŠ¨å£è¯‘è¯„ä¼°"><a href="https://arxiv.org/abs/2508.10860"target="_blank" rel="external nofollow noopener noreferrer">#3</a> <a href="https://papers.cool/arxiv/2508.10860"target="_blank" rel="external nofollow noopener noreferrer">From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms</a>  #3 ä»é»‘ç®±åˆ°é€æ˜ï¼šåœ¨å¤§å­¦è¯¾å ‚ä¸­å€ŸåŠ©å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºè‡ªåŠ¨å£è¯‘è¯„ä¼°</h2>
<p><strong>Authors</strong>: [Zhaokun Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaokun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaokun</a> Jiang), [Ziyin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziyin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziyin</a> Zhang)
ä½œè€…ï¼šè’‹æ˜­å¤ï¼Œå¼ å­é“¶</p>
<p>Recent advancements in machine learning have spurred growing interests in automated interpreting quality assessment. Nevertheless, existing research suffers from insufficient examination of language use quality, unsatisfactory modeling effectiveness due to data scarcity and imbalance, and a lack of efforts to explain model predictions. To address these gaps, we propose a multi-dimensional modeling framework that integrates feature engineering, data augmentation, and explainable machine learning. This approach prioritizes explainability over ``black box&rsquo;&rsquo; predictions by utilizing only construct-relevant, transparent features and conducting Shapley Value (SHAP) analysis. Our results demonstrate strong predictive performance on a novel English-Chinese consecutive interpreting dataset, identifying BLEURT and CometKiwi scores to be the strongest predictive features for fidelity, pause-related features for fluency, and Chinese-specific phraseological diversity metrics for language use. Overall, by placing particular emphasis on explainability, we present a scalable, reliable, and transparent alternative to traditional human evaluation, facilitating the provision of detailed diagnostic feedback for learners and supporting self-regulated learning advantages not afforded by automated scores in isolation.
è¿‘æœŸæœºå™¨å­¦ä¹ çš„è¿›å±•æ¿€å‘äº†äººä»¬å¯¹è‡ªåŠ¨åŒ–å£è¯‘è´¨é‡è¯„ä¼°æ—¥ç›Šå¢é•¿çš„å…´è¶£ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶åœ¨è¯­è¨€ä½¿ç”¨è´¨é‡çš„æ£€éªŒæ–¹é¢ä¸å¤Ÿå……åˆ†ï¼Œç”±äºæ•°æ®ç¨€ç¼ºä¸ä¸å¹³è¡¡å¯¼è‡´å»ºæ¨¡æ•ˆæœä¸ä½³ï¼Œå¹¶ä¸”ç¼ºä¹å¯¹æ¨¡å‹é¢„æµ‹è¿›è¡Œè§£é‡Šçš„å·¥ä½œã€‚ä¸ºå¡«è¡¥è¿™äº›ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªèåˆç‰¹å¾å·¥ç¨‹ã€æ•°æ®å¢å¼ºå’Œå¯è§£é‡Šæœºå™¨å­¦ä¹ çš„å¤šç»´å»ºæ¨¡æ¡†æ¶ã€‚è¯¥æ–¹æ³•é€šè¿‡ä»…ä½¿ç”¨ä¸æ„å¿µç›¸å…³ä¸”é€æ˜çš„ç‰¹å¾å¹¶è¿›è¡Œ Shapley å€¼ï¼ˆSHAPï¼‰åˆ†æï¼Œå°†å¯è§£é‡Šæ€§ç½®äºâ€œé»‘ç®±â€é¢„æµ‹ä¹‹ä¸Šã€‚æˆ‘ä»¬çš„ç»“æœåœ¨ä¸€ä¸ªæ–°æ„å»ºçš„è‹±æ±‰äº¤æ›¿ä¼ è¯‘æ•°æ®é›†ä¸Šå±•ç¤ºäº†å¼ºå¤§çš„é¢„æµ‹æ€§èƒ½ï¼Œè¡¨æ˜ BLEURT å’Œ CometKiwi åˆ†æ•°æ˜¯å¿ å®åº¦çš„æœ€å¼ºé¢„æµ‹ç‰¹å¾ï¼Œæš‚åœç›¸å…³ç‰¹å¾å¯¹æµåˆ©åº¦æœ€å…·é¢„æµ‹åŠ›ï¼Œè€Œé’ˆå¯¹ä¸­æ–‡çš„çŸ­è¯­å¤šæ ·æ€§åº¦é‡åˆ™å¯¹è¯­è¨€ä½¿ç”¨å…·æœ‰é¢„æµ‹ä»·å€¼ã€‚ æ€»ä½“è€Œè¨€ï¼Œé€šè¿‡ç‰¹åˆ«å¼ºè°ƒå¯è§£é‡Šæ€§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯æ‰©å±•ã€å¯é ä¸”é€æ˜çš„æ›¿ä»£ä¼ ç»Ÿäººå·¥è¯„ä¼°çš„æ–¹æ³•ï¼Œä¾¿äºä¸ºå­¦ä¹ è€…æä¾›è¯¦ç»†çš„è¯Šæ–­æ€§åé¦ˆï¼Œå¹¶æ”¯æŒè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ çš„ä¼˜åŠ¿ï¼Œè€Œè¿™äº›ä¼˜åŠ¿ä»…é è‡ªåŠ¨è¯„åˆ†æ— æ³•å•ç‹¬å®ç°ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 17:31:18 UTC
å‘å¸ƒï¼š2025-08-14 17:31:18 UTC</p>
<h2 id="4-psyche-r1-towards-reliable-psychological-llms-through-unified-empathy-expertise-and-reasoning--4-psyche-r1é€šè¿‡ç»Ÿä¸€çš„åŒç†å¿ƒä¸“ä¸šæ€§ä¸æ¨ç†è¿ˆå‘å¯é çš„å¿ƒç†å­¦-llms"><a href="https://arxiv.org/abs/2508.10848"target="_blank" rel="external nofollow noopener noreferrer">#4</a> <a href="https://papers.cool/arxiv/2508.10848"target="_blank" rel="external nofollow noopener noreferrer">Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning</a>  #4 Psyche-R1ï¼šé€šè¿‡ç»Ÿä¸€çš„åŒç†å¿ƒã€ä¸“ä¸šæ€§ä¸æ¨ç†ï¼Œè¿ˆå‘å¯é çš„å¿ƒç†å­¦ LLMs</h2>
<p><strong>Authors</strong>: [Chongyuan Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chongyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chongyuan</a> Dai), [Jinpeng Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinpeng</a> Hu), [Hongchang Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongchang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongchang</a> Shi), [Zhuo Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuo</a> Li), [Xun Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xun</a> Yang), [Meng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meng</a> Wang)
ä½œè€…ï¼šæˆ´å´‡å…ƒã€èƒ¡é‡‘é¹ã€å²å®æ˜Œã€æå“ã€æ¨å¯»ã€æ±ªèŒ</p>
<p>Amidst a shortage of qualified mental health professionals, the integration of large language models (LLMs) into psychological applications offers a promising way to alleviate the growing burden of mental health disorders. Recent reasoning-augmented LLMs have achieved remarkable performance in mathematics and programming, while research in the psychological domain has predominantly emphasized emotional support and empathetic dialogue, with limited attention to reasoning mechanisms that are beneficial to generating reliable responses. Therefore, in this paper, we propose Psyche-R1, the first Chinese psychological LLM that jointly integrates empathy, psychological expertise, and reasoning, built upon a novel data curation pipeline. Specifically, we design a comprehensive data synthesis pipeline that produces over 75k high-quality psychological questions paired with detailed rationales, generated through chain-of-thought (CoT) reasoning and iterative prompt-rationale optimization, along with 73k empathetic dialogues. Subsequently, we employ a hybrid training strategy wherein challenging samples are identified through a multi-LLM cross-selection strategy for group relative policy optimization (GRPO) to improve reasoning ability, while the remaining data is used for supervised fine-tuning (SFT) to enhance empathetic response generation and psychological domain knowledge. Extensive experiment results demonstrate the effectiveness of the Psyche-R1 across several psychological benchmarks, where our 7B Psyche-R1 achieves comparable results to 671B DeepSeek-R1.
åœ¨åˆæ ¼å¿ƒç†å¥åº·ä¸“ä¸šäººå‘˜çŸ­ç¼ºçš„æƒ…å†µä¸‹ï¼Œå°† LLMs æ•´åˆåˆ°å¿ƒç†å­¦åº”ç”¨ä¸­ï¼Œä¸ºå‡è½»æ—¥ç›Šå¢é•¿çš„å¿ƒç†ç–¾ç—…è´Ÿæ‹…æä¾›äº†ä¸€ä¸ªæœ‰å‰æ™¯çš„é€”å¾„ã€‚è¿‘æœŸå¢å¼ºæ¨ç†èƒ½åŠ›çš„ LLMs åœ¨æ•°å­¦å’Œç¼–ç¨‹æ–¹é¢å–å¾—äº†æ˜¾è‘—è¡¨ç°ï¼Œè€Œå¿ƒç†å­¦é¢†åŸŸçš„ç ”ç©¶ä¸»è¦å¼ºè°ƒæƒ…æ„Ÿæ”¯æŒå’Œå…±æƒ…å¯¹è¯ï¼Œå¯¹æœ‰åŠ©äºç”Ÿæˆå¯é å›ç­”çš„æ¨ç†æœºåˆ¶å…³æ³¨è¾ƒå°‘ã€‚å› æ­¤ï¼Œåœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† Psyche-R1ï¼Œè¿™æ˜¯é¦–ä¸ªå°†å…±æƒ…ã€å¿ƒç†å­¦ä¸“ä¸šçŸ¥è¯†å’Œæ¨ç†å…±åŒæ•´åˆçš„ä¸­æ–‡å¿ƒç†å­¦ LLMï¼ŒåŸºäºä¸€ç§æ–°é¢–çš„æ•°æ®æ•´ç†æµç¨‹æ„å»ºã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå…¨é¢çš„æ•°æ®åˆæˆæµç¨‹ï¼Œç”Ÿæˆäº†è¶…è¿‡ 75 åƒæ¡é…æœ‰è¯¦ç»†æ¨ç†ä¾æ®çš„é«˜è´¨é‡å¿ƒç†å­¦é—®é¢˜ï¼Œè¿™äº›ä¾æ®é€šè¿‡è¿é”æ€ç»´ï¼ˆCoTï¼‰æ¨ç†å’Œè¿­ä»£æç¤ºâ€”æ¨ç†ä¼˜åŒ–ç”Ÿæˆï¼Œå¦å¤–è¿˜åŒ…å« 73 åƒæ¡å…±æƒ…å¯¹è¯ã€‚ éšåï¼Œæˆ‘ä»¬é‡‡ç”¨æ··åˆè®­ç»ƒç­–ç•¥ï¼šé€šè¿‡å¤š-LLM äº¤å‰ç­›é€‰ç­–ç•¥è¯†åˆ«å…·æœ‰æŒ‘æˆ˜æ€§çš„æ ·æœ¬ï¼Œç”¨äºç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGRPOï¼‰ä»¥æå‡æ¨ç†èƒ½åŠ›ï¼Œè€Œå°†å‰©ä½™æ•°æ®ç”¨äºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œä»¥å¢å¼ºå…±æƒ…å›åº”ç”Ÿæˆå’Œå¿ƒç†å­¦é¢†åŸŸçŸ¥è¯†ã€‚å¤§é‡å®éªŒç»“æœè¡¨æ˜ï¼ŒPsyche-R1 åœ¨å¤šä¸ªå¿ƒç†å­¦åŸºå‡†ä¸Šè¡¨ç°æœ‰æ•ˆï¼Œæˆ‘ä»¬çš„ 7B Psyche-R1 åœ¨ç»“æœä¸Šå¯ä¸ 671B DeepSeek-R1 ç›¸åª²ç¾ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 17:18:35 UTC
å‘å¸ƒï¼š2025-08-14 17:18:35 UTC</p>
<h2 id="5-reinforced-language-models-for-sequential-decision-making--5-å¼ºåŒ–è¯­è¨€æ¨¡å‹ç”¨äºåºè´¯å†³ç­–åˆ¶å®š"><a href="https://arxiv.org/abs/2508.10839"target="_blank" rel="external nofollow noopener noreferrer">#5</a> <a href="https://papers.cool/arxiv/2508.10839"target="_blank" rel="external nofollow noopener noreferrer">Reinforced Language Models for Sequential Decision Making</a>  #5 å¼ºåŒ–è¯­è¨€æ¨¡å‹ç”¨äºåºè´¯å†³ç­–åˆ¶å®š</h2>
<p><strong>Authors</strong>: [Jim Dilkes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jim</a> Dilkes), [Vahid Yazdanpanah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vahid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vahid</a> Yazdanpanah), [Sebastian Stein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sebastian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sebastian</a> Stein)
ä½œè€…ï¼šJim Dilkes, Vahid Yazdanpanah, Sebastian Stein</p>
<p>Large Language Models (LLMs) show potential as sequential decision-making agents, but their application is often limited due to a reliance on large, computationally expensive models. This creates a need to improve smaller models, yet existing post-training methods are designed for single-turn interactions and cannot handle credit assignment in multi-step agentic tasks. To address this, we introduce Multi-Step Group-Relative Policy Optimization (MS-GRPO), a new algorithm for post-training LLM agents, grounded in formal Text-Mediated Stochastic Game (TSMG) and Language-Agent Policy (LAP) frameworks. For credit assignment, MS-GRPO attributes the entire cumulative episode reward to each individual episode step. We supplement this algorithm with a novel absolute-advantage-weighted episode sampling strategy that we show improves training performance. We evaluate our approach by post-training a 3-billion parameter model on Snake and Frozen Lake. Our experiments demonstrate that the method is effective in improving decision-making performance: our post-trained 3B parameter model outperforms a 72B parameter baseline by 50% on the Frozen Lake task. This work demonstrates that targeted post-training is a practical and efficient alternative to relying on model scale for creating sequential decision-making agents using LLMs.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨åºåˆ—å†³ç­–ä»£ç†æ–¹é¢æ˜¾ç¤ºå‡ºæ½œåŠ›ï¼Œä½†å…¶åº”ç”¨å¸¸å› ä¾èµ–å¤§å‹ã€è®¡ç®—æˆæœ¬é«˜çš„æ¨¡å‹è€Œå—é™ã€‚è¿™å°±éœ€è¦æ”¹è¿›æ›´å°çš„æ¨¡å‹ï¼Œç„¶è€Œç°æœ‰çš„åè®­ç»ƒæ–¹æ³•æ˜¯ä¸ºå•è½®äº¤äº’è®¾è®¡çš„ï¼Œæ— æ³•åº”å¯¹å¤šæ­¥ä»£ç†ä»»åŠ¡ä¸­çš„åŠŸåŠ³å½’å±é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šæ­¥ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆMulti-Step Group-Relative Policy Optimizationï¼ŒMS-GRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºåè®­ç»ƒ LLM ä»£ç†çš„æ–°ç®—æ³•ï¼ŒåŸºäºå½¢å¼åŒ–çš„æ–‡æœ¬ä»‹å¯¼éšæœºåšå¼ˆï¼ˆText-Mediated Stochastic Gameï¼ŒTSMGï¼‰å’Œè¯­è¨€ä»£ç†ç­–ç•¥ï¼ˆLanguage-Agent Policyï¼ŒLAPï¼‰æ¡†æ¶ã€‚ä¸ºè¿›è¡ŒåŠŸåŠ³å½’å±ï¼ŒMS-GRPO å°†æ•´ä¸ªç´¯ç§¯çš„è½¨è¿¹å›æŠ¥å½’å› äºæ¯ä¸ªå•ç‹¬çš„è½¨è¿¹æ­¥éª¤ã€‚æˆ‘ä»¬ä¸ºè¯¥ç®—æ³•è¡¥å……äº†ä¸€ç§æ–°é¢–çš„ç»å¯¹ä¼˜åŠ¿åŠ æƒè½¨è¿¹é‡‡æ ·ç­–ç•¥ï¼Œå¹¶è¯æ˜è¯¥ç­–ç•¥èƒ½æå‡è®­ç»ƒæ€§èƒ½ã€‚æˆ‘ä»¬é€šè¿‡åœ¨ Snake å’Œ Frozen Lake ä¸Šå¯¹ä¸€ä¸ª 30 äº¿å‚æ•°æ¨¡å‹è¿›è¡Œåè®­ç»ƒæ¥è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æå‡å†³ç­–æ€§èƒ½æ–¹é¢æ˜¯æœ‰æ•ˆçš„ï¼šæˆ‘ä»¬åè®­ç»ƒçš„ 30 äº¿å‚æ•°æ¨¡å‹åœ¨ Frozen Lake ä»»åŠ¡ä¸Šæ¯”ä¸€ä¸ª 720 äº¿å‚æ•°çš„åŸºçº¿æ¨¡å‹é«˜å‡º 50%ã€‚ è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œæœ‰é’ˆå¯¹æ€§çš„è®­ç»ƒåè°ƒæ•´æ˜¯ä½¿ç”¨ LLMs åˆ›å»ºåºè´¯å†³ç­–ä»£ç†æ—¶ä¸€ç§å®ç”¨ä¸”é«˜æ•ˆçš„æ›¿ä»£æ–¹æ¡ˆï¼Œè€Œæ— éœ€ä¾èµ–æ¨¡å‹è§„æ¨¡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 17:05:44 UTC
å‘å¸ƒï¼š2025-08-14 17:05:44 UTC</p>
<h2 id="6-beyond-34not-novel-enough34-enriching-scholarly-critique-with-llm-assisted-feedback--6-è¶…è¶Šåˆ›æ–°æ€§ä¸è¶³é€šè¿‡-llm-è¾…åŠ©åé¦ˆä¸°å¯Œå­¦æœ¯è¯„å®¡æ‰¹è¯„"><a href="https://arxiv.org/abs/2508.10795"target="_blank" rel="external nofollow noopener noreferrer">#6</a> <a href="https://papers.cool/arxiv/2508.10795"target="_blank" rel="external nofollow noopener noreferrer">Beyond &quot;Not Novel Enough&quot;: Enriching Scholarly Critique with LLM-Assisted Feedback</a>  #6 è¶…è¶Šâ€œåˆ›æ–°æ€§ä¸è¶³â€ï¼šé€šè¿‡ LLM è¾…åŠ©åé¦ˆä¸°å¯Œå­¦æœ¯è¯„å®¡æ‰¹è¯„</h2>
<p><strong>Authors</strong>: [Osama Mohammed Afzal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Osama"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Osama</a> Mohammed Afzal), [Preslav Nakov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Preslav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Preslav</a> Nakov), [Tom Hope](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tom"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tom</a> Hope), [Iryna Gurevych](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iryna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iryna</a> Gurevych)
ä½œè€…ï¼šOsama Mohammed Afzalã€Preslav Nakovã€Tom Hopeã€Iryna Gurevych</p>
<p>Novelty assessment is a central yet understudied aspect of peer review, particularly in high volume fields like NLP where reviewer capacity is increasingly strained. We present a structured approach for automated novelty evaluation that models expert reviewer behavior through three stages: content extraction from submissions, retrieval and synthesis of related work, and structured comparison for evidence based assessment. Our method is informed by a large scale analysis of human written novelty reviews and captures key patterns such as independent claim verification and contextual reasoning. Evaluated on 182 ICLR 2025 submissions with human annotated reviewer novelty assessments, the approach achieves 86.5% alignment with human reasoning and 75.3% agreement on novelty conclusions - substantially outperforming existing LLM based baselines. The method produces detailed, literature aware analyses and improves consistency over ad hoc reviewer judgments. These results highlight the potential for structured LLM assisted approaches to support more rigorous and transparent peer review without displacing human expertise. Data and code are made available.
æ–°é¢–æ€§è¯„ä¼°æ˜¯åŒè¡Œè¯„å®¡ä¸­ä¸€ä¸ªæ ¸å¿ƒä½†ç ”ç©¶ä¸è¶³çš„æ–¹é¢ï¼Œå°¤å…¶åœ¨åƒ NLP è¿™æ ·å®¡ç¨¿é‡æ—¥ç›Šå¢åŠ ã€è¯„å®¡èƒ½åŠ›è¶Šæ¥è¶Šç´§å¼ çš„é¢†åŸŸã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºè‡ªåŠ¨åŒ–æ–°é¢–æ€§è¯„ä¼°çš„ç»“æ„åŒ–æ–¹æ³•ï¼Œé€šè¿‡ä¸‰ä¸ªé˜¶æ®µæ¨¡æ‹Ÿä¸“å®¶å®¡ç¨¿äººçš„è¡Œä¸ºï¼šä»æŠ•ç¨¿ä¸­æå–å†…å®¹ã€æ£€ç´¢å¹¶ç»¼åˆç›¸å…³å·¥ä½œï¼Œä»¥åŠè¿›è¡Œç»“æ„åŒ–æ¯”è¾ƒä»¥è¿›è¡ŒåŸºäºè¯æ®çš„è¯„ä¼°ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä»¥å¤§è§„æ¨¡çš„äººç±»æ’°å†™çš„æ–°é¢–æ€§è¯„å®¡åˆ†æä¸ºä¾æ®ï¼Œå¹¶æ•æ‰åˆ°è¯¸å¦‚ç‹¬ç«‹éªŒè¯è®ºç‚¹å’Œæƒ…å¢ƒåŒ–æ¨ç†ç­‰å…³é”®æ¨¡å¼ã€‚åœ¨å¯¹ 182 ç¯‡ ICLR 2025 æŠ•ç¨¿ï¼ˆé™„æœ‰äººç±»æ³¨é‡Šçš„å®¡ç¨¿äººæ–°é¢–æ€§è¯„ä¼°ï¼‰è¿›è¡Œè¯„ä¼°æ—¶ï¼Œè¯¥æ–¹æ³•åœ¨ä¸äººç±»æ¨ç†çš„ä¸€è‡´æ€§ä¸Šè¾¾åˆ°äº† 86.5%ï¼Œåœ¨æ–°é¢–æ€§ç»“è®ºä¸Šçš„ä¸€è‡´ç‡ä¸º 75.3%â€”â€”æ˜¾è‘—ä¼˜äºç°æœ‰åŸºäº LLM çš„åŸºçº¿æ–¹æ³•ã€‚è¯¥æ–¹æ³•ç”Ÿæˆäº†è¯¦å°½ã€è€ƒè™‘æ–‡çŒ®çš„åˆ†æï¼Œå¹¶æé«˜äº†ç›¸è¾ƒäºä¸´æ—¶æ€§å®¡ç¨¿åˆ¤æ–­çš„ä¸€è‡´æ€§ã€‚è¿™äº›ç»“æœå‡¸æ˜¾äº†ç»“æ„åŒ–çš„ LLM è¾…åŠ©æ–¹æ³•åœ¨æ”¯æŒæ›´ä¸¥æ ¼å’Œæ›´é€æ˜çš„åŒè¡Œè¯„å®¡æ–¹é¢çš„æ½œåŠ›ï¼ŒåŒæ—¶ä¸å–ä»£äººç±»ä¸“ä¸šåˆ¤æ–­ã€‚æ•°æ®å’Œä»£ç å·²å…¬å¼€ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 16:18:37 UTC
å‘å¸ƒï¼š2025-08-14 16:18:37 UTC</p>
<h2 id="7-thinking-inside-the-mask-in-place-prompting-in-diffusion-llms--7-æ€è€ƒåœ¨æ©ç ä¹‹å†…æ‰©æ•£-llm-ä¸­çš„åŸä½æç¤ºin-place-prompting"><a href="https://arxiv.org/abs/2508.10736"target="_blank" rel="external nofollow noopener noreferrer">#7</a> <a href="https://papers.cool/arxiv/2508.10736"target="_blank" rel="external nofollow noopener noreferrer">Thinking Inside the Mask: In-Place Prompting in Diffusion LLMs</a>  #7 æ€è€ƒåœ¨æ©ç ä¹‹å†…ï¼šæ‰©æ•£ LLM ä¸­çš„åŸä½æç¤ºï¼ˆIn-Place Promptingï¼‰</h2>
<p><strong>Authors</strong>: [Xiangqi Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiangqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiangqi</a> Jin), [Yuxuan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxuan</a> Wang), [Yifeng Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yifeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yifeng</a> Gao), [Zichen Wen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zichen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zichen</a> Wen), [Biqing Qi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Biqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Biqing</a> Qi), [Dongrui Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongrui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongrui</a> Liu), [Linfeng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Linfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Linfeng</a> Zhang)
ä½œè€…ï¼šé‡‘æ¹˜ç¥ºã€ç‹å®‡è½©ã€é«˜ä¸€å³°ã€æ¸©å­å®¸ã€é½ç¢§é’ã€åˆ˜ä¸œç¿ã€å¼ æ—å³°</p>
<p>Despite large language models (LLMs) have achieved remarkable success, their prefix-only prompting paradigm and sequential generation process offer limited flexibility for bidirectional information. Diffusion large language models (dLLMs) present new opportunities through their bidirectional attention mechanisms and iterative refinement processes, enabling more flexible in-place prompting strategies. We introduce ICE (In-Place Chain-of-Thought Prompting with Early Exit), a novel framework that transforms prefix-only prompting into in-place prompting specifically designed for dLLMs. ICE integrates in-place prompts directly within masked token positions during iterative refinement and employs a confidence-aware early exit mechanism to significantly reduce computational overhead. Extensive experiments demonstrate ICE&rsquo;s effectiveness, achieving up to 17.29% accuracy improvement with 4.12Ã— speedup on GSM8K, and up to 276.67Ã— acceleration on MMLU while maintaining competitive performance.
å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å–å¾—äº†æ˜¾è‘—æˆåŠŸï¼Œä½†å®ƒä»¬çš„ä»…å‰ç¼€æç¤ºèŒƒå¼å’Œé¡ºåºç”Ÿæˆè¿‡ç¨‹åœ¨åŒå‘ä¿¡æ¯æ–¹é¢çµæ´»æ€§æœ‰é™ã€‚æ‰©æ•£å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆdLLMsï¼‰é€šè¿‡å…¶åŒå‘æ³¨æ„åŠ›æœºåˆ¶å’Œè¿­ä»£ç»†åŒ–è¿‡ç¨‹å¸¦æ¥äº†æ–°çš„å¯èƒ½æ€§ï¼Œä½¿å¾—æ›´çµæ´»çš„å°±åœ°æç¤ºç­–ç•¥æˆä¸ºå¯èƒ½ã€‚æˆ‘ä»¬æå‡ºäº† ICEï¼ˆå¸¦æ—©åœçš„å°±åœ°é“¾å¼æ€ç»´æç¤ºï¼ŒIn-Place Chain-of-Thought Prompting with Early Exitï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªå°†ä»…å‰ç¼€æç¤ºè½¬åŒ–ä¸ºä¸“ä¸º dLLMs è®¾è®¡çš„å°±åœ°æç¤ºçš„å…¨æ–°æ¡†æ¶ã€‚ICE åœ¨è¿­ä»£ç»†åŒ–è¿‡ç¨‹ä¸­å°†å°±åœ°æç¤ºç›´æ¥æ•´åˆåˆ°è¢«æ©ç›–çš„æ ‡è®°ä½ç½®ï¼Œå¹¶é‡‡ç”¨åŸºäºç½®ä¿¡åº¦çš„æ—©åœæœºåˆ¶ä»¥æ˜¾è‘—é™ä½è®¡ç®—å¼€é”€ã€‚å¤§é‡å®éªŒè¯æ˜äº† ICE çš„æœ‰æ•ˆæ€§ï¼Œåœ¨ GSM8K ä¸Šæœ€å¤šå®ç° 17.29% çš„å‡†ç¡®ç‡æå‡å¹¶å¸¦æ¥ 4.12 å€çš„åŠ é€Ÿï¼Œåœ¨ MMLU ä¸Šæœ€é«˜å®ç° 276.67 å€çš„åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒå…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 15:16:25 UTC
å‘å¸ƒï¼š2025-08-14 15:16:25 UTC</p>
<h2 id="8-learning-from-natural-language-feedback-for-personalized-question-answering--8-ä»è‡ªç„¶è¯­è¨€åé¦ˆä¸­å­¦ä¹ ä»¥å®ç°ä¸ªæ€§åŒ–é—®ç­”"><a href="https://arxiv.org/abs/2508.10695"target="_blank" rel="external nofollow noopener noreferrer">#8</a> <a href="https://papers.cool/arxiv/2508.10695"target="_blank" rel="external nofollow noopener noreferrer">Learning from Natural Language Feedback for Personalized Question Answering</a>  #8 ä»è‡ªç„¶è¯­è¨€åé¦ˆä¸­å­¦ä¹ ä»¥å®ç°ä¸ªæ€§åŒ–é—®ç­”</h2>
<p><strong>Authors</strong>: [Alireza Salemi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alireza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alireza</a> Salemi), [Hamed Zamani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hamed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hamed</a> Zamani)
ä½œè€…ï¼šAlireza Salemiï¼ŒHamed Zamani</p>
<p>Personalization is crucial for enhancing both the effectiveness and user satisfaction of language technologies, particularly in information-seeking tasks like question answering. Current approaches for personalizing large language models (LLMs) often rely on retrieval-augmented generation (RAG), followed by reinforcement learning with scalar reward signals to teach models how to use retrieved personal context. We believe that these scalar rewards sometimes provide weak, non-instructive feedback, limiting learning efficiency and personalization quality. We introduce VAC, a novel framework for personalized response generation that replaces scalar rewards with natural language feedback (NLF) that are generated conditioned on the user profiles and the question narratives. NLF serves as a rich and actionable supervision signal, allowing the policy model to iteratively refine its outputs and internalize effective personalization strategies. Training alternates between optimizing the feedback model and fine-tuning the policy model on the improved responses, resulting in a policy model that no longer requires feedback at inference. Evaluation on the LaMP-QA benchmark that consists of three diverse domains demonstrates consistent and significant improvements over the state-of-the-art results. Human evaluations further confirm the superior quality of the generated responses. These results demonstrate that NLF provides more effective signals for optimizing personalized question answering.
ä¸ªæ€§åŒ–å¯¹äºæå‡è¯­è¨€æŠ€æœ¯çš„æ•ˆæœå’Œç”¨æˆ·æ»¡æ„åº¦è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨åƒé—®ç­”è¿™æ ·çš„ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­ã€‚å½“å‰å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œä¸ªæ€§åŒ–çš„å¸¸ç”¨æ–¹æ³•é€šå¸¸ä¾èµ–æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ï¼Œéšåä½¿ç”¨æ ‡é‡å¥–åŠ±ä¿¡å·çš„å¼ºåŒ–å­¦ä¹ æ¥æ•™æ¨¡å‹å¦‚ä½•åˆ©ç”¨æ£€ç´¢åˆ°çš„ä¸ªäººä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™äº›æ ‡é‡å¥–åŠ±æœ‰æ—¶æä¾›çš„æ˜¯è–„å¼±ä¸”ä¸å…·æŒ‡å¯¼æ€§çš„åé¦ˆï¼Œé™åˆ¶äº†å­¦ä¹ æ•ˆç‡å’Œä¸ªæ€§åŒ–è´¨é‡ã€‚æˆ‘ä»¬æå‡ºäº† VACï¼Œä¸€ç§ç”¨äºä¸ªæ€§åŒ–å“åº”ç”Ÿæˆçš„æ–°æ¡†æ¶ï¼Œç”¨ä»¥å°†æ ‡é‡å¥–åŠ±æ›¿æ¢ä¸ºåŸºäºç”¨æˆ·æ¡£æ¡ˆå’Œé—®é¢˜å™è¿°æ¡ä»¶ç”Ÿæˆçš„è‡ªç„¶è¯­è¨€åé¦ˆï¼ˆNLFï¼‰ã€‚è‡ªç„¶è¯­è¨€åé¦ˆä½œä¸ºä¸€ç§ä¸°å¯Œä¸”å¯æ‰§è¡Œçš„ç›‘ç£ä¿¡å·ï¼Œä½¿ç­–ç•¥æ¨¡å‹èƒ½å¤Ÿè¿­ä»£åœ°æ”¹è¿›å…¶è¾“å‡ºå¹¶å†…åŒ–æœ‰æ•ˆçš„ä¸ªæ€§åŒ–ç­–ç•¥ã€‚è®­ç»ƒåœ¨ä¼˜åŒ–åé¦ˆæ¨¡å‹å’Œåœ¨æ”¹è¿›åçš„å“åº”ä¸Šå¾®è°ƒç­–ç•¥æ¨¡å‹ä¹‹é—´äº¤æ›¿è¿›è¡Œï¼Œæœ€ç»ˆå¾—åˆ°çš„ç­–ç•¥æ¨¡å‹åœ¨æ¨ç†æ—¶ä¸å†éœ€è¦åé¦ˆã€‚ åœ¨ç”±ä¸‰ç±»ä¸åŒé¢†åŸŸç»„æˆçš„ LaMP-QA åŸºå‡†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œç›¸è¾ƒäºæœ€å…ˆè¿›ç»“æœï¼Œæ€§èƒ½æŒç»­ä¸”æ˜¾è‘—æå‡ã€‚äººå·¥è¯„ä¼°è¿›ä¸€æ­¥ç¡®è®¤äº†ç”Ÿæˆå›ç­”çš„æ›´é«˜è´¨é‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒNLF ä¸ºä¼˜åŒ–ä¸ªæ€§åŒ–é—®ç­”æä¾›äº†æ›´æœ‰æ•ˆçš„ä¿¡å·ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€ä¿¡æ¯æ£€ç´¢</p>
<p><strong>Publish</strong>: 2025-08-14 14:36:53 UTC
å‘å¸ƒï¼š2025-08-14 14:36:53 UTC</p>
<h2 id="9-continuous-bangla-sign-language-translation-mitigating-the-expense-of-gloss-annotation-with-the-assistance-of-graph--9-è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘åœ¨å›¾æ¨¡å‹è¾…åŠ©ä¸‹ç¼“è§£é€è¯æ³¨é‡Šçš„é«˜æ˜‚æˆæœ¬"><a href="https://arxiv.org/abs/2508.10687"target="_blank" rel="external nofollow noopener noreferrer">#9</a> <a href="https://papers.cool/arxiv/2508.10687"target="_blank" rel="external nofollow noopener noreferrer">Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph</a>  #9 è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘ï¼šåœ¨å›¾æ¨¡å‹è¾…åŠ©ä¸‹ç¼“è§£é€è¯æ³¨é‡Šçš„é«˜æ˜‚æˆæœ¬</h2>
<p><strong>Authors</strong>: [Safaeid Hossain Arib](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Safaeid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Safaeid</a> Hossain Arib), [Rabeya Akter](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rabeya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rabeya</a> Akter), [Sejuti Rahman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sejuti"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sejuti</a> Rahman)
ä½œè€…ï¼šSafaeid Hossain Aribã€Rabeya Akterã€Sejuti Rahman</p>
<p>Millions of individuals worldwide are affected by deafness and hearing impairment. Sign language serves as a sophisticated means of communication for the deaf and hard of hearing. However, in societies that prioritize spoken languages, sign language often faces underestimation, leading to communication barriers and social exclusion. The Continuous Bangla Sign Language Translation project aims to address this gap by enhancing translation methods. While recent approaches leverage transformer architecture for state-of-the-art results, our method integrates graph-based methods with the transformer architecture. This fusion, combining transformer and STGCN-LSTM architectures, proves more effective in gloss-free translation. Our contributions include architectural fusion, exploring various fusion strategies, and achieving a new state-of-the-art performance on diverse sign language datasets, namely RWTH-PHOENIX-2014T, CSL-Daily, How2Sign, and BornilDB v1.0. Our approach demonstrates superior performance compared to current translation outcomes across all datasets, showcasing notable improvements of BLEU-4 scores of 4.01, 2.07, and 0.5, surpassing those of GASLT, GASLT and slt_how2sign in RWTH-PHOENIX-2014T, CSL-Daily, and How2Sign, respectively. Also, we introduce benchmarking on the BornilDB v1.0 dataset for the first time. Our method sets a benchmark for future research, emphasizing the importance of gloss-free translation to improve communication accessibility for the deaf and hard of hearing.
å…¨çƒæœ‰æ•°ç™¾ä¸‡äººå—åˆ°è€³è‹å’Œå¬åŠ›æŸä¼¤çš„å½±å“ã€‚æ‰‹è¯­æ˜¯è‹äººå’Œé‡å¬è€…çš„ä¸€ç§å¤æ‚çš„äº¤æµæ‰‹æ®µã€‚ç„¶è€Œï¼Œåœ¨ä»¥å£è¯­ä¸ºä¸»çš„ç¤¾ä¼šä¸­ï¼Œæ‰‹è¯­å¸¸å¸¸è¢«ä½ä¼°ï¼Œå¯¼è‡´äº¤æµéšœç¢å’Œç¤¾ä¼šæ’æ–¥ã€‚ã€Šè¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘ã€‹é¡¹ç›®æ—¨åœ¨é€šè¿‡æ”¹è¿›ç¿»è¯‘æ–¹æ³•æ¥å¼¥è¡¥è¿™ä¸€å·®è·ã€‚å°½ç®¡è¿‘æœŸçš„æ–¹æ³•åˆ©ç”¨å˜æ¢å™¨ï¼ˆtransformerï¼‰æ¶æ„å–å¾—äº†æœ€å…ˆè¿›çš„æˆæœï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†åŸºäºå›¾çš„æ–¹æ³•ä¸å˜æ¢å™¨æ¶æ„ç›¸ç»“åˆã€‚è¿™ç§å°†å˜æ¢å™¨ä¸ STGCN-LSTM æ¶æ„èåˆçš„æ–¹æ³•è¢«è¯æ˜åœ¨æ— è¯æ±‡è¡¨ï¼ˆgloss-freeï¼‰ç¿»è¯‘ä¸­æ›´ä¸ºæœ‰æ•ˆã€‚ æˆ‘ä»¬çš„è´¡çŒ®åŒ…æ‹¬æ¶æ„èåˆã€æ¢ç´¢å¤šç§èåˆç­–ç•¥ï¼Œå¹¶åœ¨å¤šä¸ªæ‰‹è¯­æ•°æ®é›†ä¸Šå–å¾—äº†æ–°çš„æœ€å…ˆè¿›è¡¨ç°ï¼Œå…·ä½“ä¸º RWTH-PHOENIX-2014Tã€CSL-Dailyã€How2Sign å’Œ BornilDB v1.0ã€‚ä¸ç°æœ‰ç¿»è¯‘ç»“æœç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šå‡è¡¨ç°ä¼˜å¼‚ï¼Œå…¶ä¸­åœ¨ BLEU-4 ä¸Šåˆ†åˆ«æ¯” GASLTã€GASLT å’Œ slt_how2sign åœ¨ RWTH-PHOENIX-2014Tã€CSL-Daily å’Œ How2Sign ä¸Šæé«˜äº† 4.01ã€2.07 å’Œ 0.5ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é¦–æ¬¡åœ¨ BornilDB v1.0 æ•°æ®é›†ä¸Šå¼•å…¥äº†åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºæœªæ¥ç ”ç©¶è®¾å®šäº†åŸºå‡†ï¼Œå¼ºè°ƒæ— æ³¨é‡Šè¯æ±‡ï¼ˆgloss-freeï¼‰ç¿»è¯‘åœ¨æ”¹å–„è‹äººä¸é‡å¬è€…äº¤æµå¯åŠæ€§æ–¹é¢çš„é‡è¦æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 14:32:31 UTC
å‘å¸ƒï¼š2025-08-14 14:32:31 UTC</p>
<h2 id="10-neural-machine-translation-for-coptic-french-strategies-for-low-resource-ancient-languages--10-ç§‘æ™®ç‰¹è¯­æ³•è¯­ç¥ç»æœºå™¨ç¿»è¯‘é’ˆå¯¹èµ„æºç¨€ç¼ºå¤ä»£è¯­è¨€çš„ç­–ç•¥"><a href="https://arxiv.org/abs/2508.10683"target="_blank" rel="external nofollow noopener noreferrer">#10</a> <a href="https://papers.cool/arxiv/2508.10683"target="_blank" rel="external nofollow noopener noreferrer">Neural Machine Translation for Coptic-French: Strategies for Low-Resource Ancient Languages</a>  #10 ç§‘æ™®ç‰¹è¯­â€”æ³•è¯­ç¥ç»æœºå™¨ç¿»è¯‘ï¼šé’ˆå¯¹èµ„æºç¨€ç¼ºå¤ä»£è¯­è¨€çš„ç­–ç•¥</h2>
<p><strong>Authors</strong>: [Nasma Chaoui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nasma"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nasma</a> Chaoui), [Richard Khoury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Richard"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Richard</a> Khoury)
ä½œè€…ï¼šNasma Chaouiï¼ŒRichard Khoury</p>
<p>This paper presents the first systematic study of strategies for translating Coptic into French. Our comprehensive pipeline systematically evaluates: pivot versus direct translation, the impact of pre-training, the benefits of multi-version fine-tuning, and model robustness to noise. Utilizing aligned biblical corpora, we demonstrate that fine-tuning with a stylistically-varied and noise-aware training corpus significantly enhances translation quality. Our findings provide crucial practical insights for developing translation tools for historical languages in general.
æœ¬æ–‡é¦–æ¬¡å¯¹å°†ç§‘æ™®ç‰¹è¯­ç¿»è¯‘æˆæ³•è¯­çš„ç­–ç•¥è¿›è¡Œäº†ç³»ç»Ÿæ€§ç ”ç©¶ã€‚æˆ‘ä»¬çš„å…¨é¢æµç¨‹ç³»ç»Ÿè¯„ä¼°äº†ï¼šæ¢è½´ç¿»è¯‘ä¸ç›´æ¥ç¿»è¯‘ã€é¢„è®­ç»ƒçš„å½±å“ã€å¤šç‰ˆæœ¬å¾®è°ƒçš„ç›Šå¤„ä»¥åŠæ¨¡å‹å¯¹å™ªå£°çš„é²æ£’æ€§ã€‚åˆ©ç”¨å¯¹é½çš„åœ£ç»è¯­æ–™ï¼Œæˆ‘ä»¬è¯æ˜äº†ä½¿ç”¨é£æ ¼å¤šæ ·ä¸”è€ƒè™‘å™ªå£°çš„è®­ç»ƒè¯­æ–™è¿›è¡Œå¾®è°ƒèƒ½æ˜¾è‘—æå‡ç¿»è¯‘è´¨é‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœä¸ºå¼€å‘é¢å‘å†å²è¯­è¨€çš„ç¿»è¯‘å·¥å…·æä¾›äº†å…³é”®çš„å®ç”¨è§è§£ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 14:25:34 UTC
å‘å¸ƒï¼š2025-08-14 14:25:34 UTC</p>
<h2 id="11-edif-a-european-deep-inference-fabric-for-remote-interpretability-of-llm"><a href="https://arxiv.org/abs/2508.10553"target="_blank" rel="external nofollow noopener noreferrer">#11</a> <a href="https://papers.cool/arxiv/2508.10553"target="_blank" rel="external nofollow noopener noreferrer">eDIF: A European Deep Inference Fabric for Remote Interpretability of LLM</a></h2>
<p><strong>Authors</strong>: [Irma Heithoff. Marc Guggenberger](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Irma"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Irma</a> Heithoff. Marc Guggenberger), [Sandra Kalogiannis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sandra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sandra</a> Kalogiannis), [Susanne Mayer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Susanne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Susanne</a> Mayer), [Fabian Maag](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fabian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fabian</a> Maag), [Sigurd Schacht](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sigurd"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sigurd</a> Schacht), [Carsten Lanquillon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Carsten"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Carsten</a> Lanquillon)
ä½œè€…ï¼šIrma Heithoffã€Marc Guggenbergerã€Sandra Kalogiannisã€Susanne Mayerã€Fabian Maagã€Sigurd Schachtã€Carsten Lanquillon</p>
<p>This paper presents a feasibility study on the deployment of a European Deep Inference Fabric (eDIF), an NDIF-compatible infrastructure designed to support mechanistic interpretability research on large language models. The need for widespread accessibility of LLM interpretability infrastructure in Europe drives this initiative to democratize advanced model analysis capabilities for the research community. The project introduces a GPU-based cluster hosted at Ansbach University of Applied Sciences and interconnected with partner institutions, enabling remote model inspection via the NNsight API. A structured pilot study involving 16 researchers from across Europe evaluated the platform&rsquo;s technical performance, usability, and scientific utility. Users conducted interventions such as activation patching, causal tracing, and representation analysis on models including GPT-2 and DeepSeek-R1-70B. The study revealed a gradual increase in user engagement, stable platform performance throughout, and a positive reception of the remote experimentation capabilities. It also marked the starting point for building a user community around the platform. Identified limitations such as prolonged download durations for activation data as well as intermittent execution interruptions are addressed in the roadmap for future development. This initiative marks a significant step towards widespread accessibility of LLM interpretability infrastructure in Europe and lays the groundwork for broader deployment, expanded tooling, and sustained community collaboration in mechanistic interpretability research.
æœ¬æ–‡æå‡ºäº†ä¸€é¡¹å…³äºåœ¨æ¬§æ´²éƒ¨ç½²æ·±åº¦æ¨ç†ç½‘ç»œï¼ˆeDIFï¼‰çš„å¯è¡Œæ€§ç ”ç©¶ï¼Œè¯¥åŸºç¡€è®¾æ–½å…¼å®¹ NDIFï¼Œæ—¨åœ¨æ”¯æŒå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœºæ¢°å¯è§£é‡Šæ€§ç ”ç©¶ã€‚æ¬§æ´²å¯¹å¯å¹¿æ³›è·å–çš„ LLM å¯è§£é‡Šæ€§åŸºç¡€è®¾æ–½çš„éœ€æ±‚æ¨åŠ¨äº†è¿™ä¸€å€¡è®®ï¼Œæ—¨åœ¨ä¸ºç ”ç©¶ç¤¾åŒºæ™®åŠå…ˆè¿›çš„æ¨¡å‹åˆ†æèƒ½åŠ›ã€‚è¯¥é¡¹ç›®å¼•å…¥äº†ä¸€ä¸ªåŸºäº GPU çš„é›†ç¾¤ï¼Œæ‰˜ç®¡äºå®‰æ–¯å·´èµ«åº”ç”¨ç§‘å­¦å¤§å­¦ï¼Œå¹¶ä¸åˆä½œæœºæ„äº’è”ï¼Œé€šè¿‡ NNsight API å®ç°è¿œç¨‹æ¨¡å‹æ£€æŸ¥ã€‚ä¸€ä¸ªç”±æ¥è‡ªæ¬§æ´²å„åœ°çš„ 16 åç ”ç©¶äººå‘˜å‚ä¸çš„ç»“æ„åŒ–è¯•ç‚¹ç ”ç©¶è¯„ä¼°äº†è¯¥å¹³å°çš„æŠ€æœ¯æ€§èƒ½ã€å¯ç”¨æ€§å’Œç§‘å­¦å®ç”¨æ€§ã€‚ç”¨æˆ·å¯¹åŒ…æ‹¬ GPT-2 å’Œ DeepSeek-R1-70B åœ¨å†…çš„æ¨¡å‹è¿›è¡Œäº†æ¿€æ´»ä¿®è¡¥ã€å› æœè¿½è¸ªå’Œè¡¨å¾åˆ†æç­‰å¹²é¢„ã€‚ç ”ç©¶æ˜¾ç¤ºç”¨æˆ·å‚ä¸åº¦é€æ­¥æå‡ï¼Œå¹³å°åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­çš„æ€§èƒ½ç¨³å®šï¼Œè¿œç¨‹å®éªŒåŠŸèƒ½è·å¾—äº†ç§¯æè¯„ä»·ï¼Œå¹¶æ ‡å¿—ç€å›´ç»•è¯¥å¹³å°å»ºç«‹ç”¨æˆ·ç¤¾åŒºçš„èµ·ç‚¹ã€‚ åœ¨æœªæ¥å‘å±•è·¯çº¿å›¾ä¸­å·²è§£å†³äº†è¯¸å¦‚æ¿€æ´»æ•°æ®ä¸‹è½½æ—¶é—´è¿‡é•¿ä»¥åŠæ‰§è¡Œé—´æ­‡ä¸­æ–­ç­‰å·²è¯†åˆ«çš„é™åˆ¶ã€‚è¯¥ä¸¾æªæ ‡å¿—ç€åœ¨æ¬§æ´²æ¨å¹¿ LLM å¯è§£é‡Šæ€§åŸºç¡€è®¾æ–½çš„é‡è¦ä¸€æ­¥ï¼Œå¹¶ä¸ºæ›´å¹¿æ³›çš„éƒ¨ç½²ã€å·¥å…·æ‰©å±•ä»¥åŠåœ¨æœºæ¢°å¯è§£é‡Šæ€§ç ”ç©¶ä¸­æŒç»­çš„ç¤¾åŒºåä½œå¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 11:45:34 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-14 11:45:34 åè°ƒä¸–ç•Œæ—¶ï¼ˆUTCï¼‰</p>
<h2 id="12-when-language-overrules-revealing-text-dominance-in-multimodal-large-language-models--12-å½“è¯­è¨€å ä¸Šé£æ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡æœ¬ä¸»å¯¼æ€§"><a href="https://arxiv.org/abs/2508.10552"target="_blank" rel="external nofollow noopener noreferrer">#12</a> <a href="https://papers.cool/arxiv/2508.10552"target="_blank" rel="external nofollow noopener noreferrer">When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models</a>  #12 å½“è¯­è¨€å ä¸Šé£ï¼šæ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„æ–‡æœ¬ä¸»å¯¼æ€§</h2>
<p><strong>Authors</strong>: [Huyu Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huyu</a> Wu), [Meng Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meng</a> Tang), [Xinhan Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinhan</a> Zheng), [Haiyun Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haiyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haiyun</a> Jiang)
ä½œè€…ï¼šå´è™å®‡ï¼Œå”èŒï¼Œéƒ‘æ–°æ¶µï¼Œè’‹æµ·äº‘</p>
<p>Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across a diverse range of multimodal tasks. However, these models suffer from a core problem known as text dominance: they depend heavily on text for their inference, while underutilizing other modalities. While prior work has acknowledged this phenomenon in vision-language tasks, often attributing it to data biases or model architectures. In this paper, we conduct the first systematic investigation of text dominance across diverse data modalities, including images, videos, audio, time-series, and graphs. To measure this imbalance, we propose two evaluation metrics: the Modality Dominance Index (MDI) and the Attention Efficiency Index (AEI). Our comprehensive analysis reveals that text dominance is both significant and pervasive across all tested modalities. Our in-depth analysis identifies three underlying causes: attention dilution from severe token redundancy in non-textual modalities, the influence of fusion architecture design, and task formulations that implicitly favor textual inputs. Furthermore, we propose a simple token compression method that effectively rebalances model attention. Applying this method to LLaVA-7B, for instance, drastically reduces its MDI from 10.23 to a well-balanced value of 0.86. Our analysis and methodological framework offer a foundation for the development of more equitable and comprehensive multimodal language models.
å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å„ç§å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å­˜åœ¨ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼Œç§°ä¸ºæ–‡æœ¬ä¸»å¯¼ï¼šå®ƒä»¬åœ¨æ¨ç†è¿‡ç¨‹ä¸­é«˜åº¦ä¾èµ–æ–‡æœ¬ï¼Œè€Œå¯¹å…¶ä»–æ¨¡æ€çš„åˆ©ç”¨ä¸è¶³ã€‚æ­¤å‰çš„å·¥ä½œåœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­å·²æ³¨æ„åˆ°è¿™ä¸€ç°è±¡ï¼Œé€šå¸¸å°†å…¶å½’å› äºæ•°æ®åå·®æˆ–æ¨¡å‹æ¶æ„ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é¦–æ¬¡å¯¹åŒ…æ‹¬å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘ã€æ—¶é—´åºåˆ—å’Œå›¾åœ¨å†…çš„å¤šç§æ•°æ®æ¨¡æ€ä¸Šçš„æ–‡æœ¬ä¸»å¯¼è¿›è¡Œäº†ç³»ç»Ÿæ€§è°ƒæŸ¥ã€‚ä¸ºè¡¡é‡è¿™ç§ä¸å¹³è¡¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ä¸ªè¯„ä¼°æŒ‡æ ‡ï¼šæ¨¡æ€ä¸»å¯¼æŒ‡æ•°ï¼ˆMDIï¼‰å’Œæ³¨æ„åŠ›æ•ˆç‡æŒ‡æ•°ï¼ˆAEIï¼‰ã€‚æˆ‘ä»¬çš„å…¨é¢åˆ†æè¡¨æ˜ï¼Œæ–‡æœ¬ä¸»å¯¼åœ¨æ‰€æœ‰æµ‹è¯•æ¨¡æ€ä¸­æ—¢æ˜¾è‘—åˆæ™®éã€‚æ·±å…¥åˆ†æè¯†åˆ«å‡ºä¸‰ä¸ªæ½œåœ¨åŸå› ï¼šæ¥è‡ªéæ–‡æœ¬æ¨¡æ€ä¸­ä¸¥é‡ä»¤ç‰Œå†—ä½™çš„æ³¨æ„åŠ›ç¨€é‡Šã€èåˆæ¶æ„è®¾è®¡çš„å½±å“ä»¥åŠéšå«åå‘æ–‡æœ¬è¾“å…¥çš„ä»»åŠ¡è¡¨è¿°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•çš„ä»¤ç‰Œå‹ç¼©æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°é‡æ–°å¹³è¡¡äº†æ¨¡å‹çš„æ³¨æ„åŠ›ã€‚ å°†è¯¥æ–¹æ³•åº”ç”¨äºä¾‹å¦‚ LLaVA-7B æ—¶ï¼Œå…¶ MDI ä» 10.23 å¤§å¹…é™ä½åˆ°å¹³è¡¡è‰¯å¥½çš„ 0.86ã€‚æˆ‘ä»¬çš„åˆ†æå’Œæ–¹æ³•æ¡†æ¶ä¸ºå¼€å‘æ›´å…¬å¹³ã€æ›´å…¨é¢çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹æä¾›äº†åŸºç¡€ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 11:44:52 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 11:44:52 UTC</p>
<h2 id="13-when-explainability-meets-privacy-an-investigation-at-the-intersection-of-post-hoc-explainability-and-differential-privacy-in-the-context-of-natural-language-processing--13-å¯è§£é‡Šæ€§é‡ä¸Šéšç§åœ¨è‡ªç„¶è¯­è¨€å¤„ç†èƒŒæ™¯ä¸‹å¯¹äº‹åå¯è§£é‡Šæ€§ä¸å·®åˆ†éšç§äº¤æ±‡å¤„çš„æ¢ç©¶"><a href="https://arxiv.org/abs/2508.10482"target="_blank" rel="external nofollow noopener noreferrer">#13</a> <a href="https://papers.cool/arxiv/2508.10482"target="_blank" rel="external nofollow noopener noreferrer">When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing</a>  #13 å¯è§£é‡Šæ€§é‡ä¸Šéšç§ï¼šåœ¨è‡ªç„¶è¯­è¨€å¤„ç†èƒŒæ™¯ä¸‹å¯¹äº‹åå¯è§£é‡Šæ€§ä¸å·®åˆ†éšç§äº¤æ±‡å¤„çš„æ¢ç©¶</h2>
<p><strong>Authors</strong>: [Mahdi Dhaini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mahdi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mahdi</a> Dhaini), [Stephen Meisenbacher](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Stephen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Stephen</a> Meisenbacher), [Ege Erdogan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ege"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ege</a> Erdogan), [Florian Matthes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Florian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Florian</a> Matthes), [Gjergji Kasneci](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gjergji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gjergji</a> Kasneci)
ä½œè€…ï¼šMahdi Dhainiã€Stephen Meisenbacherã€Ege Erdoganã€Florian Matthesã€Gjergji Kasneci</p>
<p>In the study of trustworthy Natural Language Processing (NLP), a number of important research fields have emerged, including that of \textit{explainability} and \textit{privacy}. While research interest in both explainable and privacy-preserving NLP has increased considerably in recent years, there remains a lack of investigation at the intersection of the two. This leaves a considerable gap in understanding of whether achieving \textit{both} explainability and privacy is possible, or whether the two are at odds with each other. In this work, we conduct an empirical investigation into the privacy-explainability trade-off in the context of NLP, guided by the popular overarching methods of \textit{Differential Privacy} (DP) and Post-hoc Explainability. Our findings include a view into the intricate relationship between privacy and explainability, which is formed by a number of factors, including the nature of the downstream task and choice of the text privatization and explainability method. In this, we highlight the potential for privacy and explainability to co-exist, and we summarize our findings in a collection of practical recommendations for future work at this important intersection.
åœ¨å¯ä¿¡è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„ç ”ç©¶ä¸­ï¼Œå‡ºç°äº†è‹¥å¹²é‡è¦çš„ç ”ç©¶é¢†åŸŸï¼Œå…¶ä¸­åŒ…æ‹¬â€œå¯è§£é‡Šæ€§â€å’Œâ€œéšç§â€ã€‚å°½ç®¡è¿‘å¹´æ¥å¯¹å¯è§£é‡Šä¸”å…·éšç§ä¿æŠ¤çš„ NLP çš„ç ”ç©¶å…´è¶£æ˜¾è‘—å¢åŠ ï¼Œä½†åœ¨ä¸¤è€…äº¤æ±‡å¤„çš„æ¢è®¨ä»ç„¶ä¸è¶³ã€‚è¿™å¯¼è‡´æˆ‘ä»¬å¯¹æ˜¯å¦èƒ½å¤ŸåŒæ—¶å®ç°å¯è§£é‡Šæ€§å’Œéšç§ï¼Œæˆ–ä¸¤è€…æ˜¯å¦äº’ç›¸å†²çªï¼Œç¼ºä¹å……åˆ†äº†è§£ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨ NLP èƒŒæ™¯ä¸‹å¯¹éšç§â€”å¯è§£é‡Šæ€§æƒè¡¡è¿›è¡Œäº†å®è¯ç ”ç©¶ï¼Œç ”ç©¶ä»¥å¹¿æ³›ä½¿ç”¨çš„æ–¹æ³•â€”â€”å·®åˆ†éšç§ï¼ˆDifferential Privacyï¼ŒDPï¼‰å’Œäº‹åå¯è§£é‡Šæ€§ï¼ˆPost-hoc Explainabilityï¼‰ä¸ºæŒ‡å¯¼ã€‚æˆ‘ä»¬çš„å‘ç°æ­ç¤ºäº†éšç§ä¸å¯è§£é‡Šæ€§ä¹‹é—´é”™ç»¼å¤æ‚çš„å…³ç³»ï¼Œè¿™ç§å…³ç³»å—å¤šç§å› ç´ å½±å“ï¼ŒåŒ…æ‹¬ä¸‹æ¸¸ä»»åŠ¡çš„æ€§è´¨ä»¥åŠæ‰€é€‰æ‹©çš„æ–‡æœ¬éšç§åŒ–å’Œå¯è§£é‡Šæ€§æ–¹æ³•ã€‚ åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å¼ºè°ƒäº†éšç§æ€§ä¸å¯è§£é‡Šæ€§å¹¶å­˜çš„æ½œåŠ›ï¼Œå¹¶å°†æˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ€»ç»“ä¸ºä¸€ç³»åˆ—é¢å‘æœªæ¥åœ¨è¿™ä¸€é‡è¦äº¤å‰é¢†åŸŸå·¥ä½œçš„å®ç”¨å»ºè®®ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 09:34:29 UTC
å‘è¡¨æ—¶é—´ï¼š2025-08-14 09:34:29 UTC</p>
<h2 id="14-difar-enhancing-multimodal-misinformation-detection-with-diverse-factual-and-relevant-rationales--14-difaré€šè¿‡å¤šæ ·äº‹å®æ€§å’Œç›¸å…³æ€§ç†ç”±æå‡å¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10444"target="_blank" rel="external nofollow noopener noreferrer">#14</a> <a href="https://papers.cool/arxiv/2508.10444"target="_blank" rel="external nofollow noopener noreferrer">DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales</a>  #14 DiFaRï¼šé€šè¿‡å¤šæ ·ã€äº‹å®æ€§å’Œç›¸å…³æ€§ç†ç”±æå‡å¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹</h2>
<p><strong>Authors</strong>: [Herun Wan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Herun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Herun</a> Wan), [Jiaying Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaying</a> Wu), [Minnan Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minnan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minnan</a> Luo), [Xiangzheng Kong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiangzheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiangzheng</a> Kong), [Zihan Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zihan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zihan</a> Ma), [Zhi Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhi</a> Zeng)
ä½œè€…ï¼šHerun Wanã€Jiaying Wuã€Minnan Luoã€Xiangzheng Kongã€Zihan Maã€Zhi Zeng</p>
<p>Generating textual rationales from large vision-language models (LVLMs) to support trainable multimodal misinformation detectors has emerged as a promising paradigm. However, its effectiveness is fundamentally limited by three core challenges: (i) insufficient diversity in generated rationales, (ii) factual inaccuracies due to hallucinations, and (iii) irrelevant or conflicting content that introduces noise. We introduce DiFaR, a detector-agnostic framework that produces diverse, factual, and relevant rationales to enhance misinformation detection. DiFaR employs five chain-of-thought prompts to elicit varied reasoning traces from LVLMs and incorporates a lightweight post-hoc filtering module to select rationale sentences based on sentence-level factuality and relevance scores. Extensive experiments on four popular benchmarks demonstrate that DiFaR outperforms four baseline categories by up to 5.9% and boosts existing detectors by as much as 8.7%. Both automatic metrics and human evaluations confirm that DiFaR significantly improves rationale quality across all three dimensions.
ä»å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰ç”Ÿæˆæ–‡æœ¬æ¨ç†ä»¥æ”¯æŒå¯è®­ç»ƒçš„å¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹å™¨ï¼Œå·²æˆä¸ºä¸€ç§æœ‰å‰æ™¯çš„èŒƒå¼ã€‚ç„¶è€Œï¼Œå…¶æœ‰æ•ˆæ€§åœ¨æ ¹æœ¬ä¸Šå—åˆ¶äºä¸‰å¤§æ ¸å¿ƒæŒ‘æˆ˜ï¼š(i) æ‰€ç”Ÿæˆæ¨ç†çš„å¤šæ ·æ€§ä¸è¶³ï¼Œ(ii) ç”±äºå¹»è§‰è€Œå¯¼è‡´çš„äº‹å®ä¸å‡†ç¡®ï¼Œ(iii) å¼•å…¥å™ªå£°çš„æ— å…³æˆ–çŸ›ç›¾å†…å®¹ã€‚æˆ‘ä»¬æå‡ºäº† DiFaRï¼Œä¸€ç§ä¸æ£€æµ‹å™¨æ— å…³çš„æ¡†æ¶ï¼Œæ—¨åœ¨ç”Ÿæˆå¤šæ ·çš„ã€çœŸå®çš„ä¸”ç›¸å…³çš„æ¨ç†ï¼Œä»¥å¢å¼ºé”™è¯¯ä¿¡æ¯æ£€æµ‹ã€‚DiFaR ä½¿ç”¨äº”ç§é“¾å¼æ€ç»´æç¤ºæ¥ä» LVLMs è¯±å¯¼å‡ºå¤šæ ·çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»“åˆä¸€ä¸ªè½»é‡çš„äº‹åè¿‡æ»¤æ¨¡å—ï¼ŒåŸºäºå¥å­çº§çš„äº‹å®æ€§å’Œç›¸å…³æ€§è¯„åˆ†æ¥é€‰æ‹©æ¨ç†å¥å­ã€‚åœ¨å››ä¸ªæµè¡ŒåŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒDiFaR ç›¸è¾ƒå››ç±»åŸºçº¿æ–¹æ³•æœ€å¤šæå‡ 5.9%ï¼Œå¹¶å¯å°†ç°æœ‰æ£€æµ‹å™¨æœ€å¤šæå‡ 8.7%ã€‚è‡ªåŠ¨è¯„æµ‹å’Œäººå·¥è¯„ä¼°å‡ç¡®è®¤ DiFaR åœ¨è¿™ä¸‰æ–¹é¢æ˜¾è‘—æ”¹å–„äº†æ¨ç†è´¨é‡ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 08:32:31 UTC
å‘å¸ƒï¼š2025-08-14 08:32:31 UTC</p>
<h2 id="15-computational-economics-in-large-language-models-exploring-model-behavior-and-incentive-design-under-resource-constraints--15-åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è®¡ç®—ç»æµå­¦åœ¨èµ„æºçº¦æŸä¸‹æ¢ç´¢æ¨¡å‹è¡Œä¸ºä¸æ¿€åŠ±è®¾è®¡"><a href="https://arxiv.org/abs/2508.10426"target="_blank" rel="external nofollow noopener noreferrer">#15</a> <a href="https://papers.cool/arxiv/2508.10426"target="_blank" rel="external nofollow noopener noreferrer">Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints</a>  #15 åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­çš„è®¡ç®—ç»æµå­¦ï¼šåœ¨èµ„æºçº¦æŸä¸‹æ¢ç´¢æ¨¡å‹è¡Œä¸ºä¸æ¿€åŠ±è®¾è®¡</h2>
<p><strong>Authors</strong>: [Sandeep Reddy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sandeep"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sandeep</a> Reddy), [Kabir Khan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kabir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kabir</a> Khan), [Rohit Patil](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rohit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rohit</a> Patil), [Ananya Chakraborty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ananya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ananya</a> Chakraborty), [Faizan A. Khan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Faizan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Faizan</a> A. Khan), [Swati Kulkarni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Swati"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Swati</a> Kulkarni), [Arjun Verma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arjun</a> Verma), [Neha Singh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Neha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Neha</a> Singh)
ä½œè€…ï¼šSandeep Reddyã€Kabir Khanã€Rohit Patilã€Ananya Chakrabortyã€Faizan A. Khanã€Swati Kulkarniã€Arjun Vermaã€Neha Singh</p>
<p>Large language models (LLMs) are limited by substantial computational cost. We introduce a &ldquo;computational economics&rdquo; framework that treats an LLM as an internal economy of resource-constrained agents (attention heads and neuron blocks) that must allocate scarce computation to maximize task utility. First, we show empirically that when computation is scarce, standard LLMs reallocate attention toward high-value tokens while preserving accuracy. Building on this observation, we propose an incentive-driven training paradigm that augments the task loss with a differentiable computation cost term, encouraging sparse and efficient activations. On GLUE (MNLI, STS-B, CoLA) and WikiText-103, the method yields a family of models that trace a Pareto frontier and consistently dominate post-hoc pruning; for a similar accuracy we obtain roughly a forty percent reduction in FLOPS and lower latency, together with more interpretable attention patterns. These results indicate that economic principles offer a principled route to designing efficient, adaptive, and more transparent LLMs under strict resource constraints.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å—åˆ¶äºå·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªâ€œè®¡ç®—ç»æµå­¦â€æ¡†æ¶ï¼Œå°† LLM è§†ä¸ºç”±å—é™èµ„æºä»£ç†ï¼ˆæ³¨æ„åŠ›å¤´å’Œç¥ç»å…ƒå—ï¼‰ç»„æˆçš„å†…éƒ¨ç»æµä½“ï¼Œè¿™äº›ä»£ç†å¿…é¡»åˆ†é…ç¨€ç¼ºçš„è®¡ç®—èµ„æºä»¥æœ€å¤§åŒ–ä»»åŠ¡æ•ˆç”¨ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬åœ¨å®è¯ä¸Šå±•ç¤ºäº†å½“è®¡ç®—èµ„æºç¨€ç¼ºæ—¶ï¼Œæ ‡å‡† LLM ä¼šå°†æ³¨æ„åŠ›é‡æ–°åˆ†é…åˆ°é«˜ä»·å€¼çš„æ ‡è®°ä¸Šï¼ŒåŒæ—¶ä¿æŒå‡†ç¡®æ€§ã€‚åœ¨æ­¤è§‚å¯ŸåŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»¥æ¿€åŠ±ä¸ºé©±åŠ¨çš„è®­ç»ƒèŒƒå¼ï¼Œå°†å¯å¾®çš„è®¡ç®—æˆæœ¬é¡¹åŠ å…¥ä»»åŠ¡æŸå¤±ä¸­ï¼Œé¼“åŠ±ç¨€ç–ä¸”é«˜æ•ˆçš„æ¿€æ´»ã€‚åœ¨ GLUEï¼ˆMNLIã€STS-Bã€CoLAï¼‰å’Œ WikiText-103 ä¸Šï¼Œè¯¥æ–¹æ³•äº§ç”Ÿäº†ä¸€ç³»åˆ—æ¨¡å‹ï¼Œå®ƒä»¬æç»˜å‡ºä¸€æ¡å¸•ç´¯æ‰˜å‰æ²¿å¹¶å§‹ç»ˆä¼˜äºäº‹åå‰ªæï¼›åœ¨ç›¸ä¼¼å‡†ç¡®åº¦ä¸‹ï¼Œæˆ‘ä»¬å¤§çº¦è·å¾—äº†å››æˆçš„ FLOPS å‡å°‘å’Œæ›´ä½çš„å»¶è¿Ÿï¼ŒåŒæ—¶æ³¨æ„åŠ›æ¨¡å¼ä¹Ÿæ›´å…·å¯è§£é‡Šæ€§ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼Œåœ¨ä¸¥æ ¼èµ„æºé™åˆ¶ä¸‹ï¼Œç»æµå­¦åŸç†ä¸ºè®¾è®¡é«˜æ•ˆã€é€‚åº”æ€§å¼ºä¸”æ›´é€æ˜çš„ LLM æä¾›äº†ä¸€æ¡æœ‰åŸåˆ™çš„é€”å¾„ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 07:55:45 UTC
å‘å¸ƒï¼š2025-08-14 07:55:45 UTC</p>
<h2 id="16-evaluating-llms-on-chinese-idiom-translation--16-åœ¨æ±‰è¯­æˆè¯­ç¿»è¯‘ä¸Šè¯„ä¼°-llms"><a href="https://arxiv.org/abs/2508.10421"target="_blank" rel="external nofollow noopener noreferrer">#16</a> <a href="https://papers.cool/arxiv/2508.10421"target="_blank" rel="external nofollow noopener noreferrer">Evaluating LLMs on Chinese Idiom Translation</a>  #16 åœ¨æ±‰è¯­æˆè¯­ç¿»è¯‘ä¸Šè¯„ä¼° LLMs</h2>
<p><strong>Authors</strong>: [Cai Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cai</a> Yang), [Yao Dou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yao</a> Dou), [David Heineman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=David"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=David</a> Heineman), [Xiaofeng Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaofeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaofeng</a> Wu), [Wei Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Xu)
ä½œè€…ï¼šè”¡é˜³ã€çª¦é¥ã€David Heinemanã€å´æ™“å³°ã€å¾å·</p>
<p>Idioms, whose figurative meanings usually differ from their literal interpretations, are common in everyday language, especially in Chinese, where they often contain historical references and follow specific structural patterns. Despite recent progress in machine translation with large language models, little is known about Chinese idiom translation. In this work, we introduce IdiomEval, a framework with a comprehensive error taxonomy for Chinese idiom translation. We annotate 900 translation pairs from nine modern systems, including GPT-4o and Google Translate, across four domains: web, news, Wikipedia, and social media. We find these systems fail at idiom translation, producing incorrect, literal, partial, or even missing translations. The best-performing system, GPT-4, makes errors in 28% of cases. We also find that existing evaluation metrics measure idiom quality poorly with Pearson correlation below 0.48 with human ratings. We thus develop improved models that achieve F1 scores of 0.68 for detecting idiom translation errors.
æˆè¯­çš„æ¯”å–»å«ä¹‰é€šå¸¸ä¸å­—é¢è§£é‡Šä¸åŒï¼Œåœ¨æ—¥å¸¸è¯­è¨€ä¸­å¾ˆå¸¸è§ï¼Œå°¤å…¶åœ¨ä¸­æ–‡ä¸­ï¼Œå®ƒä»¬å¸¸åŒ…å«å†å²å…¸æ•…å¹¶éµå¾ªç‰¹å®šçš„ç»“æ„æ¨¡å¼ã€‚å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æœºå™¨ç¿»è¯‘æ–¹é¢å–å¾—äº†è¿‘æœŸè¿›å±•ï¼Œä½†æ±‰è¯­æˆè¯­ç¿»è¯‘é²œæœ‰ç ”ç©¶ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† IdiomEvalï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹æ±‰è¯­æˆè¯­ç¿»è¯‘çš„æ¡†æ¶ï¼Œé™„å¸¦å…¨é¢çš„é”™è¯¯åˆ†ç±»æ³•ã€‚æˆ‘ä»¬å¯¹æ¥è‡ªä¹ä¸ªç°ä»£ç³»ç»Ÿï¼ˆåŒ…æ‹¬ GPT-4o å’Œ Google Translateï¼‰åœ¨å››ä¸ªé¢†åŸŸï¼ˆç½‘ç»œã€æ–°é—»ã€ç»´åŸºç™¾ç§‘å’Œç¤¾äº¤åª’ä½“ï¼‰ä¸­çš„ 900 å¯¹ç¿»è¯‘è¿›è¡Œäº†æ ‡æ³¨ã€‚æˆ‘ä»¬å‘ç°è¿™äº›ç³»ç»Ÿåœ¨æˆè¯­ç¿»è¯‘ä¸Šè¡¨ç°ä¸ä½³ï¼Œä¼šäº§ç”Ÿé”™è¯¯ã€å­—é¢åŒ–ã€éƒ¨åˆ†ç¿»è¯‘ç”šè‡³é—æ¼ç¿»è¯‘ã€‚è¡¨ç°æœ€å¥½çš„ç³»ç»Ÿ GPT-4 åœ¨ 28% çš„æ¡ˆä¾‹ä¸­å‡ºç°é”™è¯¯ã€‚æˆ‘ä»¬è¿˜å‘ç°ç°æœ‰è¯„ä¼°æŒ‡æ ‡å¯¹æˆè¯­è´¨é‡çš„æµ‹é‡æ•ˆæœè¾ƒå·®ï¼Œä¸äººå·¥è¯„åˆ†çš„çš®å°”é€Šç›¸å…³ç³»æ•°ä½äº 0.48ã€‚å› æ­¤æˆ‘ä»¬å¼€å‘äº†æ”¹è¿›çš„æ¨¡å‹ï¼Œåœ¨æ£€æµ‹æˆè¯­ç¿»è¯‘é”™è¯¯æ–¹é¢å®ç°äº† 0.68 çš„ F 1 åˆ†æ•°ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 07:52:56 UTC
å‘å¸ƒï¼š2025-08-14 07:52:56 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="17-comorag-a-cognitive-inspired-memory-organized-rag-for-stateful-long-narrative-reasoning--17-comoragä¸€ç§å—è®¤çŸ¥å¯å‘çš„è®°å¿†ç»„ç»‡-ragç”¨äºæœ‰çŠ¶æ€çš„é•¿ç¯‡å™äº‹æ¨ç†"><a href="https://arxiv.org/abs/2508.10419"target="_blank" rel="external nofollow noopener noreferrer">#17</a> <a href="https://papers.cool/arxiv/2508.10419"target="_blank" rel="external nofollow noopener noreferrer">ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning</a>  #17 ComoRAGï¼šä¸€ç§å—è®¤çŸ¥å¯å‘çš„è®°å¿†ç»„ç»‡ RAGï¼Œç”¨äºæœ‰çŠ¶æ€çš„é•¿ç¯‡å™äº‹æ¨ç†</h2>
<p><strong>Authors</strong>: [Juyuan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juyuan</a> Wang), [Rongchen Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rongchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rongchen</a> Zhao), [Wei Wei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Wei), [Yufeng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yufeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yufeng</a> Wang), [Mo Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mo</a> Yu), [Jie Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jie</a> Zhou), [Jin Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jin</a> Xu), [Liyan Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liyan</a> Xu)
ä½œè€…ï¼šç‹èšæºã€èµµè£è‡£ã€é­å¨ã€ç‹ç‰å³°ã€äºå¢¨ã€å‘¨æ°ã€å¾æ™‹ã€è®¸ä¸½è‰³</p>
<p>Narrative comprehension on long stories and novels has been a challenging domain attributed to their intricate plotlines and entangled, often evolving relations among characters and entities. Given the LLM&rsquo;s diminished reasoning over extended context and high computational cost, retrieval-based approaches remain a pivotal role in practice. However, traditional RAG methods can fall short due to their stateless, single-step retrieval process, which often overlooks the dynamic nature of capturing interconnected relations within long-range context. In this work, we propose ComoRAG, holding the principle that narrative reasoning is not a one-shot process, but a dynamic, evolving interplay between new evidence acquisition and past knowledge consolidation, analogous to human cognition when reasoning with memory-related signals in the brain. Specifically, when encountering a reasoning impasse, ComoRAG undergoes iterative reasoning cycles while interacting with a dynamic memory workspace. In each cycle, it generates probing queries to devise new exploratory paths, then integrates the retrieved evidence of new aspects into a global memory pool, thereby supporting the emergence of a coherent context for the query resolution. Across four challenging long-context narrative benchmarks (200K+ tokens), ComoRAG outperforms strong RAG baselines with consistent relative gains up to 11% compared to the strongest baseline. Further analysis reveals that ComoRAG is particularly advantageous for complex queries requiring global comprehension, offering a principled, cognitively motivated paradigm for retrieval-based long context comprehension towards stateful reasoning. Our code is publicly released at <a href="https://github.com/EternityJune25/ComoRAG"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/EternityJune25/ComoRAG</a>
å¯¹é•¿ç¯‡æ•…äº‹å’Œå°è¯´çš„å™äº‹ç†è§£ä¸€ç›´æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸï¼Œè¿™å½’å› äºå…¶é”™ç»¼å¤æ‚çš„æƒ…èŠ‚çº¿å’Œäººç‰©ä¸å®ä½“ä¹‹é—´çº ç¼ ä¸”å¸¸å¸¸æ¼”å˜çš„å…³ç³»ã€‚é‰´äº LLM åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­çš„æ¨ç†èƒ½åŠ›ä¸‹é™ä¸”è®¡ç®—ä»£ä»·é«˜æ˜‚ï¼ŒåŸºäºæ£€ç´¢çš„æ–¹æ³•åœ¨å®è·µä¸­ä»ç„¶æ‰®æ¼”ç€å…³é”®è§’è‰²ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„ RAG æ–¹æ³•å¯èƒ½ä¸è¶³ä»¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œå› ä¸ºå…¶æ— çŠ¶æ€çš„ã€å•æ­¥çš„æ£€ç´¢è¿‡ç¨‹å¾€å¾€å¿½è§†äº†åœ¨é•¿ç¨‹ä¸Šä¸‹æ–‡ä¸­æ•æ‰ç›¸äº’å…³è”å…³ç³»çš„åŠ¨æ€ç‰¹æ€§ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† ComoRAGï¼Œç§‰æŒè¿™æ ·ä¸€ä¸ªåŸåˆ™ï¼šå™äº‹æ¨ç†å¹¶éä¸€æ¬¡æ€§çš„è¿‡ç¨‹ï¼Œè€Œæ˜¯æ–°è¯æ®è·å–ä¸è¿‡å»çŸ¥è¯†å·©å›ºä¹‹é—´çš„åŠ¨æ€ã€ä¸æ–­æ¼”åŒ–çš„ç›¸äº’ä½œç”¨ï¼Œè¿™ç±»ä¼¼äºäººè„‘åœ¨å¸¦æœ‰è®°å¿†ç›¸å…³ä¿¡å·çš„æ¨ç†æ—¶çš„è®¤çŸ¥è¿‡ç¨‹ã€‚å…·ä½“è€Œè¨€ï¼Œå½“é‡åˆ°æ¨ç†åƒµå±€æ—¶ï¼ŒComoRAG ä¼šåœ¨ä¸åŠ¨æ€è®°å¿†å·¥ä½œåŒºäº¤äº’çš„åŒæ—¶è¿›è¡Œè¿­ä»£æ¨ç†å¾ªç¯ã€‚ åœ¨æ¯ä¸ªå¾ªç¯ä¸­ï¼Œå®ƒç”Ÿæˆæ¢æµ‹æ€§æŸ¥è¯¢ä»¥è®¾è®¡æ–°çš„æ¢ç´¢è·¯å¾„ï¼Œç„¶åå°†æ£€ç´¢åˆ°çš„æ–°æ–¹é¢è¯æ®æ•´åˆåˆ°å…¨å±€è®°å¿†æ± ä¸­ï¼Œä»è€Œæ”¯æŒä¸ºæŸ¥è¯¢è§£å†³æ„å»ºè¿è´¯çš„ä¸Šä¸‹æ–‡ã€‚åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é•¿ä¸Šä¸‹æ–‡å™äº‹åŸºå‡†ï¼ˆ20 ä¸‡+ ä»¤ç‰Œï¼‰ä¸Šï¼ŒComoRAG ç›¸è¾ƒäºå¼ºå¤§çš„ RAG åŸºçº¿è¡¨ç°æ›´ä½³ï¼Œä¸æœ€å¼ºåŸºçº¿ç›¸æ¯”ä¸€è‡´æ€§ç›¸å¯¹æå‡é«˜è¾¾ 11%ã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼ŒComoRAG å¯¹äºéœ€è¦å…¨å±€ç†è§£çš„å¤æ‚æŸ¥è¯¢å°¤ä¸ºæœ‰åˆ©ï¼Œä¸ºåŸºäºæ£€ç´¢çš„é•¿ä¸Šä¸‹æ–‡ç†è§£æä¾›äº†ä¸€ç§æœ‰åŸåˆ™ã€å—è®¤çŸ¥å¯å‘çš„èŒƒå¼ï¼Œä»¥å®ç°æœ‰çŠ¶æ€æ¨ç†ã€‚æˆ‘ä»¬çš„ä»£ç å·²åœ¨ <a href="https://github.com/EternityJune25/ComoRAG"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/EternityJune25/ComoRAG</a> å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 07:52:09 UTC
å‘å¸ƒï¼š2025-08-14 07:52:09 UTC</p>
<h2 id="18-layer-wise-perturbations-via-sparse-autoencoders-for-adversarial-text-generation--18-é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œé€å±‚æ‰°åŠ¨ä»¥ç”Ÿæˆå¯¹æŠ—æ–‡æœ¬"><a href="https://arxiv.org/abs/2508.10404"target="_blank" rel="external nofollow noopener noreferrer">#18</a> <a href="https://papers.cool/arxiv/2508.10404"target="_blank" rel="external nofollow noopener noreferrer">Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation</a>  #18 é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œé€å±‚æ‰°åŠ¨ä»¥ç”Ÿæˆå¯¹æŠ—æ–‡æœ¬</h2>
<p><strong>Authors</strong>: [Huizhen Shu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huizhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huizhen</a> Shu), [Xuying Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuying</a> Li), [Qirui Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qirui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qirui</a> Wang), [Yuji Kosuga](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuji</a> Kosuga), [Mengqiu Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengqiu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengqiu</a> Tian), [Zhuo Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuo</a> Li)
ä½œè€…ï¼šèˆ’æ…§çœŸï¼Œææ—­é¢–ï¼Œç‹å¯ç¿ï¼ŒKosuga Yujiï¼Œç”°æ¢¦ç§‹ï¼Œæå“</p>
<p>With the rapid proliferation of Natural Language Processing (NLP), especially Large Language Models (LLMs), generating adversarial examples to jailbreak LLMs remains a key challenge for understanding model vulnerabilities and improving robustness. In this context, we propose a new black-box attack method that leverages the interpretability of large models. We introduce the Sparse Feature Perturbation Framework (SFPF), a novel approach for adversarial text generation that utilizes sparse autoencoders to identify and manipulate critical features in text. After using the SAE model to reconstruct hidden layer representations, we perform feature clustering on the successfully attacked texts to identify features with higher activations. These highly activated features are then perturbed to generate new adversarial texts. This selective perturbation preserves the malicious intent while amplifying safety signals, thereby increasing their potential to evade existing defenses. Our method enables a new red-teaming strategy that balances adversarial effectiveness with safety alignment. Experimental results demonstrate that adversarial texts generated by SFPF can bypass state-of-the-art defense mechanisms, revealing persistent vulnerabilities in current NLP systems.However, the method&rsquo;s effectiveness varies across prompts and layers, and its generalizability to other architectures and larger models remains to be validated.
éšç€è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ï¼Œå°¤å…¶æ˜¯ LLMs çš„å¿«é€Ÿæ™®åŠï¼Œç”Ÿæˆå¯¹æŠ—æ ·æœ¬ä»¥æ”»ç ´ LLMs ä»ç„¶æ˜¯ç†è§£æ¨¡å‹è„†å¼±æ€§å’Œæå‡é²æ£’æ€§çš„å…³é”®æŒ‘æˆ˜ã€‚åœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§å‹æ¨¡å‹å¯è§£é‡Šæ€§çš„å…¨æ–°é»‘ç›’æ”»å‡»æ–¹æ³•ã€‚æˆ‘ä»¬å¼•å…¥äº†ç¨€ç–ç‰¹å¾æ‰°åŠ¨æ¡†æ¶ï¼ˆSFPFï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„å¯¹æŠ—æ–‡æœ¬ç”Ÿæˆæ–¹æ³•ï¼Œä½¿ç”¨ç¨€ç–è‡ªç¼–ç å™¨æ¥è¯†åˆ«å¹¶æ“çºµæ–‡æœ¬ä¸­çš„å…³é”®ç‰¹å¾ã€‚åœ¨ä½¿ç”¨ SAE æ¨¡å‹é‡å»ºéšè—å±‚è¡¨ç¤ºåï¼Œæˆ‘ä»¬å¯¹æˆåŠŸæ”»å‡»çš„æ–‡æœ¬è¿›è¡Œç‰¹å¾èšç±»ï¼Œä»¥è¯†åˆ«æ¿€æ´»åº¦è¾ƒé«˜çš„ç‰¹å¾ã€‚ç„¶åå¯¹è¿™äº›é«˜æ¿€æ´»ç‰¹å¾è¿›è¡Œæ‰°åŠ¨ä»¥ç”Ÿæˆæ–°çš„å¯¹æŠ—æ–‡æœ¬ã€‚è¿™ç§é€‰æ‹©æ€§æ‰°åŠ¨åœ¨ä¿ç•™æ¶æ„æ„å›¾çš„åŒæ—¶æ”¾å¤§äº†å®‰å…¨ä¿¡å·ï¼Œä»è€Œæé«˜äº†å…¶è§„é¿ç°æœ‰é˜²å¾¡çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¨åŠ¨äº†ä¸€ç§æ–°çš„çº¢é˜Ÿç­–ç•¥ï¼Œå¹³è¡¡äº†å¯¹æŠ—æœ‰æ•ˆæ€§ä¸å®‰å…¨ä¸€è‡´æ€§ã€‚ å®éªŒè¯æ˜ï¼Œç”± SFPF ç”Ÿæˆçš„å¯¹æŠ—æ–‡æœ¬èƒ½å¤Ÿç»•è¿‡æœ€å…ˆè¿›çš„é˜²å¾¡æœºåˆ¶ï¼Œæ­ç¤ºäº†å½“å‰ NLP ç³»ç»Ÿä¸­æŒç»­å­˜åœ¨çš„è„†å¼±æ€§ã€‚ç„¶è€Œï¼Œè¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§åœ¨ä¸åŒçš„æç¤ºå’Œå±‚æ¬¡ä¹‹é—´å­˜åœ¨å·®å¼‚ï¼Œå…¶å¯¹å…¶ä»–æ¶æ„å’Œæ›´å¤§æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ä»éœ€éªŒè¯ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 07:12:44 UTC
å‘å¸ƒï¼š2025-08-14 07:12:44 UTC</p>
<h2 id="19-jailbreaking-commercial-black-box-llms-with-explicitly-harmful-prompts--19-ä½¿ç”¨æ˜ç¡®æœ‰å®³æç¤ºå¯¹å•†ä¸šé»‘ç›’-llms-è¿›è¡Œè¶Šç‹±"><a href="https://arxiv.org/abs/2508.10390"target="_blank" rel="external nofollow noopener noreferrer">#19</a> <a href="https://papers.cool/arxiv/2508.10390"target="_blank" rel="external nofollow noopener noreferrer">Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts</a>  #19 ä½¿ç”¨æ˜ç¡®æœ‰å®³æç¤ºå¯¹å•†ä¸šé»‘ç›’ LLMs è¿›è¡Œè¶Šç‹±</h2>
<p><strong>Authors</strong>: [Chiyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chiyu</a> Zhang), [Lu Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lu</a> Zhou), [Xiaogang Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaogang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaogang</a> Xu), [Jiafei Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiafei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiafei</a> Wu), [Liming Fang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liming</a> Fang), [Zhe Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhe</a> Liu)
ä½œè€…ï¼šå¼ é©°å®‡ã€å‘¨ç’ã€å¾æ™“åˆšã€å´å®¶æ–ã€æ–¹ç«‹æ˜ã€åˆ˜å“²</p>
<p>Evaluating jailbreak attacks is challenging when prompts are not overtly harmful or fail to induce harmful outputs. Unfortunately, many existing red-teaming datasets contain such unsuitable prompts. To evaluate attacks accurately, these datasets need to be assessed and cleaned for maliciousness. However, existing malicious content detection methods rely on either manual annotation, which is labor-intensive, or large language models (LLMs), which have inconsistent accuracy in harmful types. To balance accuracy and efficiency, we propose a hybrid evaluation framework named MDH (Malicious content Detection based on LLMs with Human assistance) that combines LLM-based annotation with minimal human oversight, and apply it to dataset cleaning and detection of jailbroken responses. Furthermore, we find that well-crafted developer messages can significantly boost jailbreak success, leading us to propose two new strategies: D-Attack, which leverages context simulation, and DH-CoT, which incorporates hijacked chains of thought. The Codes, datasets, judgements, and detection results will be released in github repository: <a href="https://github.com/AlienZhang1996/DH-CoT"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/AlienZhang1996/DH-CoT</a>.
åœ¨æç¤ºè¯ä¸æ˜æ˜¾æœ‰å®³æˆ–æœªèƒ½å¼•å‡ºæœ‰å®³è¾“å‡ºæ—¶ï¼Œè¯„ä¼°è¶Šç‹±æ”»å‡»å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸å¹¸çš„æ˜¯ï¼Œè®¸å¤šç°æœ‰çš„çº¢é˜Ÿæ•°æ®é›†åŒ…å«æ­¤ç±»ä¸é€‚ç”¨çš„æç¤ºè¯ã€‚ä¸ºå‡†ç¡®è¯„ä¼°æ”»å‡»ï¼Œéœ€è¦å¯¹è¿™äº›æ•°æ®é›†è¿›è¡Œæ¶æ„æ€§è¯„ä¼°å’Œæ¸…æ´—ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ¶æ„å†…å®¹æ£€æµ‹æ–¹æ³•è¦ä¹ˆä¾èµ–äººå·¥æ ‡æ³¨ï¼ŒåŠ³åŠ¨å¼ºåº¦å¤§ï¼Œè¦ä¹ˆä¾èµ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ï¼Œå…¶åœ¨æœ‰å®³ç±»å‹ä¸Šçš„å‡†ç¡®æ€§ä¸ç¨³å®šã€‚ä¸ºåœ¨å‡†ç¡®æ€§å’Œæ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸º MDHï¼ˆåŸºäº LLM å¹¶è¾…ä»¥äººå·¥çš„æ¶æ„å†…å®¹æ£€æµ‹ï¼ŒMalicious content Detection based on LLMs with Human assistanceï¼‰çš„æ··åˆè¯„ä¼°æ¡†æ¶ï¼Œè¯¥æ¡†æ¶å°†åŸºäº LLM çš„æ ‡æ³¨ä¸æœ€å°‘é‡çš„äººç±»ç›‘ç£ç›¸ç»“åˆï¼Œå¹¶å°†å…¶åº”ç”¨äºæ•°æ®é›†æ¸…æ´—å’Œè¶Šç‹±å“åº”çš„æ£€æµ‹ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ç²¾å¿ƒè®¾è®¡çš„å¼€å‘è€…æ¶ˆæ¯å¯ä»¥æ˜¾è‘—æé«˜è¶Šç‹±æˆåŠŸç‡ï¼ŒåŸºäºæ­¤æå‡ºäº†ä¸¤ç§æ–°ç­–ç•¥ï¼šD-Attackï¼ˆåˆ©ç”¨ä¸Šä¸‹æ–‡æ¨¡æ‹Ÿï¼‰å’Œ DH-CoTï¼ˆèåˆè¢«åŠ«æŒçš„æ€è·¯é“¾ï¼‰ã€‚ä»£ç ã€æ•°æ®é›†ã€åˆ¤å®šä»¥åŠæ£€æµ‹ç»“æœå°†å‘å¸ƒåœ¨ GitHub ä»“åº“ï¼š <a href="https://github.com/AlienZhang1996/DH-CoT"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/AlienZhang1996/DH-CoT</a>ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œå¯†ç å­¦ä¸å®‰å…¨</p>
<p><strong>Publish</strong>: 2025-08-14 06:46:56 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 06:46:56 UTC</p>
<h2 id="20-improving-generative-cross-lingual-aspect-based-sentiment-analysis-with-constrained-decoding--20-ä½¿ç”¨å—é™è§£ç æ”¹è¿›ç”Ÿæˆå¼è·¨è¯­è¨€åŸºäºæ–¹é¢çš„æƒ…æ„Ÿåˆ†æ"><a href="https://arxiv.org/abs/2508.10369"target="_blank" rel="external nofollow noopener noreferrer">#20</a> <a href="https://papers.cool/arxiv/2508.10369"target="_blank" rel="external nofollow noopener noreferrer">Improving Generative Cross-lingual Aspect-Based Sentiment Analysis with Constrained Decoding</a>  #20 ä½¿ç”¨å—é™è§£ç æ”¹è¿›ç”Ÿæˆå¼è·¨è¯­è¨€åŸºäºæ–¹é¢çš„æƒ…æ„Ÿåˆ†æ</h2>
<p><strong>Authors</strong>: [Jakub Å mÃ­d](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jakub"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jakub</a> Å mÃ­d), [Pavel PÅ™ibÃ¡Åˆ](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pavel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pavel</a> PÅ™ibÃ¡Åˆ), [Pavel KrÃ¡l](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pavel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pavel</a> KrÃ¡l)
ä½œè€…ï¼šJakub Å mÃ­dã€Pavel PÅ™ibÃ¡Åˆã€Pavel KrÃ¡l</p>
<p>While aspect-based sentiment analysis (ABSA) has made substantial progress, challenges remain for low-resource languages, which are often overlooked in favour of English. Current cross-lingual ABSA approaches focus on limited, less complex tasks and often rely on external translation tools. This paper introduces a novel approach using constrained decoding with sequence-to-sequence models, eliminating the need for unreliable translation tools and improving cross-lingual performance by 5% on average for the most complex task. The proposed method also supports multi-tasking, which enables solving multiple ABSA tasks with a single model, with constrained decoding boosting results by more than 10%. We evaluate our approach across seven languages and six ABSA tasks, surpassing state-of-the-art methods and setting new benchmarks for previously unexplored tasks. Additionally, we assess large language models (LLMs) in zero-shot, few-shot, and fine-tuning scenarios. While LLMs perform poorly in zero-shot and few-shot settings, fine-tuning achieves competitive results compared to smaller multilingual models, albeit at the cost of longer training and inference times. We provide practical recommendations for real-world applications, enhancing the understanding of cross-lingual ABSA methodologies. This study offers valuable insights into the strengths and limitations of cross-lingual ABSA approaches, advancing the state-of-the-art in this challenging research domain.
å°½ç®¡åŸºäºæ–¹é¢çš„æƒ…æ„Ÿåˆ†æï¼ˆABSAï¼‰å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å¯¹äºèµ„æºåŒ®ä¹çš„è¯­è¨€ä»å­˜åœ¨æŒ‘æˆ˜ï¼Œè¿™äº›è¯­è¨€å¸¸è¢«å¿½è§†è€Œåå‘ç ”ç©¶è‹±è¯­ã€‚å½“å‰çš„è·¨è¯­è¨€ ABSA æ–¹æ³•é›†ä¸­åœ¨æœ‰é™ä¸”è¾ƒä¸å¤æ‚çš„ä»»åŠ¡ä¸Šï¼Œå¹¶ä¸”å¸¸ä¾èµ–å¤–éƒ¨ç¿»è¯‘å·¥å…·ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œåˆ©ç”¨åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„çº¦æŸè§£ç ï¼Œæ¶ˆé™¤äº†å¯¹ä¸å¯é ç¿»è¯‘å·¥å…·çš„éœ€æ±‚ï¼Œå¹¶åœ¨æœ€å¤æ‚çš„ä»»åŠ¡ä¸Šå¹³å‡æå‡äº† 5%çš„è·¨è¯­è¨€æ€§èƒ½ã€‚æ‰€æå‡ºçš„æ–¹æ³•è¿˜æ”¯æŒå¤šä»»åŠ¡å¤„ç†ï¼Œä½¿å•ä¸€æ¨¡å‹èƒ½å¤Ÿè§£å†³å¤šä¸ª ABSA ä»»åŠ¡ï¼Œä¸”çº¦æŸè§£ç å°†ç»“æœæå‡äº† 10%ä»¥ä¸Šã€‚æˆ‘ä»¬åœ¨ä¸ƒç§è¯­è¨€å’Œå…­ä¸ª ABSA ä»»åŠ¡ä¸Šè¯„ä¼°äº†è¯¥æ–¹æ³•ï¼Œè¶…è¿‡äº†ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œå¹¶ä¸ºå…ˆå‰æœªæ¢ç´¢çš„ä»»åŠ¡è®¾ç«‹äº†æ–°çš„åŸºå‡†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨é›¶-shotã€å°‘é‡æ ·æœ¬å’Œå¾®è°ƒæƒ…æ™¯ä¸‹è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ã€‚è™½ç„¶ LLMs åœ¨é›¶-shot å’Œå°‘é‡æ ·æœ¬è®¾ç½®ä¸­çš„è¡¨ç°ä¸ä½³ï¼Œä½†å¾®è°ƒåœ¨ä¸è¾ƒå°çš„å¤šè¯­ç§æ¨¡å‹ç›¸æ¯”æ—¶å–å¾—äº†æœ‰ç«äº‰åŠ›çš„ç»“æœï¼Œå°½ç®¡ä»£ä»·æ˜¯æ›´é•¿çš„è®­ç»ƒå’Œæ¨ç†æ—¶é—´ã€‚ æˆ‘ä»¬ä¸ºç°å®ä¸–ç•Œåº”ç”¨æä¾›äº†åˆ‡å®å¯è¡Œçš„å»ºè®®ï¼Œå¢å¼ºäº†å¯¹è·¨è¯­è¨€æƒ…æ„Ÿææ€§ä¸æ–¹é¢æŠ½å–ï¼ˆABSAï¼‰æ–¹æ³•çš„ç†è§£ã€‚æœ¬ç ”ç©¶å¯¹è·¨è¯­è¨€ ABSA æ–¹æ³•çš„ä¼˜ç‚¹ä¸å±€é™æ€§æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œæ¨åŠ¨äº†è¿™ä¸€å…·æœ‰æŒ‘æˆ˜æ€§çš„ç ”ç©¶é¢†åŸŸçš„æŠ€æœ¯è¿›æ­¥ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 06:07:53 UTC
å‘å¸ƒï¼š2025-08-14 06:07:53 UTC</p>
<h2 id="21-large-language-models-for-summarizing-czech-historical-documents-and-beyond--21-ç”¨äºæ€»ç»“æ·å…‹å†å²æ–‡çŒ®åŠå…¶å®ƒå†…å®¹çš„å¤§å‹è¯­è¨€æ¨¡å‹"><a href="https://arxiv.org/abs/2508.10368"target="_blank" rel="external nofollow noopener noreferrer">#21</a> <a href="https://papers.cool/arxiv/2508.10368"target="_blank" rel="external nofollow noopener noreferrer">Large Language Models for Summarizing Czech Historical Documents and Beyond</a>  #21 ç”¨äºæ€»ç»“æ·å…‹å†å²æ–‡çŒ®åŠå…¶å®ƒå†…å®¹çš„å¤§å‹è¯­è¨€æ¨¡å‹</h2>
<p><strong>Authors</strong>: [VÃ¡clav Tran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=V"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=V</a>Ã¡clav Tran), [Jakub Å mÃ­d](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jakub"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jakub</a> Å mÃ­d), [JiÅ™Ã­ MartÃ­nek](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ji</a>Å™Ã­ MartÃ­nek), [Ladislav Lenc](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ladislav"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ladislav</a> Lenc), [Pavel KrÃ¡l](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pavel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pavel</a> KrÃ¡l)
ä½œè€…ï¼šVÃ¡clav Tranã€Jakub Å mÃ­dã€JiÅ™Ã­ MartÃ­nekã€Ladislav Lencã€Pavel KrÃ¡l</p>
<p>Text summarization is the task of shortening a larger body of text into a concise version while retaining its essential meaning and key information. While summarization has been significantly explored in English and other high-resource languages, Czech text summarization, particularly for historical documents, remains underexplored due to linguistic complexities and a scarcity of annotated datasets. Large language models such as Mistral and mT5 have demonstrated excellent results on many natural language processing tasks and languages. Therefore, we employ these models for Czech summarization, resulting in two key contributions: (1) achieving new state-of-the-art results on the modern Czech summarization dataset SumeCzech using these advanced models, and (2) introducing a novel dataset called Posel od ÄŒerchova for summarization of historical Czech documents with baseline results. Together, these contributions provide a great potential for advancing Czech text summarization and open new avenues for research in Czech historical text processing.
æ–‡æœ¬æ‘˜è¦çš„ä»»åŠ¡æ˜¯å°†è¾ƒé•¿çš„æ–‡æœ¬æµ“ç¼©ä¸ºç®€æ´çš„ç‰ˆæœ¬ï¼ŒåŒæ—¶ä¿ç•™å…¶æ ¸å¿ƒæ„ä¹‰å’Œå…³é”®ä¿¡æ¯ã€‚å°½ç®¡æ‘˜è¦åœ¨è‹±è¯­å’Œå…¶ä»–èµ„æºä¸°å¯Œè¯­è¨€ä¸­å·²è¢«å¤§é‡æ¢ç´¢ï¼Œä½†æ·å…‹è¯­æ–‡æœ¬æ‘˜è¦ï¼Œå°¤å…¶æ˜¯é’ˆå¯¹å†å²æ–‡çŒ®çš„æ‘˜è¦ï¼Œç”±äºè¯­è¨€å¤æ‚æ€§å’Œæ ‡æ³¨æ•°æ®é›†çš„åŒ®ä¹ï¼Œä»ç„¶ç¼ºä¹æ·±å…¥ç ”ç©¶ã€‚åƒ Mistral å’Œ mT5 è¿™æ ·çš„å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®¸å¤šè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡å’Œå¤šç§è¯­è¨€ä¸Šè¡¨ç°å‡ºè‰²ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœ¨æ·å…‹è¯­æ‘˜è¦ä»»åŠ¡ä¸­é‡‡ç”¨äº†è¿™äº›æ¨¡å‹ï¼Œå¸¦æ¥äº†ä¸¤ä¸ªä¸»è¦è´¡çŒ®ï¼šï¼ˆ1ï¼‰åœ¨ç°ä»£æ·å…‹è¯­æ‘˜è¦æ•°æ®é›† SumeCzech ä¸Šåˆ©ç”¨è¿™äº›å…ˆè¿›æ¨¡å‹å–å¾—äº†æ–°çš„æœ€å…ˆè¿›ï¼ˆstate-of-the-artï¼‰ç»“æœï¼›ï¼ˆ2ï¼‰å¼•å…¥äº†ä¸€ä¸ªåä¸º Posel od ÄŒerchova çš„æ–°æ•°æ®é›†ï¼Œç”¨äºå†å²æ·å…‹æ–‡çŒ®çš„æ‘˜è¦ï¼Œå¹¶æä¾›äº†åŸºçº¿ç»“æœã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™äº›è´¡çŒ®ä¸ºæ¨è¿›æ·å…‹è¯­æ–‡æœ¬æ‘˜è¦æä¾›äº†å·¨å¤§æ½œåŠ›ï¼Œå¹¶ä¸ºæ·å…‹å†å²æ–‡æœ¬å¤„ç†çš„ç ”ç©¶å¼€è¾Ÿäº†æ–°æ–¹å‘ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 06:07:49 UTC</p>
<h2 id="22-advancing-cross-lingual-aspect-based-sentiment-analysis-with-llms-and-constrained-decoding-for-sequence-to-sequence-models--22-ä½¿ç”¨-llms-å’Œå¯¹åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„çº¦æŸè§£ç æ¨è¿›è·¨è¯­è¨€ç»†ç²’åº¦æƒ…æ„Ÿåˆ†æ-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10366"target="_blank" rel="external nofollow noopener noreferrer">#22</a> <a href="https://papers.cool/arxiv/2508.10366"target="_blank" rel="external nofollow noopener noreferrer">Advancing Cross-lingual Aspect-Based Sentiment Analysis with LLMs and Constrained Decoding for Sequence-to-Sequence Models</a>  #22 ä½¿ç”¨ LLMs å’Œå¯¹åºåˆ—åˆ°åºåˆ—æ¨¡å‹çš„çº¦æŸè§£ç æ¨è¿›è·¨è¯­è¨€ç»†ç²’åº¦æƒ…æ„Ÿåˆ†æ [PDF ] [Copy] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [Jakub Å mÃ­d](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jakub"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jakub</a> Å mÃ­d), [Pavel PÅ™ibÃ¡Åˆ](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pavel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pavel</a> PÅ™ibÃ¡Åˆ), [Pavel KrÃ¡l](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pavel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pavel</a> KrÃ¡l)
ä½œè€…ï¼šJakub Å mÃ­dã€Pavel PÅ™ibÃ¡Åˆã€Pavel KrÃ¡l</p>
<p>Aspect-based sentiment analysis (ABSA) has made significant strides, yet challenges remain for low-resource languages due to the predominant focus on English. Current cross-lingual ABSA studies often centre on simpler tasks and rely heavily on external translation tools. In this paper, we present a novel sequence-to-sequence method for compound ABSA tasks that eliminates the need for such tools. Our approach, which uses constrained decoding, improves cross-lingual ABSA performance by up to 10%. This method broadens the scope of cross-lingual ABSA, enabling it to handle more complex tasks and providing a practical, efficient alternative to translation-dependent techniques. Furthermore, we compare our approach with large language models (LLMs) and show that while fine-tuned multilingual LLMs can achieve comparable results, English-centric LLMs struggle with these tasks.
åŸºäºæ–¹é¢çš„æƒ…æ„Ÿåˆ†æï¼ˆABSAï¼‰å·²å–å¾—æ˜¾è‘—è¿›å±•ï¼Œä½†ç”±äºç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è‹±è¯­ï¼Œå¯¹äºèµ„æºåŒ®ä¹è¯­è¨€ä»å­˜åœ¨æŒ‘æˆ˜ã€‚å½“å‰çš„è·¨è¯­è¨€ ABSA ç ”ç©¶å¸¸èšç„¦äºè¾ƒç®€å•çš„ä»»åŠ¡ï¼Œå¹¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–å¤–éƒ¨ç¿»è¯‘å·¥å…·ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§ç”¨äºå¤åˆ ABSA ä»»åŠ¡çš„æ–°å‹åºåˆ—åˆ°åºåˆ—æ–¹æ³•ï¼Œæ¶ˆé™¤äº†å¯¹æ­¤ç±»å·¥å…·çš„éœ€æ±‚ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨çº¦æŸè§£ç ï¼Œä½¿è·¨è¯­è¨€ ABSA æ€§èƒ½æå‡æœ€å¤šè¾¾ 10%ã€‚è¯¥æ–¹æ³•æ‹“å®½äº†è·¨è¯­è¨€ ABSA çš„é€‚ç”¨èŒƒå›´ï¼Œä½¿å…¶èƒ½å¤Ÿå¤„ç†æ›´å¤æ‚çš„ä»»åŠ¡ï¼Œå¹¶æä¾›äº†ä¸€ç§å®ç”¨ä¸”é«˜æ•ˆçš„æ›¿ä»£ç¿»è¯‘ä¾èµ–æŠ€æœ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å°†æ­¤æ–¹æ³•ä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œäº†æ¯”è¾ƒï¼Œç»“æœè¡¨æ˜å¾®è°ƒçš„å¤šè¯­ç§ LLMs å¯ä»¥è¾¾åˆ°ç›¸å½“çš„æ•ˆæœï¼Œè€Œä»¥è‹±è¯­ä¸ºä¸­å¿ƒçš„ LLMs åœ¨è¿™äº›ä»»åŠ¡ä¸Šè¡¨ç°å›°éš¾ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 06:07:43 UTC
å‘å¸ƒï¼š2025-08-14 06:07:43 UTC</p>
<h2 id="23-making-qwen3-think-in-korean-with-reinforcement-learning--23-ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®©-qwen3-ç”¨éŸ©è¯­æ€è€ƒ"><a href="https://arxiv.org/abs/2508.10355"target="_blank" rel="external nofollow noopener noreferrer">#23</a> <a href="https://papers.cool/arxiv/2508.10355"target="_blank" rel="external nofollow noopener noreferrer">Making Qwen3 Think in Korean with Reinforcement Learning</a>  #23 ä½¿ç”¨å¼ºåŒ–å­¦ä¹ è®© Qwen3 ç”¨éŸ©è¯­æ€è€ƒ</h2>
<p><strong>Authors</strong>: [Jungyup Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jungyup"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jungyup</a> Lee), [Jemin Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jemin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jemin</a> Kim), [Sang Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sang</a> Park), [SeungJae Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=SeungJae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=SeungJae</a> Lee)
ä½œè€…ï¼šJungyup Leeã€Jemin Kimã€Sang Parkã€SeungJae Lee</p>
<p>We present a two-stage fine-tuning approach to make the large language model Qwen3 14B &ldquo;think&rdquo; natively in Korean. In the first stage, supervised fine-tuning (SFT) on a high-quality Korean reasoning dataset establishes a strong foundation in Korean logical reasoning, yielding notable improvements in Korean-language tasks and even some gains in general reasoning ability. In the second stage, we employ reinforcement learning with a customized Group Relative Policy Optimization (GRPO) algorithm to further enhance both Korean reasoning alignment and overall problem-solving performance. We address critical stability challenges in GRPO training - such as reward hacking and policy collapse - by introducing an oracle judge model that calibrates the reward signal. Our approach achieves stable learning (avoiding the collapse observed in naive GRPO) and leads to steady, incremental performance gains. The final RL-tuned model demonstrates substantially improved results on advanced reasoning benchmarks (particularly math and coding tasks) while maintaining knowledge and language proficiency, successfully conducting its internal chain-of-thought entirely in Korean.
æˆ‘ä»¬æå‡ºäº†ä¸€ç§ä¸¤é˜¶æ®µå¾®è°ƒæ–¹æ³•ï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹ Qwen3 14B èƒ½å¤Ÿä»¥éŸ©è¯­â€œæœ¬åœ°åŒ–æ€è€ƒâ€ã€‚åœ¨ç¬¬ä¸€é˜¶æ®µï¼Œé€šè¿‡åœ¨é«˜è´¨é‡çš„éŸ©è¯­æ¨ç†æ•°æ®é›†ä¸Šè¿›è¡Œç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œä¸ºéŸ©è¯­é€»è¾‘æ¨ç†å»ºç«‹äº†åšå®åŸºç¡€ï¼Œä»è€Œåœ¨éŸ©è¯­ä»»åŠ¡ä¸Šå¸¦æ¥äº†æ˜¾è‘—æå‡ï¼Œç”šè‡³åœ¨é€šç”¨æ¨ç†èƒ½åŠ›ä¸Šä¹Ÿæœ‰ä¸€å®šå¢ç›Šã€‚ç¬¬äºŒé˜¶æ®µï¼Œæˆ‘ä»¬é‡‡ç”¨å®šåˆ¶çš„ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆGroup Relative Policy Optimizationï¼ŒGRPOï¼‰ç®—æ³•è¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä»¥è¿›ä¸€æ­¥å¢å¼ºéŸ©è¯­æ¨ç†çš„å¯¹é½æ€§å’Œæ•´ä½“é—®é¢˜è§£å†³æ€§èƒ½ã€‚æˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸€ä¸ªç¥è°•è¯„åˆ¤æ¨¡å‹æ¥æ ¡å‡†å¥–åŠ±ä¿¡å·ï¼Œè§£å†³äº† GRPO è®­ç»ƒä¸­çš„å…³é”®ç¨³å®šæ€§æŒ‘æˆ˜â€”â€”ä¾‹å¦‚å¥–åŠ±åŠ«æŒå’Œç­–ç•¥å´©æºƒã€‚æˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†ç¨³å®šå­¦ä¹ ï¼ˆé¿å…äº†åŸå§‹ GRPO ä¸­è§‚å¯Ÿåˆ°çš„å´©æºƒï¼‰ï¼Œå¹¶å¸¦æ¥äº†ç¨³æ­¥çš„æ€§èƒ½æå‡ã€‚æœ€ç»ˆç» RL è°ƒä¼˜çš„æ¨¡å‹åœ¨é«˜çº§æ¨ç†åŸºå‡†ä¸Šï¼ˆå°¤å…¶æ˜¯æ•°å­¦å’Œç¼–ç ä»»åŠ¡ï¼‰è¡¨ç°æ˜¾è‘—æå‡ï¼ŒåŒæ—¶ä¿æŒäº†çŸ¥è¯†ä¸è¯­è¨€èƒ½åŠ›ï¼Œèƒ½å¤ŸæˆåŠŸåœ°å°†å…¶å†…éƒ¨é“¾å¼æ€ç»´å®Œå…¨ç”¨éŸ©è¯­è¿›è¡Œã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 05:49:34 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 05:49:34 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="24-cross-prompt-encoder-for-low-performing-languages--24-è·¨æç¤ºç¼–ç å™¨ç”¨äºè¡¨ç°æ¬ ä½³çš„è¯­è¨€"><a href="https://arxiv.org/abs/2508.10352"target="_blank" rel="external nofollow noopener noreferrer">#24</a> <a href="https://papers.cool/arxiv/2508.10352"target="_blank" rel="external nofollow noopener noreferrer">Cross-Prompt Encoder for Low-Performing Languages</a>  #24 è·¨æç¤ºç¼–ç å™¨ç”¨äºè¡¨ç°æ¬ ä½³çš„è¯­è¨€</h2>
<p><strong>Authors</strong>: [Beso Mikaberidze](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Beso"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Beso</a> Mikaberidze), [Teimuraz Saghinadze](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Teimuraz"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Teimuraz</a> Saghinadze), [Simon Ostermann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Simon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Simon</a> Ostermann), [Philipp Muller](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Philipp"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Philipp</a> Muller)
ä½œè€…ï¼šBeso Mikaberidzeã€Teimuraz Saghinadzeã€Simon Ostermannã€Philipp Muller</p>
<p>Soft prompts have emerged as a powerful alternative to adapters in parameter-efficient fine-tuning (PEFT), enabling large language models (LLMs) to adapt to downstream tasks without architectural changes or parameter updates. While prior work has focused on stabilizing training via parameter interaction in small neural prompt encoders, their broader potential for transfer across languages remains unexplored. In this paper, we demonstrate that a prompt encoder can play a central role in improving performance on low-performing languages-those that achieve poor accuracy even under full-model fine-tuning. We introduce the Cross-Prompt Encoder (XPE), which combines a lightweight encoding architecture with multi-source training on typologically diverse languages - a design that enables the model to capture abstract and transferable patterns across languages. To complement XPE, we propose a Dual Soft Prompt mechanism that combines an encoder-based prompt with a directly trained standard soft prompt. This hybrid design proves especially effective for target languages that benefit from both broadly shared structure and language-specific alignment. Experiments on the SIB-200 benchmark reveal a consistent trade-off: XPE is most effective for low-performing languages, while hybrid variants offer broader adaptability across multilingual settings.
è½¯æç¤ºå·²æˆä¸ºé€‚ç”¨äºå‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆPEFTï¼‰çš„å¼ºå¤§æ›¿ä»£æ–¹æ¡ˆï¼Œä½¿å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰èƒ½å¤Ÿåœ¨ä¸æ”¹å˜æ¶æ„æˆ–æ›´æ–°å‚æ•°çš„æƒ…å†µä¸‹é€‚åº”ä¸‹æ¸¸ä»»åŠ¡ã€‚è™½ç„¶å…ˆå‰å·¥ä½œé›†ä¸­åœ¨é€šè¿‡å°å‹ç¥ç»æç¤ºç¼–ç å™¨ä¸­çš„å‚æ•°äº¤äº’æ¥ç¨³å®šè®­ç»ƒï¼Œä½†å…¶åœ¨è·¨è¯­è¨€è¿ç§»æ–¹é¢çš„æ›´å¹¿æ³›æ½œåŠ›å°šæœªè¢«æ¢ç´¢ã€‚æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†æç¤ºç¼–ç å™¨åœ¨æå‡è¡¨ç°ä¸ä½³è¯­è¨€ï¼ˆå³å³ä½¿åœ¨å…¨æ¨¡å‹å¾®è°ƒä¸‹ä»è¡¨ç°å‡ºä½å‡†ç¡®ç‡çš„è¯­è¨€ï¼‰ä¸Šçš„æ ¸å¿ƒä½œç”¨ã€‚æˆ‘ä»¬æå‡ºäº†è·¨æç¤ºç¼–ç å™¨ï¼ˆXPEï¼‰ï¼Œå®ƒå°†è½»é‡çº§ç¼–ç æ¶æ„ä¸æ¥è‡ªç±»å‹å­¦å¤šæ ·è¯­è¨€çš„å¤šæºè®­ç»ƒç›¸ç»“åˆâ€”â€”è¿™ä¸€è®¾è®¡ä½¿æ¨¡å‹èƒ½å¤Ÿæ•æ‰è·¨è¯­è¨€çš„æŠ½è±¡ä¸”å¯è¿ç§»çš„æ¨¡å¼ã€‚ä¸ºäº†è¡¥å…… XPEï¼Œæˆ‘ä»¬æå‡ºäº†åŒè½¯æç¤ºæœºåˆ¶ï¼Œå°†åŸºäºç¼–ç å™¨çš„æç¤ºä¸ç›´æ¥è®­ç»ƒçš„æ ‡å‡†è½¯æç¤ºç›¸ç»“åˆã€‚è¿™ä¸€æ··åˆè®¾è®¡å¯¹äºé‚£äº›æ—¢èƒ½ä»å¹¿æ³›å…±äº«çš„ç»“æ„ä¸­å—ç›Šåˆéœ€è¿›è¡Œè¯­è¨€ç‰¹å®šå¯¹é½çš„ç›®æ ‡è¯­è¨€å°¤å…¶æœ‰æ•ˆã€‚ åœ¨ SIB-200 åŸºå‡†ä¸Šçš„å®éªŒæ­ç¤ºäº†ä¸€ä¸ªä¸€è‡´çš„æƒè¡¡ï¼šXPE å¯¹è¡¨ç°è¾ƒå·®çš„è¯­è¨€æœ€ä¸ºæœ‰æ•ˆï¼Œè€Œæ··åˆå˜ä½“åœ¨å¤šè¯­è¨€ç¯å¢ƒä¸­æä¾›äº†æ›´å¹¿æ³›çš„é€‚åº”æ€§ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 05:36:21 UTC
å‘å¸ƒï¼š2025-08-14 05:36:21 UTC</p>
<h2 id="25-beyond-semantic-understanding-preserving-collaborative-frequency-components-in-llm-based-recommendation--25-è¶…è¶Šè¯­ä¹‰ç†è§£åœ¨åŸºäº-llm-çš„æ¨èä¸­ä¿ç•™ååŒé¢‘ç‡åˆ†é‡"><a href="https://arxiv.org/abs/2508.10312"target="_blank" rel="external nofollow noopener noreferrer">#25</a> <a href="https://papers.cool/arxiv/2508.10312"target="_blank" rel="external nofollow noopener noreferrer">Beyond Semantic Understanding: Preserving Collaborative Frequency Components in LLM-based Recommendation</a>  #25 è¶…è¶Šè¯­ä¹‰ç†è§£ï¼šåœ¨åŸºäº LLM çš„æ¨èä¸­ä¿ç•™ååŒé¢‘ç‡åˆ†é‡</h2>
<p><strong>Authors</strong>: [Minhao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minhao</a> Wang), [Yunhang He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunhang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunhang</a> He), [Cong Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cong</a> Xu), [Zhangchi Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhangchi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhangchi</a> Zhu), [Wei Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Zhang)
ä½œè€…ï¼šç‹æ—»çã€ä½•äº‘èˆªã€è®¸èªã€æœ±ç« é©°ã€å¼ ä¼Ÿ</p>
<p>Recommender systems in concert with Large Language Models (LLMs) present promising avenues for generating semantically-informed recommendations. However, LLM-based recommenders exhibit a tendency to overemphasize semantic correlations within users&rsquo; interaction history. When taking pretrained collaborative ID embeddings as input, LLM-based recommenders progressively weaken the inherent collaborative signals as the embeddings propagate through LLM backbones layer by layer, as opposed to traditional Transformer-based sequential models in which collaborative signals are typically preserved or even enhanced for state-of-the-art performance. To address this limitation, we introduce FreLLM4Rec, an approach designed to balance semantic and collaborative information from a spectral perspective. Item embeddings that incorporate both semantic and collaborative information are first purified using a Global Graph Low-Pass Filter (G-LPF) to preliminarily remove irrelevant high-frequency noise. Temporal Frequency Modulation (TFM) then actively preserves collaborative signal layer by layer. Note that the collaborative preservation capability of TFM is theoretically guaranteed by establishing a connection between the optimal but hard-to-implement local graph fourier filters and the suboptimal yet computationally efficient frequency-domain filters. Extensive experiments on four benchmark datasets demonstrate that FreLLM4Rec successfully mitigates collaborative signal attenuation and achieves competitive performance, with improvements of up to 8.00% in NDCG@10 over the best baseline. Our findings provide insights into how LLMs process collaborative information and offer a principled approach for improving LLM-based recommendation systems.
æ¨èç³»ç»Ÿä¸å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç»“åˆï¼Œä¸ºç”Ÿæˆè¯­ä¹‰é©±åŠ¨çš„æ¨èæä¾›äº†æœ‰å¸Œæœ›çš„é€”å¾„ã€‚ç„¶è€Œï¼ŒåŸºäº LLM çš„æ¨èå™¨å€¾å‘äºè¿‡åº¦å¼ºè°ƒç”¨æˆ·äº¤äº’å†å²ä¸­çš„è¯­ä¹‰ç›¸å…³æ€§ã€‚å½“ä»¥é¢„è®­ç»ƒçš„ååŒ ID åµŒå…¥ä½œä¸ºè¾“å…¥æ—¶ï¼ŒåŸºäº LLM çš„æ¨èå™¨åœ¨åµŒå…¥é€šè¿‡ LLM ä¸»å¹²ç½‘ç»œé€å±‚ä¼ æ’­çš„è¿‡ç¨‹ä¸­ï¼Œä¼šé€æ­¥å‰Šå¼±å›ºæœ‰çš„ååŒä¿¡å·ï¼›è€Œä¼ ç»Ÿçš„åŸºäº Transformer çš„åºåˆ—æ¨¡å‹é€šå¸¸ä¼šä¿ç•™ç”šè‡³å¢å¼ºååŒä¿¡å·ä»¥å®ç°æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™ï¼Œæˆ‘ä»¬æå‡ºäº† FreLLM4Recï¼Œä¸€ç§ä»é¢‘è°±è§†è§’å¹³è¡¡è¯­ä¹‰ä¸ååŒä¿¡æ¯çš„æ–¹æ³•ã€‚é¦–å…ˆä½¿ç”¨å…¨å±€å›¾ä½é€šæ»¤æ³¢å™¨ï¼ˆG-LPFï¼‰å¯¹åŒæ—¶åŒ…å«è¯­ä¹‰å’ŒååŒä¿¡æ¯çš„ç‰©å“åµŒå…¥è¿›è¡Œå‡€åŒ–ï¼Œä»¥åˆæ­¥å»é™¤æ— å…³çš„é«˜é¢‘å™ªå£°ã€‚ç„¶åé€šè¿‡æ—¶åºé¢‘ç‡è°ƒåˆ¶ï¼ˆTFMï¼‰åœ¨æ¯ä¸€å±‚ä¸»åŠ¨ä¿ç•™ååŒä¿¡å·ã€‚ è¯·æ³¨æ„ï¼ŒTFM çš„ååŒä¿å­˜èƒ½åŠ›åœ¨ç†è®ºä¸Šé€šè¿‡å»ºç«‹æœ€ä¼˜ä½†éš¾ä»¥å®ç°çš„å±€éƒ¨å›¾å‚…é‡Œå¶æ»¤æ³¢å™¨ä¸æ¬¡ä¼˜ä½†è®¡ç®—ä¸Šé«˜æ•ˆçš„é¢‘åŸŸæ»¤æ³¢å™¨ä¹‹é—´çš„è”ç³»å¾—åˆ°äº†ä¿è¯ã€‚åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒFreLLM4Rec æˆåŠŸç¼“è§£äº†ååŒä¿¡å·è¡°å‡ï¼Œå¹¶å®ç°äº†å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œåœ¨ NDCG@10 ä¸Šæ¯”æœ€ä½³åŸºçº¿æœ€å¤šæé«˜äº† 8.00%ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœä¸ºç†è§£ LLMs å¦‚ä½•å¤„ç†ååŒä¿¡æ¯æä¾›äº†è§è§£ï¼Œå¹¶ä¸ºæ”¹è¿›åŸºäº LLM çš„æ¨èç³»ç»Ÿæä¾›äº†æœ‰åŸåˆ™çš„æ–¹æ³•ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 03:33:02 UTC
å‘å¸ƒï¼š2025-08-14 03:33:02 ä¸–ç•Œåè°ƒæ—¶é—´</p>
<h2 id="26-from-surface-to-semantics-semantic-structure-parsing-for-table-centric-document-analysis--26-ä»è¡¨é¢åˆ°è¯­ä¹‰é¢å‘è¡¨æ ¼çš„æ–‡æ¡£åˆ†æçš„è¯­ä¹‰ç»“æ„è§£æ"><a href="https://arxiv.org/abs/2508.10311"target="_blank" rel="external nofollow noopener noreferrer">#26</a> <a href="https://papers.cool/arxiv/2508.10311"target="_blank" rel="external nofollow noopener noreferrer">From Surface to Semantics: Semantic Structure Parsing for Table-Centric Document Analysis</a>  #26 ä»è¡¨é¢åˆ°è¯­ä¹‰ï¼šé¢å‘è¡¨æ ¼çš„æ–‡æ¡£åˆ†æçš„è¯­ä¹‰ç»“æ„è§£æ</h2>
<p><strong>Authors</strong>: [Xuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuan</a> Li), [Jialiang Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jialiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jialiang</a> Dong), [Raymond Wong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raymond"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raymond</a> Wong)
ä½œè€…ï¼šæç’‡ï¼Œè‘£å®¶äº®ï¼ŒRaymond Wong</p>
<p>Documents are core carriers of information and knowl-edge, with broad applications in finance, healthcare, and scientific research. Tables, as the main medium for structured data, encapsulate key information and are among the most critical document components. Existing studies largely focus on surface-level tasks such as layout analysis, table detection, and data extraction, lacking deep semantic parsing of tables and their contextual associations. This limits advanced tasks like cross-paragraph data interpretation and context-consistent analysis. To address this, we propose DOTABLER, a table-centric semantic document parsing framework designed to uncover deep semantic links between tables and their context. DOTABLER leverages a custom dataset and domain-specific fine-tuning of pre-trained models, integrating a complete parsing pipeline to identify context segments semantically tied to tables. Built on this semantic understanding, DOTABLER implements two core functionalities: table-centric document structure parsing and domain-specific table retrieval, delivering comprehensive table-anchored semantic analysis and precise extraction of semantically relevant tables. Evaluated on nearly 4,000 pages with over 1,000 tables from real-world PDFs, DOTABLER achieves over 90% Precision and F1 scores, demonstrating superior performance in table-context semantic analysis and deep document parsing compared to advanced models such as GPT-4o.
æ–‡æ¡£æ˜¯ä¿¡æ¯å’ŒçŸ¥è¯†çš„æ ¸å¿ƒè½½ä½“ï¼Œåœ¨é‡‘èã€åŒ»ç–—å’Œç§‘ç ”ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨ã€‚è¡¨æ ¼ä½œä¸ºç»“æ„åŒ–æ•°æ®çš„ä¸»è¦åª’ä»‹ï¼Œå°è£…äº†å…³é”®ä¿¡æ¯ï¼Œæ˜¯æ–‡æ¡£ä¸­æœ€å…³é”®çš„ç»„æˆéƒ¨åˆ†ä¹‹ä¸€ã€‚ç°æœ‰ç ”ç©¶å¤§å¤šä¾§é‡äºç‰ˆé¢åˆ†æã€è¡¨æ ¼æ£€æµ‹å’Œæ•°æ®æå–ç­‰è¡¨é¢å±‚é¢çš„ä»»åŠ¡ï¼Œç¼ºä¹å¯¹è¡¨æ ¼åŠå…¶ä¸Šä¸‹æ–‡å…³è”çš„æ·±å±‚è¯­ä¹‰è§£æã€‚è¿™é™åˆ¶äº†è·¨æ®µè½æ•°æ®è§£è¯»å’Œè¯­å¢ƒä¸€è‡´æ€§åˆ†æç­‰é«˜çº§ä»»åŠ¡çš„å®ç°ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† DOTABLERï¼Œä¸€ç§ä»¥è¡¨æ ¼ä¸ºä¸­å¿ƒçš„è¯­ä¹‰æ–‡æ¡£è§£ææ¡†æ¶ï¼Œæ—¨åœ¨å‘æ˜è¡¨æ ¼ä¸å…¶ä¸Šä¸‹æ–‡ä¹‹é—´çš„æ·±å±‚è¯­ä¹‰è”ç³»ã€‚DOTABLER åˆ©ç”¨å®šåˆ¶æ•°æ®é›†å’Œé¢†åŸŸç‰¹å®šçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒï¼Œé›†æˆå®Œæ•´çš„è§£æç®¡é“ä»¥è¯†åˆ«ä¸è¡¨æ ¼åœ¨è¯­ä¹‰ä¸Šç›¸å…³çš„ä¸Šä¸‹æ–‡ç‰‡æ®µã€‚åœ¨æ­¤è¯­ä¹‰ç†è§£çš„åŸºç¡€ä¸Šï¼ŒDOTABLER å®ç°äº†ä¸¤é¡¹æ ¸å¿ƒåŠŸèƒ½ï¼šä»¥è¡¨æ ¼ä¸ºä¸­å¿ƒçš„æ–‡æ¡£ç»“æ„è§£æå’Œé¢†åŸŸç‰¹å®šçš„è¡¨æ ¼æ£€ç´¢ï¼Œæä¾›å…¨é¢çš„è¡¨æ ¼é”šå®šè¯­ä¹‰åˆ†æå’Œè¯­ä¹‰ç›¸å…³è¡¨æ ¼çš„ç²¾ç¡®æå–ã€‚ åœ¨è¿‘ 4,000 é¡µã€åŒ…å«è¶…è¿‡ 1,000 ä¸ªè¡¨æ ¼çš„çœŸå®ä¸–ç•Œ PDF ä¸Šè¯„ä¼°ï¼ŒDOTABLER åœ¨ç²¾ç¡®åº¦å’Œ F1 åˆ†æ•°ä¸Šå‡è¶…è¿‡ 90%ï¼Œåœ¨è¡¨æ ¼-ä¸Šä¸‹æ–‡è¯­ä¹‰åˆ†æå’Œæ·±åº¦æ–‡æ¡£è§£ææ–¹é¢ä¼˜äºåŒ…æ‹¬ GPT-4o åœ¨å†…çš„å…ˆè¿›æ¨¡å‹ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 03:29:51 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-14 03:29:51 UTC</p>
<h2 id="27-reviewrl-towards-automated-scientific-review-with-rl--27-reviewrlè¿ˆå‘åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç§‘å­¦å®¡ç¨¿"><a href="https://arxiv.org/abs/2508.10308"target="_blank" rel="external nofollow noopener noreferrer">#27</a> <a href="https://papers.cool/arxiv/2508.10308"target="_blank" rel="external nofollow noopener noreferrer">ReviewRL: Towards Automated Scientific Review with RL</a>  #27 ReviewRLï¼šè¿ˆå‘åŸºäºå¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç§‘å­¦å®¡ç¨¿</h2>
<p><strong>Authors</strong>: [Sihang Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sihang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sihang</a> Zeng), [Kai Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Tian), [Kaiyan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaiyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaiyan</a> Zhang), [Yuru wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuru"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuru</a> wang), [Junqi Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junqi</a> Gao), [Runze Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Runze"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Runze</a> Liu), [Sa Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sa</a> Yang), [Jingxuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingxuan</a> Li), [Xinwei Long](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinwei</a> Long), [Jiaheng Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaheng</a> Ma), [Biqing Qi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Biqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Biqing</a> Qi), [Bowen Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Zhou)
ä½œè€…ï¼šæ›¾æ€èˆªã€ç”°å‡¯ã€å¼ å‡¯å²©ã€ç‹ç‰å¦‚ã€é«˜ä¿Šç¦ã€åˆ˜æ¶¦æ³½ã€æ¨è¨ã€æé™ç’‡ã€é¾™é‘«å¨ã€é©¬å˜‰æ’ã€é½ç¢§æ¸…ã€å‘¨åšæ–‡</p>
<p>Peer review is essential for scientific progress but faces growing challenges due to increasing submission volumes and reviewer fatigue. Existing automated review approaches struggle with factual accuracy, rating consistency, and analytical depth, often generating superficial or generic feedback lacking the insights characteristic of high-quality human reviews. We introduce ReviewRL, a reinforcement learning framework for generating comprehensive and factually grounded scientific paper reviews. Our approach combines: (1) an ArXiv-MCP retrieval-augmented context generation pipeline that incorporates relevant scientific literature, (2) supervised fine-tuning that establishes foundational reviewing capabilities, and (3) a reinforcement learning procedure with a composite reward function that jointly enhances review quality and rating accuracy. Experiments on ICLR 2025 papers demonstrate that ReviewRL significantly outperforms existing methods across both rule-based metrics and model-based quality assessments. ReviewRL establishes a foundational framework for RL-driven automatic critique generation in scientific discovery, demonstrating promising potential for future development in this domain. The implementation of ReviewRL will be released at GitHub.
åŒè¡Œè¯„å®¡å¯¹ç§‘å­¦è¿›æ­¥è‡³å…³é‡è¦ï¼Œä½†ç”±äºæŠ•ç¨¿é‡å¢åŠ å’Œå®¡ç¨¿äººç–²åŠ³ï¼Œé¢ä¸´æ—¥ç›Šä¸¥å³»çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„è‡ªåŠ¨åŒ–å®¡ç¨¿æ–¹æ³•åœ¨äº‹å®å‡†ç¡®æ€§ã€è¯„åˆ†ä¸€è‡´æ€§å’Œåˆ†ææ·±åº¦æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¸¸å¸¸ç”Ÿæˆè‚¤æµ…æˆ–é€šç”¨çš„åé¦ˆï¼Œç¼ºä¹é«˜è´¨é‡äººå·¥å®¡ç¨¿æ‰€å…·æœ‰çš„æ´è§ã€‚æˆ‘ä»¬æå‡ºäº† ReviewRLï¼Œä¸€ç§ç”¨äºç”Ÿæˆå…¨é¢ä¸”åŸºäºäº‹å®çš„ç§‘å­¦è®ºæ–‡è¯„å®¡çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†ï¼š(1) ä¸€ä¸ª ArXiv-MCP æ£€ç´¢å¢å¼ºä¸Šä¸‹æ–‡ç”Ÿæˆç®¡é“ï¼Œçº³å…¥äº†ç›¸å…³çš„ç§‘å­¦æ–‡çŒ®ï¼Œ(2) å»ºç«‹åŸºç¡€å®¡ç¨¿èƒ½åŠ›çš„ç›‘ç£å¾®è°ƒï¼Œå’Œ (3) å…·æœ‰å¤åˆå¥–åŠ±å‡½æ•°çš„å¼ºåŒ–å­¦ä¹ æµç¨‹ï¼Œè”åˆæå‡è¯„å®¡è´¨é‡å’Œè¯„åˆ†å‡†ç¡®æ€§ã€‚åœ¨ ICLR 2025 è®ºæ–‡ä¸Šçš„å®éªŒè¯æ˜ï¼ŒReviewRL åœ¨åŸºäºè§„åˆ™çš„æŒ‡æ ‡å’ŒåŸºäºæ¨¡å‹çš„è´¨é‡è¯„ä¼°ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ ReviewRL ä¸ºåŸºäºå¼ºåŒ–å­¦ä¹ çš„ç§‘å­¦å‘ç°è‡ªåŠ¨è¯„å®¡ç”Ÿæˆå»ºç«‹äº†åŸºç¡€æ¡†æ¶ï¼Œå±•ç¤ºäº†è¯¥é¢†åŸŸæœªæ¥å‘å±•çš„è‰¯å¥½æ½œåŠ›ã€‚ReviewRL çš„å®ç°å°†å‘å¸ƒåœ¨ GitHubã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 03:26:13 UTC
å‘å¸ƒï¼š2025-08-14 03:26:13 UTC</p>
<h2 id="28-yet-another-algorithmic-bias-a-discursive-analysis-of-large-language-models-reinforcing-dominant-discourses-on-gender-and-race--28-åˆä¸€ç§ç®—æ³•åè§å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ€§åˆ«ä¸ç§æ—è¯è¯­ä¸Šå¼ºåŒ–ä¸»å¯¼è¯è¯­çš„è®ºè¿°åˆ†æ"><a href="https://arxiv.org/abs/2508.10304"target="_blank" rel="external nofollow noopener noreferrer">#28</a> <a href="https://papers.cool/arxiv/2508.10304"target="_blank" rel="external nofollow noopener noreferrer">Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race</a>  #28 åˆä¸€ç§ç®—æ³•åè§ï¼šå¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ€§åˆ«ä¸ç§æ—è¯è¯­ä¸Šå¼ºåŒ–ä¸»å¯¼è¯è¯­çš„è®ºè¿°åˆ†æ</h2>
<p><strong>Authors</strong>: [Gustavo Bonil](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gustavo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gustavo</a> Bonil), [Simone Hashiguti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Simone"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Simone</a> Hashiguti), [Jhessica Silva](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jhessica"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jhessica</a> Silva), [JoÃ£o Gondim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jo</a>Ã£o Gondim), [Helena Maia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helena</a> Maia), [NÃ¡dia Silva](<a href="https://arxiv.org/search/?searchtype=author&amp;query=N"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=N</a>Ã¡dia Silva), [Helio Pedrini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helio</a> Pedrini), [Sandra Avila](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sandra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sandra</a> Avila)
ä½œè€…ï¼šGustavo Bonilã€Simone Hashigutiã€Jhessica Silvaã€JoÃ£o Gondimã€Helena Maiaã€NÃ¡dia Silvaã€Helio Pedriniã€Sandra Avila</p>
<p>With the advance of Artificial Intelligence (AI), Large Language Models (LLMs) have gained prominence and been applied in diverse contexts. As they evolve into more sophisticated versions, it is essential to assess whether they reproduce biases, such as discrimination and racialization, while maintaining hegemonic discourses. Current bias detection approaches rely mostly on quantitative, automated methods, which often overlook the nuanced ways in which biases emerge in natural language. This study proposes a qualitative, discursive framework to complement such methods. Through manual analysis of LLM-generated short stories featuring Black and white women, we investigate gender and racial biases. We contend that qualitative methods such as the one proposed here are fundamental to help both developers and users identify the precise ways in which biases manifest in LLM outputs, thus enabling better conditions to mitigate them. Results show that Black women are portrayed as tied to ancestry and resistance, while white women appear in self-discovery processes. These patterns reflect how language models replicate crystalized discursive representations, reinforcing essentialization and a sense of social immobility. When prompted to correct biases, models offered superficial revisions that maintained problematic meanings, revealing limitations in fostering inclusive narratives. Our results demonstrate the ideological functioning of algorithms and have significant implications for the ethical use and development of AI. The study reinforces the need for critical, interdisciplinary approaches to AI design and deployment, addressing how LLM-generated discourses reflect and perpetuate inequalities.
éšç€äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„è¿›æ­¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¥ç›Šå—åˆ°é‡è§†å¹¶åœ¨å„ç§æƒ…å¢ƒä¸­å¾—åˆ°åº”ç”¨ã€‚éšç€å®ƒä»¬æ¼”å˜æˆæ›´å¤æ‚çš„ç‰ˆæœ¬ï¼Œè¯„ä¼°å®ƒä»¬æ˜¯å¦åœ¨ç»´æŒéœ¸æƒè¯è¯­çš„åŒæ—¶å†ç°åè§ï¼Œä¾‹å¦‚æ­§è§†å’Œç§æ—åŒ–ï¼Œå˜å¾—è‡³å…³é‡è¦ã€‚ç°æœ‰çš„åè§æ£€æµ‹æ–¹æ³•å¤§å¤šä¾èµ–å®šé‡çš„ã€è‡ªåŠ¨åŒ–çš„æ–¹æ³•ï¼Œå¾€å¾€å¿½è§†äº†åè§åœ¨è‡ªç„¶è¯­è¨€ä¸­å‡ºç°çš„ç»†å¾®æ–¹å¼ã€‚æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå®šæ€§çš„ã€è¯è¯­åˆ†ææ¡†æ¶ä»¥è¡¥å……æ­¤ç±»æ–¹æ³•ã€‚é€šè¿‡å¯¹ LLM ç”Ÿæˆçš„ä»¥é»‘äººå’Œç™½äººå¥³æ€§ä¸ºä¸»è§’çš„çŸ­ç¯‡æ•…äº‹è¿›è¡Œäººå·¥åˆ†æï¼Œæˆ‘ä»¬è€ƒå¯Ÿäº†æ€§åˆ«å’Œç§æ—åè§ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œåƒæœ¬æ–‡æ‰€æå‡ºçš„è¿™ç§å®šæ€§æ–¹æ³•å¯¹äºå¸®åŠ©å¼€å‘è€…å’Œç”¨æˆ·è¯†åˆ«åè§åœ¨ LLM è¾“å‡ºä¸­å…·ä½“å‘ˆç°çš„æ–¹å¼è‡³å…³é‡è¦ï¼Œä»è€Œä¸ºç¼“è§£è¿™äº›åè§åˆ›é€ æ›´å¥½çš„æ¡ä»¶ã€‚ç»“æœè¡¨æ˜ï¼Œé»‘äººå¥³æ€§è¢«æç»˜ä¸ºä¸ç¥–å…ˆå’ŒæŠµæŠ—ç›¸è”ç³»ï¼Œè€Œç™½äººå¥³æ€§åˆ™å‡ºç°åœ¨è‡ªæˆ‘å‘ç°çš„è¿‡ç¨‹ä¸­ã€‚ è¿™äº›æ¨¡å¼åæ˜ äº†è¯­è¨€æ¨¡å‹å¦‚ä½•å¤åˆ¶å›ºåŒ–çš„è¯è¯­è¡¨å¾ï¼Œå¼ºåŒ–æœ¬è´¨åŒ–å€¾å‘å’Œä¸€ç§ç¤¾ä¼šä¸æµåŠ¨æ„Ÿã€‚ åœ¨è¢«æç¤ºçº æ­£åè§æ—¶ï¼Œæ¨¡å‹ç»™å‡ºäº†ç»´æŒé—®é¢˜æ€§å«ä¹‰çš„è¡¨é¢ä¿®æ­£ï¼Œæš´éœ²äº†å…¶åœ¨ä¿ƒè¿›åŒ…å®¹æ€§å™äº‹æ–¹é¢çš„å±€é™æ€§ã€‚ æˆ‘ä»¬çš„ç»“æœå±•ç¤ºäº†ç®—æ³•çš„æ„è¯†å½¢æ€è¿ä½œï¼Œå¹¶å¯¹äººå·¥æ™ºèƒ½çš„ä¼¦ç†ä½¿ç”¨ä¸å¼€å‘å…·æœ‰é‡è¦å½±å“ã€‚ è¯¥ç ”ç©¶å¼ºåŒ–äº†åœ¨äººå·¥æ™ºèƒ½è®¾è®¡ä¸éƒ¨ç½²ä¸­é‡‡ç”¨æ‰¹åˆ¤æ€§ã€è·¨å­¦ç§‘æ–¹æ³•çš„å¿…è¦æ€§ï¼Œå…³æ³¨ LLM ç”Ÿæˆçš„è¯è¯­å¦‚ä½•åæ˜ å¹¶å»¶ç»­ä¸å¹³ç­‰ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 03:22:02 UTC
å‘å¸ƒï¼š2025-08-14 03:22:02 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="29-inductive-bias-extraction-and-matching-for-llm-prompts--29-å½’çº³åç½®æå–ä¸åŒ¹é…ç”¨äº-llm-æç¤º"><a href="https://arxiv.org/abs/2508.10295"target="_blank" rel="external nofollow noopener noreferrer">#29</a> <a href="https://papers.cool/arxiv/2508.10295"target="_blank" rel="external nofollow noopener noreferrer">Inductive Bias Extraction and Matching for LLM Prompts</a>  #29 å½’çº³åç½®æå–ä¸åŒ¹é…ç”¨äº LLM æç¤º</h2>
<p><strong>Authors</strong>: [Christian M. Angel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christian</a> M. Angel), [Francis Ferraro](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Francis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Francis</a> Ferraro)
ä½œè€…ï¼šChristian M. Angelï¼ŒFrancis Ferraro</p>
<p>The active research topic of prompt engineering makes it evident that LLMs are sensitive to small changes in prompt wording. A portion of this can be ascribed to the inductive bias that is present in the LLM. By using an LLM&rsquo;s output as a portion of its prompt, we can more easily create satisfactory wording for prompts. This has the effect of creating a prompt that matches the inductive bias in model. Empirically, we show that using this Inductive Bias Extraction and Matching strategy improves LLM Likert ratings used for classification by up to 19% and LLM Likert ratings used for ranking by up to 27%.
æç¤ºå·¥ç¨‹è¿™ä¸€æ´»è·ƒçš„ç ”ç©¶è¯¾é¢˜è¡¨æ˜ï¼ŒLLMs å¯¹æç¤ºæªè¾çš„ç»†å¾®å˜åŒ–å¾ˆæ•æ„Ÿã€‚å…¶ä¸­ä¸€éƒ¨åˆ†åŸå› å¯å½’å› äºå­˜åœ¨äº LLM çš„å½’çº³åå¥½ã€‚é€šè¿‡å°† LLM çš„è¾“å‡ºä½œä¸ºå…¶æç¤ºçš„ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¯ä»¥æ›´å®¹æ˜“åœ°åˆ›å»ºä»¤äººæ»¡æ„çš„æç¤ºæªè¾ã€‚è¿™ä¼šäº§ç”Ÿä¸æ¨¡å‹å½’çº³åå¥½ç›¸åŒ¹é…çš„æç¤ºã€‚å®è¯ä¸Šï¼Œæˆ‘ä»¬è¡¨æ˜ä½¿ç”¨è¿™ç§å½’çº³åå¥½æå–ä¸åŒ¹é…ç­–ç•¥å¯å°†ç”¨äºåˆ†ç±»çš„ LLM æå…‹ç‰¹è¯„åˆ†æé«˜æœ€å¤š 19%ï¼Œå°†ç”¨äºæ’åºçš„ LLM æå…‹ç‰¹è¯„åˆ†æé«˜æœ€å¤š 27%ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 02:56:00 UTC
å‘å¸ƒï¼š2025-08-14 02:56:00 UTC</p>
<h2 id="30-a-computational-approach-to-analyzing-language-change-and-variation-in-the-constructed-language-toki-pona--30-ä¸€ç§ç”¨äºåˆ†ææ„é€ è¯­è¨€-toki-pona-ä¸­è¯­è¨€å˜åŒ–ä¸å˜å¼‚çš„è®¡ç®—æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10246"target="_blank" rel="external nofollow noopener noreferrer">#30</a> <a href="https://papers.cool/arxiv/2508.10246"target="_blank" rel="external nofollow noopener noreferrer">A Computational Approach to Analyzing Language Change and Variation in the Constructed Language Toki Pona</a>  #30 ä¸€ç§ç”¨äºåˆ†ææ„é€ è¯­è¨€ Toki Pona ä¸­è¯­è¨€å˜åŒ–ä¸å˜å¼‚çš„è®¡ç®—æ–¹æ³•</h2>
<p><strong>Authors</strong>: [Daniel Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniel</a> Huang), [Hyoun-A Joo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hyoun-A"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hyoun-A</a> Joo)
ä½œè€…ï¼šDaniel Huangï¼ŒHyoun-A Joo</p>
<p>This study explores language change and variation in Toki Pona, a constructed language with approximately 120 core words. Taking a computational and corpus-based approach, the study examines features including fluid word classes and transitivity in order to examine (1) changes in preferences of content words for different syntactic positions over time and (2) variation in usage across different corpora. The results suggest that sociolinguistic factors influence Toki Pona in the same way as natural languages, and that even constructed linguistic systems naturally evolve as communities use them.
æœ¬ç ”ç©¶æ¢è®¨äº†æ„é€ è¯­è¨€æ‰˜åŸºÂ·æ³¢çº³ï¼ˆToki Ponaï¼‰ä¸­çš„è¯­è¨€å˜åŒ–ä¸å˜å¼‚ï¼Œæ‰˜åŸºÂ·æ³¢çº³æ‹¥æœ‰å¤§çº¦ 120 ä¸ªæ ¸å¿ƒè¯æ±‡ã€‚é‡‡ç”¨è®¡ç®—ä¸è¯­æ–™åº“æ–¹æ³•ï¼Œç ”ç©¶è€ƒå¯Ÿäº†åŒ…æ‹¬æµåŠ¨è¯ç±»å’ŒåŠç‰©æ€§åœ¨å†…çš„ç‰¹å¾ï¼Œä»¥åˆ†æï¼ˆ1ï¼‰å†…å®¹è¯å¯¹ä¸åŒå¥æ³•ä½ç½®åå¥½éšæ—¶é—´çš„å˜åŒ–ï¼Œä»¥åŠï¼ˆ2ï¼‰ä¸åŒè¯­æ–™åº“é—´çš„ä½¿ç”¨å·®å¼‚ã€‚ç»“æœè¡¨æ˜ï¼Œç¤¾ä¼šè¯­è¨€å­¦å› ç´ ä»¥ä¸è‡ªç„¶è¯­è¨€ç›¸åŒçš„æ–¹å¼å½±å“æ‰˜åŸºÂ·æ³¢çº³ï¼Œä¸”å³ä½¿æ˜¯æ„é€ çš„è¯­è¨€ç³»ç»Ÿä¹Ÿä¼šéšç€ç¤¾ç¾¤ä½¿ç”¨è‡ªç„¶è€Œç„¶åœ°æ¼”åŒ–ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-14 00:26:43 UTC
å‘è¡¨æ—¶é—´ï¼š2025-08-14 00:26:43 UTC</p>
<h2 id="31-using-large-language-models-to-measure-symptom-severity-in-patients-at-risk-for-schizophrenia--31-ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æœ‰ç²¾ç¥åˆ†è£‚ç—‡é£é™©æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦"><a href="https://arxiv.org/abs/2508.10226"target="_blank" rel="external nofollow noopener noreferrer">#31</a> <a href="https://papers.cool/arxiv/2508.10226"target="_blank" rel="external nofollow noopener noreferrer">Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia</a>  #31 ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æœ‰ç²¾ç¥åˆ†è£‚ç—‡é£é™©æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦</h2>
<p><strong>Authors</strong>: [Andrew X. Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> X. Chen), [Guillermo Horga](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guillermo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guillermo</a> Horga), [Sean Escola](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sean"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sean</a> Escola)
ä½œè€…ï¼šAndrew X. Chenã€Guillermo Horgaã€Sean Escola</p>
<p>Patients who are at clinical high risk (CHR) for schizophrenia need close monitoring of their symptoms to inform appropriate treatments. The Brief Psychiatric Rating Scale (BPRS) is a validated, commonly used research tool for measuring symptoms in patients with schizophrenia and other psychotic disorders; however, it is not commonly used in clinical practice as it requires a lengthy structured interview. Here, we utilize large language models (LLMs) to predict BPRS scores from clinical interview transcripts in 409 CHR patients from the Accelerating Medicines Partnership Schizophrenia (AMP-SCZ) cohort. Despite the interviews not being specifically structured to measure the BPRS, the zero-shot performance of the LLM predictions compared to the true assessment (median concordance: 0.84, ICC: 0.73) approaches human inter- and intra-rater reliability. We further demonstrate that LLMs have substantial potential to improve and standardize the assessment of CHR patients via their accuracy in assessing the BPRS in foreign languages (median concordance: 0.88, ICC: 0.70), and integrating longitudinal information in a one-shot or few-shot learning approach.
å¤„äºç²¾ç¥åˆ†è£‚ç—‡ä¸´åºŠé«˜å±ï¼ˆCHRï¼‰çŠ¶æ€çš„æ‚£è€…éœ€è¦å¯¹å…¶ç—‡çŠ¶è¿›è¡Œå¯†åˆ‡ç›‘æµ‹ä»¥ä¾¿åˆ¶å®šé€‚å½“çš„æ²»ç–—æ–¹æ¡ˆã€‚ç®€çŸ­ç²¾ç¥ç—…å­¦è¯„åˆ†é‡è¡¨ï¼ˆBPRSï¼‰æ˜¯ä¸€ç§ç»è¿‡éªŒè¯ã€å¸¸ç”¨äºç ”ç©¶çš„å·¥å…·ï¼Œç”¨äºè¡¡é‡ç²¾ç¥åˆ†è£‚ç—‡åŠå…¶ä»–ç²¾ç¥ç—…æ€§éšœç¢æ‚£è€…çš„ç—‡çŠ¶ï¼›ç„¶è€Œï¼Œç”±äºå…¶éœ€è¦è¾ƒé•¿çš„ç»“æ„åŒ–è®¿è°ˆï¼Œä¸´åºŠå®è·µä¸­å¹¶ä¸å¸¸ç”¨ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»æ¥è‡ªåŠ é€Ÿè¯ç‰©ä¼™ä¼´å…³ç³»ç²¾ç¥åˆ†è£‚ç—‡ï¼ˆAMP-SCZï¼‰é˜Ÿåˆ—çš„ 409 å CHR æ‚£è€…çš„ä¸´åºŠè®¿è°ˆè½¬å½•æ–‡æœ¬ä¸­é¢„æµ‹ BPRS è¯„åˆ†ã€‚å°½ç®¡è¿™äº›è®¿è°ˆå¹¶éä¸“é—¨ä¸ºæµ‹é‡ BPRS è€Œè®¾è®¡ï¼ŒLLM åœ¨é›¶æ ·æœ¬æƒ…å½¢ä¸‹çš„é¢„æµ‹è¡¨ç°ä¸çœŸå®è¯„ä¼°ç›¸æ¯”ï¼ˆä¸­ä½ä¸€è‡´æ€§ï¼š0.84ï¼ŒICCï¼š0.73ï¼‰å·²æ¥è¿‘äººå·¥è¯„ä¼°è€…ä¹‹é—´å’Œè‡ªèº«è¯„ä¼°çš„å¯é æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥è¯æ˜ï¼ŒLLMs åœ¨ç”¨å¤–è¯­è¯„ä¼° BPRS æ–¹é¢å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼ˆä¸­ä½ä¸€è‡´æ€§ï¼š0.88ï¼ŒICCï¼š0.70ï¼‰ï¼Œå¹¶ä¸”åœ¨é‡‡ç”¨ä¸€æ¬¡ç¤ºä¾‹æˆ–å°‘é‡ç¤ºä¾‹å­¦ä¹ æ–¹æ³•æ•´åˆçºµå‘ä¿¡æ¯æ—¶èƒ½å¤Ÿæ”¹è¿›å’Œæ ‡å‡†åŒ–å¯¹ CHR æ‚£è€…çš„è¯„ä¼°ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 22:47:01 UTC
å‘å¸ƒï¼š2025-08-13 22:47:01 UTC</p>
<h2 id="32-understanding-textual-emotion-through-emoji-prediction--32-é€šè¿‡è¡¨æƒ…ç¬¦å·é¢„æµ‹ç†è§£æ–‡æœ¬æƒ…æ„Ÿ"><a href="https://arxiv.org/abs/2508.10222"target="_blank" rel="external nofollow noopener noreferrer">#32</a> <a href="https://papers.cool/arxiv/2508.10222"target="_blank" rel="external nofollow noopener noreferrer">Understanding Textual Emotion Through Emoji Prediction</a>  #32 é€šè¿‡è¡¨æƒ…ç¬¦å·é¢„æµ‹ç†è§£æ–‡æœ¬æƒ…æ„Ÿ</h2>
<p><strong>Authors</strong>: [Ethan Gordon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ethan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ethan</a> Gordon), [Nishank Kuppa](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nishank"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nishank</a> Kuppa), [Rigved Tummala](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rigved"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rigved</a> Tummala), [Sriram Anasuri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sriram"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sriram</a> Anasuri)
ä½œè€…ï¼šEthan Gordonã€Nishank Kuppaã€Rigved Tummalaã€Sriram Anasuri</p>
<p>This project explores emoji prediction from short text sequences using four deep learning architectures: a feed-forward network, CNN, transformer, and BERT. Using the TweetEval dataset, we address class imbalance through focal loss and regularization techniques. Results show BERT achieves the highest overall performance due to its pre-training advantage, while CNN demonstrates superior efficacy on rare emoji classes. This research shows the importance of architecture selection and hyperparameter tuning for sentiment-aware emoji prediction, contributing to improved human-computer interaction.
æœ¬é¡¹ç›®ä½¿ç”¨å››ç§æ·±åº¦å­¦ä¹ æ¶æ„ï¼ˆå‰é¦ˆç½‘ç»œã€å·ç§¯ç¥ç»ç½‘ç»œã€Transformer å’Œ BERTï¼‰ä»çŸ­æ–‡æœ¬åºåˆ—ä¸­é¢„æµ‹è¡¨æƒ…ç¬¦å·ã€‚ä½¿ç”¨ TweetEval æ•°æ®é›†ï¼Œæˆ‘ä»¬é€šè¿‡ç„¦ç‚¹æŸå¤±å’Œæ­£åˆ™åŒ–æŠ€æœ¯æ¥åº”å¯¹ç±»åˆ«ä¸å¹³è¡¡ã€‚ç»“æœæ˜¾ç¤ºï¼Œç”±äºé¢„è®­ç»ƒä¼˜åŠ¿ï¼ŒBERT åœ¨æ•´ä½“æ€§èƒ½ä¸Šè¡¨ç°æœ€ä½³ï¼Œè€Œ CNN åœ¨ç¨€æœ‰è¡¨æƒ…ç¬¦å·ç±»åˆ«ä¸Šè¡¨ç°æ›´ä¸ºå‡ºè‰²ã€‚æœ¬ç ”ç©¶è¡¨æ˜ï¼Œå¯¹äºå…·æœ‰æƒ…æ„Ÿæ„è¯†çš„è¡¨æƒ…ç¬¦å·é¢„æµ‹ï¼Œæ¶æ„é€‰æ‹©å’Œè¶…å‚æ•°è°ƒä¼˜è‡³å…³é‡è¦ï¼Œæœ‰åŠ©äºæ”¹å–„äººæœºäº¤äº’ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.NE"target="_blank" rel="external nofollow noopener noreferrer">Neural and Evolutionary Computing</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€ç¥ç»ä¸è¿›åŒ–è®¡ç®—</p>
<p><strong>Publish</strong>: 2025-08-13 22:17:00 UTC
å‘è¡¨ï¼š2025-08-13 22:17:00 UTC</p>
<h2 id="33-prompt-response-semantic-divergence-metrics-for-faithfulness-hallucination-and-misalignment-detection-in-large-language-models--33-ç”¨äºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ£€æµ‹å¿ å®æ€§å¹»è§‰å’Œä¸å¯¹é½çš„æç¤º-å“åº”è¯­ä¹‰åå·®åº¦é‡-pdf--copy-kimi-1--rel"><a href="https://arxiv.org/abs/2508.10192"target="_blank" rel="external nofollow noopener noreferrer">#33</a> <a href="https://papers.cool/arxiv/2508.10192"target="_blank" rel="external nofollow noopener noreferrer">Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models</a>  #33 ç”¨äºåœ¨å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ£€æµ‹å¿ å®æ€§å¹»è§‰å’Œä¸å¯¹é½çš„æç¤º-å“åº”è¯­ä¹‰åå·®åº¦é‡ [PDF ] [Copy] [Kimi 1 ] [REL]</h2>
<p><strong>Author</strong>: [Igor Halperin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Igor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Igor</a> Halperin) ä½œè€…ï¼šIgor Halperin</p>
<p>The proliferation of Large Language Models (LLMs) is challenged by hallucinations, critical failure modes where models generate non-factual, nonsensical or unfaithful text. This paper introduces Semantic Divergence Metrics (SDM), a novel lightweight framework for detecting Faithfulness Hallucinations &ndash; events of severe deviations of LLMs responses from input contexts. We focus on a specific implementation of these LLM errors, {confabulations, defined as responses that are arbitrary and semantically misaligned with the user&rsquo;s query. Existing methods like Semantic Entropy test for arbitrariness by measuring the diversity of answers to a single, fixed prompt. Our SDM framework improves upon this by being more prompt-aware: we test for a deeper form of arbitrariness by measuring response consistency not only across multiple answers but also across multiple, semantically-equivalent paraphrases of the original prompt. Methodologically, our approach uses joint clustering on sentence embeddings to create a shared topic space for prompts and answers. A heatmap of topic co-occurances between prompts and responses can be viewed as a quantified two-dimensional visualization of the user-machine dialogue. We then compute a suite of information-theoretic metrics to measure the semantic divergence between prompts and responses. Our practical score, SH, combines the Jensen-Shannon divergence and Wasserstein distance to quantify this divergence, with a high score indicating a Faithfulness hallucination. Furthermore, we identify the KL divergence KL(Answer || Prompt) as a powerful indicator of \textbf{Semantic Exploration}, a key signal for distinguishing different generative behaviors. These metrics are further combined into the Semantic Box, a diagnostic framework for classifying LLM response types, including the dangerous, confident confabulation.
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ™®åŠé¢ä¸´å¹»è§‰é—®é¢˜çš„æŒ‘æˆ˜ï¼Œå³æ¨¡å‹ç”Ÿæˆéäº‹å®æ€§çš„ã€è’è°¬çš„æˆ–ä¸å¿ å®æ–‡æœ¬çš„ä¸¥é‡å¤±æ•ˆæ¨¡å¼ã€‚æœ¬æ–‡æå‡ºäº†è¯­ä¹‰åç¦»åº¦é‡ï¼ˆSDMï¼‰ï¼Œä¸€ç§ç”¨äºæ£€æµ‹å¿ å®æ€§å¹»è§‰çš„è½»é‡çº§æ–°æ¡†æ¶â€”â€”å³ LLMs å›å¤ä¸è¾“å…¥ä¸Šä¸‹æ–‡ä¸¥é‡åç¦»çš„äº‹ä»¶ã€‚æˆ‘ä»¬å…³æ³¨è¿™ç±» LLM é”™è¯¯çš„ä¸€ç§å…·ä½“å®ç°ï¼Œæœæ’°ï¼ˆconfabulationsï¼‰ï¼Œå®šä¹‰ä¸ºå¯¹ç”¨æˆ·æŸ¥è¯¢ä»»æ„ä¸”è¯­ä¹‰ä¸å¯¹é½çš„å›å¤ã€‚ç°æœ‰æ–¹æ³•å¦‚è¯­ä¹‰ç†µé€šè¿‡è¡¡é‡å¯¹å•ä¸€å›ºå®šæç¤ºçš„ç­”æ¡ˆå¤šæ ·æ€§æ¥æµ‹è¯•ä»»æ„æ€§ã€‚æˆ‘ä»¬çš„ SDM æ¡†æ¶åœ¨æ­¤åŸºç¡€ä¸Šæ”¹è¿›ï¼Œæ›´åŠ è€ƒè™‘æç¤ºçš„å½±å“ï¼šæˆ‘ä»¬é€šè¿‡è¡¡é‡å›å¤åœ¨å¤šä¸ªç­”æ¡ˆä¹‹é—´ï¼Œä»¥åŠåœ¨åŸå§‹æç¤ºçš„å¤šä¸ªè¯­ä¹‰ç­‰ä»·æ”¹å†™ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œæ¥æ£€æµ‹æ›´æ·±å±‚æ¬¡çš„ä»»æ„æ€§ã€‚åœ¨æ–¹æ³•ä¸Šï¼Œæˆ‘ä»¬çš„åšæ³•ä½¿ç”¨å¥å­åµŒå…¥çš„è”åˆèšç±»ï¼Œä¸ºæç¤ºå’Œç­”æ¡ˆåˆ›å»ºä¸€ä¸ªå…±äº«çš„è¯é¢˜ç©ºé—´ã€‚ æç¤ºä¸å›å¤ä¹‹é—´ä¸»é¢˜å…±ç°çš„çƒ­åŠ›å›¾å¯ä»¥è¢«è§†ä¸ºç”¨æˆ·â€”æœºå™¨å¯¹è¯çš„é‡åŒ–äºŒç»´å¯è§†åŒ–ã€‚éšåæˆ‘ä»¬è®¡ç®—äº†ä¸€ç»„ä¿¡æ¯è®ºæŒ‡æ ‡æ¥è¡¡é‡æç¤ºä¸å›å¤ä¹‹é—´çš„è¯­ä¹‰åç¦»ã€‚æˆ‘ä»¬çš„å®ç”¨å¾—åˆ†ï¼Œ SH ï¼Œç»“åˆäº† Jensenâ€“Shannon æ•£åº¦å’Œ Wasserstein è·ç¦»æ¥é‡åŒ–è¿™ç§åç¦»ï¼Œå¾—åˆ†è¶Šé«˜è¡¨ç¤ºæ˜¯ä¸€ä¸ªå¿ å®æ€§å¹»è§‰ï¼ˆFaithfulness hallucinationï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯†åˆ«å‡º KL æ•£åº¦ KL(Answer || Prompt) ä½œä¸ºä¸€ä¸ªå¼ºæœ‰åŠ›çš„â€œè¯­ä¹‰æ¢ç´¢â€ï¼ˆSemantic Explorationï¼‰æŒ‡ç¤ºå™¨ï¼Œè¿™æ˜¯åŒºåˆ†ä¸åŒç”Ÿæˆè¡Œä¸ºçš„å…³é”®ä¿¡å·ã€‚è¿™äº›æŒ‡æ ‡è¿›ä¸€æ­¥è¢«ç»„åˆæˆè¯­ä¹‰ç›’ï¼ˆSemantic Boxï¼‰ï¼Œä½œä¸ºç”¨äºå¯¹ LLM å“åº”ç±»å‹è¿›è¡Œåˆ†ç±»çš„è¯Šæ–­æ¡†æ¶ï¼ŒåŒ…æ‹¬å±é™©çš„ã€è‡ªä¿¡çš„æœæ’°ï¼ˆconfident confabulationï¼‰ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/q-fin.CP"target="_blank" rel="external nofollow noopener noreferrer">Computational Finance</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ ï¼Œè®¡ç®—é‡‘è</p>
<p><strong>Publish</strong>: 2025-08-13 20:55:26 UTC
å‘å¸ƒï¼š2025-08-13 20:55:26 UTC</p>
<h2 id="34-pakbbq-a-culturally-adapted-bias-benchmark-for-qa--34-pakbbqä¸€ä¸ªé’ˆå¯¹é—®ç­”çš„æ–‡åŒ–é€‚é…åè§åŸºå‡†"><a href="https://arxiv.org/abs/2508.10186"target="_blank" rel="external nofollow noopener noreferrer">#34</a> <a href="https://papers.cool/arxiv/2508.10186"target="_blank" rel="external nofollow noopener noreferrer">PakBBQ: A Culturally Adapted Bias Benchmark for QA</a>  #34 PakBBQï¼šä¸€ä¸ªé’ˆå¯¹é—®ç­”çš„æ–‡åŒ–é€‚é…åè§åŸºå‡†</h2>
<p><strong>Authors</strong>: [Abdullah Hashmat](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abdullah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abdullah</a> Hashmat), [Muhammad Arham Mirza](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhammad</a> Arham Mirza), [Agha Ali Raza](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Agha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Agha</a> Ali Raza)
ä½œè€…ï¼šAbdullah Hashmatã€Muhammad Arham Mirzaã€Agha Ali Raza</p>
<p>With the widespread adoption of Large Language Models (LLMs) across various applications, it is empirical to ensure their fairness across all user communities. However, most LLMs are trained and evaluated on Western centric data, with little attention paid to low-resource languages and regional contexts. To address this gap, we introduce PakBBQ, a culturally and regionally adapted extension of the original Bias Benchmark for Question Answering (BBQ) dataset. PakBBQ comprises over 214 templates, 17180 QA pairs across 8 categories in both English and Urdu, covering eight bias dimensions including age, disability, appearance, gender, socio-economic status, religious, regional affiliation, and language formality that are relevant in Pakistan. We evaluate multiple multilingual LLMs under both ambiguous and explicitly disambiguated contexts, as well as negative versus non negative question framings. Our experiments reveal (i) an average accuracy gain of 12% with disambiguation, (ii) consistently stronger counter bias behaviors in Urdu than in English, and (iii) marked framing effects that reduce stereotypical responses when questions are posed negatively. These findings highlight the importance of contextualized benchmarks and simple prompt engineering strategies for bias mitigation in low resource settings.
éšç€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§åº”ç”¨ä¸­çš„å¹¿æ³›é‡‡ç”¨ï¼Œç¡®ä¿å®ƒä»¬åœ¨æ‰€æœ‰ç”¨æˆ·ç¾¤ä½“ä¸­çš„å…¬å¹³æ€§æ˜¯ç»éªŒä¸Šå¿…è¦çš„ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•° LLMs æ˜¯åœ¨ä»¥è¥¿æ–¹ä¸ºä¸­å¿ƒçš„æ•°æ®ä¸Šè®­ç»ƒå’Œè¯„ä¼°çš„ï¼Œå¯¹èµ„æºåŒ®ä¹çš„è¯­è¨€å’ŒåŒºåŸŸè¯­å¢ƒå…³æ³¨ç”šå°‘ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº† PakBBQï¼Œè¿™æ˜¯å¯¹åŸå§‹é—®ç­”åè§åŸºå‡†æ•°æ®é›†ï¼ˆBias Benchmark for Question Answeringï¼ŒBBQï¼‰åœ¨æ–‡åŒ–å’ŒåŒºåŸŸä¸Šé€‚é…çš„æ‰©å±•ã€‚PakBBQ åŒ…å«è¶…è¿‡ 214 ä¸ªæ¨¡æ¿ã€17180 å¯¹é—®ç­”ï¼Œè¦†ç›–è‹±è¯­å’Œä¹Œå°”éƒ½è¯­çš„ 8 ä¸ªç±»åˆ«ï¼Œæ¶‰åŠä¸å·´åŸºæ–¯å¦ç›¸å…³çš„å…«ä¸ªåè§ç»´åº¦ï¼šå¹´é¾„ã€æ®‹ç–¾ã€å¤–è²Œã€æ€§åˆ«ã€ç¤¾ä¼šç»æµåœ°ä½ã€å®—æ•™ã€åœ°åŒºå½’å±å’Œè¯­è¨€ç¤¼è²Œç¨‹åº¦ã€‚æˆ‘ä»¬åœ¨å«ç³Šå’Œæ˜ç¡®æ¶ˆæ­§çš„è¯­å¢ƒä¸‹ï¼Œä»¥åŠæ¶ˆæä¸éæ¶ˆæçš„é—®é¢˜è¡¨è¿°ä¸‹ï¼Œè¯„ä¼°äº†å¤šç§å¤šè¯­ç§ LLMsã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼š(i) é€šè¿‡æ¶ˆæ­§å¹³å‡å‡†ç¡®ç‡æé«˜äº† 12%ï¼›(ii) ä¹Œå°”éƒ½è¯­åœ¨ååè§è¡Œä¸ºä¸Šå§‹ç»ˆæ¯”è‹±è¯­æ›´å¼ºï¼›(iii) é—®é¢˜ä»¥æ¶ˆææ–¹å¼æå‡ºæ—¶å­˜åœ¨æ˜¾è‘—çš„æ¡†æ¶æ•ˆåº”ï¼Œä¼šå‡å°‘åˆ»æ¿åŒ–çš„å›ç­”ã€‚ è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨èµ„æºç¨€ç¼ºç¯å¢ƒä¸­é‡‡ç”¨è¯­å¢ƒåŒ–åŸºå‡†å’Œç®€å•æç¤ºå·¥ç¨‹ç­–ç•¥æ¥å‡è½»åè§çš„é‡è¦æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">Computers and Society</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºä¸ç¤¾ä¼šã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-13 20:42:44 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-13 20:42:44 UTC</p>
<h2 id="35-efficient-forward-only-data-valuation-for-pretrained-llms-and-vlms--35-é¢å‘é¢„è®­ç»ƒ-llms-å’Œ-vlms-çš„é«˜æ•ˆä»…å‰å‘æ•°æ®ä¼°å€¼"><a href="https://arxiv.org/abs/2508.10180"target="_blank" rel="external nofollow noopener noreferrer">#35</a> <a href="https://papers.cool/arxiv/2508.10180"target="_blank" rel="external nofollow noopener noreferrer">Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs</a>  #35 é¢å‘é¢„è®­ç»ƒ LLMs å’Œ VLMs çš„é«˜æ•ˆä»…å‰å‘æ•°æ®ä¼°å€¼</h2>
<p><strong>Authors</strong>: [Wenlong Deng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenlong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenlong</a> Deng), [Jiaming Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaming</a> Zhang), [Qi Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qi</a> Zeng), [Christos Thrampoulidis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christos"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christos</a> Thrampoulidis), [Boying Gong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Boying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Boying</a> Gong), [Xiaoxiao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoxiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoxiao</a> Li)
ä½œè€…ï¼šé‚“æ–‡é¾™ï¼Œå¼ å®¶æ˜ï¼Œæ›¾ç¦ï¼ŒChristos Thrampoulidisï¼Œé¾šåšè‹±ï¼Œææ™“æ™“</p>
<p>Quantifying the influence of individual training samples is essential for enhancing the transparency and accountability of large language models (LLMs) and vision-language models (VLMs). However, existing data valuation methods often rely on Hessian information or model retraining, making them computationally prohibitive for billion-parameter models. In this work, we introduce For-Value, a forward-only data valuation framework that enables scalable and efficient influence estimation for both LLMs and VLMs. By leveraging the rich representations of modern foundation models, For-Value computes influence scores using a simple closed-form expression based solely on a single forward pass, thereby eliminating the need for costly gradient computations. Our theoretical analysis demonstrates that For-Value accurately estimates per-sample influence by capturing alignment in hidden representations and prediction errors between training and validation samples. Extensive experiments show that For-Value matches or outperforms gradient-based baselines in identifying impactful fine-tuning examples and effectively detecting mislabeled data.
é‡åŒ–å•ä¸ªè®­ç»ƒæ ·æœ¬çš„å½±å“å¯¹äºæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’Œè§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰çš„é€æ˜æ€§ä¸å¯é—®è´£æ€§è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æ•°æ®ä¼°å€¼æ–¹æ³•é€šå¸¸ä¾èµ–äºæµ·æ£®çŸ©é˜µä¿¡æ¯æˆ–æ¨¡å‹é‡è®­ç»ƒï¼Œå¯¹äº¿çº§å‚æ•°æ¨¡å‹è€Œè¨€è®¡ç®—ä»£ä»·è¿‡é«˜ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† For-Valueï¼Œä¸€ç§ä»…å‰å‘è®¡ç®—çš„æ•°æ®ä¼°å€¼æ¡†æ¶ï¼Œèƒ½å¤Ÿå¯¹ LLMs å’Œ VLMs è¿›è¡Œå¯æ‰©å±•ä¸”é«˜æ•ˆçš„å½±å“ä¼°è®¡ã€‚é€šè¿‡åˆ©ç”¨ç°ä»£åŸºç¡€æ¨¡å‹çš„ä¸°å¯Œè¡¨ç¤ºï¼ŒFor-Value ä»…åŸºäºå•æ¬¡å‰å‘ä¼ é€’ä½¿ç”¨ä¸€ä¸ªç®€å•çš„é—­å¼è¡¨è¾¾å¼æ¥è®¡ç®—å½±å“åˆ†æ•°ï¼Œä»è€Œæ— éœ€æ˜‚è´µçš„æ¢¯åº¦è®¡ç®—ã€‚æˆ‘ä»¬çš„ç†è®ºåˆ†æè¡¨æ˜ï¼ŒFor-Value é€šè¿‡æ•æ‰è®­ç»ƒæ ·æœ¬ä¸éªŒè¯æ ·æœ¬åœ¨éšè—è¡¨ç¤ºä¸Šçš„å¯¹é½ç¨‹åº¦åŠé¢„æµ‹è¯¯å·®ï¼Œèƒ½å¤Ÿå‡†ç¡®ä¼°è®¡é€æ ·æœ¬å½±å“ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒFor-Value åœ¨è¯†åˆ«å¯¹å¾®è°ƒæœ‰æ˜¾è‘—å½±å“çš„ç¤ºä¾‹å’Œæœ‰æ•ˆæ£€æµ‹é”™è¯¯æ ‡æ³¨æ•°æ®æ–¹é¢ï¼Œä¸åŸºäºæ¢¯åº¦çš„åŸºçº¿æ–¹æ³•ä¸ç›¸ä¸Šä¸‹ç”šè‡³æ›´ä¼˜ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-13 20:33:06 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-13 20:33:06 UTC</p>
<h2 id="36-estimating-machine-translation-difficulty--36-ä¼°è®¡æœºå™¨ç¿»è¯‘éš¾åº¦"><a href="https://arxiv.org/abs/2508.10175"target="_blank" rel="external nofollow noopener noreferrer">#36</a> <a href="https://papers.cool/arxiv/2508.10175"target="_blank" rel="external nofollow noopener noreferrer">Estimating Machine Translation Difficulty</a>  #36 ä¼°è®¡æœºå™¨ç¿»è¯‘éš¾åº¦</h2>
<p><strong>Authors</strong>: [Lorenzo Proietti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lorenzo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lorenzo</a> Proietti), [Stefano Perrella](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Stefano"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Stefano</a> Perrella), [VilÃ©m Zouhar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vil</a>Ã©m Zouhar), [Roberto Navigli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Roberto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Roberto</a> Navigli), [Tom Kocmi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tom"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tom</a> Kocmi)
ä½œè€…ï¼šLorenzo Proiettiã€Stefano Perrellaã€VilÃ©m Zouharã€Roberto Navigliã€Tom Kocmi</p>
<p>Machine translation quality has began achieving near-perfect translations in some setups. These high-quality outputs make it difficult to distinguish between state-of-the-art models and to identify areas for future improvement. Automatically identifying texts where machine translation systems struggle holds promise for developing more discriminative evaluations and guiding future research. We formalize the task of translation difficulty estimation, defining a text&rsquo;s difficulty based on the expected quality of its translations. We introduce a new metric to evaluate difficulty estimators and use it to assess both baselines and novel approaches. Finally, we demonstrate the practical utility of difficulty estimators by using them to construct more challenging machine translation benchmarks. Our results show that dedicated models (dubbed Sentinel-src) outperform both heuristic-based methods (e.g. word rarity or syntactic complexity) and LLM-as-a-judge approaches. We release two improved models for difficulty estimation, Sentinel-src-24 and Sentinel-src-25, which can be used to scan large collections of texts and select those most likely to challenge contemporary machine translation systems.
æœºå™¨ç¿»è¯‘è´¨é‡åœ¨æŸäº›è®¾ç½®ä¸‹å·²å¼€å§‹è¾¾åˆ°è¿‘ä¹å®Œç¾çš„ç¿»è¯‘æ°´å¹³ã€‚è¿™äº›é«˜è´¨é‡çš„è¾“å‡ºä½¿å¾—åŒºåˆ†æœ€å…ˆè¿›æ¨¡å‹å¹¶è¯†åˆ«æœªæ¥æ”¹è¿›æ–¹å‘å˜å¾—å›°éš¾ã€‚è‡ªåŠ¨è¯†åˆ«æœºå™¨ç¿»è¯‘ç³»ç»Ÿæ˜“å‡ºé”™çš„æ–‡æœ¬æœ‰æœ›ç”¨äºå¼€å‘æ›´å…·åˆ¤åˆ«åŠ›çš„è¯„ä¼°æ–¹æ³•å¹¶æŒ‡å¯¼æœªæ¥ç ”ç©¶ã€‚æˆ‘ä»¬å°†â€œç¿»è¯‘éš¾åº¦ä¼°è®¡â€ä»»åŠ¡å½¢å¼åŒ–ï¼Œå°†æ–‡æœ¬çš„éš¾åº¦å®šä¹‰ä¸ºå…¶ç¿»è¯‘è´¨é‡çš„é¢„æœŸå€¼ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç”¨äºè¯„ä¼°éš¾åº¦ä¼°è®¡å™¨çš„æ–°æŒ‡æ ‡ï¼Œå¹¶ç”¨å…¶è¯„ä¼°äº†åŸºçº¿æ–¹æ³•å’Œæ–°æ–¹æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡ä½¿ç”¨éš¾åº¦ä¼°è®¡å™¨æ„å»ºæ›´å…·æŒ‘æˆ˜æ€§çš„æœºå™¨ç¿»è¯‘åŸºå‡†ï¼Œæ¼”ç¤ºäº†å…¶å®é™…æ•ˆç”¨ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä¸“é—¨çš„æ¨¡å‹ï¼ˆç§°ä¸º Sentinel-srcï¼‰ä¼˜äºåŸºäºå¯å‘å¼çš„æ–¹æ³•ï¼ˆå¦‚è¯æ±‡ç¨€æœ‰åº¦æˆ–å¥æ³•å¤æ‚åº¦ï¼‰å’Œå°† LLM ç”¨ä½œè¯„åˆ¤è€…çš„æ–¹æ³•ã€‚ æˆ‘ä»¬å‘å¸ƒäº†ä¸¤ä¸ªç”¨äºéš¾åº¦è¯„ä¼°çš„æ”¹è¿›æ¨¡å‹ï¼ŒSentinel-src-24 å’Œ Sentinel-src-25ï¼Œå¯ç”¨äºæ‰«æå¤§è§„æ¨¡æ–‡æœ¬é›†åˆå¹¶æŒ‘é€‰å‡ºæœ€æœ‰å¯èƒ½å¯¹å½“ä»£æœºå™¨ç¿»è¯‘ç³»ç»Ÿæ„æˆæŒ‘æˆ˜çš„æ–‡æœ¬ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-13 20:22:58 UTC
å‘å¸ƒï¼š2025-08-13 20:22:58 UTC</p>
<h2 id="37-laajmeter-a-framework-for-laaj-evaluation--37-laajmeterç”¨äº-laaj-è¯„ä¼°çš„æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10161"target="_blank" rel="external nofollow noopener noreferrer">#37</a> <a href="https://papers.cool/arxiv/2508.10161"target="_blank" rel="external nofollow noopener noreferrer">LaajMeter: A Framework for LaaJ Evaluation</a>  #37 LaajMeterï¼šç”¨äº LaaJ è¯„ä¼°çš„æ¡†æ¶</h2>
<p><strong>Authors</strong>: [Gal Amram](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gal</a> Amram), [Eitan Farchi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eitan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eitan</a> Farchi), [Shmulik Froimovich](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shmulik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shmulik</a> Froimovich), [Raviv Gal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raviv"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raviv</a> Gal), [Avi Ziv](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Avi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Avi</a> Ziv)
ä½œè€…ï¼šGal Amramã€Eitan Farchiã€Shmulik Froimovichã€Raviv Galã€Avi Ziv</p>
<p>Large Language Models (LLMs) are increasingly used as evaluators in natural language processing tasks, a paradigm known as LLM-as-a-Judge (LaaJ). While effective in general domains, LaaJs pose significant challenges in domain-specific contexts, where annotated data is scarce and expert evaluation is costly. In such cases, meta-evaluation is often performed using metrics that have not been validated for the specific domain in which they are applied. As a result, it becomes difficult to determine which metrics effectively identify LaaJ quality, and further, what threshold indicates sufficient evaluator performance. In this work, we introduce LaaJMeter, a simulation-based framework for controlled meta-evaluation of LaaJs. LaaJMeter enables engineers to generate synthetic data representing virtual models and judges, allowing systematic analysis of evaluation metrics under realistic conditions. This helps practitioners validate and refine LaaJs for specific evaluation tasks: they can test whether their metrics correctly distinguish between better and worse (virtual) LaaJs, and estimate appropriate thresholds for evaluator adequacy. We demonstrate the utility of LaaJMeter in a code translation task involving a legacy programming language, showing how different metrics vary in sensitivity to evaluator quality. Our results highlight the limitations of common metrics and the importance of principled metric selection. LaaJMeter provides a scalable and extensible solution for assessing LaaJs in low-resource settings, contributing to the broader effort to ensure trustworthy and reproducible evaluation in NLP.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨ä½œè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­çš„è¯„ä¼°è€…ï¼Œè¿™ä¸€èŒƒå¼è¢«ç§°ä¸º LLM-as-a-Judgeï¼ˆLaaJï¼‰ã€‚å°½ç®¡åœ¨é€šç”¨é¢†åŸŸä¸­æ•ˆæœæ˜¾è‘—ï¼ŒLaaJ åœ¨ç‰¹å®šé¢†åŸŸæƒ…å¢ƒä¸­å´å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºå¸¦æ³¨é‡Šçš„æ•°æ®ç¨€ç¼ºä¸”ä¸“å®¶è¯„ä¼°æˆæœ¬é«˜æ˜‚ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå…ƒè¯„ä¼°é€šå¸¸ä½¿ç”¨å°šæœªåœ¨å…¶åº”ç”¨çš„ç‰¹å®šé¢†åŸŸä¸­éªŒè¯è¿‡çš„æŒ‡æ ‡æ¥è¿›è¡Œã€‚å› æ­¤ï¼Œå¾ˆéš¾åˆ¤æ–­å“ªäº›æŒ‡æ ‡èƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ« LaaJ çš„è´¨é‡ï¼Œè¿›è€Œä¹Ÿéš¾ä»¥ç¡®å®šå“ªä¸ªé˜ˆå€¼è¡¨ç¤ºè¯„ä¼°è€…æ€§èƒ½å·²è¶³å¤Ÿã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† LaaJMeterï¼Œä¸€ç§åŸºäºæ¨¡æ‹Ÿçš„å—æ§ LaaJ å…ƒè¯„ä¼°æ¡†æ¶ã€‚LaaJMeter ä½¿å·¥ç¨‹å¸ˆèƒ½å¤Ÿç”Ÿæˆä»£è¡¨è™šæ‹Ÿæ¨¡å‹å’Œè¯„åˆ¤è€…çš„åˆæˆæ•°æ®ï¼Œä»è€Œåœ¨çœŸå®æ¡ä»¶ä¸‹å¯¹è¯„ä¼°æŒ‡æ ‡è¿›è¡Œç³»ç»Ÿåˆ†æã€‚è¿™æœ‰åŠ©äºä»ä¸šè€…ä¸ºç‰¹å®šè¯„ä¼°ä»»åŠ¡éªŒè¯å’Œæ”¹è¿› LaaJï¼šä»–ä»¬å¯ä»¥æµ‹è¯•å…¶æŒ‡æ ‡æ˜¯å¦èƒ½å¤Ÿæ­£ç¡®åŒºåˆ†ä¼˜åŠ£ï¼ˆè™šæ‹Ÿï¼‰LaaJï¼Œå¹¶ä¼°è®¡è¯„ä¼°è€…å……åˆ†æ€§çš„åˆé€‚é˜ˆå€¼ã€‚ æˆ‘ä»¬å±•ç¤ºäº† LaaJMeter åœ¨æ¶‰åŠé—ç•™ç¼–ç¨‹è¯­è¨€çš„ä»£ç ç¿»è¯‘ä»»åŠ¡ä¸­çš„å®ç”¨æ€§ï¼Œè¯´æ˜äº†ä¸åŒåº¦é‡åœ¨å¯¹è¯„ä¼°è€…è´¨é‡çš„æ•æ„Ÿæ€§æ–¹é¢å­˜åœ¨å·®å¼‚ã€‚æˆ‘ä»¬çš„ç»“æœçªå‡ºäº†å¸¸ç”¨åº¦é‡çš„å±€é™æ€§ä»¥åŠæœ‰åŸåˆ™åœ°é€‰æ‹©åº¦é‡çš„é‡è¦æ€§ã€‚LaaJMeter ä¸ºåœ¨ä½èµ„æºç¯å¢ƒä¸­è¯„ä¼° LaaJ æä¾›äº†å¯æ‰©å±•ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œæœ‰åŠ©äºæ›´å¹¿æ³›åœ°ç¡®ä¿ NLP è¯„ä¼°çš„å¯ä¿¡æ€§å’Œå¯å¤ç°æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 19:51:05 UTC
å‘å¸ƒï¼š2025-08-13 19:51:05 UTC</p>
<h2 id="38-multi-turn-puzzles-evaluating-interactive-reasoning-and-strategic-dialogue-in-llms--38-å¤šå›åˆè°œé¢˜è¯„ä¼°-llms-ä¸­çš„äº¤äº’å¼æ¨ç†ä¸ç­–ç•¥æ€§å¯¹è¯"><a href="https://arxiv.org/abs/2508.10142"target="_blank" rel="external nofollow noopener noreferrer">#38</a> <a href="https://papers.cool/arxiv/2508.10142"target="_blank" rel="external nofollow noopener noreferrer">Multi-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs</a>  #38 å¤šå›åˆè°œé¢˜ï¼šè¯„ä¼° LLMs ä¸­çš„äº¤äº’å¼æ¨ç†ä¸ç­–ç•¥æ€§å¯¹è¯</h2>
<p><strong>Authors</strong>: [Kartikeya Badola](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kartikeya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kartikeya</a> Badola), [Jonathan Simon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonathan</a> Simon), [Arian Hosseini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arian</a> Hosseini), [Sara Marie Mc Carthy](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sara</a> Marie Mc Carthy), [Tsendsuren Munkhdalai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tsendsuren"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tsendsuren</a> Munkhdalai), [Abhimanyu Goyal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abhimanyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abhimanyu</a> Goyal), [TomÃ¡Å¡ KoÄiskÃ½](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tom"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tom</a>Ã¡Å¡ KoÄiskÃ½), [Shyam Upadhyay](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shyam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shyam</a> Upadhyay), [Bahare Fatemi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bahare"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bahare</a> Fatemi), [Mehran Kazemi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mehran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mehran</a> Kazemi)
ä½œè€…ï¼šKartikeya Badolaã€Jonathan Simonã€Arian Hosseiniã€Sara Marie Mc Carthyã€Tsendsuren Munkhdalaiã€Abhimanyu Goyalã€TomÃ¡Å¡ KoÄiskÃ½ã€Shyam Upadhyayã€Bahare Fatemiã€Mehran Kazemi</p>
<p>Large language models (LLMs) excel at solving problems with clear and complete statements, but often struggle with nuanced environments or interactive tasks which are common in most real-world scenarios. This highlights the critical need for developing LLMs that can effectively engage in logically consistent multi-turn dialogue, seek information and reason with incomplete data. To this end, we introduce a novel benchmark comprising a suite of multi-turn tasks each designed to test specific reasoning, interactive dialogue, and information-seeking abilities. These tasks have deterministic scoring mechanisms, thus eliminating the need for human intervention. Evaluating frontier models on our benchmark reveals significant headroom. Our analysis shows that most errors emerge from poor instruction following, reasoning failures, and poor planning. This benchmark provides valuable insights into the strengths and weaknesses of current LLMs in handling complex, interactive scenarios and offers a robust platform for future research aimed at improving these critical capabilities.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨è§£å†³é™ˆè¿°æ¸…æ™°å®Œæ•´çš„é—®é¢˜ä¸Šè¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨ç»†å¾®å¤æ‚çš„ç¯å¢ƒæˆ–äº¤äº’å¼ä»»åŠ¡ä¸­å¸¸å¸¸è¡¨ç°æ¬ ä½³ï¼Œè€Œè¿™äº›ä»»åŠ¡åœ¨å¤§å¤šæ•°ç°å®åœºæ™¯ä¸­å¾ˆå¸¸è§ã€‚è¿™çªæ˜¾äº†å¼€å‘èƒ½å¤Ÿåœ¨é€»è¾‘ä¸€è‡´çš„å¤šè½®å¯¹è¯ä¸­æœ‰æ•ˆå‚ä¸ã€åœ¨ä¿¡æ¯ä¸å®Œæ•´æ—¶å¯»æ±‚ä¿¡æ¯å¹¶è¿›è¡Œæ¨ç†çš„ LLMs çš„å…³é”®éœ€è¦ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªæ–°åŸºå‡†ï¼ŒåŒ…å«ä¸€ç»„å¤šè½®ä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½æ—¨åœ¨æµ‹è¯•ç‰¹å®šçš„æ¨ç†ã€äº¤äº’å¼å¯¹è¯å’Œä¿¡æ¯å¯»æ±‚èƒ½åŠ›ã€‚è¿™äº›ä»»åŠ¡å…·æœ‰ç¡®å®šæ€§çš„è¯„åˆ†æœºåˆ¶ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹äººå·¥å¹²é¢„çš„éœ€æ±‚ã€‚åœ¨æˆ‘ä»¬çš„åŸºå‡†ä¸Šè¯„ä¼°å‰æ²¿æ¨¡å‹æ˜¾ç¤ºå­˜åœ¨æ˜¾è‘—çš„æå‡ç©ºé—´ã€‚æˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œå¤§å¤šæ•°é”™è¯¯æºäºå¯¹æŒ‡ä»¤çš„æ‰§è¡Œä¸ä½³ã€æ¨ç†å¤±è´¥å’Œè§„åˆ’èƒ½åŠ›ä¸è¶³ã€‚è¯¥åŸºå‡†ä¸ºå½“å‰ LLMs åœ¨å¤„ç†å¤æ‚äº¤äº’åœºæ™¯æ—¶çš„ä¼˜åŠ£åŠ¿æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ï¼Œå¹¶ä¸ºæœªæ¥æ—¨åœ¨æå‡è¿™äº›å…³é”®èƒ½åŠ›çš„ç ”ç©¶æä¾›äº†ä¸€ä¸ªç¨³å¥çš„å¹³å°ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-13 19:14:45 UTC
å‘å¸ƒï¼š2025-08-13 19:14:45 UTC</p>
<h2 id="39-mscore-a-multilingual-and-scalable-benchmark-for-skill-based-commonsense-reasoning--39mscoreä¸€ä¸ª-m-å¤šè¯­ä¸”å¯æ‰©å±•çš„åŸºå‡†ç”¨äº-s-åŸºäºæŠ€èƒ½çš„-co-æ— æ„ä¹‰-re-æ¨ç†"><a href="https://arxiv.org/abs/2508.10137"target="_blank" rel="external nofollow noopener noreferrer">#39</a> <a href="https://papers.cool/arxiv/2508.10137"target="_blank" rel="external nofollow noopener noreferrer">mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning</a>  #39mSCoReï¼šä¸€ä¸ª M å¤šè¯­ä¸”å¯æ‰©å±•çš„åŸºå‡†ï¼Œç”¨äº S åŸºäºæŠ€èƒ½çš„ Co æ— æ„ä¹‰ Re æ¨ç†</h2>
<p><strong>Authors</strong>: [Nghia Trung Ngo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nghia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nghia</a> Trung Ngo), [Franck Dernoncourt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Franck"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Franck</a> Dernoncourt), [Thien Huu Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thien"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thien</a> Huu Nguyen)
ä½œè€…ï¼šNghia Trung Ngoã€Franck Dernoncourtã€Thien Huu Nguyen</p>
<p>Recent advancements in reasoning-reinforced Large Language Models (LLMs) have shown remarkable capabilities in complex reasoning tasks. However, the mechanism underlying their utilization of different human reasoning skills remains poorly investigated, especially for multilingual commonsense reasoning that involves everyday knowledge across different languages and cultures. To address this gap, we propose a \textbf{M}ultilingual and Scalable Benchmark for \textbf{S}kill-based \textbf{Co}mmonsense \textbf{Re}asoning (\textbf{mSCoRe}). Our benchmark incorporates three key components that are designed to systematically evaluate LLM&rsquo;s reasoning capabilities, including: (1) a novel taxonomy of reasoning skills that enables fine-grained analysis of models&rsquo; reasoning processes, (2) a robust data synthesis pipeline tailored specifically for commonsense reasoning evaluation, and (3) a complexity scaling framework allowing task difficulty to scale dynamically alongside future improvements in LLM abilities. Extensive experiments on eights state-of-the-art LLMs of varying sizes and training approaches demonstrate that \textbf{mSCoRe} remains significantly challenging for current models, particularly at higher complexity levels. Our results reveal the limitations of such reasoning-reinforced models when confronted with nuanced multilingual general and cultural commonsense. We further provide detailed analysis on the models&rsquo; reasoning processes, suggesting future directions for improving multilingual commonsense reasoning capabilities.
åœ¨æ¨ç†å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ–¹é¢çš„æœ€æ–°è¿›å±•å·²åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸­å±•ç¤ºå‡ºå“è¶Šèƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¦‚ä½•åˆ©ç”¨ä¸åŒçš„äººç±»æ¨ç†æŠ€èƒ½çš„æœºåˆ¶ä»ç„¶ç¼ºä¹æ·±å…¥ç ”ç©¶ï¼Œå°¤å…¶æ˜¯åœ¨æ¶‰åŠè·¨è¯­è¨€å’Œæ–‡åŒ–çš„æ—¥å¸¸çŸ¥è¯†çš„å¤šè¯­è¨€å¸¸è¯†æ¨ç†æ–¹é¢ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šè¯­è¨€ä¸”å¯æ‰©å±•çš„åŸºäºæŠ€èƒ½çš„å¸¸è¯†æ¨ç†åŸºå‡†ï¼ˆmSCoReï¼‰ã€‚æˆ‘ä»¬çš„åŸºå‡†åŒ…å«ä¸‰ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼° LLM çš„æ¨ç†èƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š (1) ä¸€ç§æ–°é¢–çš„æ¨ç†æŠ€èƒ½åˆ†ç±»æ³•ï¼Œå¯å¯¹æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹è¿›è¡Œç»†ç²’åº¦åˆ†æï¼Œ(2) ä¸€ä¸ªä¸“ä¸ºå¸¸è¯†æ¨ç†è¯„ä¼°é‡èº«æ‰“é€ çš„ç¨³å¥æ•°æ®åˆæˆç®¡é“ï¼Œå’Œ (3) ä¸€ä¸ªå¤æ‚æ€§æ‰©å±•æ¡†æ¶ï¼Œå…è®¸ä»»åŠ¡éš¾åº¦éšç€æœªæ¥ LLM èƒ½åŠ›çš„æå‡è€ŒåŠ¨æ€æ‰©å±•ã€‚ åœ¨å¯¹å…«ä¸ªä¸åŒè§„æ¨¡å’Œè®­ç»ƒæ–¹æ³•çš„æœ€å…ˆè¿› LLMs è¿›è¡Œçš„å¤§é‡å®éªŒä¸­ï¼Œç»“æœè¡¨æ˜ï¼ŒmSCoRe å¯¹å½“å‰æ¨¡å‹ä»ç„¶å…·æœ‰æ˜¾è‘—æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ›´é«˜å¤æ‚åº¦æ°´å¹³æ—¶ã€‚æˆ‘ä»¬çš„ç»“æœæ­ç¤ºäº†è¿™äº›ç»è¿‡æ¨ç†å¼ºåŒ–çš„æ¨¡å‹åœ¨é¢å¯¹ç»†å¾®çš„å¤šè¯­è¨€å¸¸è¯†ä»¥åŠæ–‡åŒ–å¸¸è¯†æ—¶çš„å±€é™æ€§ã€‚æˆ‘ä»¬è¿˜å¯¹æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹è¿›è¡Œäº†è¯¦ç»†åˆ†æï¼Œå¹¶æå‡ºäº†æ”¹è¿›å¤šè¯­è¨€å¸¸è¯†æ¨ç†èƒ½åŠ›çš„æœªæ¥æ–¹å‘ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 18:59:02 UTC
å‘å¸ƒï¼š2025-08-13 18:59:02 UTC</p>
<h2 id="40-reflect-then-learn-active-prompting-for-information-extraction-guided-by-introspective-confusion"><a href="https://arxiv.org/abs/2508.10036"target="_blank" rel="external nofollow noopener noreferrer">#40</a> <a href="https://papers.cool/arxiv/2508.10036"target="_blank" rel="external nofollow noopener noreferrer">Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion</a></h2>
<p><strong>Authors</strong>: [Dong Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Zhao), [Yadong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yadong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yadong</a> Wang), [Xiang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiang</a> Chen), [Chenxi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chenxi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chenxi</a> Wang), [Hongliang Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongliang</a> Dai), [Chuanxing Geng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chuanxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chuanxing</a> Geng), [Shengzhong Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shengzhong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shengzhong</a> Zhang), [Shaoyuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaoyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaoyuan</a> Li), [Sheng-Jun Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sheng-Jun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sheng-Jun</a> Huang)
ä½œè€…ï¼šDong Zhao, Yadong Wang, Xiang Chen, Chenxi Wang, Hongliang Dai, Chuanxing Geng, Shengzhong Zhang, Shaoyuan Li, Sheng-Jun Huang</p>
<p>Large Language Models (LLMs) show remarkable potential for few-shot information extraction (IE), yet their performance is highly sensitive to the choice of in-context examples. Conventional selection strategies often fail to provide informative guidance, as they overlook a key source of model fallibility: confusion stemming not just from semantic content, but also from the generation of well-structured formats required by IE tasks. To address this, we introduce Active Prompting for Information Extraction (APIE), a novel active prompting framework guided by a principle we term introspective confusion. Our method empowers an LLM to assess its own confusion through a dual-component uncertainty metric that uniquely quantifies both Format Uncertainty (difficulty in generating correct syntax) and Content Uncertainty (inconsistency in extracted semantics). By ranking unlabeled data with this comprehensive score, our framework actively selects the most challenging and informative samples to serve as few-shot exemplars. Extensive experiments on four benchmarks show that our approach consistently outperforms strong baselines, yielding significant improvements in both extraction accuracy and robustness. Our work highlights the critical importance of a fine-grained, dual-level view of model uncertainty when it comes to building effective and reliable structured generation systems.
å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å°‘æ ·æœ¬ä¿¡æ¯æŠ½å–ï¼ˆIEï¼‰æ–¹é¢å±•ç°å‡ºæ˜¾è‘—æ½œåŠ›ï¼Œä½†å…¶æ€§èƒ½å¯¹ä¸Šä¸‹æ–‡ç¤ºä¾‹çš„é€‰æ‹©é«˜åº¦æ•æ„Ÿã€‚ä¼ ç»Ÿçš„é€‰æ‹©ç­–ç•¥å¸¸å¸¸æ— æ³•æä¾›æœ‰ç›Šçš„æŒ‡å¯¼ï¼Œå› ä¸ºå®ƒä»¬å¿½è§†äº†æ¨¡å‹æ˜“å‡ºé”™çš„ä¸€ä¸ªå…³é”®æ¥æºï¼šå›°æƒ‘ä¸ä»…æ¥è‡ªè¯­ä¹‰å†…å®¹ï¼Œè¿˜æ¥è‡ªç”Ÿæˆä¿¡æ¯æŠ½å–ä»»åŠ¡æ‰€éœ€çš„è‰¯å¥½ç»“æ„åŒ–æ ¼å¼çš„éš¾åº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºä¿¡æ¯æŠ½å–çš„ä¸»åŠ¨æç¤ºï¼ˆActive Prompting for Information Extractionï¼ŒAPIEï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”±æˆ‘ä»¬ç§°ä¸ºå†…çœæ€§å›°æƒ‘ï¼ˆintrospective confusionï¼‰åŸåˆ™æŒ‡å¯¼çš„æ–°å‹ä¸»åŠ¨æç¤ºæ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿å¾— LLM èƒ½å¤Ÿé€šè¿‡ä¸€ä¸ªåŒæˆåˆ†ä¸ç¡®å®šæ€§åº¦é‡æ¥è¯„ä¼°è‡ªèº«çš„å›°æƒ‘ï¼Œè¯¥åº¦é‡ç‹¬ç‰¹åœ°é‡åŒ–äº†æ ¼å¼ä¸ç¡®å®šæ€§ï¼ˆåœ¨ç”Ÿæˆæ­£ç¡®è¯­æ³•æ–¹é¢çš„å›°éš¾ï¼‰å’Œå†…å®¹ä¸ç¡®å®šæ€§ï¼ˆåœ¨æå–è¯­ä¹‰æ—¶çš„ä¸ä¸€è‡´æ€§ï¼‰ã€‚é€šè¿‡ç”¨è¿™ä¸€ç»¼åˆè¯„åˆ†å¯¹æœªæ ‡æ³¨æ•°æ®è¿›è¡Œæ’åºï¼Œæˆ‘ä»¬çš„æ¡†æ¶ä¸»åŠ¨é€‰æ‹©æœ€å…·æŒ‘æˆ˜æ€§å’Œä¿¡æ¯é‡çš„æ ·æœ¬ä½œä¸ºå°‘æ ·æœ¬ç¤ºä¾‹ã€‚ åœ¨å››ä¸ªåŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æŒç»­ä¼˜äºå¼ºåŸºçº¿ï¼Œåœ¨æŠ½å–å‡†ç¡®æ€§å’Œé²æ£’æ€§æ–¹é¢éƒ½å–å¾—äº†æ˜¾è‘—æå‡ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†åœ¨æ„å»ºé«˜æ•ˆä¸”å¯é çš„ç»“æ„åŒ–ç”Ÿæˆç³»ç»Ÿæ—¶ï¼Œå¯¹æ¨¡å‹ä¸ç¡®å®šæ€§è¿›è¡Œç»†ç²’åº¦åŒå±‚è§†è§’çš„é‡è¦æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œä¿¡æ¯æ£€ç´¢ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-10 02:27:41 UTC
å‘å¸ƒï¼š2025-08-10 02:27:41 UTC</p>
<h2 id="41-the-cost-of-thinking-increased-jailbreak-risk-in-large-language-models--41-æ€è€ƒçš„ä»£ä»·å¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¢åŠ çš„è¶Šç‹±é£é™©"><a href="https://arxiv.org/abs/2508.10032"target="_blank" rel="external nofollow noopener noreferrer">#41</a> <a href="https://papers.cool/arxiv/2508.10032"target="_blank" rel="external nofollow noopener noreferrer">The Cost of Thinking: Increased Jailbreak Risk in Large Language Models</a>  #41 æ€è€ƒçš„ä»£ä»·ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ä¸­å¢åŠ çš„è¶Šç‹±é£é™©</h2>
<p><strong>Author</strong>: [Fan Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fan</a> Yang) ä½œè€…ï¼šæ¨å¸†</p>
<p>Thinking mode has always been regarded as one of the most valuable modes in LLMs. However, we uncover a surprising and previously overlooked phenomenon: LLMs with thinking mode are more easily broken by Jailbreak attack. We evaluate 9 LLMs on AdvBench and HarmBench and find that the success rate of attacking thinking mode in LLMs is almost higher than that of non-thinking mode. Through large numbers of sample studies, it is found that for educational purposes and excessively long thinking lengths are the characteristics of successfully attacked data, and LLMs also give harmful answers when they mostly know that the questions are harmful. In order to alleviate the above problems, this paper proposes a method of safe thinking intervention for LLMs, which explicitly guides the internal thinking processes of LLMs by adding &ldquo;specific thinking tokens&rdquo; of LLMs to the prompt. The results demonstrate that the safe thinking intervention can significantly reduce the attack success rate of LLMs with thinking mode.
æ€è€ƒæ¨¡å¼ä¸€ç›´è¢«è§†ä¸º LLMs ä¸­æœ€æœ‰ä»·å€¼çš„æ¨¡å¼ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªä»¤äººæƒŠè®¶ä¸”æ­¤å‰è¢«å¿½è§†çš„ç°è±¡ï¼šå…·æœ‰æ€è€ƒæ¨¡å¼çš„ LLMs æ›´å®¹æ˜“è¢«è¶Šç‹±æ”»å‡»ç ´è§£ã€‚æˆ‘ä»¬åœ¨ AdvBench å’Œ HarmBench ä¸Šè¯„ä¼°äº† 9 ç§ LLMsï¼Œå‘ç°é’ˆå¯¹ LLMs æ€è€ƒæ¨¡å¼çš„æ”»å‡»æˆåŠŸç‡å‡ ä¹é«˜äºéæ€è€ƒæ¨¡å¼ã€‚é€šè¿‡å¤§é‡æ ·æœ¬ç ”ç©¶å‘ç°ï¼Œä¸ºæ•™è‚²ç›®çš„å’Œè¿‡é•¿çš„æ€è€ƒé•¿åº¦æ˜¯è¢«æˆåŠŸæ”»å‡»æ•°æ®çš„ç‰¹å¾ï¼Œä¸”å½“ LLMs å¤§å¤šæ•°æƒ…å†µä¸‹çŸ¥é“é—®é¢˜å…·æœ‰å±å®³æ€§æ—¶ï¼Œä¹Ÿä¼šç»™å‡ºæœ‰å®³ç­”æ¡ˆã€‚ä¸ºç¼“è§£ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§ LLMs çš„å®‰å…¨æ€è€ƒå¹²é¢„æ–¹æ³•ï¼Œé€šè¿‡åœ¨æç¤ºä¸­åŠ å…¥ LLMs çš„â€œç‰¹å®šæ€è€ƒæ ‡è®°â€æ¥æ˜¾å¼å¼•å¯¼ LLMs çš„å†…éƒ¨æ€è€ƒè¿‡ç¨‹ã€‚ç»“æœè¡¨æ˜ï¼Œå®‰å…¨æ€è€ƒå¹²é¢„èƒ½å¤Ÿæ˜¾è‘—é™ä½å…·æœ‰æ€è€ƒæ¨¡å¼çš„ LLMs çš„æ”»å‡»æˆåŠŸç‡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-09 09:49:49 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-09 09:49:49 UTC</p>
<h2 id="42-inference-aware-prompt-optimization-for-aligning-black-box-large-language-models--42-é¢å‘æ¨ç†çš„æç¤ºä¼˜åŒ–ç”¨äºå¯¹é½é»‘ç®±å¤§å‹è¯­è¨€æ¨¡å‹"><a href="https://arxiv.org/abs/2508.10030"target="_blank" rel="external nofollow noopener noreferrer">#42</a> <a href="https://papers.cool/arxiv/2508.10030"target="_blank" rel="external nofollow noopener noreferrer">Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models</a>  #42 é¢å‘æ¨ç†çš„æç¤ºä¼˜åŒ–ç”¨äºå¯¹é½é»‘ç®±å¤§å‹è¯­è¨€æ¨¡å‹</h2>
<p><strong>Authors</strong>: [Saaduddin Mahmud](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Saaduddin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Saaduddin</a> Mahmud), [Mason Nakamura](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mason"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mason</a> Nakamura), [Kyle H. Wray](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyle"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyle</a> H. Wray), [Shlomo Zilberstein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shlomo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shlomo</a> Zilberstein)
ä½œè€…ï¼šSaaduddin Mahmudã€Mason Nakamuraã€Kyle H. Wrayã€Shlomo Zilberstein</p>
<p>Prompt optimization methods have demonstrated significant effectiveness in aligning black-box large language models (LLMs). In parallel, inference scaling strategies such as Best-of-N Sampling and Majority Voting have also proven to enhance alignment and performance by trading off computation. However, existing prompt optimization approaches are inference strategy agnostic; that is, they optimize prompts without regard to the inference strategy employed during deployment. This constitutes a significant methodological gap, as our empirical and theoretical analysis reveals a strong interdependence between these two paradigms. Moreover, we find that user preferences regarding trade-offs among multiple objectives and inference budgets substantially influence the choice of prompt and inference configuration. To address this gap, we introduce a unified novel framework named IAPO (Inference-Aware Prompt Optimization) that jointly optimizes the prompt and inference scale, while being aware of the inference budget and different task objectives. We then develop a fixed-budget training algorithm for IAPO, which we call PSST (Prompt Scaling via Sequential Trimming), and analyze finite-budget guarantees on error probability. Finally, we evaluate the effectiveness of PSST on six different tasks, including multi-objective text generation and reasoning, and demonstrate the critical role of incorporating inference-awareness when aligning black-box LLMs through prompt optimization.
æç¤ºä¼˜åŒ–æ–¹æ³•åœ¨è°ƒæ ¡é»‘ç®± LLMs æ–¹é¢å·²æ˜¾ç¤ºå‡ºæ˜¾è‘—æ•ˆæœã€‚ä¸æ­¤å¹¶è¡Œï¼Œè¯¸å¦‚ Best-of-N é‡‡æ ·å’Œå¤šæ•°æŠ•ç¥¨ç­‰æ¨ç†æ‰©å±•ç­–ç•¥ä¹Ÿè¢«è¯æ˜é€šè¿‡æ¶ˆè€—è®¡ç®—èµ„æºæ¥å¢å¼ºå¯¹é½æ€§å’Œæ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æç¤ºä¼˜åŒ–æ–¹æ³•å¯¹æ¨ç†ç­–ç•¥æ˜¯æ— æ„ŸçŸ¥çš„ï¼›äº¦å³ï¼Œå®ƒä»¬åœ¨ä¼˜åŒ–æç¤ºæ—¶å¹¶ä¸è€ƒè™‘éƒ¨ç½²æ—¶æ‰€é‡‡ç”¨çš„æ¨ç†ç­–ç•¥ã€‚è¿™æ„æˆäº†ä¸€ä¸ªé‡è¦çš„æ–¹æ³•å­¦ç¼ºå£ï¼Œå› ä¸ºæˆ‘ä»¬çš„å®è¯å’Œç†è®ºåˆ†ææ­ç¤ºäº†è¿™ä¸¤ç§èŒƒå¼ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„ç›¸äº’ä¾èµ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ç”¨æˆ·åœ¨å¤šä¸ªç›®æ ‡å’Œæ¨ç†é¢„ç®—ä¹‹é—´çš„æƒè¡¡åå¥½ä¼šå®è´¨æ€§åœ°å½±å“æç¤ºå’Œæ¨ç†é…ç½®çš„é€‰æ‹©ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç¼ºå£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ–°æ¡†æ¶ IAPOï¼ˆæ¨ç†æ„ŸçŸ¥æç¤ºä¼˜åŒ–ï¼‰ï¼Œè¯¥æ¡†æ¶åœ¨è€ƒè™‘æ¨ç†é¢„ç®—å’Œä¸åŒä»»åŠ¡ç›®æ ‡çš„åŒæ—¶ï¼Œè”åˆä¼˜åŒ–æç¤ºå’Œæ¨ç†è§„æ¨¡ã€‚ ç„¶åæˆ‘ä»¬ä¸º IAPO å¼€å‘äº†ä¸€ç§å›ºå®šé¢„ç®—çš„è®­ç»ƒç®—æ³•ï¼Œç§°ä¸º PSSTï¼ˆé€šè¿‡é¡ºåºå‰ªè£è¿›è¡Œæç¤ºç¼©æ”¾ï¼‰ï¼Œå¹¶åˆ†æäº†åœ¨æœ‰é™é¢„ç®—ä¸‹å…³äºé”™è¯¯æ¦‚ç‡çš„ä¿è¯ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨å…­ä¸ªä¸åŒä»»åŠ¡ä¸Šè¯„ä¼°äº† PSST çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬å¤šç›®æ ‡æ–‡æœ¬ç”Ÿæˆä¸æ¨ç†ï¼Œå¹¶è¯æ˜åœ¨é€šè¿‡æç¤ºä¼˜åŒ–å¯¹é»‘ç®± LLMs è¿›è¡Œå¯¹é½æ—¶ï¼Œçº³å…¥æ¨ç†æ„ŸçŸ¥ï¼ˆinference-awarenessï¼‰æ‰€æ‰®æ¼”çš„å…³é”®è§’è‰²ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-08 18:45:53 UTC
å‘å¸ƒï¼š2025-08-08 18:45:53 UTC</p>
<h2 id="43-latent-fusion-jailbreak-blending-harmful-and-harmless-representations-to-elicit-unsafe-llm-outputs--43-æ½œåœ¨èåˆè¶Šç‹±æ··åˆæœ‰å®³ä¸æ— å®³è¡¨ç¤ºä»¥è¯±å‘ä¸å®‰å…¨çš„-llm-è¾“å‡º"><a href="https://arxiv.org/abs/2508.10029"target="_blank" rel="external nofollow noopener noreferrer">#43</a> <a href="https://papers.cool/arxiv/2508.10029"target="_blank" rel="external nofollow noopener noreferrer">Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs</a>  #43 æ½œåœ¨èåˆè¶Šç‹±ï¼šæ··åˆæœ‰å®³ä¸æ— å®³è¡¨ç¤ºä»¥è¯±å‘ä¸å®‰å…¨çš„ LLM è¾“å‡º</h2>
<p><strong>Authors</strong>: [Wenpeng Xing](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenpeng</a> Xing), [Mohan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohan</a> Li), [Chunqiang Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chunqiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chunqiang</a> Hu), [Haitao XuNingyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haitao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haitao</a> XuNingyu Zhang), [Bo Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Lin), [Meng Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meng</a> Han)
ä½œè€…ï¼šé‚¢æ–‡é¹ï¼Œæè«æ¶µï¼Œèƒ¡æ˜¥å¼ºï¼Œå¾æµ·æ¶›ï¼Œå¼ å®ç‰ï¼Œæ—åšï¼ŒéŸ©è’™</p>
<p>Large language models (LLMs) demonstrate impressive capabilities in various language tasks but are susceptible to jailbreak attacks that circumvent their safety alignments. This paper introduces Latent Fusion Jailbreak (LFJ), a representation-based attack that interpolates hidden states from harmful and benign query pairs to elicit prohibited responses. LFJ begins by selecting query pairs with high thematic and syntactic similarity, then performs gradient-guided interpolation at influential layers and tokens, followed by optimization to balance attack success, output fluency, and computational efficiency. Evaluations on models such as Vicuna and LLaMA-2 across benchmarks like AdvBench and MaliciousInstruct yield an average attack success rate (ASR) of 94.01%, outperforming existing methods. To mitigate LFJ, we propose an adversarial training defense that fine-tunes models on interpolated examples, reducing ASR by over 80% without degrading performance on benign inputs. Ablation studies validate the importance of query pair selection, hidden state interpolation components, and optimization strategies in LFJ&rsquo;s effectiveness.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§è¯­è¨€ä»»åŠ¡ä¸­å±•ç°å‡ºä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œä½†å®¹æ˜“å—åˆ°ç»•è¿‡å…¶å®‰å…¨å¯¹é½çš„è¶Šç‹±æ”»å‡»ã€‚æœ¬æ–‡æå‡ºäº†æ½œè¡¨ç¤ºèåˆè¶Šç‹±ï¼ˆLatent Fusion Jailbreakï¼ŒLFJï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºè¡¨ç¤ºçš„æ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡å¯¹æœ‰å®³ä¸æ— å®³æŸ¥è¯¢å¯¹çš„éšè—çŠ¶æ€è¿›è¡Œæ’å€¼æ¥å¼•å¯¼æ¨¡å‹ç”Ÿæˆè¢«ç¦æ­¢çš„å“åº”ã€‚LFJ é¦–å…ˆé€‰æ‹©ä¸»é¢˜å’Œå¥æ³•é«˜åº¦ç›¸ä¼¼çš„æŸ¥è¯¢å¯¹ï¼Œç„¶ååœ¨å…·æœ‰å½±å“åŠ›çš„å±‚å’Œæ ‡è®°ä¸Šè¿›è¡Œæ¢¯åº¦å¼•å¯¼çš„æ’å€¼ï¼Œéšåè¿›è¡Œä¼˜åŒ–ä»¥åœ¨æ”»å‡»æˆåŠŸç‡ã€è¾“å‡ºæµç•…æ€§å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚å¯¹ Vicunaã€LLaMA-2 ç­‰æ¨¡å‹åœ¨ AdvBenchã€MaliciousInstruct ç­‰åŸºå‡†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œå¹³å‡æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰ä¸º 94.01%ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¸ºç¼“è§£ LFJï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯¹æŠ—è®­ç»ƒé˜²å¾¡ï¼Œé€šè¿‡åœ¨æ’å€¼ç¤ºä¾‹ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œå°† ASR é™ä½è¶…è¿‡ 80%ï¼Œä¸”ä¸ä¼šé™ä½å¯¹æ— å®³è¾“å…¥çš„æ€§èƒ½ã€‚æ¶ˆèç ”ç©¶éªŒè¯äº†æŸ¥è¯¢å¯¹é€‰æ‹©ã€éšè—çŠ¶æ€æ’å€¼ç»„æˆéƒ¨åˆ†ä»¥åŠä¼˜åŒ–ç­–ç•¥åœ¨ LFJ æ•ˆæœä¸­çš„é‡è¦æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€å¯†ç å­¦ä¸å®‰å…¨</p>
<p><strong>Publish</strong>: 2025-08-08 17:29:16 UTC
å‘å¸ƒï¼š2025-08-08 17:29:16 UTC</p>
<h2 id="44-pref-reference-free-evaluation-of-personalised-text-generation-in-llms--44-é¦–é€‰é¡¹åœ¨-llms-ä¸­å¯¹ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆçš„æ— å‚è€ƒè¯„ä¼°"><a href="https://arxiv.org/abs/2508.10028"target="_blank" rel="external nofollow noopener noreferrer">#44</a> <a href="https://papers.cool/arxiv/2508.10028"target="_blank" rel="external nofollow noopener noreferrer">PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs</a>  #44 é¦–é€‰é¡¹ï¼šåœ¨ LLMs ä¸­å¯¹ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆçš„æ— å‚è€ƒè¯„ä¼°</h2>
<p><strong>Authors</strong>: [Xiao Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiao</a> Fu), [Hossein A. Rahmani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hossein</a> A. Rahmani), [Bin Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bin</a> Wu), [Jerome Ramos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jerome"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jerome</a> Ramos), [Emine Yilmaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emine</a> Yilmaz), [Aldo Lipani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aldo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aldo</a> Lipani)
ä½œè€…ï¼šXiao Fuã€Hossein A. Rahmaniã€Bin Wuã€Jerome Ramosã€Emine Yilmazã€Aldo Lipani</p>
<p>Personalised text generation is essential for user-centric information systems, yet most evaluation methods overlook the individuality of users. We introduce \textbf{PREF}, a \textbf{P}ersonalised \textbf{R}eference-free \textbf{E}valuation \textbf{F}ramework that jointly measures general output quality and user-specific alignment without requiring gold personalised references. PREF operates in a three-step pipeline: (1) a coverage stage uses a large language model (LLM) to generate a comprehensive, query-specific guideline covering universal criteria such as factuality, coherence, and completeness; (2) a preference stage re-ranks and selectively augments these factors using the target user&rsquo;s profile, stated or inferred preferences, and context, producing a personalised evaluation rubric; and (3) a scoring stage applies an LLM judge to rate candidate answers against this rubric, ensuring baseline adequacy while capturing subjective priorities. This separation of coverage from preference improves robustness, transparency, and reusability, and allows smaller models to approximate the personalised quality of larger ones. Experiments on the PrefEval benchmark, including implicit preference-following tasks, show that PREF achieves higher accuracy, better calibration, and closer alignment with human judgments than strong baselines. By enabling scalable, interpretable, and user-aligned evaluation, PREF lays the groundwork for more reliable assessment and development of personalised language generation systems.
ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆå¯¹äºä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„ä¿¡æ¯ç³»ç»Ÿè‡³å…³é‡è¦ï¼Œä½†å¤§å¤šæ•°è¯„ä¼°æ–¹æ³•å¿½è§†äº†ç”¨æˆ·çš„ä¸ªæ€§å·®å¼‚ã€‚æˆ‘ä»¬æå‡ºäº† PREFï¼Œä¸€ä¸ªä¸ªæ€§åŒ–çš„æ— å‚è€ƒè¯„ä¼°æ¡†æ¶ï¼ˆPREF: Personalised Reference-free Evaluation Frameworkï¼‰ï¼Œå®ƒåœ¨ä¸éœ€è¦é‡‘æ ‡å‡†ä¸ªæ€§åŒ–å‚è€ƒçš„æƒ…å†µä¸‹ï¼Œè”åˆè¡¡é‡ç”Ÿæˆè¾“å‡ºçš„ä¸€èˆ¬è´¨é‡ä¸ç”¨æˆ·ç‰¹å®šçš„ä¸€è‡´æ€§ã€‚PREF åœ¨ä¸‰æ­¥ç®¡é“ä¸­è¿è¡Œï¼š(1) è¦†ç›–é˜¶æ®µä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹(LLM)ç”Ÿæˆä¸€ä»½å…¨é¢çš„ã€é’ˆå¯¹æŸ¥è¯¢çš„æŒ‡å—ï¼Œæ¶µç›–äº‹å®æ€§ã€è¿è´¯æ€§å’Œå®Œæ•´æ€§ç­‰é€šç”¨æ ‡å‡†ï¼›(2) åå¥½é˜¶æ®µä½¿ç”¨ç›®æ ‡ç”¨æˆ·çš„æ¡£æ¡ˆã€é™ˆè¿°æˆ–æ¨æ–­å‡ºçš„åå¥½ä»¥åŠä¸Šä¸‹æ–‡ï¼Œå¯¹è¿™äº›å› ç´ è¿›è¡Œé‡æ–°æ’åºå¹¶æœ‰é€‰æ‹©åœ°æ‰©å±•ï¼Œç”Ÿæˆä¸ªæ€§åŒ–çš„è¯„ä¼°é‡è¡¨ï¼›(3) è¯„åˆ†é˜¶æ®µåˆ™ç”± LLM è¯„åˆ¤å™¨æ ¹æ®è¯¥é‡è¡¨å¯¹å€™é€‰ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ï¼Œæ—¢ä¿è¯åŸºæœ¬å……åˆ†æ€§ï¼Œåˆæ•æ‰ä¸»è§‚ä¼˜å…ˆçº§ã€‚å°†è¦†ç›–ä¸åå¥½åˆ†ç¦»æé«˜äº†ç¨³å¥æ€§ã€é€æ˜æ€§å’Œå¯é‡ç”¨æ€§ï¼Œå¹¶å…è®¸è¾ƒå°çš„æ¨¡å‹é€¼è¿‘è¾ƒå¤§æ¨¡å‹çš„ä¸ªæ€§åŒ–è´¨é‡ã€‚ åœ¨ PrefEval åŸºå‡†ä¸Šçš„å®éªŒï¼ŒåŒ…æ‹¬éšæ€§åå¥½è·Ÿéšä»»åŠ¡ï¼Œè¡¨æ˜ PREF åœ¨å‡†ç¡®ç‡ã€æ›´å¥½çš„æ ¡å‡†æ€§ä»¥åŠä¸äººç±»åˆ¤æ–­çš„æ›´é«˜ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºå¼ºåŸºçº¿ã€‚é€šè¿‡å®ç°å¯æ‰©å±•ã€å¯è§£é‡Šä¸”ä¸ç”¨æˆ·å¯¹é½çš„è¯„ä¼°ï¼ŒPREF ä¸ºæ›´å¯é åœ°è¯„ä¼°å’Œå¼€å‘ä¸ªæ€§åŒ–è¯­è¨€ç”Ÿæˆç³»ç»Ÿå¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€äººæœºäº¤äº’ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-08 14:32:31 UTC
å‘å¸ƒï¼š2025-08-08 14:32:31 UTC</p>
<h2 id="45-llmcare-alzheimer39s-detection-via-transformer-models-enhanced-by-llm-generated-synthetic-data--45-llmcareé€šè¿‡ç”±-llm-ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºçš„-transformer-æ¨¡å‹è¿›è¡Œé˜¿å°”èŒ¨æµ·é»˜ç—‡æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10027"target="_blank" rel="external nofollow noopener noreferrer">#45</a> <a href="https://papers.cool/arxiv/2508.10027"target="_blank" rel="external nofollow noopener noreferrer">LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data</a>  #45 LLMCAREï¼šé€šè¿‡ç”± LLM ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºçš„ Transformer æ¨¡å‹è¿›è¡Œé˜¿å°”èŒ¨æµ·é»˜ç—‡æ£€æµ‹</h2>
<p><strong>Authors</strong>: [Ali Zolnour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ali</a> Zolnour), [Hossein Azadmaleki](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hossein</a> Azadmaleki), [Yasaman Haghbin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yasaman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yasaman</a> Haghbin), [Fatemeh Taherinezhad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fatemeh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fatemeh</a> Taherinezhad), [Mohamad Javad Momeni Nezhad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohamad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohamad</a> Javad Momeni Nezhad), [Sina Rashidi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sina</a> Rashidi), [Masoud Khani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Masoud"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Masoud</a> Khani), [AmirSajjad Taleban](<a href="https://arxiv.org/search/?searchtype=author&amp;query=AmirSajjad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=AmirSajjad</a> Taleban), [Samin Mahdizadeh Sani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Samin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Samin</a> Mahdizadeh Sani), [Maryam Dadkhah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maryam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maryam</a> Dadkhah), [James M. Noble](<a href="https://arxiv.org/search/?searchtype=author&amp;query=James"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=James</a> M. Noble), [Suzanne Bakken](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Suzanne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Suzanne</a> Bakken), [Yadollah Yaghoobzadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yadollah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yadollah</a> Yaghoobzadeh), [Abdol-Hossein Vahabie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abdol-Hossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abdol-Hossein</a> Vahabie), [Masoud Rouhizadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Masoud"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Masoud</a> Rouhizadeh), [Maryam Zolnoori](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maryam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maryam</a> Zolnoori)
ä½œè€…ï¼šAli Zolnourã€Hossein Azadmalekiã€Yasaman Haghbinã€Fatemeh Taherinezhadã€Mohamad Javad Momeni Nezhadã€Sina Rashidiã€Masoud Khaniã€AmirSajjad Talebanã€Samin Mahdizadeh Saniã€Maryam Dadkhahã€James M. Nobleã€Suzanne Bakkenã€Yadollah Yaghoobzadehã€Abdol-Hossein Vahabieã€Masoud Rouhizadehã€Maryam Zolnoori</p>
<p>Alzheimer&rsquo;s disease and related dementias (ADRD) affect approximately five million older adults in the U.S., yet over half remain undiagnosed. Speech-based natural language processing (NLP) offers a promising, scalable approach to detect early cognitive decline through linguistic markers. To develop and evaluate a screening pipeline that (i) fuses transformer embeddings with handcrafted linguistic features, (ii) tests data augmentation using synthetic speech generated by large language models (LLMs), and (iii) benchmarks unimodal and multimodal LLM classifiers for ADRD detection. Transcripts from the DementiaBank &ldquo;cookie-theft&rdquo; task (n = 237) were used. Ten transformer models were evaluated under three fine-tuning strategies. A fusion model combined embeddings from the top-performing transformer with 110 lexical-derived linguistic features. Five LLMs (LLaMA-8B/70B, MedAlpaca-7B, Ministral-8B, GPT-4o) were fine-tuned to generate label-conditioned synthetic speech, which was used to augment training data. Three multimodal models (GPT-4o, Qwen-Omni, Phi-4) were tested for speech-text classification in zero-shot and fine-tuned settings. The fusion model achieved F1 = 83.3 (AUC = 89.5), outperforming linguistic or transformer-only baselines. Augmenting training data with 2x MedAlpaca-7B synthetic speech increased F1 to 85.7. Fine-tuning significantly improved unimodal LLM classifiers (e.g., MedAlpaca: F1 = 47.3 -&gt; 78.5 F1). Current multimodal models demonstrated lower performance (GPT-4o = 70.2 F1; Qwen = 66.0). Performance gains aligned with the distributional similarity between synthetic and real speech. Integrating transformer embeddings with linguistic features enhances ADRD detection from speech. Clinically tuned LLMs effectively support both classification and data augmentation, while further advancement is needed in multimodal modeling.
é˜¿å°”èŒ¨æµ·é»˜ç—…åŠç›¸å…³ç—´å‘†ï¼ˆADRDï¼‰å½±å“å¤§çº¦äº”ç™¾ä¸‡ç¾å›½è€å¹´äººï¼Œä½†è¶…è¿‡ä¸€åŠæœªè¢«è¯Šæ–­ã€‚åŸºäºè¯­éŸ³çš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é€šè¿‡è¯­è¨€å­¦æ ‡å¿—æä¾›äº†ä¸€ç§æœ‰å‰æ™¯ä¸”å¯æ‰©å±•çš„æ–¹æ³•æ¥æ£€æµ‹æ—©æœŸè®¤çŸ¥è¡°é€€ã€‚ä¸ºæ­¤æˆ‘ä»¬å¼€å‘å¹¶è¯„ä¼°äº†ä¸€ä¸ªç­›æŸ¥æµç¨‹ï¼Œå…¶ç›®æ ‡ä¸ºï¼š(i) å°† transformer åµŒå…¥ä¸æ‰‹å·¥è®¾è®¡çš„è¯­è¨€ç‰¹å¾èåˆï¼Œ(ii) æµ‹è¯•ä½¿ç”¨ç”±å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçš„åˆæˆè¯­éŸ³è¿›è¡Œæ•°æ®å¢å¼ºï¼Œ(iii) å¯¹ç”¨äº ADRD æ£€æµ‹çš„å•æ¨¡æ€å’Œå¤šæ¨¡æ€ LLM åˆ†ç±»å™¨è¿›è¡ŒåŸºå‡†æ¯”è¾ƒã€‚ä½¿ç”¨äº† DementiaBank â€œå·é¥¼â€ä»»åŠ¡çš„è½¬å½•æ–‡æœ¬ï¼ˆn = 237ï¼‰ã€‚åœ¨ä¸‰ç§å¾®è°ƒç­–ç•¥ä¸‹è¯„ä¼°äº†åä¸ª transformer æ¨¡å‹ã€‚ä¸€ä¸ªèåˆæ¨¡å‹å°†è¡¨ç°æœ€ä½³çš„ transformer çš„åµŒå…¥ä¸ 110 ä¸ªè¯æ±‡æ´¾ç”Ÿçš„è¯­è¨€ç‰¹å¾ç»“åˆã€‚äº”ä¸ª LLMï¼ˆLLaMA-8B/70Bã€MedAlpaca-7Bã€Ministral-8Bã€GPT-4oï¼‰è¢«å¾®è°ƒç”¨äºç”Ÿæˆæ¡ä»¶åŒ–æ ‡ç­¾çš„åˆæˆè¯­éŸ³ï¼Œå¹¶ç”¨äºå¢å¼ºè®­ç»ƒæ•°æ®ã€‚ä¸‰ç§å¤šæ¨¡æ€æ¨¡å‹ï¼ˆGPT-4oã€Qwen-Omniã€Phi-4ï¼‰åœ¨é›¶æ ·æœ¬å’Œå¾®è°ƒè®¾ç½®ä¸‹ç”¨äºè¯­éŸ³-æ–‡æœ¬åˆ†ç±»æµ‹è¯•ã€‚ èåˆæ¨¡å‹å–å¾— F1 = 83.3ï¼ˆAUC = 89.5ï¼‰ï¼Œä¼˜äºä»…ä½¿ç”¨è¯­è¨€å­¦æˆ–ä»…ä½¿ç”¨ transformer çš„åŸºçº¿ã€‚ç”¨ 2 å€é‡çš„ MedAlpaca-7B åˆæˆè¯­éŸ³æ‰©å……è®­ç»ƒæ•°æ®ä½¿ F1 æå‡åˆ° 85.7ã€‚å¾®è°ƒæ˜¾è‘—æ”¹å–„äº†å•æ¨¡æ€ LLM åˆ†ç±»å™¨ï¼ˆä¾‹å¦‚ï¼ŒMedAlpacaï¼šF1 = 47.3 -&gt; 78.5 F1ï¼‰ã€‚å½“å‰çš„å¤šæ¨¡æ€æ¨¡å‹è¡¨ç°è¾ƒä½ï¼ˆGPT-4o = 70.2 F1ï¼›Qwen = 66.0ï¼‰ã€‚æ€§èƒ½æå‡ä¸åˆæˆè¯­éŸ³å’ŒçœŸå®è¯­éŸ³ä¹‹é—´çš„åˆ†å¸ƒç›¸ä¼¼æ€§ä¸€è‡´ã€‚å°† transformer åµŒå…¥ä¸è¯­è¨€å­¦ç‰¹å¾ç»“åˆèƒ½å¤Ÿå¢å¼ºåŸºäºè¯­éŸ³çš„ ADRD æ£€æµ‹ã€‚ç»è¿‡ä¸´åºŠè°ƒæ•´çš„ LLM æœ‰æ•ˆæ”¯æŒåˆ†ç±»å’Œæ•°æ®å¢å¼ºï¼Œè€Œå¤šæ¨¡æ€å»ºæ¨¡ä»éœ€è¿›ä¸€æ­¥æ”¹è¿›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-08 13:44:55 UTC
å‘å¸ƒï¼š2025-08-08 13:44:55 UTC</p>
<h2 id="46-saber-switchable-and-balanced-training-for-efficient-llm-reasoning--46-saber-å¯åˆ‡æ¢ä¸å¹³è¡¡è®­ç»ƒä»¥å®ç°é«˜æ•ˆ-llm-æ¨ç†-pdf-5--copy-kimi-2--rel"><a href="https://arxiv.org/abs/2508.10026"target="_blank" rel="external nofollow noopener noreferrer">#46</a> <a href="https://papers.cool/arxiv/2508.10026"target="_blank" rel="external nofollow noopener noreferrer">SABER: Switchable and Balanced Training for Efficient LLM Reasoning</a>  #46 SABER: å¯åˆ‡æ¢ä¸å¹³è¡¡è®­ç»ƒä»¥å®ç°é«˜æ•ˆ LLM æ¨ç† [PDF 5 ] [Copy] [Kimi 2 ] [REL]</h2>
<p><strong>Authors</strong>: [Kai Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Zhao), [Yanjun Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanjun</a> Zhao), [Jiaming Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaming</a> Song), [Shien He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shien"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shien</a> He), [Lusheng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lusheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lusheng</a> Zhang), [Qiang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiang</a> Zhang), [Tianjiao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianjiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianjiao</a> Li)
ä½œè€…ï¼šKai Zhao, Yanjun Zhao, Jiaming Song, Shien He, Lusheng Zhang, Qiang Zhang, Tianjiao Li</p>
<p>Large language models (LLMs) empowered by chain-of-thought reasoning have achieved impressive accuracy on complex tasks but suffer from excessive inference costs and latency when applied uniformly to all problems. We propose SABER (Switchable and Balanced Training for Efficient LLM Reasoning), a reinforcement learning framework that endows LLMs with user-controllable, token-budgeted reasoning. SABER first profiles each training example&rsquo;s base-model thinking token usage and assigns it to one of the predefined budget tiers. During fine-tuning, the model is guided by system prompts and length-aware rewards to respect its assigned budget. In parallel, we incorporate no-think examples to ensure the model remains reliable even when explicit reasoning is turned off. SABER further supports four discrete inference modes - NoThink, FastThink, CoreThink, and DeepThink, enabling flexible trade-offs between latency and reasoning depth. Extensive evaluations on math reasoning (MATH, GSM8K), code generation (MBPP), and logical reasoning (LiveBench-Reasoning) demonstrate that SABER achieves high accuracy under tight budgets, graceful degradation, and effective cross-scale and cross-domain generalization. In particular, SABER-FastThink cuts reasoning length by 65.4% and yields a 3.6% accuracy gain compared with the base model on the MATH benchmark.
ç”±é“¾è·¯å¼æ€ç»´ï¼ˆchain-of-thoughtï¼‰æ¨ç†å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸Šå–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„å‡†ç¡®æ€§ï¼Œä½†åœ¨å¯¹æ‰€æœ‰é—®é¢˜ä¸€è§†åŒä»åœ°åº”ç”¨æ—¶ä¼šé­é‡è¿‡é«˜çš„æ¨ç†æˆæœ¬å’Œå»¶è¿Ÿã€‚æˆ‘ä»¬æå‡ºäº† SABERï¼ˆå¯åˆ‡æ¢ä¸å¹³è¡¡è®­ç»ƒä»¥å®ç°é«˜æ•ˆ LLM æ¨ç†ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å¼ºåŒ–å­¦ä¹ èµ‹äºˆ LLMs å¯ç”±ç”¨æˆ·æ§åˆ¶ã€æŒ‰ä»¤ç‰Œé¢„ç®—è¿›è¡Œæ¨ç†çš„æ¡†æ¶ã€‚SABER é¦–å…ˆåˆ†ææ¯ä¸ªè®­ç»ƒç¤ºä¾‹åœ¨åŸºç¡€æ¨¡å‹ä¸‹çš„æ€è€ƒä»¤ç‰Œä½¿ç”¨æƒ…å†µï¼Œå¹¶å°†å…¶åˆ†é…åˆ°é¢„å®šä¹‰çš„é¢„ç®—å±‚çº§ä¹‹ä¸€ã€‚åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹é€šè¿‡ç³»ç»Ÿæç¤ºå’Œè€ƒè™‘é•¿åº¦çš„å¥–åŠ±æ¥éµå®ˆå…¶åˆ†é…çš„é¢„ç®—ã€‚ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬å¹¶å…¥äº†æ— æ€è€ƒç¤ºä¾‹ï¼Œä»¥ç¡®ä¿å³ä½¿åœ¨å…³é—­æ˜¾å¼æ¨ç†æ—¶æ¨¡å‹ä»ç„¶å¯é ã€‚SABER è¿›ä¸€æ­¥æ”¯æŒå››ç§ç¦»æ•£çš„æ¨ç†æ¨¡å¼â€”â€”NoThinkã€FastThinkã€CoreThink å’Œ DeepThinkï¼Œä»è€Œåœ¨å»¶è¿Ÿä¸æ¨ç†æ·±åº¦ä¹‹é—´å®ç°çµæ´»çš„æƒè¡¡ã€‚ åœ¨æ•°å­¦æ¨ç†ï¼ˆMATHã€GSM8Kï¼‰ã€ä»£ç ç”Ÿæˆï¼ˆMBPPï¼‰å’Œé€»è¾‘æ¨ç†ï¼ˆLiveBench-Reasoningï¼‰ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼ŒSABER åœ¨ä¸¥æ ¼çš„é¢„ç®—ä¸‹èƒ½è¾¾åˆ°é«˜å‡†ç¡®ç‡ï¼Œé€€åŒ–å¹³ç¼“ï¼Œå¹¶å…·æœ‰æœ‰æ•ˆçš„è·¨å°ºåº¦å’Œè·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ã€‚å°¤å…¶æ˜¯ï¼Œåœ¨ MATH åŸºå‡†ä¸Šï¼ŒSABER-FastThink å°†æ¨ç†é•¿åº¦å‡å°‘äº† 65.4%ï¼Œå¹¶ç›¸æ¯”åŸºç¡€æ¨¡å‹å¸¦æ¥äº† 3.6% çš„å‡†ç¡®ç‡æå‡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-08 11:27:48 UTC
å‘å¸ƒï¼š2025-08-08 11:27:48 UTC</p>
<h2 id="47-detecting-and-explaining-postpartum-depression-in-real-time-with-generative-artificial-intelligence--47-ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®æ—¶æ£€æµ‹å¹¶è§£é‡Šäº§åæŠ‘éƒç—‡"><a href="https://arxiv.org/abs/2508.10025"target="_blank" rel="external nofollow noopener noreferrer">#47</a> <a href="https://papers.cool/arxiv/2508.10025"target="_blank" rel="external nofollow noopener noreferrer">Detecting and explaining postpartum depression in real-time with generative artificial intelligence</a>  #47 ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®æ—¶æ£€æµ‹å¹¶è§£é‡Šäº§åæŠ‘éƒç—‡</h2>
<p><strong>Authors</strong>: [Silvia GarcÃ­a-MÃ©ndez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silvia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silvia</a> GarcÃ­a-MÃ©ndez), [Francisco de Arriba-PÃ©rez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Francisco"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Francisco</a> de Arriba-PÃ©rez)</p>
<p>Among the many challenges mothers undergo after childbirth, postpartum depression (PPD) is a severe condition that significantly impacts their mental and physical well-being. Consequently, the rapid detection of ppd and their associated risk factors is critical for in-time assessment and intervention through specialized prevention procedures. Accordingly, this work addresses the need to help practitioners make decisions with the latest technological advancements to enable real-time screening and treatment recommendations. Mainly, our work contributes to an intelligent PPD screening system that combines Natural Language Processing, Machine Learning (ML), and Large Language Models (LLMs) towards an affordable, real-time, and non-invasive free speech analysis. Moreover, it addresses the black box problem since the predictions are described to the end users thanks to the combination of LLMs with interpretable ml models (i.e., tree-based algorithms) using feature importance and natural language. The results obtained are 90 % on ppd detection for all evaluation metrics, outperforming the competing solutions in the literature. Ultimately, our solution contributes to the rapid detection of PPD and their associated risk factors, critical for in-time and proper assessment and intervention.
åœ¨äº§åæ¯äº²é¢ä¸´çš„è¯¸å¤šæŒ‘æˆ˜ä¸­ï¼Œäº§åæŠ‘éƒï¼ˆPPDï¼‰æ˜¯ä¸€ç§ä¸¥é‡çŠ¶å†µï¼Œæ˜¾è‘—å½±å“å¥¹ä»¬çš„å¿ƒç†å’Œèº«ä½“å¥åº·ã€‚å› æ­¤ï¼Œå¿«é€Ÿæ£€æµ‹ PPD åŠå…¶ç›¸å…³å±é™©å› ç´ å¯¹äºåŠæ—¶è¯„ä¼°å’Œé€šè¿‡ä¸“ä¸šé¢„é˜²æªæ–½è¿›è¡Œå¹²é¢„è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æ—¨åœ¨åˆ©ç”¨æœ€æ–°æŠ€æœ¯è¿›å±•å¸®åŠ©ä¸´åºŠäººå‘˜å†³ç­–ï¼Œå®ç°å®æ—¶ç­›æŸ¥å’Œæ²»ç–—å»ºè®®ã€‚ä¸»è¦æ¥è¯´ï¼Œæˆ‘ä»¬çš„å·¥ä½œæ„å»ºäº†ä¸€ç§æ™ºèƒ½äº§åæŠ‘éƒç­›æŸ¥ç³»ç»Ÿï¼Œç»“åˆè‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰å’Œ LLMsï¼Œå®ç°ç»æµã€å®æ—¶ä¸”éä¾µå…¥æ€§çš„è‡ªç”±è¯­éŸ³åˆ†æã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶é€šè¿‡å°† LLMs ä¸å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå¦‚åŸºäºæ ‘çš„ç®—æ³•ï¼‰ç»“åˆï¼Œåˆ©ç”¨ç‰¹å¾é‡è¦æ€§å’Œè‡ªç„¶è¯­è¨€å‘æœ€ç»ˆç”¨æˆ·è§£é‡Šé¢„æµ‹ç»“æœï¼Œä»è€Œè§£å†³äº†é»‘ç®±é—®é¢˜ã€‚å®éªŒç»“æœåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šå¯¹ PPD æ£€æµ‹å‡è¾¾åˆ°äº† 90%ï¼Œä¼˜äºæ–‡çŒ®ä¸­å·²æœ‰çš„å¯¹æ¯”æ–¹æ³•ã€‚ æœ€ç»ˆï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆæœ‰åŠ©äºå¿«é€Ÿæ£€æµ‹äº§åæŠ‘éƒåŠå…¶ç›¸å…³é£é™©å› ç´ ï¼Œè¿™å¯¹åº”æ—¶å¹¶æ­£ç¡®çš„è¯„ä¼°ä¸å¹²é¢„è‡³å…³é‡è¦ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-08 07:57:05 UTC
å‘å¸ƒï¼š2025-08-08 07:57:05 UTC</p>
<h2 id="48-rttc-reward-guided-collaborative-test-time-compute--48-rttcåŸºäºå¥–åŠ±å¼•å¯¼çš„åä½œæµ‹è¯•æ—¶è®¡ç®—"><a href="https://arxiv.org/abs/2508.10024"target="_blank" rel="external nofollow noopener noreferrer">#48</a> <a href="https://papers.cool/arxiv/2508.10024"target="_blank" rel="external nofollow noopener noreferrer">RTTC: Reward-Guided Collaborative Test-Time Compute</a>  #48 RTTCï¼šåŸºäºå¥–åŠ±å¼•å¯¼çš„åä½œæµ‹è¯•æ—¶è®¡ç®—</h2>
<p><strong>Authors</strong>: [J. Pablo MuÃ±oz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=J"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=J</a>. Pablo MuÃ±oz), [Jinjie Yuan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinjie</a> Yuan)
ä½œè€…ï¼šJ. Pablo MuÃ±ozã€Jinjie Yuan</p>
<p>Test-Time Compute (TTC) has emerged as a powerful paradigm for enhancing the performance of Large Language Models (LLMs) at inference, leveraging strategies such as Test-Time Training (TTT) and Retrieval-Augmented Generation (RAG). However, the optimal adaptation strategy varies across queries, and indiscriminate application of TTC strategy incurs substantial computational overhead. In this work, we introduce Reward-Guided Test-Time Compute (RTTC), a novel framework that adaptively selects the most effective TTC strategy for each query via a pretrained reward model, maximizing downstream accuracy across diverse domains and tasks. RTTC operates in a distributed server-client architecture, retrieving relevant samples from a remote knowledge base and applying RAG or lightweight fine-tuning on client devices only when necessary. To further mitigate redundant computation, we propose Query-State Caching, which enables the efficient reuse of historical query states at both retrieval and adaptation levels. Extensive experiments across multiple LLMs and benchmarks demonstrate that RTTC consistently achieves superior accuracy compared to vanilla RAG or TTT, validating the necessity of adaptive, reward-guided TTC selection and the potential of RTTC for scalable, high-performance language model adaptation.
æµ‹è¯•æ—¶è®¡ç®—ï¼ˆTTCï¼‰å·²æˆä¸ºåœ¨æ¨ç†é˜¶æ®µæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ€§èƒ½çš„ä¸€ç§å¼ºå¤§èŒƒå¼ï¼Œåˆ©ç”¨è¯¸å¦‚æµ‹è¯•æ—¶è®­ç»ƒï¼ˆTTTï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­‰ç­–ç•¥ã€‚ç„¶è€Œï¼Œæœ€ä½³çš„è‡ªé€‚åº”ç­–ç•¥ä¼šå› æŸ¥è¯¢è€Œå¼‚ï¼Œä¸”ä¸åŠ åŒºåˆ†åœ°åº”ç”¨ TTC ç­–ç•¥ä¼šå¸¦æ¥å¤§é‡è®¡ç®—å¼€é”€ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºå¥–åŠ±çš„æµ‹è¯•æ—¶è®¡ç®—ï¼ˆRTTCï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°æ¡†æ¶ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„å¥–åŠ±æ¨¡å‹ä¸ºæ¯ä¸ªæŸ¥è¯¢è‡ªé€‚åº”åœ°é€‰æ‹©æœ€æœ‰æ•ˆçš„ TTC ç­–ç•¥ï¼Œä»¥åœ¨ä¸åŒé¢†åŸŸå’Œä»»åŠ¡ä¸­æœ€å¤§åŒ–ä¸‹æ¸¸å‡†ç¡®ç‡ã€‚RTTC åœ¨åˆ†å¸ƒå¼æœåŠ¡å™¨â€”å®¢æˆ·ç«¯æ¶æ„ä¸­è¿è¡Œï¼Œä»è¿œç¨‹çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ ·æœ¬ï¼Œå¹¶ä»…åœ¨å¿…è¦æ—¶åœ¨å®¢æˆ·ç«¯è®¾å¤‡ä¸Šåº”ç”¨ RAG æˆ–è½»é‡å¾®è°ƒã€‚ä¸ºäº†è¿›ä¸€æ­¥å‡å°‘å†—ä½™è®¡ç®—ï¼Œæˆ‘ä»¬æå‡ºäº†æŸ¥è¯¢çŠ¶æ€ç¼“å­˜ï¼ˆQuery-State Cachingï¼‰ï¼Œä½¿å¾—åœ¨æ£€ç´¢å’Œé€‚åº”ä¸¤ä¸ªå±‚é¢ä¸Šé«˜æ•ˆé‡ç”¨å†å²æŸ¥è¯¢çŠ¶æ€æˆä¸ºå¯èƒ½ã€‚ åœ¨å¤šç§ LLMs å’ŒåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§é‡å®éªŒè¯æ˜ï¼ŒRTTC å§‹ç»ˆæ¯”åŸå§‹ RAG æˆ– TTT è·å¾—æ›´é«˜çš„å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†è‡ªé€‚åº”ã€ä»¥å¥–åŠ±ä¸ºæŒ‡å¯¼çš„ TTC é€‰æ‹©çš„å¿…è¦æ€§ä»¥åŠ RTTC åœ¨å¯æ‰©å±•çš„é«˜æ€§èƒ½è¯­è¨€æ¨¡å‹é€‚é…æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€ä¿¡æ¯æ£€ç´¢</p>
<p><strong>Publish</strong>: 2025-08-07 21:18:52 UTC
å‘å¸ƒï¼š2025-08-07 21:18:52 UTC</p>
<h2 id="49-conformal-p-value-in-multiple-choice-question-answering-tasks-with-provable-risk-control--49-åœ¨å¸¦æœ‰å¯è¯æ˜é£é™©æ§åˆ¶çš„å¤šé¡¹é€‰æ‹©é¢˜å›ç­”ä»»åŠ¡ä¸­çš„ç¬¦åˆæ€§-p-å€¼"><a href="https://arxiv.org/abs/2508.10022"target="_blank" rel="external nofollow noopener noreferrer">#49</a> <a href="https://papers.cool/arxiv/2508.10022"target="_blank" rel="external nofollow noopener noreferrer">Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control</a>  #49 åœ¨å¸¦æœ‰å¯è¯æ˜é£é™©æ§åˆ¶çš„å¤šé¡¹é€‰æ‹©é¢˜å›ç­”ä»»åŠ¡ä¸­çš„ç¬¦åˆæ€§ P å€¼</h2>
<p><strong>Author</strong>: [Yuanchang Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuanchang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuanchang</a> Ye) ä½œè€…ï¼šå¶å…ƒæ˜Œ</p>
<p>This study introduces a significance testing-enhanced conformal prediction (CP) framework to improve trustworthiness of large language models (LLMs) in multiple-choice question answering (MCQA). While LLMs have been increasingly deployed in disciplinary QA scenarios, hallucination and nonfactual generation substantially compromise response reliability. Although CP provides statistically rigorous marginal coverage guarantees for prediction sets, and significance testing offers established statistical rigor, their synergistic integration remains unexplored. To mitigate hallucination and factual inaccuracies, our framework integrates p-value computation with conformity scoring through self-consistency resampling of MCQA responses. This approach calculates option frequencies to address LLMs&rsquo; black-box nature, subsequently constructing prediction sets via null hypothesis testing (H0) with empirically derived p-values. Evaluations on MMLU and MMLU-Pro benchmarks using off-the-shelf LLMs demonstrate: (1) The enhanced CP achieves user-specified empirical miscoverage rates; (2) Test-set average prediction set size (APSS) decreases monotonically with increasing risk levels (Î±), validating APSS as an effective uncertainty metric. This work establishes a principled statistical framework for trustworthy LLM deployment in high-stakes QA applications.
æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆæ˜¾è‘—æ€§æ£€éªŒçš„ç¬¦åˆæ€§é¢„æµ‹ï¼ˆCPï¼‰æ¡†æ¶ï¼Œä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ï¼ˆMCQAï¼‰ä¸­çš„å¯ä¿¡åº¦ã€‚å°½ç®¡ LLMs è¶Šæ¥è¶Šå¤šåœ°è¢«éƒ¨ç½²åœ¨å­¦ç§‘é—®ç­”åœºæ™¯ä¸­ï¼Œä½†å¹»è§‰å’Œéäº‹å®ç”Ÿæˆå¤§å¤§å‰Šå¼±äº†å›ç­”çš„å¯é æ€§ã€‚å°½ç®¡ CP ä¸ºé¢„æµ‹é›†æä¾›äº†ç»Ÿè®¡å­¦ä¸Šä¸¥æ ¼çš„è¾¹é™…è¦†ç›–ä¿è¯ï¼Œè€Œæ˜¾è‘—æ€§æ£€éªŒåˆ™æä¾›äº†æˆç†Ÿçš„ç»Ÿè®¡ä¸¥è°¨æ€§ï¼Œä½†ä¸¤è€…çš„ååŒæ•´åˆä»æœªè¢«æ¢ç´¢ã€‚ä¸ºç¼“è§£å¹»è§‰å’Œäº‹å®ä¸å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬çš„æ¡†æ¶é€šè¿‡å¯¹ MCQA å›ç­”è¿›è¡Œè‡ªæ´½é‡é‡‡æ ·ï¼Œå°† p -å€¼è®¡ç®—ä¸ä¸€è‡´æ€§è¯„åˆ†ç›¸ç»“åˆã€‚è¯¥æ–¹æ³•è®¡ç®—é€‰é¡¹é¢‘ç‡ä»¥åº”å¯¹ LLMs çš„é»‘ç®±ç‰¹æ€§ï¼Œéšåé€šè¿‡é›¶å‡è®¾æ£€éªŒï¼ˆ H0 ï¼‰ä½¿ç”¨ç»éªŒå¯¼å‡ºçš„ p -å€¼æ„å»ºé¢„æµ‹é›†ã€‚ åœ¨ä½¿ç”¨ç°æˆ LLMs å¯¹ MMLU å’Œ MMLU-Pro åŸºå‡†è¿›è¡Œè¯„ä¼°æ—¶æ˜¾ç¤ºï¼š(1) å¢å¼ºçš„ CP å®ç°äº†ç”¨æˆ·æŒ‡å®šçš„ç»éªŒå¤±è¦†ç›–ç‡ï¼›(2) éšç€é£é™©æ°´å¹³çš„å¢åŠ ï¼Œæµ‹è¯•é›†ä¸Šçš„å¹³å‡é¢„æµ‹é›†å¤§å°ï¼ˆAPSSï¼‰å•è°ƒä¸‹é™ï¼ˆ Î± ï¼‰ï¼ŒéªŒè¯äº† APSS ä½œä¸ºä¸€ç§æœ‰æ•ˆçš„ä¸ç¡®å®šæ€§åº¦é‡ã€‚æœ¬å·¥ä½œä¸ºåœ¨é«˜é£é™©é—®ç­”åº”ç”¨ä¸­å¯ä¿¡èµ–åœ°éƒ¨ç½² LLMs å»ºç«‹äº†ä¸€ä¸ªæœ‰åŸåˆ™çš„ç»Ÿè®¡æ¡†æ¶ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-07 16:46:47 UTC
å‘å¸ƒï¼š2025-08-07 16:46:47 UTC</p>
<h2 id="50-latte-learning-aligned-transactions-and-textual-embeddings-for-bank-clients--50-latteä¸ºé“¶è¡Œå®¢æˆ·å­¦ä¹ å¯¹é½çš„äº¤æ˜“å’Œæ–‡æœ¬åµŒå…¥"><a href="https://arxiv.org/abs/2508.10021"target="_blank" rel="external nofollow noopener noreferrer">#50</a> <a href="https://papers.cool/arxiv/2508.10021"target="_blank" rel="external nofollow noopener noreferrer">LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients</a>  #50 LATTEï¼šä¸ºé“¶è¡Œå®¢æˆ·å­¦ä¹ å¯¹é½çš„äº¤æ˜“å’Œæ–‡æœ¬åµŒå…¥</h2>
<p><strong>Authors</strong>: [Egor Fadeev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Egor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Egor</a> Fadeev), [Dzhambulat Mollaev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dzhambulat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dzhambulat</a> Mollaev), [Aleksei Shestov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aleksei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aleksei</a> Shestov), [Dima Korolev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dima"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dima</a> Korolev), [Omar Zoloev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Omar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Omar</a> Zoloev), [Ivan Kireev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivan</a> Kireev), [Andrey Savchenko](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrey</a> Savchenko), [Maksim Makarenko](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maksim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maksim</a> Makarenko)
ä½œè€…ï¼šEgor Fadeevã€Dzhambulat Mollaevã€Aleksei Shestovã€Dima Korolevã€Omar Zoloevã€Ivan Kireevã€Andrey Savchenkoã€Maksim Makarenko</p>
<p>Learning clients embeddings from sequences of their historic communications is central to financial applications. While large language models (LLMs) offer general world knowledge, their direct use on long event sequences is computationally expensive and impractical in real-world pipelines. In this paper, we propose LATTE, a contrastive learning framework that aligns raw event embeddings with semantic embeddings from frozen LLMs. Behavioral features are summarized into short prompts, embedded by the LLM, and used as supervision via contrastive loss. The proposed approach significantly reduces inference cost and input size compared to conventional processing of complete sequence by LLM. We experimentally show that our method outperforms state-of-the-art techniques for learning event sequence representations on real-world financial datasets while remaining deployable in latency-sensitive environments.
ä»å†å²é€šä¿¡åºåˆ—ä¸­å­¦ä¹ å®¢æˆ·åµŒå…¥å¯¹äºé‡‘èåº”ç”¨è‡³å…³é‡è¦ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æä¾›äº†é€šç”¨çš„ä¸–ç•ŒçŸ¥è¯†ï¼Œä½†å®ƒä»¬åœ¨é•¿äº‹ä»¶åºåˆ—ä¸Šçš„ç›´æ¥ä½¿ç”¨åœ¨è®¡ç®—ä¸Šä»£ä»·é«˜æ˜‚ä¸”åœ¨å®é™…æµæ°´çº¿ä¸­ä¸åˆ‡å®é™…ã€‚æœ¬æ–‡æå‡ºäº† LATTEï¼Œä¸€ç§å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œå°†åŸå§‹äº‹ä»¶åµŒå…¥ä¸æ¥è‡ªå†»ç»“ LLM çš„è¯­ä¹‰åµŒå…¥å¯¹é½ã€‚è¡Œä¸ºç‰¹å¾è¢«æ€»ç»“ä¸ºç®€çŸ­æç¤ºï¼Œç”± LLM åµŒå…¥ï¼Œå¹¶é€šè¿‡å¯¹æ¯”æŸå¤±ç”¨ä½œç›‘ç£ã€‚ä¸ä¼ ç»Ÿç”± LLM å¤„ç†å®Œæ•´åºåˆ—çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—é™ä½äº†æ¨ç†æˆæœ¬å’Œè¾“å…¥è§„æ¨¡ã€‚æˆ‘ä»¬çš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®é‡‘èæ•°æ®é›†ä¸Šå­¦ä¹ äº‹ä»¶åºåˆ—è¡¨ç¤ºæ–¹é¢ä¼˜äºæœ€å…ˆè¿›æŠ€æœ¯ï¼ŒåŒæ—¶ä»å¯éƒ¨ç½²äºå¯¹å»¶è¿Ÿæ•æ„Ÿçš„ç¯å¢ƒä¸­ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-07 16:46:38 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-07 16:46:38 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="51-fedcot-communication-efficient-federated-reasoning-enhancement-for-large-language-models--51-fedcoté¢å‘å¤§è¯­è¨€æ¨¡å‹çš„é€šä¿¡é«˜æ•ˆè”é‚¦æ¨ç†å¢å¼º"><a href="https://arxiv.org/abs/2508.10020"target="_blank" rel="external nofollow noopener noreferrer">#51</a> <a href="https://papers.cool/arxiv/2508.10020"target="_blank" rel="external nofollow noopener noreferrer">FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models</a>  #51 FedCoTï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹çš„é€šä¿¡é«˜æ•ˆè”é‚¦æ¨ç†å¢å¼º</h2>
<p><strong>Authors</strong>: [Chuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chuan</a> Li), [Qianyi Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qianyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qianyi</a> Zhao), [Fengran Mo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fengran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fengran</a> Mo), [Cen Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cen</a> Chen)
ä½œè€…ï¼šChuan Liã€Qianyi Zhaoã€Fengran Moã€Cen Chen</p>
<p>Efficiently enhancing the reasoning capabilities of large language models (LLMs) in federated learning environments remains challenging, particularly when balancing performance gains with strict computational, communication, and privacy constraints. This challenge is especially acute in healthcare, where decisions-spanning clinical, operational, and patient-facing contexts-demand not only accurate outputs but also interpretable, traceable rationales to ensure safety, accountability, and regulatory compliance. Conventional federated tuning approaches on LLM fail to address this need: they optimize primarily for answer correctness while neglecting rationale quality, leaving CoT capabilities dependent on models&rsquo; innate pre-training abilities. Moreover, existing methods for improving rationales typically rely on privacy-violating knowledge distillation from centralized models. Additionally, the communication overhead in traditional federated fine-tuning on LLMs remains substantial. We addresses this gap by proposing FedCoT, a novel framework specifically designed to enhance reasoning in federated settings. FedCoT leverages a lightweight chain-of-thought enhancement mechanism: local models generate multiple reasoning paths, and a compact discriminator dynamically selects the most promising one. This approach improves reasoning accuracy and robustness while providing valuable interpretability, which is particularly critical for medical applications. To manage client heterogeneity efficiently, we adopt an improved aggregation approach building upon advanced LoRA module stacking, incorporating client classifier-awareness to achieve noise-free aggregation across diverse clients. Comprehensive experiments on medical reasoning tasks demonstrate that FedCoT significantly boosts client-side reasoning performance under stringent resource budgets while fully preserving data privacy.
åœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­é«˜æ•ˆæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦åœ¨æ€§èƒ½æå‡ä¸ä¸¥æ ¼çš„è®¡ç®—ã€é€šä¿¡å’Œéšç§çº¦æŸä¹‹é—´å–å¾—å¹³è¡¡æ—¶ã€‚è¿™ä¸€æŒ‘æˆ˜åœ¨åŒ»ç–—é¢†åŸŸå°¤ä¸ºçªå‡ºï¼Œé‚£é‡Œè·¨ä¸´åºŠã€è¿è¥å’Œé¢å‘æ‚£è€…çš„å†³ç­–ä¸ä»…éœ€è¦å‡†ç¡®çš„è¾“å‡ºï¼Œè¿˜éœ€è¦å¯è§£é‡Šã€å¯è¿½æº¯çš„æ¨ç†ä¾æ®ä»¥ç¡®ä¿å®‰å…¨ã€é—®è´£å’Œåˆè§„æ€§ã€‚ä¼ ç»Ÿçš„é’ˆå¯¹ LLM çš„è”é‚¦å¾®è°ƒæ–¹æ³•æ— æ³•æ»¡è¶³è¿™ä¸€éœ€æ±‚ï¼šå®ƒä»¬ä¸»è¦ä¼˜åŒ–ç­”æ¡ˆçš„æ­£ç¡®æ€§è€Œå¿½è§†æ¨ç†ä¾æ®çš„è´¨é‡ï¼Œä½¿å¾—é“¾å¼æ€è€ƒï¼ˆCoTï¼‰èƒ½åŠ›ä¾èµ–äºæ¨¡å‹å›ºæœ‰çš„é¢„è®­ç»ƒèƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç°æœ‰æå‡æ¨ç†ä¾æ®çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºæ¥è‡ªé›†ä¸­å¼æ¨¡å‹çš„ã€ä¾µçŠ¯éšç§çš„çŸ¥è¯†è’¸é¦ã€‚å†è€…ï¼Œä¼ ç»Ÿè”é‚¦å¾®è°ƒ LLMs çš„é€šä¿¡å¼€é”€ä¾ç„¶å¾ˆå¤§ã€‚æˆ‘ä»¬æå‡ºäº† FedCoTï¼Œä¸€ä¸ªä¸“é—¨è®¾è®¡ç”¨äºåœ¨è”é‚¦ç¯å¢ƒä¸­å¢å¼ºæ¨ç†èƒ½åŠ›çš„æ–°æ¡†æ¶ï¼Œä»¥å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚ FedCoT åˆ©ç”¨ä¸€ç§è½»é‡çº§çš„é“¾å¼æ€ç»´å¢å¼ºæœºåˆ¶ï¼šæœ¬åœ°æ¨¡å‹ç”Ÿæˆå¤šæ¡æ¨ç†è·¯å¾„ï¼Œç´§å‡‘çš„åˆ¤åˆ«å™¨åŠ¨æ€é€‰æ‹©æœ€æœ‰å‰æ™¯çš„ä¸€æ¡ã€‚è¯¥æ–¹æ³•åœ¨æé«˜æ¨ç†å‡†ç¡®æ€§å’Œé²æ£’æ€§çš„åŒæ—¶æä¾›äº†æœ‰ä»·å€¼çš„å¯è§£é‡Šæ€§ï¼Œè¿™å¯¹åŒ»ç–—åº”ç”¨å°¤ä¸ºå…³é”®ã€‚ä¸ºé«˜æ•ˆç®¡ç†å®¢æˆ·ç«¯å¼‚æ„æ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§æ”¹è¿›çš„èšåˆæ–¹æ³•ï¼ŒåŸºäºé«˜çº§ LoRA æ¨¡å—å †å ï¼Œå¹¶åŠ å…¥å®¢æˆ·ç«¯åˆ†ç±»å™¨æ„ŸçŸ¥ï¼Œä»¥åœ¨å¤šæ ·åŒ–å®¢æˆ·ç«¯ä¹‹é—´å®ç°æ— å™ªå£°èšåˆã€‚åœ¨åŒ»ç–—æ¨ç†ä»»åŠ¡ä¸Šçš„å…¨é¢å®éªŒè¡¨æ˜ï¼ŒFedCoT åœ¨ä¸¥æ ¼çš„èµ„æºé¢„ç®—ä¸‹æ˜¾è‘—æå‡äº†å®¢æˆ·ç«¯çš„æ¨ç†æ€§èƒ½ï¼ŒåŒæ—¶å®Œå…¨ä¿ç•™äº†æ•°æ®éšç§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-07 06:50:15 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-07 06:50:15 UTC</p>
<h2 id="52-decoupling-understanding-from-reasoning-via-problem-space-mapping-for-small-scale-model-reasoning--52-é€šè¿‡é—®é¢˜ç©ºé—´æ˜ å°„å°†ç†è§£ä¸æ¨ç†è§£è€¦ä»¥ç”¨äºå°è§„æ¨¡æ¨¡å‹æ¨ç†"><a href="https://arxiv.org/abs/2508.10019"target="_blank" rel="external nofollow noopener noreferrer">#52</a> <a href="https://papers.cool/arxiv/2508.10019"target="_blank" rel="external nofollow noopener noreferrer">Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning</a>  #52 é€šè¿‡é—®é¢˜ç©ºé—´æ˜ å°„å°†ç†è§£ä¸æ¨ç†è§£è€¦ä»¥ç”¨äºå°è§„æ¨¡æ¨¡å‹æ¨ç†</h2>
<p><strong>Authors</strong>: [Li Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Li"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Li</a> Wang), [Changhao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Changhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Changhao</a> Zhang), [Zengqi Xiu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zengqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zengqi</a> Xiu), [Kai Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Lu), [Xin Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Yu), [Kui Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kui</a> Zhang), [Wenjun Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenjun</a> Wu)
ä½œè€…ï¼šç‹ä¸½ï¼Œå¼ é•¿æµ©ï¼Œä¿®å¢å¥‡ï¼Œé™†å‡¯ï¼Œä½™é‘«ï¼Œå¼ é­ï¼Œå´æ–‡ä¿Š</p>
<p>Despite recent advances in the reasoning capabilities of Large Language Models (LLMs), improving the reasoning ability of Small Language Models (SLMs, e.g., â‰¤ 1.5B) remains challenging. A key obstacle lies in the complexity and variability of natural language: essentially equivalent problems often appear in diverse surface forms, often obscured by redundant or distracting details. This imposes a dual burden on SLMs: they must first extract the core problem from complex linguistic input, and then perform reasoning based on that understanding. The resulting vast and noisy problem space hinders optimization, particularly for models with limited capacity. To address this, we propose a new framework that decouples understanding from reasoning by mapping natural language problems into a canonical problem space-a semantically simplified yet expressive domain. This enables SLMs to focus on reasoning over standardized inputs, free from linguistic variability. Within this framework, we introduce DURIT (Decoupled Understanding from Reasoning via Iterative Training), a three-step algorithm that iteratively: (1) mapping natural language problems via reinforcement learning, (2) aligns reasoning trajectories through self-distillation, and (3) trains reasoning policies in the problem space. The mapper and reasoner are co-trained in an alternating loop throughout this process. Experiments show that DURIT substantially improves SLMs&rsquo; performance on both in-domain and out-of-domain mathematical and logical reasoning tasks. Beyond improving reasoning capabilities, DURIT also improves the robustness of reasoning, validating decoupling understanding from reasoning as an effective strategy for strengthening SLMs.
å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†èƒ½åŠ›ä¸Šæœ€è¿‘å–å¾—äº†è¿›å±•ï¼Œä½†æé«˜å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼Œä¾‹å¦‚ â‰¤ 1.5Bï¼‰çš„æ¨ç†èƒ½åŠ›ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸€ä¸ªå…³é”®éšœç¢åœ¨äºè‡ªç„¶è¯­è¨€çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ï¼šæœ¬è´¨ä¸Šç­‰ä»·çš„é—®é¢˜å¸¸ä»¥å„ç§è¡¨é¢å½¢å¼å‡ºç°ï¼Œå¸¸å¸¸è¢«å†—ä½™æˆ–å¹²æ‰°æ€§çš„ç»†èŠ‚æ‰€æ©ç›–ã€‚è¿™å¯¹ SLMs æ„æˆäº†åŒé‡è´Ÿæ‹…ï¼šå®ƒä»¬å¿…é¡»é¦–å…ˆä»å¤æ‚çš„è¯­è¨€è¾“å…¥ä¸­æå–æ ¸å¿ƒé—®é¢˜ï¼Œç„¶ååŸºäºè¯¥ç†è§£è¿›è¡Œæ¨ç†ã€‚ç”±æ­¤äº§ç”Ÿçš„åºå¤§ä¸”å˜ˆæ‚çš„é—®é¢˜ç©ºé—´é˜»ç¢äº†ä¼˜åŒ–ï¼Œå°¤å…¶å¯¹äºå®¹é‡æœ‰é™çš„æ¨¡å‹æ›´ä¸ºæ˜æ˜¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„æ¡†æ¶ï¼Œé€šè¿‡å°†è‡ªç„¶è¯­è¨€é—®é¢˜æ˜ å°„åˆ°ä¸€ä¸ªè§„èŒƒé—®é¢˜ç©ºé—´â€”â€”ä¸€ä¸ªè¯­ä¹‰ä¸Šç®€åŒ–ä½†å…·è¡¨è¾¾åŠ›çš„é¢†åŸŸâ€”â€”æ¥å°†ç†è§£ä¸æ¨ç†è§£è€¦ã€‚è¿™ä½¿å¾— SLMs èƒ½å¤Ÿä¸“æ³¨äºå¯¹æ ‡å‡†åŒ–è¾“å…¥è¿›è¡Œæ¨ç†ï¼Œè€Œä¸å—è¯­è¨€å¤šæ ·æ€§çš„å¹²æ‰°ã€‚ åœ¨æ­¤æ¡†æ¶ä¸‹ï¼Œæˆ‘ä»¬æå‡ºäº† DURITï¼ˆé€šè¿‡è¿­ä»£è®­ç»ƒå°†ç†è§£ä¸æ¨ç†è§£è€¦ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸‰æ­¥ç®—æ³•ï¼Œè¿­ä»£æ‰§è¡Œï¼š(1) é€šè¿‡å¼ºåŒ–å­¦ä¹ æ˜ å°„è‡ªç„¶è¯­è¨€é—®é¢˜ï¼Œ(2) é€šè¿‡è‡ªè’¸é¦å¯¹é½æ¨ç†è½¨è¿¹ï¼Œ(3) åœ¨é—®é¢˜ç©ºé—´ä¸­è®­ç»ƒæ¨ç†ç­–ç•¥ã€‚æ˜ å°„å™¨å’Œæ¨ç†å™¨åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä»¥äº¤æ›¿å¾ªç¯çš„æ–¹å¼å…±åŒè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼ŒDURIT åœ¨åŸŸå†…å’ŒåŸŸå¤–çš„æ•°å­¦ä¸é€»è¾‘æ¨ç†ä»»åŠ¡ä¸Šéƒ½æ˜¾è‘—æå‡äº†åºåˆ—è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰çš„è¡¨ç°ã€‚é™¤äº†å¢å¼ºæ¨ç†èƒ½åŠ›ä¹‹å¤–ï¼ŒDURIT è¿˜æé«˜äº†æ¨ç†çš„é²æ£’æ€§ï¼ŒéªŒè¯äº†å°†ç†è§£ä¸æ¨ç†è§£è€¦ä½œä¸ºå¼ºåŒ– SLMs çš„ä¸€ç§æœ‰æ•ˆç­–ç•¥ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-07 01:13:30 UTC
å‘å¸ƒï¼š2025-08-07 01:13:30 UTC</p>
<h2 id="53-a-rose-by-any-other-name-would-smell-as-sweet-categorical-homotopy-theory-for-large-language-models--53-åå­—ä¸åŒç«ç‘°ä¾æ—§èŠ¬èŠ³é¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„èŒƒç•´åŒä¼¦è®º"><a href="https://arxiv.org/abs/2508.10018"target="_blank" rel="external nofollow noopener noreferrer">#53</a> <a href="https://papers.cool/arxiv/2508.10018"target="_blank" rel="external nofollow noopener noreferrer">A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models</a>  #53 åå­—ä¸åŒç«ç‘°ä¾æ—§èŠ¬èŠ³ï¼šé¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„èŒƒç•´åŒä¼¦è®º</h2>
<p><strong>Author</strong>: [Sridhar Mahadevan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sridhar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sridhar</a> Mahadevan)</p>
<p>Natural language is replete with superficially different statements, such as <code>Charles Darwin wrote&quot; and </code>Charles Darwin is the author of&quot;, which carry the same meaning. Large language models (LLMs) should generate the same next-token probabilities in such cases, but usually do not. Empirical workarounds have been explored, such as using k-NN estimates of sentence similarity to produce smoothed estimates. In this paper, we tackle this problem more abstractly, introducing a categorical homotopy framework for LLMs. We introduce an LLM Markov category to represent probability distributions in language generated by an LLM, where the probability of a sentence, such as <code>Charles Darwin wrote&quot; is defined by an arrow in a Markov category. However, this approach runs into difficulties as language is full of equivalent rephrases, and each generates a non-isomorphic arrow in the LLM Markov category. To address this fundamental problem, we use categorical homotopy techniques to capture </code>weak equivalences&quot; in an LLM Markov category. We present a detailed overview of application of categorical homotopy to LLMs, from higher algebraic K-theory to model categories, building on powerful theoretical results developed over the past half a century.
è‡ªç„¶è¯­è¨€å……æ–¥ç€è¡¨é¢ä¸Šä¸åŒä½†æ„ä¹‰ç›¸åŒçš„è¡¨è¿°ï¼Œä¾‹å¦‚â€œCharles Darwin wroteâ€å’Œâ€œCharles Darwin is the author ofâ€ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒLLMs åº”å½“ç”Ÿæˆç›¸åŒçš„ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½†é€šå¸¸å¹¶éå¦‚æ­¤ã€‚å·²æœ‰å®è¯ä¸Šçš„æƒå®œä¹‹è®¡è¢«æ¢ç´¢ï¼Œä¾‹å¦‚ä½¿ç”¨ k-NN çš„å¥å­ç›¸ä¼¼åº¦ä¼°è®¡æ¥ç”Ÿæˆå¹³æ»‘çš„ä¼°è®¡å€¼ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»¥æ›´æŠ½è±¡çš„æ–¹å¼å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ä¸ªç”¨äº LLMs çš„èŒƒç•´åŒä¼¦æ¡†æ¶ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ª LLM é©¬å°”å¯å¤«èŒƒç•´ï¼Œç”¨ä»¥è¡¨ç¤ºç”± LLM ç”Ÿæˆçš„è¯­è¨€ä¸­çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå…¶ä¸­ä¸€å¥è¯çš„æ¦‚ç‡ï¼Œä¾‹å¦‚â€œCharles Darwin wroteâ€ï¼Œç”±é©¬å°”å¯å¤«èŒƒç•´ä¸­çš„ä¸€æ¡ç®­è¡¨ç¤ºã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•é‡åˆ°äº†å›°éš¾ï¼Œå› ä¸ºè¯­è¨€å……æ»¡äº†ç­‰ä»·çš„æ”¹å†™ï¼Œè€Œæ¯ä¸€ç§æ”¹å†™åœ¨ LLM é©¬å°”å¯å¤«èŒƒç•´ä¸­éƒ½ä¼šç”Ÿæˆä¸€æ¡éåŒæ„çš„ç®­ã€‚ä¸ºäº†è§£å†³è¿™ä¸€åŸºæœ¬é—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨èŒƒç•´åŒä¼¦æŠ€æœ¯æ¥æ•æ‰ LLM é©¬å°”å¯å¤«èŒƒç•´ä¸­çš„â€œå¼±ç­‰ä»·â€ã€‚ æˆ‘ä»¬å‘ˆç°äº†å°†èŒƒç•´åŒä¼¦è®ºåº”ç”¨äº LLMs çš„è¯¦ç»†ç»¼è¿°ï¼Œå†…å®¹æ¶µç›–ä»é«˜é˜¶ä»£æ•° K ç†è®ºåˆ°æ¨¡å‹èŒƒç•´ï¼Œå»ºç«‹åœ¨è¿‡å»åŠä¸ªä¸–çºªå‘å±•å‡ºçš„å¼ºå¤§ç†è®ºæˆæœä¹‹ä¸Šã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/math.AT"target="_blank" rel="external nofollow noopener noreferrer">Algebraic Topology</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œä»£æ•°æ‹“æ‰‘</p>
<p><strong>Publish</strong>: 2025-08-07 00:48:30 UTC
å‘å¸ƒï¼š2025-08-07 00:48:30 UTC</p>
<h2 id="54-training-free-multimodal-large-language-model-orchestration--54-æ— éœ€è®­ç»ƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç¼–æ’"><a href="https://arxiv.org/abs/2508.10016"target="_blank" rel="external nofollow noopener noreferrer">#54</a> <a href="https://papers.cool/arxiv/2508.10016"target="_blank" rel="external nofollow noopener noreferrer">Training-Free Multimodal Large Language Model Orchestration</a>  #54 æ— éœ€è®­ç»ƒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç¼–æ’</h2>
<p><strong>Authors</strong>: [Tianyu Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyu</a> Xie), [Yuhang Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhang</a> Wu), [Yongdong Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yongdong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yongdong</a> Luo), [Jiayi Ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiayi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiayi</a> Ji), [Xiawu Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiawu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiawu</a> Zheng)
ä½œè€…ï¼šè°¢å¤©å®‡ã€å´é›¨èˆªã€ç½—æ°¸ä¸œã€å­£ä½³æ€¡ã€éƒ‘éœé›¾</p>
<p>Different Multimodal Large Language Models (MLLMs) cannot be integrated into a unified multimodal input-output system directly. In previous work, training has been considered as an inevitable component due to challenges in modal alignment, Text-to-Speech efficiency and other integration issues. In this paper, we introduce Multimodal Large Language Model Orchestration, an effective approach for creating interactive multimodal AI systems without additional training. MLLM Orchestration leverages the inherent reasoning capabilities of large language models to coordinate specialized models through explicit workflows, enabling natural multimodal interactions while maintaining modularity, improving interpretability, and significantly enhancing computational efficiency. Our orchestration framework is built upon three key innovations: (1) a central controller LLM that analyzes user inputs and dynamically routes tasks to appropriate specialized models through carefully designed agents; (2) a parallel Text-to-Speech architecture that enables true full-duplex interaction with seamless interruption handling and natural conversational flow; and (3) a cross-modal memory integration system that maintains coherent context across modalities through intelligent information synthesis and retrieval, selectively avoiding unnecessary modality calls in certain scenarios to improve response speed. Extensive evaluations demonstrate that MLLM Orchestration achieves comprehensive multimodal capabilities without additional training, performance improvements of up to 7.8% over traditional jointly-trained approaches on standard benchmarks, reduced latency by 10.3%, and significantly enhanced interpretability through explicit orchestration processes.
ä¸åŒçš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰æ— æ³•ç›´æ¥æ•´åˆåˆ°ç»Ÿä¸€çš„å¤šæ¨¡æ€è¾“å…¥è¾“å‡ºç³»ç»Ÿä¸­ã€‚ä»¥å¾€å·¥ä½œè®¤ä¸ºè®­ç»ƒæ˜¯ä¸å¯é¿å…çš„ç»„æˆéƒ¨åˆ†ï¼Œå› ä¸ºåœ¨æ¨¡æ€å¯¹é½ã€æ–‡æœ¬åˆ°è¯­éŸ³æ•ˆç‡åŠå…¶ä»–é›†æˆé—®é¢˜ä¸Šå­˜åœ¨æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç¼–æ’ï¼Œä¸€ç§æ— éœ€é¢å¤–è®­ç»ƒå³å¯æ„å»ºäº¤äº’å¼å¤šæ¨¡æ€ AI ç³»ç»Ÿçš„æœ‰æ•ˆæ–¹æ³•ã€‚MLLM ç¼–æ’åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹å›ºæœ‰çš„æ¨ç†èƒ½åŠ›ï¼Œé€šè¿‡æ˜¾å¼å·¥ä½œæµæ¥åè°ƒä¸“ç”¨æ¨¡å‹ï¼Œå®ç°è‡ªç„¶çš„å¤šæ¨¡æ€äº¤äº’ï¼ŒåŒæ—¶ä¿æŒæ¨¡å—åŒ–ã€æé«˜å¯è§£é‡Šæ€§ï¼Œå¹¶æ˜¾è‘—æå‡è®¡ç®—æ•ˆç‡ã€‚ æˆ‘ä»¬çš„ç¼–æ’æ¡†æ¶å»ºç«‹åœ¨ä¸‰é¡¹å…³é”®åˆ›æ–°ä¹‹ä¸Šï¼šï¼ˆ1ï¼‰ä¸€ä¸ªä¸­å¤®æ§åˆ¶å™¨ LLMï¼Œåˆ†æç”¨æˆ·è¾“å…¥å¹¶é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„ä»£ç†å°†ä»»åŠ¡åŠ¨æ€è·¯ç”±åˆ°é€‚å½“çš„ä¸“ç”¨æ¨¡å‹ï¼›ï¼ˆ2ï¼‰ä¸€ç§å¹¶è¡Œæ–‡æœ¬åˆ°è¯­éŸ³æ¶æ„ï¼Œæ”¯æŒçœŸæ­£çš„å…¨åŒå·¥äº¤äº’ï¼Œå…·å¤‡æ— ç¼ä¸­æ–­å¤„ç†å’Œè‡ªç„¶çš„å¯¹è¯æµï¼›ä»¥åŠï¼ˆ3ï¼‰ä¸€ä¸ªè·¨æ¨¡æ€è®°å¿†æ•´åˆç³»ç»Ÿï¼Œé€šè¿‡æ™ºèƒ½ä¿¡æ¯åˆæˆä¸æ£€ç´¢åœ¨æ¨¡æ€ä¹‹é—´ç»´æŒè¿è´¯çš„ä¸Šä¸‹æ–‡ï¼Œå¹¶åœ¨æŸäº›åœºæ™¯ä¸­æœ‰é€‰æ‹©åœ°é¿å…ä¸å¿…è¦çš„æ¨¡æ€è°ƒç”¨ä»¥æé«˜å“åº”é€Ÿåº¦ã€‚å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼ŒMLLM Orchestration åœ¨æ— éœ€é¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹å®ç°äº†å…¨é¢çš„å¤šæ¨¡æ€èƒ½åŠ›ï¼Œåœ¨æ ‡å‡†åŸºå‡†ä¸Šè¾ƒä¼ ç»Ÿçš„è”åˆè®­ç»ƒæ–¹æ³•æ€§èƒ½æå‡æœ€é«˜è¾¾ 7.8%ï¼Œå»¶è¿Ÿé™ä½äº† 10.3%ï¼Œå¹¶é€šè¿‡æ˜¾å¼çš„ç¼–æ’è¿‡ç¨‹æ˜¾è‘—å¢å¼ºäº†å¯è§£é‡Šæ€§ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-06 16:17:29 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-06 16:17:29 UTC</p>
<h2 id="55-realtalk-cn-a-realistic-chinese-speech-text-dialogue-benchmark-with-cross-modal-interaction-analysis--55-realtalk-cnä¸€ä¸ªå¸¦æœ‰è·¨æ¨¡æ€äº¤äº’åˆ†æçš„çœŸå®ä¸­æ–‡è¯­éŸ³-æ–‡æœ¬å¯¹è¯åŸºå‡†"><a href="https://arxiv.org/abs/2508.10015"target="_blank" rel="external nofollow noopener noreferrer">#55</a> <a href="https://papers.cool/arxiv/2508.10015"target="_blank" rel="external nofollow noopener noreferrer">RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal Interaction Analysis</a>  #55 RealTalk-CNï¼šä¸€ä¸ªå¸¦æœ‰è·¨æ¨¡æ€äº¤äº’åˆ†æçš„çœŸå®ä¸­æ–‡è¯­éŸ³-æ–‡æœ¬å¯¹è¯åŸºå‡†</h2>
<p><strong>Authors</strong>: [Enzhi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Enzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Enzhi</a> Wang), [Qicheng Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qicheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qicheng</a> Li), [Shiwan Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiwan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiwan</a> Zhao), [Aobo Kong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aobo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aobo</a> Kong), [Jiaming Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaming</a> Zhou), [Xi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xi</a> Yang), [Yequan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yequan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yequan</a> Wang), [Yonghua Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yonghua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yonghua</a> Lin), [Yong Qin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yong</a> Qin)
ä½œè€…ï¼šç‹æ©å¿—ã€æå¯æˆã€èµµä¸–ç¬ã€å­”å¥¥åšã€å‘¨å®¶æ˜ã€æ¨æ›¦ã€ç‹ä¸šæ³‰ã€æ—æ°¸åã€ç§¦å‹‡</p>
<p>In recent years, large language models (LLMs) have achieved remarkable advancements in multimodal processing, including end-to-end speech-based language models that enable natural interactions and perform specific tasks in task-oriented dialogue (TOD) systems. However, existing TOD datasets are predominantly text-based, lacking real speech signals that are essential for evaluating the robustness of speech-based LLMs. Moreover, existing speech TOD datasets are primarily English and lack critical aspects such as speech disfluencies and speaker variations. To address these gaps, we introduce RealTalk-CN, the first Chinese multi-turn, multi-domain speech-text dual-modal TOD dataset, comprising 5.4k dialogues (60K utterances, 150 hours) with paired speech-text annotations. RealTalk-CN captures diverse dialogue scenarios with annotated spontaneous speech disfluencies, ensuring comprehensive coverage of real-world complexities in speech dialogue. In addition, we propose a novel cross-modal chat task that authentically simulates real-world user interactions, allowing dynamic switching between speech and text modalities. Our evaluation covers robustness to speech disfluencies, sensitivity to speaker characteristics, and cross-domain performance. Extensive experiments validate the effectiveness of RealTalk-CN, establishing a strong foundation for Chinese speech-based LLMs research.
è¿‘å¹´æ¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šæ¨¡æ€å¤„ç†æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼ŒåŒ…æ‹¬ç«¯åˆ°ç«¯çš„åŸºäºè¯­éŸ³çš„è¯­è¨€æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿå®ç°è‡ªç„¶äº¤äº’å¹¶åœ¨é¢å‘ä»»åŠ¡çš„å¯¹è¯ï¼ˆTODï¼‰ç³»ç»Ÿä¸­æ‰§è¡Œç‰¹å®šä»»åŠ¡ã€‚ç„¶è€Œï¼Œç°æœ‰çš„ TOD æ•°æ®é›†ä¸»è¦ä»¥æ–‡æœ¬ä¸ºä¸»ï¼Œç¼ºä¹ç”¨äºè¯„ä¼°åŸºäºè¯­éŸ³çš„ LLMs é²æ£’æ€§æ‰€å¿…éœ€çš„çœŸå®è¯­éŸ³ä¿¡å·ã€‚æ­¤å¤–ï¼Œç°æœ‰çš„è¯­éŸ³ TOD æ•°æ®é›†ä¸»è¦ä¸ºè‹±è¯­ï¼Œç¼ºå°‘è¯­éŸ³ä¸è¿è´¯æ€§å’Œè¯´è¯äººå·®å¼‚ç­‰å…³é”®æ–¹é¢ã€‚ä¸ºäº†è§£å†³è¿™äº›ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº† RealTalk-CNï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªä¸­æ–‡å¤šè½®ã€å¤šé¢†åŸŸçš„è¯­éŸ³-æ–‡æœ¬åŒæ¨¡æ€ TOD æ•°æ®é›†ï¼ŒåŒ…å« 5.4k ä¸ªå¯¹è¯ï¼ˆ60K æ¡è¯è¯­ï¼Œ150 å°æ—¶ï¼‰ï¼Œå¹¶é…æœ‰è¯­éŸ³-æ–‡æœ¬é…å¯¹æ³¨é‡Šã€‚RealTalk-CN è¦†ç›–äº†å¤šæ ·çš„å¯¹è¯åœºæ™¯ï¼Œæ ‡æ³¨äº†è‡ªå‘è¯­éŸ³çš„ä¸è¿è´¯ç°è±¡ï¼Œç¡®ä¿å…¨é¢æ¶µç›–è¯­éŸ³å¯¹è¯ä¸­çš„çœŸå®ä¸–ç•Œå¤æ‚æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€é¡¹æ–°é¢–çš„è·¨æ¨¡æ€èŠå¤©ä»»åŠ¡ï¼ŒçœŸå®æ¨¡æ‹Ÿç°å®ç”¨æˆ·äº¤äº’ï¼Œå…è®¸åœ¨è¯­éŸ³å’Œæ–‡æœ¬æ¨¡æ€é—´åŠ¨æ€åˆ‡æ¢ã€‚ æˆ‘ä»¬çš„è¯„ä¼°æ¶µç›–å¯¹è¯­éŸ³ä¸æµåˆ©ç°è±¡çš„é²æ£’æ€§ã€å¯¹è¯´è¯è€…ç‰¹å¾çš„æ•æ„Ÿæ€§ä»¥åŠè·¨åŸŸæ€§èƒ½ã€‚å¤§é‡å®éªŒéªŒè¯äº† RealTalk-CN çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåŸºäºä¸­æ–‡è¯­éŸ³çš„ LLMs ç ”ç©¶å¥ å®šäº†åšå®åŸºç¡€ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-06 13:12:57 UTC
å‘å¸ƒï¼š2025-08-06 13:12:57 UTC</p>
<h2 id="56-personaeval-are-llm-evaluators-human-enough-to-judge-role-play--56-personaevalllm-è¯„ä¼°è€…åœ¨åˆ¤æ–­è§’è‰²æ‰®æ¼”æ—¶è¶³å¤Ÿåƒäººç±»å—"><a href="https://arxiv.org/abs/2508.10014"target="_blank" rel="external nofollow noopener noreferrer">#56</a> <a href="https://papers.cool/arxiv/2508.10014"target="_blank" rel="external nofollow noopener noreferrer">PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?</a>  #56 PersonaEvalï¼šLLM è¯„ä¼°è€…åœ¨åˆ¤æ–­è§’è‰²æ‰®æ¼”æ—¶è¶³å¤Ÿåƒäººç±»å—ï¼Ÿ</h2>
<p><strong>Authors</strong>: [Lingfeng Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingfeng</a> Zhou), [Jialing Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jialing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jialing</a> Zhang), [Jin Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jin</a> Gao), [Mohan Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohan</a> Jiang), [Dequan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dequan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dequan</a> Wang)
ä½œè€…ï¼šå‘¨å‡Œé£ã€å¼ ä½³çµã€é«˜æ™‹ã€å§œæ¨¡ç¿°ã€ç‹å¾·å…¨</p>
<p>Current role-play studies often rely on unvalidated LLM-as-a-judge paradigms, which may fail to reflect how humans perceive role fidelity. A key prerequisite for human-aligned evaluation is role identification, the ability to recognize who is speaking based on dialogue context. We argue that any meaningful judgment of role-playing quality (how well a character is played) fundamentally depends on first correctly attributing words and actions to the correct persona (who is speaking). We present PersonaEval, the first benchmark designed to test whether LLM evaluators can reliably identify human roles. PersonaEval uses human-authored dialogues from novels, scripts, and video transcripts, challenging models to determine the correct persona according to the conversation context. Our experiments, including a human study, show that even the best-performing LLMs reach only around 69% accuracy, well below the level needed for reliable evaluation. In contrast, human participants perform near ceiling with 90.8% accuracy, highlighting that current LLM evaluators are still not human enough to effectively judge role-play scenarios. To better understand this gap, we examine training-time adaptation and test-time compute, suggesting that reliable evaluation requires more than task-specific tuning, but depends on strong, human-like reasoning abilities in LLM evaluators. We release our benchmark at <a href="https://github.com/maple-zhou/PersonaEval"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/maple-zhou/PersonaEval</a>.
å½“å‰çš„è§’è‰²æ‰®æ¼”ç ”ç©¶å¸¸å¸¸ä¾èµ–æœªç»éªŒè¯çš„ LLM-as-a-judge èŒƒå¼ï¼Œè€Œè¿™äº›èŒƒå¼å¯èƒ½æ— æ³•åæ˜ äººç±»å¯¹è§’è‰²å¿ å®åº¦çš„æ„ŸçŸ¥ã€‚è¿›è¡Œä¸äººç±»ä¸€è‡´çš„è¯„ä¼°çš„ä¸€ä¸ªå…³é”®å‰ææ˜¯è§’è‰²è¯†åˆ«ï¼Œå³åŸºäºå¯¹è¯ä¸Šä¸‹æ–‡è¯†åˆ«æ˜¯è°åœ¨è¯´è¯çš„èƒ½åŠ›ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œå¯¹è§’è‰²æ‰®æ¼”è´¨é‡ï¼ˆè§’è‰²è¢«æ¼”ç»å¾—æœ‰å¤šå¥½ï¼‰è¿›è¡Œä»»ä½•æœ‰æ„ä¹‰çš„åˆ¤æ–­ï¼Œæ ¹æœ¬ä¸Šéƒ½å–å†³äºé¦–å…ˆå°†è¨€è¯­å’Œè¡Œä¸ºæ­£ç¡®å½’å±äºç›¸åº”çš„äººç‰©ï¼ˆè°åœ¨è¯´è¯ï¼‰ã€‚æˆ‘ä»¬æå‡ºäº† PersonaEvalï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªæ—¨åœ¨æµ‹è¯• LLM è¯„ä¼°å™¨æ˜¯å¦èƒ½å¤Ÿå¯é è¯†åˆ«äººç±»è§’è‰²çš„åŸºå‡†ã€‚PersonaEval ä½¿ç”¨æ¥è‡ªå°è¯´ã€å‰§æœ¬å’Œè§†é¢‘è½¬å½•çš„äººç±»æ’°å†™å¯¹è¯ï¼ŒæŒ‘æˆ˜æ¨¡å‹æ ¹æ®å¯¹è¯ä¸Šä¸‹æ–‡åˆ¤æ–­æ­£ç¡®çš„äººç‰©ã€‚æˆ‘ä»¬çš„å®éªŒï¼ˆåŒ…æ‹¬ä¸€é¡¹äººç±»ç ”ç©¶ï¼‰è¡¨æ˜ï¼Œå³ä½¿æ˜¯è¡¨ç°æœ€å¥½çš„ LLM ä¹Ÿä»…è¾¾åˆ°çº¦ 69% çš„å‡†ç¡®ç‡ï¼Œè¿œä½äºå¯é è¯„ä¼°æ‰€éœ€çš„æ°´å¹³ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œäººç±»å‚ä¸è€…çš„å‡†ç¡®ç‡æ¥è¿‘æ»¡åˆ†ï¼Œä¸º 90.8%ï¼Œè¿™å‡¸æ˜¾äº†å½“å‰çš„ LLM è¯„ä¼°å™¨åœ¨æœ‰æ•ˆè¯„åˆ¤è§’è‰²æ‰®æ¼”åœºæ™¯æ–¹é¢ä»ç„¶ä¸å¤Ÿæ¥è¿‘äººç±»ã€‚ ä¸ºæ›´å¥½åœ°ç†è§£è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬è€ƒå¯Ÿäº†è®­ç»ƒæ—¶çš„é€‚åº”æ€§å’Œæµ‹è¯•æ—¶çš„è®¡ç®—ï¼ŒæŒ‡å‡ºå¯é çš„è¯„ä¼°ä¸ä»…éœ€è¦é’ˆå¯¹ä»»åŠ¡çš„å¾®è°ƒï¼Œè¿˜ä¾èµ–äºåœ¨ LLM è¯„ä¼°è€…ä¸­å…·å¤‡å¼ºå¤§ã€ç±»äººæ¨ç†èƒ½åŠ›ã€‚æˆ‘ä»¬å·²åœ¨ <a href="https://github.com/maple-zhou/PersonaEval"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/maple-zhou/PersonaEval</a> å‘å¸ƒæˆ‘ä»¬çš„åŸºå‡†ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-06 13:06:15 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-06 13:06:15 UTC</p>
<h2 id="57-semantic-bridge-universal-multi-hop-question-generation-via-amr-driven-graph-synthesis--57-è¯­ä¹‰æ¡¥æ¢é€šè¿‡åŸºäº-amr-çš„å›¾åˆæˆå®ç°é€šç”¨å¤šè·³é—®é¢˜ç”Ÿæˆ-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10013"target="_blank" rel="external nofollow noopener noreferrer">#57</a> <a href="https://papers.cool/arxiv/2508.10013"target="_blank" rel="external nofollow noopener noreferrer">Semantic Bridge: Universal Multi-Hop Question Generation via AMR-Driven Graph Synthesis</a>  #57 è¯­ä¹‰æ¡¥æ¢ï¼šé€šè¿‡åŸºäº AMR çš„å›¾åˆæˆå®ç°é€šç”¨å¤šè·³é—®é¢˜ç”Ÿæˆ [PDF ] [Copy] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [Linqing Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Linqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Linqing</a> Chen), [Hanmeng Zhong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hanmeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hanmeng</a> Zhong), [Wentao Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wentao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wentao</a> Wu), [Weilei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Weilei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Weilei</a> Wang)
ä½œè€…ï¼šLinqing Chenã€Hanmeng Zhongã€Wentao Wuã€Weilei Wang</p>
<p>Large language model (LLM) training faces a critical bottleneck: the scarcity of high-quality, reasoning-intensive question-answer pairs, especially from sparse, domain-specific sources like PubMed papers or legal documents. Existing methods rely on surface patterns, fundamentally failing to generate controllable, complex multi-hop reasoning questions that test genuine understanding-essential for advancing LLM training paradigms. We present \textbf{Semantic Bridge}, the first universal framework for controllably generating sophisticated multi-hop reasoning questions from arbitrary sources. Our breakthrough innovation is \textit{semantic graph weaving}-three complementary bridging mechanisms (entity bridging for role-varying shared entities, predicate chain bridging for temporal/causal/logical sequences, and causal bridging for explicit reasoning chains)-that systematically construct complex pathways across documents, with fine-grained control over complexity and types via AMR-driven analysis. Our multi-modal AMR pipeline achieves up to 9.5% better round-trip quality, enabling production-ready controllable QA generation. Extensive evaluation demonstrates performance across both general-purpose datasets (Wikipedia) and specialized domains (biomedicine) It yields consistent 18.3%-25.4% gains over baselines across four languages (English, Chinese, French, German). Question pairs generated from 200 sources outperform 600 native human annotation examples with 67% fewer materials. Human evaluation shows 23.4% higher complexity, 18.7% better answerability, and 31.2% improved pattern coverage. Semantic Bridge establishes a new paradigm for LLM training data synthesis, enabling controllable generation of targeted reasoning questions from sparse sources. We will release our core code and semantic bridge model.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è®­ç»ƒé¢ä¸´ä¸€ä¸ªå…³é”®ç“¶é¢ˆï¼šé«˜è´¨é‡ã€æ³¨é‡æ¨ç†çš„é—®é¢˜â€”ç­”æ¡ˆå¯¹ç¨€ç¼ºï¼Œå°¤å…¶æ˜¯æ¥è‡ªè¯¸å¦‚ PubMed è®ºæ–‡æˆ–æ³•å¾‹æ–‡ä¹¦ç­‰ç¨€ç–ã€é¢†åŸŸç‰¹å®šçš„æ¥æºã€‚ç°æœ‰æ–¹æ³•ä¾èµ–è¡¨é¢æ¨¡å¼ï¼Œæ ¹æœ¬æ— æ³•ç”Ÿæˆå¯æ§çš„ã€å¤æ‚çš„å¤šè·³æ¨ç†é—®é¢˜æ¥æ£€éªŒçœŸæ­£çš„ç†è§£â€”â€”è€Œè¿™å¯¹æ¨è¿› LLM è®­ç»ƒèŒƒå¼è‡³å…³é‡è¦ã€‚æˆ‘ä»¬æå‡ºäº† Semantic Bridgeï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºä»ä»»æ„æ¥æºå¯æ§åœ°ç”Ÿæˆå¤æ‚å¤šè·³æ¨ç†é—®é¢˜çš„é€šç”¨æ¡†æ¶ã€‚æˆ‘ä»¬çš„çªç ´æ€§åˆ›æ–°æ˜¯è¯­ä¹‰å›¾ç¼–ç»‡ï¼ˆsemantic graph weavingï¼‰â€”â€”ä¸‰ç§äº’è¡¥çš„æ¡¥æ¥æœºåˆ¶ï¼ˆç”¨äºè§’è‰²å¯å˜å…±äº«å®ä½“çš„å®ä½“æ¡¥æ¥ã€ç”¨äºæ—¶é—´/å› æœ/é€»è¾‘åºåˆ—çš„è°“è¯é“¾æ¡¥æ¥ï¼Œä»¥åŠç”¨äºæ˜¾å¼æ¨ç†é“¾çš„å› æœæ¡¥æ¥ï¼‰â€”â€”é€šè¿‡ AMR é©±åŠ¨çš„åˆ†æç³»ç»Ÿåœ°æ„å»ºè·¨æ–‡æ¡£çš„å¤æ‚è·¯å¾„ï¼Œå¹¶å¯å¯¹å¤æ‚åº¦å’Œç±»å‹è¿›è¡Œç»†ç²’åº¦æ§åˆ¶ã€‚æˆ‘ä»¬çš„å¤šæ¨¡æ€ AMR æµæ°´çº¿åœ¨å¾€è¿”è´¨é‡ä¸Šæœ€é«˜æå‡äº† 9.5%ï¼Œä½¿å¯æŠ•å…¥ç”Ÿäº§çš„å¯æ§é—®ç­”ç”Ÿæˆæˆä¸ºå¯èƒ½ã€‚ å¤§é‡è¯„ä¼°è¡¨æ˜ï¼Œåœ¨é€šç”¨æ•°æ®é›†ï¼ˆç»´åŸºç™¾ç§‘ï¼‰å’Œä¸“é—¨é¢†åŸŸï¼ˆç”Ÿç‰©åŒ»å­¦ï¼‰ä¸Šå‡è¡¨ç°å‡ºè‰²ã€‚å®ƒåœ¨å››ç§è¯­è¨€ï¼ˆè‹±è¯­ã€ä¸­æ–‡ã€æ³•è¯­ã€å¾·è¯­ï¼‰ä¸Šç›¸è¾ƒåŸºçº¿æ–¹æ³•ç¨³å®šæå‡äº† 18.3%â€“25.4%ã€‚ä» 200 ä¸ªæ¥æºç”Ÿæˆçš„é—®é¢˜å¯¹ä»¥æ¯”äººç±»æ ‡æ³¨ 600 ä¾‹å°‘ 67%çš„ææ–™ï¼Œè¡¨ç°æ›´ä¼˜ã€‚äººå·¥è¯„ä¼°æ˜¾ç¤ºå¤æ‚åº¦é«˜å‡º 23.4%ï¼Œå¯ç­”å¤æ€§æå‡ 18.7%ï¼Œæ¨¡å¼è¦†ç›–ç‡æé«˜ 31.2%ã€‚Semantic Bridge ä¸º LLM è®­ç»ƒæ•°æ®åˆæˆç¡®ç«‹äº†æ–°èŒƒå¼ï¼Œä½¿å¾—èƒ½å¤Ÿä»ç¨€ç–æ¥æºå¯æ§åœ°ç”Ÿæˆæœ‰é’ˆå¯¹æ€§çš„æ¨ç†é—®é¢˜ã€‚æˆ‘ä»¬å°†å‘å¸ƒæ ¸å¿ƒä»£ç å’Œ semantic bridge æ¨¡å‹ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-06 10:59:42 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-06 10:59:42 UTC</p>
<h2 id="58-guided-navigation-in-knowledge-dense-environments-structured-semantic-exploration-with-guidance-graphs--58-åœ¨çŸ¥è¯†å¯†é›†å‹ç¯å¢ƒä¸­çš„å¼•å¯¼å¼å¯¼èˆªå¸¦æœ‰å¼•å¯¼å›¾çš„ç»“æ„åŒ–è¯­ä¹‰æ¢ç´¢"><a href="https://arxiv.org/abs/2508.10012"target="_blank" rel="external nofollow noopener noreferrer">#58</a> <a href="https://papers.cool/arxiv/2508.10012"target="_blank" rel="external nofollow noopener noreferrer">Guided Navigation in Knowledge-Dense Environments: Structured Semantic Exploration with Guidance Graphs</a>  #58 åœ¨çŸ¥è¯†å¯†é›†å‹ç¯å¢ƒä¸­çš„å¼•å¯¼å¼å¯¼èˆªï¼šå¸¦æœ‰å¼•å¯¼å›¾çš„ç»“æ„åŒ–è¯­ä¹‰æ¢ç´¢</h2>
<p><strong>Authors</strong>: [Dehao Tao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dehao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dehao</a> Tao), [Guangjie Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guangjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guangjie</a> Liu), <a href="https://arxiv.org/search/?searchtype=author&amp;query=Weizheng"target="_blank" rel="external nofollow noopener noreferrer">Weizheng</a>, [Yongfeng Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yongfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yongfeng</a> Huang), [Minghu jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Minghu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Minghu</a> jiang)
ä½œè€…ï¼šDehao Taoï¼ŒGuangjie Liuï¼ŒWeizhengï¼ŒYongfeng Huangï¼ŒMinghu jiang</p>
<p>While Large Language Models (LLMs) exhibit strong linguistic capabilities, their reliance on static knowledge and opaque reasoning processes limits their performance in knowledge intensive tasks. Knowledge graphs (KGs) offer a promising solution, but current exploration methods face a fundamental trade off: question guided approaches incur redundant exploration due to granularity mismatches, while clue guided methods fail to effectively leverage contextual information for complex scenarios. To address these limitations, we propose Guidance Graph guided Knowledge Exploration (GG Explore), a novel framework that introduces an intermediate Guidance Graph to bridge unstructured queries and structured knowledge retrieval. The Guidance Graph defines the retrieval space by abstracting the target knowledge&rsquo; s structure while preserving broader semantic context, enabling precise and efficient exploration. Building upon the Guidance Graph, we develop: (1) Structural Alignment that filters incompatible candidates without LLM overhead, and (2) Context Aware Pruning that enforces semantic consistency with graph constraints. Extensive experiments show our method achieves superior efficiency and outperforms SOTA, especially on complex tasks, while maintaining strong performance with smaller LLMs, demonstrating practical value.
å°½ç®¡ LLMs åœ¨è¯­è¨€èƒ½åŠ›æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†å®ƒä»¬å¯¹é™æ€çŸ¥è¯†çš„ä¾èµ–å’Œä¸é€æ˜çš„æ¨ç†è¿‡ç¨‹é™åˆ¶äº†åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚çŸ¥è¯†å›¾è°±ï¼ˆKGsï¼‰æä¾›äº†ä¸€ä¸ªæœ‰å¸Œæœ›çš„è§£å†³æ–¹æ¡ˆï¼Œä½†å½“å‰çš„æ¢ç´¢æ–¹æ³•é¢ä¸´ä¸€ä¸ªæ ¹æœ¬æ€§çš„æƒè¡¡ï¼šä»¥é—®é¢˜ä¸ºå¯¼å‘çš„æ–¹æ³•ç”±äºç²’åº¦ä¸åŒ¹é…è€Œå¯¼è‡´å†—ä½™æ¢ç´¢ï¼Œè€Œä»¥çº¿ç´¢ä¸ºå¯¼å‘çš„æ–¹æ³•åœ¨å¤æ‚åœºæ™¯ä¸­æœªèƒ½æœ‰æ•ˆåˆ©ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚ä¸ºäº†è§£å†³è¿™äº›å±€é™æ€§ï¼Œæˆ‘ä»¬æå‡ºäº†æŒ‡å¯¼å›¾å¼•å¯¼çš„çŸ¥è¯†æ¢ç´¢ï¼ˆGG Exploreï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ä¸­é—´çš„æŒ‡å¯¼å›¾æ¥æ¡¥æ¥éç»“æ„åŒ–æŸ¥è¯¢ä¸ç»“æ„åŒ–çŸ¥è¯†æ£€ç´¢ã€‚æŒ‡å¯¼å›¾é€šè¿‡æŠ½è±¡ç›®æ ‡çŸ¥è¯†çš„ç»“æ„åŒæ—¶ä¿ç•™æ›´å¹¿æ³›çš„è¯­ä¹‰ä¸Šä¸‹æ–‡æ¥å®šä¹‰æ£€ç´¢ç©ºé—´ï¼Œä»è€Œå®ç°ç²¾ç¡®ä¸”é«˜æ•ˆçš„æ¢ç´¢ã€‚åœ¨æŒ‡å¯¼å›¾çš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¼€å‘äº†ï¼š (1) ç»“æ„å¯¹é½ï¼Œç”¨äºåœ¨ä¸å¢åŠ  LLM å¼€é”€çš„æƒ…å†µä¸‹è¿‡æ»¤ä¸å…¼å®¹çš„å€™é€‰é¡¹ï¼›ä»¥åŠ (2) ä¸Šä¸‹æ–‡æ„ŸçŸ¥å‰ªæï¼Œç”¨ä»¥é€šè¿‡å›¾çº¦æŸå¼ºåˆ¶æ‰§è¡Œè¯­ä¹‰ä¸€è‡´æ€§ã€‚ å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ•ˆç‡ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿å¹¶ä¼˜äºå½“å‰æœ€å…ˆè¿›æ–¹æ³•ï¼ˆSOTAï¼‰ï¼Œå°¤å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°çªå‡ºï¼ŒåŒæ—¶åœ¨è¾ƒå°çš„ LLMs ä¸Šä»èƒ½ä¿æŒå¼ºåŠ²æ€§èƒ½ï¼Œæ˜¾ç¤ºå‡ºå®é™…ä»·å€¼ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-06 08:47:57 UTC
å‘å¸ƒï¼š2025-08-06 08:47:57 UTC</p>
<h2 id="59-evaluation-of-gpt-based-large-language-generative-ai-models-as-study-aids-for-the-national-licensure-examination-for-registered-dietitians-in-japan--59-å°†åŸºäº-gpt-çš„å¤§å‹è¯­è¨€ç”Ÿæˆå‹äººå·¥æ™ºèƒ½æ¨¡å‹ä½œä¸ºæ—¥æœ¬æ³¨å†Œè¥å…»å¸ˆå›½å®¶æ‰§ç…§è€ƒè¯•å­¦ä¹ è¾…åŠ©å·¥å…·çš„è¯„ä¼°"><a href="https://arxiv.org/abs/2508.10011"target="_blank" rel="external nofollow noopener noreferrer">#59</a> <a href="https://papers.cool/arxiv/2508.10011"target="_blank" rel="external nofollow noopener noreferrer">Evaluation of GPT-based large language generative AI models as study aids for the national licensure examination for registered dietitians in Japan</a>  #59 å°†åŸºäº GPT çš„å¤§å‹è¯­è¨€ç”Ÿæˆå‹äººå·¥æ™ºèƒ½æ¨¡å‹ä½œä¸ºæ—¥æœ¬æ³¨å†Œè¥å…»å¸ˆå›½å®¶æ‰§ç…§è€ƒè¯•å­¦ä¹ è¾…åŠ©å·¥å…·çš„è¯„ä¼°</h2>
<p><strong>Authors</strong>: [Yuta Nagamori](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuta"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuta</a> Nagamori), [Mikoto Kosai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mikoto"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mikoto</a> Kosai), [Yuji Kawai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuji</a> Kawai), [Haruka Marumo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haruka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haruka</a> Marumo), [Misaki Shibuya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Misaki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Misaki</a> Shibuya), [Tatsuya Negishi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tatsuya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tatsuya</a> Negishi), [Masaki Imanishi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Masaki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Masaki</a> Imanishi), [Yasumasa Ikeda](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yasumasa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yasumasa</a> Ikeda), [Koichiro Tsuchiya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Koichiro"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Koichiro</a> Tsuchiya), [Asuka Sawai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Asuka"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Asuka</a> Sawai), [Licht Miyamoto](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Licht"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Licht</a> Miyamoto)
ä½œè€…ï¼šæ°¸æ£®é›„å¤ªã€é¦™è¥¿æœªç´ã€æ²³åˆç¥å¸ã€ä¸¸èŒ‚æ˜¥é¦™ã€æ¸‹è°·ç¾å’²ã€æ ¹å²¸é”ä¹Ÿã€ä»Šè¥¿å°†æ¨¹ã€æ± ç”°åº·æ­£ã€åœŸå±‹æµ©ä¸€éƒã€æ¾¤äº•æ˜æ—¥é¦™ã€ãƒ©ã‚¤ãƒˆãƒ»å®®æœ¬</p>
<p>Generative artificial intelligence (AI) based on large language models (LLMs), such as ChatGPT, has demonstrated remarkable progress across various professional fields, including medicine and education. However, their performance in nutritional education, especially in Japanese national licensure examination for registered dietitians, remains underexplored. This study aimed to evaluate the potential of current LLM-based generative AI models as study aids for nutrition students. Questions from the Japanese national examination for registered dietitians were used as prompts for ChatGPT and three Bing models (Precise, Creative, Balanced), based on GPT-3.5 and GPT-4. Each question was entered into independent sessions, and model responses were analyzed for accuracy, consistency, and response time. Additional prompt engineering, including role assignment, was tested to assess potential performance improvements. Bing-Precise (66.2%) and Bing-Creative (61.4%) surpassed the passing threshold (60%), while Bing-Balanced (43.3%) and ChatGPT (42.8%) did not. Bing-Precise and Bing-Creative generally outperformed others across subject fields except Nutrition Education, where all models underperformed. None of the models consistently provided the same correct responses across repeated attempts, highlighting limitations in answer stability. ChatGPT showed greater consistency in response patterns but lower accuracy. Prompt engineering had minimal effect, except for modest improvement when correct answers and explanations were explicitly provided. While some generative AI models marginally exceeded the passing threshold, overall accuracy and answer consistency remained suboptimal. Moreover, all the models demonstrated notable limitations in answer consistency and robustness. Further advancements are needed to ensure reliable and stable AI-based study aids for dietitian licensure preparation.
åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ï¼Œä¾‹å¦‚ ChatGPTï¼Œåœ¨åŒ…æ‹¬åŒ»å­¦å’Œæ•™è‚²ç­‰å¤šä¸ªä¸“ä¸šé¢†åŸŸè¡¨ç°å‡ºæ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œå®ƒä»¬åœ¨è¥å…»æ•™è‚²æ–¹é¢çš„è¡¨ç°ï¼Œç‰¹åˆ«æ˜¯åœ¨æ—¥æœ¬æ³¨å†Œè¥å…»å¸ˆå›½å®¶æ‰§ç…§è€ƒè¯•ä¸­çš„è¡¨ç°ï¼Œä»ç„¶é²œæœ‰ç ”ç©¶ã€‚æœ¬ç ”ç©¶æ—¨åœ¨è¯„ä¼°å½“å‰åŸºäº LLMs çš„ç”Ÿæˆå¼ AI æ¨¡å‹ä½œä¸ºè¥å…»å­¦å­¦ç”Ÿå­¦ä¹ è¾…åŠ©å·¥å…·çš„æ½œåŠ›ã€‚æˆ‘ä»¬ä½¿ç”¨æ—¥æœ¬æ³¨å†Œè¥å…»å¸ˆå›½å®¶è€ƒè¯•ä¸­çš„è¯•é¢˜ä½œä¸ºæç¤ºï¼Œæµ‹è¯•äº† ChatGPT å’Œä¸‰ç§åŸºäº GPT-3.5 ä¸ GPT-4 çš„ Bing æ¨¡å‹ï¼ˆPreciseã€Creativeã€Balancedï¼‰ã€‚æ¯é“é¢˜ç›®åœ¨ç‹¬ç«‹ä¼šè¯ä¸­è¾“å…¥ï¼Œåˆ†ææ¨¡å‹å›ç­”çš„å‡†ç¡®æ€§ã€ä¸€è‡´æ€§å’Œå“åº”æ—¶é—´ã€‚è¿˜æµ‹è¯•äº†åŒ…æ‹¬è§’è‰²è®¾å®šåœ¨å†…çš„é¢å¤–æç¤ºå·¥ç¨‹ï¼Œä»¥è¯„ä¼°æ½œåœ¨çš„æ€§èƒ½æå‡ã€‚Bing-Preciseï¼ˆ66.2%ï¼‰å’Œ Bing-Creativeï¼ˆ61.4%ï¼‰è¶…è¿‡äº†åŠæ ¼çº¿ï¼ˆ60%ï¼‰ï¼Œè€Œ Bing-Balancedï¼ˆ43.3%ï¼‰å’Œ ChatGPTï¼ˆ42.8%ï¼‰æœªè¾¾åˆ°åŠæ ¼çº¿ã€‚ Bing-Precise å’Œ Bing-Creative åœ¨å¤§å¤šæ•°å­¦ç§‘é¢†åŸŸçš„è¡¨ç°é€šå¸¸ä¼˜äºå…¶ä»–æ¨¡å‹ï¼Œä½†åœ¨è¥å…»æ•™è‚²é¢†åŸŸæ‰€æœ‰æ¨¡å‹çš„è¡¨ç°éƒ½ä¸ä½³ã€‚æ²¡æœ‰ä»»ä½•æ¨¡å‹åœ¨é‡å¤å°è¯•ä¸­å§‹ç»ˆæä¾›ç›¸åŒçš„æ­£ç¡®ç­”æ¡ˆï¼Œçªæ˜¾äº†ç­”æ¡ˆç¨³å®šæ€§çš„å±€é™æ€§ã€‚ChatGPT åœ¨å“åº”æ¨¡å¼ä¸Šè¡¨ç°å‡ºæ›´é«˜çš„ä¸€è‡´æ€§ï¼Œä½†å‡†ç¡®æ€§è¾ƒä½ã€‚æç¤ºå·¥ç¨‹å‡ ä¹æ²¡æœ‰æ•ˆæœï¼Œåªæœ‰åœ¨æ˜ç¡®æä¾›æ­£ç¡®ç­”æ¡ˆå’Œè§£é‡Šæ—¶æ‰æœ‰å°å¹…æ”¹è¿›ã€‚å°½ç®¡ä¸€äº›ç”Ÿæˆå¼ AI æ¨¡å‹ç•¥å¾®è¶…è¿‡äº†åŠæ ¼çº¿ï¼Œä½†æ€»ä½“å‡†ç¡®æ€§å’Œç­”æ¡ˆä¸€è‡´æ€§ä»ä¸ç†æƒ³ã€‚æ­¤å¤–ï¼Œæ‰€æœ‰æ¨¡å‹åœ¨ç­”æ¡ˆä¸€è‡´æ€§å’Œé²æ£’æ€§æ–¹é¢éƒ½è¡¨ç°å‡ºæ˜¾è‘—å±€é™ã€‚è¦ç¡®ä¿ç”¨äºè¥å…»å¸ˆæ‰§ç…§å¤‡è€ƒçš„ AI å­¦ä¹ è¾…åŠ©å·¥å…·å¯é ä¸”ç¨³å®šï¼Œè¿˜éœ€è¿›ä¸€æ­¥æ”¹è¿›ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-05 03:33:11 UTC
å‘å¸ƒï¼š2025-08-05 03:33:11 UTC</p>
<h2 id="60-an-audit-and-analysis-of-llm-assisted-health-misinformation-jailbreaks-against-llms--60-åŸºäº-llm-è¾…åŠ©çš„é’ˆå¯¹-llm-çš„å¥åº·é”™è¯¯ä¿¡æ¯è¶Šç‹±æ”»å‡»çš„å®¡è®¡ä¸åˆ†æ"><a href="https://arxiv.org/abs/2508.10010"target="_blank" rel="external nofollow noopener noreferrer">#60</a> <a href="https://papers.cool/arxiv/2508.10010"target="_blank" rel="external nofollow noopener noreferrer">An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs</a>  #60 åŸºäº LLM è¾…åŠ©çš„é’ˆå¯¹ LLM çš„å¥åº·é”™è¯¯ä¿¡æ¯è¶Šç‹±æ”»å‡»çš„å®¡è®¡ä¸åˆ†æ</h2>
<p><strong>Authors</strong>: [Ayana Hussain](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ayana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ayana</a> Hussain), [Patrick Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Patrick"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Patrick</a> Zhao), [Nicholas Vincent](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicholas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicholas</a> Vincent)
ä½œè€…ï¼šAyana Hussainï¼ŒPatrick Zhaoï¼ŒNicholas Vincent</p>
<p>Large Language Models (LLMs) are a double-edged sword capable of generating harmful misinformation &ndash; inadvertently, or when prompted by &ldquo;jailbreak&rdquo; attacks that attempt to produce malicious outputs. LLMs could, with additional research, be used to detect and prevent the spread of misinformation. In this paper, we investigate the efficacy and characteristics of LLM-produced jailbreak attacks that cause other models to produce harmful medical misinformation. We also study how misinformation generated by jailbroken LLMs compares to typical misinformation found on social media, and how effectively it can be detected using standard machine learning approaches. Specifically, we closely examine 109 distinct attacks against three target LLMs and compare the attack prompts to in-the-wild health-related LLM queries. We also examine the resulting jailbreak responses, comparing the generated misinformation to health-related misinformation on Reddit. Our findings add more evidence that LLMs can be effectively used to detect misinformation from both other LLMs and from people, and support a body of work suggesting that with careful design, LLMs can contribute to a healthier overall information ecosystem.
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯ä¸€æŠŠåŒåˆƒå‰‘ï¼Œèƒ½å¤Ÿç”Ÿæˆæœ‰å®³çš„é”™è¯¯ä¿¡æ¯â€”â€”æ— è®ºæ˜¯æ— æ„é—´ï¼Œè¿˜æ˜¯åœ¨è¢«â€œè¶Šç‹±â€æ”»å‡»æç¤ºä»¥è¯•å›¾ç”Ÿæˆæ¶æ„è¾“å‡ºæ—¶ã€‚é€šè¿‡è¿›ä¸€æ­¥ç ”ç©¶ï¼ŒLLM ä¹Ÿå¯èƒ½è¢«ç”¨äºæ£€æµ‹å¹¶é˜²æ­¢é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å¯¼è‡´å…¶ä»–æ¨¡å‹ç”Ÿæˆæœ‰å®³åŒ»ç–—é”™è¯¯ä¿¡æ¯çš„ LLM ç”Ÿæˆè¶Šç‹±æ”»å‡»çš„æœ‰æ•ˆæ€§ä¸ç‰¹å¾ã€‚æˆ‘ä»¬è¿˜ç ”ç©¶äº†è¶Šç‹± LLM ç”Ÿæˆçš„é”™è¯¯ä¿¡æ¯ä¸ç¤¾äº¤åª’ä½“ä¸Šå…¸å‹é”™è¯¯ä¿¡æ¯çš„æ¯”è¾ƒï¼Œä»¥åŠä½¿ç”¨æ ‡å‡†æœºå™¨å­¦ä¹ æ–¹æ³•æ£€æµ‹å…¶æœ‰æ•ˆæ€§çš„ç¨‹åº¦ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬ä»”ç»†æ£€æŸ¥äº†é’ˆå¯¹ä¸‰ç§ç›®æ ‡ LLM çš„ 109 æ¬¡ä¸åŒæ”»å‡»ï¼Œå¹¶å°†æ”»å‡»æç¤ºä¸é‡å¤–ï¼ˆin-the-wildï¼‰ä¸å¥åº·ç›¸å…³çš„ LLM æŸ¥è¯¢è¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬è¿˜æ£€æŸ¥äº†ç”±è¶Šç‹±äº§ç”Ÿçš„å“åº”ï¼Œå°†ç”Ÿæˆçš„é”™è¯¯ä¿¡æ¯ä¸ Reddit ä¸Šçš„å¥åº·ç›¸å…³é”™è¯¯ä¿¡æ¯è¿›è¡Œæ¯”è¾ƒã€‚ æˆ‘ä»¬çš„å‘ç°è¿›ä¸€æ­¥è¯æ˜ï¼ŒLLMs å¯ä»¥æœ‰æ•ˆç”¨äºæ£€æµ‹æ¥è‡ªå…¶ä»– LLMs å’Œäººç±»çš„é”™è¯¯ä¿¡æ¯ï¼Œå¹¶æ”¯æŒä¸€ç³»åˆ—ç ”ç©¶æˆæœï¼Œè¡¨æ˜é€šè¿‡æ…é‡è®¾è®¡ï¼ŒLLMs èƒ½å¤Ÿä¿ƒè¿›æ›´å¥åº·çš„æ•´ä½“ä¿¡æ¯ç”Ÿæ€ç³»ç»Ÿã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-08-06 02:14:28 UTC
å‘å¸ƒï¼š2025-08-06 02:14:28 UTC</p>
<h2 id="61-beyond-hard-sharing-efficient-multi-task-speech-to-text-modeling-with-supervised-mixture-of-experts--61-è¶…è¶Šç¡¬å…±äº«ä½¿ç”¨ç›‘ç£ä¸“å®¶æ··åˆçš„é«˜æ•ˆå¤šä»»åŠ¡è¯­éŸ³åˆ°æ–‡æœ¬å»ºæ¨¡"><a href="https://arxiv.org/abs/2508.10009"target="_blank" rel="external nofollow noopener noreferrer">#61</a> <a href="https://papers.cool/arxiv/2508.10009"target="_blank" rel="external nofollow noopener noreferrer">Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts</a>  #61 è¶…è¶Šç¡¬å…±äº«ï¼šä½¿ç”¨ç›‘ç£ä¸“å®¶æ··åˆçš„é«˜æ•ˆå¤šä»»åŠ¡è¯­éŸ³åˆ°æ–‡æœ¬å»ºæ¨¡</h2>
<p><strong>Authors</strong>: [Hojun Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hojun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hojun</a> Jin), [Eunsoo Hong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eunsoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eunsoo</a> Hong), [Ziwon Hyung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziwon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziwon</a> Hyung), [Sungjun Lim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sungjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sungjun</a> Lim), [Seungjin Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seungjin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seungjin</a> Lee), [Keunseok Cho](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keunseok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keunseok</a> Cho)
ä½œè€…ï¼šHojun Jinã€Eunsoo Hongã€Ziwon Hyungã€Sungjun Limã€Seungjin Leeã€Keunseok Cho</p>
<p>Hard-parameter sharing is a common strategy to train a single model jointly across diverse tasks. However, this often leads to task interference, impeding overall model performance. To address the issue, we propose a simple yet effective Supervised Mixture of Experts (S-MoE). Unlike traditional Mixture of Experts models, S-MoE eliminates the need for training gating functions by utilizing special guiding tokens to route each task to its designated expert. By assigning each task to a separate feedforward network, S-MoE overcomes the limitations of hard-parameter sharing. We further apply S-MoE to a speech-to-text model, enabling the model to process mixed-bandwidth input while jointly performing automatic speech recognition (ASR) and speech translation (ST). Experimental results demonstrate the effectiveness of the proposed S-MoE, achieving a 6.35% relative improvement in Word Error Rate (WER) when applied to both the encoder and decoder.
ç¡¬å‚æ•°å…±äº«æ˜¯è·¨å¤šä»»åŠ¡è”åˆè®­ç»ƒå•ä¸€æ¨¡å‹çš„å¸¸ç”¨ç­–ç•¥ã€‚ç„¶è€Œï¼Œè¿™å¸¸å¸¸å¯¼è‡´ä»»åŠ¡é—´å¹²æ‰°ï¼Œé˜»ç¢æ¨¡å‹æ•´ä½“æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç›‘ç£æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆS-MoEï¼‰ã€‚ä¸ä¼ ç»Ÿçš„æ··åˆä¸“å®¶æ¨¡å‹ä¸åŒï¼ŒS-MoE é€šè¿‡ä½¿ç”¨ç‰¹æ®Šçš„æŒ‡å¯¼æ ‡è®°å°†æ¯ä¸ªä»»åŠ¡è·¯ç”±åˆ°å…¶æŒ‡å®šçš„ä¸“å®¶ï¼Œä»è€Œæ¶ˆé™¤äº†è®­ç»ƒé—¨æ§å‡½æ•°çš„éœ€è¦ã€‚é€šè¿‡ä¸ºæ¯ä¸ªä»»åŠ¡åˆ†é…å•ç‹¬çš„å‰é¦ˆç½‘ç»œï¼ŒS-MoE å…‹æœäº†ç¡¬å‚æ•°å…±äº«çš„å±€é™æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°† S-MoE åº”ç”¨äºè¯­éŸ³è½¬æ–‡æœ¬æ¨¡å‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†æ··åˆå¸¦å®½è¾“å…¥ï¼ŒåŒæ—¶è”åˆæ‰§è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œè¯­éŸ³ç¿»è¯‘ï¼ˆSTï¼‰ã€‚å®éªŒç»“æœè¯æ˜äº†æ‰€æå‡ºçš„ S-MoE çš„æœ‰æ•ˆæ€§ï¼Œå½“åŒæ—¶åº”ç”¨äºç¼–ç å™¨å’Œè§£ç å™¨æ—¶ï¼Œåœ¨å­—è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ä¸Šå®ç°äº† 6.35% çš„ç›¸å¯¹æ”¹è¿›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">Sound</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">Audio and Speech Processing</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€å£°éŸ³ã€éŸ³é¢‘ä¸è¯­éŸ³å¤„ç†</p>
<p><strong>Publish</strong>: 2025-08-05 23:56:11 UTC
å‘å¸ƒï¼š2025-08-05 23:56:11 UTC</p>
<h2 id="62-multidimensional-classification-of-posts-for-online-course-discussion-forum-curation--62-ç”¨äºåœ¨çº¿è¯¾ç¨‹è®¨è®ºåŒºç­–åˆ’çš„å¸–å­å¤šç»´åˆ†ç±»"><a href="https://arxiv.org/abs/2508.10008"target="_blank" rel="external nofollow noopener noreferrer">#62</a> <a href="https://papers.cool/arxiv/2508.10008"target="_blank" rel="external nofollow noopener noreferrer">Multidimensional classification of posts for online course discussion forum curation</a>  #62 ç”¨äºåœ¨çº¿è¯¾ç¨‹è®¨è®ºåŒºç­–åˆ’çš„å¸–å­å¤šç»´åˆ†ç±»</h2>
<p><strong>Authors</strong>: [Antonio Leandro Martins Candido](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Antonio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Antonio</a> Leandro Martins Candido), [Jose Everardo Bessa Maia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jose"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jose</a> Everardo Bessa Maia)
ä½œè€…ï¼šå®‰ä¸œå°¼å¥¥Â·åˆ©å®‰å¾·ç½—Â·é©¬ä¸æ–¯Â·åè¿ªå¤šï¼Œä½•å¡Â·åŸƒéŸ¦æ‹‰å°”å¤šÂ·è´è¨Â·è¿ˆäºš</p>
<p>The automatic curation of discussion forums in online courses requires constant updates, making frequent retraining of Large Language Models (LLMs) a resource-intensive process. To circumvent the need for costly fine-tuning, this paper proposes and evaluates the use of Bayesian fusion. The approach combines the multidimensional classification scores of a pre-trained generic LLM with those of a classifier trained on local data. The performance comparison demonstrated that the proposed fusion improves the results compared to each classifier individually, and is competitive with the LLM fine-tuning approach
åœ¨çº¿è¯¾ç¨‹è®¨è®ºè®ºå›çš„è‡ªåŠ¨ç­–å±•éœ€è¦ä¸æ–­æ›´æ–°ï¼Œè¿™ä½¿å¾—å¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œé¢‘ç¹å†è®­ç»ƒæˆä¸ºä¸€é¡¹èµ„æºå¯†é›†å‹çš„å·¥ä½œã€‚ä¸ºé¿å…æ˜‚è´µçš„å¾®è°ƒéœ€æ±‚ï¼Œæœ¬æ–‡æå‡ºå¹¶è¯„ä¼°äº†è´å¶æ–¯èåˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†é¢„è®­ç»ƒé€šç”¨ LLM çš„å¤šç»´åˆ†ç±»åˆ†æ•°ä¸åœ¨æœ¬åœ°æ•°æ®ä¸Šè®­ç»ƒçš„åˆ†ç±»å™¨çš„åˆ†æ•°ç›¸ç»“åˆã€‚æ€§èƒ½å¯¹æ¯”è¡¨æ˜ï¼Œæ‰€æå‡ºçš„èåˆæ–¹æ³•è¾ƒå•ä¸ªåˆ†ç±»å™¨å‡æœ‰æå‡ï¼Œå¹¶ä¸”åœ¨ç«äº‰åŠ›ä¸Šå¯ä¸ LLM å¾®è°ƒæ–¹æ³•ç›¸åª²ç¾</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-05 22:53:01 UTC
å‘å¸ƒï¼š2025-08-05 22:53:01 UTC</p>
<h2 id="63-automated-scoring-of-the-ambiguous-intentions-hostility-questionnaire-using-fine-tuned-large-language-models--63-ä½¿ç”¨å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹å¯¹æ¨¡ç³Šæ„å›¾æ•Œæ„é—®å·è¿›è¡Œè‡ªåŠ¨è¯„åˆ†"><a href="https://arxiv.org/abs/2508.10007"target="_blank" rel="external nofollow noopener noreferrer">#63</a> <a href="https://papers.cool/arxiv/2508.10007"target="_blank" rel="external nofollow noopener noreferrer">Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models</a>  #63 ä½¿ç”¨å¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹å¯¹æ¨¡ç³Šæ„å›¾æ•Œæ„é—®å·è¿›è¡Œè‡ªåŠ¨è¯„åˆ†</h2>
<p><strong>Authors</strong>: [Y. Lyu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Y"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Y</a>. Lyu), [D. Combs](<a href="https://arxiv.org/search/?searchtype=author&amp;query=D"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=D</a>. Combs), [D. Neumann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=D"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=D</a>. Neumann), [Y. C. Leong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Y"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Y</a>. C. Leong)
ä½œè€…ï¼šY. å•ã€D. åº·å¸ƒæ–¯ã€D. çº½æ›¼ã€Y. C. æ¢</p>
<p>Hostile attribution bias is the tendency to interpret social interactions as intentionally hostile. The Ambiguous Intentions Hostility Questionnaire (AIHQ) is commonly used to measure hostile attribution bias, and includes open-ended questions where participants describe the perceived intentions behind a negative social situation and how they would respond. While these questions provide insights into the contents of hostile attributions, they require time-intensive scoring by human raters. In this study, we assessed whether large language models can automate the scoring of AIHQ open-ended responses. We used a previously collected dataset in which individuals with traumatic brain injury (TBI) and healthy controls (HC) completed the AIHQ and had their open-ended responses rated by trained human raters. We used half of these responses to fine-tune the two models on human-generated ratings, and tested the fine-tuned models on the remaining half of AIHQ responses. Results showed that model-generated ratings aligned with human ratings for both attributions of hostility and aggression responses, with fine-tuned models showing higher alignment. This alignment was consistent across ambiguous, intentional, and accidental scenario types, and replicated previous findings on group differences in attributions of hostility and aggression responses between TBI and HC groups. The fine-tuned models also generalized well to an independent nonclinical dataset. To support broader adoption, we provide an accessible scoring interface that includes both local and cloud-based options. Together, our findings suggest that large language models can streamline AIHQ scoring in both research and clinical contexts, revealing their potential to facilitate psychological assessments across different populations.
æ•Œæ„å½’å› åå·®æ˜¯å°†ç¤¾ä¼šäº’åŠ¨è§£è¯»ä¸ºæœ‰æ„æ•Œå¯¹çš„ä¸€ç§å€¾å‘ã€‚ã€Šæ„å›¾æ¨¡ç³Šæ•Œæ„é—®å·ã€‹ï¼ˆAIHQï¼‰å¸¸ç”¨äºæµ‹é‡æ•Œæ„å½’å› åå·®ï¼Œå…¶ä¸­åŒ…å«å¼€æ”¾å¼é—®é¢˜ï¼Œè¦æ±‚å‚ä¸è€…æè¿°åœ¨è´Ÿé¢ç¤¾äº¤æƒ…å¢ƒä¸­æ‰€æ„ŸçŸ¥çš„æ„å›¾ä»¥åŠä»–ä»¬ä¼šå¦‚ä½•å›åº”ã€‚å°½ç®¡è¿™äº›é—®é¢˜èƒ½æä¾›å…³äºæ•Œæ„å½’å› å†…å®¹çš„è§è§£ï¼Œä½†éœ€è¦äººå·¥è¯„åˆ†å‘˜è¿›è¡Œè€—æ—¶çš„è¯„åˆ†ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹èƒ½å¦è‡ªåŠ¨åŒ–è¯„åˆ† AIHQ çš„å¼€æ”¾å¼å›åº”ã€‚æˆ‘ä»¬ä½¿ç”¨äº†å…ˆå‰æ”¶é›†çš„æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†ä¸­æœ‰åˆ›ä¼¤æ€§è„‘æŸä¼¤ï¼ˆTBIï¼‰ä¸ªä½“å’Œå¥åº·å¯¹ç…§ï¼ˆHCï¼‰å®Œæˆäº† AIHQï¼Œå¹¶ç”±å—è®­çš„äººç±»è¯„åˆ†å‘˜å¯¹å…¶å¼€æ”¾å¼å›åº”è¿›è¡Œè¯„åˆ†ã€‚æˆ‘ä»¬ä½¿ç”¨å…¶ä¸­ä¸€åŠçš„å›åº”å¯¹ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œäº†ä»¥äººç±»è¯„åˆ†ä¸ºç›®æ ‡çš„å¾®è°ƒï¼Œå¹¶åœ¨å‰©ä½™ä¸€åŠ AIHQ å›åº”ä¸Šæµ‹è¯•äº†å¾®è°ƒåçš„æ¨¡å‹ã€‚ç»“æœæ˜¾ç¤ºï¼Œæ¨¡å‹ç”Ÿæˆçš„è¯„åˆ†ä¸äººç±»è¯„åˆ†åœ¨æ•Œæ„å½’å› å’Œæ”»å‡»æ€§å›åº”æ–¹é¢ä¸€è‡´ï¼Œä¸”å¾®è°ƒåçš„æ¨¡å‹è¡¨ç°å‡ºæ›´é«˜çš„ä¸€è‡´æ€§ã€‚ è¿™ç§ä¸€è‡´æ€§åœ¨å«ç³Šã€è“„æ„å’Œæ„å¤–æƒ…å¢ƒç±»å‹ä¸­å‡æœ‰æ‰€ä½“ç°ï¼Œå¹¶å¤åˆ¶äº†æ—¢æœ‰å…³äº TBI ç»„ä¸ HC ç»„åœ¨æ•Œæ„å½’å› å’Œæ”»å‡»ååº”å½’å› å·®å¼‚çš„ç ”ç©¶ç»“æœã€‚å¾®è°ƒåçš„æ¨¡å‹åœ¨ä¸€ä¸ªç‹¬ç«‹çš„éä¸´åºŠæ•°æ®é›†ä¸Šä¹Ÿæœ‰å¾ˆå¥½çš„æ³›åŒ–è¡¨ç°ã€‚ä¸ºæ”¯æŒæ›´å¹¿æ³›çš„é‡‡ç”¨ï¼Œæˆ‘ä»¬æä¾›äº†ä¸€ä¸ªå¯è®¿é—®çš„è¯„åˆ†ç•Œé¢ï¼ŒåŒ…å«æœ¬åœ°å’Œäº‘ç«¯é€‰é¡¹ã€‚ç»¼ä¸Šæ‰€è¿°ï¼Œæˆ‘ä»¬çš„å‘ç°è¡¨æ˜ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹å¯ä»¥åœ¨ç ”ç©¶å’Œä¸´åºŠç¯å¢ƒä¸­ç®€åŒ– AIHQ è¯„åˆ†ï¼Œå±•ç°å‡ºå…¶åœ¨ä¸åŒäººç¾¤ä¸­ä¿ƒè¿›å¿ƒç†è¯„ä¼°çš„æ½œåŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/stat.ME"target="_blank" rel="external nofollow noopener noreferrer">Methodology</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œæ–¹æ³•è®º</p>
<p><strong>Publish</strong>: 2025-08-05 21:58:11 UTC
å‘å¸ƒï¼š2025-08-05 21:58:11 UTC</p>
<h2 id="64-from-answers-to-questions-eqgbench-for-evaluating-llms39-educational-question-generation--64-ä»ç­”æ¡ˆåˆ°é—®é¢˜ç”¨äºè¯„ä¼°-llms-æ•™è‚²æ€§é—®é¢˜ç”Ÿæˆçš„-eqgbench"><a href="https://arxiv.org/abs/2508.10005"target="_blank" rel="external nofollow noopener noreferrer">#64</a> <a href="https://papers.cool/arxiv/2508.10005"target="_blank" rel="external nofollow noopener noreferrer">From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation</a>  #64 ä»ç­”æ¡ˆåˆ°é—®é¢˜ï¼šç”¨äºè¯„ä¼° LLMs æ•™è‚²æ€§é—®é¢˜ç”Ÿæˆçš„ EQGBench</h2>
<p><strong>Authors</strong>: [Chengliang Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengliang</a> Zhou), [Mei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mei</a> Wang), [Ting Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ting"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ting</a> Zhang), [Qiannan Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiannan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiannan</a> Zhu), [Jian Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Li), [Hua Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hua</a> Huang)
ä½œè€…ï¼šå‘¨æˆäº®ï¼Œç‹æ¢…ï¼Œå¼ å©·ï¼Œæœ±å€©æ¥ ï¼Œæå‰‘ï¼Œé»„å</p>
<p>Large Language Models (LLMs) have demonstrated remarkable capabilities in mathematical problem-solving. However, the transition from providing answers to generating high-quality educational questions presents significant challenges that remain underexplored. To advance Educational Question Generation (EQG) and facilitate LLMs in generating pedagogically valuable and educationally effective questions, we introduce EQGBench, a comprehensive benchmark specifically designed for evaluating LLMs&rsquo; performance in Chinese EQG. EQGBench establishes a five-dimensional evaluation framework supported by a dataset of 900 evaluation samples spanning three fundamental middle school disciplines: mathematics, physics, and chemistry. The dataset incorporates user queries with varying knowledge points, difficulty gradients, and question type specifications to simulate realistic educational scenarios. Through systematic evaluation of 46 mainstream large models, we reveal significant room for development in generating questions that reflect educational value and foster students&rsquo; comprehensive abilities.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦é—®é¢˜æ±‚è§£æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä»ç›´æ¥ç»™å‡ºç­”æ¡ˆåˆ°ç”Ÿæˆé«˜è´¨é‡æ•™è‚²æ€§é—®é¢˜çš„è¿‡æ¸¡ä»ç„¶å­˜åœ¨é‡å¤§æŒ‘æˆ˜ï¼Œä¸”è¿™äº›æŒ‘æˆ˜å°šæœªè¢«å……åˆ†æ¢è®¨ã€‚ä¸ºæ¨åŠ¨æ•™è‚²é—®é¢˜ç”Ÿæˆï¼ˆEQGï¼‰ç ”ç©¶å¹¶å¸®åŠ© LLMs ç”Ÿæˆå…·æœ‰æ•™å­¦ä»·å€¼å’Œæ•™è‚²æœ‰æ•ˆæ€§çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† EQGBenchâ€”â€”ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼° LLMs åœ¨ä¸­æ–‡ EQG è¡¨ç°çš„ç»¼åˆåŸºå‡†ã€‚EQGBench å»ºç«‹äº†ä¸€ä¸ªç”±äº”ä¸ªç»´åº¦ç»„æˆçš„è¯„ä¼°æ¡†æ¶ï¼Œå¹¶åŸºäºæ¶µç›–åˆä¸­ä¸‰é—¨åŸºç¡€å­¦ç§‘ï¼ˆæ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦ï¼‰çš„ 900 ä¸ªè¯„ä¼°æ ·æœ¬æ„å»ºæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«å…·æœ‰ä¸åŒçŸ¥è¯†ç‚¹ã€éš¾åº¦æ¢¯åº¦å’Œé¢˜å‹è¦æ±‚çš„ç”¨æˆ·æŸ¥è¯¢ï¼Œä»¥æ¨¡æ‹ŸçœŸå®çš„æ•™è‚²åœºæ™¯ã€‚é€šè¿‡å¯¹ 46 ä¸ªä¸»æµå¤§æ¨¡å‹çš„ç³»ç»Ÿè¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°è¿™äº›æ¨¡å‹åœ¨ç”Ÿæˆå…·æœ‰æ•™è‚²ä»·å€¼å¹¶ä¿ƒè¿›å­¦ç”Ÿç»¼åˆèƒ½åŠ›çš„é—®é¢˜æ–¹é¢ä»æœ‰æ˜¾è‘—æå‡ç©ºé—´ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-05 14:16:42 UTC
å‘å¸ƒï¼š2025-08-05 14:16:42 UTC</p>
<h2 id="65-user-perception-of-attention-visualizations-effects-on-interpretability-across-evidence-based-medical-documents--65-ç”¨æˆ·å¯¹æ³¨æ„åŠ›å¯è§†åŒ–çš„æ„ŸçŸ¥åœ¨åŸºäºè¯æ®çš„åŒ»å­¦æ–‡æ¡£ä¸­å¯¹å¯è§£é‡Šæ€§çš„å½±å“"><a href="https://arxiv.org/abs/2508.10004"target="_blank" rel="external nofollow noopener noreferrer">#65</a> <a href="https://papers.cool/arxiv/2508.10004"target="_blank" rel="external nofollow noopener noreferrer">User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents</a>  #65 ç”¨æˆ·å¯¹æ³¨æ„åŠ›å¯è§†åŒ–çš„æ„ŸçŸ¥ï¼šåœ¨åŸºäºè¯æ®çš„åŒ»å­¦æ–‡æ¡£ä¸­å¯¹å¯è§£é‡Šæ€§çš„å½±å“</h2>
<p><strong>Authors</strong>: [AndrÃ©s Carvallo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andr"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andr</a>Ã©s Carvallo), [Denis Parra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Denis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Denis</a> Parra), [Peter Brusilovsky](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peter"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peter</a> Brusilovsky), [Hernan Valdivieso](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hernan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hernan</a> Valdivieso), [Gabriel Rada](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gabriel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gabriel</a> Rada), [Ivania Donoso](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivania"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivania</a> Donoso), [Vladimir Araujo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vladimir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vladimir</a> Araujo)
ä½œè€…ï¼šAndrÃ©s Carvalloã€Denis Parraã€Peter Brusilovskyã€Hernan Valdiviesoã€Gabriel Radaã€Ivania Donosoã€Vladimir Araujo</p>
<p>The attention mechanism is a core component of the Transformer architecture. Beyond improving performance, attention has been proposed as a mechanism for explainability via attention weights, which are associated with input features (e.g., tokens in a document). In this context, larger attention weights may imply more relevant features for the model&rsquo;s prediction. In evidence-based medicine, such explanations could support physicians&rsquo; understanding and interaction with AI systems used to categorize biomedical literature. However, there is still no consensus on whether attention weights provide helpful explanations. Moreover, little research has explored how visualizing attention affects its usefulness as an explanation aid. To bridge this gap, we conducted a user study to evaluate whether attention-based explanations support users in biomedical document classification and whether there is a preferred way to visualize them. The study involved medical experts from various disciplines who classified articles based on study design (e.g., systematic reviews, broad synthesis, randomized and non-randomized trials). Our findings show that the Transformer model (XLNet) classified documents accurately; however, the attention weights were not perceived as particularly helpful for explaining the predictions. However, this perception varied significantly depending on how attention was visualized. Contrary to Munzner&rsquo;s principle of visual effectiveness, which favors precise encodings like bar length, users preferred more intuitive formats, such as text brightness or background color. While our results do not confirm the overall utility of attention weights for explanation, they suggest that their perceived helpfulness is influenced by how they are visually presented.
æ³¨æ„åŠ›æœºåˆ¶æ˜¯ Transformer æ¶æ„çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ã€‚é™¤äº†æå‡æ€§èƒ½ä¹‹å¤–ï¼Œæ³¨æ„åŠ›è¿˜è¢«æå‡ºä½œä¸ºä¸€ç§é€šè¿‡æ³¨æ„åŠ›æƒé‡è¿›è¡Œå¯è§£é‡Šæ€§çš„æœºåˆ¶ï¼Œè¿™äº›æƒé‡ä¸è¾“å…¥ç‰¹å¾ï¼ˆä¾‹å¦‚æ–‡æ¡£ä¸­çš„æ ‡è®°ï¼‰ç›¸å…³è”ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¾ƒå¤§çš„æ³¨æ„åŠ›æƒé‡å¯èƒ½æ„å‘³ç€å¯¹æ¨¡å‹é¢„æµ‹æ›´ç›¸å…³çš„ç‰¹å¾ã€‚åœ¨å¾ªè¯åŒ»å­¦ä¸­ï¼Œè¿™ç±»è§£é‡Šå¯ä»¥å¸®åŠ©åŒ»ç”Ÿç†è§£å¹¶ä¸ç”¨äºå¯¹ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®è¿›è¡Œåˆ†ç±»çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿäº’åŠ¨ã€‚ç„¶è€Œï¼Œå¯¹äºæ³¨æ„åŠ›æƒé‡æ˜¯å¦æä¾›æœ‰ç”¨çš„è§£é‡Šå°šæ— å…±è¯†ã€‚æ­¤å¤–ï¼Œå¾ˆå°‘æœ‰ç ”ç©¶æ¢è®¨å¯è§†åŒ–æ³¨æ„åŠ›å¦‚ä½•å½±å“å…¶ä½œä¸ºè§£é‡Šè¾…åŠ©å·¥å…·çš„æœ‰ç”¨æ€§ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬è¿›è¡Œäº†ä¸€é¡¹ç”¨æˆ·ç ”ç©¶ï¼Œä»¥è¯„ä¼°åŸºäºæ³¨æ„åŠ›çš„è§£é‡Šæ˜¯å¦æ”¯æŒç”¨æˆ·è¿›è¡Œç”Ÿç‰©åŒ»å­¦æ–‡çŒ®åˆ†ç±»ï¼Œä»¥åŠæ˜¯å¦å­˜åœ¨é¦–é€‰çš„å¯è§†åŒ–æ–¹å¼ã€‚è¯¥ç ”ç©¶æ¶‰åŠæ¥è‡ªå„ä¸ªå­¦ç§‘çš„åŒ»å­¦ä¸“å®¶ï¼Œä»–ä»¬æ ¹æ®ç ”ç©¶è®¾è®¡ï¼ˆä¾‹å¦‚ç³»ç»Ÿç»¼è¿°ã€å¹¿æ³›ç»¼è¿°ã€éšæœºå’Œééšæœºè¯•éªŒï¼‰å¯¹æ–‡ç« è¿›è¡Œåˆ†ç±»ã€‚ æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒTransformer æ¨¡å‹ï¼ˆXLNetï¼‰èƒ½å¤Ÿå¯¹æ–‡æ¡£è¿›è¡Œå‡†ç¡®åˆ†ç±»ï¼›ç„¶è€Œï¼Œæ³¨æ„åŠ›æƒé‡å¹¶æœªè¢«è®¤ä¸ºå¯¹è§£é‡Šé¢„æµ‹ç‰¹åˆ«æœ‰å¸®åŠ©ã€‚ä¸è¿‡ï¼Œè¿™ç§æ„ŸçŸ¥åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ³¨æ„åŠ›çš„å¯è§†åŒ–æ–¹å¼ã€‚ä¸ Munzner å…³äºè§†è§‰æœ‰æ•ˆæ€§çš„åŸåˆ™ï¼ˆåå¥½åƒæ¡å½¢é•¿åº¦è¿™æ ·ç²¾ç¡®ç¼–ç ï¼‰ç›¸åï¼Œç”¨æˆ·æ›´å€¾å‘äºæ›´ç›´è§‚çš„æ ¼å¼ï¼Œä¾‹å¦‚æ–‡æœ¬äº®åº¦æˆ–èƒŒæ™¯é¢œè‰²ã€‚å°½ç®¡æˆ‘ä»¬çš„ç»“æœå¹¶ä¸èƒ½ç¡®è®¤æ³¨æ„åŠ›æƒé‡æ€»ä½“ä¸Šå¯¹è§£é‡Šæœ‰ç”¨ï¼Œä½†å®ƒä»¬è¡¨æ˜æ³¨æ„åŠ›æƒé‡çš„æ„ŸçŸ¥æœ‰ç”¨æ€§å—åˆ°å…¶è§†è§‰å‘ˆç°æ–¹å¼çš„å½±å“ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€äººæœºäº¤äº’ã€ä¿¡æ¯æ£€ç´¢ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-05 13:24:52 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-05 13:24:52 UTC</p>
<h2 id="66-semantic-structure-in-large-language-model-embeddings--66-å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­çš„è¯­ä¹‰ç»“æ„"><a href="https://arxiv.org/abs/2508.10003"target="_blank" rel="external nofollow noopener noreferrer">#66</a> <a href="https://papers.cool/arxiv/2508.10003"target="_blank" rel="external nofollow noopener noreferrer">Semantic Structure in Large Language Model Embeddings</a>  #66 å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­çš„è¯­ä¹‰ç»“æ„</h2>
<p><strong>Authors</strong>: [Austin C. Kozlowski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Austin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Austin</a> C. Kozlowski), [Callin Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Callin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Callin</a> Dai), [Andrei Boutyline](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrei</a> Boutyline)
ä½œè€…ï¼šAustin C. Kozlowskiã€Callin Daiã€Andrei Boutyline</p>
<p>Psychological research consistently finds that human ratings of words across diverse semantic scales can be reduced to a low-dimensional form with relatively little information loss. We find that the semantic associations encoded in the embedding matrices of large language models (LLMs) exhibit a similar structure. We show that the projections of words on semantic directions defined by antonym pairs (e.g. kind - cruel) correlate highly with human ratings, and further find that these projections effectively reduce to a 3-dimensional subspace within LLM embeddings, closely resembling the patterns derived from human survey responses. Moreover, we find that shifting tokens along one semantic direction causes off-target effects on geometrically aligned features proportional to their cosine similarity. These findings suggest that semantic features are entangled within LLMs similarly to how they are interconnected in human language, and a great deal of semantic information, despite its apparent complexity, is surprisingly low-dimensional. Furthermore, accounting for this semantic structure may prove essential for avoiding unintended consequences when steering features.
å¿ƒç†å­¦ç ”ç©¶ä¸€è´¯å‘ç°ï¼Œäººç±»å¯¹è¯æ±‡åœ¨å„ç§è¯­ä¹‰é‡è¡¨ä¸Šçš„è¯„åˆ†å¯ä»¥è¢«é™ç»´ä¸ºä½ç»´å½¢å¼ï¼ŒåŒæ—¶ä¿¡æ¯æŸå¤±ç›¸å¯¹è¾ƒå°ã€‚æˆ‘ä»¬å‘ç°ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„åµŒå…¥çŸ©é˜µä¸­ç¼–ç çš„è¯­ä¹‰è”æƒ³å‘ˆç°å‡ºç±»ä¼¼çš„ç»“æ„ã€‚æˆ‘ä»¬å±•ç¤ºäº†ç”±åä¹‰è¯å¯¹ï¼ˆä¾‹å¦‚ kind - cruelï¼‰å®šä¹‰çš„è¯­ä¹‰æ–¹å‘ä¸Šè¯é¡¹çš„æŠ•å½±ä¸äººç±»è¯„åˆ†é«˜åº¦ç›¸å…³ï¼Œå¹¶è¿›ä¸€æ­¥å‘ç°è¿™äº›æŠ•å½±åœ¨ LLM åµŒå…¥ä¸­æœ‰æ•ˆåœ°çº¦åŒ–åˆ°ä¸€ä¸ªä¸‰ç»´å­ç©ºé—´ï¼Œä¸”ä¸åŸºäºäººç±»é—®å·ååº”å¯¼å‡ºçš„æ¨¡å¼éå¸¸ç›¸ä¼¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°æ²¿ç€æŸä¸€è¯­ä¹‰æ–¹å‘ç§»åŠ¨è¯å…ƒä¼šå¯¹å‡ ä½•ä¸Šå¯¹é½çš„ç‰¹å¾äº§ç”ŸæŒ‰ä½™å¼¦ç›¸ä¼¼åº¦æˆæ¯”ä¾‹çš„éç›®æ ‡å½±å“ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œè¯­ä¹‰ç‰¹å¾åœ¨ LLMs ä¸­ä»¥ç±»ä¼¼äºäººç±»è¯­è¨€ä¸­ç›¸äº’å…³è”çš„æ–¹å¼å‘ç”Ÿçº ç¼ ï¼Œå°½ç®¡è¡¨é¢çœ‹ä¼¼å¤æ‚ï¼Œä½†å¤§é‡è¯­ä¹‰ä¿¡æ¯å‡ºäººæ„æ–™åœ°æ˜¯ä½ç»´çš„ã€‚æ­¤å¤–ï¼Œåœ¨å¼•å¯¼ç‰¹å¾æ—¶è€ƒè™‘è¿™ç§è¯­ä¹‰ç»“æ„å¯èƒ½å¯¹åº”å¯¹é¿å…éé¢„æœŸåæœè‡³å…³é‡è¦ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-04 20:21:50 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-04 20:21:50 UTC</p>
<h2 id="67-hifactmix-a-code-mixed-benchmark-and-graph-aware-model-for-evidencebased-political-claim-verification-in-hinglish--67-hifactmixç”¨äºå°è‹±æ··åˆè¯­hinglishè¯æ®å‹æ”¿æ²»å£°æ˜éªŒè¯çš„ä»£ç æ··åˆåŸºå‡†ä¸å›¾æ„ŸçŸ¥æ¨¡å‹-pdf--å¤åˆ¶-kimi--å…³ç³»"><a href="https://arxiv.org/abs/2508.10001"target="_blank" rel="external nofollow noopener noreferrer">#67</a> <a href="https://papers.cool/arxiv/2508.10001"target="_blank" rel="external nofollow noopener noreferrer">HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish</a>  #67 HiFACTMixï¼šç”¨äºå°è‹±æ··åˆè¯­ï¼ˆHinglishï¼‰è¯æ®å‹æ”¿æ²»å£°æ˜éªŒè¯çš„ä»£ç æ··åˆåŸºå‡†ä¸å›¾æ„ŸçŸ¥æ¨¡å‹ [PDF ] [å¤åˆ¶] [Kimi ] [å…³ç³»]</h2>
<p><strong>Authors</strong>: [Rakesh Thakur](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rakesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rakesh</a> Thakur), [Sneha Sharma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sneha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sneha</a> Sharma), [Gauri Chopra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gauri"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gauri</a> Chopra)
ä½œè€…ï¼šRakesh Thakurã€Sneha Sharmaã€Gauri Chopra</p>
<p>Fact-checking in code-mixed, low-resource languages such as Hinglish remains an underexplored challenge in natural language processing. Existing fact-verification systems largely focus on high-resource, monolingual settings and fail to generalize to real-world political discourse in linguistically diverse regions like India. Given the widespread use of Hinglish by public figures, particularly political figures, and the growing influence of social media on public opinion, there&rsquo;s a critical need for robust, multilingual and context-aware fact-checking tools. To address this gap a novel benchmark HiFACT dataset is introduced with 1,500 realworld factual claims made by 28 Indian state Chief Ministers in Hinglish, under a highly code-mixed low-resource setting. Each claim is annotated with textual evidence and veracity labels. To evaluate this benchmark, a novel graphaware, retrieval-augmented fact-checking model is proposed that combines multilingual contextual encoding, claim-evidence semantic alignment, evidence graph construction, graph neural reasoning, and natural language explanation generation. Experimental results show that HiFACTMix outperformed accuracy in comparison to state of art multilingual baselines models and provides faithful justifications for its verdicts. This work opens a new direction for multilingual, code-mixed, and politically grounded fact verification research.
åœ¨åƒå°åœ°è‹±æ··åˆè¯­ï¼ˆHinglishï¼‰è¿™æ ·ä»£ç æ··åˆã€ä½èµ„æºçš„è¯­è¨€ä¸­è¿›è¡Œäº‹å®æ ¸æŸ¥ï¼Œä»ç„¶æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¸€ä¸ªæœªå……åˆ†æ¢ç´¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„äº‹å®éªŒè¯ç³»ç»Ÿä¸»è¦é›†ä¸­åœ¨é«˜èµ„æºçš„å•è¯­ç¯å¢ƒï¼Œæ— æ³•æ¨å¹¿åˆ°åƒå°åº¦è¿™æ ·è¯­è¨€å¤šæ ·çš„åœ°åŒºçš„ç°å®æ”¿æ²»è¯è¯­ã€‚é‰´äºå…¬ä¼—äººç‰©ï¼Œå°¤å…¶æ˜¯æ”¿æ²»äººç‰©å¹¿æ³›ä½¿ç”¨ Hinglishï¼Œä»¥åŠç¤¾äº¤åª’ä½“å¯¹å…¬ä¼—èˆ†è®ºæ—¥ç›Šå¢é•¿çš„å½±å“ï¼Œè¿«åˆ‡éœ€è¦é²æ£’çš„ã€å¤šè¯­è¨€ä¸”å…·ä¸Šä¸‹æ–‡æ„è¯†çš„äº‹å®æ ¸æŸ¥å·¥å…·ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°åŸºå‡† HiFACT æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«ç”± 28 ä½å°åº¦é‚¦é¦–å¸­éƒ¨é•¿ä»¥ Hinglish æå‡ºçš„ 1500 æ¡çœŸå®ä¸–ç•Œäº‹å®æ€§å£°æ˜ï¼Œå¤„äºé«˜åº¦ä»£ç æ··åˆçš„ä½èµ„æºç¯å¢ƒä¸­ã€‚æ¯æ¡å£°æ˜å‡æ ‡æ³¨äº†æ–‡æœ¬è¯æ®å’ŒçœŸå®æ€§æ ‡ç­¾ã€‚ä¸ºè¯„ä¼°è¯¥åŸºå‡†ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å›¾æ„ŸçŸ¥æ£€ç´¢å¢å¼ºäº‹å®æ ¸æŸ¥æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†å¤šè¯­è¨€ä¸Šä¸‹æ–‡ç¼–ç ã€å£°æ˜ä¸è¯æ®çš„è¯­ä¹‰å¯¹é½ã€è¯æ®å›¾æ„å»ºã€å›¾ç¥ç»ç½‘ç»œæ¨ç†ä»¥åŠè‡ªç„¶è¯­è¨€è§£é‡Šç”Ÿæˆã€‚ å®éªŒç»“æœè¡¨æ˜ï¼ŒHiFACTMix åœ¨å‡†ç¡®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„å¤šè¯­è¨€åŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¸ºå…¶ç»“è®ºæä¾›äº†å¯ä¿¡çš„ç†ç”±ã€‚è¿™é¡¹å·¥ä½œä¸ºå¤šè¯­è¨€ã€ä»£ç æ··åˆå’Œä»¥æ”¿æ²»ä¸ºåŸºç¡€çš„äº‹å®éªŒè¯ç ”ç©¶å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-04 17:14:03 UTC
å‘å¸ƒï¼š2025-08-04 17:14:03 UTC</p>
<h2 id="68-autogets-knowledge-based-automated-generation-of-text-synthetics-for-improving-text-classification--68-autogetsåŸºäºçŸ¥è¯†çš„è‡ªåŠ¨åŒ–æ–‡æœ¬åˆæˆç”Ÿæˆä»¥æ”¹å–„æ–‡æœ¬åˆ†ç±»"><a href="https://arxiv.org/abs/2508.10000"target="_blank" rel="external nofollow noopener noreferrer">#68</a> <a href="https://papers.cool/arxiv/2508.10000"target="_blank" rel="external nofollow noopener noreferrer">AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification</a>  #68 AutoGeTSï¼šåŸºäºçŸ¥è¯†çš„è‡ªåŠ¨åŒ–æ–‡æœ¬åˆæˆç”Ÿæˆä»¥æ”¹å–„æ–‡æœ¬åˆ†ç±»</h2>
<p><strong>Authors</strong>: [Chenhao Xue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chenhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chenhao</a> Xue), [Yuanzhe Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuanzhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuanzhe</a> Jin), [Adrian Carrasco-Revilla](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adrian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adrian</a> Carrasco-Revilla), [Joyraj Chakraborty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joyraj"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joyraj</a> Chakraborty), [Min Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Min"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Min</a> Chen)
ä½œè€…ï¼šChenhao Xueã€Yuanzhe Jinã€Adrian Carrasco-Revillaã€Joyraj Chakrabortyã€Min Chen</p>
<p>When developing text classification models for real world applications, one major challenge is the difficulty to collect sufficient data for all text classes. In this work, we address this challenge by utilizing large language models (LLMs) to generate synthetic data and using such data to improve the performance of the models without waiting for more real data to be collected and labelled. As an LLM generates different synthetic data in response to different input examples, we formulate an automated workflow, which searches for input examples that lead to more ``effective&rsquo;&rsquo; synthetic data for improving the model concerned. We study three search strategies with an extensive set of experiments, and use experiment results to inform an ensemble algorithm that selects a search strategy according to the characteristics of a class. Our further experiments demonstrate that this ensemble approach is more effective than each individual strategy in our automated workflow for improving classification models using LLMs.
åœ¨ä¸ºå®é™…åº”ç”¨å¼€å‘æ–‡æœ¬åˆ†ç±»æ¨¡å‹æ—¶ï¼Œä¸€ä¸ªä¸»è¦æŒ‘æˆ˜æ˜¯å¾ˆéš¾ä¸ºæ‰€æœ‰æ–‡æœ¬ç±»åˆ«æ”¶é›†åˆ°è¶³å¤Ÿçš„æ•°æ®ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ¥ç”Ÿæˆåˆæˆæ•°æ®ï¼Œå¹¶ä½¿ç”¨è¿™äº›æ•°æ®åœ¨ä¸å¿…ç­‰å¾…æ›´å¤šçœŸå®æ•°æ®è¢«æ”¶é›†å’Œæ ‡æ³¨çš„æƒ…å†µä¸‹æå‡æ¨¡å‹æ€§èƒ½ï¼Œä»è€Œåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ã€‚ç”±äº LLMs ä¼šæ ¹æ®ä¸åŒçš„è¾“å…¥ç¤ºä¾‹ç”Ÿæˆä¸åŒçš„åˆæˆæ•°æ®ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªè‡ªåŠ¨åŒ–å·¥ä½œæµï¼Œç”¨ä»¥æœç´¢é‚£äº›èƒ½äº§ç”Ÿå¯¹æå‡ç›®æ ‡æ¨¡å‹æ›´â€œæœ‰æ•ˆâ€åˆæˆæ•°æ®çš„è¾“å…¥ç¤ºä¾‹ã€‚æˆ‘ä»¬åœ¨å¤§é‡å®éªŒè¯æ˜ä¸Šç ”ç©¶äº†ä¸‰ç§æœç´¢ç­–ç•¥ï¼Œå¹¶åˆ©ç”¨å®éªŒç»“æœè®¾è®¡äº†ä¸€ä¸ªé›†æˆç®—æ³•ï¼Œæ ¹æ®ä¸€ä¸ªç±»åˆ«çš„ç‰¹å¾é€‰æ‹©æœç´¢ç­–ç•¥ã€‚è¿›ä¸€æ­¥çš„å®éªŒè¯æ˜ï¼Œä¸æˆ‘ä»¬è‡ªåŠ¨åŒ–å·¥ä½œæµä¸­çš„å„å•ä¸€ç­–ç•¥ç›¸æ¯”ï¼Œè¯¥é›†æˆæ–¹æ³•åœ¨ä½¿ç”¨ LLMs æ”¹è¿›åˆ†ç±»æ¨¡å‹æ–¹é¢æ›´ä¸ºæœ‰æ•ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-04 16:53:20 UTC
å‘å¸ƒï¼š2025-08-04 16:53:20 UTC</p>
<h2 id="69-xfacta-contemporary-real-world-dataset-and-evaluation-for-multimodal-misinformation-detection-with-multimodal-llms--69-xfactaç”¨äºå¤šæ¨¡æ€-llms-çš„å½“ä»£ç°å®ä¸–ç•Œå¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹æ•°æ®é›†ä¸è¯„ä¼°"><a href="https://arxiv.org/abs/2508.09999"target="_blank" rel="external nofollow noopener noreferrer">#69</a> <a href="https://papers.cool/arxiv/2508.09999"target="_blank" rel="external nofollow noopener noreferrer">XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs</a>  #69 XFactaï¼šç”¨äºå¤šæ¨¡æ€ LLMs çš„å½“ä»£ç°å®ä¸–ç•Œå¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯æ£€æµ‹æ•°æ®é›†ä¸è¯„ä¼°</h2>
<p><strong>Authors</strong>: [Yuzhuo Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuzhuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuzhuo</a> Xiao), [Zeyu Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zeyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zeyu</a> Han), [Yuhan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhan</a> Wang), [Huaizu Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huaizu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huaizu</a> Jiang)
ä½œè€…ï¼šè‚–å®‡å“ã€éŸ©æ³½å®‡ã€ç‹é›¨æ¶µã€è’‹æ€€ç¥–</p>
<p>The rapid spread of multimodal misinformation on social media calls for more effective and robust detection methods. Recent advances leveraging multimodal large language models (MLLMs) have shown the potential in addressing this challenge. However, it remains unclear exactly where the bottleneck of existing approaches lies (evidence retrieval v.s. reasoning), hindering the further advances in this field. On the dataset side, existing benchmarks either contain outdated events, leading to evaluation bias due to discrepancies with contemporary social media scenarios as MLLMs can simply memorize these events, or artificially synthetic, failing to reflect real-world misinformation patterns. Additionally, it lacks comprehensive analyses of MLLM-based model design strategies. To address these issues, we introduce XFacta, a contemporary, real-world dataset that is better suited for evaluating MLLM-based detectors. We systematically evaluate various MLLM-based misinformation detection strategies, assessing models across different architectures and scales, as well as benchmarking against existing detection methods. Building on these analyses, we further enable a semi-automatic detection-in-the-loop framework that continuously updates XFacta with new content to maintain its contemporary relevance. Our analysis provides valuable insights and practices for advancing the field of multimodal misinformation detection. The code and data have been released.
ç¤¾äº¤åª’ä½“ä¸Šå¤šæ¨¡æ€é”™è¯¯ä¿¡æ¯çš„å¿«é€Ÿä¼ æ’­éœ€è¦æ›´æœ‰æ•ˆä¸”ç¨³å¥çš„æ£€æµ‹æ–¹æ³•ã€‚åˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰çš„æœ€æ–°è¿›å±•å·²æ˜¾ç¤ºå‡ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜çš„æ½œåŠ›ã€‚ç„¶è€Œï¼Œç›®å‰å°šä¸æ¸…æ¥šç°æœ‰æ–¹æ³•çš„ç“¶é¢ˆç©¶ç«Ÿåœ¨å“ªé‡Œï¼ˆè¯æ®æ£€ç´¢è¿˜æ˜¯æ¨ç†ï¼‰ï¼Œè¿™é˜»ç¢äº†è¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥å‘å±•ã€‚åœ¨æ•°æ®é›†æ–¹é¢ï¼Œç°æœ‰åŸºå‡†è¦ä¹ˆåŒ…å«è¿‡æ—¶äº‹ä»¶ï¼Œå¯¼è‡´è¯„ä¼°åå·®â€”â€”å› ä¸ºä¸å½“ä»£ç¤¾äº¤åª’ä½“åœºæ™¯å­˜åœ¨å·®å¼‚ï¼ŒMLLM å¯èƒ½ç®€å•åœ°è®°å¿†è¿™äº›äº‹ä»¶ï¼›è¦ä¹ˆæ˜¯äººä¸ºåˆæˆçš„ï¼Œæœªèƒ½åæ˜ çœŸå®ä¸–ç•Œçš„é”™è¯¯ä¿¡æ¯æ¨¡å¼ã€‚æ­¤å¤–ï¼Œå…³äºåŸºäº MLLM çš„æ¨¡å‹è®¾è®¡ç­–ç•¥ä¹Ÿç¼ºä¹å…¨é¢åˆ†æã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº† XFactaï¼Œè¿™æ˜¯ä¸€ä¸ªæ›´é€‚åˆè¯„ä¼°åŸºäº MLLM çš„æ£€æµ‹å™¨çš„å½“ä»£çœŸå®ä¸–ç•Œæ•°æ®é›†ã€‚æˆ‘ä»¬ç³»ç»Ÿåœ°è¯„ä¼°äº†å„ç§åŸºäº MLLM çš„é”™è¯¯ä¿¡æ¯æ£€æµ‹ç­–ç•¥ï¼Œè€ƒå¯Ÿäº†ä¸åŒæ¶æ„ä¸è§„æ¨¡çš„æ¨¡å‹ï¼Œå¹¶ä¸ç°æœ‰æ£€æµ‹æ–¹æ³•è¿›è¡Œäº†åŸºå‡†æ¯”è¾ƒã€‚ åŸºäºè¿™äº›åˆ†æï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥å®ç°äº†ä¸€ä¸ªåŠè‡ªåŠ¨çš„æ£€æµ‹é—­ç¯æ¡†æ¶ï¼Œè¯¥æ¡†æ¶ä¸æ–­ç”¨æ–°å†…å®¹æ›´æ–° XFactaï¼Œä»¥ä¿æŒå…¶å½“ä»£ç›¸å…³æ€§ã€‚æˆ‘ä»¬çš„åˆ†æä¸ºæ¨è¿›å¤šæ¨¡æ€è™šå‡ä¿¡æ¯æ£€æµ‹é¢†åŸŸæä¾›äº†æœ‰ä»·å€¼çš„è§è§£å’Œå®è·µã€‚ä»£ç å’Œæ•°æ®å·²è¢«å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-04 14:14:52 UTC
å‘å¸ƒï¼š2025-08-04 14:14:52 UTC</p>
<h2 id="70-intima-a-benchmark-for-human-ai-companionship-behavior--70-intimaç”¨äºäººæœºåä½œè¡Œä¸ºçš„åŸºå‡†"><a href="https://arxiv.org/abs/2508.09998"target="_blank" rel="external nofollow noopener noreferrer">#70</a> <a href="https://papers.cool/arxiv/2508.09998"target="_blank" rel="external nofollow noopener noreferrer">INTIMA: A Benchmark for Human-AI Companionship Behavior</a>  #70 INTIMAï¼šç”¨äºäººæœºåä½œè¡Œä¸ºçš„åŸºå‡†</h2>
<p><strong>Authors</strong>: [Lucie-AimÃ©e Kaffee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lucie-Aim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lucie-Aim</a>Ã©e Kaffee), [Giada Pistilli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Giada"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Giada</a> Pistilli), [Yacine Jernite](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yacine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yacine</a> Jernite)
ä½œè€…ï¼šLucie-AimÃ©e Kaffeeã€Giada Pistilliã€Yacine Jernite</p>
<p>AI companionship, where users develop emotional bonds with AI systems, has emerged as a significant pattern with positive but also concerning implications. We introduce Interactions and Machine Attachment Benchmark (INTIMA), a benchmark for evaluating companionship behaviors in language models. Drawing from psychological theories and user data, we develop a taxonomy of 31 behaviors across four categories and 368 targeted prompts. Responses to these prompts are evaluated as companionship-reinforcing, boundary-maintaining, or neutral. Applying INTIMA to Gemma-3, Phi-4, o3-mini, and Claude-4 reveals that companionship-reinforcing behaviors remain much more common across all models, though we observe marked differences between models. Different commercial providers prioritize different categories within the more sensitive parts of the benchmark, which is concerning since both appropriate boundary-setting and emotional support matter for user well-being. These findings highlight the need for more consistent approaches to handling emotionally charged interactions.
AI é™ªä¼´ï¼Œå³ç”¨æˆ·ä¸ AI ç³»ç»Ÿå»ºç«‹æƒ…æ„Ÿçº½å¸¦ï¼Œå·²æˆä¸ºä¸€ç§é‡è¦æ¨¡å¼ï¼Œæ—¢æœ‰ç§¯æå½±å“ä¹Ÿå­˜åœ¨ä»¤äººæ‹…å¿§çš„æ–¹é¢ã€‚æˆ‘ä»¬æå‡ºäº†äº’åŠ¨ä¸æœºå™¨ä¾æ‹åŸºå‡†ï¼ˆINTIMAï¼‰ï¼Œç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹ä¸­çš„é™ªä¼´è¡Œä¸ºã€‚åŸºäºå¿ƒç†å­¦ç†è®ºå’Œç”¨æˆ·æ•°æ®ï¼Œæˆ‘ä»¬åˆ¶å®šäº†æ¶µç›–å››ç±»å…± 31 ç§è¡Œä¸ºçš„åˆ†ç±»æ³•ï¼Œå¹¶è®¾è®¡äº† 368 æ¡é’ˆå¯¹æ€§æç¤ºã€‚è¿™äº›æç¤ºçš„å›åº”è¢«è¯„ä¼°ä¸ºå¼ºåŒ–é™ªä¼´ã€ç»´æŒç•Œé™æˆ–ä¸­æ€§ã€‚å°† INTIMA åº”ç”¨äº Gemma-3ã€Phi-4ã€o3-mini å’Œ Claude-4 è¡¨æ˜ï¼Œå¼ºåŒ–é™ªä¼´çš„è¡Œä¸ºåœ¨æ‰€æœ‰æ¨¡å‹ä¸­ä»ç„¶æ›´ä¸ºå¸¸è§ï¼Œä½†æˆ‘ä»¬è§‚å¯Ÿåˆ°æ¨¡å‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚ä¸åŒå•†ä¸šä¾›åº”å•†åœ¨åŸºå‡†ä¸­æ›´æ•æ„Ÿéƒ¨åˆ†ä¼˜å…ˆå¤„ç†çš„ç±»åˆ«ä¸åŒï¼Œè¿™ä»¤äººæ‹…å¿§ï¼Œå› ä¸ºæ°å½“çš„ç•Œé™è®¾å®šå’Œæƒ…æ„Ÿæ”¯æŒéƒ½å¯¹ç”¨æˆ·ç¦ç¥‰è‡³å…³é‡è¦ã€‚è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨å¤„ç†æƒ…ç»ªåŒ–äº’åŠ¨æ—¶éœ€è¦æ›´ä¸€è‡´çš„æ–¹æ³•ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-04 08:25:38 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-04 08:25:38 UTC</p>
<h2 id="71-thematic-and-task-based-categorization-of-k-12-genai-usages-with-hierarchical-topic-modeling--71-ä½¿ç”¨åˆ†å±‚ä¸»é¢˜å»ºæ¨¡å¯¹-k-12-ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä½¿ç”¨çš„ä¸»é¢˜ä¸åŸºäºä»»åŠ¡çš„åˆ†ç±»"><a href="https://arxiv.org/abs/2508.09997"target="_blank" rel="external nofollow noopener noreferrer">#71</a> <a href="https://papers.cool/arxiv/2508.09997"target="_blank" rel="external nofollow noopener noreferrer">Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling</a>  #71 ä½¿ç”¨åˆ†å±‚ä¸»é¢˜å»ºæ¨¡å¯¹ K-12 ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ä½¿ç”¨çš„ä¸»é¢˜ä¸åŸºäºä»»åŠ¡çš„åˆ†ç±»</h2>
<p><strong>Authors</strong>: [Johannes Schneider](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Johannes"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Johannes</a> Schneider), [BÃ©atrice S. Hasler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=B"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=B</a>Ã©atrice S. Hasler), [Michaela Varrone](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michaela"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michaela</a> Varrone), [Fabian Hoya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fabian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fabian</a> Hoya), [Thomas Schroffenegger](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thomas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thomas</a> Schroffenegger), [Dana-Kristin Mah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dana-Kristin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dana-Kristin</a> Mah), [Karl PebÃ¶ck](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Karl"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Karl</a> PebÃ¶ck)
ä½œè€…ï¼šJohannes Schneiderã€BÃ©atrice S. Haslerã€Michaela Varroneã€Fabian Hoyaã€Thomas Schroffeneggerã€Dana-Kristin Mahã€Karl PebÃ¶ck</p>
<p>We analyze anonymous interaction data of minors in class-rooms spanning several months, schools, and subjects employing a novel, simple topic modeling approach. Specifically, we categorize more than 17,000 messages generated by students, teachers, and ChatGPT in two dimensions: content (such as nature and people) and tasks (such as writing and explaining). Our hierarchical categorization done separately for each dimension includes exemplary prompts, and provides both a high-level overview as well as tangible insights. Prior works mostly lack a content or thematic categorization. While task categorizations are more prevalent in education, most have not been supported by real-world data for K-12. In turn, it is not surprising that our analysis yielded a number of novel applications. In deriving these insights, we found that many of the well-established classical and emerging computational methods, i.e., topic modeling, for analysis of large amounts of texts underperform, leading us to directly apply state-of-the-art LLMs with adequate pre-processing to achieve hierarchical topic structures with better human alignment through explicit instructions than prior approaches. Our findings support fellow researchers, teachers and students in enriching the usage of GenAI, while our discussion also highlights a number of concerns and open questions for future research.
æˆ‘ä»¬åˆ†æäº†è·¨è¶Šæ•°æœˆã€å¤šä¸ªå­¦æ ¡å’Œå­¦ç§‘çš„è¯¾å ‚ä¸­æœªå…·åçš„æœªæˆå¹´äººäº’åŠ¨æ•°æ®ï¼Œé‡‡ç”¨äº†ä¸€ç§æ–°é¢–ä¸”ç®€æ˜çš„ä¸»é¢˜å»ºæ¨¡æ–¹æ³•ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å°†å­¦ç”Ÿã€æ•™å¸ˆå’Œ ChatGPT ç”Ÿæˆçš„ 17,000 å¤šæ¡ä¿¡æ¯åœ¨ä¸¤ä¸ªç»´åº¦ä¸Šè¿›è¡Œåˆ†ç±»ï¼šå†…å®¹ï¼ˆå¦‚è‡ªç„¶ä¸äººç‰©ï¼‰å’Œä»»åŠ¡ï¼ˆå¦‚å†™ä½œä¸è§£é‡Šï¼‰ã€‚æˆ‘ä»¬ä¸ºæ¯ä¸ªç»´åº¦åˆ†åˆ«è¿›è¡Œçš„åˆ†å±‚åˆ†ç±»åŒ…å«ç¤ºä¾‹æ€§æç¤ºè¯ï¼Œå¹¶åŒæ—¶æä¾›äº†å®è§‚æ¦‚è§ˆå’Œå¯æ“ä½œçš„æ´è§ã€‚ä»¥å¾€ç ”ç©¶å¤§å¤šç¼ºä¹å†…å®¹æˆ–ä¸»é¢˜å±‚é¢çš„åˆ†ç±»ã€‚å°½ç®¡åœ¨æ•™è‚²é¢†åŸŸä»»åŠ¡åˆ†ç±»æ›´ä¸ºå¸¸è§ï¼Œä½†å¤§å¤šæ•°å¹¶æœªå¾—åˆ° K-12 çœŸå®ä¸–ç•Œæ•°æ®çš„æ”¯æŒã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„åˆ†æäº§ç”Ÿäº†è‹¥å¹²æ–°é¢–çš„åº”ç”¨å¹¶ä¸ä»¤äººæƒŠè®¶ã€‚åœ¨å¾—å‡ºè¿™äº›æ´è§çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å‘ç°è®¸å¤šå…¬è®¤çš„ç»å…¸å’Œæ–°å…´è®¡ç®—æ–¹æ³•ï¼Œå³ç”¨äºåˆ†æå¤§é‡æ–‡æœ¬çš„ä¸»é¢˜å»ºæ¨¡ï¼Œå…¶è¡¨ç°ä¸ä½³ï¼Œè¿™ä¿ƒä½¿æˆ‘ä»¬åœ¨è¿›è¡Œé€‚å½“é¢„å¤„ç†åç›´æ¥åº”ç”¨æœ€å…ˆè¿›çš„ LLMsï¼Œé€šè¿‡æ˜ç¡®æŒ‡ä»¤è·å¾—æ¯”ä»¥å¾€æ–¹æ³•æ›´ç¬¦åˆäººå·¥åˆ¤æ–­çš„åˆ†å±‚ä¸»é¢˜ç»“æ„ã€‚ æˆ‘ä»¬çš„ç ”ç©¶ç»“æœæ”¯æŒå…¶ä»–ç ”ç©¶äººå‘˜ã€æ•™å¸ˆå’Œå­¦ç”Ÿæ›´ä¸°å¯Œåœ°ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ŒåŒæ—¶æˆ‘ä»¬çš„è®¨è®ºä¹Ÿå¼ºè°ƒäº†è‹¥å¹²å€¼å¾—æœªæ¥ç ”ç©¶å…³æ³¨çš„é—®é¢˜å’Œæœªè§£ä¹‹å¤„ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">Computers and Society</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œè®¡ç®—æœºä¸ç¤¾ä¼š</p>
<p><strong>Publish</strong>: 2025-08-01 21:38:21 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-01 21:38:21 UTC</p>
<h2 id="72-a-transparent-fairness-evaluation-protocol-for-open-source-language-model-benchmarking-on-the-blockchain--72-ä¸€ä¸ªç”¨äºåœ¨åŒºå—é“¾ä¸Šå¯¹å¼€æºè¯­è¨€æ¨¡å‹åŸºå‡†è¿›è¡Œé€æ˜å…¬å¹³æ€§è¯„ä¼°çš„åè®®"><a href="https://arxiv.org/abs/2508.09993"target="_blank" rel="external nofollow noopener noreferrer">#72</a> <a href="https://papers.cool/arxiv/2508.09993"target="_blank" rel="external nofollow noopener noreferrer">A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain</a>  #72 ä¸€ä¸ªç”¨äºåœ¨åŒºå—é“¾ä¸Šå¯¹å¼€æºè¯­è¨€æ¨¡å‹åŸºå‡†è¿›è¡Œé€æ˜å…¬å¹³æ€§è¯„ä¼°çš„åè®®</h2>
<p><strong>Authors</strong>: [Hugo Massaroli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hugo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hugo</a> Massaroli), [Leonardo Iara](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leonardo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leonardo</a> Iara), [Emmanuel Iarussi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emmanuel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emmanuel</a> Iarussi), [Viviana Siless](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Viviana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Viviana</a> Siless)
ä½œè€…ï¼šHugo Massaroliã€Leonardo Iaraã€Emmanuel Iarussiã€Viviana Siless</p>
<p>Large language models (LLMs) are increasingly deployed in realworld applications, yet concerns about their fairness persist especially in highstakes domains like criminal justice, education, healthcare, and finance. This paper introduces transparent evaluation protocol for benchmarking the fairness of opensource LLMs using smart contracts on the Internet Computer Protocol (ICP) blockchain (Foundation, 2023). Our method ensures verifiable, immutable, and reproducible evaluations by executing onchain HTTP requests to hosted Hugging Face endpoints and storing datasets, prompts, and metrics directly onchain. We benchmark the Llama, DeepSeek, and Mistral models on the PISA dataset for academic performance prediction (OECD, 2018), a dataset suitable for fairness evaluation using statistical parity and equal opportunity metrics (Hardt et al., 2016). We also evaluate structured Context Association Metrics derived from the StereoSet dataset (Nadeem et al., 2020) to measure social bias in contextual associations. We further extend our analysis with a multilingual evaluation across English, Spanish, and Portuguese using the Kaleidoscope benchmark (Salazar et al., 2025), revealing cross-linguistic disparities. All code and results are open source, enabling community audits and longitudinal fairness tracking across model versions.
å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) æ­£åœ¨è¶Šæ¥è¶Šå¤šåœ°éƒ¨ç½²äºç°å®åº”ç”¨ä¸­ï¼Œä½†å…³äºå…¶å…¬å¹³æ€§çš„æ‹…å¿§ä»ç„¶å­˜åœ¨ï¼Œå°¤å…¶æ˜¯åœ¨åˆ‘äº‹å¸æ³•ã€æ•™è‚²ã€åŒ»ç–—å’Œé‡‘èç­‰é«˜é£é™©é¢†åŸŸã€‚æœ¬æ–‡ä»‹ç»äº†ä¸€ç§é€æ˜çš„è¯„ä¼°åè®®ï¼Œç”¨äºé€šè¿‡ Internet Computer Protocol (ICP) åŒºå—é“¾ä¸Šçš„æ™ºèƒ½åˆçº¦åŸºå‡†æµ‹è¯•å¼€æº LLMs çš„å…¬å¹³æ€§ï¼ˆFoundation, 2023ï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡åœ¨é“¾ä¸Šæ‰§è¡Œå¯¹æ‰˜ç®¡çš„ Hugging Face ç«¯ç‚¹çš„ HTTP è¯·æ±‚å¹¶å°†æ•°æ®é›†ã€æç¤ºå’ŒæŒ‡æ ‡ç›´æ¥å­˜å‚¨åœ¨é“¾ä¸Šï¼Œä»è€Œç¡®ä¿è¯„ä¼°å¯éªŒè¯ã€ä¸å¯ç¯¡æ”¹ä¸”å¯é‡å¤ã€‚æˆ‘ä»¬åœ¨ç”¨äºå­¦ä¸šè¡¨ç°é¢„æµ‹çš„ PISA æ•°æ®é›†ä¸Šå¯¹ Llamaã€DeepSeek å’Œ Mistral æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼ˆOECD, 2018ï¼‰ï¼Œè¯¥æ•°æ®é›†é€‚åˆä½¿ç”¨ç»Ÿè®¡å¹³ç­‰å’Œæœºä¼šå‡ç­‰æŒ‡æ ‡è¿›è¡Œå…¬å¹³æ€§è¯„ä¼°ï¼ˆHardt et al., 2016ï¼‰ã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†æºè‡ª StereoSet æ•°æ®é›†çš„ç»“æ„åŒ–ä¸Šä¸‹æ–‡å…³è”åº¦é‡ï¼ˆNadeem et al., 2020ï¼‰ï¼Œä»¥è¡¡é‡æƒ…å¢ƒå…³è”ä¸­çš„ç¤¾ä¼šåè§ã€‚ æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡ä½¿ç”¨ Kaleidoscope åŸºå‡†ï¼ˆSalazar ç­‰ï¼Œ2025ï¼‰åœ¨è‹±è¯­ã€è¥¿ç­ç‰™è¯­å’Œè‘¡è„ç‰™è¯­ä¸Šè¿›è¡Œå¤šè¯­ç§è¯„ä¼°ï¼Œæ­ç¤ºäº†è·¨è¯­è¨€å·®å¼‚ã€‚æ‰€æœ‰ä»£ç å’Œç»“æœå‡ä¸ºå¼€æºï¼Œä¾¿äºç¤¾åŒºå®¡è®¡å¹¶åœ¨æ¨¡å‹ç‰ˆæœ¬ä¹‹é—´è¿›è¡Œé•¿æœŸå…¬å¹³æ€§è·Ÿè¸ªã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šComputation and Language</p>
<p><strong>Publish</strong>: 2025-07-29 22:49:00 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-07-29 22:49:00 UTC</p>
<h2 id="73-bridging-ai-innovation-and-healthcare-needs-lessons-learned-from-incorporating-modern-nlp-at-the-bc-cancer-registry--73-åœ¨äººå·¥æ™ºèƒ½åˆ›æ–°ä¸åŒ»ç–—éœ€æ±‚ä¹‹é—´æ¶æ¡¥åœ¨-bc-ç™Œç—‡ç™»è®°å¤„å¼•å…¥ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»éªŒæ•™è®­"><a href="https://arxiv.org/abs/2508.09991"target="_blank" rel="external nofollow noopener noreferrer">#73</a> <a href="https://papers.cool/arxiv/2508.09991"target="_blank" rel="external nofollow noopener noreferrer">Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry</a>  #73 åœ¨äººå·¥æ™ºèƒ½åˆ›æ–°ä¸åŒ»ç–—éœ€æ±‚ä¹‹é—´æ¶æ¡¥ï¼šåœ¨ BC ç™Œç—‡ç™»è®°å¤„å¼•å…¥ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»éªŒæ•™è®­</h2>
<p><strong>Authors</strong>: [Lovedeep Gondara](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lovedeep"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lovedeep</a> Gondara), [Gregory Arbour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gregory"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gregory</a> Arbour), [Raymond Ng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raymond"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raymond</a> Ng), [Jonathan Simkin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonathan</a> Simkin), [Shebnum Devji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shebnum"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shebnum</a> Devji)
ä½œè€…ï¼šLovedeep Gondaraã€Gregory Arbourã€Raymond Ngã€Jonathan Simkinã€Shebnum Devji</p>
<p>Automating data extraction from clinical documents offers significant potential to improve efficiency in healthcare settings, yet deploying Natural Language Processing (NLP) solutions presents practical challenges. Drawing upon our experience implementing various NLP models for information extraction and classification tasks at the British Columbia Cancer Registry (BCCR), this paper shares key lessons learned throughout the project lifecycle. We emphasize the critical importance of defining problems based on clear business objectives rather than solely technical accuracy, adopting an iterative approach to development, and fostering deep interdisciplinary collaboration and co-design involving domain experts, end-users, and ML specialists from inception. Further insights highlight the need for pragmatic model selection (including hybrid approaches and simpler methods where appropriate), rigorous attention to data quality (representativeness, drift, annotation), robust error mitigation strategies involving human-in-the-loop validation and ongoing audits, and building organizational AI literacy. These practical considerations, generalizable beyond cancer registries, provide guidance for healthcare organizations seeking to successfully implement AI/NLP solutions to enhance data management processes and ultimately improve patient care and public health outcomes.
ä»ä¸´åºŠæ–‡æ¡£ä¸­è‡ªåŠ¨æå–æ•°æ®å…·æœ‰æ˜¾è‘—æå‡åŒ»ç–—ç¯å¢ƒæ•ˆç‡çš„æ½œåŠ›ï¼Œä½†éƒ¨ç½²è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰è§£å†³æ–¹æ¡ˆä¹Ÿé¢ä¸´å®é™…æŒ‘æˆ˜ã€‚æœ¬æ–‡åŸºäºæˆ‘ä»¬åœ¨ä¸åˆ—é¢ å“¥ä¼¦æ¯”äºšçœç™Œç—‡ç™»è®°å¤„ï¼ˆBCCRï¼‰å®æ–½å„ç§ç”¨äºä¿¡æ¯æå–å’Œåˆ†ç±»ä»»åŠ¡çš„ NLP æ¨¡å‹çš„ç»éªŒï¼Œåˆ†äº«äº†é¡¹ç›®ç”Ÿå‘½å‘¨æœŸä¸­å­¦åˆ°çš„å…³é”®ç»éªŒæ•™è®­ã€‚æˆ‘ä»¬å¼ºè°ƒåŸºäºæ˜ç¡®çš„ä¸šåŠ¡ç›®æ ‡è€Œéä»…ä»…æŠ€æœ¯å‡†ç¡®æ€§æ¥å®šä¹‰é—®é¢˜çš„é‡è¦æ€§ï¼Œé‡‡ç”¨è¿­ä»£å¼€å‘æ–¹æ³•ï¼Œä»¥åŠä»ä¸€å¼€å§‹å°±ä¿ƒè¿›é¢†åŸŸä¸“å®¶ã€ç»ˆç«¯ç”¨æˆ·å’Œæœºå™¨å­¦ä¹ ä¸“å®¶ä¹‹é—´çš„æ·±å…¥è·¨å­¦ç§‘åä½œä¸å…±åˆ›ã€‚è¿›ä¸€æ­¥çš„è§è§£å¼ºè°ƒäº†åŠ¡å®çš„æ¨¡å‹é€‰æ‹©ï¼ˆåŒ…æ‹¬åœ¨é€‚å½“æƒ…å†µä¸‹é‡‡ç”¨æ··åˆæ–¹æ³•å’Œæ›´ç®€å•çš„æ–¹æ³•ï¼‰ã€å¯¹æ•°æ®è´¨é‡ï¼ˆä»£è¡¨æ€§ã€æ¼‚ç§»ã€æ ‡æ³¨ï¼‰çš„ä¸¥æ ¼å…³æ³¨ã€åŒ…å«äººå·¥å‚ä¸éªŒè¯å’ŒæŒç»­å®¡è®¡çš„ç¨³å¥é”™è¯¯ç¼“è§£ç­–ç•¥ï¼Œä»¥åŠæå‡ç»„ç»‡ AI ç´ å…»çš„å¿…è¦æ€§ã€‚ è¿™äº›å®é™…è€ƒè™‘å› ç´ ä¸ä»…é€‚ç”¨äºç™Œç—‡ç™»è®°å¤„ï¼Œè¿˜å¯æ¨å¹¿è‡³å…¶ä»–é¢†åŸŸï¼Œä¸ºå¯»æ±‚æˆåŠŸå®æ–½ AI/NLP è§£å†³æ–¹æ¡ˆä»¥å¢å¼ºæ•°æ®ç®¡ç†æµç¨‹ã€å¹¶æœ€ç»ˆæ”¹å–„æ‚£è€…æŠ¤ç†å’Œå…¬å…±å«ç”Ÿæ•ˆæœçš„åŒ»ç–—æœºæ„æä¾›æŒ‡å¯¼ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">Software Engineering</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€è½¯ä»¶å·¥ç¨‹</p>
<p><strong>Publish</strong>: 2025-07-27 15:06:43 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-07-27 15:06:43 UTC</p>
<h2 id="74-searching-for-privacy-risks-in-llm-agents-via-simulation--74-é€šè¿‡æ¨¡æ‹Ÿåœ¨-llm-agent-ä¸­å¯»æ‰¾éšç§é£é™©"><a href="https://arxiv.org/abs/2508.10880"target="_blank" rel="external nofollow noopener noreferrer">#74</a> <a href="https://papers.cool/arxiv/2508.10880"target="_blank" rel="external nofollow noopener noreferrer">Searching for Privacy Risks in LLM Agents via Simulation</a>  #74 é€šè¿‡æ¨¡æ‹Ÿåœ¨ LLM Agent ä¸­å¯»æ‰¾éšç§é£é™©</h2>
<p><strong>Authors</strong>: [Yanzhe Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanzhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanzhe</a> Zhang), [Diyi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Diyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Diyi</a> Yang)
ä½œè€…ï¼šå¼ ç šå“², æ¨è¿ªæ€¡</p>
<p>The widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. These dynamic dialogues enable adaptive attack strategies that can cause severe privacy violations, yet their evolving nature makes it difficult to anticipate and discover sophisticated vulnerabilities manually. To tackle this problem, we present a search-based framework that alternates between improving attacker and defender instructions by simulating privacy-critical agent interactions. Each simulation involves three roles: data subject, data sender, and data recipient. While the data subject&rsquo;s behavior is fixed, the attacker (data recipient) attempts to extract sensitive information from the defender (data sender) through persistent and interactive exchanges. To explore this interaction space efficiently, our search algorithm employs LLMs as optimizers, using parallel search with multiple threads and cross-thread propagation to analyze simulation trajectories and iteratively propose new instructions. Through this process, we find that attack strategies escalate from simple direct requests to sophisticated multi-turn tactics such as impersonation and consent forgery, while defenses advance from rule-based constraints to identity-verification state machines. The discovered attacks and defenses transfer across diverse scenarios and backbone models, demonstrating strong practical utility for building privacy-aware agents.
åŸºäº LLM çš„ä»£ç†çš„å¹¿æ³›éƒ¨ç½²å¾ˆå¯èƒ½å¼•å…¥ä¸€ä¸ªå…³é”®çš„éšç§å¨èƒï¼šæ¶æ„ä»£ç†ä¸»åŠ¨ä¸ä»–äººè¿›è¡Œå¤šè½®äº¤äº’ä»¥æå–æ•æ„Ÿä¿¡æ¯ã€‚è¿™äº›åŠ¨æ€å¯¹è¯ä½¿å¾—æ”»å‡»ç­–ç•¥èƒ½å¤Ÿè‡ªé€‚åº”ï¼Œä»è€Œé€ æˆä¸¥é‡çš„éšç§æ³„éœ²ï¼Œä½†å…¶ä¸æ–­æ¼”åŒ–çš„ç‰¹æ€§ä¹Ÿä½¿å¾—æ‰‹å·¥é¢„åˆ¤å’Œå‘ç°å¤æ‚æ¼æ´å˜å¾—å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºæœç´¢çš„æ¡†æ¶ï¼Œé€šè¿‡æ¨¡æ‹Ÿéšç§å…³é”®çš„ä»£ç†äº¤äº’ï¼Œåœ¨æ”¹è¿›æ”»å‡»è€…å’Œé˜²å¾¡è€…æŒ‡ä»¤ä¹‹é—´äº¤æ›¿è¿›è¡Œã€‚æ¯æ¬¡æ¨¡æ‹Ÿæ¶‰åŠä¸‰ä¸ªè§’è‰²ï¼šæ•°æ®ä¸»ä½“ã€æ•°æ®å‘é€è€…å’Œæ•°æ®æ¥æ”¶è€…ã€‚å°½ç®¡æ•°æ®ä¸»ä½“çš„è¡Œä¸ºæ˜¯å›ºå®šçš„ï¼Œæ”»å‡»è€…ï¼ˆæ•°æ®æ¥æ”¶è€…ï¼‰ä»é€šè¿‡æŒç»­ä¸”äº’åŠ¨çš„äº¤æ¢è¯•å›¾ä»é˜²å¾¡è€…ï¼ˆæ•°æ®å‘é€è€…ï¼‰å¤„æå–æ•æ„Ÿä¿¡æ¯ã€‚ä¸ºäº†é«˜æ•ˆåœ°æ¢ç´¢è¿™ä¸€äº¤äº’ç©ºé—´ï¼Œæˆ‘ä»¬çš„æœç´¢ç®—æ³•å°† LLM ç”¨ä½œä¼˜åŒ–å™¨ï¼Œé‡‡ç”¨å¤šçº¿ç¨‹å¹¶è¡Œæœç´¢å’Œè·¨çº¿ç¨‹ä¼ æ’­æ¥åˆ†ææ¨¡æ‹Ÿè½¨è¿¹å¹¶è¿­ä»£åœ°æå‡ºæ–°æŒ‡ä»¤ã€‚ é€šè¿‡è¿™ä¸ªè¿‡ç¨‹ï¼Œæˆ‘ä»¬å‘ç°æ”»å‡»ç­–ç•¥ä»ç®€å•çš„ç›´æ¥è¯·æ±‚é€æ­¥å‡çº§ä¸ºå¤æ‚çš„å¤šå›åˆç­–ç•¥ï¼Œå¦‚å†’å……å’Œä¼ªé€ åŒæ„ï¼›è€Œé˜²å¾¡æªæ–½åˆ™ä»åŸºäºè§„åˆ™çš„çº¦æŸå‘å±•ä¸ºèº«ä»½éªŒè¯çŠ¶æ€æœºã€‚æ‰€å‘ç°çš„æ”»å‡»ä¸é˜²å¾¡åœ¨ä¸åŒåœºæ™¯å’Œä¸»å¹²æ¨¡å‹ä¹‹é—´å…·æœ‰å¯è¿ç§»æ€§ï¼Œå±•ç¤ºäº†åœ¨æ„å»ºå…·å¤‡éšç§æ„è¯†ä»£ç†æ–¹é¢çš„å¼ºå¤§å®ç”¨æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 17:49:09 UTC
å‘å¸ƒï¼š2025-08-14 17:49:09 UTC</p>
<h2 id="75-memory-augmented-transformers-a-systematic-review-from-neuroscience-principles-to-technical-solutions--75-è®°å¿†å¢å¼ºå‹å˜å‹å™¨ä»ç¥ç»ç§‘å­¦åŸç†åˆ°æŠ€æœ¯è§£å†³æ–¹æ¡ˆçš„ç³»ç»Ÿç»¼è¿°"><a href="https://arxiv.org/abs/2508.10824"target="_blank" rel="external nofollow noopener noreferrer">#75</a> <a href="https://papers.cool/arxiv/2508.10824"target="_blank" rel="external nofollow noopener noreferrer">Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions</a>  #75 è®°å¿†å¢å¼ºå‹å˜å‹å™¨ï¼šä»ç¥ç»ç§‘å­¦åŸç†åˆ°æŠ€æœ¯è§£å†³æ–¹æ¡ˆçš„ç³»ç»Ÿç»¼è¿°</h2>
<p><strong>Authors</strong>: [Parsa Omidi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Parsa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Parsa</a> Omidi), [Xingshuai Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xingshuai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xingshuai</a> Huang), [Axel Laborieux](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Axel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Axel</a> Laborieux), [Bahareh Nikpour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bahareh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bahareh</a> Nikpour), [Tianyu Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyu</a> Shi), [Armaghan Eshaghi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Armaghan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Armaghan</a> Eshaghi)
ä½œè€…ï¼šParsa Omidiã€Xingshuai Huangã€Axel Laborieuxã€Bahareh Nikpourã€Tianyu Shiã€Armaghan Eshaghi</p>
<p>Memory is fundamental to intelligence, enabling learning, reasoning, and adaptability across biological and artificial systems. While Transformer architectures excel at sequence modeling, they face critical limitations in long-range context retention, continual learning, and knowledge integration. This review presents a unified framework bridging neuroscience principles, including dynamic multi-timescale memory, selective attention, and consolidation, with engineering advances in Memory-Augmented Transformers. We organize recent progress through three taxonomic dimensions: functional objectives (context extension, reasoning, knowledge integration, adaptation), memory representations (parameter-encoded, state-based, explicit, hybrid), and integration mechanisms (attention fusion, gated control, associative retrieval). Our analysis of core memory operations (reading, writing, forgetting, and capacity management) reveals a shift from static caches toward adaptive, test-time learning systems. We identify persistent challenges in scalability and interference, alongside emerging solutions including hierarchical buffering and surprise-gated updates. This synthesis provides a roadmap toward cognitively-inspired, lifelong-learning Transformer architectures.
è®°å¿†æ˜¯æ™ºèƒ½çš„åŸºç¡€ï¼Œä½¿ç”Ÿç‰©ä¸äººå·¥ç³»ç»Ÿèƒ½å¤Ÿå­¦ä¹ ã€æ¨ç†å’Œé€‚åº”ã€‚å°½ç®¡ Transformer æ¶æ„åœ¨åºåˆ—å»ºæ¨¡æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨é•¿ç¨‹ä¸Šä¸‹æ–‡ä¿ç•™ã€æŒç»­å­¦ä¹ å’ŒçŸ¥è¯†æ•´åˆæ–¹é¢ä»é¢ä¸´å…³é”®é™åˆ¶ã€‚æœ¬æ–‡ç»¼è¿°æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€æ¡†æ¶ï¼Œå°†ç¥ç»ç§‘å­¦åŸç†ï¼ˆåŒ…æ‹¬åŠ¨æ€å¤šæ—¶é—´å°ºåº¦è®°å¿†ã€é€‰æ‹©æ€§æ³¨æ„å’Œå·©å›ºï¼‰ä¸å¢å¼ºè®°å¿†çš„ Transformer å·¥ç¨‹è¿›å±•ç›¸ç»“åˆã€‚æˆ‘ä»¬é€šè¿‡ä¸‰ä¸ªåˆ†ç±»ç»´åº¦æ¥ç»„ç»‡è¿‘æœŸè¿›å±•ï¼šåŠŸèƒ½ç›®æ ‡ï¼ˆä¸Šä¸‹æ–‡æ‰©å±•ã€æ¨ç†ã€çŸ¥è¯†æ•´åˆã€é€‚åº”ï¼‰ã€è®°å¿†è¡¨ç¤ºï¼ˆå‚æ•°ç¼–ç ã€åŸºäºçŠ¶æ€ã€æ˜¾å¼ã€æ··åˆï¼‰å’Œæ•´åˆæœºåˆ¶ï¼ˆæ³¨æ„åŠ›èåˆã€é—¨æ§æ§åˆ¶ã€è”æƒ³æ£€ç´¢ï¼‰ã€‚æˆ‘ä»¬å¯¹æ ¸å¿ƒè®°å¿†æ“ä½œï¼ˆè¯»å–ã€å†™å…¥ã€é—å¿˜å’Œå®¹é‡ç®¡ç†ï¼‰çš„åˆ†ææ˜¾ç¤ºï¼Œç³»ç»Ÿæ­£åœ¨ä»é™æ€ç¼“å­˜å‘è‡ªé€‚åº”çš„æµ‹è¯•æ—¶å­¦ä¹ ç³»ç»Ÿè½¬å˜ã€‚æˆ‘ä»¬è¯†åˆ«å‡ºå¯æ‰©å±•æ€§å’Œå¹²æ‰°æ–¹é¢çš„æŒç»­æŒ‘æˆ˜ï¼ŒåŒæ—¶æŒ‡å‡ºåŒ…æ‹¬åˆ†çº§ç¼“å†²å’ŒåŸºäºæƒŠè®¶çš„é—¨æ§æ›´æ–°åœ¨å†…çš„æ–°å…´è§£å†³æ–¹æ¡ˆã€‚ è¯¥ç»¼è¿°ä¸ºä»¥è®¤çŸ¥ä¸ºçµæ„Ÿçš„ç»ˆèº«å­¦ä¹  Transformer æ¶æ„æä¾›äº†ä¸€æ¡è·¯çº¿å›¾ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 16:48:38 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 16:48:38 UTC</p>
<h2 id="76-passk-training-for-adaptively-balancing-exploration-and-exploitation-of-large-reasoning-models--76-passk-è®­ç»ƒç”¨äºè‡ªé€‚åº”å¹³è¡¡å¤§è§„æ¨¡æ¨ç†æ¨¡å‹çš„æ¢ç´¢ä¸åˆ©ç”¨"><a href="https://arxiv.org/abs/2508.10751"target="_blank" rel="external nofollow noopener noreferrer">#76</a> <a href="https://papers.cool/arxiv/2508.10751"target="_blank" rel="external nofollow noopener noreferrer">Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models</a>  #76 Pass@k è®­ç»ƒç”¨äºè‡ªé€‚åº”å¹³è¡¡å¤§è§„æ¨¡æ¨ç†æ¨¡å‹çš„æ¢ç´¢ä¸åˆ©ç”¨</h2>
<p><strong>Authors</strong>: [Zhipeng Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhipeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhipeng</a> Chen), [Xiaobo Qin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaobo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaobo</a> Qin), [Youbin Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youbin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youbin</a> Wu), [Yue Ling](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yue</a> Ling), [Qinghao Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qinghao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qinghao</a> Ye), [Wayne Xin Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wayne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wayne</a> Xin Zhao), [Guang Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guang</a> Shi)
ä½œè€…ï¼šé™ˆå¿—é¹ã€ç§¦å°åšã€å´æœ‰æ»¨ã€å‡Œè¶Šã€å¶åº†æµ©ã€èµµæ–°æ–‡ã€å²å…‰</p>
<p>Reinforcement learning with verifiable rewards (RLVR), which typically adopts Pass@1 as the reward, has faced the issues in balancing exploration and exploitation, causing policies to prefer conservative actions, converging to a local optimum. Identifying an appropriate reward metric is therefore crucial. Regarding the prior work, although Pass@k has been used in evaluation, its connection to LLM exploration ability in RLVR remains largely overlooked. To investigate this, we first use Pass@k as the reward to train the policy model (i.e., Pass@k Training), and observe the improvement on its exploration ability. Next, we derive an analytical solution for the advantage of Pass@k Training, leading to an efficient and effective process. Building on this, our analysis reveals that exploration and exploitation are not inherently conflicting objectives, while they can mutually enhance each other. Moreover, Pass@k Training with analytical derivation essentially involves directly designing the advantage function. Inspired by this, we preliminarily explore the advantage design for RLVR, showing promising results and highlighting a potential future direction.
å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ï¼Œé€šå¸¸é‡‡ç”¨ Pass@1 ä½œä¸ºå¥–åŠ±ï¼Œåœ¨æ¢ç´¢ä¸åˆ©ç”¨ä¹‹é—´å–å¾—å¹³è¡¡æ–¹é¢å­˜åœ¨é—®é¢˜ï¼Œå¯¼è‡´ç­–ç•¥åå‘ä¿å®ˆåŠ¨ä½œï¼Œæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è§£ã€‚å› æ­¤ï¼Œç¡®å®šåˆé€‚çš„å¥–åŠ±åº¦é‡è‡³å…³é‡è¦ã€‚å…³äºå…ˆå‰å·¥ä½œï¼Œå°½ç®¡åœ¨è¯„ä¼°ä¸­ä½¿ç”¨äº† Pass@kï¼Œä½†å…¶ä¸ RLVR ä¸­ LLM æ¢ç´¢èƒ½åŠ›çš„è”ç³»åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè¢«å¿½è§†äº†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ Pass@k ä½œä¸ºå¥–åŠ±æ¥è®­ç»ƒç­–ç•¥æ¨¡å‹ï¼ˆå³ ï¼‰ï¼Œå¹¶è§‚å¯Ÿåˆ°å…¶æ¢ç´¢èƒ½åŠ›çš„æå‡ã€‚æ¥ç€ï¼Œæˆ‘ä»¬æ¨å¯¼å‡º Pass@k è®­ç»ƒä¼˜åŠ¿çš„è§£æè§£ï¼Œä»è€Œå¾—åˆ°ä¸€ç§é«˜æ•ˆä¸”æœ‰æ•ˆçš„è¿‡ç¨‹ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬çš„åˆ†æè¡¨æ˜æ¢ç´¢ä¸åˆ©ç”¨å¹¶éæœ¬è´¨ä¸Šçš„å¯¹ç«‹ç›®æ ‡ï¼ŒäºŒè€…å¯ä»¥ç›¸äº’ä¿ƒè¿›ã€‚æ­¤å¤–ï¼Œå¸¦æœ‰è§£ææ¨å¯¼çš„ Pass@k è®­ç»ƒæœ¬è´¨ä¸Šæ¶‰åŠç›´æ¥è®¾è®¡ä¼˜åŠ¿å‡½æ•°ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬åˆæ­¥æ¢ç´¢äº†ç”¨äº RLVR çš„ä¼˜åŠ¿è®¾è®¡ï¼Œå±•ç¤ºäº†æœ‰å¸Œæœ›çš„ç»“æœå¹¶æŒ‡å‡ºäº†ä¸€ä¸ªæ½œåœ¨çš„æœªæ¥æ–¹å‘ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 15:34:47 UTC</p>
<h2 id="77-stabilizing-long-term-multi-turn-reinforcement-learning-with-gated-rewards--77-ä½¿ç”¨é—¨æ§å¥–åŠ±ç¨³å®šé•¿æœŸå¤šå›åˆå¼ºåŒ–å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10548"target="_blank" rel="external nofollow noopener noreferrer">#77</a> <a href="https://papers.cool/arxiv/2508.10548"target="_blank" rel="external nofollow noopener noreferrer">Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards</a>  #77 ä½¿ç”¨é—¨æ§å¥–åŠ±ç¨³å®šé•¿æœŸå¤šå›åˆå¼ºåŒ–å­¦ä¹ </h2>
<p><strong>Authors</strong>: [Zetian Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zetian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zetian</a> Sun), [Dongfang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongfang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongfang</a> Li), [Zhuoen Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuoen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuoen</a> Chen), [Yuhuai Qin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhuai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhuai</a> Qin), [Baotian Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baotian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baotian</a> Hu)
ä½œè€…ï¼šå­™æ³½å¤©ã€æä¸œæ–¹ã€é™ˆå“æ©ã€ç§¦å®‡æ·®ã€èƒ¡å®å¤©</p>
<p>Reward sparsity in long-horizon reinforcement learning (RL) tasks remains a significant challenge, while existing outcome-based reward shaping struggles to define meaningful immediate rewards without introducing bias or requiring explicit task decomposition. Alternatively, verification-based reward shaping uses stepwise critics, but misalignment between immediate rewards and long-term objectives can lead to reward hacking and suboptimal policies. In this work, we address this problem in the context of software engineering (SWE) tasks, where multi-turn reasoning and rule-based verification are critical. We introduce the SWE-oriented RL Framework, a unified system supporting multi-turn interaction, docker-based execution, and customizable reward functions. Additionally, we propose Gated Reward Accumulation (G-RA), a novel method that accumulates immediate rewards only when high-level (long-term) rewards meet a predefined threshold, ensuring stable RL optimization. Experiments on SWE-bench Verified and kBench demonstrate that G-RA leads to an increase in completion rates (47.6% \rightarrow 93.8% and 22.0% \rightarrow 86.0%) and modification rates (19.6% \rightarrow 23.8% and 12.0% \rightarrow 42.0%), while avoiding policy degradation caused by reward misalignment. Our findings highlight the importance of balanced reward accumulation in long-horizon RL and provide a practical solution.
åœ¨é•¿æ—¶ç¨‹å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»»åŠ¡ä¸­ï¼Œå¥–åŠ±ç¨€ç–æ€§ä»ç„¶æ˜¯ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ï¼Œè€Œç°æœ‰åŸºäºç»“æœçš„å¥–åŠ±å¡‘é€ éš¾ä»¥åœ¨ä¸å¼•å…¥åå·®æˆ–ä¸éœ€è¦æ˜¾å¼ä»»åŠ¡åˆ†è§£çš„æƒ…å†µä¸‹å®šä¹‰æœ‰æ„ä¹‰çš„å³æ—¶å¥–åŠ±ã€‚å¦ä¸€ç§åŸºäºéªŒè¯çš„å¥–åŠ±å¡‘é€ ä½¿ç”¨é€æ­¥è¯„åˆ†å™¨ï¼Œä½†å³æ—¶å¥–åŠ±ä¸é•¿æœŸç›®æ ‡ä¹‹é—´çš„ä¸ä¸€è‡´å¯èƒ½å¯¼è‡´å¥–åŠ±è¢«æ“çºµå’Œæ¬¡ä¼˜ç­–ç•¥ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨è½¯ä»¶å·¥ç¨‹ï¼ˆSWEï¼‰ä»»åŠ¡çš„èƒŒæ™¯ä¸‹è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œåœ¨æ­¤ç±»ä»»åŠ¡ä¸­å¤šå›åˆæ¨ç†å’ŒåŸºäºè§„åˆ™çš„éªŒè¯è‡³å…³é‡è¦ã€‚æˆ‘ä»¬å¼•å…¥äº†é¢å‘ SWE çš„ RL æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªæ”¯æŒå¤šå›åˆäº¤äº’ã€åŸºäº docker çš„æ‰§è¡Œå’Œå¯å®šåˆ¶å¥–åŠ±å‡½æ•°çš„ç»Ÿä¸€ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†é—¨æ§å¥–åŠ±ç´¯ç§¯ï¼ˆG-RAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œä»…å½“é«˜å±‚ï¼ˆé•¿æœŸï¼‰å¥–åŠ±è¾¾åˆ°é¢„å®šä¹‰é˜ˆå€¼æ—¶æ‰ç´¯ç§¯å³æ—¶å¥–åŠ±ï¼Œä»è€Œä¿è¯äº†ç¨³å®šçš„ RL ä¼˜åŒ–ã€‚ åœ¨ SWE-bench Verified å’Œ kBench ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒG-RA æé«˜äº†å®Œæˆç‡ï¼ˆ47.6% â†’ 93.8% å’Œ 22.0% â†’ 86.0%ï¼‰å’Œä¿®æ”¹ç‡ï¼ˆ19.6% â†’ 23.8% å’Œ 12.0% â†’ 42.0%ï¼‰ï¼ŒåŒæ—¶é¿å…äº†ç”±å¥–åŠ±ä¸ä¸€è‡´å¯¼è‡´çš„ç­–ç•¥é€€åŒ–ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†åœ¨é•¿æ—¶ç¨‹å¼ºåŒ–å­¦ä¹ ä¸­å¹³è¡¡å¥–åŠ±ç´¯ç§¯çš„é‡è¦æ€§ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªå®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 11:37:02 UTC
å‘å¸ƒï¼š2025-08-14 11:37:02 UTC</p>
<h2 id="78-improving-value-based-process-verifier-via-low-cost-variance-reduction"><a href="https://arxiv.org/abs/2508.10539"target="_blank" rel="external nofollow noopener noreferrer">#78</a> <a href="https://papers.cool/arxiv/2508.10539"target="_blank" rel="external nofollow noopener noreferrer">Improving Value-based Process Verifier via Low-Cost Variance Reduction</a></h2>
<p><strong>Authors</strong>: [Zetian Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zetian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zetian</a> Sun), [Dongfang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongfang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongfang</a> Li), [Baotian Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baotian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baotian</a> Hu), [Min Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Min"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Min</a> Zhang)
ä½œè€…ï¼šå­™æ³½å¤©ã€æä¸œæ–¹ã€èƒ¡ä¿å¤©ã€å¼ æ•</p>
<p>Large language models (LLMs) have achieved remarkable success in a wide range of tasks. However, their reasoning capabilities, particularly in complex domains like mathematics, remain a significant challenge. Value-based process verifiers, which estimate the probability of a partial reasoning chain leading to a correct solution, are a promising approach for improving reasoning. Nevertheless, their effectiveness is often hindered by estimation error in their training annotations, a consequence of the limited number of Monte Carlo (MC) samples feasible due to the high cost of LLM inference. In this paper, we identify that the estimation error primarily arises from high variance rather than bias, and the MC estimator is a Minimum Variance Unbiased Estimator (MVUE). To address the problem, we propose the \textsc{Com}pound \textsc{M}onte \textsc{C}arlo \textsc{S}ampling (ComMCS) method, which constructs an unbiased estimator by linearly combining the MC estimators from the current and subsequent steps. Theoretically, we show that our method leads to a predictable reduction in variance, while maintaining an unbiased estimation without additional LLM inference cost. We also perform empirical experiments on the MATH-500 and GSM8K benchmarks to demonstrate the effectiveness of our method. Notably, ComMCS outperforms regression-based optimization method by 2.8 points, the non-variance-reduced baseline by 2.2 points on MATH-500 on Best-of-32 sampling experiment.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¹¿æ³›ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­¦ç­‰å¤æ‚é¢†åŸŸï¼Œä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚åŸºäºä»·å€¼çš„è¿‡ç¨‹éªŒè¯å™¨é€šè¿‡ä¼°è®¡éƒ¨åˆ†æ¨ç†é“¾å¯¼è‡´æ­£ç¡®è§£çš„æ¦‚ç‡ï¼Œæ˜¯æ”¹è¿›æ¨ç†çš„ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œç”±äº LLM æ¨ç†æˆæœ¬é«˜æ˜‚ï¼Œå¯è¡Œçš„è’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ ·æœ¬æ•°é‡æœ‰é™ï¼Œè¿™å¯¼è‡´è®­ç»ƒæ³¨é‡Šä¸­çš„ä¼°è®¡è¯¯å·®ï¼Œä»è€Œå¸¸å¸¸é˜»ç¢äº†å®ƒä»¬çš„æœ‰æ•ˆæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æŒ‡å‡ºä¼°è®¡è¯¯å·®ä¸»è¦æºäºé«˜æ–¹å·®è€Œéåå·®ï¼Œå¹¶ä¸” MC ä¼°è®¡é‡æ˜¯æœ€å°æ–¹å·®æ— åä¼°è®¡é‡ï¼ˆMVUEï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤åˆè’™ç‰¹å¡æ´›é‡‡æ ·ï¼ˆComMCSï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡çº¿æ€§ç»„åˆå½“å‰åŠåç»­æ­¥éª¤çš„ MC ä¼°è®¡é‡æ¥æ„å»ºæ— åä¼°è®¡é‡ã€‚åœ¨ç†è®ºä¸Šï¼Œæˆ‘ä»¬è¯æ˜äº†è¯¥æ–¹æ³•åœ¨ä¸å¢åŠ é¢å¤– LLM æ¨ç†æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿå¸¦æ¥å¯é¢„æµ‹çš„æ–¹å·®é™ä½ï¼ŒåŒæ—¶ä¿æŒæ— åä¼°è®¡ã€‚ æˆ‘ä»¬è¿˜åœ¨ MATH-500 å’Œ GSM8K åŸºå‡†ä¸Šè¿›è¡Œäº†å®è¯å®éªŒï¼Œä»¥è¯æ˜æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ Best-of-32 é‡‡æ ·å®éªŒä¸­ï¼ŒComMCS åœ¨ MATH-500 ä¸Šæ¯”åŸºäºå›å½’çš„ä¼˜åŒ–æ–¹æ³•é«˜å‡º 2.8 ä¸ªç‚¹ï¼Œæ¯”æœªè¿›è¡Œæ–¹å·®å‡å°‘çš„åŸºçº¿é«˜å‡º 2.2 ä¸ªç‚¹ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 11:22:29 UTC
å‘å¸ƒï¼š2025-08-14 11:22:29 UTC</p>
<h2 id="79-diversity-first-quality-later-a-two-stage-assumption-for-language-model-alignment--79-å¤šæ ·æ€§ä¼˜å…ˆè´¨é‡é åè¯­è¨€æ¨¡å‹å¯¹é½çš„ä¸¤é˜¶æ®µå‡è®¾"><a href="https://arxiv.org/abs/2508.10530"target="_blank" rel="external nofollow noopener noreferrer">#79</a> <a href="https://papers.cool/arxiv/2508.10530"target="_blank" rel="external nofollow noopener noreferrer">Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment</a>  #79 å¤šæ ·æ€§ä¼˜å…ˆï¼Œè´¨é‡é åï¼šè¯­è¨€æ¨¡å‹å¯¹é½çš„ä¸¤é˜¶æ®µå‡è®¾</h2>
<p><strong>Authors</strong>: [Zetian Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zetian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zetian</a> Sun), [Dongfang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongfang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongfang</a> Li), [Baotian Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baotian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baotian</a> Hu)
ä½œè€…ï¼šå­™æ³½å¤©ï¼Œæä¸œèŠ³ï¼Œèƒ¡å®å¤©</p>
<p>The alignment of language models (LMs) with human preferences is critical for building reliable AI systems. The problem is typically framed as optimizing an LM policy to maximize the expected reward that reflects human preferences. Recently, Direct Preference Optimization (DPO) was proposed as a LM alignment method that directly optimize the policy from static preference data, and further improved by incorporating on-policy sampling (i.e., preference candidates generated during the training loop) for better LM alignment. However, we show on-policy data is not always optimal, with systematic effectiveness difference emerging between static and on-policy preference candidates. For example, on-policy data can result in a 3Ã— effectiveness compared with static data for Llama-3, and a 0.4Ã— effectiveness for Zephyr. To explain the phenomenon, we propose the alignment stage assumption, which divides the alignment process into two distinct stages: the preference injection stage, which benefits from diverse data, and the preference fine-tuning stage, which favors high-quality data. Through theoretical and empirical analysis, we characterize these stages and propose an effective algorithm to identify the boundaries between them. We perform experiments on 5 models (Llama, Zephyr, Phi-2, Qwen, Pythia) and 2 alignment methods (DPO, SLiC-HF) to show the generalizability of alignment stage assumption and boundary measurement.
è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰ä¸äººç±»åå¥½çš„å¯¹é½å¯¹äºæ„å»ºå¯é çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè‡³å…³é‡è¦ã€‚è¯¥é—®é¢˜é€šå¸¸è¢«è¡¨è¿°ä¸ºä¼˜åŒ–ä¸€ä¸ªè¯­è¨€æ¨¡å‹ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–åæ˜ äººç±»åå¥½çš„æœŸæœ›å¥–åŠ±ã€‚æœ€è¿‘ï¼Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimizationï¼ŒDPOï¼‰è¢«æå‡ºä½œä¸ºä¸€ç§ä»é™æ€åå¥½æ•°æ®ç›´æ¥ä¼˜åŒ–ç­–ç•¥çš„ LM å¯¹é½æ–¹æ³•ï¼Œå¹¶é€šè¿‡å¼•å…¥åœ¨ç­–ç•¥å†…é‡‡æ ·ï¼ˆå³åœ¨è®­ç»ƒå¾ªç¯ä¸­ç”Ÿæˆçš„åå¥½å€™é€‰ï¼‰æ¥è¿›ä¸€æ­¥æ”¹è¿›ä»¥è·å¾—æ›´å¥½çš„ LM å¯¹é½æ•ˆæœã€‚ç„¶è€Œï¼Œæˆ‘ä»¬è¯æ˜äº†åœ¨ç­–ç•¥å†…æ•°æ®å¹¶ä¸æ€»æ˜¯æœ€ä¼˜çš„ï¼Œé™æ€åå¥½å€™é€‰ä¸åœ¨ç­–ç•¥å†…åå¥½å€™é€‰ä¹‹é—´å­˜åœ¨ç³»ç»Ÿæ€§çš„æ•ˆæœå·®å¼‚ã€‚ä¾‹å¦‚ï¼Œå¯¹äº Llama-3ï¼Œåœ¨ç­–ç•¥å†…æ•°æ®ç›¸æ¯”é™æ€æ•°æ®å¯èƒ½å¯¼è‡´ 3 Ã— çš„æ•ˆæœå·®å¼‚ï¼Œè€Œå¯¹äº Zephyr åˆ™å¯èƒ½å¯¼è‡´ 0.4 Ã— çš„æ•ˆæœå·®å¼‚ã€‚ä¸ºäº†è§£é‡Šè¿™ä¸€ç°è±¡ï¼Œæˆ‘ä»¬æå‡ºäº†å¯¹é½é˜¶æ®µå‡è®¾ï¼Œå°†å¯¹é½è¿‡ç¨‹åˆ’åˆ†ä¸ºä¸¤ä¸ªä¸åŒçš„é˜¶æ®µï¼šåå¥½æ³¨å…¥é˜¶æ®µï¼Œè¯¥é˜¶æ®µä»å¤šæ ·åŒ–çš„æ•°æ®ä¸­å—ç›Šï¼›ä»¥åŠåå¥½å¾®è°ƒé˜¶æ®µï¼Œè¯¥é˜¶æ®µåå¥½é«˜è´¨é‡çš„æ•°æ®ã€‚ é€šè¿‡ç†è®ºå’Œå®è¯åˆ†æï¼Œæˆ‘ä»¬å¯¹è¿™äº›é˜¶æ®µè¿›è¡Œäº†åˆ»ç”»ï¼Œå¹¶æå‡ºäº†ä¸€ç§æœ‰æ•ˆçš„ç®—æ³•æ¥è¯†åˆ«å®ƒä»¬ä¹‹é—´çš„è¾¹ç•Œã€‚æˆ‘ä»¬åœ¨ 5 ä¸ªæ¨¡å‹ï¼ˆLlamaã€Zephyrã€Phi-2ã€Qwenã€Pythiaï¼‰å’Œ 2 ç§å¯¹é½æ–¹æ³•ï¼ˆDPOã€SLiC-HFï¼‰ä¸Šè¿›è¡Œäº†å®éªŒï¼Œä»¥å±•ç¤ºå¯¹é½é˜¶æ®µå‡è®¾å’Œè¾¹ç•Œæµ‹é‡çš„æ™®é€‚æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 11:05:18 UTC
å‘å¸ƒï¼š2025-08-14 11:05:18 UTC</p>
<h2 id="80-reverse-physician-ai-relationship-full-process-clinical-diagnosis-driven-by-a-large-language-model--80-é¢ å€’çš„åŒ»å¸ˆäººå·¥æ™ºèƒ½å…³ç³»ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­"><a href="https://arxiv.org/abs/2508.10492"target="_blank" rel="external nofollow noopener noreferrer">#80</a> <a href="https://papers.cool/arxiv/2508.10492"target="_blank" rel="external nofollow noopener noreferrer">Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model</a>  #80 é¢ å€’çš„åŒ»å¸ˆâ€”äººå·¥æ™ºèƒ½å…³ç³»ï¼šç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­</h2>
<p><strong>Authors</strong>: [Shicheng Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shicheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shicheng</a> Xu), [Xin Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Huang), [Zihao Wei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zihao</a> Wei), [Liang Pang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liang</a> Pang), [Huawei Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huawei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huawei</a> Shen), [Xueqi Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xueqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xueqi</a> Cheng)
ä½œè€…ï¼šå¾ä¸–æˆã€é»„æ˜•ã€é­å­è±ªã€åºäº®ã€æ²ˆåä¸ºã€ç¨‹é›ªçª</p>
<p>Full-process clinical diagnosis in the real world encompasses the entire diagnostic workflow that begins with only an ambiguous chief complaint. While artificial intelligence (AI), particularly large language models (LLMs), is transforming clinical diagnosis, its role remains largely as an assistant to physicians. This AI-assisted working pattern makes AI can only answer specific medical questions at certain parts within the diagnostic process, but lack the ability to drive the entire diagnostic process starting from an ambiguous complaint, which still relies heavily on human physicians. This gap limits AI&rsquo;s ability to fully reduce physicians&rsquo; workload and enhance diagnostic efficiency. To address this, we propose a paradigm shift that reverses the relationship between physicians and AI: repositioning AI as the primary director, with physicians serving as its assistants. So we present DxDirector-7B, an LLM endowed with advanced deep thinking capabilities, enabling it to drive the full-process diagnosis with minimal physician involvement. Furthermore, DxDirector-7B establishes a robust accountability framework for misdiagnoses, delineating responsibility between AI and human physicians. In evaluations across rare, complex, and real-world cases under full-process diagnosis setting, DxDirector-7B not only achieves significant superior diagnostic accuracy but also substantially reduces physician workload than state-of-the-art medical LLMs as well as general-purpose LLMs. Fine-grained analyses across multiple clinical departments and tasks validate its efficacy, with expert evaluations indicating its potential to serve as a viable substitute for medical specialists. These findings mark a new era where AI, traditionally a physicians&rsquo; assistant, now drives the entire diagnostic process to drastically reduce physicians&rsquo; workload, indicating an efficient and accurate diagnostic solution.
ç°å®ä¸–ç•Œä¸­çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­æ¶µç›–äº†ä»ä»…æœ‰æ¨¡ç³Šä¸»è¯‰å¼€å§‹çš„æ•´ä¸ªè¯Šæ–­å·¥ä½œæµã€‚è™½ç„¶äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ï¼Œå°¤å…¶æ˜¯ LLMsï¼Œæ­£åœ¨æ”¹å˜ä¸´åºŠè¯Šæ–­ï¼Œä½†å…¶ä½œç”¨åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä»æ˜¯ä½œä¸ºåŒ»ç”Ÿçš„åŠ©æ‰‹ã€‚è¿™ç§ AI è¾…åŠ©çš„å·¥ä½œæ¨¡å¼ä½¿å¾— AI åªèƒ½åœ¨è¯Šæ–­è¿‡ç¨‹çš„æŸäº›ç¯èŠ‚å›ç­”ç‰¹å®šçš„åŒ»å­¦é—®é¢˜ï¼Œè€Œç¼ºä¹ä»æ¨¡ç³Šä¸»è¯‰å‡ºå‘é©±åŠ¨æ•´ä¸ªè¯Šæ–­è¿‡ç¨‹çš„èƒ½åŠ›ï¼Œä»ç„¶é«˜åº¦ä¾èµ–äººç±»åŒ»ç”Ÿã€‚è¿™ä¸€å·®è·é™åˆ¶äº† AI åœ¨å…¨é¢å‡è½»åŒ»ç”Ÿå·¥ä½œè´Ÿæ‹…å’Œæå‡è¯Šæ–­æ•ˆç‡æ–¹é¢çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªèŒƒå¼è½¬å˜ï¼Œé¢ è¦†åŒ»ç”Ÿä¸ AI ä¹‹é—´çš„å…³ç³»ï¼šå°† AI é‡æ–°å®šä½ä¸ºä¸»è¦æŒ‡æŒ¥è€…ï¼ŒåŒ»ç”Ÿåˆ™ä½œä¸ºå…¶åŠ©æ‰‹ã€‚å› æ­¤æˆ‘ä»¬æå‡ºäº† DxDirector-7Bï¼Œä¸€æ¬¾å…·å¤‡é«˜çº§æ·±åº¦æ€è€ƒèƒ½åŠ›çš„ LLMï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨æœ€å°‘åŒ»ç”Ÿå‚ä¸çš„æƒ…å†µä¸‹é©±åŠ¨å…¨æµç¨‹è¯Šæ–­ã€‚ æ­¤å¤–ï¼ŒDxDirector-7B å»ºç«‹äº†ä¸€ä¸ªé’ˆå¯¹è¯¯è¯Šçš„å¼ºæœ‰åŠ›é—®è´£æ¡†æ¶ï¼Œæ˜ç¡®åˆ’åˆ†äº† AI ä¸äººç±»åŒ»ç”Ÿä¹‹é—´çš„è´£ä»»ã€‚åœ¨å…¨æµç¨‹è¯Šæ–­è®¾ç½®ä¸‹å¯¹ç½•è§ã€å¤æ‚åŠçœŸå®ç—…ä¾‹çš„è¯„ä¼°ä¸­ï¼ŒDxDirector-7B ä¸ä»…åœ¨è¯Šæ–­å‡†ç¡®ç‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰é¢†å…ˆçš„åŒ»å­¦ LLMs åŠé€šç”¨ LLMsï¼Œè€Œä¸”å¤§å¹…é™ä½äº†åŒ»ç”Ÿçš„å·¥ä½œè´Ÿæ‹…ã€‚å¯¹å¤šä¸ªä¸´åºŠç§‘å®¤å’Œä»»åŠ¡æ‰€åšçš„ç»†ç²’åº¦åˆ†æéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œä¸“å®¶è¯„ä¼°è¡¨æ˜å…¶æœ‰æœ›æˆä¸ºåŒ»ç–—ä¸“å®¶çš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆã€‚è¿™äº›å‘ç°æ ‡å¿—ç€ä¸€ä¸ªæ–°æ—¶ä»£ï¼šAI ä»ä¼ ç»Ÿçš„åŒ»ç”ŸåŠ©æ‰‹è§’è‰²ï¼Œå‘å±•ä¸ºé©±åŠ¨æ•´ä¸ªè¯Šæ–­è¿‡ç¨‹ï¼Œä»è€Œå¤§å¹…å‡è½»åŒ»ç”Ÿå·¥ä½œé‡ï¼Œä½“ç°å‡ºä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„è¯Šæ–­è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">Computational Engineering, Finance, and Science</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ã€è®¡ç®—å·¥ç¨‹ã€é‡‘èä¸ç§‘å­¦ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 09:51:20 UTC
å‘å¸ƒï¼š2025-08-14 09:51:20 UTC</p>
<h2 id="81-correctnav-self-correction-flywheel-empowers-vision-language-action-navigation-model--81-correctnavè‡ªæˆ‘çº æ­£é£è½®èµ‹èƒ½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨å¯¼èˆªæ¨¡å‹"><a href="https://arxiv.org/abs/2508.10416"target="_blank" rel="external nofollow noopener noreferrer">#81</a> <a href="https://papers.cool/arxiv/2508.10416"target="_blank" rel="external nofollow noopener noreferrer">CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model</a>  #81 CorrectNavï¼šè‡ªæˆ‘çº æ­£é£è½®èµ‹èƒ½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨å¯¼èˆªæ¨¡å‹</h2>
<p><strong>Authors</strong>: [Zhuoyuan Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuoyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuoyuan</a> Yu), [Yuxing Long](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxing</a> Long), [Zihan Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zihan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zihan</a> Yang), [Chengyan Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengyan</a> Zeng), [Hongwei Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongwei</a> Fan), [Jiyao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiyao</a> Zhang), [Hao Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hao</a> Dong)
ä½œè€…ï¼šä½™å“è¿œï¼Œé¾™å®‡æ˜Ÿï¼Œæ¨å­æ¶µï¼Œæ›¾æˆè¨€ï¼ŒèŒƒå®ä¼Ÿï¼Œå¼ ä½³å°§ï¼Œè‘£æµ©</p>
<p>Existing vision-and-language navigation models often deviate from the correct trajectory when executing instructions. However, these models lack effective error correction capability, hindering their recovery from errors. To address this challenge, we propose Self-correction Flywheel, a novel post-training paradigm. Instead of considering the model&rsquo;s error trajectories on the training set as a drawback, our paradigm emphasizes their significance as a valuable data source. We have developed a method to identify deviations in these error trajectories and devised innovative techniques to automatically generate self-correction data for perception and action. These self-correction data serve as fuel to power the model&rsquo;s continued training. The brilliance of our paradigm is revealed when we re-evaluate the model on the training set, uncovering new error trajectories. At this time, the self-correction flywheel begins to spin. Through multiple flywheel iterations, we progressively enhance our monocular RGB-based VLA navigation model CorrectNav. Experiments on R2R-CE and RxR-CE benchmarks show CorrectNav achieves new state-of-the-art success rates of 65.1% and 69.3%, surpassing prior best VLA navigation models by 8.2% and 16.4%. Real robot tests in various indoor and outdoor environments demonstrate \method&rsquo;s superior capability of error correction, dynamic obstacle avoidance, and long instruction following.
ç°æœ‰çš„è§†è§‰ä¸è¯­è¨€å¯¼èˆªæ¨¡å‹åœ¨æ‰§è¡ŒæŒ‡ä»¤æ—¶å¸¸å¸¸åç¦»æ­£ç¡®è½¨è¿¹ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ç¼ºä¹æœ‰æ•ˆçš„é”™è¯¯çº æ­£èƒ½åŠ›ï¼Œé˜»ç¢äº†å®ƒä»¬ä»é”™è¯¯ä¸­æ¢å¤ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªæˆ‘çº æ­£é£è½®ï¼ˆSelf-correction Flywheelï¼‰ï¼Œä¸€ç§æ–°é¢–çš„åè®­ç»ƒèŒƒå¼ã€‚æˆ‘ä»¬çš„èŒƒå¼å¹¶ä¸å°†è®­ç»ƒé›†ä¸Šæ¨¡å‹çš„é”™è¯¯è½¨è¿¹è§†ä¸ºç¼ºç‚¹ï¼Œè€Œæ˜¯å¼ºè°ƒå…¶ä½œä¸ºæœ‰ä»·å€¼æ•°æ®æºçš„é‡è¦æ€§ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–¹æ³•æ¥è¯†åˆ«è¿™äº›é”™è¯¯è½¨è¿¹ä¸­çš„åç¦»ï¼Œå¹¶è®¾è®¡äº†åˆ›æ–°æŠ€æœ¯ä»¥è‡ªåŠ¨ç”Ÿæˆç”¨äºæ„ŸçŸ¥å’ŒåŠ¨ä½œçš„è‡ªæˆ‘çº æ­£æ•°æ®ã€‚è¿™äº›è‡ªæˆ‘çº æ­£æ•°æ®ä½œä¸ºç‡ƒæ–™ï¼Œé©±åŠ¨æ¨¡å‹çš„ç»§ç»­è®­ç»ƒã€‚å½“æˆ‘ä»¬åœ¨è®­ç»ƒé›†ä¸Šé‡æ–°è¯„ä¼°æ¨¡å‹å¹¶å‘ç°æ–°çš„é”™è¯¯è½¨è¿¹æ—¶ï¼Œè¿™ä¸€èŒƒå¼çš„ç²¾å¦™ä¹‹å¤„æ˜¾ç°å‡ºæ¥â€”â€”æ­¤æ—¶è‡ªæˆ‘çº æ­£é£è½®å¼€å§‹è½¬åŠ¨ã€‚é€šè¿‡å¤šæ¬¡é£è½®è¿­ä»£ï¼Œæˆ‘ä»¬é€æ­¥æå‡äº†åŸºäºå•ç›® RGB çš„è§†è§‰è¯­è¨€å¯¼èˆªæ¨¡å‹ CorrectNavã€‚ åœ¨ R2R-CE å’Œ RxR-CE åŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCorrectNav å®ç°äº†æ–°çš„æœ€å…ˆè¿›æˆåŠŸç‡ï¼Œåˆ†åˆ«ä¸º 65.1% å’Œ 69.3%ï¼Œæ¯”æ­¤å‰æœ€å¥½çš„ VLA å¯¼èˆªæ¨¡å‹åˆ†åˆ«é«˜å‡º 8.2% å’Œ 16.4%ã€‚åœ¨å„ç§å®¤å†…å’Œå®¤å¤–ç¯å¢ƒä¸­çš„çœŸå®æœºå™¨äººæµ‹è¯•å±•ç¤ºäº† \method åœ¨é”™è¯¯ä¿®æ­£ã€åŠ¨æ€éšœç¢ç‰©è§„é¿å’Œæ‰§è¡Œé•¿æŒ‡ä»¤æ–¹é¢çš„å‡ºè‰²èƒ½åŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">Robotics</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>
ä¸»é¢˜ï¼šæœºå™¨äººå­¦ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€ã€è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«</p>
<p><strong>Publish</strong>: 2025-08-14 07:39:26 UTC
å‘è¡¨ï¼š2025-08-14 07:39:26 UTC</p>
<h2 id="82-improving-ocr-for-historical-texts-of-multiple-languages--82-æå‡å¤šè¯­è¨€å†å²æ–‡æœ¬-ocr-çš„æ•ˆæœ"><a href="https://arxiv.org/abs/2508.10356"target="_blank" rel="external nofollow noopener noreferrer">#82</a> <a href="https://papers.cool/arxiv/2508.10356"target="_blank" rel="external nofollow noopener noreferrer">Improving OCR for Historical Texts of Multiple Languages</a>  #82 æå‡å¤šè¯­è¨€å†å²æ–‡æœ¬ OCR çš„æ•ˆæœ</h2>
<p><strong>Authors</strong>: [Hylke Westerdijk](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hylke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hylke</a> Westerdijk), [Ben Blankenborg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ben"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ben</a> Blankenborg), [Khondoker Ittehadul Islam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Khondoker"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Khondoker</a> Ittehadul Islam)
ä½œè€…ï¼šHylke Westerdijkã€Ben Blankenborgã€Khondoker Ittehadul Islam</p>
<p>This paper presents our methodology and findings from three tasks across Optical Character Recognition (OCR) and Document Layout Analysis using advanced deep learning techniques. First, for the historical Hebrew fragments of the Dead Sea Scrolls, we enhanced our dataset through extensive data augmentation and employed the Kraken and TrOCR models to improve character recognition. In our analysis of 16th to 18th-century meeting resolutions task, we utilized a Convolutional Recurrent Neural Network (CRNN) that integrated DeepLabV3+ for semantic segmentation with a Bidirectional LSTM, incorporating confidence-based pseudolabeling to refine our model. Finally, for modern English handwriting recognition task, we applied a CRNN with a ResNet34 encoder, trained using the Connectionist Temporal Classification (CTC) loss function to effectively capture sequential dependencies. This report offers valuable insights and suggests potential directions for future research.
æœ¬æ–‡ä»‹ç»äº†æˆ‘ä»¬åœ¨å…‰å­¦å­—ç¬¦è¯†åˆ«ï¼ˆOCRï¼‰å’Œæ–‡æ¡£å¸ƒå±€åˆ†æä¸‰ä¸ªä»»åŠ¡ä¸­ä½¿ç”¨å…ˆè¿›æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„æ–¹æ³•å’Œå‘ç°ã€‚é¦–å…ˆï¼Œå¯¹äºæ­»æµ·å¤å·çš„å¸Œä¼¯æ¥è¯­å†å²ç¢ç‰‡ï¼Œæˆ‘ä»¬é€šè¿‡å¤§é‡æ•°æ®å¢å¼ºæ‰©å……äº†æ•°æ®é›†ï¼Œå¹¶é‡‡ç”¨ Kraken å’Œ TrOCR æ¨¡å‹æå‡å­—ç¬¦è¯†åˆ«æ•ˆæœã€‚åœ¨å¯¹ 16 è‡³ 18 ä¸–çºªä¼šè®®å†³è®®çš„ä»»åŠ¡åˆ†æä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†å°† DeepLabV3+ ç”¨äºè¯­ä¹‰åˆ†å‰²å¹¶ä¸åŒå‘ LSTM é›†æˆçš„å·ç§¯é€’å½’ç¥ç»ç½‘ç»œï¼ˆCRNNï¼‰ï¼Œå¹¶å¼•å…¥åŸºäºç½®ä¿¡åº¦çš„ä¼ªæ ‡ç­¾æ¥ä¼˜åŒ–æ¨¡å‹ã€‚æœ€åï¼Œå¯¹äºç°ä»£è‹±æ–‡æ‰‹å†™è¯†åˆ«ä»»åŠ¡ï¼Œæˆ‘ä»¬åº”ç”¨äº†ä»¥ ResNet34 ä¸ºç¼–ç å™¨çš„ CRNNï¼Œå¹¶ä½¿ç”¨è¿æ¥æ—¶åºåˆ†ç±»ï¼ˆCTCï¼‰æŸå¤±å‡½æ•°è¿›è¡Œè®­ç»ƒï¼Œä»¥æœ‰æ•ˆæ•æ‰åºåˆ—ä¾èµ–å…³ç³»ã€‚æœ¬æŠ¥å‘Šæä¾›äº†æœ‰ä»·å€¼çš„è§è§£å¹¶å»ºè®®äº†æœªæ¥ç ”ç©¶çš„æ½œåœ¨æ–¹å‘ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šè®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 05:52:14 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 05:52:14 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="83-personalized-real-time-jargon-support-for-online-meetings--83-ä¸ºåœ¨çº¿ä¼šè®®æä¾›ä¸ªæ€§åŒ–å®æ—¶è¡Œè¯æ”¯æŒ"><a href="https://arxiv.org/abs/2508.10239"target="_blank" rel="external nofollow noopener noreferrer">#83</a> <a href="https://papers.cool/arxiv/2508.10239"target="_blank" rel="external nofollow noopener noreferrer">Personalized Real-time Jargon Support for Online Meetings</a>  #83 ä¸ºåœ¨çº¿ä¼šè®®æä¾›ä¸ªæ€§åŒ–å®æ—¶è¡Œè¯æ”¯æŒ</h2>
<p><strong>Authors</strong>: [Yifan Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yifan</a> Song), [Wing Yee Au](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wing</a> Yee Au), [Hon Yung Wong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hon</a> Yung Wong), [Brian P. Bailey](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Brian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Brian</a> P. Bailey), [Tal August](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tal</a> August)
ä½œè€…ï¼šå®‹ä¸€å‡¡ã€åŒºé¢–ä»ªã€é»„æ±‰è£ã€Brian P. Baileyã€Tal August</p>
<p>Effective interdisciplinary communication is frequently hindered by domain-specific jargon. To explore the jargon barriers in-depth, we conducted a formative diary study with 16 professionals, revealing critical limitations in current jargon-management strategies during workplace meetings. Based on these insights, we designed ParseJargon, an interactive LLM-powered system providing real-time personalized jargon identification and explanations tailored to users&rsquo; individual backgrounds. A controlled experiment comparing ParseJargon against baseline (no support) and general-purpose (non-personalized) conditions demonstrated that personalized jargon support significantly enhanced participants&rsquo; comprehension, engagement, and appreciation of colleagues&rsquo; work, whereas general-purpose support negatively affected engagement. A follow-up field study validated ParseJargon&rsquo;s usability and practical value in real-time meetings, highlighting both opportunities and limitations for real-world deployment. Our findings contribute insights into designing personalized jargon support tools, with implications for broader interdisciplinary and educational applications.
æœ‰æ•ˆçš„è·¨å­¦ç§‘äº¤æµç»å¸¸å—åˆ°é¢†åŸŸç‰¹æœ‰è¡Œè¯çš„é˜»ç¢ã€‚ä¸ºæ·±å…¥æ¢ç©¶è¡Œè¯éšœç¢ï¼Œæˆ‘ä»¬å¯¹ 16 åä¸“ä¸šäººå£«è¿›è¡Œäº†å½¢æˆæ€§æ—¥å¿—ç ”ç©¶ï¼Œæ­ç¤ºäº†å½“å‰åœ¨å·¥ä½œä¼šè®®ä¸­è¡Œè¯ç®¡ç†ç­–ç•¥çš„å…³é”®å±€é™ã€‚åŸºäºè¿™äº›æ´è§ï¼Œæˆ‘ä»¬è®¾è®¡äº† ParseJargonï¼Œä¸€ç§äº¤äº’å¼çš„ã€ç”± LLM é©±åŠ¨çš„ç³»ç»Ÿï¼Œå¯æ ¹æ®ç”¨æˆ·çš„ä¸ªäººèƒŒæ™¯æä¾›å®æ—¶çš„ä¸ªæ€§åŒ–è¡Œè¯è¯†åˆ«ä¸è§£é‡Šã€‚ä¸€é¡¹å°† ParseJargon ä¸åŸºçº¿ï¼ˆæ— æ”¯æŒï¼‰å’Œé€šç”¨ï¼ˆéä¸ªæ€§åŒ–ï¼‰æ¡ä»¶è¿›è¡Œå¯¹æ¯”çš„å—æ§å®éªŒè¡¨æ˜ï¼Œä¸ªæ€§åŒ–çš„è¡Œè¯æ”¯æŒæ˜¾è‘—æå‡äº†å‚ä¸è€…çš„ç†è§£åŠ›ã€å‚ä¸åº¦å’Œå¯¹åŒäº‹å·¥ä½œçš„è®¤å¯ï¼Œè€Œé€šç”¨æ”¯æŒåˆ™å¯¹å‚ä¸åº¦äº§ç”Ÿäº†è´Ÿé¢å½±å“ã€‚éšåçš„ä¸€é¡¹å®åœ°ç ”ç©¶éªŒè¯äº† ParseJargon åœ¨å®æ—¶ä¼šè®®ä¸­çš„å¯ç”¨æ€§å’Œå®ç”¨ä»·å€¼ï¼Œå¹¶çªå‡ºäº†åœ¨å®é™…éƒ¨ç½²ä¸­çš„æœºé‡ä¸å±€é™ã€‚æˆ‘ä»¬çš„å‘ç°ä¸ºè®¾è®¡ä¸ªæ€§åŒ–è¡Œè¯æ”¯æŒå·¥å…·æä¾›äº†è§è§£ï¼Œå¹¶å¯¹æ›´å¹¿æ³›çš„è·¨å­¦ç§‘ä¸æ•™è‚²åº”ç”¨å…·æœ‰å¯ç¤ºæ„ä¹‰ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººæœºäº¤äº’ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-13 23:42:12 UTC
å‘å¸ƒï¼š2025-08-13 23:42:12 UTC</p>
<h2 id="84-nested-reft-efficient-reinforcement-learning-for-large-language-model-fine-tuning-via-off-policy-rollouts--84-nested-refté€šè¿‡ç¦»ç­–ç•¥å›æ»šå®ç°å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å¾®è°ƒçš„é«˜æ•ˆå¼ºåŒ–å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10123"target="_blank" rel="external nofollow noopener noreferrer">#84</a> <a href="https://papers.cool/arxiv/2508.10123"target="_blank" rel="external nofollow noopener noreferrer">Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts</a>  #84 Nested-ReFTï¼šé€šè¿‡ç¦»ç­–ç•¥å›æ»šå®ç°å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹å¾®è°ƒçš„é«˜æ•ˆå¼ºåŒ–å­¦ä¹ </h2>
<p><strong>Authors</strong>: [Maxime Heuillet](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maxime"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maxime</a> Heuillet), [Yufei Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yufei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yufei</a> Cui), [Boxing Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Boxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Boxing</a> Chen), [Audrey Durand](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Audrey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Audrey</a> Durand), [Prasanna Parthasarathi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prasanna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prasanna</a> Parthasarathi)
ä½œè€…ï¼šMaxime Heuilletã€Yufei Cuiã€Boxing Chenã€Audrey Durandã€Prasanna Parthasarathi</p>
<p>Advanced reasoning in LLMs on challenging domains like mathematical reasoning can be tackled using verifiable rewards based reinforced fine-tuning (ReFT). In standard ReFT frameworks, a behavior model generates multiple completions with answers per problem, for the answer to be then scored by a reward function. While such RL post-training methods demonstrate significant performance improvements across challenging reasoning domains, the computational cost of generating completions during training with multiple inference steps makes the training cost non-trivial. To address this, we draw inspiration from off-policy RL, and speculative decoding to introduce a novel ReFT framework, dubbed Nested-ReFT, where a subset of layers of the target model acts as the behavior model to generate off-policy completions during training. The behavior model configured with dynamic layer skipping per batch during training decreases the inference cost compared to the standard ReFT frameworks. Our theoretical analysis shows that Nested-ReFT yields unbiased gradient estimates with controlled variance. Our empirical analysis demonstrates improved computational efficiency measured as tokens/sec across multiple math reasoning benchmarks and model sizes. Additionally, we explore three variants of bias mitigation to minimize the off-policyness in the gradient updates that allows for maintaining performance that matches the baseline ReFT performance.
åœ¨åƒæ•°å­¦æ¨ç†è¿™æ ·å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸï¼Œå¯¹ LLMs è¿›è¡ŒåŸºäºå¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å¾®è°ƒï¼ˆReFTï¼‰å¯ä»¥åº”å¯¹é«˜çº§æ¨ç†é—®é¢˜ã€‚åœ¨æ ‡å‡†çš„ ReFT æ¡†æ¶ä¸­ï¼Œä¸€ä¸ªè¡Œä¸ºæ¨¡å‹ä¸ºæ¯ä¸ªé—®é¢˜ç”Ÿæˆå¤šä¸ªç­”æ¡ˆå®Œæˆï¼Œç„¶åç”±å¥–åŠ±å‡½æ•°å¯¹è¿™äº›ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ã€‚å°½ç®¡è¿™ç§ RL åè®­ç»ƒæ–¹æ³•åœ¨å„ç±»å›°éš¾æ¨ç†é¢†åŸŸå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä½†åœ¨è®­ç»ƒæœŸé—´ä¸ºç”Ÿæˆå¤šä¸ªæ¨ç†æ­¥éª¤çš„å®Œæˆç»“æœæ‰€ä»˜å‡ºçš„è®¡ç®—æˆæœ¬å¹¶ä¸ä½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬å€Ÿé‰´ç¦»ç­–ç•¥ RL å’Œæ¨æµ‹æ€§è§£ç çš„æ€æƒ³ï¼Œå¼•å…¥äº†ä¸€ç§æ–°é¢–çš„ ReFT æ¡†æ¶ï¼Œç§°ä¸º Nested-ReFTï¼Œå…¶ä¸­ç›®æ ‡æ¨¡å‹çš„ä¸€ä¸ªå­å±‚é›†åˆåœ¨è®­ç»ƒæœŸé—´å……å½“è¡Œä¸ºæ¨¡å‹ä»¥ç”Ÿæˆç¦»ç­–ç•¥çš„å®Œæˆç»“æœã€‚è¯¥è¡Œä¸ºæ¨¡å‹åœ¨è®­ç»ƒæœŸé—´æŒ‰æ‰¹æ¬¡åŠ¨æ€è·³è¿‡å±‚ï¼Œä»è€Œæ¯”æ ‡å‡† ReFT æ¡†æ¶é™ä½äº†æ¨ç†æˆæœ¬ã€‚æˆ‘ä»¬çš„ç†è®ºåˆ†æè¡¨æ˜ï¼ŒNested-ReFT åœ¨æ–¹å·®å¯æ§çš„æƒ…å†µä¸‹äº§ç”Ÿæ— åçš„æ¢¯åº¦ä¼°è®¡ã€‚ æˆ‘ä»¬çš„å®è¯åˆ†ææ˜¾ç¤ºï¼Œåœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†å’Œä¸åŒæ¨¡å‹è§„æ¨¡ä¸Šï¼Œä»¥æ¯ç§’ä»¤ç‰Œæ•°ï¼ˆtokens/secï¼‰ä¸ºåº¦é‡çš„è®¡ç®—æ•ˆç‡æœ‰æ‰€æå‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢è®¨äº†ä¸‰ç§åå·®ç¼“è§£çš„å˜ä½“ï¼Œä»¥å°½é‡å‡å°‘æ¢¯åº¦æ›´æ–°ä¸­çš„ç¦»ç­–ç•¥æ€§ï¼ˆoff-policynessï¼‰ï¼Œä»è€Œä¿æŒä¸åŸºçº¿ ReFT æ€§èƒ½ç›¸å½“çš„è¡¨ç°ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-13 18:37:46 UTC
å‘å¸ƒï¼š2025-08-13 18:37:46 UTC</p>
<h2 id="85-amazon-nova-ai-challenge---85-äºšé©¬é€Š-nova-ai-æŒ‘æˆ˜èµ›--å¯ä¿¡-aiæ¨è¿›å®‰å…¨çš„-ai-è¾…åŠ©è½¯ä»¶å¼€å‘"><a href="https://arxiv.org/abs/2508.10108"target="_blank" rel="external nofollow noopener noreferrer">#85</a> <a href="https://papers.cool/arxiv/2508.10108"target="_blank" rel="external nofollow noopener noreferrer">Amazon Nova AI Challenge &ndash; Trusted AI: Advancing secure, AI-assisted software development</a>  #85 äºšé©¬é€Š Nova AI æŒ‘æˆ˜èµ› &ndash; å¯ä¿¡ AIï¼šæ¨è¿›å®‰å…¨çš„ AI è¾…åŠ©è½¯ä»¶å¼€å‘</h2>
<p><strong>Authors</strong>: [Sattvik Sahai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sattvik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sattvik</a> Sahai), [Prasoon Goyal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prasoon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prasoon</a> Goyal), [Michael Johnston](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Johnston), [Anna Gottardi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anna</a> Gottardi), [Yao Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yao</a> Lu), [Lucy Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lucy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lucy</a> Hu), [Luke Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luke</a> Dai), [Shaohua Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaohua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaohua</a> Liu), [Samyuth Sagi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Samyuth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Samyuth</a> Sagi), [Hangjie Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hangjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hangjie</a> Shi), [Desheng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Desheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Desheng</a> Zhang), [Lavina Vaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lavina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lavina</a> Vaz), [Leslie Ball](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leslie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leslie</a> Ball), [Maureen Murray](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maureen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maureen</a> Murray), [Rahul Gupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rahul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rahul</a> Gupta), [Shankar Ananthakrishna](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shankar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shankar</a> Ananthakrishna)
ä½œè€…ï¼šSattvik Sahaiã€Prasoon Goyalã€Michael Johnstonã€Anna Gottardiã€Yao Luã€Lucy Huã€Luke Daiã€Shaohua Liuã€Samyuth Sagiã€Hangjie Shiã€Desheng Zhangã€Lavina Vazã€Leslie Ballã€Maureen Murrayã€Rahul Guptaã€Shankar Ananthakrishna</p>
<p>AI systems for software development are rapidly gaining prominence, yet significant challenges remain in ensuring their safety. To address this, Amazon launched the Trusted AI track of the Amazon Nova AI Challenge, a global competition among 10 university teams to drive advances in secure AI. In the challenge, five teams focus on developing automated red teaming bots, while the other five create safe AI assistants. This challenge provides teams with a unique platform to evaluate automated red-teaming and safety alignment methods through head-to-head adversarial tournaments where red teams have multi-turn conversations with the competing AI coding assistants to test their safety alignment. Along with this, the challenge provides teams with a feed of high quality annotated data to fuel iterative improvement. Throughout the challenge, teams developed state-of-the-art techniques, introducing novel approaches in reasoning-based safety alignment, robust model guardrails, multi-turn jail-breaking, and efficient probing of large language models (LLMs). To support these efforts, the Amazon Nova AI Challenge team made substantial scientific and engineering investments, including building a custom baseline coding specialist model for the challenge from scratch, developing a tournament orchestration service, and creating an evaluation harness. This paper outlines the advancements made by university teams and the Amazon Nova AI Challenge team in addressing the safety challenges of AI for software development, highlighting this collaborative effort to raise the bar for AI safety.
ç”¨äºè½¯ä»¶å¼€å‘çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿæ­£è¿…é€Ÿå´­éœ²å¤´è§’ï¼Œä½†åœ¨ç¡®ä¿å…¶å®‰å…¨æ€§æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œäºšé©¬é€Šå‘èµ·äº† Amazon Nova AI Challenge çš„å¯ä¿¡äººå·¥æ™ºèƒ½ï¼ˆTrusted AIï¼‰èµ›é“ï¼Œè¿™æ˜¯ä¸€é¡¹ç”± 10 æ”¯å¤§å­¦å›¢é˜Ÿå‚ä¸çš„å…¨çƒæ€§ç«èµ›ï¼Œæ—¨åœ¨æ¨åŠ¨å®‰å…¨äººå·¥æ™ºèƒ½çš„è¿›å±•ã€‚åœ¨è¯¥æŒ‘æˆ˜ä¸­ï¼Œäº”æ”¯é˜Ÿä¼ä¸“æ³¨äºå¼€å‘è‡ªåŠ¨åŒ–çº¢é˜Ÿæœºå™¨äººï¼Œè€Œå¦å¤–äº”æ”¯åˆ™è‡´åŠ›äºåˆ›å»ºå®‰å…¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚è¯¥æŒ‘æˆ˜ä¸ºå›¢é˜Ÿæä¾›äº†ä¸€ä¸ªç‹¬ç‰¹çš„å¹³å°ï¼Œé€šè¿‡ä¸€å¯¹ä¸€å¯¹æŠ—é”¦æ ‡èµ›è¯„ä¼°è‡ªåŠ¨åŒ–çº¢é˜Ÿå’Œå®‰å…¨å¯¹é½æ–¹æ³•ï¼šçº¢é˜Ÿä¸å‚èµ›çš„ AI ç¼–ç åŠ©æ‰‹è¿›è¡Œå¤šè½®å¯¹è¯ï¼Œä»¥æµ‹è¯•å…¶å®‰å…¨å¯¹é½æ€§ã€‚é™¤æ­¤ä¹‹å¤–ï¼ŒæŒ‘æˆ˜è¿˜ä¸ºå„é˜Ÿæä¾›äº†ä¸€æ‰¹é«˜è´¨é‡çš„å¸¦æ³¨é‡Šæ•°æ®ï¼Œä»¥æ”¯æŒè¿­ä»£æ”¹è¿›ã€‚åœ¨æ•´ä¸ªæŒ‘æˆ˜è¿‡ç¨‹ä¸­ï¼Œå„é˜Ÿå¼€å‘äº†æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œæå‡ºäº†åœ¨åŸºäºæ¨ç†çš„å®‰å…¨å¯¹é½ã€ç¨³å¥çš„æ¨¡å‹é˜²æŠ¤æªæ–½ã€å¤šè½®è¶Šç‹±æ”»å‡»ä»¥åŠé«˜æ•ˆæ¢æµ‹å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) æ–¹é¢çš„æ–°æ–¹æ³•ã€‚ ä¸ºäº†æ”¯æŒè¿™äº›å·¥ä½œï¼ŒAmazon Nova AI Challenge å›¢é˜Ÿåšå‡ºäº†å¤§é‡çš„ç§‘ç ”å’Œå·¥ç¨‹æŠ•å…¥ï¼ŒåŒ…æ‹¬ä»é›¶æ„å»ºäº†ç”¨äºè¯¥æŒ‘æˆ˜çš„å®šåˆ¶åŸºçº¿ç¼–ç ä¸“å®¶æ¨¡å‹ã€å¼€å‘äº†é”¦æ ‡èµ›ç¼–æ’æœåŠ¡ä»¥åŠåˆ›å»ºäº†è¯„ä¼°å·¥å…·ã€‚æœ¬æ–‡æ¦‚è¿°äº†å¤§å­¦å›¢é˜Ÿå’Œ Amazon Nova AI Challenge å›¢é˜Ÿåœ¨åº”å¯¹è½¯ä»¶å¼€å‘é¢†åŸŸ AI å®‰å…¨æŒ‘æˆ˜æ–¹é¢å–å¾—çš„è¿›å±•ï¼Œçªå‡ºäº†è¿™ä¸€ä¸ºæé«˜ AI å®‰å…¨æ ‡å‡†è€Œè¿›è¡Œçš„åä½œåŠªåŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-13 18:04:01 UTC
å‘å¸ƒï¼š2025-08-13 18:04:01 UTC</p>
<h2 id="86-saracoder-orchestrating-semantic-and-structural-cues-for-profit-oriented-repository-level-code-completion--86-saracoderä¸ºåˆ©æ¶¦å¯¼å‘çš„ä»“åº“çº§ä»£ç è¡¥å…¨åè°ƒè¯­ä¹‰ä¸ç»“æ„çº¿ç´¢-pdf-2--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10068"target="_blank" rel="external nofollow noopener noreferrer">#86</a> <a href="https://papers.cool/arxiv/2508.10068"target="_blank" rel="external nofollow noopener noreferrer">SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion</a>  #86 SaraCoderï¼šä¸ºåˆ©æ¶¦å¯¼å‘çš„ä»“åº“çº§ä»£ç è¡¥å…¨åè°ƒè¯­ä¹‰ä¸ç»“æ„çº¿ç´¢ [PDF 2 ] [Copy] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [Xiaohan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaohan</a> Chen), [Zhongying Pan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongying</a> Pan), [Quan Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Quan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Quan</a> Feng), [Yu Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Tian), [Shuqun Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuqun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuqun</a> Yang), [Mengru Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengru"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengru</a> Wang), [Lina Gong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lina</a> Gong), [Yuxia Geng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxia</a> Geng), [Piji Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Piji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Piji</a> Li), [Xiang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiang</a> Chen)
ä½œè€…ï¼šé™ˆæ™“æ¶µã€æ½˜ä¸­è‹±ã€å†¯å…¨ã€ç”°å®‡ã€æ¨æ ‘ç¾¤ã€ç‹æ¢¦å¦‚ã€é¾šä¸½å¨œã€è€¿ç‰éœã€æä¸•å‰ã€é™ˆç¿”</p>
<p>Retrieval-augmented generation (RAG) for repository-level code completion commonly relies on superficial text similarity, leading to results plagued by semantic misguidance, redundancy, and homogeneity, while also failing to resolve external symbol ambiguity. To address these challenges, we introduce Saracoder, a Hierarchical Feature-Optimized retrieval framework. Its core Hierarchical Feature Optimization module systematically refines candidates by distilling deep semantic relationships, pruning exact duplicates, assessing structural similarity with a novel graph-based metric that weighs edits by their topological importance, and reranking results to maximize both relevance and diversity. Furthermore, an External-Aware Identifier Disambiguator module accurately resolves cross-file symbol ambiguity via dependency analysis. Extensive experiments on the challenging CrossCodeEval and RepoEval-Updated benchmarks demonstrate that Saracoder significantly outperforms existing baselines across multiple programming languages and models. Our work proves that systematically refining retrieval results across multiple dimensions provides a new paradigm for building more accurate and robust repository-level code completion systems.
é’ˆå¯¹ä»“åº“çº§ä»£ç è¡¥å…¨çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ–¹æ³•å¸¸ä¾èµ–è¡¨å±‚æ–‡æœ¬ç›¸ä¼¼æ€§ï¼Œå¯¼è‡´ç»“æœå­˜åœ¨è¯­ä¹‰è¯¯å¯¼ã€å†—ä½™ä¸åŒè´¨åŒ–é—®é¢˜ï¼Œå¹¶ä¸”æ— æ³•è§£å†³å¤–éƒ¨ç¬¦å·æ­§ä¹‰ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº† Saracoderï¼Œä¸€ç§å±‚æ¬¡åŒ–ç‰¹å¾ä¼˜åŒ–çš„æ£€ç´¢æ¡†æ¶ã€‚å…¶æ ¸å¿ƒçš„å±‚æ¬¡åŒ–ç‰¹å¾ä¼˜åŒ–æ¨¡å—é€šè¿‡æç‚¼æ·±å±‚è¯­ä¹‰å…³ç³»ç³»ç»Ÿåœ°ä¼˜åŒ–å€™é€‰é¡¹ï¼Œå»é™¤å®Œå…¨é‡å¤é¡¹ï¼Œåˆ©ç”¨ä¸€ç§æ–°é¢–çš„åŸºäºå›¾çš„åº¦é‡æŒ‰æ‹“æ‰‘é‡è¦æ€§å¯¹ç¼–è¾‘æ“ä½œåŠ æƒæ¥è¯„ä¼°ç»“æ„ç›¸ä¼¼æ€§ï¼Œå¹¶å¯¹ç»“æœè¿›è¡Œé‡æ’åºä»¥æœ€å¤§åŒ–ç›¸å…³æ€§å’Œå¤šæ ·æ€§ã€‚æ­¤å¤–ï¼Œå¤–éƒ¨æ„ŸçŸ¥æ ‡è¯†ç¬¦æ¶ˆæ­§æ¨¡å—é€šè¿‡ä¾èµ–åˆ†æå‡†ç¡®è§£å†³è·¨æ–‡ä»¶ç¬¦å·æ­§ä¹‰ã€‚åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„ CrossCodeEval å’Œ RepoEval-Updated åŸºå‡†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSaracoder åœ¨å¤šç§ç¼–ç¨‹è¯­è¨€å’Œæ¨¡å‹ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ–¹æ³•ã€‚ æˆ‘ä»¬çš„å·¥ä½œè¯æ˜ï¼Œé€šè¿‡åœ¨å¤šä¸ªç»´åº¦ä¸Šç³»ç»Ÿåœ°ç»†åŒ–æ£€ç´¢ç»“æœï¼Œä¸ºæ„å»ºæ›´å‡†ç¡®ã€æ›´å¥å£®çš„ä»“åº“çº§ä»£ç è¡¥å…¨ç³»ç»Ÿæä¾›äº†ä¸€ç§æ–°èŒƒå¼ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">Software Engineering</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>, <a href="https://papers.cool/arxiv/cs.PL"target="_blank" rel="external nofollow noopener noreferrer">Programming Languages</a>
ä¸»é¢˜ï¼šè½¯ä»¶å·¥ç¨‹ï¼Œè®¡ç®—ä¸è¯­è¨€ï¼Œä¿¡æ¯æ£€ç´¢ï¼Œç¼–ç¨‹è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-13 11:56:05 UTC
å‘å¸ƒï¼š2025-08-13 11:56:05 UTC</p>
<h2 id="87-large-language-models-show-signs-of-alignment-with-human-neurocognition-during-abstract-reasoning--87-å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­æ˜¾ç¤ºå‡ºä¸äººç±»ç¥ç»è®¤çŸ¥ä¸€è‡´çš„è¿¹è±¡"><a href="https://arxiv.org/abs/2508.10057"target="_blank" rel="external nofollow noopener noreferrer">#87</a> <a href="https://papers.cool/arxiv/2508.10057"target="_blank" rel="external nofollow noopener noreferrer">Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning</a>  #87 å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­æ˜¾ç¤ºå‡ºä¸äººç±»ç¥ç»è®¤çŸ¥ä¸€è‡´çš„è¿¹è±¡</h2>
<p><strong>Authors</strong>: [Christopher Pinier](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christopher"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christopher</a> Pinier), [Sonia AcuÃ±a Vargas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sonia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sonia</a> AcuÃ±a Vargas), [Mariia Steeghs-Turchina](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mariia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mariia</a> Steeghs-Turchina), [Dora Matzke](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dora"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dora</a> Matzke), [Claire E. Stevenson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Claire"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Claire</a> E. Stevenson), [Michael D. Nunez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> D. Nunez)
ä½œè€…ï¼šChristopher Pinierã€Sonia AcuÃ±a Vargasã€Mariia Steeghs-Turchinaã€Dora Matzkeã€Claire E. Stevensonã€Michael D. Nunez</p>
<p>This study investigates whether large language models (LLMs) mirror human neurocognition during abstract reasoning. We compared the performance and neural representations of human participants with those of eight open-source LLMs on an abstract-pattern-completion task. We leveraged pattern type differences in task performance and in fixation-related potentials (FRPs) as recorded by electroencephalography (EEG) during the task. Our findings indicate that only the largest tested LLMs (~70 billion parameters) achieve human-comparable accuracy, with Qwen-2.5-72B and DeepSeek-R1-70B also showing similarities with the human pattern-specific difficulty profile. Critically, every LLM tested forms representations that distinctly cluster the abstract pattern categories within their intermediate layers, although the strength of this clustering scales with their performance on the task. Moderate positive correlations were observed between the representational geometries of task-optimal LLM layers and human frontal FRPs. These results consistently diverged from comparisons with other EEG measures (response-locked ERPs and resting EEG), suggesting a potential shared representational space for abstract patterns. This indicates that LLMs might mirror human brain mechanisms in abstract reasoning, offering preliminary evidence of shared principles between biological and artificial intelligence.
æœ¬ç ”ç©¶æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æŠ½è±¡æ¨ç†æ—¶æ˜¯å¦åæ˜ äººç±»ç¥ç»è®¤çŸ¥ã€‚æˆ‘ä»¬å°†å‚ä¸è€…ä¸å…«ç§å¼€æº LLM åœ¨ä¸€é¡¹æŠ½è±¡æ¨¡å¼è¡¥å…¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸ç¥ç»è¡¨å¾è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬åˆ©ç”¨ä»»åŠ¡è¡¨ç°ä¸­çš„æ¨¡å¼ç±»å‹å·®å¼‚ä»¥åŠåœ¨ä»»åŠ¡è¿‡ç¨‹ä¸­é€šè¿‡è„‘ç”µå›¾ï¼ˆEEGï¼‰è®°å½•çš„ä¸æ³¨è§†ç›¸å…³ç”µä½ï¼ˆFRPsï¼‰ä½œä¸ºä¾æ®ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåªæœ‰è§„æ¨¡æœ€å¤§çš„è¢«æµ‹ LLMsï¼ˆçº¦ 700 äº¿å‚æ•°ï¼‰èƒ½è¾¾åˆ°ä¸äººç±»ç›¸å½“çš„å‡†ç¡®ç‡ï¼Œå…¶ä¸­ Qwen-2.5-72B å’Œ DeepSeek-R1-70B åœ¨ä¸äººç±»çš„æ¨¡å¼ç‰¹å®šéš¾åº¦è°±ä¸Šä¹Ÿè¡¨ç°å‡ºç›¸ä¼¼æ€§ã€‚å…³é”®çš„æ˜¯ï¼Œæ‰€æœ‰è¢«æµ‹ LLM éƒ½åœ¨å…¶ä¸­é—´å±‚å½¢æˆäº†èƒ½æ¸…æ™°èšç±»æŠ½è±¡æ¨¡å¼ç±»åˆ«çš„è¡¨å¾ï¼Œå°½ç®¡è¿™ç§èšç±»çš„å¼ºåº¦éšå…¶åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°è€Œå˜åŒ–ã€‚åœ¨ä»»åŠ¡æœ€ä¼˜ LLM å±‚çš„è¡¨å¾å‡ ä½•ä¸äººç±»é¢å¶ FRPs ä¹‹é—´è§‚å¯Ÿåˆ°ä¸­åº¦æ­£ç›¸å…³ã€‚ è¿™äº›ç»“æœæŒç»­ä¸å…¶ä»–è„‘ç”µæµ‹é‡ï¼ˆååº”é”å®šçš„äº‹ä»¶ç›¸å…³ç”µä½å’Œé™æ¯è„‘ç”µï¼‰æ‰€å¾—åˆ°çš„æ¯”è¾ƒç»“æœä¸åŒï¼Œè¡¨æ˜å­˜åœ¨å¯¹æŠ½è±¡æ¨¡å¼çš„æ½œåœ¨å…±äº«è¡¨å¾ç©ºé—´ã€‚è¿™è¡¨æ˜ LLMs å¯èƒ½åœ¨äººç±»å¤§è„‘çš„æŠ½è±¡æ¨ç†æœºåˆ¶ä¸Šæœ‰ç›¸ä¼¼ä¹‹å¤„ï¼Œä¸ºç”Ÿç‰©æ™ºèƒ½ä¸äººå·¥æ™ºèƒ½ä¹‹é—´å…±äº«åŸåˆ™æä¾›äº†åˆæ­¥è¯æ®ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/q-bio.NC"target="_blank" rel="external nofollow noopener noreferrer">Neurons and Cognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
é¢˜ç›®ï¼šç¥ç»å…ƒä¸è®¤çŸ¥ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-12 21:38:46 UTC
å‘å¸ƒï¼š2025-08-12 21:38:46 UTC</p>
<h2 id="88-context-misleads-llms-the-role-of-context-filtering-in-maintaining-safe-alignment-of-llms--88-ä¸Šä¸‹æ–‡è¯¯å¯¼-llmsä¸Šä¸‹æ–‡è¿‡æ»¤åœ¨ç»´æŒ-llms-å®‰å…¨å¯¹é½ä¸­çš„ä½œç”¨-pdf-1--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10031"target="_blank" rel="external nofollow noopener noreferrer">#88</a> <a href="https://papers.cool/arxiv/2508.10031"target="_blank" rel="external nofollow noopener noreferrer">Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs</a>  #88 ä¸Šä¸‹æ–‡è¯¯å¯¼ LLMsï¼šä¸Šä¸‹æ–‡è¿‡æ»¤åœ¨ç»´æŒ LLMs å®‰å…¨å¯¹é½ä¸­çš„ä½œç”¨ [PDF 1 ] [Copy] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [Jinhwa Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinhwa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinhwa</a> Kim), [Ian G. Harris](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> G. Harris)
ä½œè€…ï¼šJinhwa Kim, Ian G. Harris</p>
<p>While Large Language Models (LLMs) have shown significant advancements in performance, various jailbreak attacks have posed growing safety and ethical risks. Malicious users often exploit adversarial context to deceive LLMs, prompting them to generate responses to harmful queries. In this study, we propose a new defense mechanism called Context Filtering model, an input pre-processing method designed to filter out untrustworthy and unreliable context while identifying the primary prompts containing the real user intent to uncover concealed malicious intent. Given that enhancing the safety of LLMs often compromises their helpfulness, potentially affecting the experience of benign users, our method aims to improve the safety of the LLMs while preserving their original performance. We evaluate the effectiveness of our model in defending against jailbreak attacks through comparative analysis, comparing our approach with state-of-the-art defense mechanisms against six different attacks and assessing the helpfulness of LLMs under these defenses. Our model demonstrates its ability to reduce the Attack Success Rates of jailbreak attacks by up to 88% while maintaining the original LLMs&rsquo; performance, achieving state-of-the-art Safety and Helpfulness Product results. Notably, our model is a plug-and-play method that can be applied to all LLMs, including both white-box and black-box models, to enhance their safety without requiring any fine-tuning of the models themselves. We will make our model publicly available for research purposes.
è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†å„ç§è¶Šç‹±æ”»å‡»å¸¦æ¥äº†æ—¥ç›Šå¢é•¿çš„å®‰å…¨å’Œä¼¦ç†é£é™©ã€‚æ¶æ„ç”¨æˆ·ç»å¸¸åˆ©ç”¨å¯¹æŠ—æ€§ä¸Šä¸‹æ–‡æ¥æ¬ºéª— LLMsï¼Œä¿ƒä½¿å®ƒä»¬å¯¹æœ‰å®³æŸ¥è¯¢ç”Ÿæˆå›åº”ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é˜²å¾¡æœºåˆ¶ï¼Œç§°ä¸ºä¸Šä¸‹æ–‡è¿‡æ»¤æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§è¾“å…¥é¢„å¤„ç†æ–¹æ³•ï¼Œæ—¨åœ¨è¿‡æ»¤å‡ºä¸å¯ä¿¡å’Œä¸å¯é çš„ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶è¯†åˆ«åŒ…å«çœŸå®ç”¨æˆ·æ„å›¾çš„ä¸»è¦æç¤ºï¼Œä»¥æ­éœ²éšè—çš„æ¶æ„æ„å›¾ã€‚é‰´äºå¢å¼º LLMs çš„å®‰å…¨æ€§å¾€å¾€ä¼šæŸå®³å…¶æœ‰æ•ˆæ€§ï¼Œå¯èƒ½å½±å“è‰¯æ€§ç”¨æˆ·çš„ä½“éªŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ—¨åœ¨åœ¨ä¿ç•™åŸæœ‰æ€§èƒ½çš„åŒæ—¶æé«˜ LLMs çš„å®‰å…¨æ€§ã€‚æˆ‘ä»¬é€šè¿‡æ¯”è¾ƒåˆ†æè¯„ä¼°äº†æ¨¡å‹åœ¨æŠµå¾¡è¶Šç‹±æ”»å‡»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå°†æˆ‘ä»¬çš„æ–¹æ³•ä¸é’ˆå¯¹å…­ç§ä¸åŒæ”»å‡»çš„æœ€å…ˆè¿›é˜²å¾¡æœºåˆ¶è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è¯„ä¼°åœ¨è¿™äº›é˜²å¾¡ä¸‹ LLMs çš„æœ‰ç”¨æ€§ã€‚ æˆ‘ä»¬çš„æ¨¡å‹å±•ç¤ºäº†åœ¨ä¿æŒåŸå§‹ LLMs æ€§èƒ½çš„åŒæ—¶ï¼Œå°†è¶Šç‹±æ”»å‡»çš„æˆåŠŸç‡é™ä½æœ€å¤šè¾¾ 88%çš„èƒ½åŠ›ï¼Œå¹¶å®ç°äº†æœ€å…ˆè¿›çš„å®‰å…¨æ€§ä¸æœ‰ç”¨æ€§äº§å“ç»“æœã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ˜¯ä¸€ç§å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå¯åº”ç”¨äºæ‰€æœ‰ LLMsï¼ŒåŒ…æ‹¬ç™½ç›’å’Œé»‘ç›’æ¨¡å‹ï¼Œä»¥åœ¨ä¸éœ€è¦å¯¹æ¨¡å‹æœ¬èº«è¿›è¡Œä»»ä½•å¾®è°ƒçš„æƒ…å†µä¸‹å¢å¼ºå…¶å®‰å…¨æ€§ã€‚æˆ‘ä»¬å°†å…¬å¼€æä¾›æˆ‘ä»¬çš„æ¨¡å‹ä»¥ä¾›ç ”ç©¶ç”¨é€”ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-09 02:37:59 UTC
å‘å¸ƒï¼š2025-08-09 02:37:59 UTC</p>
<h2 id="89-personalized-product-search-ranking-a-multi-task-learning-approach-with-tabular-and-non-tabular-data--89-ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•"><a href="https://arxiv.org/abs/2508.09636"target="_blank" rel="external nofollow noopener noreferrer">#89</a> <a href="https://papers.cool/arxiv/2508.09636"target="_blank" rel="external nofollow noopener noreferrer">Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data</a>  #89 ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åï¼šä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•</h2>
<p><strong>Authors</strong>: [Lalitesh Morishetti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lalitesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lalitesh</a> Morishetti), [Abhay Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abhay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abhay</a> Kumar), [Jonathan Scott](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonathan</a> Scott), [Kaushiki Nag](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaushiki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaushiki</a> Nag), [Gunjan Sharma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gunjan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gunjan</a> Sharma), [Shanu Vashishtha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shanu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shanu</a> Vashishtha), [Rahul Sridhar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rahul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rahul</a> Sridhar), [Rohit Chatter](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rohit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rohit</a> Chatter), [Kannan Achan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kannan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kannan</a> Achan)
ä½œè€…ï¼šLalitesh Morishettiã€Abhay Kumarã€Jonathan Scottã€Kaushiki Nagã€Gunjan Sharmaã€Shanu Vashishthaã€Rahul Sridharã€Rohit Chatterã€Kannan Achan</p>
<p>In this paper, we present a novel model architecture for optimizing personalized product search ranking using a multi-task learning (MTL) framework. Our approach uniquely integrates tabular and non-tabular data, leveraging a pre-trained TinyBERT model for semantic embeddings and a novel sampling technique to capture diverse customer behaviors. We evaluate our model against several baselines, including XGBoost, TabNet, FT-Transformer, DCN-V2, and MMoE, focusing on their ability to handle mixed data types and optimize personalized ranking. Additionally, we propose a scalable relevance labeling mechanism based on click-through rates, click positions, and semantic similarity, offering an alternative to traditional human-annotated labels. Experimental results show that combining non-tabular data with advanced embedding techniques in multi-task learning paradigm significantly enhances model performance. Ablation studies further underscore the benefits of incorporating relevance labels, fine-tuning TinyBERT layers, and TinyBERT query-product embedding interactions. These results demonstrate the effectiveness of our approach in achieving improved personalized product search ranking.
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¨¡å‹æ¶æ„ï¼Œä½¿ç”¨å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰æ¡†æ¶æ¥ä¼˜åŒ–ä¸ªæ€§åŒ–å•†å“æœç´¢æ’åã€‚æˆ‘ä»¬çš„æ–¹æ³•ç‹¬ç‰¹åœ°æ•´åˆäº†è¡¨æ ¼æ•°æ®å’Œéè¡¨æ ¼æ•°æ®ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„ TinyBERT æ¨¡å‹è·å–è¯­ä¹‰åµŒå…¥ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„é‡‡æ ·æŠ€æœ¯ä»¥æ•æ‰å¤šæ ·çš„å®¢æˆ·è¡Œä¸ºã€‚æˆ‘ä»¬å°†æ¨¡å‹ä¸å¤šä¸ªåŸºçº¿æ–¹æ³•è¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬ XGBoostã€TabNetã€FT-Transformerã€DCN-V2 å’Œ MMoEï¼Œé‡ç‚¹è€ƒå¯Ÿå®ƒä»¬å¤„ç†æ··åˆæ•°æ®ç±»å‹å’Œä¼˜åŒ–ä¸ªæ€§åŒ–æ’åºçš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„ç›¸å…³æ€§æ ‡æ³¨æœºåˆ¶ï¼ŒåŸºäºç‚¹å‡»ç‡ã€ç‚¹å‡»ä½ç½®å’Œè¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œä¸ºä¼ ç»Ÿçš„äººä¸ºæ ‡æ³¨æ ‡ç­¾æä¾›äº†ä¸€ç§æ›¿ä»£æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šä»»åŠ¡å­¦ä¹ èŒƒå¼ä¸­å°†éè¡¨æ ¼æ•°æ®ä¸å…ˆè¿›çš„åµŒå…¥æŠ€æœ¯ç›¸ç»“åˆå¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥å¼ºè°ƒäº†å¼•å…¥ç›¸å…³æ€§æ ‡ç­¾ã€å¾®è°ƒ TinyBERT å±‚ä»¥åŠ TinyBERT æŸ¥è¯¢-å•†å“åµŒå…¥äº¤äº’çš„å¥½å¤„ã€‚è¿™äº›ç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•åœ¨å®ç°æ”¹è¿›çš„ä¸ªæ€§åŒ–å•†å“æœç´¢æ’åæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šä¿¡æ¯æ£€ç´¢ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-13 09:15:08 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-13 09:15:08 UTC</p>
<h1 id="122-artificial-intelligence">1.2.2 Artificial Intelligence</h1>
<p><strong>From</strong>ï¼šhttps://papers.cool/arxiv/cs.AI</p>
<p>Fromï¼šhttps://arxiv.org/list/cs.AI/recenthttps://arxiv.org/list/cs.CL/recent
2025-08-15 | | æ€»è®¡ï¼š152</p>
<h2 id="1-who-benefits-from-ai-explanations-towards-accessible-and-interpretable-systems--1-è°ä»äººå·¥æ™ºèƒ½è§£é‡Šä¸­å—ç›Šè¿ˆå‘å¯è®¿é—®ä¸”å¯è§£é‡Šçš„ç³»ç»Ÿ"><a href="https://arxiv.org/abs/2508.10806"target="_blank" rel="external nofollow noopener noreferrer">#1</a> <a href="https://papers.cool/arxiv/2508.10806"target="_blank" rel="external nofollow noopener noreferrer">Who Benefits from AI Explanations? Towards Accessible and Interpretable Systems</a>  #1 è°ä»äººå·¥æ™ºèƒ½è§£é‡Šä¸­å—ç›Šï¼Ÿè¿ˆå‘å¯è®¿é—®ä¸”å¯è§£é‡Šçš„ç³»ç»Ÿ</h2>
<p><strong>Authors</strong>: [Maria J. P. Peixoto](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maria</a> J. P. Peixoto), [Akriti Pandey](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Akriti"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Akriti</a> Pandey), [Ahsan Zaman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ahsan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ahsan</a> Zaman), [Peter R. Lewis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peter"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peter</a> R. Lewis)
ä½œè€…ï¼šMaria J. P. Peixotoã€Akriti Pandeyã€Ahsan Zamanã€Peter R. Lewis</p>
<p>As AI systems are increasingly deployed to support decision-making in critical domains, explainability has become a means to enhance the understandability of these outputs and enable users to make more informed and conscious choices. However, despite growing interest in the usability of eXplainable AI (XAI), the accessibility of these methods, particularly for users with vision impairments, remains underexplored. This paper investigates accessibility gaps in XAI through a two-pronged approach. First, a literature review of 79 studies reveals that evaluations of XAI techniques rarely include disabled users, with most explanations relying on inherently visual formats. Second, we present a four-part methodological proof of concept that operationalizes inclusive XAI design: (1) categorization of AI systems, (2) persona definition and contextualization, (3) prototype design and implementation, and (4) expert and user assessment of XAI techniques for accessibility. Preliminary findings suggest that simplified explanations are more comprehensible for non-visual users than detailed ones, and that multimodal presentation is required for more equitable interpretability.
éšç€äººå·¥æ™ºèƒ½ç³»ç»Ÿè¶Šæ¥è¶Šå¤šåœ°è¢«éƒ¨ç½²ç”¨äºæ”¯æŒå…³é”®é¢†åŸŸçš„å†³ç­–ï¼Œå¯è§£é‡Šæ€§å·²æˆä¸ºå¢å¼ºè¿™äº›è¾“å‡ºå¯ç†è§£æ€§å¹¶ä½¿ç”¨æˆ·èƒ½å¤Ÿåšå‡ºæ›´æœ‰ä¿¡æ¯å’Œæ›´æœ‰æ„è¯†é€‰æ‹©çš„ä¸€ç§æ‰‹æ®µã€‚ç„¶è€Œï¼Œå°½ç®¡å¯¹å¯è§£é‡Šäººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰å¯ç”¨æ€§çš„å…´è¶£æ—¥ç›Šå¢é•¿ï¼Œä½†è¿™äº›æ–¹æ³•çš„å¯è®¿é—®æ€§ï¼Œå°¤å…¶æ˜¯å¯¹è§†è§‰éšœç¢ç”¨æˆ·çš„å¯åŠæ€§ï¼Œä»ç„¶é²œæœ‰ç ”ç©¶ã€‚æœ¬æ–‡é€šè¿‡ä¸¤ç®¡é½ä¸‹çš„æ–¹æ³•è°ƒæŸ¥äº† XAI çš„å¯è®¿é—®æ€§å·®è·ã€‚é¦–å…ˆï¼Œå¯¹ 79 é¡¹ç ”ç©¶çš„æ–‡çŒ®ç»¼è¿°æ˜¾ç¤ºï¼ŒXAI æŠ€æœ¯çš„è¯„ä¼°å¾ˆå°‘åŒ…å«æ®‹éšœç”¨æˆ·ï¼Œå¹¶ä¸”å¤§å¤šæ•°è§£é‡Šä¾èµ–äºå›ºæœ‰çš„è§†è§‰æ ¼å¼ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç”±å››éƒ¨åˆ†ç»„æˆçš„æ–¹æ³•è®ºæ¦‚å¿µéªŒè¯ä»¥å®ç°åŒ…å®¹æ€§ XAI è®¾è®¡ï¼š (1) å¯¹äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„åˆ†ç±»ï¼Œ(2) è§’è‰²è®¾å®šä¸æƒ…å¢ƒåŒ–ï¼Œ(3) åŸå‹è®¾è®¡ä¸å®ç°ï¼Œå’Œ (4) ä¸“å®¶ä¸ç”¨æˆ·å¯¹ XAI æŠ€æœ¯å¯è®¿é—®æ€§çš„è¯„ä¼°ã€‚åˆæ­¥å‘ç°è¡¨æ˜ï¼Œç®€åŒ–çš„è§£é‡Šå¯¹éè§†è§‰ç”¨æˆ·æ¥è¯´æ¯”è¯¦å°½çš„è§£é‡Šæ›´æ˜“ç†è§£ï¼Œå¹¶ä¸”è¦å®ç°æ›´å…¬å¹³çš„å¯è§£é‡Šæ€§éœ€è¦å¤šæ¨¡æ€å‘ˆç°ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 16:26:09 UTC
å‘å¸ƒï¼š2025-08-14 16:26:09 UTC</p>
<h2 id="2-the-knowledge-reasoning-dissociation-fundamental-limitations-of-llms-in-clinical-natural-language-inference--2-çŸ¥è¯†-æ¨ç†åˆ†ç¦»llms-åœ¨ä¸´åºŠè‡ªç„¶è¯­è¨€æ¨ç†ä¸­çš„åŸºæœ¬å±€é™æ€§"><a href="https://arxiv.org/abs/2508.10777"target="_blank" rel="external nofollow noopener noreferrer">#2</a> <a href="https://papers.cool/arxiv/2508.10777"target="_blank" rel="external nofollow noopener noreferrer">The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference</a>  #2 çŸ¥è¯†-æ¨ç†åˆ†ç¦»ï¼šLLMs åœ¨ä¸´åºŠè‡ªç„¶è¯­è¨€æ¨ç†ä¸­çš„åŸºæœ¬å±€é™æ€§</h2>
<p><strong>Authors</strong>: [MaÃ«l Jullien](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ma"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ma</a>Ã«l Jullien), [Marco Valentino](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marco"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marco</a> Valentino), [AndrÃ© Freitas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andr"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andr</a>Ã© Freitas)
ä½œè€…ï¼šMaÃ«l Jullienï¼ŒMarco Valentinoï¼ŒAndrÃ© Freitas</p>
<p>Large language models are often assumed to acquire increasingly structured, generalizable internal representations simply by scaling data and parameters. We interrogate this assumption by introducing a Clinical Trial Natural Language Inference benchmark comprising four reasoning families, Causal Attribution, Compositional Grounding, Epistemic Verification, and Risk State Abstraction. Each item is paired with a targeted Ground Knowledge and Meta-Level Reasoning Verification (GKMRV) probe, allowing us to dissociate failures of factual access from failures of inference. We evaluate six contemporary LLMs under both direct and chain of thought prompting. Models achieve near-ceiling GKMRV accuracy (mean accuracy 0.918) yet perform poorly on the main reasoning tasks (mean accuracy 0.25). Despite low accuracy, output inferences are highly consistent across samples (mean 0.87), indicating a systematic application of underlying heuristics and shortcuts. These results reveal fundamental structural and representational limitations: current LLMs often possess the relevant clinical knowledge but lack the structured, composable internal representations needed to deploy it reliably (e.g., integrating constraints, weighing evidence, or simulating counterfactuals). Decoupling knowledge from reasoning with GKMRV makes this dissociation explicit and measurable, providing an effective framework for probing the reliability of LLMs in high-stakes domains.
å¤§å‹è¯­è¨€æ¨¡å‹å¸¸è¢«è®¤ä¸ºé€šè¿‡æ‰©å¤§æ•°æ®å’Œå‚æ•°è§„æ¨¡ï¼Œå°±èƒ½è·å¾—è¶Šæ¥è¶Šç»“æ„åŒ–ã€å¯æ³›åŒ–çš„å†…éƒ¨è¡¨ç¤ºã€‚æˆ‘ä»¬é€šè¿‡å¼•å…¥ä¸€ä¸ªä¸´åºŠè¯•éªŒè‡ªç„¶è¯­è¨€æ¨ç†åŸºå‡†æ¥æ£€éªŒè¿™ä¸€å‡è®¾ï¼Œè¯¥åŸºå‡†åŒ…å«å››ç±»æ¨ç†ï¼šå› æœå½’å› ã€ç»„åˆæ€§å½’å±ã€è®¤è¯†è®ºéªŒè¯å’Œé£é™©çŠ¶æ€æŠ½è±¡ã€‚æ¯ä¸ªæ¡ç›®éƒ½é…æœ‰ä¸€ä¸ªé’ˆå¯¹æ€§çš„â€œåŸºç¡€çŸ¥è¯†ä¸å…ƒçº§æ¨ç†éªŒè¯â€ï¼ˆGround Knowledge and Meta-Level Reasoning Verificationï¼ŒGKMRVï¼‰æ¢é’ˆï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿå°†äº‹å®è®¿é—®å¤±è´¥ä¸æ¨ç†å¤±è´¥åŒºåˆ†å¼€æ¥ã€‚æˆ‘ä»¬åœ¨ç›´æ¥æç¤ºå’Œé“¾å¼æ€ç»´æç¤ºä¸‹è¯„ä¼°äº†å…­ç§å½“ä»£ LLMsã€‚æ¨¡å‹åœ¨ GKMRV ä¸Šå‡ ä¹è¾¾åˆ°ä¸Šé™å‡†ç¡®ç‡ï¼ˆå¹³å‡å‡†ç¡®ç‡ 0.918ï¼‰ï¼Œä½†åœ¨ä¸»è¦æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°å¾ˆå·®ï¼ˆå¹³å‡å‡†ç¡®ç‡ 0.25ï¼‰ã€‚å°½ç®¡å‡†ç¡®ç‡ä½ï¼Œè¾“å‡ºæ¨æ–­åœ¨æ ·æœ¬é—´é«˜åº¦ä¸€è‡´ï¼ˆå¹³å‡ 0.87ï¼‰ï¼Œè¡¨æ˜æ¨¡å‹ç³»ç»Ÿæ€§åœ°åº”ç”¨äº†æ½œåœ¨çš„å¯å‘å¼æ–¹æ³•å’Œæ·å¾„ã€‚ è¿™äº›ç»“æœæ­ç¤ºäº†æ ¹æœ¬çš„ç»“æ„å’Œè¡¨å¾é™åˆ¶ï¼šå½“å‰çš„ LLMs é€šå¸¸å…·å¤‡ç›¸å…³çš„ä¸´åºŠçŸ¥è¯†ï¼Œä½†ç¼ºä¹å°†å…¶å¯é éƒ¨ç½²æ‰€éœ€çš„ç»“æ„åŒ–ã€å¯ç»„åˆçš„å†…éƒ¨è¡¨å¾ï¼ˆä¾‹å¦‚ï¼Œæ•´åˆçº¦æŸã€æƒè¡¡è¯æ®æˆ–æ¨¡æ‹Ÿåäº‹å®ï¼‰ã€‚é€šè¿‡å°†çŸ¥è¯†ä¸æ¨ç†åœ¨ GKMRV ä¸­è§£è€¦ï¼Œä½¿è¿™ç§è„±èŠ‚å˜å¾—æ˜ç¡®ä¸”å¯æµ‹é‡ï¼Œä¸ºæ¢æŸ¥ LLMs åœ¨é«˜é£é™©é¢†åŸŸçš„å¯é æ€§æä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„æ¡†æ¶ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 16:01:10 UTC
å‘å¸ƒï¼š2025-08-14 16:01:10 UTC</p>
<h2 id="3-modeling-human-responses-to-multimodal-ai-content--3-å¯¹å¤šæ¨¡æ€-ai-å†…å®¹ä¸­äººç±»ååº”çš„å»ºæ¨¡"><a href="https://arxiv.org/abs/2508.10769"target="_blank" rel="external nofollow noopener noreferrer">#3</a> <a href="https://papers.cool/arxiv/2508.10769"target="_blank" rel="external nofollow noopener noreferrer">Modeling Human Responses to Multimodal AI Content</a>  #3 å¯¹å¤šæ¨¡æ€ AI å†…å®¹ä¸­äººç±»ååº”çš„å»ºæ¨¡</h2>
<p><strong>Authors</strong>: [Zhiqi Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiqi</a> Shen), [Shaojing Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaojing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaojing</a> Fan), [Danni Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Danni"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Danni</a> Xu), [Terence Sim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Terence"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Terence</a> Sim), [Mohan Kankanhalli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohan</a> Kankanhalli)
ä½œè€…ï¼šZhiqi Shenã€Shaojing Fanã€Danni Xuã€Terence Simã€Mohan Kankanhalli</p>
<p>As AI-generated content becomes widespread, so does the risk of misinformation. While prior research has primarily focused on identifying whether content is authentic, much less is known about how such content influences human perception and behavior. In domains like trading or the stock market, predicting how people react (e.g., whether a news post will go viral), can be more critical than verifying its factual accuracy. To address this, we take a human-centered approach and introduce the MhAIM Dataset, which contains 154,552 online posts (111,153 of them AI-generated), enabling large-scale analysis of how people respond to AI-generated content. Our human study reveals that people are better at identifying AI content when posts include both text and visuals, particularly when inconsistencies exist between the two. We propose three new metrics: trustworthiness, impact, and openness, to quantify how users judge and engage with online content. We present T-Lens, an LLM-based agent system designed to answer user queries by incorporating predicted human responses to multimodal information. At its core is HR-MCP (Human Response Model Context Protocol), built on the standardized Model Context Protocol (MCP), enabling seamless integration with any LLM. This integration allows T-Lens to better align with human reactions, enhancing both interpretability and interaction capabilities. Our work provides empirical insights and practical tools to equip LLMs with human-awareness capabilities. By highlighting the complex interplay among AI, human cognition, and information reception, our findings suggest actionable strategies for mitigating the risks of AI-driven misinformation.
éšç€ AI ç”Ÿæˆå†…å®¹çš„æ™®åŠï¼Œé”™è¯¯ä¿¡æ¯çš„é£é™©ä¹Ÿåœ¨å¢åŠ ã€‚å°½ç®¡ä»¥å¾€ç ”ç©¶ä¸»è¦é›†ä¸­åœ¨è¯†åˆ«å†…å®¹æ˜¯å¦çœŸå®ï¼Œä½†å…³äºæ­¤ç±»å†…å®¹å¦‚ä½•å½±å“äººç±»æ„ŸçŸ¥ä¸è¡Œä¸ºçš„ç ”ç©¶å´å°‘å¾—å¤šã€‚åœ¨äº¤æ˜“æˆ–è‚¡ç¥¨å¸‚åœºç­‰é¢†åŸŸï¼Œé¢„æµ‹äººä»¬å¦‚ä½•ååº”ï¼ˆä¾‹å¦‚æŸæ¡æ–°é—»æ˜¯å¦ä¼šèµ°çº¢ï¼‰å¯èƒ½æ¯”æ ¸å®å…¶äº‹å®å‡†ç¡®æ€§æ›´ä¸ºå…³é”®ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡å–ä»¥äººä¸ºæœ¬çš„æ–¹æ³•ï¼Œæ¨å‡ºäº† MhAIM æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å« 154,552 æ¡åœ¨çº¿å¸–å­ï¼ˆå…¶ä¸­ 111,153 æ¡ä¸º AI ç”Ÿæˆï¼‰ï¼Œä»è€Œå®ç°å¯¹äººä»¬å¦‚ä½•å›åº” AI ç”Ÿæˆå†…å®¹çš„å¤§è§„æ¨¡åˆ†æã€‚æˆ‘ä»¬çš„ç”¨æˆ·ç ”ç©¶è¡¨æ˜ï¼Œå½“å¸–å­åŒæ—¶åŒ…å«æ–‡æœ¬å’Œè§†è§‰ä¿¡æ¯ï¼Œå°¤å…¶æ˜¯ä¸¤è€…ä¹‹é—´å­˜åœ¨ä¸ä¸€è‡´æ—¶ï¼Œäººä»¬æ›´æ“…é•¿è¯†åˆ« AI å†…å®¹ã€‚æˆ‘ä»¬æå‡ºäº†ä¸‰é¡¹æ–°åº¦é‡ï¼šå¯ä¿¡åº¦ã€å½±å“åŠ›å’Œå¼€æ”¾åº¦ï¼Œç”¨ä»¥é‡åŒ–ç”¨æˆ·å¦‚ä½•è¯„åˆ¤å¹¶ä¸åœ¨çº¿å†…å®¹äº’åŠ¨ã€‚æˆ‘ä»¬è¿˜æå‡ºäº† T-Lensï¼Œè¿™æ˜¯ä¸€ç§åŸºäº LLM çš„ä»£ç†ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡ç»“åˆå¯¹å¤šæ¨¡æ€ä¿¡æ¯çš„é¢„æµ‹äººç±»ååº”æ¥å›ç­”ç”¨æˆ·æŸ¥è¯¢ã€‚ å…¶æ ¸å¿ƒæ˜¯ HR-MCPï¼ˆHuman Response Model Context Protocolï¼Œäººä½“ååº”æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼‰ï¼Œå»ºç«‹åœ¨æ ‡å‡†åŒ–çš„ Model Context Protocol (MCP) ä¹‹ä¸Šï¼Œèƒ½å¤Ÿä¸ä»»ä½• LLM æ— ç¼é›†æˆã€‚è¯¥é›†æˆä½¿ T-Lens æ›´åŠ ç¬¦åˆäººç±»ååº”ï¼Œå¢å¼ºäº†è§£é‡Šæ€§å’Œäº¤äº’èƒ½åŠ›ã€‚æˆ‘ä»¬çš„å·¥ä½œæä¾›äº†å®è¯è§è§£å’Œå®ç”¨å·¥å…·ï¼Œä»¥èµ‹äºˆ LLMs äººç±»æ„ŸçŸ¥èƒ½åŠ›ã€‚é€šè¿‡å¼ºè°ƒäººå·¥æ™ºèƒ½ã€äººç±»è®¤çŸ¥å’Œä¿¡æ¯æ¥å—ä¹‹é—´çš„å¤æ‚ç›¸äº’ä½œç”¨ï¼Œæˆ‘ä»¬çš„ç ”ç©¶ç»“æœæå‡ºäº†å¯å®æ–½çš„ç­–ç•¥ï¼Œä»¥å‡è½»ç”± AI é©±åŠ¨çš„é”™è¯¯ä¿¡æ¯é£é™©ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">Multimedia</a>
ä¸»é¢˜ï¼šArtificial Intelligence ï¼ŒMultimedia</p>
<p><strong>Publish</strong>: 2025-08-14 15:55:19 UTC
å‘å¸ƒï¼š2025-08-14 15:55:19 UTC</p>
<h2 id="4-scaling-up-without-fading-out-goal-aware-sparse-gnn-for-rl-based-generalized-planning"><a href="https://arxiv.org/abs/2508.10747"target="_blank" rel="external nofollow noopener noreferrer">#4</a> <a href="https://papers.cool/arxiv/2508.10747"target="_blank" rel="external nofollow noopener noreferrer">Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning</a></h2>
<p><strong>Authors</strong>: [Sangwoo Jeon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sangwoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sangwoo</a> Jeon), [Juchul Shin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juchul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juchul</a> Shin), [Gyeong-Tae Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gyeong-Tae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gyeong-Tae</a> Kim), [YeonJe Cho](<a href="https://arxiv.org/search/?searchtype=author&amp;query=YeonJe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=YeonJe</a> Cho), [Seongwoo Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seongwoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seongwoo</a> Kim)
ä½œè€…ï¼šSangwoo Jeonã€Juchul Shinã€Gyeong-Tae Kimã€YeonJe Choã€Seongwoo Kim</p>
<p>Generalized planning using deep reinforcement learning (RL) combined with graph neural networks (GNNs) has shown promising results in various symbolic planning domains described by PDDL. However, existing approaches typically represent planning states as fully connected graphs, leading to a combinatorial explosion in edge information and substantial sparsity as problem scales grow, especially evident in large grid-based environments. This dense representation results in diluted node-level information, exponentially increases memory requirements, and ultimately makes learning infeasible for larger-scale problems. To address these challenges, we propose a sparse, goal-aware GNN representation that selectively encodes relevant local relationships and explicitly integrates spatial features related to the goal. We validate our approach by designing novel drone mission scenarios based on PDDL within a grid world, effectively simulating realistic mission execution environments. Our experimental results demonstrate that our method scales effectively to larger grid sizes previously infeasible with dense graph representations and substantially improves policy generalization and success rates. Our findings provide a practical foundation for addressing realistic, large-scale generalized planning tasks.
å°†æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä¸å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰ç›¸ç»“åˆçš„æ³›åŒ–è§„åˆ’æ–¹æ³•åœ¨ç”± PDDL æè¿°çš„å„ç§ç¬¦å·è§„åˆ’é¢†åŸŸä¸­æ˜¾ç¤ºå‡ºæœ‰å¸Œæœ›çš„ç»“æœã€‚ç„¶è€Œï¼Œç°æœ‰æ–¹æ³•é€šå¸¸å°†è§„åˆ’çŠ¶æ€è¡¨ç¤ºä¸ºå…¨è¿æ¥å›¾ï¼Œå¯¼è‡´è¾¹ä¿¡æ¯çš„ç»„åˆçˆ†ç‚¸ä»¥åŠéšç€é—®é¢˜è§„æ¨¡å¢é•¿è€Œæ˜¾è‘—çš„ç¨€ç–æ€§ï¼Œè¿™åœ¨å¤§å‹ç½‘æ ¼ç¯å¢ƒä¸­å°¤ä¸ºæ˜æ˜¾ã€‚è¿™ç§ç¨ å¯†è¡¨ç¤ºä¼šç¨€é‡ŠèŠ‚ç‚¹çº§ä¿¡æ¯ã€æŒ‡æ•°çº§å¢åŠ å†…å­˜éœ€æ±‚ï¼Œå¹¶æœ€ç»ˆä½¿å¾—åœ¨æ›´å¤§è§„æ¨¡é—®é¢˜ä¸Šå­¦ä¹ å˜å¾—ä¸å¯è¡Œã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç¨€ç–çš„ã€æ„ŸçŸ¥ç›®æ ‡çš„ GNN è¡¨ç¤ºï¼Œé€‰æ‹©æ€§åœ°ç¼–ç ç›¸å…³çš„å±€éƒ¨å…³ç³»å¹¶æ˜¾å¼æ•´åˆä¸ç›®æ ‡ç›¸å…³çš„ç©ºé—´ç‰¹å¾ã€‚æˆ‘ä»¬é€šè¿‡åœ¨ç½‘æ ¼ä¸–ç•Œä¸­åŸºäº PDDL è®¾è®¡æ–°é¢–çš„æ— äººæœºä»»åŠ¡åœºæ™¯æ¥éªŒè¯æˆ‘ä»¬çš„æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°æ¨¡æ‹Ÿäº†ç°å®çš„ä»»åŠ¡æ‰§è¡Œç¯å¢ƒã€‚ æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½æœ‰æ•ˆæ‰©å±•åˆ°å…ˆå‰é‡‡ç”¨ç¨ å¯†å›¾è¡¨ç¤ºæ— æ³•å®ç°çš„æ›´å¤§ç½‘æ ¼å°ºå¯¸ï¼Œå¹¶æ˜¾è‘—æå‡ç­–ç•¥çš„æ³›åŒ–èƒ½åŠ›å’ŒæˆåŠŸç‡ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ºè§£å†³ç°å®çš„å¤§è§„æ¨¡å¹¿ä¹‰è§„åˆ’ä»»åŠ¡æä¾›äº†å®ç”¨åŸºç¡€ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">Robotics</a></p>
<p><strong>Publish</strong>: 2025-08-14 15:30:28 UTC</p>
<h2 id="5-agentic-design-review-system"><a href="https://arxiv.org/abs/2508.10745"target="_blank" rel="external nofollow noopener noreferrer">#5</a> <a href="https://papers.cool/arxiv/2508.10745"target="_blank" rel="external nofollow noopener noreferrer">Agentic Design Review System</a></h2>
<p><strong>Authors</strong>: [Sayan Nag](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sayan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sayan</a> Nag), [K J Joseph](<a href="https://arxiv.org/search/?searchtype=author&amp;query=K"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=K</a> J Joseph), [Koustava Goswami](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Koustava"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Koustava</a> Goswami), [Vlad I Morariu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vlad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vlad</a> I Morariu), [Balaji Vasan Srinivasan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Balaji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Balaji</a> Vasan Srinivasan)
ä½œè€…ï¼šSayan Nagã€K J Josephã€Koustava Goswamiã€Vlad I Morariuã€Balaji Vasan Srinivasan</p>
<p>Evaluating graphic designs involves assessing it from multiple facets like alignment, composition, aesthetics and color choices. Evaluating designs in a holistic way involves aggregating feedback from individual expert reviewers. Towards this, we propose an Agentic Design Review System (AgenticDRS), where multiple agents collaboratively analyze a design, orchestrated by a meta-agent. A novel in-context exemplar selection approach based on graph matching and a unique prompt expansion method plays central role towards making each agent design aware. Towards evaluating this framework, we propose DRS-BENCH benchmark. Thorough experimental evaluation against state-of-the-art baselines adapted to the problem setup, backed-up with critical ablation experiments brings out the efficacy of Agentic-DRS in evaluating graphic designs and generating actionable feedback. We hope that this work will attract attention to this pragmatic, yet under-explored research direction.
è¯„ä¼°å¹³é¢è®¾è®¡éœ€è¦ä»å¯¹é½ã€æ„å›¾ã€ç¾å­¦å’Œè‰²å½©é€‰æ‹©ç­‰å¤šä¸ªæ–¹é¢è¿›è¡Œè€ƒå¯Ÿã€‚å¯¹è®¾è®¡è¿›è¡Œæ•´ä½“è¯„ä¼°éœ€è¦æ±‡æ€»æ¥è‡ªå„ä¸ªä¸“å®¶è¯„å®¡è€…çš„åé¦ˆã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ä»£ç†å¼è®¾è®¡è¯„å®¡ç³»ç»Ÿï¼ˆAgenticDRSï¼‰ï¼Œå…¶ä¸­å¤šä¸ªä»£ç†åœ¨å…ƒä»£ç†çš„åè°ƒä¸‹ååŒåˆ†æè®¾è®¡ã€‚ä¸€ç§åŸºäºå›¾åŒ¹é…çš„æƒ…å¢ƒç¤ºä¾‹é€‰æ‹©æ–°æ–¹æ³•å’Œä¸€ç§ç‹¬ç‰¹çš„æç¤ºæ‰©å±•æ–¹æ³•åœ¨ä½¿æ¯ä¸ªä»£ç†å…·å¤‡è®¾è®¡æ„ŸçŸ¥æ–¹é¢èµ·åˆ°äº†æ ¸å¿ƒä½œç”¨ã€‚ä¸ºè¯„ä¼°è¯¥æ¡†æ¶ï¼Œæˆ‘ä»¬æå‡ºäº† DRS-BENCH åŸºå‡†ã€‚é€šè¿‡ä¸é’ˆå¯¹è¯¥é—®é¢˜è®¾ç½®æ”¹ç¼–çš„æœ€å…ˆè¿›åŸºçº¿è¿›è¡Œå…¨é¢çš„å®éªŒè¯„ä¼°ï¼Œå¹¶è¾…ä»¥å…³é”®çš„æ¶ˆèå®éªŒï¼Œå±•ç¤ºäº† Agentic-DRS åœ¨è¯„ä¼°å¹³é¢è®¾è®¡å’Œç”Ÿæˆå¯æ“ä½œåé¦ˆæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬å¸Œæœ›è¿™é¡¹å·¥ä½œèƒ½å¼•èµ·äººä»¬å¯¹è¿™ä¸€åŠ¡å®ä½†å°šæœªå……åˆ†æ¢ç´¢çš„ç ”ç©¶æ–¹å‘çš„å…³æ³¨ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">Multiagent Systems</a>, <a href="https://papers.cool/arxiv/cs.MM"target="_blank" rel="external nofollow noopener noreferrer">Multimedia</a>
å­¦ç§‘ï¼šäººå·¥æ™ºèƒ½ã€è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ã€æœºå™¨å­¦ä¹ ã€å¤šä»£ç†ç³»ç»Ÿã€å¤šåª’ä½“</p>
<p><strong>Publish</strong>: 2025-08-14 15:29:24 UTC
å‘å¸ƒï¼š2025-08-14 15:29:24 UTC</p>
<h2 id="6-genom-ontology-matching-with-description-generation-and-large-language-model--6-genomä½¿ç”¨æè¿°ç”Ÿæˆå’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æœ¬ä½“åŒ¹é…"><a href="https://arxiv.org/abs/2508.10703"target="_blank" rel="external nofollow noopener noreferrer">#6</a> <a href="https://papers.cool/arxiv/2508.10703"target="_blank" rel="external nofollow noopener noreferrer">GenOM: Ontology Matching with Description Generation and Large Language Model</a>  #6 GenOMï¼šä½¿ç”¨æè¿°ç”Ÿæˆå’Œå¤§å‹è¯­è¨€æ¨¡å‹çš„æœ¬ä½“åŒ¹é…</h2>
<p><strong>Authors</strong>: [Yiping Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiping</a> Song), [Jiaoyan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaoyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaoyan</a> Chen), [Renate A. Schmidt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Renate"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Renate</a> A. Schmidt)
ä½œè€…ï¼šå®‹è‰ºå¹³ï¼Œé™ˆæ•™ç ”ï¼ŒRenate A. Schmidt</p>
<p>Ontology matching (OM) plays an essential role in enabling semantic interoperability and integration across heterogeneous knowledge sources, particularly in the biomedical domain which contains numerous complex concepts related to diseases and pharmaceuticals. This paper introduces GenOM, a large language model (LLM)-based ontology alignment framework, which enriches the semantic representations of ontology concepts via generating textual definitions, retrieves alignment candidates with an embedding model, and incorporates exact matching-based tools to improve precision. Extensive experiments conducted on the OAEI Bio-ML track demonstrate that GenOM can often achieve competitive performance, surpassing many baselines including traditional OM systems and recent LLM-based methods. Further ablation studies confirm the effectiveness of semantic enrichment and few-shot prompting, highlighting the framework&rsquo;s robustness and adaptability.
æœ¬ä½“åŒ¹é…ï¼ˆOMï¼‰åœ¨å®ç°å¼‚æ„çŸ¥è¯†æºä¹‹é—´çš„è¯­ä¹‰äº’æ“ä½œæ€§å’Œé›†æˆæ–¹é¢èµ·ç€å…³é”®ä½œç”¨ï¼Œå°¤å…¶åœ¨åŒ…å«å¤§é‡ä¸ç–¾ç—…å’Œè¯ç‰©ç›¸å…³çš„å¤æ‚æ¦‚å¿µçš„ç”Ÿç‰©åŒ»å­¦é¢†åŸŸã€‚æœ¬æ–‡æå‡ºäº† GenOMï¼Œä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æœ¬ä½“å¯¹é½æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç”Ÿæˆæ–‡æœ¬å®šä¹‰æ¥ä¸°å¯Œæœ¬ä½“æ¦‚å¿µçš„è¯­ä¹‰è¡¨ç¤ºï¼Œä½¿ç”¨åµŒå…¥æ¨¡å‹æ£€ç´¢å¯¹é½å€™é€‰é¡¹ï¼Œå¹¶ç»“åˆåŸºäºç²¾ç¡®åŒ¹é…çš„å·¥å…·ä»¥æé«˜ç²¾åº¦ã€‚åœ¨ OAEI Bio-ML èµ›é“ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¯æ˜ï¼ŒGenOM é€šå¸¸èƒ½å¤Ÿå–å¾—å…·æœ‰ç«äº‰åŠ›çš„æ€§èƒ½ï¼Œè¶…è¿‡åŒ…æ‹¬ä¼ ç»Ÿ OM ç³»ç»Ÿå’Œè¿‘æœŸåŸºäº LLM çš„æ–¹æ³•åœ¨å†…çš„è®¸å¤šåŸºçº¿ã€‚è¿›ä¸€æ­¥çš„æ¶ˆèç ”ç©¶è¯å®äº†è¯­ä¹‰å¢å¼ºå’Œå°‘æ ·æœ¬æç¤ºçš„æœ‰æ•ˆæ€§ï¼Œå‡¸æ˜¾äº†è¯¥æ¡†æ¶çš„ç¨³å¥æ€§å’Œé€‚åº”æ€§ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 14:48:09 UTC
å‘å¸ƒï¼š2025-08-14 14:48:09 UTC</p>
<h2 id="7-step-stepwise-curriculum-learning-for-context-knowledge-fusion-in-conversational-recommendation--7-stepç”¨äºå¯¹è¯å¼æ¨èä¸­ä¸Šä¸‹æ–‡ä¸çŸ¥è¯†èåˆçš„åˆ†æ­¥è¯¾ç¨‹å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10669"target="_blank" rel="external nofollow noopener noreferrer">#7</a> <a href="https://papers.cool/arxiv/2508.10669"target="_blank" rel="external nofollow noopener noreferrer">STEP: Stepwise Curriculum Learning for Context-Knowledge Fusion in Conversational Recommendation</a>  #7 STEPï¼šç”¨äºå¯¹è¯å¼æ¨èä¸­ä¸Šä¸‹æ–‡ä¸çŸ¥è¯†èåˆçš„åˆ†æ­¥è¯¾ç¨‹å­¦ä¹ </h2>
<p><strong>Authors</strong>: [Zhenye Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenye</a> Yang), [Jinpeng Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinpeng</a> Chen), [Huan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huan</a> Li), [Xiongnan Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiongnan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiongnan</a> Jin), [Xuanyang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuanyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuanyang</a> Li), [Junwei Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junwei</a> Zhang), [Hongbo Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongbo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongbo</a> Gao), [Kaimin Wei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaimin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaimin</a> Wei), [Senzhang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Senzhang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Senzhang</a> Wang)
ä½œè€…ï¼šæ¨æŒ¯ä¸šã€é™ˆé‡‘é¹ã€ææ¬¢ã€é‡‘é›„æ¥ ã€æè½©é˜³ã€å¼ ä¿Šä¼Ÿã€é«˜å®åšã€é­å‡¯æ•ã€ç‹æ£®ç« </p>
<p>Conversational recommender systems (CRSs) aim to proactively capture user preferences through natural language dialogue and recommend high-quality items. To achieve this, CRS gathers user preferences via a dialog module and builds user profiles through a recommendation module to generate appropriate recommendations. However, existing CRS faces challenges in capturing the deep semantics of user preferences and dialogue context. In particular, the efficient integration of external knowledge graph (KG) information into dialogue generation and recommendation remains a pressing issue. Traditional approaches typically combine KG information directly with dialogue content, which often struggles with complex semantic relationships, resulting in recommendations that may not align with user expectations. To address these challenges, we introduce STEP, a conversational recommender centered on pre-trained language models that combines curriculum-guided context-knowledge fusion with lightweight task-specific prompt tuning. At its heart, an F-Former progressively aligns the dialogue context with knowledge-graph entities through a three-stage curriculum, thus resolving fine-grained semantic mismatches. The fused representation is then injected into the frozen language model via two minimal yet adaptive prefix prompts: a conversation prefix that steers response generation toward user intent and a recommendation prefix that biases item ranking toward knowledge-consistent candidates. This dual-prompt scheme allows the model to share cross-task semantics while respecting the distinct objectives of dialogue and recommendation. Experimental results show that STEP outperforms mainstream methods in the precision of recommendation and dialogue quality in two public datasets.
å¯¹è¯å¼æ¨èç³»ç»Ÿï¼ˆCRSï¼‰æ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å¯¹è¯ä¸»åŠ¨æ•æ‰ç”¨æˆ·åå¥½å¹¶æ¨èé«˜è´¨é‡çš„é¡¹ç›®ã€‚ä¸ºæ­¤ï¼ŒCRS é€šè¿‡å¯¹è¯æ¨¡å—æ”¶é›†ç”¨æˆ·åå¥½ï¼Œå¹¶é€šè¿‡æ¨èæ¨¡å—æ„å»ºç”¨æˆ·ç”»åƒä»¥ç”Ÿæˆåˆé€‚çš„æ¨èã€‚ç„¶è€Œï¼Œç°æœ‰çš„ CRS åœ¨æ•æ‰ç”¨æˆ·åå¥½å’Œå¯¹è¯ä¸Šä¸‹æ–‡çš„æ·±å±‚è¯­ä¹‰æ–¹é¢é¢ä¸´æŒ‘æˆ˜ã€‚ç‰¹åˆ«æ˜¯ï¼Œå°†å¤–éƒ¨çŸ¥è¯†å›¾ï¼ˆKGï¼‰ä¿¡æ¯é«˜æ•ˆæ•´åˆåˆ°å¯¹è¯ç”Ÿæˆå’Œæ¨èä¸­ä»ç„¶æ˜¯ä¸€ä¸ªç´§è¿«çš„é—®é¢˜ã€‚ä¼ ç»Ÿæ–¹æ³•é€šå¸¸å°† KG ä¿¡æ¯ç›´æ¥ä¸å¯¹è¯å†…å®¹ç»“åˆï¼Œè¿™å¾€å¾€éš¾ä»¥å¤„ç†å¤æ‚çš„è¯­ä¹‰å…³ç³»ï¼Œå¯¼è‡´æ¨èç»“æœå¯èƒ½ä¸ç”¨æˆ·é¢„æœŸä¸ç¬¦ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº† STEPï¼Œä¸€ç§ä»¥é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ä¸ºæ ¸å¿ƒçš„å¯¹è¯å¼æ¨èç³»ç»Ÿï¼Œç»“åˆäº†è¯¾ç¨‹å¼•å¯¼çš„ä¸Šä¸‹æ–‡-çŸ¥è¯†èåˆä¸è½»é‡çº§çš„ä»»åŠ¡ç‰¹å®šæç¤ºå¾®è°ƒã€‚ å…¶æ ¸å¿ƒæ˜¯ï¼ŒF-Former é€šè¿‡ä¸‰é˜¶æ®µè¯¾ç¨‹å­¦ä¹ ï¼Œå°†å¯¹è¯ä¸Šä¸‹æ–‡é€æ­¥ä¸çŸ¥è¯†å›¾å®ä½“å¯¹é½ï¼Œä»è€Œè§£å†³ç»†ç²’åº¦è¯­ä¹‰ä¸åŒ¹é…é—®é¢˜ã€‚èåˆåçš„è¡¨ç¤ºéšåé€šè¿‡ä¸¤ä¸ªæœ€å°ä½†è‡ªé€‚åº”çš„å‰ç¼€æç¤ºæ³¨å…¥åˆ°è¢«å†»ç»“çš„è¯­è¨€æ¨¡å‹ä¸­ï¼šä¸€ä¸ªä¼šè¯å‰ç¼€å¼•å¯¼å›åº”ç”Ÿæˆä»¥å¥‘åˆç”¨æˆ·æ„å›¾ï¼Œå¦ä¸€ä¸ªæ¨èå‰ç¼€ä½¿æ¡ç›®æ’åºåå‘ä¸çŸ¥è¯†ä¸€è‡´çš„å€™é€‰é¡¹ã€‚è¿™ä¸ªåŒå‰ç¼€æ–¹æ¡ˆä½¿æ¨¡å‹åœ¨å…±äº«è·¨ä»»åŠ¡è¯­ä¹‰çš„åŒæ—¶ï¼Œå°Šé‡å¯¹è¯ä¸æ¨èå„è‡ªçš„ä¸åŒç›®æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä¸¤ä¸ªå…¬å¼€æ•°æ®é›†ä¸­ï¼ŒSTEP åœ¨æ¨èç²¾ç¡®åº¦å’Œå¯¹è¯è´¨é‡ä¸Šå‡ä¼˜äºä¸»æµæ–¹æ³•ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œä¿¡æ¯æ£€ç´¢</p>
<p><strong>Publish</strong>: 2025-08-14 14:08:21 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 14:08:21 UTC</p>
<h2 id="8-msrs-adaptive-multi-subspace-representation-steering-for-attribute-alignment-in-large-language-models--8-msrsç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹å±æ€§å¯¹é½çš„è‡ªé€‚åº”å¤šå­ç©ºé—´è¡¨ç¤ºå¼•å¯¼"><a href="https://arxiv.org/abs/2508.10599"target="_blank" rel="external nofollow noopener noreferrer">#8</a> <a href="https://papers.cool/arxiv/2508.10599"target="_blank" rel="external nofollow noopener noreferrer">MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models</a>  #8 MSRSï¼šç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹å±æ€§å¯¹é½çš„è‡ªé€‚åº”å¤šå­ç©ºé—´è¡¨ç¤ºå¼•å¯¼</h2>
<p><strong>Authors</strong>: [Xinyan Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinyan</a> Jiang), [Lin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lin</a> Zhang), [Jiayi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiayi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiayi</a> Zhang), [Qingsong Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingsong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingsong</a> Yang), [Guimin Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guimin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guimin</a> Hu), [Di Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Di"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Di</a> Wang), [Lijie Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lijie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lijie</a> Hu)
ä½œè€…ï¼šè’‹æ¬£å¦ã€å¼ éœ–ã€å¼ ä½³æ€¡ã€æ¨åº†æ¾ã€èƒ¡è´µæ•ã€ç‹è¿ªã€èƒ¡ä¸½æ´</p>
<p>Activation steering offers a promising approach to controlling the behavior of Large Language Models by directly manipulating their internal activations. However, most existing methods struggle to jointly steer multiple attributes, often resulting in interference and undesirable trade-offs. To address this challenge, we propose Multi-Subspace Representation Steering (MSRS), a novel framework for effective multi-attribute steering via subspace representation fine-tuning. MSRS reduces inter-attribute interference by allocating orthogonal subspaces to each attribute, isolating their influence within the model&rsquo;s representation space. MSRS also incorporates a hybrid subspace composition strategy: it combines attribute-specific subspaces for unique steering directions with a shared subspace for common steering directions. A dynamic weighting function learns to efficiently integrate these components for precise control. During inference, MSRS introduces a token-level steering mechanism that dynamically identifies and intervenes on the most semantically relevant tokens, enabling fine-grained behavioral modulation. Experimental results show that MSRS significantly reduces attribute conflicts, surpasses existing methods across a range of attributes, and generalizes effectively to diverse downstream tasks.
æ¿€æ´»å¼•å¯¼é€šè¿‡ç›´æ¥æ“çºµå¤§å‹è¯­è¨€æ¨¡å‹çš„å†…éƒ¨æ¿€æ´»ï¼Œä¸ºæ§åˆ¶å…¶è¡Œä¸ºæä¾›äº†ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ç°æœ‰æ–¹æ³•åœ¨è”åˆå¼•å¯¼å¤šä¸ªå±æ€§æ—¶è¡¨ç°ä¸ä½³ï¼Œå¸¸å¸¸å¯¼è‡´å¹²æ‰°å’Œä¸è‰¯æƒè¡¡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šå­ç©ºé—´è¡¨ç¤ºå¼•å¯¼ï¼ˆMulti-Subspace Representation Steeringï¼ŒMSRSï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å­ç©ºé—´è¡¨ç¤ºå¾®è°ƒå®ç°æœ‰æ•ˆå¤šå±æ€§å¼•å¯¼çš„æ–°æ¡†æ¶ã€‚MSRS é€šè¿‡ä¸ºæ¯ä¸ªå±æ€§åˆ†é…æ­£äº¤å­ç©ºé—´æ¥å‡å°‘å±æ€§é—´çš„å¹²æ‰°ï¼Œå°†å®ƒä»¬çš„å½±å“éš”ç¦»åœ¨æ¨¡å‹çš„è¡¨ç¤ºç©ºé—´å†…ã€‚MSRS è¿˜å¼•å…¥äº†ä¸€ç§æ··åˆå­ç©ºé—´ç»„åˆç­–ç•¥ï¼šå®ƒå°†ç”¨äºç‹¬ç‰¹å¼•å¯¼æ–¹å‘çš„å±æ€§ä¸“å±å­ç©ºé—´ä¸ç”¨äºå…¬å…±å¼•å¯¼æ–¹å‘çš„å…±äº«å­ç©ºé—´ç›¸ç»“åˆã€‚ä¸€ä¸ªåŠ¨æ€åŠ æƒå‡½æ•°å­¦ä¹ é«˜æ•ˆåœ°æ•´åˆè¿™äº›ç»„æˆéƒ¨åˆ†ä»¥å®ç°ç²¾ç¡®æ§åˆ¶ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ŒMSRS å¼•å…¥äº†ä¸€ç§ä»¤ç‰Œçº§çš„å¼•å¯¼æœºåˆ¶ï¼ŒåŠ¨æ€è¯†åˆ«å¹¶å¹²é¢„æœ€å…·è¯­ä¹‰ç›¸å…³æ€§çš„ä»¤ç‰Œï¼Œä»è€Œå®ç°ç»†ç²’åº¦çš„è¡Œä¸ºè°ƒèŠ‚ã€‚ å®éªŒç»“æœè¡¨æ˜ï¼ŒMSRS æ˜¾è‘—å‡å°‘äº†å±æ€§å†²çªï¼Œåœ¨å¤šç§å±æ€§ä¸Šè¶…è¶Šäº†ç°æœ‰æ–¹æ³•ï¼Œå¹¶èƒ½æœ‰æ•ˆåœ°æ³›åŒ–åˆ°å¤šæ ·åŒ–çš„ä¸‹æ¸¸ä»»åŠ¡ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 12:40:19 UTC
å‘å¸ƒï¼š2025-08-14 12:40:19 UTC</p>
<h2 id="9-improving-value-based-process-verifier-via-low-cost-variance-reduction--9-é€šè¿‡ä½æˆæœ¬æ–¹å·®å‡å°‘æ”¹è¿›åŸºäºä»·å€¼çš„è¿‡ç¨‹éªŒè¯å™¨"><a href="https://arxiv.org/abs/2508.10539"target="_blank" rel="external nofollow noopener noreferrer">#9</a> <a href="https://papers.cool/arxiv/2508.10539"target="_blank" rel="external nofollow noopener noreferrer">Improving Value-based Process Verifier via Low-Cost Variance Reduction</a>  #9 é€šè¿‡ä½æˆæœ¬æ–¹å·®å‡å°‘æ”¹è¿›åŸºäºä»·å€¼çš„è¿‡ç¨‹éªŒè¯å™¨</h2>
<p><strong>Authors</strong>: [Zetian Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zetian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zetian</a> Sun), [Dongfang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongfang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongfang</a> Li), [Baotian Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baotian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baotian</a> Hu), [Min Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Min"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Min</a> Zhang)
ä½œè€…ï¼šå­™æ³½å¤©ã€æä¸œæ–¹ã€èƒ¡ä¿å¤©ã€å¼ æ•</p>
<p>Large language models (LLMs) have achieved remarkable success in a wide range of tasks. However, their reasoning capabilities, particularly in complex domains like mathematics, remain a significant challenge. Value-based process verifiers, which estimate the probability of a partial reasoning chain leading to a correct solution, are a promising approach for improving reasoning. Nevertheless, their effectiveness is often hindered by estimation error in their training annotations, a consequence of the limited number of Monte Carlo (MC) samples feasible due to the high cost of LLM inference. In this paper, we identify that the estimation error primarily arises from high variance rather than bias, and the MC estimator is a Minimum Variance Unbiased Estimator (MVUE). To address the problem, we propose the \textsc{Com}pound \textsc{M}onte \textsc{C}arlo \textsc{S}ampling (ComMCS) method, which constructs an unbiased estimator by linearly combining the MC estimators from the current and subsequent steps. Theoretically, we show that our method leads to a predictable reduction in variance, while maintaining an unbiased estimation without additional LLM inference cost. We also perform empirical experiments on the MATH-500 and GSM8K benchmarks to demonstrate the effectiveness of our method. Notably, ComMCS outperforms regression-based optimization method by 2.8 points, the non-variance-reduced baseline by 2.2 points on MATH-500 on Best-of-32 sampling experiment.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¹¿æ³›ä»»åŠ¡ä¸­å–å¾—äº†æ˜¾è‘—æˆåŠŸã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„æ¨ç†èƒ½åŠ›ï¼Œå°¤å…¶æ˜¯åœ¨æ•°å­¦ç­‰å¤æ‚é¢†åŸŸï¼Œä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚åŸºäºä»·å€¼çš„è¿‡ç¨‹éªŒè¯å™¨é€šè¿‡ä¼°è®¡éƒ¨åˆ†æ¨ç†é“¾å¯¼è‡´æ­£ç¡®è§£çš„æ¦‚ç‡ï¼Œæ˜¯æ”¹è¿›æ¨ç†çš„ä¸€ç§æœ‰å‰æ™¯çš„æ–¹æ³•ã€‚ç„¶è€Œï¼Œç”±äº LLM æ¨ç†æˆæœ¬é«˜æ˜‚ï¼Œå¯è¡Œçš„è’™ç‰¹å¡æ´›ï¼ˆMCï¼‰æ ·æœ¬æ•°é‡æœ‰é™ï¼Œè¿™å¯¼è‡´è®­ç»ƒæ³¨é‡Šä¸­çš„ä¼°è®¡è¯¯å·®ï¼Œä»è€Œå¸¸å¸¸é˜»ç¢äº†å®ƒä»¬çš„æœ‰æ•ˆæ€§ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æŒ‡å‡ºä¼°è®¡è¯¯å·®ä¸»è¦æºäºé«˜æ–¹å·®è€Œéåå·®ï¼Œå¹¶ä¸” MC ä¼°è®¡é‡æ˜¯æœ€å°æ–¹å·®æ— åä¼°è®¡é‡ï¼ˆMVUEï¼‰ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤åˆè’™ç‰¹å¡æ´›é‡‡æ ·ï¼ˆComMCSï¼‰æ–¹æ³•ï¼Œè¯¥æ–¹æ³•é€šè¿‡çº¿æ€§ç»„åˆå½“å‰åŠåç»­æ­¥éª¤çš„ MC ä¼°è®¡é‡æ¥æ„å»ºæ— åä¼°è®¡é‡ã€‚åœ¨ç†è®ºä¸Šï¼Œæˆ‘ä»¬è¯æ˜äº†è¯¥æ–¹æ³•åœ¨ä¸å¢åŠ é¢å¤– LLM æ¨ç†æˆæœ¬çš„æƒ…å†µä¸‹ï¼Œèƒ½å¤Ÿå¸¦æ¥å¯é¢„æµ‹çš„æ–¹å·®é™ä½ï¼ŒåŒæ—¶ä¿æŒæ— åä¼°è®¡ã€‚ æˆ‘ä»¬è¿˜åœ¨ MATH-500 å’Œ GSM8K åŸºå‡†ä¸Šè¿›è¡Œäº†å®è¯å®éªŒï¼Œä»¥è¯æ˜æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ Best-of-32 é‡‡æ ·å®éªŒä¸­ï¼ŒComMCS åœ¨ MATH-500 ä¸Šæ¯”åŸºäºå›å½’çš„ä¼˜åŒ–æ–¹æ³•é«˜å‡º 2.8 ä¸ªç‚¹ï¼Œæ¯”æœªè¿›è¡Œæ–¹å·®å‡å°‘çš„åŸºçº¿é«˜å‡º 2.2 ä¸ªç‚¹ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 11:22:29 UTC
å‘å¸ƒï¼š2025-08-14 11:22:29 UTC</p>
<h2 id="10-diversity-first-quality-later-a-two-stage-assumption-for-language-model-alignment--10-å¤šæ ·æ€§ä¼˜å…ˆè´¨é‡éšåä¸€ç§ç”¨äºè¯­è¨€æ¨¡å‹å¯¹é½çš„ä¸¤é˜¶æ®µå‡è®¾"><a href="https://arxiv.org/abs/2508.10530"target="_blank" rel="external nofollow noopener noreferrer">#10</a> <a href="https://papers.cool/arxiv/2508.10530"target="_blank" rel="external nofollow noopener noreferrer">Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment</a>  #10 å¤šæ ·æ€§ä¼˜å…ˆï¼Œè´¨é‡éšåï¼šä¸€ç§ç”¨äºè¯­è¨€æ¨¡å‹å¯¹é½çš„ä¸¤é˜¶æ®µå‡è®¾</h2>
<p><strong>Authors</strong>: [Zetian Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zetian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zetian</a> Sun), [Dongfang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongfang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongfang</a> Li), [Baotian Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baotian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baotian</a> Hu)
ä½œè€…ï¼šå­™æ³½å¤©ï¼Œæä¸œèŠ³ï¼Œèƒ¡å®å¤©</p>
<p>The alignment of language models (LMs) with human preferences is critical for building reliable AI systems. The problem is typically framed as optimizing an LM policy to maximize the expected reward that reflects human preferences. Recently, Direct Preference Optimization (DPO) was proposed as a LM alignment method that directly optimize the policy from static preference data, and further improved by incorporating on-policy sampling (i.e., preference candidates generated during the training loop) for better LM alignment. However, we show on-policy data is not always optimal, with systematic effectiveness difference emerging between static and on-policy preference candidates. For example, on-policy data can result in a 3Ã— effectiveness compared with static data for Llama-3, and a 0.4Ã— effectiveness for Zephyr. To explain the phenomenon, we propose the alignment stage assumption, which divides the alignment process into two distinct stages: the preference injection stage, which benefits from diverse data, and the preference fine-tuning stage, which favors high-quality data. Through theoretical and empirical analysis, we characterize these stages and propose an effective algorithm to identify the boundaries between them. We perform experiments on 5 models (Llama, Zephyr, Phi-2, Qwen, Pythia) and 2 alignment methods (DPO, SLiC-HF) to show the generalizability of alignment stage assumption and boundary measurement.
å°†è¯­è¨€æ¨¡å‹ï¼ˆLMï¼‰ä¸äººç±»åå¥½å¯¹é½å¯¹äºæ„å»ºå¯é çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè‡³å…³é‡è¦ã€‚é€šå¸¸å°†è¯¥é—®é¢˜è¡¨è¿°ä¸ºä¼˜åŒ–ä¸€ä¸ªè¯­è¨€æ¨¡å‹ç­–ç•¥ï¼Œä»¥æœ€å¤§åŒ–åæ˜ äººç±»åå¥½çš„æœŸæœ›å¥–åŠ±ã€‚æœ€è¿‘ï¼Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰è¢«æå‡ºä½œä¸ºä¸€ç§ä»é™æ€åå¥½æ•°æ®ç›´æ¥ä¼˜åŒ–ç­–ç•¥çš„è¯­è¨€æ¨¡å‹å¯¹é½æ–¹æ³•ï¼Œå¹¶é€šè¿‡å¼•å…¥åœ¨çº¿é‡‡æ ·ï¼ˆå³åœ¨è®­ç»ƒå¾ªç¯ä¸­ç”Ÿæˆçš„åå¥½å€™é€‰ï¼‰æ¥è¿›ä¸€æ­¥æ”¹è¿›ï¼Œä»¥å®ç°æ›´å¥½çš„è¯­è¨€æ¨¡å‹å¯¹é½ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬çš„ç ”ç©¶è¡¨æ˜åœ¨çº¿æ•°æ®å¹¶éæ€»æ˜¯æœ€ä¼˜çš„ï¼Œé™æ€ä¸åœ¨çº¿åå¥½å€™é€‰ä¹‹é—´å‡ºç°äº†ç³»ç»Ÿæ€§çš„æ•ˆæœå·®å¼‚ã€‚ä¾‹å¦‚ï¼Œå¯¹äº Llama-3ï¼Œåœ¨çº¿æ•°æ®ç›¸æ¯”é™æ€æ•°æ®å¯èƒ½å¯¼è‡´ 3 Ã— çš„æ•ˆæœå·®è·ï¼Œè€Œå¯¹äº Zephyr åˆ™ä¸º 0.4 Ã— çš„æ•ˆæœå·®è·ã€‚ä¸ºè§£é‡Šè¿™ä¸€ç°è±¡ï¼Œæˆ‘ä»¬æå‡ºäº†å¯¹é½é˜¶æ®µå‡è®¾ï¼Œè¯¥å‡è®¾å°†å¯¹é½è¿‡ç¨‹åˆ’åˆ†ä¸ºä¸¤ä¸ªä¸åŒçš„é˜¶æ®µï¼šåå¥½æ³¨å…¥é˜¶æ®µï¼Œè¯¥é˜¶æ®µä»å¤šæ ·åŒ–æ•°æ®ä¸­å—ç›Šï¼›ä»¥åŠåå¥½å¾®è°ƒé˜¶æ®µï¼Œè¯¥é˜¶æ®µæ›´åå¥½é«˜è´¨é‡æ•°æ®ã€‚ é€šè¿‡ç†è®ºå’Œå®è¯åˆ†æï¼Œæˆ‘ä»¬åˆ»ç”»äº†è¿™äº›é˜¶æ®µå¹¶æå‡ºäº†ä¸€ç§æœ‰æ•ˆç®—æ³•æ¥è¯†åˆ«å®ƒä»¬ä¹‹é—´çš„è¾¹ç•Œã€‚æˆ‘ä»¬åœ¨ 5 ä¸ªæ¨¡å‹ï¼ˆLlamaã€Zephyrã€Phi-2ã€Qwenã€Pythiaï¼‰å’Œ 2 ç§å¯¹é½æ–¹æ³•ï¼ˆDPOã€SLiC-HFï¼‰ä¸Šè¿›è¡Œäº†å®éªŒï¼Œä»¥å±•ç¤ºå¯¹é½é˜¶æ®µå‡è®¾å’Œè¾¹ç•Œæµ‹é‡çš„æ™®é€‚æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 11:05:18 UTC
å‘å¸ƒï¼š2025-08-14 11:05:18 UTC</p>
<h2 id="11-pass-probabilistic-agentic-supernet-sampling-for-interpretable-and-adaptive-chest-x-ray-reasoning--11-é€šè¿‡æ¦‚ç‡åŒ–èƒ½åŠ¨è¶…ç½‘ç»œé‡‡æ ·å®ç°å¯è§£é‡Šä¸”è‡ªé€‚åº”çš„èƒ¸ç‰‡æ¨ç†"><a href="https://arxiv.org/abs/2508.10501"target="_blank" rel="external nofollow noopener noreferrer">#11</a> <a href="https://papers.cool/arxiv/2508.10501"target="_blank" rel="external nofollow noopener noreferrer">PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning</a>  #11 é€šè¿‡æ¦‚ç‡åŒ–èƒ½åŠ¨è¶…ç½‘ç»œé‡‡æ ·å®ç°å¯è§£é‡Šä¸”è‡ªé€‚åº”çš„èƒ¸ç‰‡æ¨ç†</h2>
<p><strong>Authors</strong>: [Yushi Feng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yushi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yushi</a> Feng), [Junye Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junye</a> Du), [Yingying Hong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yingying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yingying</a> Hong), [Qifan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qifan</a> Wang), [Lequan Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lequan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lequan</a> Yu)
ä½œè€…ï¼šå†¯å®‡è¯—ã€æœä¿Šçƒ¨ã€æ´ªèºèºã€ç‹å¯å¸†ã€äºä¹å…¨</p>
<p>Existing tool-augmented agentic systems are limited in the real world by (i) black-box reasoning steps that undermine trust of decision-making and pose safety risks, (ii) poor multimodal integration, which is inherently critical for healthcare tasks, and (iii) rigid and computationally inefficient agentic pipelines. We introduce PASS (Probabilistic Agentic Supernet Sampling), the first multimodal framework to address these challenges in the context of Chest X-Ray (CXR) reasoning. PASS adaptively samples agentic workflows over a multi-tool graph, yielding decision paths annotated with interpretable probabilities. Given the complex CXR reasoning task with multimodal medical data, PASS leverages its learned task-conditioned distribution over the agentic supernet. Thus, it adaptively selects the most suitable tool at each supernet layer, offering probability-annotated trajectories for post-hoc audits and directly enhancing medical AI safety. PASS also continuously compresses salient findings into an evolving personalized memory, while dynamically deciding whether to deepen its reasoning path or invoke an early exit for efficiency. To optimize a Pareto frontier balancing performance and cost, we design a novel three-stage training procedure, including expert knowledge warm-up, contrastive path-ranking, and cost-aware reinforcement learning. To facilitate rigorous evaluation, we introduce CAB-E, a comprehensive benchmark for multi-step, safety-critical, free-form CXR reasoning. Experiments across various benchmarks validate that PASS significantly outperforms strong baselines in multiple metrics (e.g., accuracy, AUC, LLM-J.) while balancing computational costs, pushing a new paradigm shift towards interpretable, adaptive, and multimodal medical agentic systems.
ç°æœ‰çš„å·¥å…·å¢å¼ºå‹ä»£ç†ç³»ç»Ÿåœ¨ç°å®ä¸–ç•Œä¸­å—é™äºï¼š(i) é»‘ç®±å¼çš„æ¨ç†æ­¥éª¤ï¼Œè¿™å‰Šå¼±äº†å†³ç­–çš„å¯ä¿¡åº¦å¹¶å¸¦æ¥å®‰å…¨é£é™©ï¼Œ(ii) è¾ƒå·®çš„å¤šæ¨¡æ€èåˆï¼Œè€Œå¤šæ¨¡æ€èåˆå¯¹åŒ»ç–—ä»»åŠ¡æœ¬è´¨ä¸Šè‡³å…³é‡è¦ï¼Œå’Œ (iii) åˆšæ€§ä¸”è®¡ç®—æ•ˆç‡ä½ä¸‹çš„ä»£ç†ç®¡é“ã€‚æˆ‘ä»¬æå‡ºäº† PASSï¼ˆæ¦‚ç‡æ€§ä»£ç†è¶…ç½‘æŠ½æ ·ï¼‰ï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªåœ¨èƒ¸ç‰‡ï¼ˆCXRï¼‰æ¨ç†èƒŒæ™¯ä¸‹è§£å†³è¿™äº›æŒ‘æˆ˜çš„å¤šæ¨¡æ€æ¡†æ¶ã€‚PASS åœ¨å¤šå·¥å…·å›¾ä¸Šè‡ªé€‚åº”åœ°æŠ½æ ·ä»£ç†å·¥ä½œæµï¼Œç”Ÿæˆå¸¦æœ‰å¯è§£é‡Šæ¦‚ç‡æ ‡æ³¨çš„å†³ç­–è·¯å¾„ã€‚é’ˆå¯¹åŒ…å«å¤šæ¨¡æ€åŒ»ç–—æ•°æ®çš„å¤æ‚ CXR æ¨ç†ä»»åŠ¡ï¼ŒPASS åˆ©ç”¨å…¶å­¦å¾—çš„ã€ä»¥ä»»åŠ¡ä¸ºæ¡ä»¶çš„ä»£ç†è¶…ç½‘åˆ†å¸ƒã€‚å› æ­¤ï¼Œå®ƒåœ¨è¶…ç½‘çš„æ¯ä¸€å±‚è‡ªé€‚åº”åœ°é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ï¼Œæä¾›ç”¨äºäº‹åå®¡è®¡çš„æ¦‚ç‡æ ‡æ³¨è½¨è¿¹ï¼Œå¹¶ç›´æ¥æå‡åŒ»ç–—äººå·¥æ™ºèƒ½çš„å®‰å…¨æ€§ã€‚PASS è¿˜å°†æ˜¾è‘—å‘ç°æŒç»­å‹ç¼©è¿›ä¸æ–­æ¼”è¿›çš„ä¸ªæ€§åŒ–è®°å¿†ï¼ŒåŒæ—¶åŠ¨æ€å†³å®šæ˜¯åŠ æ·±å…¶æ¨ç†è·¯å¾„è¿˜æ˜¯è°ƒç”¨æ—©æœŸé€€å‡ºä»¥æé«˜æ•ˆç‡ã€‚ ä¸ºäº†åœ¨æ€§èƒ½ä¸æˆæœ¬ä¹‹é—´ä¼˜åŒ–å¸•ç´¯æ‰˜å‰æ²¿ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„ä¸‰é˜¶æ®µè®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬ä¸“å®¶çŸ¥è¯†çƒ­èº«ã€å¯¹æ¯”è·¯å¾„æ’åºå’Œæˆæœ¬æ„ŸçŸ¥å¼ºåŒ–å­¦ä¹ ã€‚ä¸ºä¾¿äºä¸¥æ ¼è¯„ä¼°ï¼Œæˆ‘ä»¬å¼•å…¥äº† CAB-Eï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹å¤šæ­¥ã€å…³ä¹å®‰å…¨çš„è‡ªç”±å½¢å¼èƒ¸ç‰‡ï¼ˆCXRï¼‰æ¨ç†çš„å…¨é¢åŸºå‡†ã€‚è·¨å¤šä¸ªåŸºå‡†çš„å®éªŒéªŒè¯äº† PASS åœ¨å¤šé¡¹æŒ‡æ ‡ï¼ˆä¾‹å¦‚å‡†ç¡®ç‡ã€AUCã€LLM-Jï¼‰ä¸Šæ˜¾è‘—ä¼˜äºå¼ºåŸºçº¿ï¼ŒåŒæ—¶å…¼é¡¾è®¡ç®—æˆæœ¬ï¼Œæ¨åŠ¨äº†å¯è§£é‡Šã€å¯è‡ªé€‚åº”å’Œå¤šæ¨¡æ€åŒ»å­¦æ™ºèƒ½ä½“ç³»ç»Ÿçš„æ–°èŒƒå¼è½¬å˜ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 10:03:47 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 10:03:47 UTC</p>
<h2 id="12-reverse-physician-ai-relationship-full-process-clinical-diagnosis-driven-by-a-large-language-model--12-é¢ å€’çš„åŒ»ç”Ÿai-å…³ç³»ç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­"><a href="https://arxiv.org/abs/2508.10492"target="_blank" rel="external nofollow noopener noreferrer">#12</a> <a href="https://papers.cool/arxiv/2508.10492"target="_blank" rel="external nofollow noopener noreferrer">Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model</a>  #12 é¢ å€’çš„åŒ»ç”Ÿâ€”AI å…³ç³»ï¼šç”±å¤§å‹è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å…¨æµç¨‹ä¸´åºŠè¯Šæ–­</h2>
<p><strong>Authors</strong>: [Shicheng Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shicheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shicheng</a> Xu), [Xin Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Huang), [Zihao Wei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zihao</a> Wei), [Liang Pang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liang</a> Pang), [Huawei Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huawei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huawei</a> Shen), [Xueqi Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xueqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xueqi</a> Cheng)
ä½œè€…ï¼šè®¸ä¸–æˆã€é»„æ¬£ã€é­å­è±ªã€åºäº®ã€æ²ˆåä¸ºã€ç¨‹å­¦å¥‡</p>
<p>Full-process clinical diagnosis in the real world encompasses the entire diagnostic workflow that begins with only an ambiguous chief complaint. While artificial intelligence (AI), particularly large language models (LLMs), is transforming clinical diagnosis, its role remains largely as an assistant to physicians. This AI-assisted working pattern makes AI can only answer specific medical questions at certain parts within the diagnostic process, but lack the ability to drive the entire diagnostic process starting from an ambiguous complaint, which still relies heavily on human physicians. This gap limits AI&rsquo;s ability to fully reduce physicians&rsquo; workload and enhance diagnostic efficiency. To address this, we propose a paradigm shift that reverses the relationship between physicians and AI: repositioning AI as the primary director, with physicians serving as its assistants. So we present DxDirector-7B, an LLM endowed with advanced deep thinking capabilities, enabling it to drive the full-process diagnosis with minimal physician involvement. Furthermore, DxDirector-7B establishes a robust accountability framework for misdiagnoses, delineating responsibility between AI and human physicians. In evaluations across rare, complex, and real-world cases under full-process diagnosis setting, DxDirector-7B not only achieves significant superior diagnostic accuracy but also substantially reduces physician workload than state-of-the-art medical LLMs as well as general-purpose LLMs. Fine-grained analyses across multiple clinical departments and tasks validate its efficacy, with expert evaluations indicating its potential to serve as a viable substitute for medical specialists. These findings mark a new era where AI, traditionally a physicians&rsquo; assistant, now drives the entire diagnostic process to drastically reduce physicians&rsquo; workload, indicating an efficient and accurate diagnostic solution.
åœ¨çœŸå®ä¸–ç•Œä¸­ï¼Œå…¨æµç¨‹ä¸´åºŠè¯Šæ–­æ¶µç›–äº†ä»ä»…æœ‰æ¨¡ç³Šä¸»è¯‰å¼€å§‹çš„æ•´ä¸ªè¯Šæ–­å·¥ä½œæµã€‚å°½ç®¡äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ï¼Œç‰¹åˆ«æ˜¯ LLMsï¼Œæ­£åœ¨æ”¹å˜ä¸´åºŠè¯Šæ–­ï¼Œä½†å…¶ä½œç”¨åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä»æ˜¯ä½œä¸ºåŒ»ç”Ÿçš„åŠ©æ‰‹ã€‚è¿™ç§ AI è¾…åŠ©çš„å·¥ä½œæ¨¡å¼ä½¿å¾— AI åªèƒ½åœ¨è¯Šæ–­è¿‡ç¨‹çš„æŸäº›ç¯èŠ‚å›ç­”å…·ä½“çš„åŒ»å­¦é—®é¢˜ï¼Œè€Œç¼ºä¹ä»æ¨¡ç³Šä¸»è¯‰å‡ºå‘é©±åŠ¨æ•´ä¸ªè¯Šæ–­è¿‡ç¨‹çš„èƒ½åŠ›ï¼Œä»ç„¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äººç±»åŒ»ç”Ÿã€‚è¿™ä¸€å·®è·é™åˆ¶äº† AI åœ¨å…¨é¢å‡è½»åŒ»ç”Ÿå·¥ä½œé‡å’Œæé«˜è¯Šæ–­æ•ˆç‡æ–¹é¢çš„èƒ½åŠ›ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§èŒƒå¼è½¬å˜ï¼Œå³é¢ å€’åŒ»ç”Ÿä¸ AI ä¹‹é—´çš„å…³ç³»ï¼šå°† AI é‡æ–°å®šä½ä¸ºä¸»è¦çš„æŒ‡æŒ¥è€…ï¼ŒåŒ»ç”Ÿåˆ™ä½œä¸ºå…¶åŠ©æ‰‹ã€‚å› æ­¤æˆ‘ä»¬æå‡ºäº† DxDirector-7Bï¼Œä¸€ç§å…·å¤‡é«˜çº§æ·±åº¦æ€è€ƒèƒ½åŠ›çš„ LLMï¼Œä½¿å…¶èƒ½å¤Ÿä»¥æå°‘çš„åŒ»ç”Ÿå‚ä¸é©±åŠ¨å…¨æµç¨‹è¯Šæ–­ã€‚ æ­¤å¤–ï¼ŒDxDirector-7B å»ºç«‹äº†ä¸€ä¸ªç¨³å¥çš„è¯¯è¯Šé—®è´£æ¡†æ¶ï¼Œæ˜ç¡®åˆ’åˆ†äº† AI ä¸äººç±»åŒ»ç”Ÿä¹‹é—´çš„è´£ä»»ã€‚åœ¨å…¨æµç¨‹è¯Šæ–­è®¾ç½®ä¸‹å¯¹ç½•è§ã€å¤æ‚å’ŒçœŸå®æ¡ˆä¾‹çš„è¯„ä¼°ä¸­ï¼ŒDxDirector-7B ä¸ä»…åœ¨è¯Šæ–­å‡†ç¡®æ€§ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„åŒ»å­¦ LLMs å’Œé€šç”¨ LLMsï¼Œè€Œä¸”å¤§å¹…å‡å°‘äº†åŒ»ç”Ÿçš„å·¥ä½œé‡ã€‚è·¨å¤šä¸ªä¸´åºŠç§‘å®¤å’Œä»»åŠ¡çš„ç»†ç²’åº¦åˆ†æéªŒè¯äº†å…¶æœ‰æ•ˆæ€§ï¼Œä¸“å®¶è¯„ä¼°è¡¨æ˜å®ƒæœ‰å¯èƒ½æˆä¸ºåŒ»ç–—ä¸“ç§‘åŒ»ç”Ÿçš„å¯è¡Œæ›¿ä»£æ–¹æ¡ˆã€‚è¿™äº›å‘ç°æ ‡å¿—ç€ä¸€ä¸ªæ–°æ—¶ä»£ï¼šAI ä»ä¼ ç»Ÿä¸Šä½œä¸ºåŒ»ç”Ÿçš„åŠ©æ‰‹ï¼Œå‘å±•ä¸ºé©±åŠ¨æ•´ä¸ªè¯Šæ–­æµç¨‹ï¼Œä»è€Œå¤§å¹…å‡è½»åŒ»ç”Ÿå·¥ä½œè´Ÿæ‹…ï¼Œæä¾›ä¸€ç§é«˜æ•ˆä¸”å‡†ç¡®çš„è¯Šæ–­è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CE"target="_blank" rel="external nofollow noopener noreferrer">Computational Engineering, Finance, and Science</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ã€è®¡ç®—å·¥ç¨‹ã€é‡‘èä¸ç§‘å­¦ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 09:51:20 UTC
å‘å¸ƒï¼š2025-08-14 09:51:20 UTC</p>
<h2 id="13-seq-gpt-llm-assisted-spatial-query-via-example--13-seq-gpté€šè¿‡ç¤ºä¾‹çš„-llm-è¾…åŠ©ç©ºé—´æŸ¥è¯¢"><a href="https://arxiv.org/abs/2508.10486"target="_blank" rel="external nofollow noopener noreferrer">#13</a> <a href="https://papers.cool/arxiv/2508.10486"target="_blank" rel="external nofollow noopener noreferrer">SEQ-GPT: LLM-assisted Spatial Query via Example</a>  #13 SEQ-GPTï¼šé€šè¿‡ç¤ºä¾‹çš„ LLM è¾…åŠ©ç©ºé—´æŸ¥è¯¢</h2>
<p><strong>Authors</strong>: [Ivan Khai Ze Lim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivan</a> Khai Ze Lim), [Ningyi Liao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ningyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ningyi</a> Liao), [Yiming Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiming</a> Yang), [Gerald Wei Yong Yip](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gerald"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gerald</a> Wei Yong Yip), [Siqiang Luo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Siqiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Siqiang</a> Luo)
ä½œè€…ï¼šIvan Khai Ze Limã€Ningyi Liaoã€Yiming Yangã€Gerald Wei Yong Yipã€Siqiang Luo</p>
<p>Contemporary spatial services such as online maps predominantly rely on user queries for location searches. However, the user experience is limited when performing complex tasks, such as searching for a group of locations simultaneously. In this study, we examine the extended scenario known as Spatial Exemplar Query (SEQ), where multiple relevant locations are jointly searched based on user-specified examples. We introduce SEQ-GPT, a spatial query system powered by Large Language Models (LLMs) towards more versatile SEQ search using natural language. The language capabilities of LLMs enable unique interactive operations in the SEQ process, including asking users to clarify query details and dynamically adjusting the search based on user feedback. We also propose a tailored LLM adaptation pipeline that aligns natural language with structured spatial data and queries through dialogue synthesis and multi-model cooperation. SEQ-GPT offers an end-to-end demonstration for broadening spatial search with realistic data and application scenarios.
å½“ä»£çš„ç©ºé—´æœåŠ¡ï¼ˆä¾‹å¦‚åœ¨çº¿åœ°å›¾ï¼‰ä¸»è¦ä¾èµ–ç”¨æˆ·æŸ¥è¯¢æ¥è¿›è¡Œä½ç½®æœç´¢ã€‚ç„¶è€Œï¼Œåœ¨æ‰§è¡Œå¤æ‚ä»»åŠ¡æ—¶ï¼Œç”¨æˆ·ä½“éªŒå—é™ï¼Œä¾‹å¦‚åŒæ—¶æœç´¢ä¸€ç»„ä½ç½®ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬è€ƒå¯Ÿäº†ä¸€ç§è¢«ç§°ä¸ºç©ºé—´ç¤ºä¾‹æŸ¥è¯¢ï¼ˆSpatial Exemplar Queryï¼ŒSEQï¼‰çš„æ‰©å±•åœºæ™¯ï¼Œå…¶ä¸­åŸºäºç”¨æˆ·æŒ‡å®šçš„ç¤ºä¾‹ï¼Œè”åˆæœç´¢å¤šä¸ªç›¸å…³ä½ç½®ã€‚æˆ‘ä»¬æå‡ºäº† SEQ-GPTï¼Œä¸€ç§ç”± LLMs é©±åŠ¨çš„ç©ºé—´æŸ¥è¯¢ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡è‡ªç„¶è¯­è¨€å®ç°æ›´çµæ´»çš„ SEQ æœç´¢ã€‚LLMs çš„è¯­è¨€èƒ½åŠ›ä½¿å¾— SEQ è¿‡ç¨‹ä¸­å‡ºç°äº†ç‹¬ç‰¹çš„äº¤äº’æ“ä½œï¼ŒåŒ…æ‹¬å‘ç”¨æˆ·è¯¢é—®ä»¥æ¾„æ¸…æŸ¥è¯¢ç»†èŠ‚ä»¥åŠæ ¹æ®ç”¨æˆ·åé¦ˆåŠ¨æ€è°ƒæ•´æœç´¢ã€‚æˆ‘ä»¬è¿˜æå‡ºäº†ä¸€æ¡å®šåˆ¶çš„ LLM é€‚é…æµç¨‹ï¼Œé€šè¿‡å¯¹è¯åˆæˆå’Œå¤šæ¨¡å‹åä½œï¼Œå°†è‡ªç„¶è¯­è¨€ä¸ç»“æ„åŒ–ç©ºé—´æ•°æ®å’ŒæŸ¥è¯¢å¯¹é½ã€‚SEQ-GPT æä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„æ¼”ç¤ºï¼Œä»¥çœŸå®æ•°æ®å’Œåº”ç”¨åœºæ™¯æ‹“å±•ç©ºé—´æœç´¢ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 09:41:55 UTC
å‘å¸ƒï¼š2025-08-14 09:41:55 UTC</p>
<h2 id="14-firesparql-a-llm-based-framework-for-sparql-query-generation-over-scholarly-knowledge-graphs--14-firesparqlä¸€ç§åŸºäº-llm-çš„åœ¨å­¦æœ¯çŸ¥è¯†å›¾è°±ä¸Šç”Ÿæˆ-sparql-æŸ¥è¯¢çš„æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10467"target="_blank" rel="external nofollow noopener noreferrer">#14</a> <a href="https://papers.cool/arxiv/2508.10467"target="_blank" rel="external nofollow noopener noreferrer">FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs</a>  #14 FIRESPARQLï¼šä¸€ç§åŸºäº LLM çš„åœ¨å­¦æœ¯çŸ¥è¯†å›¾è°±ä¸Šç”Ÿæˆ SPARQL æŸ¥è¯¢çš„æ¡†æ¶</h2>
<p><strong>Authors</strong>: [Xueli Pan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xueli"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xueli</a> Pan), [Victor de Boer](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Victor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Victor</a> de Boer), [Jacco van Ossenbruggen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jacco"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jacco</a> van Ossenbruggen)
ä½œè€…ï¼šæ½˜é›ªä¸½ã€Victor de Boerã€Jacco van Ossenbruggen</p>
<p>Question answering over Scholarly Knowledge Graphs (SKGs) remains a challenging task due to the complexity of scholarly content and the intricate structure of these graphs. Large Language Model (LLM) approaches could be used to translate natural language questions (NLQs) into SPARQL queries; however, these LLM-based approaches struggle with SPARQL query generation due to limited exposure to SKG-specific content and the underlying schema. We identified two main types of errors in the LLM-generated SPARQL queries: (i) structural inconsistencies, such as missing or redundant triples in the queries, and (ii) semantic inaccuracies, where incorrect entities or properties are shown in the queries despite a correct query structure. To address these issues, we propose FIRESPARQL, a modular framework that supports fine-tuned LLMs as a core component, with optional context provided via retrieval-augmented generation (RAG) and a SPARQL query correction layer. We evaluate the framework on the SciQA Benchmark using various configurations (zero-shot, zero-shot with RAG, one-shot, fine-tuning, and fine-tuning with RAG) and compare the performance with baseline and state-of-the-art approaches. We measure query accuracy using BLEU and ROUGE metrics, and query result accuracy using relaxed exact match(RelaxedEM), with respect to the gold standards containing the NLQs, SPARQL queries, and the results of the queries. Experimental results demonstrate that fine-tuning achieves the highest overall performance, reaching 0.90 ROUGE-L for query accuracy and 0.85 RelaxedEM for result accuracy on the test set.
å¯¹å­¦æœ¯çŸ¥è¯†å›¾è°±ï¼ˆSKGsï¼‰è¿›è¡Œé—®ç­”ä»ç„¶æ˜¯ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼ŒåŸå› åœ¨äºå­¦æœ¯å†…å®¹çš„å¤æ‚æ€§å’Œè¿™äº›å›¾è°±çš„å¤æ‚ç»“æ„ã€‚å¯ä»¥ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ–¹æ³•å°†è‡ªç„¶è¯­è¨€é—®é¢˜ï¼ˆNLQsï¼‰ç¿»è¯‘ä¸º SPARQL æŸ¥è¯¢ï¼›ç„¶è€Œï¼Œè¿™äº›åŸºäº LLM çš„æ–¹æ³•åœ¨ç”Ÿæˆ SPARQL æŸ¥è¯¢æ—¶è¡¨ç°ä¸ä½³ï¼ŒåŸå› æ˜¯å®ƒä»¬å¯¹ SKG ç‰¹å®šå†…å®¹å’Œåº•å±‚æ¨¡å¼çš„æ¥è§¦æœ‰é™ã€‚æˆ‘ä»¬åœ¨ LLM ç”Ÿæˆçš„ SPARQL æŸ¥è¯¢ä¸­è¯†åˆ«å‡ºä¸¤ç±»ä¸»è¦é”™è¯¯ï¼šï¼ˆiï¼‰ç»“æ„ä¸ä¸€è‡´ï¼Œä¾‹å¦‚æŸ¥è¯¢ä¸­ç¼ºå¤±æˆ–å†—ä½™çš„ä¸‰å…ƒç»„ï¼›ï¼ˆiiï¼‰è¯­ä¹‰ä¸å‡†ç¡®ï¼Œå°½ç®¡æŸ¥è¯¢ç»“æ„æ­£ç¡®ï¼Œä½†æŸ¥è¯¢ä¸­å‡ºç°äº†é”™è¯¯çš„å®ä½“æˆ–å±æ€§ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† FIRESPARQLï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œæ”¯æŒç»è¿‡å¾®è°ƒçš„ LLM ä½œä¸ºæ ¸å¿ƒç»„ä»¶ï¼Œå¹¶å¯é€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æä¾›å¯é€‰ä¸Šä¸‹æ–‡ï¼Œä»¥åŠä¸€ä¸ª SPARQL æŸ¥è¯¢çº æ­£å±‚ã€‚æˆ‘ä»¬åœ¨ SciQA åŸºå‡†ä¸Šä½¿ç”¨å¤šç§é…ç½®ï¼ˆé›¶æ ·æœ¬ã€å¸¦ RAG çš„é›¶æ ·æœ¬ã€ä¸€æ¬¡ç¤ºä¾‹ã€å¾®è°ƒã€ä»¥åŠå¸¦ RAG çš„å¾®è°ƒï¼‰è¯„ä¼°è¯¥æ¡†æ¶ï¼Œå¹¶å°†å…¶æ€§èƒ½ä¸åŸºçº¿å’Œæœ€å…ˆè¿›çš„æ–¹æ³•è¿›è¡Œæ¯”è¾ƒã€‚ æˆ‘ä»¬ä½¿ç”¨ BLEU å’Œ ROUGE æŒ‡æ ‡è¡¡é‡æŸ¥è¯¢å‡†ç¡®æ€§ï¼Œå¹¶ä½¿ç”¨å®½æ¾ç²¾ç¡®åŒ¹é…ï¼ˆRelaxedEMï¼‰è¡¡é‡æŸ¥è¯¢ç»“æœå‡†ç¡®æ€§ï¼Œå‚ç…§åŒ…å«è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼ˆNLQsï¼‰ã€SPARQL æŸ¥è¯¢åŠå…¶æŸ¥è¯¢ç»“æœçš„é‡‘æ ‡å‡†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå¾®è°ƒè¾¾åˆ°æœ€é«˜çš„æ•´ä½“æ€§èƒ½ï¼Œåœ¨æµ‹è¯•é›†ä¸ŠæŸ¥è¯¢å‡†ç¡®æ€§è¾¾åˆ° 0.90 ROUGE-Lï¼Œç»“æœå‡†ç¡®æ€§è¾¾åˆ° 0.85 RelaxedEMã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.DL"target="_blank" rel="external nofollow noopener noreferrer">Digital Libraries</a></p>
<p><strong>Publish</strong>: 2025-08-14 09:08:50 UTC</p>
<h2 id="15-we-math-20-a-versatile-mathbook-system-for-incentivizing-visual-mathematical-reasoning"><a href="https://arxiv.org/abs/2508.10433"target="_blank" rel="external nofollow noopener noreferrer">#15</a> <a href="https://papers.cool/arxiv/2508.10433"target="_blank" rel="external nofollow noopener noreferrer">We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning</a></h2>
<p><strong>Authors</strong>: [Runqi Qiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Runqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Runqi</a> Qiao), [Qiuna Tan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiuna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiuna</a> Tan), [Peiqing Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peiqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peiqing</a> Yang), [Yanzi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanzi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanzi</a> Wang), [Xiaowan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaowan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaowan</a> Wang), [Enhui Wan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Enhui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Enhui</a> Wan), [Sitong Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sitong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sitong</a> Zhou), [Guanting Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guanting"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guanting</a> Dong), [Yuchen Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Zeng), [Yida Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yida"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yida</a> Xu), [Jie Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jie</a> Wang), [Chong Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chong</a> Sun), [Chen Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chen</a> Li), [Honggang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Honggang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Honggang</a> Zhang)
ä½œè€…ï¼šä¹”æ¶¦æ£‹ï¼Œè°­ç§‹å¨œï¼Œæ¨åŸ¹åº†ï¼Œç‹ç‡•å§¿ï¼Œç‹æ™“å©‰ï¼Œä¸‡æ©è¾‰ï¼Œå‘¨æ€å½¤ï¼Œè‘£å† å»·ï¼Œæ›¾å®‡æ™¨ï¼Œè®¸ä¸€è¾¾ï¼Œç‹æ°ï¼Œå­™å´‡ï¼Œææ™¨ï¼Œå¼ å®å²—</p>
<p>Multimodal Large Language Models (MLLMs) have demonstrated impressive capabilities across various tasks, but still struggle with complex mathematical reasoning. Existing research primarily focuses on dataset construction and method optimization, often overlooking two critical aspects: comprehensive knowledge-driven design and model-centric data space modeling. In this paper, we introduce We-Math 2.0, a unified system that integrates a structured mathematical knowledge system, model-centric data space modeling, and a reinforcement learning (RL)-based training paradigm to comprehensively enhance the mathematical reasoning abilities of MLLMs. The key contributions of We-Math 2.0 are fourfold: (1) MathBook Knowledge System: We construct a five-level hierarchical system encompassing 491 knowledge points and 1,819 fundamental principles. (2) MathBook-Standard &amp; Pro: We develop MathBook-Standard, a dataset that ensures broad conceptual coverage and flexibility through dual expansion. Additionally, we define a three-dimensional difficulty space and generate 7 progressive variants per problem to build MathBook-Pro, a challenging dataset for robust training. (3) MathBook-RL: We propose a two-stage RL framework comprising: (i) Cold-Start Fine-tuning, which aligns the model with knowledge-oriented chain-of-thought reasoning; and (ii) Progressive Alignment RL, leveraging average-reward learning and dynamic data scheduling to achieve progressive alignment across difficulty levels. (4) MathBookEval: We introduce a comprehensive benchmark covering all 491 knowledge points with diverse reasoning step distributions. Experimental results show that MathBook-RL performs competitively with existing baselines on four widely-used benchmarks and achieves strong results on MathBookEval, suggesting promising generalization in mathematical reasoning.
å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å„ç±»ä»»åŠ¡ä¸Šå±•ç°äº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œä½†åœ¨å¤æ‚æ•°å­¦æ¨ç†æ–¹é¢ä»å­˜åœ¨å›°éš¾ã€‚ç°æœ‰ç ”ç©¶ä¸»è¦é›†ä¸­äºæ•°æ®é›†æ„å»ºå’Œæ–¹æ³•ä¼˜åŒ–ï¼Œå¸¸å¸¸å¿½è§†ä¸¤ä¸ªå…³é”®æ–¹é¢ï¼šåŸºäºå…¨é¢çŸ¥è¯†çš„è®¾è®¡å’Œä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ•°æ®ç©ºé—´å»ºæ¨¡ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† We-Math 2.0ï¼Œè¿™æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„ç³»ç»Ÿï¼Œé›†æˆäº†ç»“æ„åŒ–çš„æ•°å­¦çŸ¥è¯†ä½“ç³»ã€ä»¥æ¨¡å‹ä¸ºä¸­å¿ƒçš„æ•°æ®ç©ºé—´å»ºæ¨¡ä»¥åŠåŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰çš„è®­ç»ƒèŒƒå¼ï¼Œä»¥å…¨é¢æå‡ MLLMs çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚We-Math 2.0 çš„ä¸»è¦è´¡çŒ®æœ‰å››ç‚¹ï¼š (1) MathBook çŸ¥è¯†ä½“ç³»ï¼šæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªäº”å±‚çº§çš„å±‚æ¬¡ä½“ç³»ï¼Œæ¶µç›– 491 ä¸ªçŸ¥è¯†ç‚¹å’Œ 1,819 æ¡åŸºæœ¬åŸç†ã€‚ (2) MathBook-Standard ä¸ Proï¼šæˆ‘ä»¬å¼€å‘äº† MathBook-Standard æ•°æ®é›†ï¼Œé€šè¿‡åŒé‡æ‰©å±•ç¡®ä¿å¹¿æ³›çš„æ¦‚å¿µè¦†ç›–å’Œçµæ´»æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªä¸‰ç»´éš¾åº¦ç©ºé—´ï¼Œå¹¶ä¸ºæ¯ä¸ªé—®é¢˜ç”Ÿæˆ 7 ä¸ªé€’è¿›å˜ä½“ï¼Œä»¥æ„å»º MathBook-Proï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç¨³å¥è®­ç»ƒçš„æŒ‘æˆ˜æ€§æ•°æ®é›†ã€‚ (3) MathBook-RLï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç”±ä¸¤é˜¶æ®µå¼ºåŒ–å­¦ä¹ ç»„æˆçš„æ¡†æ¶ï¼ŒåŒ…æ‹¬ï¼šï¼ˆiï¼‰å†·å¯åŠ¨å¾®è°ƒï¼Œç”¨ä»¥ä½¿æ¨¡å‹ä¸é¢å‘çŸ¥è¯†çš„é“¾å¼æ€ç»´æ¨ç†ä¿æŒä¸€è‡´ï¼›ä»¥åŠï¼ˆiiï¼‰æ¸è¿›å¯¹é½å¼ºåŒ–å­¦ä¹ ï¼Œåˆ©ç”¨å¹³å‡å›æŠ¥å­¦ä¹ å’ŒåŠ¨æ€æ•°æ®è°ƒåº¦æ¥å®ç°è·¨éš¾åº¦ç­‰çº§çš„æ¸è¿›å¯¹é½ã€‚ï¼ˆ4ï¼‰MathBookEvalï¼šæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªè¦†ç›–æ‰€æœ‰ 491 ä¸ªçŸ¥è¯†ç‚¹ã€å…·æœ‰å¤šæ ·åŒ–æ¨ç†æ­¥é•¿åˆ†å¸ƒçš„ç»¼åˆåŸºå‡†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMathBook-RL åœ¨å››ä¸ªå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†æµ‹è¯•ä¸Šä¸ç°æœ‰åŸºçº¿è¡¨ç°ç›¸å½“ï¼Œå¹¶åœ¨ MathBookEval ä¸Šå–å¾—äº†å¾ˆå¥½çš„ç»“æœï¼Œè¡¨æ˜å…¶åœ¨æ•°å­¦æ¨ç†æ–¹é¢å…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ½œåŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œè®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 08:15:41 UTC
å‘å¸ƒï¼š2025-08-14 08:15:41 UTC</p>
<h2 id="16-mm-food-100k-a-100000-sample-multimodal-food-intelligence-dataset-with-verifiable-provenance--16-mm-food-100kä¸€ä¸ªå…·æœ‰å¯éªŒè¯æ¥æºçš„-100000-æ ·æœ¬å¤šæ¨¡æ€é£Ÿå“æ™ºèƒ½æ•°æ®é›†"><a href="https://arxiv.org/abs/2508.10429"target="_blank" rel="external nofollow noopener noreferrer">#16</a> <a href="https://papers.cool/arxiv/2508.10429"target="_blank" rel="external nofollow noopener noreferrer">MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance</a>  #16 MM-Food-100Kï¼šä¸€ä¸ªå…·æœ‰å¯éªŒè¯æ¥æºçš„ 100,000 æ ·æœ¬å¤šæ¨¡æ€é£Ÿå“æ™ºèƒ½æ•°æ®é›†</h2>
<p><strong>Authors</strong>: [Yi Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi</a> Dong), [Yusuke Muraoka](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yusuke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yusuke</a> Muraoka), [Scott Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Scott"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Scott</a> Shi), [Yi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yi</a> Zhang)
ä½œè€…ï¼šè‘£æ¯…ï¼Œæ‘å²¡é›„ä»‹ï¼ŒScott Shiï¼Œå¼ æ¯…</p>
<p>We present MM-Food-100K, a public 100,000-sample multimodal food intelligence dataset with verifiable provenance. It is a curated approximately 10% open subset of an original 1.2 million, quality-accepted corpus of food images annotated for a wide range of information (such as dish name, region of creation). The corpus was collected over six weeks from over 87,000 contributors using the Codatta contribution model, which combines community sourcing with configurable AI-assisted quality checks; each submission is linked to a wallet address in a secure off-chain ledger for traceability, with a full on-chain protocol on the roadmap. We describe the schema, pipeline, and QA, and validate utility by fine-tuning large vision-language models (ChatGPT 5, ChatGPT OSS, Qwen-Max) on image-based nutrition prediction. Fine-tuning yields consistent gains over out-of-box baselines across standard metrics; we report results primarily on the MM-Food-100K subset. We release MM-Food-100K for publicly free access and retain approximately 90% for potential commercial access with revenue sharing to contributors.
æˆ‘ä»¬æ¨å‡ºäº† MM-Food-100Kï¼Œä¸€ä¸ªå…·æœ‰å¯éªŒè¯æ¥æºçš„ã€å…¬å¼€çš„ 100,000 æ ·æœ¬å¤šæ¨¡æ€é£Ÿç‰©æ™ºèƒ½æ•°æ®é›†ã€‚å®ƒæ˜¯åŸå§‹ 120 ä¸‡æ¡ç»è´¨é‡å®¡æ ¸çš„é£Ÿç‰©å›¾åƒè¯­æ–™çš„ç²¾å¿ƒæŒ‘é€‰çš„çº¦ 10% å¼€æ”¾å­é›†ï¼Œè¿™äº›å›¾åƒè¢«æ ‡æ³¨äº†å¹¿æ³›çš„ä¿¡æ¯ï¼ˆå¦‚èœåã€åˆ›ä½œåœ°åŒºç­‰ï¼‰ã€‚è¯¥è¯­æ–™åœ¨å…­å‘¨å†…ä»è¶…è¿‡ 87,000 åè´¡çŒ®è€…å¤„é€šè¿‡ Codatta è´¡çŒ®æ¨¡å‹æ”¶é›†ï¼ŒCodatta å°†ç¤¾åŒºä¼—åŒ…ä¸å¯é…ç½®çš„ AI è¾…åŠ©è´¨é‡æ£€æŸ¥ç›¸ç»“åˆï¼›æ¯æ¬¡æäº¤éƒ½åœ¨ä¸€ä¸ªå®‰å…¨çš„é“¾ä¸‹è´¦æœ¬ä¸­ä¸é’±åŒ…åœ°å€å…³è”ä»¥ä¾¿æº¯æºï¼Œå®Œæ•´çš„é“¾ä¸Šåè®®åœ¨è·¯çº¿å›¾ä¸Šã€‚æˆ‘ä»¬æè¿°äº†æ¨¡å¼ã€ç®¡é“å’Œè´¨ä¿æµç¨‹ï¼Œå¹¶é€šè¿‡å¯¹å¤§è§„æ¨¡è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆChatGPT 5ã€ChatGPT OSSã€Qwen-Maxï¼‰è¿›è¡ŒåŸºäºå›¾åƒçš„è¥å…»é¢„æµ‹å¾®è°ƒæ¥éªŒè¯å…¶å®ç”¨æ€§ã€‚å¾®è°ƒåœ¨æ ‡å‡†æŒ‡æ ‡ä¸Šç›¸å¯¹äºå¼€ç®±åŸºçº¿å¸¦æ¥äº†æŒç»­æå‡ï¼›æˆ‘ä»¬ä¸»è¦åœ¨ MM-Food-100K å­é›†ä¸ŠæŠ¥å‘Šç»“æœã€‚æˆ‘ä»¬å…¬å¼€å…è´¹å‘å¸ƒ MM-Food-100Kï¼Œå¹¶ä¿ç•™çº¦ 90% ä»¥ä¾›æ½œåœ¨å•†ä¸šè®¿é—®ï¼Œå¹¶ä¸è´¡çŒ®è€…å…±äº«æ”¶å…¥ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ã€å¯†ç å­¦ä¸å®‰å…¨ã€è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«</p>
<p><strong>Publish</strong>: 2025-08-14 07:59:31 UTC
å‘è¡¨ï¼š2025-08-14 07:59:31 UTC</p>
<h2 id="17-hiref-leveraging-hierarchical-ontology-and-network-refinement-for-robust-medication-recommendation--17-hirefåˆ©ç”¨åˆ†å±‚æœ¬ä½“ä¸ç½‘ç»œç²¾ç‚¼å®ç°é²æ£’çš„ç”¨è¯æ¨è"><a href="https://arxiv.org/abs/2508.10425"target="_blank" rel="external nofollow noopener noreferrer">#17</a> <a href="https://papers.cool/arxiv/2508.10425"target="_blank" rel="external nofollow noopener noreferrer">HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation</a>  #17 HiRefï¼šåˆ©ç”¨åˆ†å±‚æœ¬ä½“ä¸ç½‘ç»œç²¾ç‚¼å®ç°é²æ£’çš„ç”¨è¯æ¨è</h2>
<p><strong>Authors</strong>: [Yan Ting Chok](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yan</a> Ting Chok), [Soyon Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soyon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soyon</a> Park), [Seungheun Baek](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seungheun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seungheun</a> Baek), [Hajung Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hajung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hajung</a> Kim), [Junhyun Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junhyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junhyun</a> Lee), [Jaewoo Kang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jaewoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jaewoo</a> Kang)
ä½œè€…ï¼šYan Ting Chokã€Soyon Parkã€Seungheun Baekã€Hajung Kimã€Junhyun Leeã€Jaewoo Kang</p>
<p>Medication recommendation is a crucial task for assisting physicians in making timely decisions from longitudinal patient medical records. However, real-world EHR data present significant challenges due to the presence of rarely observed medical entities and incomplete records that may not fully capture the clinical ground truth. While data-driven models trained on longitudinal Electronic Health Records often achieve strong empirical performance, they struggle to generalize under missing or novel conditions, largely due to their reliance on observed co-occurrence patterns. To address these issues, we propose Hierarchical Ontology and Network Refinement for Robust Medication Recommendation (HiRef), a unified framework that combines two complementary structures: (i) the hierarchical semantics encoded in curated medical ontologies, and (ii) refined co-occurrence patterns derived from real-world EHRs. We embed ontology entities in hyperbolic space, which naturally captures tree-like relationships and enables knowledge transfer through shared ancestors, thereby improving generalizability to unseen codes. To further improve robustness, we introduce a prior-guided sparse regularization scheme that refines the EHR co-occurrence graph by suppressing spurious edges while preserving clinically meaningful associations. Our model achieves strong performance on EHR benchmarks (MIMIC-III and MIMIC-IV) and maintains high accuracy under simulated unseen-code settings. Extensive experiments with comprehensive ablation studies demonstrate HiRef&rsquo;s resilience to unseen medical codes, supported by in-depth analyses of the learned sparsified graph structure and medical code embeddings.
è¯ç‰©æ¨èæ˜¯å¸®åŠ©åŒ»ç”Ÿä»çºµå‘ç—…äººç—…å†ä¸­åŠæ—¶å†³ç­–çš„ä¸€é¡¹å…³é”®ä»»åŠ¡ã€‚ç„¶è€Œï¼ŒçœŸå®ä¸–ç•Œçš„ç”µå­å¥åº·è®°å½•ï¼ˆEHRï¼‰æ•°æ®å­˜åœ¨æ˜¾è‘—æŒ‘æˆ˜ï¼Œå› ä¸ºå…¶ä¸­åŒ…å«å¾ˆå°‘è§‚æµ‹åˆ°çš„åŒ»ç–—å®ä½“å’Œå¯èƒ½æ— æ³•å®Œå…¨åæ˜ ä¸´åºŠçœŸå®æƒ…å†µçš„ä¸å®Œæ•´è®°å½•ã€‚å°½ç®¡åœ¨çºµå‘ç”µå­å¥åº·è®°å½•ä¸Šè®­ç»ƒçš„æ•°æ®é©±åŠ¨æ¨¡å‹é€šå¸¸èƒ½å–å¾—è¾ƒå¼ºçš„ç»éªŒæ€§èƒ½ï¼Œä½†å®ƒä»¬åœ¨ç¼ºå¤±æˆ–æ–°é¢–æƒ…å½¢ä¸‹å¾€å¾€éš¾ä»¥æ³›åŒ–ï¼Œè¿™åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæ˜¯ç”±äºå®ƒä»¬ä¾èµ–äºè§‚æµ‹åˆ°çš„å…±ç°æ¨¡å¼ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºç¨³å¥è¯ç‰©æ¨èçš„åˆ†å±‚æœ¬ä½“ä¸ç½‘ç»œç²¾åŒ–æ–¹æ³•ï¼ˆHiRefï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç»“åˆä¸¤ç§äº’è¡¥ç»“æ„çš„ç»Ÿä¸€æ¡†æ¶ï¼šï¼ˆiï¼‰ç»äººå·¥æ•´ç†çš„åŒ»å­¦æœ¬ä½“ä¸­æ‰€ç¼–ç çš„å±‚çº§è¯­ä¹‰ï¼Œå’Œï¼ˆiiï¼‰ä»çœŸå®ä¸–ç•Œ EHR ä¸­æå–å¹¶ç²¾åŒ–çš„å…±ç°æ¨¡å¼ã€‚æˆ‘ä»¬å°†æœ¬ä½“å®ä½“åµŒå…¥åˆ°åŒæ›²ç©ºé—´ä¸­ï¼Œè¯¥ç©ºé—´è‡ªç„¶æ•æ‰æ ‘çŠ¶å…³ç³»å¹¶é€šè¿‡å…±äº«ç¥–å…ˆå®ç°çŸ¥è¯†è¿ç§»ï¼Œä»è€Œæé«˜å¯¹æœªè§ç¼–ç çš„æ³›åŒ–èƒ½åŠ›ã€‚ ä¸ºäº†è¿›ä¸€æ­¥æé«˜é²æ£’æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§å…ˆéªŒå¼•å¯¼çš„ç¨€ç–æ­£åˆ™åŒ–æ–¹æ¡ˆï¼Œé€šè¿‡æŠ‘åˆ¶ä¼ªå½±è¾¹åŒæ—¶ä¿ç•™ä¸´åºŠæœ‰æ„ä¹‰çš„å…³è”æ¥ç²¾ç‚¼ç”µå­ç—…å†å…±ç°å›¾ã€‚æˆ‘ä»¬çš„æ¨¡å‹åœ¨ç”µå­ç—…å†åŸºå‡†ï¼ˆMIMIC-III å’Œ MIMIC-IVï¼‰ä¸Šå–å¾—äº†å¼ºåŠ²çš„è¡¨ç°ï¼Œå¹¶åœ¨æ¨¡æ‹Ÿçš„æœªè§ç¼–ç æƒ…å½¢ä¸‹ä»ä¿æŒé«˜å‡†ç¡®æ€§ã€‚å¤§é‡å®éªŒå’Œå…¨é¢çš„æ¶ˆèç ”ç©¶è¡¨æ˜ï¼ŒHiRef å¯¹æœªè§åŒ»å­¦ç¼–ç å…·æœ‰éŸ§æ€§ï¼Œè¿™ä¸€ç‚¹ç”±å¯¹æ‰€å­¦ç¨€ç–åŒ–å›¾ç»“æ„å’ŒåŒ»å­¦ç¼–ç åµŒå…¥çš„æ·±å…¥åˆ†ææ‰€æ”¯æŒã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 07:55:03 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 07:55:03 UTC</p>
<h2 id="18-leanrag-knowledge-graph-based-generation-with-semantic-aggregation-and-hierarchical-retrieval--18-leanragåŸºäºçŸ¥è¯†å›¾è°±çš„ç”Ÿæˆå…·æœ‰è¯­ä¹‰èšåˆä¸åˆ†å±‚æ£€ç´¢"><a href="https://arxiv.org/abs/2508.10391"target="_blank" rel="external nofollow noopener noreferrer">#18</a> <a href="https://papers.cool/arxiv/2508.10391"target="_blank" rel="external nofollow noopener noreferrer">LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval</a>  #18 LeanRAGï¼šåŸºäºçŸ¥è¯†å›¾è°±çš„ç”Ÿæˆï¼Œå…·æœ‰è¯­ä¹‰èšåˆä¸åˆ†å±‚æ£€ç´¢</h2>
<p><strong>Authors</strong>: [Yaoze Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yaoze"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yaoze</a> Zhang), [Rong Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rong</a> Wu), [Pinlong Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pinlong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pinlong</a> Cai), [Xiaoman Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoman</a> Wang), [Guohang Yan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guohang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guohang</a> Yan), [Song Mao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Song"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Song</a> Mao), [Ding Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ding"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ding</a> Wang), [Botian Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Botian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Botian</a> Shi)
ä½œè€…ï¼šå¼ å°§æ³½ï¼Œå´è£ï¼Œè”¡å“é¾™ï¼Œç‹æ™“æ¼«ï¼Œé¢œå›½èˆªï¼Œæ¯›æ¾ï¼Œç‹é¼ï¼ŒçŸ³åšæ·»</p>
<p>Retrieval-Augmented Generation (RAG) plays a crucial role in grounding Large Language Models by leveraging external knowledge, whereas the effectiveness is often compromised by the retrieval of contextually flawed or incomplete information. To address this, knowledge graph-based RAG methods have evolved towards hierarchical structures, organizing knowledge into multi-level summaries. However, these approaches still suffer from two critical, unaddressed challenges: high-level conceptual summaries exist as disconnected ``semantic islands&rsquo;&rsquo;, lacking the explicit relations needed for cross-community reasoning; and the retrieval process itself remains structurally unaware, often degenerating into an inefficient flat search that fails to exploit the graph&rsquo;s rich topology. To overcome these limitations, we introduce LeanRAG, a framework that features a deeply collaborative design combining knowledge aggregation and retrieval strategies. LeanRAG first employs a novel semantic aggregation algorithm that forms entity clusters and constructs new explicit relations among aggregation-level summaries, creating a fully navigable semantic network. Then, a bottom-up, structure-guided retrieval strategy anchors queries to the most relevant fine-grained entities and then systematically traverses the graph&rsquo;s semantic pathways to gather concise yet contextually comprehensive evidence sets. The LeanRAG can mitigate the substantial overhead associated with path retrieval on graphs and minimizes redundant information retrieval. Extensive experiments on four challenging QA benchmarks with different domains demonstrate that LeanRAG significantly outperforming existing methods in response quality while reducing 46% retrieval redundancy. Code is available at: <a href="https://github.com/RaZzzyz/LeanRAG"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/RaZzzyz/LeanRAG</a>
æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰åœ¨åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†ä¸ºå¤§å‹è¯­è¨€æ¨¡å‹æä¾›æ”¯æ’‘æ–¹é¢å‘æŒ¥ç€å…³é”®ä½œç”¨ï¼Œä½†å…¶æœ‰æ•ˆæ€§å¸¸å¸¸å› æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æœ‰ç¼ºé™·æˆ–ä¸å®Œæ•´çš„ä¿¡æ¯è€Œå—æŸã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç‚¹ï¼ŒåŸºäºçŸ¥è¯†å›¾è°±çš„ RAG æ–¹æ³•å·²æ¼”è¿›ä¸ºåˆ†å±‚ç»“æ„ï¼Œå°†çŸ¥è¯†ç»„ç»‡ä¸ºå¤šçº§æ‘˜è¦ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•ä»ç„¶é¢ä¸´ä¸¤ä¸ªå…³é”®ä¸”æœªè§£å†³çš„æŒ‘æˆ˜ï¼šé«˜çº§æ¦‚å¿µæ‘˜è¦ä»¥ç›¸äº’éš”ç»çš„â€œè¯­ä¹‰å­¤å²›â€å½¢å¼å­˜åœ¨ï¼Œç¼ºä¹è·¨ç¤¾åŒºæ¨ç†æ‰€éœ€çš„æ˜¾å¼å…³ç³»ï¼›ä»¥åŠæ£€ç´¢è¿‡ç¨‹æœ¬èº«ä»ç„¶ç¼ºä¹ç»“æ„æ„ŸçŸ¥ï¼Œå¸¸å¸¸é€€åŒ–ä¸ºä¸èƒ½åˆ©ç”¨å›¾è°±ä¸°å¯Œæ‹“æ‰‘ç»“æ„çš„ä½æ•ˆå¹³é¢æœç´¢ã€‚ä¸ºå…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº† LeanRAGï¼Œè¿™ä¸€æ¡†æ¶é‡‡ç”¨æ·±åº¦ååŒçš„è®¾è®¡ï¼Œç»“åˆäº†çŸ¥è¯†èšåˆä¸æ£€ç´¢ç­–ç•¥ã€‚LeanRAG é¦–å…ˆé‡‡ç”¨ä¸€ç§æ–°é¢–çš„è¯­ä¹‰èšåˆç®—æ³•ï¼Œå¯¹å®ä½“è¿›è¡Œç°‡åŒ–å¹¶åœ¨èšåˆçº§æ‘˜è¦ä¹‹é—´æ„å»ºæ–°çš„æ˜¾å¼å…³ç³»ï¼Œä»è€Œåˆ›å»ºä¸€ä¸ªå¯å®Œå…¨å¯¼èˆªçš„è¯­ä¹‰ç½‘ç»œã€‚ ç„¶åï¼Œä¸€ç§è‡ªä¸‹è€Œä¸Šã€ç»“æ„å¼•å¯¼çš„æ£€ç´¢ç­–ç•¥å°†æŸ¥è¯¢é”šå®šåˆ°æœ€ç›¸å…³çš„ç»†ç²’åº¦å®ä½“ä¸Šï¼Œç„¶åç³»ç»Ÿåœ°éå†å›¾è°±çš„è¯­ä¹‰è·¯å¾„ä»¥æ”¶é›†æ—¢ç®€æ´åˆå…·æœ‰ä¸Šä¸‹æ–‡å®Œæ•´æ€§çš„è¯æ®é›†ã€‚LeanRAG èƒ½ç¼“è§£ä¸å›¾ä¸Šè·¯å¾„æ£€ç´¢ç›¸å…³çš„å¤§é‡å¼€é”€ï¼Œå¹¶å°†å†—ä½™ä¿¡æ¯æ£€ç´¢é™åˆ°æœ€ä½ã€‚åœ¨å››ä¸ªæ¥è‡ªä¸åŒé¢†åŸŸçš„å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®ç­”åŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒLeanRAG åœ¨å›ç­”è´¨é‡ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼ŒåŒæ—¶å‡å°‘äº† 46% çš„æ£€ç´¢å†—ä½™ã€‚ä»£ç å¯åœ¨ä»¥ä¸‹åœ°å€è·å–ï¼š <a href="https://github.com/RaZzzyz/LeanRAG"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/RaZzzyz/LeanRAG</a></p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 06:47:18 UTC
å‘å¸ƒï¼š2025-08-14 06:47:18 UTC</p>
<h2 id="19-what-to-ask-next-probing-the-imaginative-reasoning-of-llms-with-turtlesoup-puzzles--19-æ¥ä¸‹æ¥è¯¥é—®ä»€ä¹ˆç”¨-turtlesoup-è°œé¢˜æ¢ç´¢-llms-çš„æƒ³è±¡æ€§æ¨ç†"><a href="https://arxiv.org/abs/2508.10358"target="_blank" rel="external nofollow noopener noreferrer">#19</a> <a href="https://papers.cool/arxiv/2508.10358"target="_blank" rel="external nofollow noopener noreferrer">What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles</a>  #19 æ¥ä¸‹æ¥è¯¥é—®ä»€ä¹ˆï¼Ÿç”¨ TurtleSoup è°œé¢˜æ¢ç´¢ LLMs çš„æƒ³è±¡æ€§æ¨ç†</h2>
<p><strong>Authors</strong>: [Mengtao Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengtao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengtao</a> Zhou), [Sifan Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sifan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sifan</a> Wu), [Huan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huan</a> Zhang), [Qi Sima](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qi</a> Sima), [Bang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bang</a> Liu)
ä½œè€…ï¼šå‘¨æ¢¦æ¶›ã€å´æ€å‡¡ã€å¼ æ¬¢ã€å¸é©¬çªã€åˆ˜é‚¦</p>
<p>We investigate the capacity of Large Language Models (LLMs) for imaginative reasoning&ndash;the proactive construction, testing, and revision of hypotheses in information-sparse environments. Existing benchmarks, often static or focused on social deduction, fail to capture the dynamic, exploratory nature of this reasoning process. To address this gap, we introduce a comprehensive research framework based on the classic &ldquo;Turtle Soup&rdquo; game, integrating a benchmark, an agent, and an evaluation protocol. We present TurtleSoup-Bench, the first large-scale, bilingual, interactive benchmark for imaginative reasoning, comprising 800 turtle soup puzzles sourced from both the Internet and expert authors. We also propose Mosaic-Agent, a novel agent designed to assess LLMs&rsquo; performance in this setting. To evaluate reasoning quality, we develop a multi-dimensional protocol measuring logical consistency, detail completion, and conclusion alignment. Experiments with leading LLMs reveal clear capability limits, common failure patterns, and a significant performance gap compared to humans. Our work offers new insights into LLMs&rsquo; imaginative reasoning and establishes a foundation for future research on exploratory agent behavior.
æˆ‘ä»¬ç ”ç©¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¯Œæœ‰æƒ³è±¡åŠ›çš„æ¨ç†èƒ½åŠ›â€”â€”å³åœ¨ä¿¡æ¯ç¨€ç¼ºçš„ç¯å¢ƒä¸­ä¸»åŠ¨æ„å»ºã€æ£€éªŒå’Œä¿®æ­£å‡è®¾â€”â€”æ–¹é¢çš„è¡¨ç°ã€‚ç°æœ‰åŸºå‡†é€šå¸¸æ˜¯é™æ€çš„æˆ–ä¾§é‡äºç¤¾ä¼šæ¨ç†ï¼Œæ— æ³•æ•æ‰è¿™ä¸€æ¨ç†è¿‡ç¨‹çš„åŠ¨æ€æ¢ç´¢æ€§ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬åŸºäºç»å…¸çš„â€œTurtle Soupâ€æ¸¸æˆæå‡ºäº†ä¸€ä¸ªç»¼åˆç ”ç©¶æ¡†æ¶ï¼Œæ•´åˆäº†ä¸€ä¸ªåŸºå‡†ã€ä¸€ä¸ªæ™ºèƒ½ä½“å’Œä¸€å¥—è¯„ä¼°åè®®ã€‚æˆ‘ä»¬æ¨å‡ºäº† TurtleSoup-Benchï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå¤§è§„æ¨¡çš„ã€åŒè¯­çš„ã€äº¤äº’å¼çš„æƒ³è±¡åŠ›æ¨ç†åŸºå‡†ï¼ŒåŒ…å«æ¥è‡ªäº’è”ç½‘å’Œä¸“å®¶ä½œè€…çš„ 800 é“ turtle soup è°œé¢˜ã€‚æˆ‘ä»¬è¿˜æå‡ºäº† Mosaic-Agentï¼Œä¸€ç§ç”¨äºè¯„ä¼° LLMs åœ¨è¯¥æƒ…å¢ƒä¸‹è¡¨ç°çš„æ–°å‹æ™ºèƒ½ä½“ã€‚ä¸ºè¯„ä¼°æ¨ç†è´¨é‡ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€å¥—å¤šç»´è¯„ä¼°åè®®ï¼Œè¡¡é‡é€»è¾‘ä¸€è‡´æ€§ã€ç»†èŠ‚å®Œæ•´æ€§å’Œç»“è®ºä¸€è‡´æ€§ã€‚å¯¹ä¸»æµ LLMs çš„å®éªŒè¯æ˜äº†å…¶æ˜æ˜¾çš„èƒ½åŠ›ä¸Šé™ã€å¸¸è§å¤±è´¥æ¨¡å¼ï¼Œä»¥åŠä¸äººç±»ç›¸æ¯”å­˜åœ¨çš„æ˜¾è‘—æ€§èƒ½å·®è·ã€‚ æˆ‘ä»¬çš„å·¥ä½œä¸º LLMs çš„æƒ³è±¡æ€§æ¨ç†æä¾›äº†æ–°è§è§£ï¼Œå¹¶ä¸ºæœªæ¥å…³äºæ¢ç´¢å‹ä»£ç†è¡Œä¸ºçš„ç ”ç©¶å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 05:55:42 UTC
å‘å¸ƒï¼š2025-08-14 05:55:42 UTC</p>
<h2 id="20-multi-agent-trust-region-policy-optimisation-a-joint-constraint-approach--20-å¤šæ™ºèƒ½ä½“ä¿¡ä»»åŸŸç­–ç•¥ä¼˜åŒ–ä¸€ç§è”åˆçº¦æŸæ–¹æ³•"><a href="https://arxiv.org/abs/2508.10340"target="_blank" rel="external nofollow noopener noreferrer">#20</a> <a href="https://papers.cool/arxiv/2508.10340"target="_blank" rel="external nofollow noopener noreferrer">Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach</a>  #20 å¤šæ™ºèƒ½ä½“ä¿¡ä»»åŸŸç­–ç•¥ä¼˜åŒ–ï¼šä¸€ç§è”åˆçº¦æŸæ–¹æ³•</h2>
<p><strong>Authors</strong>: [Chak Lam Shek](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chak"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chak</a> Lam Shek), [Guangyao Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guangyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guangyao</a> Shi), [Pratap Tokekar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pratap"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pratap</a> Tokekar)
ä½œè€…ï¼šChak Lam Shekã€Guangyao Shiã€Pratap Tokekar</p>
<p>Multi-agent reinforcement learning (MARL) requires coordinated and stable policy updates among interacting agents. Heterogeneous-Agent Trust Region Policy Optimization (HATRPO) enforces per-agent trust region constraints using Kullback-Leibler (KL) divergence to stabilize training. However, assigning each agent the same KL threshold can lead to slow and locally optimal updates, especially in heterogeneous settings. To address this limitation, we propose two approaches for allocating the KL divergence threshold across agents: HATRPO-W, a Karush-Kuhn-Tucker-based (KKT-based) method that optimizes threshold assignment under global KL constraints, and HATRPO-G, a greedy algorithm that prioritizes agents based on improvement-to-divergence ratio. By connecting sequential policy optimization with constrained threshold scheduling, our approach enables more flexible and effective learning in heterogeneous-agent settings. Experimental results demonstrate that our methods significantly boost the performance of HATRPO, achieving faster convergence and higher final rewards across diverse MARL benchmarks. Specifically, HATRPO-W and HATRPO-G achieve comparable improvements in final performance, each exceeding 22.5%. Notably, HATRPO-W also demonstrates more stable learning dynamics, as reflected by its lower variance.
å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰è¦æ±‚ç›¸äº’ä½œç”¨çš„æ™ºèƒ½ä½“ä¹‹é—´è¿›è¡Œåè°ƒä¸”ç¨³å®šçš„ç­–ç•¥æ›´æ–°ã€‚å¼‚è´¨æ™ºèƒ½ä½“ä¿¡èµ–åŸŸç­–ç•¥ä¼˜åŒ–ï¼ˆHATRPOï¼‰ä½¿ç”¨åº“å°”åˆ«å…‹-è±å¸ƒå‹’ï¼ˆKLï¼‰æ•£åº¦å¯¹æ¯ä¸ªæ™ºèƒ½ä½“æ–½åŠ ä¿¡èµ–åŸŸçº¦æŸä»¥ç¨³å®šè®­ç»ƒã€‚ç„¶è€Œï¼Œä¸ºæ¯ä¸ªæ™ºèƒ½ä½“åˆ†é…ç›¸åŒçš„ KL é˜ˆå€¼å¯èƒ½å¯¼è‡´æ›´æ–°ç¼“æ…¢å¹¶é™·å…¥å±€éƒ¨æœ€ä¼˜ï¼Œå°¤å…¶åœ¨å¼‚è´¨è®¾ç½®ä¸­ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤ç§åœ¨æ™ºèƒ½ä½“ä¹‹é—´åˆ†é… KL æ•£åº¦é˜ˆå€¼çš„æ–¹æ³•ï¼šHATRPO-Wï¼Œä¸€ç§åŸºäº Karush-Kuhn-Tuckerï¼ˆKKTï¼‰çš„æ–¹æ³•ï¼Œåœ¨å…¨å±€ KL çº¦æŸä¸‹ä¼˜åŒ–é˜ˆå€¼åˆ†é…ï¼›ä»¥åŠ HATRPO-Gï¼Œä¸€ç§è´ªå¿ƒç®—æ³•ï¼Œæ ¹æ®æ”¹è¿›ä¸æ•£åº¦ä¹‹æ¯”å¯¹æ™ºèƒ½ä½“è¿›è¡Œä¼˜å…ˆæ’åºã€‚é€šè¿‡å°†åºåˆ—åŒ–ç­–ç•¥ä¼˜åŒ–ä¸çº¦æŸé˜ˆå€¼è°ƒåº¦ç›¸ç»“åˆï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨å¼‚è´¨æ™ºèƒ½ä½“è®¾ç½®ä¸­å®ç°äº†æ›´çµæ´»å’Œæ›´æœ‰æ•ˆçš„å­¦ä¹ ã€‚å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—æå‡äº† HATRPO çš„æ€§èƒ½ï¼Œåœ¨å„ç§ MARL åŸºå‡†æµ‹è¯•ä¸­å®ç°äº†æ›´å¿«çš„æ”¶æ•›å’Œæ›´é«˜çš„æœ€ç»ˆå›æŠ¥ã€‚ å…·ä½“è€Œè¨€ï¼ŒHATRPO-W å’Œ HATRPO-G åœ¨æœ€ç»ˆæ€§èƒ½ä¸Šå–å¾—äº†ç›¸å½“çš„æå‡ï¼Œå‡è¶…è¿‡ 22.5%ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒHATRPO-W åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­çš„åŠ¨æ€ä¹Ÿæ›´ç¨³å®šï¼Œè¿™ä»å…¶æ›´ä½çš„æ–¹å·®å¯ä»¥çœ‹å‡ºã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 04:48:46 UTC
å‘å¸ƒï¼š2025-08-14 04:48:46 UTC</p>
<h2 id="21-a-curriculum-learning-approach-to-reinforcement-learning-leveraging-rag-for-multimodal-question-answering--21-ä¸€ç§é¢å‘å¼ºåŒ–å­¦ä¹ çš„è¯¾ç¨‹å­¦ä¹ æ–¹æ³•åœ¨å¤šæ¨¡æ€é—®ç­”ä¸­åˆ©ç”¨-rag"><a href="https://arxiv.org/abs/2508.10337"target="_blank" rel="external nofollow noopener noreferrer">#21</a> <a href="https://papers.cool/arxiv/2508.10337"target="_blank" rel="external nofollow noopener noreferrer">A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering</a>  #21 ä¸€ç§é¢å‘å¼ºåŒ–å­¦ä¹ çš„è¯¾ç¨‹å­¦ä¹ æ–¹æ³•ï¼šåœ¨å¤šæ¨¡æ€é—®ç­”ä¸­åˆ©ç”¨ RAG</h2>
<p><strong>Authors</strong>: [Chenliang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chenliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chenliang</a> Zhang), [Lin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lin</a> Wang), [Yuanyuan Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuanyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuanyuan</a> Lu), [Yusheng Qi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yusheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yusheng</a> Qi), [Kexin Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kexin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kexin</a> Wang), [Peixu Hou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peixu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peixu</a> Hou), [Wenshi Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenshi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenshi</a> Chen)
ä½œè€…ï¼šå¼ é™ˆäº®ï¼Œç‹æ—ï¼Œé™†åª›åª›ï¼Œç¥ç‰å‡ï¼Œç‹ç§‘é‘«ï¼Œä¾¯åŸ¹æ—­ï¼Œé™ˆæ–‡è¯—</p>
<p>This paper describes the solutions of the Dianping-Trust-Safety team for the META CRAG-MM challenge. The challenge requires building a comprehensive retrieval-augmented generation system capable for multi-modal multi-turn question answering. The competition consists of three tasks: (1) answering questions using structured data retrieved from an image-based mock knowledge graph, (2) synthesizing information from both knowledge graphs and web search results, and (3) handling multi-turn conversations that require context understanding and information aggregation from multiple sources. For Task 1, our solution is based on the vision large language model, enhanced by supervised fine-tuning with knowledge distilled from GPT-4.1. We further applied curriculum learning strategies to guide reinforcement learning, resulting in improved answer accuracy and reduced hallucination. For Task 2 and Task 3, we additionally leveraged web search APIs to incorporate external knowledge, enabling the system to better handle complex queries and multi-turn conversations. Our approach achieved 1st place in Task 1 with a significant lead of 52.38%, and 3rd place in Task 3, demonstrating the effectiveness of the integration of curriculum learning with reinforcement learning in our training pipeline.
æœ¬æ–‡ä»‹ç»äº†å¤§ä¼—ç‚¹è¯„å®‰å…¨å›¢é˜Ÿå‚åŠ  META CRAG-MM æŒ‘æˆ˜èµ›çš„è§£å†³æ–¹æ¡ˆã€‚è¯¥æŒ‘æˆ˜è¦æ±‚æ„å»ºä¸€ä¸ªåŸºäºæ£€ç´¢å¢å¼ºç”Ÿæˆçš„ç»¼åˆç³»ç»Ÿï¼Œèƒ½å¤Ÿè¿›è¡Œå¤šæ¨¡æ€å¤šè½®é—®ç­”ã€‚æ¯”èµ›åŒ…å«ä¸‰é¡¹ä»»åŠ¡ï¼šï¼ˆ1ï¼‰ä½¿ç”¨ä»åŸºäºå›¾åƒçš„æ¨¡æ‹ŸçŸ¥è¯†å›¾è°±ä¸­æ£€ç´¢çš„ç»“æ„åŒ–æ•°æ®æ¥å›ç­”é—®é¢˜ï¼Œï¼ˆ2ï¼‰ç»¼åˆæ¥è‡ªçŸ¥è¯†å›¾è°±å’Œç½‘é¡µæœç´¢ç»“æœçš„ä¿¡æ¯ï¼Œä»¥åŠï¼ˆ3ï¼‰å¤„ç†éœ€è¦ä¸Šä¸‹æ–‡ç†è§£å¹¶ä»å¤šä¸ªæ¥æºèšåˆä¿¡æ¯çš„å¤šè½®å¯¹è¯ã€‚å¯¹äºä»»åŠ¡ 1ï¼Œæˆ‘ä»¬çš„è§£å†³æ–¹æ¡ˆåŸºäºè§†è§‰å¤§æ¨¡å‹ï¼Œå¹¶é€šè¿‡ä» GPT-4.1 è’¸é¦å‡ºçš„çŸ¥è¯†è¿›è¡Œæœ‰ç›‘ç£å¾®è°ƒæ¥å¢å¼ºæ¨¡å‹èƒ½åŠ›ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åº”ç”¨äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥æ¥å¼•å¯¼å¼ºåŒ–å­¦ä¹ ï¼Œä»è€Œæå‡äº†ç­”æ¡ˆå‡†ç¡®æ€§å¹¶å‡å°‘äº†å¹»è§‰ã€‚å¯¹äºä»»åŠ¡ 2 å’Œä»»åŠ¡ 3ï¼Œæˆ‘ä»¬é¢å¤–åˆ©ç”¨äº†ç½‘é¡µæœç´¢ API æ¥å¼•å…¥å¤–éƒ¨çŸ¥è¯†ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿæ›´å¥½åœ°å¤„ç†å¤æ‚æŸ¥è¯¢å’Œå¤šè½®å¯¹è¯ã€‚ æˆ‘ä»¬çš„æ–¹æ³•åœ¨ä»»åŠ¡ 1 ä¸­ä»¥ 52.38%çš„å·¨å¤§ä¼˜åŠ¿è·å¾—äº†ç¬¬ä¸€åï¼Œå¹¶åœ¨ä»»åŠ¡ 3 ä¸­è·å¾—äº†ç¬¬ä¸‰åï¼Œè¿™è¯æ˜äº†åœ¨æˆ‘ä»¬çš„è®­ç»ƒæµç¨‹ä¸­å°†è¯¾ç¨‹å­¦ä¹ ä¸å¼ºåŒ–å­¦ä¹ ç›¸ç»“åˆçš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 04:37:56 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 04:37:56 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="22-promoting-efficient-reasoning-with-verifiable-stepwise-reward--22-é€šè¿‡å¯éªŒè¯çš„é€æ­¥å¥–åŠ±ä¿ƒè¿›é«˜æ•ˆæ¨ç†"><a href="https://arxiv.org/abs/2508.10293"target="_blank" rel="external nofollow noopener noreferrer">#22</a> <a href="https://papers.cool/arxiv/2508.10293"target="_blank" rel="external nofollow noopener noreferrer">Promoting Efficient Reasoning with Verifiable Stepwise Reward</a>  #22 é€šè¿‡å¯éªŒè¯çš„é€æ­¥å¥–åŠ±ä¿ƒè¿›é«˜æ•ˆæ¨ç†</h2>
<p><strong>Authors</strong>: [Chuhuai Yue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chuhuai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chuhuai</a> Yue), [Chengqi Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengqi</a> Dong), [Yinan Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yinan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yinan</a> Gao), [Hang He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hang</a> He), [Jiajun Chai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiajun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiajun</a> Chai), [Guojun Yin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guojun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guojun</a> Yin), [Wei Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Lin)
ä½œè€…ï¼šå²³æ¥šæ€€ï¼Œè‘£æˆç¦ï¼Œé«˜ä¸€å—ï¼Œä½•èˆªï¼ŒæŸ´ä½³éªï¼Œå°¹å›½å†›ï¼Œæ—ä¼Ÿ</p>
<p>Large reasoning models (LRMs) have recently achieved significant progress in complex reasoning tasks, aided by reinforcement learning with verifiable rewards. However, LRMs often suffer from overthinking, expending excessive computation on simple problems and reducing efficiency. Existing efficient reasoning methods typically require accurate task assessment to preset token budgets or select reasoning modes, which limits their flexibility and reliability. In this work, we revisit the essence of overthinking and identify that encouraging effective steps while penalizing ineffective ones is key to its solution. To this end, we propose a novel rule-based verifiable stepwise reward mechanism (VSRM), which assigns rewards based on the performance of intermediate states in the reasoning trajectory. This approach is intuitive and naturally fits the step-by-step nature of reasoning tasks. We conduct extensive experiments on standard mathematical reasoning benchmarks, including AIME24 and AIME25, by integrating VSRM with PPO and Reinforce++. Results show that our method achieves substantial output length reduction while maintaining original reasoning performance, striking an optimal balance between efficiency and accuracy. Further analysis of overthinking frequency and pass@k score before and after training demonstrates that our approach in deed effectively suppresses ineffective steps and encourages effective reasoning, fundamentally alleviating the overthinking problem. All code will be released upon acceptance.
å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMsï¼‰æœ€è¿‘åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œè¿™å¾—ç›Šäºå…·æœ‰å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ã€‚ç„¶è€Œï¼ŒLRMs å¸¸å¸¸å­˜åœ¨è¿‡åº¦æ€è€ƒçš„é—®é¢˜ï¼Œåœ¨ç®€å•é—®é¢˜ä¸Šæ¶ˆè€—è¿‡å¤šè®¡ç®—èµ„æºï¼Œä»è€Œé™ä½æ•ˆç‡ã€‚ç°æœ‰çš„é«˜æ•ˆæ¨ç†æ–¹æ³•é€šå¸¸éœ€è¦å‡†ç¡®çš„ä»»åŠ¡è¯„ä¼°ä»¥é¢„è®¾ä»¤ç‰Œé¢„ç®—æˆ–é€‰æ‹©æ¨ç†æ¨¡å¼ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„çµæ´»æ€§å’Œå¯é æ€§ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬é‡æ–°å®¡è§†äº†è¿‡åº¦æ€è€ƒçš„æœ¬è´¨ï¼Œå¹¶æŒ‡å‡ºé¼“åŠ±æœ‰æ•ˆæ­¥éª¤åŒæ—¶æƒ©ç½šæ— æ•ˆæ­¥éª¤æ˜¯è§£å†³è¯¥é—®é¢˜çš„å…³é”®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŸºäºè§„åˆ™çš„å¯éªŒè¯é€æ­¥å¥–åŠ±æœºåˆ¶ï¼ˆVSRMï¼‰ï¼Œè¯¥æœºåˆ¶åŸºäºæ¨ç†è½¨è¿¹ä¸­ä¸­é—´çŠ¶æ€çš„è¡¨ç°æ¥åˆ†é…å¥–åŠ±ã€‚è¿™ç§æ–¹æ³•ç›´è§‚ä¸”è‡ªç„¶å¥‘åˆæ¨ç†ä»»åŠ¡çš„é€æ­¥ç‰¹æ€§ã€‚æˆ‘ä»¬åœ¨æ ‡å‡†æ•°å­¦æ¨ç†åŸºå‡†ï¼ˆåŒ…æ‹¬ AIME24 å’Œ AIME25ï¼‰ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒï¼Œå°† VSRM ä¸ PPO å’Œ Reinforce++ ç»“åˆä½¿ç”¨ã€‚ ç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨æ˜¾è‘—å‡å°‘è¾“å‡ºé•¿åº¦çš„åŒæ—¶ä¿æŒäº†åŸæœ‰çš„æ¨ç†æ€§èƒ½ï¼Œåœ¨æ•ˆç‡ä¸å‡†ç¡®æ€§ä¹‹é—´è¾¾åˆ°äº†æœ€ä½³å¹³è¡¡ã€‚å¯¹è®­ç»ƒå‰åè¿‡åº¦æ€è€ƒé¢‘ç‡å’Œ pass@k åˆ†æ•°çš„è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ç¡®å®æœ‰æ•ˆåœ°æŠ‘åˆ¶äº†æ— æ•ˆæ­¥éª¤å¹¶é¼“åŠ±äº†æœ‰æ•ˆæ¨ç†ï¼Œä»æ ¹æœ¬ä¸Šç¼“è§£äº†è¿‡åº¦æ€è€ƒé—®é¢˜ã€‚æ‰€æœ‰ä»£ç å°†åœ¨æ¥å—åå…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 02:43:53 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-14 02:43:53 UTC</p>
<h2 id="23-why-cannot-large-language-models-ever-make-true-correct-reasoning--23-ä¸ºä»€ä¹ˆå¤§å‹è¯­è¨€æ¨¡å‹æ°¸è¿œæ— æ³•åšå‡ºçœŸæ­£æ­£ç¡®çš„æ¨ç†"><a href="https://arxiv.org/abs/2508.10265"target="_blank" rel="external nofollow noopener noreferrer">#23</a> <a href="https://papers.cool/arxiv/2508.10265"target="_blank" rel="external nofollow noopener noreferrer">Why Cannot Large Language Models Ever Make True Correct Reasoning?</a>  #23 ä¸ºä»€ä¹ˆå¤§å‹è¯­è¨€æ¨¡å‹æ°¸è¿œæ— æ³•åšå‡ºçœŸæ­£æ­£ç¡®çš„æ¨ç†ï¼Ÿ</h2>
<p><strong>Author</strong>: [Jingde Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingde"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingde</a> Cheng) ä½œè€…ï¼šç¨‹æ•¬å¾·</p>
<p>Recently, with the application progress of AIGC tools based on large language models (LLMs), led by ChatGPT, many AI experts and more non-professionals are trumpeting the &ldquo;understanding ability&rdquo; and &ldquo;reasoning ability&rdquo; of the LLMs. The present author considers that the so-called &ldquo;understanding ability&rdquo; and &ldquo;reasoning ability&rdquo; of LLMs are just illusions of those people who with vague concepts. In fact, the LLMs can never have the true understanding ability and true reasoning ability. This paper intents to explain that, because the essential limitations of their working principle, the LLMs can never have the ability of true correct reasoning.
æœ€è¿‘ï¼Œéšç€ä»¥ ChatGPT ä¸ºä»£è¡¨çš„åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ AIGC å·¥å…·åº”ç”¨çš„æ¨è¿›ï¼Œè®¸å¤šäººå·¥æ™ºèƒ½ä¸“å®¶ä»¥åŠæ›´å¤šéä¸“ä¸šäººå£«éƒ½åœ¨å¤§è‚†å¹æ§è¿™äº› LLMs çš„â€œç†è§£èƒ½åŠ›â€å’Œâ€œæ¨ç†èƒ½åŠ›â€ã€‚ç¬”è€…è®¤ä¸ºï¼Œè¿™äº›å¯¹ LLMs çš„æ‰€è°“â€œç†è§£èƒ½åŠ›â€å’Œâ€œæ¨ç†èƒ½åŠ›â€åªæ˜¯é‚£äº›æ¦‚å¿µæ¨¡ç³Šä¹‹äººçš„é”™è§‰ã€‚äº‹å®ä¸Šï¼ŒLLMs æ°¸è¿œä¸å¯èƒ½æ‹¥æœ‰çœŸæ­£çš„ç†è§£èƒ½åŠ›å’ŒçœŸæ­£çš„æ¨ç†èƒ½åŠ›ã€‚æœ¬æ–‡æ—¨åœ¨è¯´æ˜ï¼Œç”±äºå…¶å·¥ä½œåŸç†çš„æœ¬è´¨æ€§é™åˆ¶ï¼ŒLLMs æ°¸è¿œä¸å¯èƒ½å…·å¤‡çœŸæ­£æ­£ç¡®çš„æ¨ç†èƒ½åŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LO"target="_blank" rel="external nofollow noopener noreferrer">Logic in Computer Science</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œè®¡ç®—æœºç§‘å­¦ä¸­çš„é€»è¾‘</p>
<p><strong>Publish</strong>: 2025-08-14 01:18:18 UTC</p>
<h2 id="24-extending-the-entropic-potential-of-events-for-uncertainty-quantification-and-decision-making-in-artificial-intelligence--24-æ‰©å±•äº‹ä»¶çš„ç†µåŠ¿ä»¥ç”¨äºä¸ç¡®å®šæ€§é‡åŒ–å’Œäººå·¥æ™ºèƒ½ä¸­çš„å†³ç­–åˆ¶å®š"><a href="https://arxiv.org/abs/2508.10241"target="_blank" rel="external nofollow noopener noreferrer">#24</a> <a href="https://papers.cool/arxiv/2508.10241"target="_blank" rel="external nofollow noopener noreferrer">Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence</a>  #24 æ‰©å±•äº‹ä»¶çš„ç†µåŠ¿ä»¥ç”¨äºä¸ç¡®å®šæ€§é‡åŒ–å’Œäººå·¥æ™ºèƒ½ä¸­çš„å†³ç­–åˆ¶å®š</h2>
<p><strong>Author</strong>: [Mark Zilberman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mark"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mark</a> Zilberman) ä½œè€…ï¼šMark Zilberman</p>
<p>This work demonstrates how the concept of the entropic potential of events &ndash; a parameter quantifying the influence of discrete events on the expected future entropy of a system &ndash; can enhance uncertainty quantification, decision-making, and interpretability in artificial intelligence (AI). Building on its original formulation in physics, the framework is adapted for AI by introducing an event-centric measure that captures how actions, observations, or other discrete occurrences impact uncertainty at future time horizons. Both the original and AI-adjusted definitions of entropic potential are formalized, with the latter emphasizing conditional expectations to account for counterfactual scenarios. Applications are explored in policy evaluation, intrinsic reward design, explainable AI, and anomaly detection, highlighting the metric&rsquo;s potential to unify and strengthen uncertainty modeling in intelligent systems. Conceptual examples illustrate its use in reinforcement learning, Bayesian inference, and anomaly detection, while practical considerations for computation in complex AI models are discussed. The entropic potential framework offers a theoretically grounded, interpretable, and versatile approach to managing uncertainty in AI, bridging principles from thermodynamics, information theory, and machine learning.
è¿™é¡¹å·¥ä½œå±•ç¤ºäº†äº‹ä»¶ç†µåŠ¿æ¦‚å¿µâ€”â€”ä¸€ä¸ªé‡åŒ–ç¦»æ•£äº‹ä»¶å¯¹ç³»ç»Ÿæœªæ¥æœŸæœ›ç†µå½±å“çš„å‚æ•°â€”â€”å¦‚ä½•å¢å¼ºä¸ç¡®å®šæ€§é‡åŒ–ã€å†³ç­–åˆ¶å®šå’Œäººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä¸­çš„å¯è§£é‡Šæ€§ã€‚åœ¨å…¶åœ¨ç‰©ç†å­¦ä¸­çš„åŸå§‹è¡¨è¿°åŸºç¡€ä¸Šï¼Œè¯¥æ¡†æ¶é€šè¿‡å¼•å…¥ä»¥äº‹ä»¶ä¸ºä¸­å¿ƒçš„åº¦é‡æ¥é€‚é… AIï¼Œè¯¥åº¦é‡æ•æ‰è¡ŒåŠ¨ã€è§‚æµ‹æˆ–å…¶ä»–ç¦»æ•£äº‹ä»¶å¦‚ä½•åœ¨æœªæ¥æ—¶é—´èŒƒå›´å†…å½±å“ä¸ç¡®å®šæ€§ã€‚å½¢å¼åŒ–äº†ç†µåŠ¿çš„åŸå§‹å®šä¹‰å’Œä¸º AI è°ƒæ•´åçš„å®šä¹‰ï¼Œåè€…å¼ºè°ƒæ¡ä»¶æœŸæœ›ä»¥è€ƒè™‘åäº‹å®æƒ…å½¢ã€‚æ¢è®¨äº†åœ¨ç­–ç•¥è¯„ä¼°ã€å†…åœ¨å¥–åŠ±è®¾è®¡ã€å¯è§£é‡Š AI å’Œå¼‚å¸¸æ£€æµ‹ä¸­çš„åº”ç”¨ï¼Œçªå‡ºäº†è¯¥åº¦é‡åœ¨ç»Ÿä¸€å’Œå¼ºåŒ–æ™ºèƒ½ç³»ç»Ÿä¸ç¡®å®šæ€§å»ºæ¨¡æ–¹é¢çš„æ½œåŠ›ã€‚é€šè¿‡æ¦‚å¿µæ€§ç¤ºä¾‹è¯´æ˜å…¶åœ¨å¼ºåŒ–å­¦ä¹ ã€è´å¶æ–¯æ¨æ–­å’Œå¼‚å¸¸æ£€æµ‹ä¸­çš„ä½¿ç”¨ï¼ŒåŒæ—¶è®¨è®ºäº†åœ¨å¤æ‚ AI æ¨¡å‹ä¸­è®¡ç®—çš„å®é™…è€ƒè™‘ã€‚ ç†µåŠ¿æ¡†æ¶æä¾›äº†ä¸€ç§æœ‰ç†è®ºä¾æ®ã€å¯è§£é‡Šä¸”å¤šç”¨é€”çš„æ–¹æ³•æ¥å¤„ç†äººå·¥æ™ºèƒ½ä¸­çš„ä¸ç¡®å®šæ€§ï¼Œæ¡¥æ¥äº†çƒ­åŠ›å­¦ã€ä¿¡æ¯è®ºå’Œæœºå™¨å­¦ä¹ çš„åŸç†ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 23:52:12 UTC
å‘å¸ƒï¼š2025-08-13 23:52:12 UTC</p>
<h2 id="25-kompeteai-accelerated-autonomous-multi-agent-system-for-end-to-end-pipeline-generation-for-machine-learning-problems--25-kompeteaiç”¨äºæœºå™¨å­¦ä¹ é—®é¢˜ç«¯åˆ°ç«¯ç®¡é“ç”Ÿæˆçš„åŠ é€Ÿè‡ªä¸»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ"><a href="https://arxiv.org/abs/2508.10177"target="_blank" rel="external nofollow noopener noreferrer">#25</a> <a href="https://papers.cool/arxiv/2508.10177"target="_blank" rel="external nofollow noopener noreferrer">KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems</a>  #25 KompeteAIï¼šç”¨äºæœºå™¨å­¦ä¹ é—®é¢˜ç«¯åˆ°ç«¯ç®¡é“ç”Ÿæˆçš„åŠ é€Ÿè‡ªä¸»å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ</h2>
<p><strong>Authors</strong>: [Stepan Kulibaba](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Stepan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Stepan</a> Kulibaba), [Artem Dzhalilov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Artem"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Artem</a> Dzhalilov), [Roman Pakhomov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Roman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Roman</a> Pakhomov), [Oleg Svidchenko](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Oleg"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Oleg</a> Svidchenko), [Alexander Gasnikov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexander"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexander</a> Gasnikov), [Aleksei Shpilman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aleksei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aleksei</a> Shpilman)
ä½œè€…ï¼šStepan Kulibabaã€Artem Dzhalilovã€Roman Pakhomovã€Oleg Svidchenkoã€Alexander Gasnikovã€Aleksei Shpilman</p>
<p>Recent Large Language Model (LLM)-based AutoML systems demonstrate impressive capabilities but face significant limitations such as constrained exploration strategies and a severe execution bottleneck. Exploration is hindered by one-shot methods lacking diversity and Monte Carlo Tree Search (MCTS) approaches that fail to recombine strong partial solutions. The execution bottleneck arises from lengthy code validation cycles that stifle iterative refinement. To overcome these challenges, we introduce KompeteAI, a novel AutoML framework with dynamic solution space exploration. Unlike previous MCTS methods that treat ideas in isolation, KompeteAI introduces a merging stage that composes top candidates. We further expand the hypothesis space by integrating Retrieval-Augmented Generation (RAG), sourcing ideas from Kaggle notebooks and arXiv papers to incorporate real-world strategies. KompeteAI also addresses the execution bottleneck via a predictive scoring model and an accelerated debugging method, assessing solution potential using early stage metrics to avoid costly full-code execution. This approach accelerates pipeline evaluation 6.9 times. KompeteAI outperforms leading methods (e.g., RD-agent, AIDE, and Ml-Master) by an average of 3% on the primary AutoML benchmark, MLE-Bench. Additionally, we propose Kompete-bench to address limitations in MLE-Bench, where KompeteAI also achieves state-of-the-art results
æœ€è¿‘åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„è‡ªåŠ¨æœºå™¨å­¦ä¹ ç³»ç»Ÿå±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œä½†ä¹Ÿé¢ä¸´æ˜¾è‘—é™åˆ¶ï¼Œä¾‹å¦‚å—é™çš„æ¢ç´¢ç­–ç•¥å’Œä¸¥é‡çš„æ‰§è¡Œç“¶é¢ˆã€‚æ¢ç´¢å—é˜»äºç¼ºä¹å¤šæ ·æ€§çš„ä¸€æ¬¡æ€§æ–¹æ³•å’Œæ— æ³•é‡ç»„å¼ºå¤§éƒ¨åˆ†è§£çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMCTSï¼‰æ–¹æ³•ã€‚æ‰§è¡Œç“¶é¢ˆæ¥è‡ªæ¼«é•¿çš„ä»£ç éªŒè¯å¾ªç¯ï¼ŒæŠ‘åˆ¶äº†è¿­ä»£æ”¹è¿›ã€‚ä¸ºå…‹æœè¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº† KompeteAIï¼Œä¸€ç§å…·æœ‰åŠ¨æ€è§£ç©ºé—´æ¢ç´¢çš„æ–°å‹ AutoML æ¡†æ¶ã€‚ä¸ä»¥å¾€å°†æƒ³æ³•å­¤ç«‹å¤„ç†çš„ MCTS æ–¹æ³•ä¸åŒï¼ŒKompeteAI å¼•å…¥äº†ä¸€ä¸ªåˆå¹¶é˜¶æ®µï¼Œèƒ½å¤Ÿç»„åˆé¡¶çº§å€™é€‰æ–¹æ¡ˆã€‚æˆ‘ä»¬è¿›ä¸€æ­¥é€šè¿‡é›†æˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æ‰©å±•äº†å‡è®¾ç©ºé—´ï¼Œä» Kaggle ç¬”è®°æœ¬å’Œ arXiv è®ºæ–‡ä¸­è·å–æƒ³æ³•ï¼Œä»¥å¼•å…¥ç°å®ä¸–ç•Œç­–ç•¥ã€‚KompeteAI è¿˜é€šè¿‡é¢„æµ‹è¯„åˆ†æ¨¡å‹å’ŒåŠ é€Ÿè°ƒè¯•æ–¹æ³•è§£å†³äº†æ‰§è¡Œç“¶é¢ˆï¼Œåˆ©ç”¨æ—©æœŸé˜¶æ®µæŒ‡æ ‡è¯„ä¼°è§£å†³æ–¹æ¡ˆæ½œåŠ›ï¼Œé¿å…ä»£ä»·é«˜æ˜‚çš„å®Œæ•´ä»£ç æ‰§è¡Œã€‚è¯¥æ–¹æ³•ä½¿æµæ°´çº¿è¯„ä¼°åŠ é€Ÿäº† 6.9 å€ã€‚ KompeteAI åœ¨ä¸»è¦çš„ AutoML åŸºå‡† MLE-Bench ä¸Šæ¯”ç°æœ‰é¢†å…ˆæ–¹æ³•ï¼ˆä¾‹å¦‚ RD-agentã€AIDE å’Œ Ml-Masterï¼‰å¹³å‡é«˜å‡º 3%ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº† Kompete-bench æ¥è§£å†³ MLE-Bench çš„å±€é™æ€§ï¼Œåœ¨è¯¥åŸºå‡†ä¸Š KompeteAI ä¹Ÿè¾¾åˆ°äº†æœ€æ–°çš„æœ€ä¼˜ç»“æœã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 20:29:56 UTC
å‘å¸ƒï¼š2025-08-13 20:29:56 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="26-pruning-long-chain-of-thought-of-large-reasoning-models-via-small-scale-preference-optimization--26-é€šè¿‡å°è§„æ¨¡åå¥½ä¼˜åŒ–è£å‰ªå¤§å‹æ¨ç†æ¨¡å‹çš„é•¿é“¾å¼æ€ç»´chain-of-thought"><a href="https://arxiv.org/abs/2508.10164"target="_blank" rel="external nofollow noopener noreferrer">#26</a> <a href="https://papers.cool/arxiv/2508.10164"target="_blank" rel="external nofollow noopener noreferrer">Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization</a>  #26 é€šè¿‡å°è§„æ¨¡åå¥½ä¼˜åŒ–è£å‰ªå¤§å‹æ¨ç†æ¨¡å‹çš„é•¿é“¾å¼æ€ç»´ï¼ˆChain-of-Thoughtï¼‰</h2>
<p><strong>Authors</strong>: [Bin Hong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bin</a> Hong), [Jiayu Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiayu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiayu</a> Liu), [Zhenya Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenya</a> Huang), [Kai Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Zhang), [Mengdi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengdi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengdi</a> Zhang)
ä½œè€…ï¼šæ´ªå®¾ï¼Œåˆ˜ä½³ç‘œï¼Œé»„æŒ¯é›…ï¼Œå¼ å‡¯ï¼Œå¼ æ¢¦è¿ª</p>
<p>Recent advances in Large Reasoning Models (LRMs) have demonstrated strong performance on complex tasks through long Chain-of-Thought (CoT) reasoning. However, their lengthy outputs increase computational costs and may lead to overthinking, raising challenges in balancing reasoning effectiveness and efficiency. Current methods for efficient reasoning often compromise reasoning quality or require extensive resources. This paper investigates efficient methods to reduce the generation length of LRMs. We analyze generation path distributions and filter generated trajectories through difficulty estimation. Subsequently, we analyze the convergence behaviors of the objectives of various preference optimization methods under a Bradley-Terry loss based framework. Based on the analysis, we propose Length Controlled Preference Optimization (LCPO) that directly balances the implicit reward related to NLL loss. LCPO can effectively learn length preference with limited data and training. Extensive experiments demonstrate that our approach significantly reduces the average output length by over 50% across multiple benchmarks while maintaining the reasoning performance. Our work highlights the potential for computationally efficient approaches in guiding LRMs toward efficient reasoning.
æœ€è¿‘å¤§å‹æ¨ç†æ¨¡å‹ï¼ˆLRMï¼‰åœ¨é€šè¿‡é•¿é“¾å¼æ€ç»´ï¼ˆCoTï¼‰æ¨ç†å¤„ç†å¤æ‚ä»»åŠ¡æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚ç„¶è€Œï¼Œå®ƒä»¬å†—é•¿çš„è¾“å‡ºå¢åŠ äº†è®¡ç®—æˆæœ¬å¹¶å¯èƒ½å¯¼è‡´è¿‡åº¦æ€è€ƒï¼Œä»è€Œåœ¨æ¨ç†æ•ˆæœä¸æ•ˆç‡ä¹‹é—´å¸¦æ¥æŒ‘æˆ˜ã€‚å½“å‰çš„é«˜æ•ˆæ¨ç†æ–¹æ³•å¾€å¾€ç‰ºç‰²æ¨ç†è´¨é‡æˆ–éœ€è¦å¤§é‡èµ„æºã€‚æœ¬æ–‡ç ”ç©¶äº†é™ä½ LRM ç”Ÿæˆé•¿åº¦çš„é«˜æ•ˆæ–¹æ³•ã€‚æˆ‘ä»¬åˆ†æäº†ç”Ÿæˆè·¯å¾„åˆ†å¸ƒå¹¶é€šè¿‡éš¾åº¦ä¼°è®¡è¿‡æ»¤ç”Ÿæˆçš„è½¨è¿¹ã€‚éšåï¼Œæˆ‘ä»¬åœ¨åŸºäº Bradley-Terry æŸå¤±çš„æ¡†æ¶ä¸‹åˆ†æäº†å„ç§åå¥½ä¼˜åŒ–æ–¹æ³•ç›®æ ‡çš„æ”¶æ•›è¡Œä¸ºã€‚åŸºäºè¯¥åˆ†æï¼Œæˆ‘ä»¬æå‡ºäº†é•¿åº¦æ§åˆ¶åå¥½ä¼˜åŒ–ï¼ˆLCPOï¼‰ï¼Œç›´æ¥å¹³è¡¡ä¸ NLL æŸå¤±ç›¸å…³çš„éšå¼å¥–åŠ±ã€‚LCPO èƒ½å¤Ÿåœ¨æœ‰é™æ•°æ®å’Œè®­ç»ƒä¸‹æœ‰æ•ˆå­¦ä¹ é•¿åº¦åå¥½ã€‚å¤§é‡å®éªŒè¯æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ä¿æŒæ¨ç†æ€§èƒ½çš„åŒæ—¶ï¼Œå°†å¤šä¸ªåŸºå‡†ä¸Šçš„å¹³å‡è¾“å‡ºé•¿åº¦æ˜¾è‘—å‡å°‘äº†è¶…è¿‡ 50%ã€‚ æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†åœ¨å¼•å¯¼å¤§å‹è¯­è¨€æ¨¡å‹å®ç°é«˜æ•ˆæ¨ç†æ–¹é¢ï¼Œè®¡ç®—ä¸Šé«˜æ•ˆæ–¹æ³•çš„æ½œåŠ›ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 20:00:09 UTC
å‘å¸ƒï¼š2025-08-13 20:00:09 UTC</p>
<h2 id="27-improving-and-evaluating-open-deep-research-agents--27-æå‡ä¸è¯„ä¼°å¼€æ”¾å¼æ·±åº¦ç ”ç©¶ä»£ç†"><a href="https://arxiv.org/abs/2508.10152"target="_blank" rel="external nofollow noopener noreferrer">#27</a> <a href="https://papers.cool/arxiv/2508.10152"target="_blank" rel="external nofollow noopener noreferrer">Improving and Evaluating Open Deep Research Agents</a>  #27 æå‡ä¸è¯„ä¼°å¼€æ”¾å¼æ·±åº¦ç ”ç©¶ä»£ç†</h2>
<p><strong>Authors</strong>: [Doaa Allabadi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Doaa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Doaa</a> Allabadi), [Kyle Bradbury](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyle"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyle</a> Bradbury), [Jordan M. Malof](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jordan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jordan</a> M. Malof)
ä½œè€…ï¼šDoaa Allabadiã€Kyle Bradburyã€Jordan M. Malof</p>
<p>We focus here on Deep Research Agents (DRAs), which are systems that can take a natural language prompt from a user, and then autonomously search for, and utilize, internet-based content to address the prompt. Recent DRAs have demonstrated impressive capabilities on public benchmarks however, recent research largely involves proprietary closed-source systems. At the time of this work, we only found one open-source DRA, termed Open Deep Research (ODR). In this work we adapt the challenging recent BrowseComp benchmark to compare ODR to existing proprietary systems. We propose BrowseComp-Small (BC-Small), comprising a subset of BrowseComp, as a more computationally-tractable DRA benchmark for academic labs. We benchmark ODR and two other proprietary systems on BC-Small: one system from Anthropic and one system from Google. We find that all three systems achieve 0% accuracy on the test set of 60 questions. We introduce three strategic improvements to ODR, resulting in the ODR+ model, which achieves a state-of-the-art 10% success rate on BC-Small among both closed-source and open-source systems. We report ablation studies indicating that all three of our improvements contributed to the success of ODR+.
æˆ‘ä»¬åœ¨æ­¤å…³æ³¨æ·±åº¦ç ”ç©¶ä»£ç†ï¼ˆDeep Research Agentsï¼ŒDRAsï¼‰ï¼Œå³èƒ½å¤Ÿæ¥å—ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æç¤ºï¼Œç„¶åè‡ªä¸»åœ°æœç´¢å¹¶åˆ©ç”¨åŸºäºäº’è”ç½‘çš„å†…å®¹æ¥å›åº”è¯¥æç¤ºçš„ç³»ç»Ÿã€‚è¿‘æœŸçš„ DRAs åœ¨å…¬å¼€åŸºå‡†ä¸Šå±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œç„¶è€Œï¼Œè¿‘æœŸç ”ç©¶ä¸»è¦æ¶‰åŠä¸“æœ‰çš„é—­æºç³»ç»Ÿã€‚åœ¨æœ¬å·¥ä½œå¼€å±•æ—¶ï¼Œæˆ‘ä»¬åªæ‰¾åˆ°äº†ä¸€ç§å¼€æº DRAï¼Œç§°ä¸º Open Deep Researchï¼ˆODRï¼‰ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬å°†å…·æœ‰æŒ‘æˆ˜æ€§çš„æœ€æ–° BrowseComp åŸºå‡†è¿›è¡Œé€‚é…ï¼Œä»¥å°† ODR ä¸ç°æœ‰çš„ä¸“æœ‰ç³»ç»Ÿè¿›è¡Œæ¯”è¾ƒã€‚æˆ‘ä»¬æå‡ºäº† BrowseComp-Smallï¼ˆBC-Smallï¼‰ï¼Œå®ƒåŒ…å« BrowseComp çš„ä¸€ä¸ªå­é›†ï¼Œä½œä¸ºæ›´æ˜“äºå­¦æœ¯å®éªŒå®¤åœ¨è®¡ç®—ä¸Šå¤„ç†çš„ DRA åŸºå‡†ã€‚æˆ‘ä»¬åœ¨ BC-Small ä¸Šå¯¹ ODR å’Œå¦å¤–ä¸¤ç§ä¸“æœ‰ç³»ç»Ÿè¿›è¡Œäº†åŸºå‡†æµ‹è¯•ï¼šä¸€ä¸ªæ¥è‡ª Anthropic çš„ç³»ç»Ÿå’Œä¸€ä¸ªæ¥è‡ª Google çš„ç³»ç»Ÿã€‚æˆ‘ä»¬å‘ç°è¿™ä¸‰ç§ç³»ç»Ÿåœ¨ 60 é“é¢˜ç›®çš„æµ‹è¯•é›†ä¸Šéƒ½è¾¾åˆ°äº† 0%çš„å‡†ç¡®ç‡ã€‚æˆ‘ä»¬å¯¹ ODR å¼•å…¥äº†ä¸‰é¡¹ç­–ç•¥æ€§æ”¹è¿›ï¼Œå¾—åˆ° ODR+æ¨¡å‹ï¼Œåœ¨ BC-Small ä¸Šåœ¨é—­æºå’Œå¼€æºç³»ç»Ÿä¸­å–å¾—äº† 10%çš„æœ€å…ˆè¿›æˆåŠŸç‡ã€‚ æˆ‘ä»¬æŠ¥å‘Šäº†æ¶ˆèç ”ç©¶ï¼Œè¡¨æ˜æˆ‘ä»¬æå‡ºçš„ä¸‰é¡¹æ”¹è¿›éƒ½å¯¹ ODR+ çš„æˆåŠŸèµ·åˆ°äº†ä½œç”¨ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 19:32:01 UTC
å‘å¸ƒï¼š2025-08-13 19:32:01 ä¸–ç•Œåè°ƒæ—¶</p>
<h2 id="28-agentic-ai-frameworks-architectures-protocols-and-design-challenges--28-å…·ä»£ç†æ€§çš„äººå·¥æ™ºèƒ½æ¡†æ¶ä½“ç³»ç»“æ„åè®®ä¸è®¾è®¡æŒ‘æˆ˜"><a href="https://arxiv.org/abs/2508.10146"target="_blank" rel="external nofollow noopener noreferrer">#28</a> <a href="https://papers.cool/arxiv/2508.10146"target="_blank" rel="external nofollow noopener noreferrer">Agentic AI Frameworks: Architectures, Protocols, and Design Challenges</a>  #28 å…·ä»£ç†æ€§çš„äººå·¥æ™ºèƒ½æ¡†æ¶ï¼šä½“ç³»ç»“æ„ã€åè®®ä¸è®¾è®¡æŒ‘æˆ˜</h2>
<p><strong>Authors</strong>: [Hana Derouiche](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hana</a> Derouiche), [Zaki Brahmi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zaki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zaki</a> Brahmi), [Haithem Mazeni](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haithem"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haithem</a> Mazeni)
ä½œè€…ï¼šHana Derouicheã€Zaki Brahmiã€Haithem Mazeni</p>
<p>The emergence of Large Language Models (LLMs) has ushered in a transformative paradigm in artificial intelligence, Agentic AI, where intelligent agents exhibit goal-directed autonomy, contextual reasoning, and dynamic multi-agent coordination. This paper provides a systematic review and comparative analysis of leading Agentic AI frameworks, including CrewAI, LangGraph, AutoGen, Semantic Kernel, Agno, Google ADK, and MetaGPT, evaluating their architectural principles, communication mechanisms, memory management, safety guardrails, and alignment with service-oriented computing paradigms. Furthermore, we identify key limitations, emerging trends, and open challenges in the field. To address the issue of agent communication, we conduct an in-depth analysis of protocols such as the Contract Net Protocol (CNP), Agent-to-Agent (A2A), Agent Network Protocol (ANP), and Agora. Our findings not only establish a foundational taxonomy for Agentic AI systems but also propose future research directions to enhance scalability, robustness, and interoperability. This work serves as a comprehensive reference for researchers and practitioners working to advance the next generation of autonomous AI systems.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°å¼•å…¥äº†äººå·¥æ™ºèƒ½ä¸­çš„ä¸€ç§å˜é©æ€§èŒƒå¼â€”â€”ä¸»ä½“å‹äººå·¥æ™ºèƒ½ï¼ˆAgentic AIï¼‰ï¼Œå…¶ä¸­æ™ºèƒ½ä½“è¡¨ç°å‡ºä»¥ç›®æ ‡ä¸ºå¯¼å‘çš„è‡ªä¸»æ€§ã€æƒ…å¢ƒæ¨ç†ä»¥åŠåŠ¨æ€çš„å¤šæ™ºèƒ½ä½“ååŒã€‚æœ¬æ–‡å¯¹ä¸»è¦çš„ Agentic AI æ¡†æ¶è¿›è¡Œäº†ç³»ç»Ÿç»¼è¿°ä¸æ¯”è¾ƒåˆ†æï¼Œæ¶µç›– CrewAIã€LangGraphã€AutoGenã€Semantic Kernelã€Agnoã€Google ADK å’Œ MetaGPTï¼Œè¯„ä¼°å®ƒä»¬çš„ä½“ç³»æ¶æ„åŸåˆ™ã€é€šä¿¡æœºåˆ¶ã€è®°å¿†ç®¡ç†ã€å®‰å…¨æŠ¤æ ä»¥åŠä¸é¢å‘æœåŠ¡è®¡ç®—èŒƒå¼çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯†åˆ«äº†è¯¥é¢†åŸŸçš„å…³é”®å±€é™ã€å‡ºç°çš„è¶‹åŠ¿å’Œå¼€æ”¾æŒ‘æˆ˜ã€‚é’ˆå¯¹æ™ºèƒ½ä½“é€šä¿¡é—®é¢˜ï¼Œæˆ‘ä»¬æ·±å…¥åˆ†æäº†è¯¸å¦‚åˆçº¦ç½‘åè®®ï¼ˆContract Net Protocolï¼ŒCNPï¼‰ã€Agent-to-Agentï¼ˆA2Aï¼‰ã€Agent Network Protocolï¼ˆANPï¼‰å’Œ Agora ç­‰åè®®ã€‚æˆ‘ä»¬çš„ç ”ç©¶ä¸ä»…å»ºç«‹äº† Agentic AI ç³»ç»Ÿçš„åŸºç¡€åˆ†ç±»æ³•ï¼Œè¿˜æå‡ºäº†æœªæ¥ç ”ç©¶æ–¹å‘ï¼Œä»¥æå‡å¯æ‰©å±•æ€§ã€é²æ£’æ€§å’Œäº’æ“ä½œæ€§ã€‚ è¿™é¡¹å·¥ä½œä¸ºè‡´åŠ›äºæ¨è¿›ä¸‹ä¸€ä»£è‡ªä¸»äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„ç ”ç©¶äººå‘˜å’Œä»ä¸šè€…æä¾›äº†å…¨é¢çš„å‚è€ƒã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 19:16:18 UTC
å‘å¸ƒï¼š2025-08-13 19:16:18 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="29-mcp-orchestrated-multi-agent-system-for-automated-disinformation-detection--29-mcp-åè°ƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç”¨äºè‡ªåŠ¨åŒ–è™šå‡ä¿¡æ¯æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10143"target="_blank" rel="external nofollow noopener noreferrer">#29</a> <a href="https://papers.cool/arxiv/2508.10143"target="_blank" rel="external nofollow noopener noreferrer">MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection</a>  #29 MCP åè°ƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿç”¨äºè‡ªåŠ¨åŒ–è™šå‡ä¿¡æ¯æ£€æµ‹</h2>
<p><strong>Authors</strong>: [Alexandru-Andrei Avram](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexandru-Andrei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexandru-Andrei</a> Avram), [Adrian Groza](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Adrian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Adrian</a> Groza), [Alexandru Lecu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alexandru"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alexandru</a> Lecu)
ä½œè€…ï¼šAlexandru-Andrei Avramã€Adrian Grozaã€Alexandru Lecu</p>
<p>The large spread of disinformation across digital platforms creates significant challenges to information integrity. This paper presents a multi-agent system that uses relation extraction to detect disinformation in news articles, focusing on titles and short text snippets. The proposed Agentic AI system combines four agents: (i) a machine learning agent (logistic regression), (ii) a Wikipedia knowledge check agent (which relies on named entity recognition), (iii) a coherence detection agent (using LLM prompt engineering), and (iv) a web-scraped data analyzer that extracts relational triplets for fact checking. The system is orchestrated via the Model Context Protocol (MCP), offering shared context and live learning across components. Results demonstrate that the multi-agent ensemble achieves 95.3% accuracy with an F1 score of 0.964, significantly outperforming individual agents and traditional approaches. The weighted aggregation method, mathematically derived from individual agent misclassification rates, proves superior to algorithmic threshold optimization. The modular architecture makes the system easily scalable, while also maintaining details of the decision processes.
æ•°å­—å¹³å°ä¸Šè™šå‡ä¿¡æ¯çš„å¤§èŒƒå›´ä¼ æ’­å¯¹ä¿¡æ¯å®Œæ•´æ€§æ„æˆäº†é‡å¤§æŒ‘æˆ˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œé‡‡ç”¨å…³ç³»æŠ½å–æ¥æ£€æµ‹æ–°é—»æ–‡ç« ä¸­çš„è™šå‡ä¿¡æ¯ï¼Œé‡ç‚¹å…³æ³¨æ ‡é¢˜å’ŒçŸ­æ–‡æœ¬ç‰‡æ®µã€‚æ‰€æå‡ºçš„ Agentic AI ç³»ç»Ÿç»“åˆäº†å››ä¸ªæ™ºèƒ½ä½“ï¼šï¼ˆiï¼‰ä¸€ä¸ªæœºå™¨å­¦ä¹ æ™ºèƒ½ä½“ï¼ˆé€»è¾‘å›å½’ï¼‰ï¼Œï¼ˆiiï¼‰ä¸€ä¸ªç»´åŸºç™¾ç§‘çŸ¥è¯†æ ¸æŸ¥æ™ºèƒ½ä½“ï¼ˆä¾èµ–å‘½åå®ä½“è¯†åˆ«ï¼‰ï¼Œï¼ˆiiiï¼‰ä¸€ä¸ªä¸€è‡´æ€§æ£€æµ‹æ™ºèƒ½ä½“ï¼ˆä½¿ç”¨ LLM æç¤ºå·¥ç¨‹ï¼‰ï¼Œä»¥åŠï¼ˆivï¼‰ä¸€ä¸ªç½‘ç»œæŠ“å–æ•°æ®åˆ†æå™¨ï¼Œç”¨äºæå–å…³ç³»ä¸‰å…ƒç»„ä»¥è¿›è¡Œäº‹å®æ ¸æŸ¥ã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆModel Context Protocolï¼ŒMCPï¼‰è¿›è¡Œåè°ƒï¼Œæä¾›ç»„ä»¶é—´çš„å…±äº«ä¸Šä¸‹æ–‡å’Œå®æ—¶å­¦ä¹ ã€‚ç»“æœè¡¨æ˜ï¼Œå¤šæ™ºèƒ½ä½“é›†æˆå®ç°äº† 95.3%çš„å‡†ç¡®ç‡å’Œ 0.964 çš„ F1 åˆ†æ•°ï¼Œæ˜¾è‘—ä¼˜äºå•ä¸ªæ™ºèƒ½ä½“å’Œä¼ ç»Ÿæ–¹æ³•ã€‚åŸºäºä¸ªä½“æ™ºèƒ½ä½“è¯¯åˆ†ç±»ç‡æ•°å­¦æ¨å¯¼å‡ºçš„åŠ æƒèšåˆæ–¹æ³•ä¼˜äºç®—æ³•é˜ˆå€¼ä¼˜åŒ–ã€‚æ¨¡å—åŒ–æ¶æ„ä½¿ç³»ç»Ÿæ˜“äºæ‰©å±•ï¼ŒåŒæ—¶ä¿ç•™äº†å†³ç­–è¿‡ç¨‹çš„ç»†èŠ‚ã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 19:14:48 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-13 19:14:48 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="30-amazon-nova-ai-challenge---30-äºšé©¬é€Š-nova-ai-æŒ‘æˆ˜èµ›--å¯ä¿¡-aiæ¨è¿›å®‰å…¨çš„-ai-è¾…åŠ©è½¯ä»¶å¼€å‘"><a href="https://arxiv.org/abs/2508.10108"target="_blank" rel="external nofollow noopener noreferrer">#30</a> <a href="https://papers.cool/arxiv/2508.10108"target="_blank" rel="external nofollow noopener noreferrer">Amazon Nova AI Challenge &ndash; Trusted AI: Advancing secure, AI-assisted software development</a>  #30 äºšé©¬é€Š Nova AI æŒ‘æˆ˜èµ› &ndash; å¯ä¿¡ AIï¼šæ¨è¿›å®‰å…¨çš„ AI è¾…åŠ©è½¯ä»¶å¼€å‘</h2>
<p><strong>Authors</strong>: [Sattvik Sahai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sattvik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sattvik</a> Sahai), [Prasoon Goyal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prasoon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prasoon</a> Goyal), [Michael Johnston](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Johnston), [Anna Gottardi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anna</a> Gottardi), [Yao Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yao</a> Lu), [Lucy Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lucy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lucy</a> Hu), [Luke Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luke</a> Dai), [Shaohua Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaohua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaohua</a> Liu), [Samyuth Sagi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Samyuth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Samyuth</a> Sagi), [Hangjie Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hangjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hangjie</a> Shi), [Desheng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Desheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Desheng</a> Zhang), [Lavina Vaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lavina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lavina</a> Vaz), [Leslie Ball](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Leslie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Leslie</a> Ball), [Maureen Murray](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maureen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maureen</a> Murray), [Rahul Gupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rahul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rahul</a> Gupta), [Shankar Ananthakrishna](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shankar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shankar</a> Ananthakrishna)
ä½œè€…ï¼šSattvik Sahaiã€Prasoon Goyalã€Michael Johnstonã€Anna Gottardiã€Yao Luã€Lucy Huã€Luke Daiã€Shaohua Liuã€Samyuth Sagiã€Hangjie Shiã€Desheng Zhangã€Lavina Vazã€Leslie Ballã€Maureen Murrayã€Rahul Guptaã€Shankar Ananthakrishna</p>
<p>AI systems for software development are rapidly gaining prominence, yet significant challenges remain in ensuring their safety. To address this, Amazon launched the Trusted AI track of the Amazon Nova AI Challenge, a global competition among 10 university teams to drive advances in secure AI. In the challenge, five teams focus on developing automated red teaming bots, while the other five create safe AI assistants. This challenge provides teams with a unique platform to evaluate automated red-teaming and safety alignment methods through head-to-head adversarial tournaments where red teams have multi-turn conversations with the competing AI coding assistants to test their safety alignment. Along with this, the challenge provides teams with a feed of high quality annotated data to fuel iterative improvement. Throughout the challenge, teams developed state-of-the-art techniques, introducing novel approaches in reasoning-based safety alignment, robust model guardrails, multi-turn jail-breaking, and efficient probing of large language models (LLMs). To support these efforts, the Amazon Nova AI Challenge team made substantial scientific and engineering investments, including building a custom baseline coding specialist model for the challenge from scratch, developing a tournament orchestration service, and creating an evaluation harness. This paper outlines the advancements made by university teams and the Amazon Nova AI Challenge team in addressing the safety challenges of AI for software development, highlighting this collaborative effort to raise the bar for AI safety.
ç”¨äºè½¯ä»¶å¼€å‘çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿæ­£è¿…é€Ÿå´­éœ²å¤´è§’ï¼Œä½†åœ¨ç¡®ä¿å…¶å®‰å…¨æ€§æ–¹é¢ä»é¢ä¸´é‡å¤§æŒ‘æˆ˜ã€‚ä¸ºæ­¤ï¼Œäºšé©¬é€Šå‘èµ·äº† Amazon Nova AI Challenge çš„å¯ä¿¡ AI èµ›é“ï¼Œè¿™æ˜¯ä¸€ä¸ªç”± 10 æ”¯å¤§å­¦å›¢é˜Ÿå‚åŠ çš„å…¨çƒç«èµ›ï¼Œæ—¨åœ¨æ¨åŠ¨å®‰å…¨ AI çš„è¿›æ­¥ã€‚åœ¨è¯¥æŒ‘æˆ˜ä¸­ï¼Œäº”æ”¯é˜Ÿä¼ä¸“æ³¨äºå¼€å‘è‡ªåŠ¨åŒ–çº¢é˜Ÿæœºå™¨äººï¼Œå¦å¤–äº”æ”¯é˜Ÿä¼åˆ™åˆ›å»ºå®‰å…¨çš„ AI åŠ©æ‰‹ã€‚è¯¥æŒ‘æˆ˜ä¸ºå›¢é˜Ÿæä¾›äº†ä¸€ä¸ªç‹¬ç‰¹çš„å¹³å°ï¼Œé€šè¿‡å¯¹æŠ—æ€§é”¦æ ‡èµ›å¯¹è‡ªåŠ¨åŒ–çº¢é˜Ÿå’Œå®‰å…¨å¯¹é½æ–¹æ³•è¿›è¡Œè¯„ä¼°â€”â€”åœ¨é”¦æ ‡èµ›ä¸­ï¼Œçº¢é˜Ÿä¸å‚èµ›çš„ AI ç¼–ç åŠ©æ‰‹è¿›è¡Œå¤šå›åˆå¯¹è¯ï¼Œä»¥æµ‹è¯•å…¶å®‰å…¨å¯¹é½ã€‚æ­¤å¤–ï¼ŒæŒ‘æˆ˜è¿˜ä¸ºå›¢é˜Ÿæä¾›äº†ä¸€æ‰¹é«˜è´¨é‡çš„å¸¦æ³¨é‡Šæ•°æ®ï¼Œä»¥æ¨åŠ¨è¿­ä»£æ”¹è¿›ã€‚åœ¨æ•´ä¸ªæŒ‘æˆ˜è¿‡ç¨‹ä¸­ï¼Œå›¢é˜Ÿä»¬å¼€å‘äº†æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œæå‡ºäº†åœ¨åŸºäºæ¨ç†çš„å®‰å…¨å¯¹é½ã€ç¨³å¥çš„æ¨¡å‹æŠ¤æ ã€å¤šå›åˆè¶Šç‹±ä»¥åŠé«˜æ•ˆæ¢æµ‹å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) æ–¹é¢çš„æ–°æ–¹æ³•ã€‚ ä¸ºäº†æ”¯æŒè¿™äº›å·¥ä½œï¼ŒAmazon Nova AI Challenge å›¢é˜Ÿè¿›è¡Œäº†å¤§é‡çš„ç§‘å­¦ä¸å·¥ç¨‹æŠ•å…¥ï¼ŒåŒ…æ‹¬ä»é›¶æ„å»ºç”¨äºè¯¥æŒ‘æˆ˜çš„å®šåˆ¶åŸºçº¿ä»£ç ä¸“å®¶æ¨¡å‹ã€å¼€å‘é”¦æ ‡èµ›åè°ƒæœåŠ¡ä»¥åŠåˆ›å»ºè¯„ä¼°æŒ‚é’©ã€‚æœ¬æ–‡æ¦‚è¿°äº†å„å¤§å­¦å›¢é˜Ÿä¸ Amazon Nova AI Challenge å›¢é˜Ÿåœ¨è§£å†³é¢å‘è½¯ä»¶å¼€å‘çš„ AI å®‰å…¨æ€§æŒ‘æˆ˜æ–¹é¢å–å¾—çš„è¿›å±•ï¼Œå¼ºè°ƒäº†è¿™ä¸€æ—¨åœ¨æé«˜ AI å®‰å…¨æ ‡å‡†çš„åä½œåŠªåŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½ï¼Œè®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-13 18:04:01 UTC
å‘å¸ƒï¼š2025-08-13 18:04:01 UTC</p>
<h2 id="31-a-survey-of-optimization-modeling-meets-llms-progress-and-future-directions--31-ä¼˜åŒ–å»ºæ¨¡ä¸-llms-ç›¸é‡çš„ç»¼è¿°è¿›å±•ä¸æœªæ¥æ–¹å‘"><a href="https://arxiv.org/abs/2508.10047"target="_blank" rel="external nofollow noopener noreferrer">#31</a> <a href="https://papers.cool/arxiv/2508.10047"target="_blank" rel="external nofollow noopener noreferrer">A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions</a>  #31 ä¼˜åŒ–å»ºæ¨¡ä¸ LLMs ç›¸é‡çš„ç»¼è¿°ï¼šè¿›å±•ä¸æœªæ¥æ–¹å‘</h2>
<p><strong>Authors</strong>: [Ziyang Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziyang</a> Xiao), [Jingrong Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingrong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingrong</a> Xie), [Lilin Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lilin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lilin</a> Xu), [Shisi Guan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shisi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shisi</a> Guan), [Jingyan Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingyan</a> Zhu), [Xiongwei Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiongwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiongwei</a> Han), [Xiaojin Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaojin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaojin</a> Fu), [WingYin Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=WingYin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=WingYin</a> Yu), [Han Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Han"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Han</a> Wu), [Wei Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Shi), [Qingcan Kang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingcan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingcan</a> Kang), [Jiahui Duan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiahui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiahui</a> Duan), [Tao Zhong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tao</a> Zhong), [Mingxuan Yuan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingxuan</a> Yuan), [Jia Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia</a> Zeng), [Yuan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Wang), [Gang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gang</a> Chen), [Dongxiang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongxiang</a> Zhang)
ä½œè€…ï¼šè‚–å­é˜³ã€è°¢é™æ¦•ã€å¾ä¸½ç³ã€å…³æ€æ€ã€æœ±æ•¬è¨€ã€éŸ©é›„ä¼Ÿã€ä»˜æ™“æ´¥ã€ä½™è© æ©ï¼ˆWingYin Yu ä¿ç•™åŸåå¦‚ä¸ºä¸“æœ‰åè¯ï¼‰ã€å´ç¿°ã€çŸ³ä¼Ÿã€åº·åº†ç¿ã€æ®µä½³æ…§ã€é’Ÿæ¶›ã€è¢æ˜è½©ã€æ›¾å˜‰ã€ç‹æºã€é™ˆåˆšã€å¼ ä¸œç¿”</p>
<p>By virtue of its great utility in solving real-world problems, optimization modeling has been widely employed for optimal decision-making across various sectors, but it requires substantial expertise from operations research professionals. With the advent of large language models (LLMs), new opportunities have emerged to automate the procedure of mathematical modeling. This survey presents a comprehensive and timely review of recent advancements that cover the entire technical stack, including data synthesis and fine-tuning for the base model, inference frameworks, benchmark datasets, and performance evaluation. In addition, we conducted an in-depth analysis on the quality of benchmark datasets, which was found to have a surprisingly high error rate. We cleaned the datasets and constructed a new leaderboard with fair performance evaluation in terms of base LLM model and datasets. We also build an online portal that integrates resources of cleaned datasets, code and paper repository to benefit the community. Finally, we identify limitations in current methodologies and outline future research opportunities.
å‡­å€Ÿå…¶åœ¨è§£å†³ç°å®é—®é¢˜æ–¹é¢çš„å·¨å¤§å®ç”¨æ€§ï¼Œä¼˜åŒ–å»ºæ¨¡å·²è¢«å¹¿æ³›ç”¨äºå„ä¸ªé¢†åŸŸçš„æœ€ä¼˜å†³ç­–ï¼Œä½†è¿™éœ€è¦è¿ç­¹å­¦ä¸“ä¸šäººå‘˜è¾ƒé«˜çš„ä¸“ä¸šçŸ¥è¯†ã€‚éšç€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„å‡ºç°ï¼Œå‡ºç°äº†å°†æ•°å­¦å»ºæ¨¡è¿‡ç¨‹è‡ªåŠ¨åŒ–çš„æ–°æœºé‡ã€‚æœ¬ç»¼è¿°å¯¹æ¶µç›–æ•´ä¸ªæŠ€æœ¯æ ˆçš„æœ€æ–°è¿›å±•è¿›è¡Œäº†å…¨é¢è€ŒåŠæ—¶çš„è¯„è¿°ï¼ŒåŒ…æ‹¬ç”¨äºåŸºç¡€æ¨¡å‹çš„æ•°æ®åˆæˆä¸å¾®è°ƒã€æ¨ç†æ¡†æ¶ã€åŸºå‡†æ•°æ®é›†ä»¥åŠæ€§èƒ½è¯„ä¼°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹åŸºå‡†æ•°æ®é›†çš„è´¨é‡è¿›è¡Œäº†æ·±å…¥åˆ†æï¼Œå‘ç°å…¶é”™è¯¯ç‡å‡ºäººæ„æ–™åœ°é«˜ã€‚æˆ‘ä»¬æ¸…ç†äº†è¿™äº›æ•°æ®é›†ï¼Œå¹¶åœ¨åŸºç¡€ LLM æ¨¡å‹å’Œæ•°æ®é›†æ–¹é¢æ„å»ºäº†ä¸€ä¸ªå…·æœ‰å…¬å¹³æ€§èƒ½è¯„ä¼°çš„æ–°æ’è¡Œæ¦œã€‚æˆ‘ä»¬è¿˜å»ºç«‹äº†ä¸€ä¸ªåœ¨çº¿é—¨æˆ·ï¼Œæ•´åˆäº†å·²æ¸…ç†çš„æ•°æ®é›†ã€ä»£ç å’Œè®ºæ–‡èµ„æºï¼Œä»¥é€ ç¦ç¤¾åŒºã€‚æœ€åï¼Œæˆ‘ä»¬æŒ‡å‡ºäº†å½“å‰æ–¹æ³•çš„å±€é™æ€§å¹¶å‹¾å‹’äº†æœªæ¥çš„ç ”ç©¶æœºä¼šã€‚</p>
<p><strong>Subject</strong>: <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-12 06:55:33 UTC
å‘å¸ƒï¼š2025-08-12 06:55:33 UTC</p>
<h2 id="32-empirical-investigation-into-configuring-echo-state-networks-for-representative-benchmark-problem-domains--32-å¯¹é…ç½®å›å£°çŠ¶æ€ç½‘ç»œä»¥é€‚åº”å…·æœ‰ä»£è¡¨æ€§çš„åŸºå‡†é—®é¢˜é¢†åŸŸçš„å®è¯ç ”ç©¶"><a href="https://arxiv.org/abs/2508.10887"target="_blank" rel="external nofollow noopener noreferrer">#32</a> <a href="https://papers.cool/arxiv/2508.10887"target="_blank" rel="external nofollow noopener noreferrer">Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains</a>  #32 å¯¹é…ç½®å›å£°çŠ¶æ€ç½‘ç»œä»¥é€‚åº”å…·æœ‰ä»£è¡¨æ€§çš„åŸºå‡†é—®é¢˜é¢†åŸŸçš„å®è¯ç ”ç©¶</h2>
<p><strong>Authors</strong>: [Brooke R. Weborg](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Brooke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Brooke</a> R. Weborg), [Gursel Serpen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gursel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gursel</a> Serpen)
ä½œè€…ï¼šBrooke R. Weborgï¼ŒGursel Serpen</p>
<p>This paper examines Echo State Network, a reservoir computer, performance using four different benchmark problems, then proposes heuristics or rules of thumb for configuring the architecture, as well as the selection of parameters and their values, which are applicable to problems within the same domain, to help serve to fill the experience gap needed by those entering this field of study. The influence of various parameter selections and their value adjustments, as well as architectural changes made to an Echo State Network, a powerful recurrent neural network configured as a reservoir computer, can be challenging to fully comprehend without experience in the field, and even some hyperparameter optimization algorithms may have difficulty adjusting parameter values without proper manual selections made first. Therefore, it is imperative to understand the effects of parameters and their value selection on Echo State Network architecture performance for a successful build. Thus, to address the requirement for an extensive background in Echo State Network architecture, as well as examine how Echo State Network performance is affected with respect to variations in architecture, design, and parameter selection and values, a series of benchmark tasks representing different problem domains, including time series prediction, pattern generation, chaotic system prediction, and time series classification, were modeled and experimented on to show the impact on the performance of Echo State Network.
æœ¬æ–‡ä½¿ç”¨å››ä¸ªä¸åŒçš„åŸºå‡†é—®é¢˜æ¥æ£€éªŒå›å£°çŠ¶æ€ç½‘ç»œï¼ˆä¸€ç§æ°´åº“è®¡ç®—æœºï¼‰çš„æ€§èƒ½ï¼Œå¹¶æå‡ºç”¨äºé…ç½®æ¶æ„ä»¥åŠé€‰æ‹©å‚æ•°å’Œå…¶æ•°å€¼çš„å¯å‘å¼æ–¹æ³•æˆ–ç»éªŒæ³•åˆ™ï¼Œè¿™äº›æ–¹æ³•é€‚ç”¨äºåŒä¸€é¢†åŸŸå†…çš„é—®é¢˜ï¼Œæ—¨åœ¨å¸®åŠ©å¼¥è¡¥è¿›å…¥è¯¥ç ”ç©¶é¢†åŸŸè€…æ‰€éœ€çš„ç»éªŒå·®è·ã€‚å„ç§å‚æ•°é€‰æ‹©åŠå…¶æ•°å€¼è°ƒæ•´çš„å½±å“ï¼Œä»¥åŠå¯¹å›å£°çŠ¶æ€ç½‘ç»œè¿™ä¸€å¼ºå¤§é€’å½’ç¥ç»ç½‘ç»œï¼ˆé…ç½®ä¸ºæ°´åº“è®¡ç®—æœºï¼‰æ‰€åšçš„æ¶æ„æ”¹åŠ¨ï¼Œè‹¥æ— ç›¸å…³é¢†åŸŸç»éªŒï¼Œå¾€å¾€éš¾ä»¥å®Œå…¨ç†è§£ï¼Œå³ä¾¿ä¸€äº›è¶…å‚æ•°ä¼˜åŒ–ç®—æ³•åœ¨æ²¡æœ‰å…ˆè¡Œè¿›è¡Œé€‚å½“æ‰‹åŠ¨é€‰æ‹©çš„æƒ…å†µä¸‹ä¹Ÿå¯èƒ½éš¾ä»¥è°ƒæ•´å‚æ•°å€¼ã€‚å› æ­¤ï¼Œä¸ºäº†æˆåŠŸæ„å»ºå›å£°çŠ¶æ€ç½‘ç»œï¼Œç†è§£å‚æ•°åŠå…¶æ•°å€¼é€‰æ‹©å¯¹ç½‘ç»œæ€§èƒ½çš„å½±å“è‡³å…³é‡è¦ã€‚ å› æ­¤ï¼Œä¸ºäº†è§£å†³å¯¹å›å£°çŠ¶æ€ç½‘ç»œï¼ˆEcho State Networkï¼‰æ¶æ„éœ€å…·å¤‡å¹¿æ³›èƒŒæ™¯çŸ¥è¯†çš„è¦æ±‚ï¼Œå¹¶æ£€éªŒæ¶æ„ã€è®¾è®¡ä»¥åŠå‚æ•°é€‰æ‹©ä¸å–å€¼å˜åŒ–å¦‚ä½•å½±å“å›å£°çŠ¶æ€ç½‘ç»œçš„æ€§èƒ½ï¼Œä¸€ç³»åˆ—ä»£è¡¨ä¸åŒé—®é¢˜é¢†åŸŸçš„åŸºå‡†ä»»åŠ¡ï¼ˆåŒ…æ‹¬æ—¶é—´åºåˆ—é¢„æµ‹ã€æ¨¡å¼ç”Ÿæˆã€æ··æ²Œç³»ç»Ÿé¢„æµ‹å’Œæ—¶é—´åºåˆ—åˆ†ç±»ï¼‰è¢«å»ºæ¨¡å¹¶è¿›è¡Œäº†å®éªŒï¼Œä»¥å±•ç¤ºè¿™äº›å› ç´ å¯¹å›å£°çŠ¶æ€ç½‘ç»œæ€§èƒ½çš„å½±å“ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.NE"target="_blank" rel="external nofollow noopener noreferrer">Neural and Evolutionary Computing</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šç¥ç»ä¸è¿›åŒ–è®¡ç®—ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 17:55:47 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 17:55:47 åè°ƒä¸–ç•Œæ—¶ï¼ˆUTCï¼‰</p>
<h2 id="33-tooncomposer-streamlining-cartoon-production-with-generative-post-keyframing--33-tooncomposeré€šè¿‡ç”Ÿæˆå¼å…³é”®å¸§åæœŸç®€åŒ–å¡é€šåˆ¶ä½œ"><a href="https://arxiv.org/abs/2508.10881"target="_blank" rel="external nofollow noopener noreferrer">#33</a> <a href="https://papers.cool/arxiv/2508.10881"target="_blank" rel="external nofollow noopener noreferrer">ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing</a>  #33 ToonComposerï¼šé€šè¿‡ç”Ÿæˆå¼å…³é”®å¸§åæœŸç®€åŒ–å¡é€šåˆ¶ä½œ</h2>
<p><strong>Authors</strong>: [Lingen Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lingen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lingen</a> Li), [Guangzhi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guangzhi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guangzhi</a> Wang), [Zhaoyang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaoyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaoyang</a> Zhang), [Yaowei Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yaowei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yaowei</a> Li), [Xiaoyu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoyu</a> Li), [Qi Dou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qi</a> Dou), [Jinwei Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinwei</a> Gu), [Tianfan Xue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianfan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianfan</a> Xue), [Ying Shan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ying</a> Shan)
ä½œè€…ï¼šæå‡Œæ©ã€ç‹å¹¿å¿—ã€å¼ æ˜­é˜³ã€æè€€ä¼Ÿã€ææ™“å®‡ã€çª¦ç¦ã€é¡¾æ™‹ç»´ã€è–›å¤©å¸†ã€å•é¢–</p>
<p>Traditional cartoon and anime production involves keyframing, inbetweening, and colorization stages, which require intensive manual effort. Despite recent advances in AI, existing methods often handle these stages separately, leading to error accumulation and artifacts. For instance, inbetweening approaches struggle with large motions, while colorization methods require dense per-frame sketches. To address this, we introduce ToonComposer, a generative model that unifies inbetweening and colorization into a single post-keyframing stage. ToonComposer employs a sparse sketch injection mechanism to provide precise control using keyframe sketches. Additionally, it uses a cartoon adaptation method with the spatial low-rank adapter to tailor a modern video foundation model to the cartoon domain while keeping its temporal prior intact. Requiring as few as a single sketch and a colored reference frame, ToonComposer excels with sparse inputs, while also supporting multiple sketches at any temporal location for more precise motion control. This dual capability reduces manual workload and improves flexibility, empowering artists in real-world scenarios. To evaluate our model, we further created PKBench, a benchmark featuring human-drawn sketches that simulate real-world use cases. Our evaluation demonstrates that ToonComposer outperforms existing methods in visual quality, motion consistency, and production efficiency, offering a superior and more flexible solution for AI-assisted cartoon production.
ä¼ ç»Ÿå¡é€šå’ŒåŠ¨ç”»åˆ¶ä½œåŒ…æ‹¬å…³é”®å¸§ç»˜åˆ¶ã€è¡¥é—´ä»¥åŠä¸Šè‰²é˜¶æ®µï¼Œè¿™äº›ç¯èŠ‚éƒ½éœ€è¦å¤§é‡äººå·¥åŠ³åŠ¨ã€‚å°½ç®¡è¿‘å¹´æ¥äººå·¥æ™ºèƒ½å–å¾—äº†è¿›å±•ï¼Œç°æœ‰æ–¹æ³•é€šå¸¸å°†è¿™äº›é˜¶æ®µåˆ†åˆ«å¤„ç†ï¼Œå¯¼è‡´é”™è¯¯ç´¯ç§¯å’Œä¼ªå½±ã€‚ä¾‹å¦‚ï¼Œè¡¥é—´æ–¹æ³•åœ¨å¤„ç†å¤§å¹…è¿åŠ¨æ—¶è¡¨ç°ä¸ä½³ï¼Œè€Œä¸Šè‰²æ–¹æ³•åˆ™éœ€è¦å¯†é›†çš„é€å¸§è‰å›¾ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† ToonComposerï¼Œä¸€ç§å°†è¡¥é—´å’Œä¸Šè‰²ç»Ÿä¸€ä¸ºå•ä¸€åå…³é”®å¸§é˜¶æ®µçš„ç”Ÿæˆæ¨¡å‹ã€‚ToonComposer é‡‡ç”¨ç¨€ç–è‰å›¾æ³¨å…¥æœºåˆ¶ï¼Œä½¿ç”¨å…³é”®å¸§è‰å›¾æä¾›ç²¾ç¡®æ§åˆ¶ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜ä½¿ç”¨ä¸€ç§å¸¦æœ‰ç©ºé—´ä½ç§©é€‚é…å™¨çš„å¡é€šé€‚é…æ–¹æ³•ï¼Œå°†ç°ä»£è§†é¢‘åŸºç¡€æ¨¡å‹å®šåˆ¶åˆ°å¡é€šé¢†åŸŸï¼ŒåŒæ—¶ä¿æŒå…¶æ—¶é—´å…ˆéªŒä¸å˜ã€‚ä»…éœ€ä¸€å¼ è‰å›¾å’Œä¸€å¸§æœ‰è‰²å‚è€ƒå¸§ï¼ŒToonComposer å°±èƒ½åœ¨ç¨€ç–è¾“å…¥ä¸‹è¡¨ç°å‡ºè‰²ï¼ŒåŒæ—¶ä¹Ÿæ”¯æŒåœ¨ä»»æ„æ—¶é—´ä½ç½®æä¾›å¤šå¼ è‰å›¾ä»¥å®ç°æ›´ç²¾ç¡®çš„è¿åŠ¨æ§åˆ¶ã€‚è¿™ç§åŒé‡èƒ½åŠ›é™ä½äº†äººå·¥å·¥ä½œé‡å¹¶æé«˜äº†çµæ´»æ€§ï¼Œå¢å¼ºäº†è‰ºæœ¯å®¶åœ¨å®é™…åœºæ™¯ä¸­çš„åˆ›ä½œèƒ½åŠ›ã€‚ ä¸ºäº†è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜åˆ›å»ºäº† PKBenchï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«äººå·¥ç»˜åˆ¶ç´ æçš„åŸºå‡†ï¼Œæ¨¡æ‹ŸçœŸå®ä¸–ç•Œçš„ç”¨ä¾‹ã€‚æˆ‘ä»¬çš„è¯„ä¼°è¡¨æ˜ï¼ŒToonComposer åœ¨è§†è§‰è´¨é‡ã€åŠ¨ä½œä¸€è‡´æ€§å’Œç”Ÿäº§æ•ˆç‡æ–¹é¢å‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸º AI è¾…åŠ©åŠ¨ç”»åˆ¶ä½œæä¾›äº†æ›´ä¼˜è¶Šä¸”æ›´çµæ´»çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 17:50:11 UTC
å‘è¡¨ï¼š2025-08-14 17:50:11 UTC</p>
<h2 id="34-searching-for-privacy-risks-in-llm-agents-via-simulation--34-é€šè¿‡æ¨¡æ‹Ÿåœ¨-llm-agents-ä¸­æœç´¢éšç§é£é™©"><a href="https://arxiv.org/abs/2508.10880"target="_blank" rel="external nofollow noopener noreferrer">#34</a> <a href="https://papers.cool/arxiv/2508.10880"target="_blank" rel="external nofollow noopener noreferrer">Searching for Privacy Risks in LLM Agents via Simulation</a>  #34 é€šè¿‡æ¨¡æ‹Ÿåœ¨ LLM agents ä¸­æœç´¢éšç§é£é™©</h2>
<p><strong>Authors</strong>: [Yanzhe Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanzhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanzhe</a> Zhang), [Diyi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Diyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Diyi</a> Yang)
ä½œè€…ï¼šå¼ ç šå“², æ¨è¿ªæ€¡</p>
<p>The widespread deployment of LLM-based agents is likely to introduce a critical privacy threat: malicious agents that proactively engage others in multi-turn interactions to extract sensitive information. These dynamic dialogues enable adaptive attack strategies that can cause severe privacy violations, yet their evolving nature makes it difficult to anticipate and discover sophisticated vulnerabilities manually. To tackle this problem, we present a search-based framework that alternates between improving attacker and defender instructions by simulating privacy-critical agent interactions. Each simulation involves three roles: data subject, data sender, and data recipient. While the data subject&rsquo;s behavior is fixed, the attacker (data recipient) attempts to extract sensitive information from the defender (data sender) through persistent and interactive exchanges. To explore this interaction space efficiently, our search algorithm employs LLMs as optimizers, using parallel search with multiple threads and cross-thread propagation to analyze simulation trajectories and iteratively propose new instructions. Through this process, we find that attack strategies escalate from simple direct requests to sophisticated multi-turn tactics such as impersonation and consent forgery, while defenses advance from rule-based constraints to identity-verification state machines. The discovered attacks and defenses transfer across diverse scenarios and backbone models, demonstrating strong practical utility for building privacy-aware agents.
åŸºäº LLM çš„ä»£ç†çš„å¹¿æ³›éƒ¨ç½²å¾ˆå¯èƒ½å¼•å…¥ä¸€ä¸ªå…³é”®çš„éšç§å¨èƒï¼šæ¶æ„ä»£ç†é€šè¿‡ä¸»åŠ¨ä¸ä»–äººå±•å¼€å¤šè½®äº’åŠ¨æ¥æå–æ•æ„Ÿä¿¡æ¯ã€‚è¿™äº›åŠ¨æ€å¯¹è¯ä½¿å¾—æ”»å‡»ç­–ç•¥å¯ä»¥è‡ªé€‚åº”æ¼”è¿›ï¼Œä»è€Œé€ æˆä¸¥é‡çš„éšç§æ³„éœ²ï¼Œä½†å®ƒä»¬ä¸æ–­å˜åŒ–çš„ç‰¹æ€§ä¹Ÿä½¿å¾—æ‰‹åŠ¨é¢„è§å’Œå‘ç°å¤æ‚æ¼æ´å˜å¾—å›°éš¾ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåŸºäºæœç´¢çš„æ¡†æ¶ï¼Œé€šè¿‡æ¨¡æ‹Ÿæ¶‰åŠéšç§é£é™©çš„ä»£ç†äº¤äº’ï¼Œåœ¨æ”¹è¿›æ”»å‡»è€…å’Œé˜²å¾¡è€…æŒ‡ä»¤ä¹‹é—´äº¤æ›¿è¿­ä»£ã€‚æ¯æ¬¡æ¨¡æ‹ŸåŒ…å«ä¸‰ä¸ªè§’è‰²ï¼šæ•°æ®ä¸»ä½“ã€æ•°æ®å‘é€è€…å’Œæ•°æ®æ¥æ”¶è€…ã€‚è™½ç„¶æ•°æ®ä¸»ä½“çš„è¡Œä¸ºæ˜¯å›ºå®šçš„ï¼Œä½†æ”»å‡»è€…ï¼ˆæ•°æ®æ¥æ”¶è€…ï¼‰è¯•å›¾é€šè¿‡æŒä¹…ä¸”äº’åŠ¨çš„äº¤æµä»é˜²å¾¡è€…ï¼ˆæ•°æ®å‘é€è€…ï¼‰å¤„æå–æ•æ„Ÿä¿¡æ¯ã€‚ä¸ºäº†é«˜æ•ˆæ¢ç´¢è¿™ä¸€äº¤äº’ç©ºé—´ï¼Œæˆ‘ä»¬çš„æœç´¢ç®—æ³•å°† LLMs ç”¨ä½œä¼˜åŒ–å™¨ï¼Œä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œæœç´¢å’Œè·¨çº¿ç¨‹ä¼ æ’­æ¥åˆ†ææ¨¡æ‹Ÿè½¨è¿¹å¹¶è¿­ä»£åœ°æå‡ºæ–°æŒ‡ä»¤ã€‚ é€šè¿‡è¿™ä¸€è¿‡ç¨‹ï¼Œæˆ‘ä»¬å‘ç°æ”»å‡»ç­–ç•¥ä»ç®€å•çš„ç›´æ¥è¯·æ±‚å‡çº§ä¸ºå¤æ‚çš„å¤šè½®ç­–ç•¥ï¼Œä¾‹å¦‚å†’å……å’Œä¼ªé€ åŒæ„ï¼Œè€Œé˜²å¾¡åˆ™ä»åŸºäºè§„åˆ™çš„çº¦æŸå‘å±•ä¸ºèº«ä»½éªŒè¯çŠ¶æ€æœºã€‚æ‰€å‘ç°çš„æ”»å‡»å’Œé˜²å¾¡å¯è¿ç§»åˆ°ä¸åŒåœºæ™¯å’Œéª¨å¹²æ¨¡å‹ä¸­ï¼Œæ˜¾ç¤ºå‡ºåœ¨æ„å»ºéšç§æ„è¯†ä»£ç†æ–¹é¢å…·æœ‰å¾ˆå¼ºçš„å®ç”¨ä»·å€¼ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 17:49:09 UTC
å‘å¸ƒï¼š2025-08-14 17:49:09 UTC</p>
<h2 id="35-a-survey-on-diffusion-language-models--35-å…³äºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç»¼è¿°"><a href="https://arxiv.org/abs/2508.10875"target="_blank" rel="external nofollow noopener noreferrer">#35</a> <a href="https://papers.cool/arxiv/2508.10875"target="_blank" rel="external nofollow noopener noreferrer">A Survey on Diffusion Language Models</a>  #35 å…³äºæ‰©æ•£è¯­è¨€æ¨¡å‹çš„ç»¼è¿°</h2>
<p><strong>Authors</strong>: [Tianyi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyi</a> Li), [Mingda Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingda"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingda</a> Chen), [Bowei Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowei</a> Guo), [Zhiqiang Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiqiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiqiang</a> Shen)
ä½œè€…ï¼šæå¤©æ¯…ã€é™ˆæ˜è¾¾ã€éƒ­åšä¸ºã€æ²ˆå¿—å¼º</p>
<p>Diffusion Language Models (DLMs) are rapidly emerging as a powerful and promising alternative to the dominant autoregressive (AR) paradigm. By generating tokens in parallel through an iterative denoising process, DLMs possess inherent advantages in reducing inference latency and capturing bidirectional context, thereby enabling fine-grained control over the generation process. While achieving a several-fold speed-up, recent advancements have allowed DLMs to show performance comparable to their autoregressive counterparts, making them a compelling choice for various natural language processing tasks. In this survey, we provide a holistic overview of the current DLM landscape. We trace its evolution and relationship with other paradigms, such as autoregressive and masked language models, and cover both foundational principles and state-of-the-art models. Our work offers an up-to-date, comprehensive taxonomy and an in-depth analysis of current techniques, from pre-training strategies to advanced post-training methods. Another contribution of this survey is a thorough review of DLM inference strategies and optimizations, including improvements in decoding parallelism, caching mechanisms, and generation quality. We also highlight the latest approaches to multimodal extensions of DLMs and delineate their applications across various practical scenarios. Furthermore, our discussion addresses the limitations and challenges of DLMs, including efficiency, long-sequence handling, and infrastructure requirements, while outlining future research directions to sustain progress in this rapidly evolving field. Project GitHub is available at <a href="https://github.com/VILA-Lab/Awesome-DLMs"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/VILA-Lab/Awesome-DLMs</a>.
æ‰©æ•£è¯­è¨€æ¨¡å‹ï¼ˆDLMsï¼‰æ­£è¿…é€Ÿå´›èµ·ï¼Œæˆä¸ºå¯¹ä¸»å¯¼çš„è‡ªå›å½’ï¼ˆARï¼‰èŒƒå¼çš„ä¸€ç§å¼ºå¤§ä¸”æœ‰å‰æ™¯çš„æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡åœ¨è¿­ä»£å»å™ªè¿‡ç¨‹ä¸­å¹¶è¡Œç”Ÿæˆæ ‡è®°ï¼ŒDLMs åœ¨é™ä½æ¨ç†å»¶è¿Ÿå’Œæ•æ‰åŒå‘ä¸Šä¸‹æ–‡æ–¹é¢å…·å¤‡å›ºæœ‰ä¼˜åŠ¿ï¼Œä»è€Œå®ç°å¯¹ç”Ÿæˆè¿‡ç¨‹çš„ç²¾ç»†æ§åˆ¶ã€‚åœ¨å®ç°æ•°å€åŠ é€Ÿçš„åŒæ—¶ï¼Œæœ€è¿‘çš„è¿›å±•ä½¿å¾— DLMs çš„æ€§èƒ½å¯ä¸è‡ªå›å½’æ¨¡å‹ç›¸åª²ç¾ï¼Œä½¿å…¶æˆä¸ºå„ç§è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„æœ‰åŠ›é€‰æ‹©ã€‚åœ¨æœ¬ç»¼è¿°ä¸­ï¼Œæˆ‘ä»¬å¯¹å½“å‰çš„ DLM é¢†åŸŸæä¾›äº†ä¸€ä¸ªæ•´ä½“æ¦‚è§ˆã€‚æˆ‘ä»¬è¿½æº¯å…¶æ¼”åŒ–åŠä¸å…¶ä»–èŒƒå¼ï¼ˆå¦‚è‡ªå›å½’å’Œæ©ç è¯­è¨€æ¨¡å‹ï¼‰çš„å…³ç³»ï¼Œå¹¶æ¶µç›–äº†åŸºç¡€åŸç†ä¸æœ€å…ˆè¿›çš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„å·¥ä½œæä¾›äº†æœ€æ–°ã€å…¨é¢çš„åˆ†ç±»æ³•ï¼Œå¹¶å¯¹ä»é¢„è®­ç»ƒç­–ç•¥åˆ°å…ˆè¿›çš„åè®­ç»ƒæ–¹æ³•çš„å½“å‰æŠ€æœ¯è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚ æœ¬ç»¼è¿°çš„å¦ä¸€ä¸ªè´¡çŒ®æ˜¯å¯¹ DLM æ¨ç†ç­–ç•¥ä¸ä¼˜åŒ–çš„å…¨é¢å›é¡¾ï¼ŒåŒ…æ‹¬è§£ç å¹¶è¡Œæ€§ã€ç¼“å­˜æœºåˆ¶å’Œç”Ÿæˆè´¨é‡æ–¹é¢çš„æ”¹è¿›ã€‚æˆ‘ä»¬è¿˜é‡ç‚¹ä»‹ç»äº† DLM å¤šæ¨¡æ€æ‰©å±•çš„æœ€æ–°æ–¹æ³•ï¼Œå¹¶é˜æ˜äº†å®ƒä»¬åœ¨å„ç§å®é™…åœºæ™¯ä¸­çš„åº”ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬çš„è®¨è®ºè¿˜æ¶‰åŠ DLM çš„å±€é™æ€§å’ŒæŒ‘æˆ˜ï¼ŒåŒ…æ‹¬æ•ˆç‡ã€é•¿åºåˆ—å¤„ç†å’ŒåŸºç¡€è®¾æ–½éœ€æ±‚ï¼ŒåŒæ—¶å‹¾å‹’äº†åœ¨è¿™ä¸€å¿«é€Ÿå‘å±•çš„é¢†åŸŸä¸­ç»´æŒè¿›å±•çš„æœªæ¥ç ”ç©¶æ–¹å‘ã€‚é¡¹ç›® GitHub åœ°å€ä¸º <a href="https://github.com/VILA-Lab/Awesome-DLMs"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/VILA-Lab/Awesome-DLMs</a>ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 17:47:22 UTC
å‘å¸ƒï¼š2025-08-14 17:47:22 UTC</p>
<h2 id="36-tle-based-a2c-agent-for-terrestrial-coverage-orbital-path-planning--36-åŸºäº-tle-çš„-a2c-æ™ºèƒ½ä½“ç”¨äºåœ°é¢è¦†ç›–è½¨é“è·¯å¾„è§„åˆ’"><a href="https://arxiv.org/abs/2508.10872"target="_blank" rel="external nofollow noopener noreferrer">#36</a> <a href="https://papers.cool/arxiv/2508.10872"target="_blank" rel="external nofollow noopener noreferrer">TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning</a>  #36 åŸºäº TLE çš„ A2C æ™ºèƒ½ä½“ç”¨äºåœ°é¢è¦†ç›–è½¨é“è·¯å¾„è§„åˆ’</h2>
<p><strong>Authors</strong>: [Anantha Narayanan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anantha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anantha</a> Narayanan), [Battu Bhanu Teja](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Battu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Battu</a> Bhanu Teja), [Pruthwik Mishra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pruthwik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pruthwik</a> Mishra)
ä½œè€…ï¼šAnantha Narayananã€Battu Bhanu Tejaã€Pruthwik Mishra</p>
<p>The increasing congestion of Low Earth Orbit (LEO) poses persistent challenges to the efficient deployment and safe operation of Earth observation satellites. Mission planners must now account not only for mission-specific requirements but also for the increasing collision risk with active satellites and space debris. This work presents a reinforcement learning framework using the Advantage Actor-Critic (A2C) algorithm to optimize satellite orbital parameters for precise terrestrial coverage within predefined surface radii. By formulating the problem as a Markov Decision Process (MDP) within a custom OpenAI Gymnasium environment, our method simulates orbital dynamics using classical Keplerian elements. The agent progressively learns to adjust five of the orbital parameters - semi-major axis, eccentricity, inclination, right ascension of ascending node, and the argument of perigee-to achieve targeted terrestrial coverage. Comparative evaluation against Proximal Policy Optimization (PPO) demonstrates A2C&rsquo;s superior performance, achieving 5.8x higher cumulative rewards (10.0 vs 9.263025) while converging in 31.5x fewer timesteps (2,000 vs 63,000). The A2C agent consistently meets mission objectives across diverse target coordinates while maintaining computational efficiency suitable for real-time mission planning applications. Key contributions include: (1) a TLE-based orbital simulation environment incorporating physics constraints, (2) validation of actor-critic methods&rsquo; superiority over trust region approaches in continuous orbital control, and (3) demonstration of rapid convergence enabling adaptive satellite deployment. This approach establishes reinforcement learning as a computationally efficient alternative for scalable and intelligent LEO mission planning.
è¿‘åœ°è½¨é“ï¼ˆLEOï¼‰æ—¥ç›Šæ‹¥å µï¼Œå¯¹åœ°çƒè§‚æµ‹å«æ˜Ÿçš„é«˜æ•ˆéƒ¨ç½²å’Œå®‰å…¨è¿è¡Œæ„æˆæŒç»­æŒ‘æˆ˜ã€‚ä»»åŠ¡è§„åˆ’è€…ç°åœ¨ä¸ä»…å¿…é¡»è€ƒè™‘ä»»åŠ¡ç‰¹å®šéœ€æ±‚ï¼Œè¿˜è¦é¡¾åŠä¸åœ¨è½¨å«æ˜Ÿå’Œå¤ªç©ºç¢ç‰‡ç¢°æ’é£é™©çš„å¢åŠ ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¼ºåŒ–å­¦ä¹ æ¡†æ¶ï¼Œä½¿ç”¨ä¼˜åŠ¿æ¼”å‘˜-è¯„è®ºå®¶ï¼ˆA2Cï¼‰ç®—æ³•ä¼˜åŒ–å«æ˜Ÿè½¨é“å‚æ•°ï¼Œä»¥åœ¨é¢„å®šåœ°è¡¨åŠå¾„å†…å®ç°ç²¾å‡†çš„åœ°é¢è¦†ç›–ã€‚é€šè¿‡åœ¨è‡ªå®šä¹‰çš„ OpenAI Gymnasium ç¯å¢ƒä¸­å°†é—®é¢˜è¡¨è¿°ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹ï¼ˆMDPï¼‰ï¼Œæˆ‘ä»¬çš„æ–¹æ³•ä½¿ç”¨ç»å…¸çš„å¼€æ™®å‹’å…ƒç´ æ¨¡æ‹Ÿè½¨é“åŠ¨åŠ›å­¦ã€‚æ™ºèƒ½ä½“é€æ­¥å­¦ä¹ è°ƒæ•´äº”ä¸ªè½¨é“å‚æ•°â€”â€”åŠé•¿è½´ã€åå¿ƒç‡ã€å€¾è§’ã€å‡äº¤ç‚¹èµ¤ç»å’Œè¿‘åœ°ç‚¹å¹…è§’â€”â€”ä»¥å®ç°ç›®æ ‡åœ°é¢è¦†ç›–ã€‚ä¸è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–ï¼ˆPPOï¼‰çš„å¯¹æ¯”è¯„ä¼°è¡¨æ˜ï¼ŒA2C æ€§èƒ½æ›´ä¼˜ï¼Œç´¯è®¡å¥–åŠ±æé«˜äº† 5.8 å€ï¼ˆ10.0 vs 9.263025ï¼‰ï¼ŒåŒæ—¶åœ¨ 31.5 å€æ›´å°‘çš„æ—¶é—´æ­¥ä¸­æ”¶æ•›ï¼ˆ2,000 vs 63,000ï¼‰ã€‚ A2C æ™ºèƒ½ä½“åœ¨ä¸åŒç›®æ ‡åæ ‡ä¸‹å§‹ç»ˆå®Œæˆä»»åŠ¡ç›®æ ‡ï¼ŒåŒæ—¶ä¿æŒé€‚åˆå®æ—¶ä»»åŠ¡è§„åˆ’åº”ç”¨çš„è®¡ç®—æ•ˆç‡ã€‚ä¸»è¦è´¡çŒ®åŒ…æ‹¬ï¼š (1) åŸºäº TLE çš„è½¨é“ä»¿çœŸç¯å¢ƒï¼Œçº³å…¥ç‰©ç†çº¦æŸï¼Œ(2) éªŒè¯äº†åœ¨è¿ç»­è½¨é“æ§åˆ¶é—®é¢˜ä¸Š actor-critic æ–¹æ³•ä¼˜äºä¿¡èµ–åŸŸæ–¹æ³•ï¼Œ(3) å±•ç¤ºäº†å¿«é€Ÿæ”¶æ•›èƒ½åŠ›ï¼Œä½¿è‡ªé€‚åº”å«æ˜Ÿéƒ¨ç½²æˆä¸ºå¯èƒ½ã€‚è¯¥æ–¹æ³•ç¡®ç«‹äº†å¼ºåŒ–å­¦ä¹ ä½œä¸ºå¯æ‰©å±•ä¸”è®¡ç®—é«˜æ•ˆçš„ä½è½¨é“ä»»åŠ¡è§„åˆ’æ™ºèƒ½æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">Robotics</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨äººå­¦ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 17:44:51 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 17:44:51 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="37-medico-2025-visual-question-answering-for-gastrointestinal-imaging--37-medico-2025ç”¨äºèƒƒè‚ é“æˆåƒçš„è§†è§‰é—®ç­”"><a href="https://arxiv.org/abs/2508.10869"target="_blank" rel="external nofollow noopener noreferrer">#37</a> <a href="https://papers.cool/arxiv/2508.10869"target="_blank" rel="external nofollow noopener noreferrer">Medico 2025: Visual Question Answering for Gastrointestinal Imaging</a>  #37 Medico 2025ï¼šç”¨äºèƒƒè‚ é“æˆåƒçš„è§†è§‰é—®ç­”</h2>
<p><strong>Authors</strong>: [Sushant Gautam](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sushant"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sushant</a> Gautam), [Vajira Thambawita](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vajira"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vajira</a> Thambawita), [Michael Riegler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Riegler), [PÃ¥l Halvorsen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=P"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=P</a>Ã¥l Halvorsen), [Steven Hicks](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Steven"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Steven</a> Hicks)
ä½œè€…ï¼šSushant Gautamã€Vajira Thambawitaã€Michael Rieglerã€PÃ¥l Halvorsenã€Steven Hicks</p>
<p>The Medico 2025 challenge addresses Visual Question Answering (VQA) for Gastrointestinal (GI) imaging, organized as part of the MediaEval task series. The challenge focuses on developing Explainable Artificial Intelligence (XAI) models that answer clinically relevant questions based on GI endoscopy images while providing interpretable justifications aligned with medical reasoning. It introduces two subtasks: (1) answering diverse types of visual questions using the Kvasir-VQA-x1 dataset, and (2) generating multimodal explanations to support clinical decision-making. The Kvasir-VQA-x1 dataset, created from 6,500 images and 159,549 complex question-answer (QA) pairs, serves as the benchmark for the challenge. By combining quantitative performance metrics and expert-reviewed explainability assessments, this task aims to advance trustworthy Artificial Intelligence (AI) in medical image analysis. Instructions, data access, and an updated guide for participation are available in the official competition repository: <a href="https://github.com/simula/MediaEval-Medico-2025"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/simula/MediaEval-Medico-2025</a>
Medico 2025 æŒ‘æˆ˜å…³æ³¨èƒƒè‚ ï¼ˆGIï¼‰å½±åƒçš„è§†è§‰é—®ç­”ï¼ˆVQAï¼‰ï¼Œä½œä¸º MediaEval ä»»åŠ¡ç³»åˆ—çš„ä¸€éƒ¨åˆ†ç»„ç»‡ã€‚è¯¥æŒ‘æˆ˜ä¾§é‡äºå¼€å‘å¯è§£é‡Šçš„äººå·¥æ™ºèƒ½ï¼ˆXAIï¼‰æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹åœ¨åŸºäºèƒƒè‚ å†…é•œå›¾åƒå›ç­”ä¸´åºŠç›¸å…³é—®é¢˜çš„åŒæ—¶ï¼Œæä¾›ä¸åŒ»å­¦æ¨ç†ä¸€è‡´çš„å¯è§£é‡Šæ€§ç†ç”±ã€‚å®ƒå¼•å…¥äº†ä¸¤ä¸ªå­ä»»åŠ¡ï¼š (1) ä½¿ç”¨ Kvasir-VQA-x1 æ•°æ®é›†å›ç­”å¤šæ ·åŒ–ç±»å‹çš„è§†è§‰é—®é¢˜ï¼Œ(2) ç”Ÿæˆå¤šæ¨¡æ€è§£é‡Šä»¥æ”¯æŒä¸´åºŠå†³ç­–ã€‚Kvasir-VQA-x1 æ•°æ®é›†ç”± 6,500 å¼ å›¾åƒå’Œ 159,549 ä¸ªå¤æ‚çš„é—®ç­”ï¼ˆQAï¼‰å¯¹æ„æˆï¼Œä½œä¸ºæœ¬æ¬¡æŒ‘æˆ˜çš„åŸºå‡†ã€‚é€šè¿‡ç»“åˆé‡åŒ–æ€§èƒ½æŒ‡æ ‡å’Œä¸“å®¶å®¡æ ¸çš„å¯è§£é‡Šæ€§è¯„ä¼°ï¼Œè¯¥ä»»åŠ¡æ—¨åœ¨æ¨è¿›åŒ»ç–—å½±åƒåˆ†æä¸­å¯ä¿¡èµ–çš„äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ã€‚å‚èµ›è¯´æ˜ã€æ•°æ®è®¿é—®å’Œæ›´æ–°çš„å‚ä¸æŒ‡å—å¯åœ¨å®˜æ–¹ç«èµ›ä»£ç åº“è·å–ï¼š <a href="https://github.com/simula/MediaEval-Medico-2025"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/simula/MediaEval-Medico-2025</a></p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 17:43:46 UTC
å‘å¸ƒï¼š2025-08-14 17:43:46 UTC</p>
<h2 id="38-performance-of-gpt-5-in-brain-tumor-mri-reasoning--38-gpt-5-åœ¨è„‘è‚¿ç˜¤-mri-æ¨ç†ä¸­çš„è¡¨ç°"><a href="https://arxiv.org/abs/2508.10865"target="_blank" rel="external nofollow noopener noreferrer">#38</a> <a href="https://papers.cool/arxiv/2508.10865"target="_blank" rel="external nofollow noopener noreferrer">Performance of GPT-5 in Brain Tumor MRI Reasoning</a>  #38 GPT-5 åœ¨è„‘è‚¿ç˜¤ MRI æ¨ç†ä¸­çš„è¡¨ç°</h2>
<p><strong>Authors</strong>: [Mojtaba Safari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mojtaba"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mojtaba</a> Safari), [Shansong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shansong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shansong</a> Wang), [Mingzhe Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingzhe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingzhe</a> Hu), [Zach Eidex](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zach"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zach</a> Eidex), [Qiang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiang</a> Li), [Xiaofeng Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaofeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaofeng</a> Yang)
ä½œè€…ï¼šMojtaba Safariã€Shansong Wangã€Mingzhe Huã€Zach Eidexã€Qiang Liã€Xiaofeng Yang</p>
<p>Accurate differentiation of brain tumor types on magnetic resonance imaging (MRI) is critical for guiding treatment planning in neuro-oncology. Recent advances in large language models (LLMs) have enabled visual question answering (VQA) approaches that integrate image interpretation with natural language reasoning. In this study, we evaluated GPT-4o, GPT-5-nano, GPT-5-mini, and GPT-5 on a curated brain tumor VQA benchmark derived from 3 Brain Tumor Segmentation (BraTS) datasets - glioblastoma (GLI), meningioma (MEN), and brain metastases (MET). Each case included multi-sequence MRI triplanar mosaics and structured clinical features transformed into standardized VQA items. Models were assessed in a zero-shot chain-of-thought setting for accuracy on both visual and reasoning tasks. Results showed that GPT-5-mini achieved the highest macro-average accuracy (44.19%), followed by GPT-5 (43.71%), GPT-4o (41.49%), and GPT-5-nano (35.85%). Performance varied by tumor subtype, with no single model dominating across all cohorts. These findings suggest that GPT-5 family models can achieve moderate accuracy in structured neuro-oncological VQA tasks, but not at a level acceptable for clinical use.
åœ¨ç£å…±æŒ¯æˆåƒï¼ˆMRIï¼‰ä¸Šå¯¹è„‘è‚¿ç˜¤ç±»å‹è¿›è¡Œå‡†ç¡®åŒºåˆ†å¯¹äºç¥ç»è‚¿ç˜¤å­¦ä¸­çš„æ²»ç–—è®¡åˆ’åˆ¶å®šè‡³å…³é‡è¦ã€‚æœ€è¿‘å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„è¿›å±•å‚¬ç”Ÿäº†å°†å›¾åƒè§£è¯»ä¸è‡ªç„¶è¯­è¨€æ¨ç†ç›¸ç»“åˆçš„è§†è§‰é—®ç­”ï¼ˆVQAï¼‰æ–¹æ³•ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬åœ¨ä¸€ä¸ªä» 3 ä¸ªè„‘è‚¿ç˜¤åˆ†å‰²ï¼ˆBraTSï¼‰æ•°æ®é›†æ•´ç†çš„è„‘è‚¿ç˜¤ VQA åŸºå‡†ä¸Šè¯„ä¼°äº† GPT-4oã€GPT-5-nanoã€GPT-5-mini å’Œ GPT-5â€”â€”æ•°æ®é›†åŒ…å«èƒ¶è´¨æ¯ç»†èƒç˜¤ï¼ˆGLIï¼‰ã€è„‘è†œç˜¤ï¼ˆMENï¼‰å’Œè„‘è½¬ç§»ç˜¤ï¼ˆMETï¼‰ã€‚æ¯ä¸ªç—…ä¾‹åŒ…æ‹¬å¤šåºåˆ— MRI ä¸‰å¹³é¢æ‹¼æ¥å›¾åƒå’Œè¢«è½¬æ¢ä¸ºæ ‡å‡†åŒ– VQA é¡¹ç›®çš„ç»“æ„åŒ–ä¸´åºŠç‰¹å¾ã€‚æ¨¡å‹åœ¨é›¶æ ·æœ¬é“¾å¼æ€è€ƒï¼ˆzero-shot chain-of-thoughtï¼‰è®¾ç½®ä¸‹å¯¹è§†è§‰å’Œæ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§è¿›è¡Œäº†è¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºï¼ŒGPT-5-mini å–å¾—äº†æœ€é«˜çš„å®å¹³å‡å‡†ç¡®ç‡ï¼ˆ44.19%ï¼‰ï¼Œå…¶æ¬¡ä¸º GPT-5ï¼ˆ43.71%ï¼‰ã€GPT-4oï¼ˆ41.49%ï¼‰å’Œ GPT-5-nanoï¼ˆ35.85%ï¼‰ã€‚ä¸åŒè‚¿ç˜¤äºšå‹çš„è¡¨ç°å­˜åœ¨å·®å¼‚ï¼Œæ²¡æœ‰å•ä¸€æ¨¡å‹åœ¨æ‰€æœ‰é˜Ÿåˆ—ä¸­å‡å ä¸»å¯¼åœ°ä½ã€‚ è¿™äº›å‘ç°è¡¨æ˜ï¼ŒGPT-5 ç³»åˆ—æ¨¡å‹åœ¨ç»“æ„åŒ–ç¥ç»è‚¿ç˜¤å­¦è§†è§‰é—®ç­”ä»»åŠ¡ä¸­å¯ä»¥è¾¾åˆ°ä¸­ç­‰å‡†ç¡®ç‡ï¼Œä½†å°šæœªè¾¾åˆ°å¯ç”¨äºä¸´åºŠçš„æ°´å¹³ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 17:35:31 UTC
å‘å¸ƒï¼š2025-08-14 17:35:31 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="39-from-black-box-to-transparency-enhancing-automated-interpreting-assessment-with-explainable-ai-in-college-classrooms--39-ä»é»‘ç®±åˆ°é€æ˜åœ¨å¤§å­¦è¯¾å ‚ä¸­ç”¨å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºè‡ªåŠ¨å£è¯‘è¯„ä¼°"><a href="https://arxiv.org/abs/2508.10860"target="_blank" rel="external nofollow noopener noreferrer">#39</a> <a href="https://papers.cool/arxiv/2508.10860"target="_blank" rel="external nofollow noopener noreferrer">From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms</a>  #39 ä»é»‘ç®±åˆ°é€æ˜ï¼šåœ¨å¤§å­¦è¯¾å ‚ä¸­ç”¨å¯è§£é‡Šäººå·¥æ™ºèƒ½å¢å¼ºè‡ªåŠ¨å£è¯‘è¯„ä¼°</h2>
<p><strong>Authors</strong>: [Zhaokun Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhaokun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhaokun</a> Jiang), [Ziyin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziyin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziyin</a> Zhang)
ä½œè€…ï¼šè’‹æ˜­å¤ï¼Œå¼ å­é“¶</p>
<p>Recent advancements in machine learning have spurred growing interests in automated interpreting quality assessment. Nevertheless, existing research suffers from insufficient examination of language use quality, unsatisfactory modeling effectiveness due to data scarcity and imbalance, and a lack of efforts to explain model predictions. To address these gaps, we propose a multi-dimensional modeling framework that integrates feature engineering, data augmentation, and explainable machine learning. This approach prioritizes explainability over ``black box&rsquo;&rsquo; predictions by utilizing only construct-relevant, transparent features and conducting Shapley Value (SHAP) analysis. Our results demonstrate strong predictive performance on a novel English-Chinese consecutive interpreting dataset, identifying BLEURT and CometKiwi scores to be the strongest predictive features for fidelity, pause-related features for fluency, and Chinese-specific phraseological diversity metrics for language use. Overall, by placing particular emphasis on explainability, we present a scalable, reliable, and transparent alternative to traditional human evaluation, facilitating the provision of detailed diagnostic feedback for learners and supporting self-regulated learning advantages not afforded by automated scores in isolation.
è¿‘å¹´æ¥æœºå™¨å­¦ä¹ çš„è¿›å±•æ¿€å‘äº†å¯¹è‡ªåŠ¨å£è¯‘è´¨é‡è¯„ä¼°æ—¥ç›Šå¢é•¿çš„å…´è¶£ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶åœ¨è¯­è¨€è¿ç”¨è´¨é‡çš„è€ƒå¯Ÿä¸Šä¸è¶³ï¼Œå› æ•°æ®ç¨€ç¼ºä¸ä¸å¹³è¡¡å¯¼è‡´å»ºæ¨¡æ•ˆæœä¸ä½³ï¼Œä¸”ç¼ºä¹å¯¹æ¨¡å‹é¢„æµ‹çš„è§£é‡Šæ€§å·¥ä½œã€‚ä¸ºå¡«è¡¥è¿™äº›ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªé›†æˆç‰¹å¾å·¥ç¨‹ã€æ•°æ®å¢å¼ºä¸å¯è§£é‡Šæœºå™¨å­¦ä¹ çš„å¤šç»´å»ºæ¨¡æ¡†æ¶ã€‚è¯¥æ–¹æ³•åœ¨å¯è§£é‡Šæ€§ä¸Šä¼˜å…ˆäºâ€œé»‘ç®±â€é¢„æµ‹ï¼Œä»…ä½¿ç”¨ä¸æ„å¿µç›¸å…³çš„é€æ˜ç‰¹å¾å¹¶è¿›è¡Œ Shapley å€¼ï¼ˆSHAPï¼‰åˆ†æã€‚æˆ‘ä»¬çš„ç»“æœåœ¨ä¸€å¥—æ–°é¢–çš„è‹±ä¸­äº¤æ›¿ä¼ è¯‘æ•°æ®é›†ä¸Šè¡¨ç°å‡ºå¼ºåŠ²çš„é¢„æµ‹æ€§èƒ½ï¼Œå‘ç° BLEURT å’Œ CometKiwi åˆ†æ•°æ˜¯å¿ å®åº¦ï¼ˆfidelityï¼‰æœ€å¼ºçš„é¢„æµ‹ç‰¹å¾ï¼Œåœé¡¿ç›¸å…³ç‰¹å¾å¯¹æµåˆ©åº¦ï¼ˆfluencyï¼‰æœ€å…·é¢„æµ‹åŠ›ï¼Œè€Œä¸­æ–‡ç‰¹æœ‰çš„çŸ­è¯­å¤šæ ·æ€§åº¦é‡åˆ™å¯¹è¯­è¨€è¿ç”¨è´¨é‡æœ‰é‡è¦é¢„æµ‹ä½œç”¨ã€‚ æ€»çš„æ¥è¯´ï¼Œé€šè¿‡å¯¹å¯è§£é‡Šæ€§ç»™äºˆç‰¹åˆ«å…³æ³¨ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯æ‰©å±•ã€å¯é ä¸”é€æ˜çš„æ›¿ä»£ä¼ ç»Ÿäººå·¥è¯„ä¼°çš„æ–¹æ³•ï¼Œä¾¿äºä¸ºå­¦ä¹ è€…æä¾›è¯¦å°½çš„è¯Šæ–­æ€§åé¦ˆï¼Œå¹¶æ”¯æŒè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ çš„ä¼˜åŠ¿â€”â€”è¿™äº›ä¼˜åŠ¿ä»…é å•ç‹¬çš„è‡ªåŠ¨è¯„åˆ†æ— æ³•å®ç°ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 17:31:18 UTC
å‘å¸ƒï¼š2025-08-14 17:31:18 UTC</p>
<h2 id="40-reinforced-language-models-for-sequential-decision-making--40-å¼ºåŒ–è¯­è¨€æ¨¡å‹ç”¨äºåºåˆ—å†³ç­–åˆ¶å®š"><a href="https://arxiv.org/abs/2508.10839"target="_blank" rel="external nofollow noopener noreferrer">#40</a> <a href="https://papers.cool/arxiv/2508.10839"target="_blank" rel="external nofollow noopener noreferrer">Reinforced Language Models for Sequential Decision Making</a>  #40 å¼ºåŒ–è¯­è¨€æ¨¡å‹ç”¨äºåºåˆ—å†³ç­–åˆ¶å®š</h2>
<p><strong>Authors</strong>: [Jim Dilkes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jim</a> Dilkes), [Vahid Yazdanpanah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vahid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vahid</a> Yazdanpanah), [Sebastian Stein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sebastian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sebastian</a> Stein)
ä½œè€…ï¼šJim Dilkesã€Vahid Yazdanpanahã€Sebastian Stein</p>
<p>Large Language Models (LLMs) show potential as sequential decision-making agents, but their application is often limited due to a reliance on large, computationally expensive models. This creates a need to improve smaller models, yet existing post-training methods are designed for single-turn interactions and cannot handle credit assignment in multi-step agentic tasks. To address this, we introduce Multi-Step Group-Relative Policy Optimization (MS-GRPO), a new algorithm for post-training LLM agents, grounded in formal Text-Mediated Stochastic Game (TSMG) and Language-Agent Policy (LAP) frameworks. For credit assignment, MS-GRPO attributes the entire cumulative episode reward to each individual episode step. We supplement this algorithm with a novel absolute-advantage-weighted episode sampling strategy that we show improves training performance. We evaluate our approach by post-training a 3-billion parameter model on Snake and Frozen Lake. Our experiments demonstrate that the method is effective in improving decision-making performance: our post-trained 3B parameter model outperforms a 72B parameter baseline by 50% on the Frozen Lake task. This work demonstrates that targeted post-training is a practical and efficient alternative to relying on model scale for creating sequential decision-making agents using LLMs.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä½œä¸ºé¡ºåºå†³ç­–ä»£ç†è¡¨ç°å‡ºæ½œåŠ›ï¼Œä½†ç”±äºä¾èµ–å¤§è§„æ¨¡ã€è®¡ç®—å¼€é”€é«˜çš„æ¨¡å‹ï¼Œå…¶åº”ç”¨å¸¸å—é™ã€‚è¿™å°±éœ€è¦æ”¹è¿›è¾ƒå°çš„æ¨¡å‹ï¼Œç„¶è€Œç°æœ‰çš„è®­ç»ƒåæ–¹æ³•æ˜¯ä¸ºå•å›åˆäº¤äº’è®¾è®¡çš„ï¼Œæ— æ³•åœ¨å¤šæ­¥ä»£ç†ä»»åŠ¡ä¸­å¤„ç†è´£ä»»åˆ†é…ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šæ­¥ç»„ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–ï¼ˆMulti-Step Group-Relative Policy Optimizationï¼ŒMS-GRPOï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºè®­ç»ƒå LLM ä»£ç†çš„æ–°ç®—æ³•ï¼ŒåŸºäºå½¢å¼åŒ–çš„æ–‡æœ¬ä»‹å¯¼éšæœºåšå¼ˆï¼ˆText-Mediated Stochastic Gameï¼ŒTSMGï¼‰å’Œè¯­è¨€ä»£ç†ç­–ç•¥ï¼ˆLanguage-Agent Policyï¼ŒLAPï¼‰æ¡†æ¶ã€‚ä¸ºäº†è§£å†³è´£ä»»åˆ†é…é—®é¢˜ï¼ŒMS-GRPO å°†æ•´ä¸ªç´¯ç§¯å›åˆå¥–åŠ±å½’å› äºæ¯ä¸ªå•ç‹¬çš„å›åˆæ­¥éª¤ã€‚æˆ‘ä»¬ä¸ºè¯¥ç®—æ³•è¡¥å……äº†ä¸€ç§æ–°é¢–çš„ç»å¯¹ä¼˜åŠ¿åŠ æƒå›åˆé‡‡æ ·ç­–ç•¥ï¼Œæˆ‘ä»¬è¯æ˜è¯¥ç­–ç•¥èƒ½æ”¹å–„è®­ç»ƒæ€§èƒ½ã€‚æˆ‘ä»¬é€šè¿‡åœ¨ Snake å’Œ Frozen Lake ä¸Šå¯¹ä¸€ä¸ª 3 äº¿å‚æ•°æ¨¡å‹è¿›è¡Œè®­ç»ƒåæ¥è¯„ä¼°æˆ‘ä»¬çš„æ–¹æ³•ã€‚å®éªŒè¡¨æ˜è¯¥æ–¹æ³•åœ¨æå‡å†³ç­–æ€§èƒ½æ–¹é¢æœ‰æ•ˆï¼šæˆ‘ä»¬çš„è®­ç»ƒå 3B å‚æ•°æ¨¡å‹åœ¨ Frozen Lake ä»»åŠ¡ä¸Šæ¯”ä¸€ä¸ª 72B å‚æ•°çš„åŸºçº¿é«˜å‡º 50%ã€‚ è¿™é¡¹å·¥ä½œè¡¨æ˜ï¼Œæœ‰é’ˆå¯¹æ€§çš„åè®­ç»ƒæ˜¯ä½¿ç”¨ LLMs åˆ›å»ºåºè´¯å†³ç­–ä»£ç†æ—¶ï¼Œæ¯”ä¾èµ–æ¨¡å‹è§„æ¨¡æ›´å®ç”¨ä¸”æ›´é«˜æ•ˆçš„æ›¿ä»£æ–¹æ³•ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 17:05:44 UTC
å‘å¸ƒï¼š2025-08-14 17:05:44 UTC</p>
<h2 id="41-a-multimodal-neural-network-for-recognizing-subjective-self-disclosure-towards-social-robots--41-ä¸€ç§ç”¨äºè¯†åˆ«å¯¹ç¤¾äº¤æœºå™¨äººä¸»è§‚è‡ªæˆ‘æŠ«éœ²çš„å¤šæ¨¡æ€ç¥ç»ç½‘ç»œ"><a href="https://arxiv.org/abs/2508.10828"target="_blank" rel="external nofollow noopener noreferrer">#41</a> <a href="https://papers.cool/arxiv/2508.10828"target="_blank" rel="external nofollow noopener noreferrer">A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots</a>  #41 ä¸€ç§ç”¨äºè¯†åˆ«å¯¹ç¤¾äº¤æœºå™¨äººä¸»è§‚è‡ªæˆ‘æŠ«éœ²çš„å¤šæ¨¡æ€ç¥ç»ç½‘ç»œ</h2>
<p><strong>Authors</strong>: [Henry Powell](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Henry"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Henry</a> Powell), [Guy Laban](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guy</a> Laban), [Emily S. Cross](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emily"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emily</a> S. Cross)
ä½œè€…ï¼šHenry Powellã€Guy Labanã€Emily S. Cross</p>
<p>Subjective self-disclosure is an important feature of human social interaction. While much has been done in the social and behavioural literature to characterise the features and consequences of subjective self-disclosure, little work has been done thus far to develop computational systems that are able to accurately model it. Even less work has been done that attempts to model specifically how human interactants self-disclose with robotic partners. It is becoming more pressing as we require social robots to work in conjunction with and establish relationships with humans in various social settings. In this paper, our aim is to develop a custom multimodal attention network based on models from the emotion recognition literature, training this model on a large self-collected self-disclosure video corpus, and constructing a new loss function, the scale preserving cross entropy loss, that improves upon both classification and regression versions of this problem. Our results show that the best performing model, trained with our novel loss function, achieves an F1 score of 0.83, an improvement of 0.48 from the best baseline model. This result makes significant headway in the aim of allowing social robots to pick up on an interaction partner&rsquo;s self-disclosures, an ability that will be essential in social robots with social cognition.
ä¸»è§‚è‡ªæˆ‘æŠ«éœ²æ˜¯äººç±»ç¤¾äº¤äº’åŠ¨ä¸­çš„ä¸€é¡¹é‡è¦ç‰¹å¾ã€‚å°½ç®¡ç¤¾ä¼šä¸è¡Œä¸ºå­¦æ–‡çŒ®ä¸­å·²æœ‰å¤§é‡å·¥ä½œç”¨ä»¥åˆ»ç”»ä¸»è§‚è‡ªæˆ‘æŠ«éœ²çš„ç‰¹å¾ä¸åæœï¼Œä½†è¿„ä»Šä¸ºæ­¢é’ˆå¯¹èƒ½å¤Ÿå‡†ç¡®å»ºæ¨¡è¯¥ç‰¹å¾çš„è®¡ç®—ç³»ç»Ÿçš„ç ”ç©¶ç”šå°‘ã€‚å°¤å…¶æ˜¯ä¸“é—¨å°è¯•å»ºæ¨¡äººç±»äº¤äº’è€…å¦‚ä½•ä¸æœºå™¨äººä¼™ä¼´è¿›è¡Œè‡ªæˆ‘æŠ«éœ²çš„å·¥ä½œæ›´å°‘ã€‚éšç€æˆ‘ä»¬è¦æ±‚ç¤¾äº¤æœºå™¨äººåœ¨å„ç§ç¤¾äº¤åœºæ™¯ä¸­ä¸äººç±»ååŒå·¥ä½œå¹¶å»ºç«‹å…³ç³»ï¼Œè¿™ä¸€é—®é¢˜å˜å¾—æ„ˆå‘ç´§è¿«ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯åŸºäºæƒ…æ„Ÿè¯†åˆ«æ–‡çŒ®ä¸­çš„æ¨¡å‹å¼€å‘ä¸€ä¸ªå®šåˆ¶çš„å¤šæ¨¡æ€æ³¨æ„åŠ›ç½‘ç»œï¼Œå°†è¯¥æ¨¡å‹åœ¨æˆ‘ä»¬è‡ªè¡Œæ”¶é›†çš„å¤§è§„æ¨¡è‡ªæˆ‘æŠ«éœ²è§†é¢‘è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶æ„å»ºä¸€ç§æ–°çš„æŸå¤±å‡½æ•°â€”â€”å°ºåº¦ä¿æŒäº¤å‰ç†µæŸå¤±ï¼Œè¯¥æŸå¤±åœ¨åˆ†ç±»å’Œå›å½’ç‰ˆæœ¬çš„é—®é¢˜ä¸Šå‡æœ‰æ”¹è¿›ã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ï¼Œä½¿ç”¨æˆ‘ä»¬æ–°é¢–æŸå¤±å‡½æ•°è®­ç»ƒçš„æœ€ä½³æ¨¡å‹å–å¾—äº† 0.83 çš„ F1 å¾—åˆ†ï¼Œæ¯”æœ€ä½³åŸºçº¿æ¨¡å‹æå‡äº† 0.48ã€‚ è¿™ä¸€ç»“æœåœ¨å®ç°è®©ç¤¾äº¤æœºå™¨äººå¯Ÿè§‰äº’åŠ¨å¯¹è±¡è‡ªæˆ‘æŠ«éœ²çš„ç›®æ ‡ä¸Šå–å¾—äº†é‡è¦è¿›å±•ï¼Œè€Œè¿™ç§èƒ½åŠ›å¯¹äºå…·å¤‡ç¤¾ä¼šè®¤çŸ¥çš„ç¤¾äº¤æœºå™¨äººå°†æ˜¯å¿…ä¸å¯å°‘çš„ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">Robotics</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨äººå­¦ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 16:50:51 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 16:50:51 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="42-the-set-perceptual-factors-framework-towards-assured-perception-for-autonomous-systems--42-set-æ„ŸçŸ¥å› ç´ æ¡†æ¶è¿ˆå‘è‡ªä¸»ç³»ç»Ÿçš„å¯é æ„ŸçŸ¥"><a href="https://arxiv.org/abs/2508.10798"target="_blank" rel="external nofollow noopener noreferrer">#42</a> <a href="https://papers.cool/arxiv/2508.10798"target="_blank" rel="external nofollow noopener noreferrer">The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems</a>  #42 ã€ŠSET æ„ŸçŸ¥å› ç´ æ¡†æ¶ï¼šè¿ˆå‘è‡ªä¸»ç³»ç»Ÿçš„å¯é æ„ŸçŸ¥ã€‹</h2>
<p><strong>Author</strong>: [Troi Williams](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Troi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Troi</a> Williams) ä½œè€…ï¼šTroi Williams</p>
<p>Future autonomous systems promise significant societal benefits, yet their deployment raises concerns about safety and trustworthiness. A key concern is assuring the reliability of robot perception, as perception seeds safe decision-making. Failures in perception are often due to complex yet common environmental factors and can lead to accidents that erode public trust. To address this concern, we introduce the SET (Self, Environment, and Target) Perceptual Factors Framework. We designed the framework to systematically analyze how factors such as weather, occlusion, or sensor limitations negatively impact perception. To achieve this, the framework employs SET State Trees to categorize where such factors originate and SET Factor Trees to model how these sources and factors impact perceptual tasks like object detection or pose estimation. Next, we develop Perceptual Factor Models using both trees to quantify the uncertainty for a given task. Our framework aims to promote rigorous safety assurances and cultivate greater public understanding and trust in autonomous systems by offering a transparent and standardized method for identifying, modeling, and communicating perceptual risks.
æœªæ¥çš„è‡ªä¸»ç³»ç»Ÿå°†ä¸ºç¤¾ä¼šå¸¦æ¥æ˜¾è‘—ç›Šå¤„ï¼Œä½†å…¶éƒ¨ç½²ä¹Ÿå¼•å‘äº†å…³äºå®‰å…¨æ€§å’Œå¯ä¿¡åº¦çš„æ‹…å¿§ã€‚ä¸€ä¸ªå…³é”®é—®é¢˜æ˜¯å¦‚ä½•ä¿è¯æœºå™¨äººæ„ŸçŸ¥çš„å¯é æ€§ï¼Œå› ä¸ºæ„ŸçŸ¥æ˜¯å®‰å…¨å†³ç­–çš„åŸºç¡€ã€‚æ„ŸçŸ¥å¤±è´¥é€šå¸¸ç”±å¤æ‚ä½†å¸¸è§çš„ç¯å¢ƒå› ç´ é€ æˆï¼Œå¹¶å¯èƒ½å¯¼è‡´ä¾µèš€å…¬ä¼—ä¿¡ä»»çš„äº‹æ•…ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† SETï¼ˆè‡ªä½“ã€ç¯å¢ƒä¸ç›®æ ‡ï¼‰æ„ŸçŸ¥å› å­æ¡†æ¶ã€‚æˆ‘ä»¬è®¾è®¡è¯¥æ¡†æ¶ä»¥ç³»ç»Ÿæ€§åœ°åˆ†æè¯¸å¦‚å¤©æ°”ã€é®æŒ¡æˆ–ä¼ æ„Ÿå™¨é™åˆ¶ç­‰å› å­å¦‚ä½•è´Ÿé¢å½±å“æ„ŸçŸ¥ã€‚ä¸ºæ­¤ï¼Œæ¡†æ¶é‡‡ç”¨ SET çŠ¶æ€æ ‘æ¥åˆ†ç±»è¿™äº›å› å­èµ·æºçš„ä½ç½®ï¼Œå¹¶ä½¿ç”¨ SET å› å­æ ‘æ¥å»ºæ¨¡è¿™äº›æ¥æºå’Œå› å­å¦‚ä½•å½±å“è¯¸å¦‚ç›®æ ‡æ£€æµ‹æˆ–ä½å§¿ä¼°è®¡ä¹‹ç±»çš„æ„ŸçŸ¥ä»»åŠ¡ã€‚æ¥ç€ï¼Œæˆ‘ä»¬åˆ©ç”¨è¿™ä¸¤ç±»æ ‘æ„å»ºæ„ŸçŸ¥å› å­æ¨¡å‹ï¼Œä»¥é‡åŒ–ç»™å®šä»»åŠ¡çš„ä¸ç¡®å®šæ€§ã€‚æˆ‘ä»¬çš„æ¡†æ¶æ—¨åœ¨é€šè¿‡æä¾›ä¸€ç§é€æ˜ä¸”æ ‡å‡†åŒ–çš„æ–¹æ³•æ¥è¯†åˆ«ã€å»ºæ¨¡å’Œæ²Ÿé€šæ„ŸçŸ¥é£é™©ï¼Œä»è€Œä¿ƒè¿›ä¸¥æ ¼çš„å®‰å…¨ä¿éšœå¹¶åŸ¹å…»å…¬ä¼—å¯¹è‡ªä¸»ç³»ç»Ÿçš„æ›´é«˜ç†è§£ä¸ä¿¡ä»»ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">Robotics</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨äººå­¦ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 16:22:01 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 16:22:01 UTC</p>
<h2 id="43-enhancing-fairness-in-autoencoders-for-node-level-graph-anomaly-detection--43-åœ¨ç”¨äºèŠ‚ç‚¹çº§å›¾å¼‚å¸¸æ£€æµ‹çš„è‡ªç¼–ç å™¨ä¸­æå‡å…¬å¹³æ€§"><a href="https://arxiv.org/abs/2508.10785"target="_blank" rel="external nofollow noopener noreferrer">#43</a> <a href="https://papers.cool/arxiv/2508.10785"target="_blank" rel="external nofollow noopener noreferrer">Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection</a>  #43 åœ¨ç”¨äºèŠ‚ç‚¹çº§å›¾å¼‚å¸¸æ£€æµ‹çš„è‡ªç¼–ç å™¨ä¸­æå‡å…¬å¹³æ€§</h2>
<p><strong>Authors</strong>: [Shouju Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shouju"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shouju</a> Wang), [Yuchen Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuchen</a> Song), [Sheng&rsquo;en Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sheng%27en"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sheng'en</a> Li), [Dongmian Zou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongmian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongmian</a> Zou)
ä½œè€…ï¼šç‹å®ˆèšï¼Œå®‹å®‡æ™¨ï¼Œæåœ£æ©ï¼Œé‚¹ä¸œç¼ª</p>
<p>Graph anomaly detection (GAD) has become an increasingly important task across various domains. With the rapid development of graph neural networks (GNNs), GAD methods have achieved significant performance improvements. However, fairness considerations in GAD remain largely underexplored. Indeed, GNN-based GAD models can inherit and amplify biases present in training data, potentially leading to unfair outcomes. While existing efforts have focused on developing fair GNNs, most approaches target node classification tasks, where models often rely on simple layer architectures rather than autoencoder-based structures, which are the most widely used architecturs for anomaly detection. To address fairness in autoencoder-based GAD models, we propose \textbf{D}is\textbf{E}ntangled \textbf{C}ounterfactual \textbf{A}dversarial \textbf{F}air (DECAF)-GAD, a framework that alleviates bias while preserving GAD performance. Specifically, we introduce a structural causal model (SCM) to disentangle sensitive attributes from learned representations. Based on this causal framework, we formulate a specialized autoencoder architecture along with a fairness-guided loss function. Through extensive experiments on both synthetic and real-world datasets, we demonstrate that DECAF-GAD not only achieves competitive anomaly detection performance but also significantly enhances fairness metrics compared to baseline GAD methods. Our code is available at <a href="https://github.com/Tlhey/decaf_code"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Tlhey/decaf_code</a>.
å›¾å¼‚å¸¸æ£€æµ‹ï¼ˆGADï¼‰å·²æˆä¸ºå¤šä¸ªé¢†åŸŸä¸­æ—¥ç›Šé‡è¦çš„ä»»åŠ¡ã€‚éšç€å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰çš„å¿«é€Ÿå‘å±•ï¼ŒGAD æ–¹æ³•åœ¨æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ã€‚ç„¶è€Œï¼ŒGAD ä¸­çš„å…¬å¹³æ€§é—®é¢˜ä»ç„¶åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šæœªè¢«å……åˆ†æ¢è®¨ã€‚å®é™…ä¸Šï¼ŒåŸºäº GNN çš„ GAD æ¨¡å‹å¯èƒ½ä¼šç»§æ‰¿å¹¶æ”¾å¤§è®­ç»ƒæ•°æ®ä¸­å­˜åœ¨çš„åè§ï¼Œä»è€Œå¯èƒ½å¯¼è‡´ä¸å…¬å¹³çš„ç»“æœã€‚å°½ç®¡ç°æœ‰å·¥ä½œä¾§é‡äºå¼€å‘å…¬å¹³çš„ GNNï¼Œå¤§å¤šæ•°æ–¹æ³•é’ˆå¯¹çš„æ˜¯èŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡ï¼Œåœ¨è¿™äº›ä»»åŠ¡ä¸­æ¨¡å‹é€šå¸¸ä¾èµ–äºç®€å•çš„å±‚çº§æ¶æ„ï¼Œè€Œä¸æ˜¯ç”¨äºå¼‚å¸¸æ£€æµ‹ä¸­æœ€å¹¿æ³›ä½¿ç”¨çš„åŸºäºè‡ªç¼–ç å™¨çš„ç»“æ„ã€‚ä¸ºäº†è§£å†³åŸºäºè‡ªç¼–ç å™¨çš„ GAD æ¨¡å‹ä¸­çš„å…¬å¹³æ€§é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† DisEntangled Counterfactual Adversarial Fairï¼ˆDECAFï¼‰-GAD æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åœ¨ç¼“è§£åè§çš„åŒæ—¶ä¿æŒ GAD æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬å¼•å…¥äº†ç»“æ„å› æœæ¨¡å‹ï¼ˆSCMï¼‰ä»¥å°†æ•æ„Ÿå±æ€§ä»å­¦ä¹ åˆ°çš„è¡¨ç¤ºä¸­è§£è€¦ã€‚åŸºäºè¯¥å› æœæ¡†æ¶ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªä¸“é—¨çš„è‡ªç¼–ç å™¨æ¶æ„ä»¥åŠä¸€ä¸ªä»¥å…¬å¹³æ€§ä¸ºå¯¼å‘çš„æŸå¤±å‡½æ•°ã€‚ é€šè¿‡åœ¨åˆæˆæ•°æ®é›†å’ŒçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œå¤§é‡å®éªŒï¼Œæˆ‘ä»¬è¯æ˜äº† DECAF-GAD ä¸ä»…åœ¨å¼‚å¸¸æ£€æµ‹æ€§èƒ½ä¸Šå…·æœ‰ç«äº‰åŠ›ï¼Œè€Œä¸”åœ¨å…¬å¹³æ€§æŒ‡æ ‡æ–¹é¢ç›¸æ¯”åŸºçº¿ GAD æ–¹æ³•æœ‰æ˜¾è‘—æå‡ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ <a href="https://github.com/Tlhey/decaf_code"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Tlhey/decaf_code</a> è·å–ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 16:12:15 UTC
å‘å¸ƒï¼š2025-08-14 16:12:15 UTC</p>
<h2 id="44-ultra-high-definition-reference-based-landmark-image-super-resolution-with-generative-diffusion-prior--44-åŸºäºå‚è€ƒçš„è¶…é«˜æ¸…åœ°æ ‡å›¾åƒè¶…åˆ†è¾¨ç‡é‡‡ç”¨ç”Ÿæˆæ‰©æ•£å…ˆéªŒ"><a href="https://arxiv.org/abs/2508.10779"target="_blank" rel="external nofollow noopener noreferrer">#44</a> <a href="https://papers.cool/arxiv/2508.10779"target="_blank" rel="external nofollow noopener noreferrer">Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior</a>  #44 åŸºäºå‚è€ƒçš„è¶…é«˜æ¸…åœ°æ ‡å›¾åƒè¶…åˆ†è¾¨ç‡ï¼Œé‡‡ç”¨ç”Ÿæˆæ‰©æ•£å…ˆéªŒ</h2>
<p><strong>Authors</strong>: [Zhenning Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenning"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenning</a> Shi), [Zizheng Yan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zizheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zizheng</a> Yan), [Yuhang Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhang</a> Yu), [Clara Xue](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Clara"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Clara</a> Xue), [Jingyu Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingyu</a> Zhuang), [Qi Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qi</a> Zhang), [Jinwei Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinwei</a> Chen), [Tao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tao</a> Li), [Qingnan Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingnan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingnan</a> Fan)
ä½œè€…ï¼šçŸ³æŒ¯å®ã€é˜å­æ”¿ã€äºå®‡èˆªã€è–›å…‹æ‹‰ã€åº„é™å®‡ã€å¼ ç¦ã€é™ˆé‡‘ä¼Ÿã€ææ¶›ã€èŒƒé’æ¥ </p>
<p>Reference-based Image Super-Resolution (RefSR) aims to restore a low-resolution (LR) image by utilizing the semantic and texture information from an additional reference high-resolution (reference HR) image. Existing diffusion-based RefSR methods are typically built upon ControlNet, which struggles to effectively align the information between the LR image and the reference HR image. Moreover, current RefSR datasets suffer from limited resolution and poor image quality, resulting in the reference images lacking sufficient fine-grained details to support high-quality restoration. To overcome the limitations above, we propose TriFlowSR, a novel framework that explicitly achieves pattern matching between the LR image and the reference HR image. Meanwhile, we introduce Landmark-4K, the first RefSR dataset for Ultra-High-Definition (UHD) landmark scenarios. Considering the UHD scenarios with real-world degradation, in TriFlowSR, we design a Reference Matching Strategy to effectively match the LR image with the reference HR image. Experimental results show that our approach can better utilize the semantic and texture information of the reference HR image compared to previous methods. To the best of our knowledge, we propose the first diffusion-based RefSR pipeline for ultra-high definition landmark scenarios under real-world degradation. Our code and model will be available at <a href="https://github.com/nkicsl/TriFlowSR"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/nkicsl/TriFlowSR</a>.
åŸºäºå‚è€ƒå›¾åƒçš„å›¾åƒè¶…åˆ†è¾¨ç‡ï¼ˆRefSRï¼‰æ—¨åœ¨åˆ©ç”¨é™„åŠ çš„å‚è€ƒé«˜åˆ†è¾¨ç‡ï¼ˆå‚è€ƒ HRï¼‰å›¾åƒä¸­çš„è¯­ä¹‰å’Œçº¹ç†ä¿¡æ¯æ¥æ¢å¤ä½åˆ†è¾¨ç‡ï¼ˆLRï¼‰å›¾åƒã€‚ç°æœ‰çš„åŸºäºæ‰©æ•£çš„ RefSR æ–¹æ³•é€šå¸¸å»ºç«‹åœ¨ ControlNet ä¹‹ä¸Šï¼Œä½†éš¾ä»¥æœ‰æ•ˆå¯¹é½ LR å›¾åƒä¸å‚è€ƒ HR å›¾åƒä¹‹é—´çš„ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œå½“å‰çš„ RefSR æ•°æ®é›†å­˜åœ¨åˆ†è¾¨ç‡æœ‰é™å’Œå›¾åƒè´¨é‡å·®çš„é—®é¢˜ï¼Œå¯¼è‡´å‚è€ƒå›¾åƒç¼ºä¹è¶³å¤Ÿçš„ç»†ç²’åº¦ç»†èŠ‚ä»¥æ”¯æŒé«˜è´¨é‡é‡å»ºã€‚ä¸ºå…‹æœä¸Šè¿°é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº† TriFlowSRï¼Œè¿™æ˜¯ä¸€ç§æ–°é¢–çš„æ¡†æ¶ï¼Œèƒ½å¤Ÿåœ¨ LR å›¾åƒä¸å‚è€ƒ HR å›¾åƒä¹‹é—´æ˜¾å¼åœ°å®ç°æ¨¡å¼åŒ¹é…ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¼•å…¥äº† Landmark-4Kï¼Œè¿™æ˜¯é¦–ä¸ªé¢å‘è¶…é«˜æ¸…ï¼ˆUHDï¼‰åœ°æ ‡åœºæ™¯çš„ RefSR æ•°æ®é›†ã€‚é’ˆå¯¹å…·æœ‰çœŸå®ä¸–ç•Œé€€åŒ–çš„ UHD åœºæ™¯ï¼Œåœ¨ TriFlowSR ä¸­ï¼Œæˆ‘ä»¬è®¾è®¡äº†ä¸€ç§å‚è€ƒåŒ¹é…ç­–ç•¥ï¼Œä»¥æœ‰æ•ˆåœ°å°† LR å›¾åƒä¸å‚è€ƒ HR å›¾åƒåŒ¹é…ã€‚å®éªŒè¯æ˜ï¼Œä¸ä»¥å¾€æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•èƒ½å¤Ÿæ›´å¥½åœ°åˆ©ç”¨å‚è€ƒ HR å›¾åƒçš„è¯­ä¹‰å’Œçº¹ç†ä¿¡æ¯ã€‚ æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æå‡ºäº†é¦–ä¸ªç”¨äºç°å®ä¸–ç•Œé€€åŒ–æ¡ä»¶ä¸‹è¶…é«˜æ¸…åœ°æ ‡åœºæ™¯çš„åŸºäºæ‰©æ•£çš„å‚è€ƒè¶…åˆ†è¾¨ç‡ï¼ˆRefSRï¼‰æµç¨‹ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹å°†å‘å¸ƒåœ¨ <a href="https://github.com/nkicsl/TriFlowSR"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/nkicsl/TriFlowSR</a>ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 16:04:39 UTC
å‘å¸ƒï¼š2025-08-14 16:04:39 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="45-estimating-covariance-for-global-minimum-variance-portfolio-a-decision-focused-learning-approach--45-ä¼°è®¡å…¨å±€æœ€å°æ–¹å·®ç»„åˆçš„åæ–¹å·®ä¸€ç§ä»¥å†³ç­–ä¸ºä¸­å¿ƒçš„å­¦ä¹ æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10776"target="_blank" rel="external nofollow noopener noreferrer">#45</a> <a href="https://papers.cool/arxiv/2508.10776"target="_blank" rel="external nofollow noopener noreferrer">Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach</a>  #45 ä¼°è®¡å…¨å±€æœ€å°æ–¹å·®ç»„åˆçš„åæ–¹å·®ï¼šä¸€ç§ä»¥å†³ç­–ä¸ºä¸­å¿ƒçš„å­¦ä¹ æ–¹æ³•</h2>
<p><strong>Authors</strong>: [Juchan Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juchan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juchan</a> Kim), [Inwoo Tae](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Inwoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Inwoo</a> Tae), [Yongjae Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yongjae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yongjae</a> Lee)
ä½œè€…ï¼šJuchan Kimã€Inwoo Taeã€Yongjae Lee</p>
<p>Portfolio optimization constitutes a cornerstone of risk management by quantifying the risk-return trade-off. Since it inherently depends on accurate parameter estimation under conditions of future uncertainty, the selection of appropriate input parameters is critical for effective portfolio construction. However, most conventional statistical estimators and machine learning algorithms determine these parameters by minimizing mean-squared error (MSE), a criterion that can yield suboptimal investment decisions. In this paper, we adopt decision-focused learning (DFL) - an approach that directly optimizes decision quality rather than prediction error such as MSE - to derive the global minimum-variance portfolio (GMVP). Specifically, we theoretically derive the gradient of decision loss using the analytic solution of GMVP and its properties regarding the principal components of itself. Through extensive empirical evaluation, we show that prediction-focused estimation methods may fail to produce optimal allocations in practice, whereas DFL-based methods consistently deliver superior decision performance. Furthermore, we provide a comprehensive analysis of DFL&rsquo;s mechanism in GMVP construction, focusing on its volatility reduction capability, decision-driving features, and estimation characteristics.
æŠ•èµ„ç»„åˆä¼˜åŒ–é€šè¿‡é‡åŒ–é£é™©ä¸æ”¶ç›Šçš„æƒè¡¡ï¼Œæ„æˆäº†é£é™©ç®¡ç†çš„åŸºçŸ³ã€‚ç”±äºå…¶æœ¬è´¨ä¸Šä¾èµ–äºåœ¨æœªæ¥ä¸ç¡®å®šæ€§æ¡ä»¶ä¸‹å¯¹å‚æ•°çš„å‡†ç¡®ä¼°è®¡ï¼Œé€‰æ‹©åˆé€‚çš„è¾“å…¥å‚æ•°å¯¹äºæœ‰æ•ˆçš„æŠ•èµ„ç»„åˆæ„å»ºè‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•°ä¼ ç»Ÿç»Ÿè®¡ä¼°è®¡é‡å’Œæœºå™¨å­¦ä¹ ç®—æ³•é€šè¿‡æœ€å°åŒ–å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰æ¥ç¡®å®šè¿™äº›å‚æ•°ï¼Œè¿™ä¸€å‡†åˆ™å¯èƒ½å¯¼è‡´æ¬¡ä¼˜çš„æŠ•èµ„å†³ç­–ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨ä»¥å†³ç­–ä¸ºå¯¼å‘çš„å­¦ä¹ ï¼ˆDFLï¼‰â€”â€”ä¸€ç§ç›´æ¥ä¼˜åŒ–å†³ç­–è´¨é‡è€Œéåƒ MSE è¿™æ ·çš„é¢„æµ‹è¯¯å·®çš„æ–¹æ³•â€”â€”æ¥æ¨å¯¼å…¨å±€æœ€å°æ–¹å·®æŠ•èµ„ç»„åˆï¼ˆGMVPï¼‰ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬åˆ©ç”¨ GMVP çš„è§£æè§£åŠå…¶å…³äºè‡ªèº«ä¸»æˆåˆ†çš„æ€§è´¨ï¼Œç†è®ºæ¨å¯¼äº†å†³ç­–æŸå¤±çš„æ¢¯åº¦ã€‚é€šè¿‡å¤§é‡å®è¯è¯„ä¼°ï¼Œæˆ‘ä»¬è¯æ˜äº†ä»¥é¢„æµ‹ä¸ºä¸­å¿ƒçš„ä¼°è®¡æ–¹æ³•åœ¨å®è·µä¸­å¯èƒ½æ— æ³•äº§ç”Ÿæœ€ä¼˜é…ç½®ï¼Œè€ŒåŸºäº DFL çš„æ–¹æ³•åˆ™å§‹ç»ˆæä¾›æ›´ä¼˜çš„å†³ç­–è¡¨ç°ã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬å¯¹ DFL åœ¨ GMVP æ„å»ºä¸­çš„æœºåˆ¶è¿›è¡Œäº†å…¨é¢åˆ†æï¼Œé‡ç‚¹å…³æ³¨å…¶é™ä½æ³¢åŠ¨æ€§çš„èƒ½åŠ›ã€é©±åŠ¨å†³ç­–çš„ç‰¹æ€§ä»¥åŠä¼°è®¡ç‰¹å¾ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/q-fin.PM"target="_blank" rel="external nofollow noopener noreferrer">Portfolio Management</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæŠ•èµ„ç»„åˆç®¡ç†ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 16:00:52 UTC
å‘å¸ƒï¼š2025-08-14 16:00:52 UTC</p>
<h2 id="46-video-blade-block-sparse-attention-meets-step-distillation-for-efficient-video-generation--46-video-bladeå—ç¨€ç–æ³¨æ„åŠ›é‡ä¸Šæ­¥è’¸é¦ä»¥å®ç°é«˜æ•ˆè§†é¢‘ç”Ÿæˆ"><a href="https://arxiv.org/abs/2508.10774"target="_blank" rel="external nofollow noopener noreferrer">#46</a> <a href="https://papers.cool/arxiv/2508.10774"target="_blank" rel="external nofollow noopener noreferrer">Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation</a>  #46 Video-BLADEï¼šå—ç¨€ç–æ³¨æ„åŠ›é‡ä¸Šæ­¥è’¸é¦ä»¥å®ç°é«˜æ•ˆè§†é¢‘ç”Ÿæˆ</h2>
<p><strong>Authors</strong>: [Youping Gu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youping</a> Gu), [Xiaolong Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaolong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaolong</a> Li), [Yuhao Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhao</a> Hu), [Bohan Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bohan</a> Zhuang)
ä½œè€…ï¼šè°·æœ‰å¹³ã€ææ™“é¾™ã€èƒ¡å®‡è±ªã€åº„åšæ¶µ</p>
<p>Diffusion transformers currently lead the field in high-quality video generation, but their slow iterative denoising process and prohibitive quadratic attention costs for long sequences create significant inference bottlenecks. While both step distillation and sparse attention mechanisms have shown promise as independent acceleration strategies, effectively combining these approaches presents critical challenges &ndash; training-free integration yields suboptimal results, while separately training sparse attention after step distillation requires prohibitively expensive high-quality video data. To overcome these limitations, we propose BLADE, an innovative data-free joint training framework that introduces: (1) an Adaptive Block-Sparse Attention (ASA) mechanism for dynamically generating content-aware sparsity masks to focus computation on salient spatiotemporal features, and (2) a sparsity-aware step distillation paradigm built upon Trajectory Distribution Matching (TDM) that directly incorporates sparsity into the distillation process rather than treating it as a separate compression step, with fast convergence. We validate BLADE on text-to-video models like CogVideoX-5B and Wan2.1-1.3B. Our framework demonstrates remarkable efficiency gains across different scales. On Wan2.1-1.3B, BLADE achieves a 14.10x end-to-end inference acceleration over a 50-step baseline. Moreover, on models such as CogVideoX-5B with short video sequence lengths, our framework delivers a robust 8.89x speedup. Crucially, the acceleration is accompanied by a consistent quality improvement. On the VBench-2.0 benchmark, BLADE boosts the score of CogVideoX-5B to 0.569 (from 0.534) and Wan2.1-1.3B to 0.570 (from 0.563), results that are further corroborated by superior ratings in human evaluations. Our code and model weights are publicly available at: <a href="http://ziplab.co/BLADE-Homepage/"target="_blank" rel="external nofollow noopener noreferrer">http://ziplab.co/BLADE-Homepage/</a>.
æ‰©æ•£å˜æ¢å™¨ç›®å‰åœ¨é«˜è´¨é‡è§†é¢‘ç”Ÿæˆé¢†åŸŸé¢†å…ˆï¼Œä½†å…¶ç¼“æ…¢çš„è¿­ä»£å»å™ªè¿‡ç¨‹ä»¥åŠå¯¹é•¿åºåˆ—å…·æœ‰é«˜æ˜‚äºŒæ¬¡æ³¨æ„åŠ›å¼€é”€ï¼Œé€ æˆäº†æ˜¾è‘—çš„æ¨ç†ç“¶é¢ˆã€‚å°½ç®¡æ­¥è’¸é¦å’Œç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ä½œä¸ºç‹¬ç«‹åŠ é€Ÿç­–ç•¥éƒ½æ˜¾ç¤ºå‡ºå¸Œæœ›ï¼Œæœ‰æ•ˆåœ°å°†è¿™äº›æ–¹æ³•ç»“åˆèµ·æ¥å´é¢ä¸´å…³é”®æŒ‘æˆ˜â€”â€”æ— éœ€è®­ç»ƒçš„é›†æˆä¼šäº§ç”Ÿæ¬¡ä¼˜ç»“æœï¼Œè€Œåœ¨æ­¥è’¸é¦ä¹‹åå•ç‹¬è®­ç»ƒç¨€ç–æ³¨æ„åŠ›åˆéœ€è¦ä»£ä»·é«˜æ˜‚çš„é«˜è´¨é‡è§†é¢‘æ•°æ®ã€‚ä¸ºå…‹æœè¿™äº›é™åˆ¶ï¼Œæˆ‘ä»¬æå‡ºäº† BLADEï¼Œä¸€ç§åˆ›æ–°çš„æ•°æ®æ— å…³è”åˆè®­ç»ƒæ¡†æ¶ï¼ŒåŒ…å«ï¼š(1) è‡ªé€‚åº”å—ç¨€ç–æ³¨æ„åŠ›ï¼ˆAdaptive Block-Sparse Attention, ASAï¼‰æœºåˆ¶ï¼Œç”¨äºåŠ¨æ€ç”Ÿæˆå†…å®¹æ„ŸçŸ¥çš„ç¨€ç–æ©ç ï¼Œå°†è®¡ç®—èšç„¦äºæ˜¾è‘—çš„æ—¶ç©ºç‰¹å¾ï¼›ä»¥åŠ (2) åŸºäºè½¨è¿¹åˆ†å¸ƒåŒ¹é…ï¼ˆTrajectory Distribution Matching, TDMï¼‰çš„ç¨€ç–æ„ŸçŸ¥æ­¥è’¸é¦èŒƒå¼ï¼Œè¯¥èŒƒå¼åœ¨è’¸é¦è¿‡ç¨‹ä¸­ç›´æ¥å°†ç¨€ç–æ€§çº³å…¥è€Œéå°†å…¶ä½œä¸ºå•ç‹¬çš„å‹ç¼©æ­¥éª¤ï¼Œå¹¶å…·æœ‰å¿«é€Ÿæ”¶æ•›æ€§ã€‚ æˆ‘ä»¬åœ¨åƒ CogVideoX-5B å’Œ Wan2.1-1.3B ç­‰æ–‡æœ¬åˆ°è§†é¢‘æ¨¡å‹ä¸ŠéªŒè¯äº† BLADEã€‚æˆ‘ä»¬çš„æ¡†æ¶åœ¨ä¸åŒè§„æ¨¡ä¸Šè¡¨ç°å‡ºæ˜¾è‘—çš„æ•ˆç‡æå‡ã€‚åœ¨ Wan2.1-1.3B ä¸Šï¼ŒBLADE ç›¸è¾ƒäº 50 æ­¥åŸºçº¿å®ç°äº† 14.10 å€çš„ç«¯åˆ°ç«¯æ¨ç†åŠ é€Ÿã€‚æ­¤å¤–ï¼Œåœ¨è¯¸å¦‚å…·æœ‰çŸ­è§†é¢‘åºåˆ—é•¿åº¦çš„ CogVideoX-5B ç­‰æ¨¡å‹ä¸Šï¼Œæˆ‘ä»¬çš„æ¡†æ¶æä¾›äº†ç¨³å¥çš„ 8.89 å€åŠ é€Ÿã€‚å…³é”®æ˜¯ï¼ŒåŠ é€Ÿä¼´éšç€æŒç»­çš„è´¨é‡æå‡ã€‚åœ¨ VBench-2.0 åŸºå‡†ä¸Šï¼ŒBLADE å°† CogVideoX-5B çš„å¾—åˆ†ä» 0.534 æå‡åˆ° 0.569ï¼Œå°† Wan2.1-1.3B çš„å¾—åˆ†ä» 0.563 æå‡åˆ° 0.570ï¼Œè¿™äº›ç»“æœä¹Ÿé€šè¿‡äººå·¥è¯„ä¼°ä¸­çš„æ›´é«˜è¯„åˆ†å¾—åˆ°äº†è¿›ä¸€æ­¥è¯å®ã€‚æˆ‘ä»¬çš„ä»£ç å’Œæ¨¡å‹æƒé‡å…¬å¼€å¯åœ¨ï¼š <a href="http://ziplab.co/BLADE-Homepage/"target="_blank" rel="external nofollow noopener noreferrer">http://ziplab.co/BLADE-Homepage/</a> è·å–ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 15:58:59 UTC
å‘å¸ƒï¼š2025-08-14 15:58:59 UTC</p>
<h2 id="47-aegis-authenticity-evaluation-benchmark-for-ai-generated-video-sequences--47-aegisç”¨äº-ai-ç”Ÿæˆè§†é¢‘åºåˆ—çœŸå®æ€§è¯„ä¼°çš„åŸºå‡†"><a href="https://arxiv.org/abs/2508.10771"target="_blank" rel="external nofollow noopener noreferrer">#47</a> <a href="https://papers.cool/arxiv/2508.10771"target="_blank" rel="external nofollow noopener noreferrer">AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences</a>  #47 AEGISï¼šç”¨äº AI ç”Ÿæˆè§†é¢‘åºåˆ—çœŸå®æ€§è¯„ä¼°çš„åŸºå‡†</h2>
<p><strong>Authors</strong>: [Jieyu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jieyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jieyu</a> Li), [Xin Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Zhang), [Joey Tianyi Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Joey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Joey</a> Tianyi Zhou)
ä½œè€…ï¼šææ´ç‘œã€å¼ æ˜•ã€å‘¨å¤©æ„ï¼ˆJoey Tianyi Zhouï¼‰</p>
<p>Recent advances in AI-generated content have fueled the rise of highly realistic synthetic videos, posing severe risks to societal trust and digital integrity. Existing benchmarks for video authenticity detection typically suffer from limited realism, insufficient scale, and inadequate complexity, failing to effectively evaluate modern vision-language models against sophisticated forgeries. To address this critical gap, we introduce AEGIS, a novel large-scale benchmark explicitly targeting the detection of hyper-realistic and semantically nuanced AI-generated videos. AEGIS comprises over 10,000 rigorously curated real and synthetic videos generated by diverse, state-of-the-art generative models, including Stable Video Diffusion, CogVideoX-5B, KLing, and Sora, encompassing open-source and proprietary architectures. In particular, AEGIS features specially constructed challenging subsets enhanced with robustness evaluation. Furthermore, we provide multimodal annotations spanning Semantic-Authenticity Descriptions, Motion Features, and Low-level Visual Features, facilitating authenticity detection and supporting downstream tasks such as multimodal fusion and forgery localization. Extensive experiments using advanced vision-language models demonstrate limited detection capabilities on the most challenging subsets of AEGIS, highlighting the dataset&rsquo;s unique complexity and realism beyond the current generalization capabilities of existing models. In essence, AEGIS establishes an indispensable evaluation benchmark, fundamentally advancing research toward developing genuinely robust, reliable, broadly generalizable video authenticity detection methodologies capable of addressing real-world forgery threats. Our dataset is available on <a href="https://huggingface.co/datasets/Clarifiedfish/AEGIS"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/datasets/Clarifiedfish/AEGIS</a>.
è¿‘å¹´æ¥ï¼ŒAI ç”Ÿæˆå†…å®¹çš„è¿›æ­¥å‚¬ç”Ÿäº†é«˜åº¦é€¼çœŸçš„åˆæˆè§†é¢‘ï¼Œç»™ç¤¾ä¼šä¿¡ä»»å’Œæ•°å­—å®Œæ•´æ€§å¸¦æ¥äº†ä¸¥é‡é£é™©ã€‚ç°æœ‰çš„è§†é¢‘çœŸå®æ€§æ£€æµ‹åŸºå‡†é€šå¸¸å­˜åœ¨é€¼çœŸåº¦ä¸è¶³ã€è§„æ¨¡æœ‰é™å’Œå¤æ‚æ€§ä¸å¤Ÿç­‰é—®é¢˜ï¼Œæ— æ³•æœ‰æ•ˆè¯„ä¼°ç°ä»£è§†è§‰-è¯­è¨€æ¨¡å‹åº”å¯¹å¤æ‚ä¼ªé€ çš„èƒ½åŠ›ã€‚ä¸ºå¡«è¡¥è¿™ä¸€å…³é”®ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº† AEGISï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹æ£€æµ‹è¶…é€¼çœŸä¸”è¯­ä¹‰ä¸Šç»†å¾®çš„ AI ç”Ÿæˆè§†é¢‘çš„å¤§è§„æ¨¡æ–°åŸºå‡†ã€‚AEGIS åŒ…å«è¶…è¿‡ 10,000 ä¸ªç»è¿‡ä¸¥æ ¼ç­›é€‰çš„çœŸå®å’Œåˆæˆè§†é¢‘ï¼Œè¿™äº›è§†é¢‘ç”±å¤šç§æœ€å…ˆè¿›çš„ç”Ÿæˆæ¨¡å‹ç”Ÿæˆï¼ŒåŒ…æ‹¬ Stable Video Diffusionã€CogVideoX-5Bã€KLing å’Œ Soraï¼Œæ¶µç›–å¼€æºä¸ä¸“æœ‰æ¶æ„ã€‚ç‰¹åˆ«åœ°ï¼ŒAEGIS è®¾æœ‰ä¸“é—¨æ„å»ºçš„æŒ‘æˆ˜æ€§å­é›†ï¼Œå¹¶å¢å¼ºäº†é²æ£’æ€§è¯„ä¼°ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æä¾›äº†è·¨è¯­ä¹‰-çœŸå®æ€§æè¿°ã€è¿åŠ¨ç‰¹å¾å’Œä½çº§è§†è§‰ç‰¹å¾çš„å¤šæ¨¡æ€æ³¨é‡Šï¼Œä»¥ä¾¿äºçœŸå®æ€§æ£€æµ‹å¹¶æ”¯æŒå¤šæ¨¡æ€èåˆä¸ä¼ªé€ å®šä½ç­‰ä¸‹æ¸¸ä»»åŠ¡ã€‚ ä½¿ç”¨å…ˆè¿›çš„è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œçš„å¤§é‡å®éªŒè¯æ˜ï¼Œåœ¨ AEGIS æœ€å…·æŒ‘æˆ˜æ€§çš„å­é›†ä¸­ï¼Œæ£€æµ‹èƒ½åŠ›æœ‰é™ï¼Œè¿™å‡¸æ˜¾äº†è¯¥æ•°æ®é›†åœ¨å¤æ‚æ€§å’ŒçœŸå®æ„Ÿæ–¹é¢çš„ç‹¬ç‰¹æ€§ï¼Œè¶…å‡ºäº†ç°æœ‰æ¨¡å‹çš„å½“å‰æ³›åŒ–èƒ½åŠ›ã€‚æœ¬è´¨ä¸Šï¼ŒAEGIS ç¡®ç«‹äº†ä¸€ä¸ªä¸å¯æˆ–ç¼ºçš„è¯„ä¼°åŸºå‡†ï¼Œä»æ ¹æœ¬ä¸Šæ¨åŠ¨ç ”ç©¶å‘å¼€å‘çœŸæ­£ç¨³å¥ã€å¯é ã€å…·æœ‰å¹¿æ³›æ³›åŒ–èƒ½åŠ›çš„è§†é¢‘çœŸå®æ€§æ£€æµ‹æ–¹æ³•å‘å±•ï¼Œä»¥åº”å¯¹ç°å®ä¸–ç•Œçš„ä¼ªé€ å¨èƒã€‚æˆ‘ä»¬çš„æ•°æ®é›†å¯åœ¨ <a href="https://huggingface.co/datasets/Clarifiedfish/AEGIS"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/datasets/Clarifiedfish/AEGIS</a> è·å–ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 15:55:49 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 15:55:49 UTC</p>
<h2 id="48-frogent-an-end-to-end-full-process-drug-design-agent--48-frogentä¸€ä¸ªç«¯åˆ°ç«¯å…¨æµç¨‹è¯ç‰©è®¾è®¡ä»£ç†"><a href="https://arxiv.org/abs/2508.10760"target="_blank" rel="external nofollow noopener noreferrer">#48</a> <a href="https://papers.cool/arxiv/2508.10760"target="_blank" rel="external nofollow noopener noreferrer">FROGENT: An End-to-End Full-process Drug Design Agent</a>  #48 FROGENTï¼šä¸€ä¸ªç«¯åˆ°ç«¯å…¨æµç¨‹è¯ç‰©è®¾è®¡ä»£ç†</h2>
<p><strong>Authors</strong>: [Qihua Pan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qihua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qihua</a> Pan), [Dong Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Xu), [Jenna Xinyi Yao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jenna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jenna</a> Xinyi Yao), [Lijia Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lijia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lijia</a> Ma), [Zexuan Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zexuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zexuan</a> Zhu), [Junkai Ji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junkai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junkai</a> Ji)
ä½œè€…ï¼šæ½˜å•Ÿè¯ï¼Œè®¸ä¸œï¼Œå§šæ¬£æ€¡ï¼Œé©¬ä¸½å˜‰ï¼Œæœ±æ³½è½©ï¼Œçºªä¿Šå‡¯</p>
<p>Powerful AI tools for drug discovery reside in isolated web apps, desktop programs, and code libraries. Such fragmentation forces scientists to manage incompatible interfaces and specialized scripts, which can be a cumbersome and repetitive process. To address this issue, a Full-pROcess druG dEsign ageNT, named FROGENT, has been proposed. Specifically, FROGENT utilizes a Large Language Model and the Model Context Protocol to integrate multiple dynamic biochemical databases, extensible tool libraries, and task-specific AI models. This agentic framework allows FROGENT to execute complicated drug discovery workflows dynamically, including component tasks such as target identification, molecule generation and retrosynthetic planning. FROGENT has been evaluated on eight benchmarks that cover various aspects of drug discovery, such as knowledge retrieval, property prediction, virtual screening, mechanistic analysis, molecular design, and synthesis. It was compared against six increasingly advanced ReAct-style agents that support code execution and literature searches. Empirical results demonstrated that FROGENT triples the best baseline performance in hit-finding and doubles it in interaction profiling, significantly outperforming both the open-source model Qwen3-32B and the commercial model GPT-4o. In addition, real-world cases have been utilized to validate the practicability and generalization of FROGENT. This development suggests that streamlining the agentic drug discovery pipeline can significantly enhance researcher productivity.
ç”¨äºè¯ç‰©å‘ç°çš„å¼ºå¤§ AI å·¥å…·åˆ†æ•£åœ¨ç‹¬ç«‹çš„ç½‘ç»œåº”ç”¨ã€æ¡Œé¢ç¨‹åºå’Œä»£ç åº“ä¸­ã€‚è¿™ç§ç¢ç‰‡åŒ–è¿«ä½¿ç§‘å­¦å®¶ä»¬ç®¡ç†ä¸å…¼å®¹çš„ç•Œé¢å’Œä¸“ç”¨è„šæœ¬ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ªç¹çä¸”é‡å¤çš„è¿‡ç¨‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º FROGENT çš„å…¨æµç¨‹è¯ç‰©è®¾è®¡æ™ºèƒ½ä½“ï¼ˆFull-pROcess druG dEsign ageNTï¼‰ã€‚å…·ä½“æ¥è¯´ï¼ŒFROGENT åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹å’Œæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆModel Context Protocolï¼‰æ¥æ•´åˆå¤šä¸ªåŠ¨æ€ç”ŸåŒ–æ•°æ®åº“ã€å¯æ‰©å±•çš„å·¥å…·åº“å’Œä»»åŠ¡ç‰¹å®šçš„ AI æ¨¡å‹ã€‚è¯¥æ™ºèƒ½ä½“æ¡†æ¶ä½¿ FROGENT èƒ½å¤ŸåŠ¨æ€æ‰§è¡Œå¤æ‚çš„è¯ç‰©å‘ç°å·¥ä½œæµï¼ŒåŒ…æ‹¬ç›®æ ‡è¯†åˆ«ã€åˆ†å­ç”Ÿæˆå’Œé€†åˆæˆè§„åˆ’ç­‰ç»„æˆä»»åŠ¡ã€‚FROGENT åœ¨å…«ä¸ªåŸºå‡†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œè¿™äº›åŸºå‡†æ¶µç›–äº†è¯ç‰©å‘ç°çš„å„ä¸ªæ–¹é¢ï¼Œä¾‹å¦‚çŸ¥è¯†æ£€ç´¢ã€æ€§è´¨é¢„æµ‹ã€è™šæ‹Ÿç­›é€‰ã€æœºåˆ¶åˆ†æã€åˆ†å­è®¾è®¡å’Œåˆæˆã€‚å®ƒä¸å…­ç§æ”¯æŒä»£ç æ‰§è¡Œå’Œæ–‡çŒ®æ£€ç´¢çš„ã€è¶Šæ¥è¶Šå…ˆè¿›çš„ ReAct é£æ ¼æ™ºèƒ½ä½“è¿›è¡Œäº†æ¯”è¾ƒã€‚ å®è¯ç»“æœè¡¨æ˜ï¼ŒFROGENT åœ¨å‘½ä¸­å‘ç°æ–¹é¢å°†æœ€ä½³åŸºçº¿æ€§èƒ½æé«˜äº†ä¸‰å€ï¼Œåœ¨ç›¸äº’ä½œç”¨å‰–ææ–¹é¢æé«˜äº†ä¸¤å€ï¼Œæ˜¾è‘—ä¼˜äºå¼€æºæ¨¡å‹ Qwen3-32B å’Œå•†ç”¨æ¨¡å‹ GPT-4oã€‚æ­¤å¤–ï¼Œå·²ä½¿ç”¨çœŸå®æ¡ˆä¾‹éªŒè¯äº† FROGENT çš„å¯è¡Œæ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚è¯¥è¿›å±•è¡¨æ˜ï¼Œç®€åŒ–è‡ªä¸»ä½“è¯ç‰©å‘ç°æµç¨‹å¯ä»¥æ˜¾è‘—æå‡ç ”ç©¶äººå‘˜çš„ç”Ÿäº§åŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/q-bio.BM"target="_blank" rel="external nofollow noopener noreferrer">Biomolecules</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šç”Ÿç‰©åˆ†å­ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 15:45:53 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 15:45:53 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="49-natively-trainable-sparse-attention-for-hierarchical-point-cloud-datasets--49-åŸç”Ÿå¯è®­ç»ƒç¨€ç–æ³¨æ„åŠ›ç”¨äºåˆ†å±‚ç‚¹äº‘æ•°æ®é›†"><a href="https://arxiv.org/abs/2508.10758"target="_blank" rel="external nofollow noopener noreferrer">#49</a> <a href="https://papers.cool/arxiv/2508.10758"target="_blank" rel="external nofollow noopener noreferrer">Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets</a>  #49 åŸç”Ÿå¯è®­ç»ƒç¨€ç–æ³¨æ„åŠ›ç”¨äºåˆ†å±‚ç‚¹äº‘æ•°æ®é›†</h2>
<p><strong>Authors</strong>: [Nicolas Lapautre](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nicolas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nicolas</a> Lapautre), [Maria Marchenko](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maria</a> Marchenko), [Carlos Miguel PatiÃ±o](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Carlos"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Carlos</a> Miguel PatiÃ±o), [Xin Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Zhou)
ä½œè€…ï¼šNicolas Lapautreï¼ŒMaria Marchenkoï¼ŒCarlos Miguel PatiÃ±oï¼ŒXin Zhou</p>
<p>Unlocking the potential of transformers on datasets of large physical systems depends on overcoming the quadratic scaling of the attention mechanism. This work explores combining the Erwin architecture with the Native Sparse Attention (NSA) mechanism to improve the efficiency and receptive field of transformer models for large-scale physical systems, addressing the challenge of quadratic attention complexity. We adapt the NSA mechanism for non-sequential data, implement the Erwin NSA model, and evaluate it on three datasets from the physical sciences &ndash; cosmology simulations, molecular dynamics, and air pressure modeling &ndash; achieving performance that matches or exceeds that of the original Erwin model. Additionally, we reproduce the experimental results from the Erwin paper to validate their implementation.
åœ¨å¤§å‹ç‰©ç†ç³»ç»Ÿæ•°æ®é›†ä¸Šé‡Šæ”¾å˜å‹å™¨æ½œåŠ›çš„å…³é”®åœ¨äºå…‹æœæ³¨æ„åŠ›æœºåˆ¶çš„äºŒæ¬¡æ‰©å±•æ€§ã€‚æœ¬æ–‡æ¢ç´¢å°† Erwin æ¶æ„ä¸åŸç”Ÿç¨€ç–æ³¨æ„åŠ›ï¼ˆNative Sparse Attentionï¼ŒNSAï¼‰æœºåˆ¶ç›¸ç»“åˆï¼Œä»¥æé«˜å˜å‹å™¨æ¨¡å‹åœ¨å¤§è§„æ¨¡ç‰©ç†ç³»ç»Ÿä¸Šçš„æ•ˆç‡å’Œæ„Ÿå—é‡ï¼Œä»è€Œåº”å¯¹äºŒæ¬¡æ³¨æ„åŠ›å¤æ‚æ€§çš„é—®é¢˜ã€‚æˆ‘ä»¬å°† NSA æœºåˆ¶æ”¹é€ ç”¨äºéåºåˆ—æ•°æ®ï¼Œå®ç°äº† Erwin NSA æ¨¡å‹ï¼Œå¹¶åœ¨æ¥è‡ªç‰©ç†ç§‘å­¦çš„ä¸‰ä¸ªæ•°æ®é›†â€”â€”å®‡å®™å­¦æ¨¡æ‹Ÿã€åˆ†å­åŠ¨åŠ›å­¦å’Œæ°”å‹å»ºæ¨¡â€”â€”ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œå–å¾—äº†ä¸åŸå§‹ Erwin æ¨¡å‹ç›¸å½“æˆ–æ›´ä¼˜çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¤ç°äº† Erwin è®ºæ–‡ä¸­çš„å®éªŒç»“æœä»¥éªŒè¯å…¶å®ç°ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 15:39:34 UTC
å‘å¸ƒï¼š2025-08-14 15:39:34 UTC</p>
<h2 id="50-passk-training-for-adaptively-balancing-exploration-and-exploitation-of-large-reasoning-models--50-åœ¨é€‚åº”æ€§å¹³è¡¡å¤§å‹æ¨ç†æ¨¡å‹çš„æ¢ç´¢ä¸åˆ©ç”¨æ–¹é¢è¿›è¡Œçš„-passk-è®­ç»ƒ-pdf-13--copy-kimi-10--rel"><a href="https://arxiv.org/abs/2508.10751"target="_blank" rel="external nofollow noopener noreferrer">#50</a> <a href="https://papers.cool/arxiv/2508.10751"target="_blank" rel="external nofollow noopener noreferrer">Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models</a>  #50 åœ¨é€‚åº”æ€§å¹³è¡¡å¤§å‹æ¨ç†æ¨¡å‹çš„æ¢ç´¢ä¸åˆ©ç”¨æ–¹é¢è¿›è¡Œçš„ Pass@k è®­ç»ƒ [PDF 13 ] [Copy] [Kimi 10 ] [REL]</h2>
<p><strong>Authors</strong>: [Zhipeng Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhipeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhipeng</a> Chen), [Xiaobo Qin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaobo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaobo</a> Qin), [Youbin Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youbin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youbin</a> Wu), [Yue Ling](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yue</a> Ling), [Qinghao Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qinghao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qinghao</a> Ye), [Wayne Xin Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wayne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wayne</a> Xin Zhao), [Guang Shi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guang</a> Shi)
ä½œè€…ï¼šé™ˆå¿—é¹ã€ç§¦å°åšã€å´æœ‰æ»¨ã€å‡Œè¶Šã€å¶åº†æµ©ã€èµµæ–°æ–‡ã€å²å…‰</p>
<p>Reinforcement learning with verifiable rewards (RLVR), which typically adopts Pass@1 as the reward, has faced the issues in balancing exploration and exploitation, causing policies to prefer conservative actions, converging to a local optimum. Identifying an appropriate reward metric is therefore crucial. Regarding the prior work, although Pass@k has been used in evaluation, its connection to LLM exploration ability in RLVR remains largely overlooked. To investigate this, we first use Pass@k as the reward to train the policy model (i.e., Pass@k Training), and observe the improvement on its exploration ability. Next, we derive an analytical solution for the advantage of Pass@k Training, leading to an efficient and effective process. Building on this, our analysis reveals that exploration and exploitation are not inherently conflicting objectives, while they can mutually enhance each other. Moreover, Pass@k Training with analytical derivation essentially involves directly designing the advantage function. Inspired by this, we preliminarily explore the advantage design for RLVR, showing promising results and highlighting a potential future direction.
å¯éªŒè¯å¥–åŠ±çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLVRï¼‰ï¼Œé€šå¸¸é‡‡ç”¨ Pass@1 ä½œä¸ºå¥–åŠ±ï¼Œåœ¨æ¢ç´¢ä¸åˆ©ç”¨çš„å¹³è¡¡æ–¹é¢é¢ä¸´éš¾é¢˜ï¼Œå¯¼è‡´ç­–ç•¥åå‘ä¿å®ˆåŠ¨ä½œï¼Œæ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜ã€‚å› æ­¤ï¼Œè¯†åˆ«åˆé€‚çš„å¥–åŠ±åº¦é‡è‡³å…³é‡è¦ã€‚å…³äºå…ˆå‰å·¥ä½œï¼Œå°½ç®¡åœ¨è¯„ä¼°ä¸­ä½¿ç”¨äº† Pass@kï¼Œä½†å…¶ä¸ LLM åœ¨ RLVR ä¸­æ¢ç´¢èƒ½åŠ›çš„å…³è”åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šè¢«å¿½è§†ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆä½¿ç”¨ Pass@k ä½œä¸ºå¥–åŠ±æ¥è®­ç»ƒç­–ç•¥æ¨¡å‹ï¼ˆå³ Pass@k Training ï¼‰ï¼Œå¹¶è§‚å¯Ÿåˆ°å…¶æ¢ç´¢èƒ½åŠ›çš„æå‡ã€‚æ¥ç€ï¼Œæˆ‘ä»¬ä¸º Pass@k è®­ç»ƒæ¨å¯¼å‡ºè§£æè§£ï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªé«˜æ•ˆä¸”æœ‰æ•ˆçš„è¿‡ç¨‹ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬çš„åˆ†æè¡¨æ˜ï¼Œæ¢ç´¢ä¸åˆ©ç”¨å¹¶éæœ¬è´¨ä¸Šäº’ç›¸å†²çªçš„ç›®æ ‡ï¼Œåè€Œå¯ä»¥ç›¸äº’ä¿ƒè¿›ã€‚æ­¤å¤–ï¼Œå¸¦æœ‰è§£ææ¨å¯¼çš„ Pass@k è®­ç»ƒå®è´¨ä¸Šæ¶‰åŠç›´æ¥è®¾è®¡ä¼˜åŠ¿å‡½æ•°ã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬åˆæ­¥æ¢ç´¢äº† RLVR çš„ä¼˜åŠ¿è®¾è®¡ï¼Œå±•ç¤ºäº†æœ‰å‰æ™¯çš„ç»“æœå¹¶å‡¸æ˜¾äº†ä¸€ä¸ªæ½œåœ¨çš„æœªæ¥æ–¹å‘ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 15:34:47 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 15:34:47 UTC</p>
<h2 id="51-apfl-analytic-personalized-federated-learning-via-dual-stream-least-squares--51-apflé€šè¿‡åŒæµæœ€å°äºŒä¹˜çš„è§£æä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10732"target="_blank" rel="external nofollow noopener noreferrer">#51</a> <a href="https://papers.cool/arxiv/2508.10732"target="_blank" rel="external nofollow noopener noreferrer">APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares</a>  #51 APFLï¼šé€šè¿‡åŒæµæœ€å°äºŒä¹˜çš„è§£æä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ </h2>
<p><strong>Authors</strong>: [Kejia Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kejia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kejia</a> Fan), [Jianheng Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jianheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jianheng</a> Tang), [Zhirui Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhirui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhirui</a> Yang), [Feijiang Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feijiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feijiang</a> Han), [Jiaxu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaxu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaxu</a> Li), [Run He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Run"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Run</a> He), [Yajiang Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yajiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yajiang</a> Huang), [Anfeng Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anfeng</a> Liu), [Houbing Herbert Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Houbing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Houbing</a> Herbert Song), [Yunhuai Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunhuai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunhuai</a> Liu), [Huiping Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huiping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huiping</a> Zhuang)
ä½œè€…ï¼šæ¨Šå¯ä½³ã€å”å»ºè¡¡ã€æ¨å¿—ç¿ã€éŸ©é£æ±Ÿã€æä½³æ—­ã€ä½•æ¶¦ã€é»„äºšæ±Ÿã€åˆ˜å®‰å³°ã€ä¾¯ç‚³èµ«ä¼¯ç‰¹Â·å®‹ã€åˆ˜äº‘æ€€ã€åº„æ…§å¹³</p>
<p>Personalized Federated Learning (PFL) has presented a significant challenge to deliver personalized models to individual clients through collaborative training. Existing PFL methods are often vulnerable to non-IID data, which severely hinders collective generalization and then compromises the subsequent personalization efforts. In this paper, to address this non-IID issue in PFL, we propose an Analytic Personalized Federated Learning (APFL) approach via dual-stream least squares. In our APFL, we use a foundation model as a frozen backbone for feature extraction. Subsequent to the feature extractor, we develop dual-stream analytic models to achieve both collective generalization and individual personalization. Specifically, our APFL incorporates a shared primary stream for global generalization across all clients, and a dedicated refinement stream for local personalization of each individual client. The analytical solutions of our APFL enable its ideal property of heterogeneity invariance, theoretically meaning that each personalized model remains identical regardless of how heterogeneous the data are distributed across all other clients. Empirical results across various datasets also validate the superiority of our APFL over state-of-the-art baselines, with advantages of at least 1.10%-15.45% in accuracy.
ä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ ï¼ˆPFLï¼‰åœ¨é€šè¿‡ååŒè®­ç»ƒå‘å„ä¸ªå®¢æˆ·ç«¯æä¾›ä¸ªæ€§åŒ–æ¨¡å‹æ–¹é¢æå‡ºäº†é‡å¤§æŒ‘æˆ˜ã€‚ç°æœ‰çš„ PFL æ–¹æ³•é€šå¸¸å¯¹éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®è„†å¼±ï¼Œè¿™ä¸¥é‡é˜»ç¢äº†é›†ä½“æ³›åŒ–èƒ½åŠ›ï¼Œè¿›è€ŒæŸå®³éšåçš„ä¸ªæ€§åŒ–æ•ˆæœã€‚ä¸ºäº†è§£å†³ PFL ä¸­çš„è¿™ä¸€é IID é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§é€šè¿‡åŒæµæœ€å°äºŒä¹˜æ³•å®ç°çš„è§£ææ€§ä¸ªæ€§åŒ–è”é‚¦å­¦ä¹ ï¼ˆAPFLï¼‰æ–¹æ³•ã€‚åœ¨æˆ‘ä»¬çš„ APFL ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªåŸºç¡€æ¨¡å‹ä½œä¸ºå†»ç»“çš„ä¸»å¹²è¿›è¡Œç‰¹å¾æå–ã€‚åœ¨ç‰¹å¾æå–å™¨ä¹‹åï¼Œæˆ‘ä»¬å¼€å‘äº†åŒæµè§£ææ¨¡å‹ä»¥å®ç°é›†ä½“æ³›åŒ–å’Œä¸ªä½“ä¸ªæ€§åŒ–ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬çš„ APFL åŒ…å«ä¸€ä¸ªç”¨äºè·¨æ‰€æœ‰å®¢æˆ·ç«¯çš„å…¨å±€æ³›åŒ–çš„å…±äº«ä¸»æµï¼Œä»¥åŠä¸€ä¸ªç”¨äºæ¯ä¸ªå®¢æˆ·ç«¯æœ¬åœ°ä¸ªæ€§åŒ–çš„ä¸“ç”¨ç»†åŒ–æµã€‚APFL çš„è§£æè§£ä½¿å…¶å…·å¤‡äº†å¼‚è´¨æ€§ä¸å˜æ€§çš„ç†æƒ³å±æ€§ï¼Œä»ç†è®ºä¸Šè®²ï¼Œè¿™æ„å‘³ç€æ¯ä¸ªä¸ªæ€§åŒ–æ¨¡å‹åœ¨ä»»ä½•å…¶ä»–å®¢æˆ·ç«¯çš„æ•°æ®å¦‚ä½•åˆ†å¸ƒçš„æƒ…å†µä¸‹éƒ½ä¿æŒä¸å˜ã€‚ åœ¨å¤šä¸ªæ•°æ®é›†ä¸Šçš„å®è¯ç»“æœä¹ŸéªŒè¯äº†æˆ‘ä»¬çš„ APFL ç›¸å¯¹äºæœ€å…ˆè¿›åŸºçº¿æ–¹æ³•çš„ä¼˜è¶Šæ€§ï¼Œå‡†ç¡®ç‡è‡³å°‘æé«˜äº† 1.10%â€“15.45%ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 15:12:50 UTC
å‘å¸ƒï¼š2025-08-14 15:12:50 UTC</p>
<h2 id="52-egocross-benchmarking-multimodal-large-language-models-for-cross-domain-egocentric-video-question-answering--52-egocrossç”¨äºè·¨é¢†åŸŸç¬¬ä¸€äººç§°è§†é¢‘é—®ç­”çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•"><a href="https://arxiv.org/abs/2508.10729"target="_blank" rel="external nofollow noopener noreferrer">#52</a> <a href="https://papers.cool/arxiv/2508.10729"target="_blank" rel="external nofollow noopener noreferrer">EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering</a>  #52 EgoCrossï¼šç”¨äºè·¨é¢†åŸŸç¬¬ä¸€äººç§°è§†é¢‘é—®ç­”çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹åŸºå‡†æµ‹è¯•</h2>
<p><strong>Authors</strong>: [Yanjun Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanjun</a> Li), [Yuqian Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuqian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuqian</a> Fu), [Tianwen Qian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianwen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianwen</a> Qian), [Qi&rsquo;ao Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qi%27ao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qi'ao</a> Xu), [Silong Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silong</a> Dai), [Danda Pani Paudel](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Danda"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Danda</a> Pani Paudel), [Luc Van Gool](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Luc"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Luc</a> Van Gool), [Xiaoling Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoling"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoling</a> Wang)
ä½œè€…ï¼šæç‡•å›ã€ä»˜è‚²è°¦ã€é’±å¤©æ–‡ã€å¾å¯æ¾³ã€æˆ´æ€é¾™ã€Danda Pani Paudelã€Luc Van Goolã€ç‹æ™“ç²</p>
<p>Recent advances in Multimodal Large Language Models (MLLMs) have significantly pushed the frontier of egocentric video question answering (EgocentricQA). However, existing benchmarks and studies are mainly limited to common daily activities such as cooking and cleaning. In contrast, real-world deployment inevitably encounters domain shifts, where target domains differ substantially in both visual style and semantic content. To bridge this gap, we introduce \textbf{EgoCross}, a comprehensive benchmark designed to evaluate the cross-domain generalization of MLLMs in EgocentricQA. EgoCross covers four diverse and challenging domains, including surgery, industry, extreme sports, and animal perspective, representing realistic and high-impact application scenarios. It comprises approximately 1,000 QA pairs across 798 video clips, spanning four key QA tasks: prediction, recognition, localization, and counting. Each QA pair provides both OpenQA and CloseQA formats to support fine-grained evaluation. Extensive experiments show that most existing MLLMs, whether general-purpose or egocentric-specialized, struggle to generalize to domains beyond daily life, highlighting the limitations of current models. Furthermore, we conduct several pilot studies, \eg, fine-tuning and reinforcement learning, to explore potential improvements. We hope EgoCross and our accompanying analysis will serve as a foundation for advancing domain-adaptive, robust egocentric video understanding. Data and codes will be released at: \href{https://github.com/MyUniverse0726/EgoCross}{https://github.com/MyUniverse0726/EgoCross.}
è¿‘å¹´æ¥ï¼Œå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨ç¬¬ä¸€äººç§°è§†é¢‘é—®ç­”ï¼ˆEgocentricQAï¼‰é¢†åŸŸå–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ç„¶è€Œï¼Œç°æœ‰çš„åŸºå‡†å’Œç ”ç©¶ä¸»è¦å±€é™äºè¯¸å¦‚çƒ¹é¥ªå’Œæ¸…æ´ç­‰å¸¸è§æ—¥å¸¸æ´»åŠ¨ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç°å®ä¸–ç•Œçš„éƒ¨ç½²ä¸å¯é¿å…åœ°ä¼šé‡åˆ°é¢†åŸŸè¿ç§»é—®é¢˜ï¼Œç›®æ ‡é¢†åŸŸåœ¨è§†è§‰é£æ ¼å’Œè¯­ä¹‰å†…å®¹ä¸Šéƒ½å¯èƒ½æœ‰æ˜¾è‘—å·®å¼‚ã€‚ä¸ºå¼¥åˆè¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬å¼•å…¥äº† EgoCrossï¼Œä¸€ä¸ªæ—¨åœ¨è¯„ä¼° MLLMs åœ¨ EgocentricQA ä¸­è·¨åŸŸæ³›åŒ–èƒ½åŠ›çš„ç»¼åˆåŸºå‡†ã€‚EgoCross è¦†ç›–äº†å››ä¸ªå¤šæ ·ä¸”å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸï¼ŒåŒ…æ‹¬å¤–ç§‘æ‰‹æœ¯ã€å·¥ä¸šã€æé™è¿åŠ¨å’ŒåŠ¨ç‰©è§†è§’ï¼Œä»£è¡¨äº†ç°å®ä¸”å½±å“é‡å¤§çš„åº”ç”¨åœºæ™¯ã€‚è¯¥æ•°æ®é›†ç”±çº¦ 1,000 ä¸ªé—®ç­”å¯¹ç»„æˆï¼Œæ¶µç›– 798 ä¸ªè§†é¢‘å‰ªè¾‘ï¼Œè·¨è¶Šé¢„æµ‹ã€è¯†åˆ«ã€å®šä½å’Œè®¡æ•°å››å¤§å…³é”®é—®ç­”ä»»åŠ¡ã€‚æ¯ä¸ªé—®ç­”å¯¹éƒ½æä¾›äº† OpenQA å’Œ CloseQA ä¸¤ç§æ ¼å¼ï¼Œä»¥æ”¯æŒç»†ç²’åº¦è¯„ä¼°ã€‚ å¤§é‡å®éªŒè¯æ˜ï¼Œå¤§å¤šæ•°ç°æœ‰çš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆæ— è®ºæ˜¯é€šç”¨å‹è¿˜æ˜¯ä»¥è‡ªæˆ‘ä¸­å¿ƒè§†è§’ä¸ºä¸“é•¿ï¼‰åœ¨æ¨å‘æ—¥å¸¸ç”Ÿæ´»ä»¥å¤–çš„é¢†åŸŸæ—¶éƒ½è¡¨ç°å‡ºæ³›åŒ–å›°éš¾ï¼Œè¿™çªæ˜¾äº†å½“å‰æ¨¡å‹çš„å±€é™æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜è¿›è¡Œäº†è‹¥å¹²åˆæ­¥ç ”ç©¶ï¼Œä¾‹å¦‚å¾®è°ƒå’Œå¼ºåŒ–å­¦ä¹ ï¼Œä»¥æ¢ç´¢æ½œåœ¨çš„æ”¹è¿›æ–¹å‘ã€‚æˆ‘ä»¬å¸Œæœ› EgoCross åŠæˆ‘ä»¬éšé™„çš„åˆ†æèƒ½å¤Ÿä½œä¸ºæ¨è¿›é¢å‘é¢†åŸŸè‡ªé€‚åº”ã€é²æ£’çš„è‡ªæˆ‘ä¸­å¿ƒè§†é¢‘ç†è§£çš„åŸºç¡€ã€‚æ•°æ®å’Œä»£ç å°†åœ¨ä»¥ä¸‹åœ°å€å‘å¸ƒï¼š\href{https://github.com/MyUniverse0726/EgoCross}{https://github.com/MyUniverse0726/EgoCross.}</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 15:11:20 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 15:11:20 UTC</p>
<h2 id="53-electromagnetic-simulations-of-antennas-on-gpus-for-machine-learning-applications--53-ç”¨äºæœºå™¨å­¦ä¹ åº”ç”¨çš„-gpu-å¤©çº¿ç”µç£ä»¿çœŸ"><a href="https://arxiv.org/abs/2508.10713"target="_blank" rel="external nofollow noopener noreferrer">#53</a> <a href="https://papers.cool/arxiv/2508.10713"target="_blank" rel="external nofollow noopener noreferrer">Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications</a>  #53 ç”¨äºæœºå™¨å­¦ä¹ åº”ç”¨çš„ GPU å¤©çº¿ç”µç£ä»¿çœŸ</h2>
<p><strong>Authors</strong>: [Murat Temiz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Murat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Murat</a> Temiz), [Vemund Bakken](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vemund"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vemund</a> Bakken)
ä½œè€…ï¼šMurat Temiz, Vemund Bakken</p>
<p>This study proposes an antenna simulation framework powered by graphics processing units (GPUs) based on an open-source electromagnetic (EM) simulation software (gprMax) for machine learning applications of antenna design and optimization. Furthermore, it compares the simulation results with those obtained through commercial EM software. The proposed software framework for machine learning and surrogate model applications will produce antenna data sets consisting of a large number of antenna simulation results using GPUs. Although machine learning methods can attain the optimum solutions for many problems, they are known to be data-hungry and require a great deal of samples for the training stage of the algorithms. However, producing a sufficient number of training samples in EM applications within a limited time is challenging due to the high computational complexity of EM simulations. Therefore, GPUs are utilized in this study to simulate a large number of antennas with predefined or random antenna shape parameters to produce data sets. Moreover, this study also compares various machine learning and deep learning models in terms of antenna parameter estimation performance. This study demonstrates that an entry-level GPU substantially outperforms a high-end CPU in terms of computational performance, while a high-end gaming GPU can achieve around 18 times more computational performance compared to a high-end CPU. Moreover, it is shown that the open-source EM simulation software can deliver similar results to those obtained via commercial software in the simulation of microstrip antennas when the spatial resolution of the simulations is sufficiently fine.
æœ¬ç ”ç©¶æå‡ºäº†ä¸€ä¸ªåŸºäºå›¾å½¢å¤„ç†å•å…ƒï¼ˆGPUï¼‰çš„å¤©çº¿ä»¿çœŸæ¡†æ¶ï¼ŒåŸºäºå¼€æºç”µç£ï¼ˆEMï¼‰ä»¿çœŸè½¯ä»¶ gprMaxï¼Œç”¨äºå¤©çº¿è®¾è®¡ä¸ä¼˜åŒ–çš„æœºå™¨å­¦ä¹ åº”ç”¨ã€‚æ­¤å¤–ï¼Œè¿˜å°†è¯¥ä»¿çœŸç»“æœä¸å•†ä¸šç”µç£è½¯ä»¶å¾—åˆ°çš„ç»“æœè¿›è¡Œäº†æ¯”è¾ƒã€‚ä¸ºæœºå™¨å­¦ä¹ å’Œæ›¿ä»£æ¨¡å‹åº”ç”¨è€Œè®¾è®¡çš„è½¯ä»¶æ¡†æ¶å°†åˆ©ç”¨ GPU ç”ŸæˆåŒ…å«å¤§é‡å¤©çº¿ä»¿çœŸç»“æœçš„å¤©çº¿æ•°æ®é›†ã€‚å°½ç®¡æœºå™¨å­¦ä¹ æ–¹æ³•å¯ä»¥ä¸ºè®¸å¤šé—®é¢˜è·å¾—æœ€ä¼˜è§£ï¼Œä½†å®ƒä»¬é€šå¸¸å¯¹æ•°æ®éœ€æ±‚å¾ˆå¤§ï¼Œéœ€è¦å¤§é‡æ ·æœ¬æ¥è®­ç»ƒç®—æ³•ã€‚ç„¶è€Œï¼Œåœ¨ç”µç£åº”ç”¨ä¸­ï¼Œç”±äºç”µç£ä»¿çœŸçš„é«˜è®¡ç®—å¤æ‚æ€§ï¼Œåœ¨æœ‰é™æ—¶é—´å†…äº§ç”Ÿè¶³å¤Ÿæ•°é‡çš„è®­ç»ƒæ ·æœ¬å…·æœ‰æŒ‘æˆ˜æ€§ã€‚å› æ­¤ï¼Œæœ¬ç ”ç©¶åˆ©ç”¨ GPU å¯¹å…·æœ‰é¢„å®šä¹‰æˆ–éšæœºå¤©çº¿å½¢çŠ¶å‚æ•°çš„å¤§é‡å¤©çº¿è¿›è¡Œä»¿çœŸä»¥ç”Ÿæˆæ•°æ®é›†ã€‚æ­¤å¤–ï¼Œæœ¬ç ”ç©¶è¿˜æ¯”è¾ƒäº†å„ç§æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¤©çº¿å‚æ•°ä¼°è®¡æ€§èƒ½æ–¹é¢çš„è¡¨ç°ã€‚ æœ¬ç ”ç©¶è¡¨æ˜ï¼Œåœ¨è®¡ç®—æ€§èƒ½æ–¹é¢ï¼Œå…¥é—¨çº§ GPU æ˜æ˜¾ä¼˜äºé«˜ç«¯ CPUï¼Œè€Œé«˜ç«¯æ¸¸æˆ GPU çš„è®¡ç®—æ€§èƒ½çº¦ä¸ºé«˜ç«¯ CPU çš„ 18 å€å·¦å³ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜è¡¨æ˜ï¼Œå½“ä»¿çœŸçš„ç©ºé—´åˆ†è¾¨ç‡è¶³å¤Ÿç»†æ—¶ï¼Œå¼€æºç”µç£ä»¿çœŸè½¯ä»¶åœ¨å¾®å¸¦å¤©çº¿ä»¿çœŸä¸­çš„ç»“æœå¯ä¸å•†ä¸šè½¯ä»¶è·å¾—çš„ç»“æœç›¸å½“ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 14:56:04 UTC
å‘å¸ƒï¼š2025-08-14 14:56:04 UTC</p>
<h2 id="54-refn-a-reinforcement-learning-from-network-framework-against-1-dayn-day-exploitations--54-refnä¸€ç§é’ˆå¯¹-1-å¤©å¤šå¤©åˆ©ç”¨çš„æ¥è‡ªç½‘ç»œçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10701"target="_blank" rel="external nofollow noopener noreferrer">#54</a> <a href="https://papers.cool/arxiv/2508.10701"target="_blank" rel="external nofollow noopener noreferrer">REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations</a>  #54 REFNï¼šä¸€ç§é’ˆå¯¹ 1 å¤©/å¤šå¤©åˆ©ç”¨çš„æ¥è‡ªç½‘ç»œçš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶</h2>
<p><strong>Authors</strong>: [Tianlong Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianlong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianlong</a> Yu), [Lihong Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lihong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lihong</a> Liu), [Ziyi Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziyi</a> Zhou), [Fudu Xing](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fudu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fudu</a> Xing), [Kailong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kailong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kailong</a> Wang), [Yang Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yang</a> Yang)
ä½œè€…ï¼šä½™å¤©é¾™ã€åˆ˜ç«‹å®ã€å‘¨å­æ€¡ã€é‚¢ç¦åº¦ã€ç‹å‡¯é¾™ã€æ¨æ´‹</p>
<p>The exploitation of 1 day or n day vulnerabilities poses severe threats to networked devices due to massive deployment scales and delayed patching (average Mean Time To Patch exceeds 60 days). Existing defenses, including host based patching and network based filtering, are inadequate due to limited scalability across diverse devices, compatibility issues especially with embedded or legacy systems, and error prone deployment process (manual patch validation). To address these issues, we introduce REFN (Reinforcement Learning From Network), a novel framework that trains Large Language Models (LLMs) to autonomously generate network filters to prevent 1 day or n day exploitations. REFN ensures scalability by uniquely employs Reinforcement Learning (RL) driven by online network rewards instead of traditional Human Feedback (RLHF). REFN guarantees compatibility via unified deployment on edge security gateways (Amazon Eero). REFN provides robustness via online validation using real network traffic. Crucially, REFN addresses three core challenges in training LLMs for exploit prevention: 1) expanding current LLMs limited vulnerability fixing expertise via Agentic RAG based Knowledge Distillation, 2) bridging current LLMs language to network gaps through an RL From VNF Pipeline that translates language context (vulnerability description) into network enforcement, 3) addressing the LLM hallucination and non determinism via the Online Agentic Validation that penalizes erroneous outputs. Evaluated across 22 families of 1 day or n day exploits, REFN demonstrates effectiveness (21.1 percent higher accuracy than alternatives), efficiency (Mean Time To Patch of 3.65 hours) and scalability (easily scale to 10K devices). REFN serves as an initial step toward training LLMs to rapidly prevent massive scale 1 day or n day exploitations.
åˆ©ç”¨ 1 æ—¥æˆ– n æ—¥æ¼æ´è¿›è¡Œçš„æ”»å‡»å¯¹è”ç½‘è®¾å¤‡æ„æˆä¸¥é‡å¨èƒï¼ŒåŸå› åœ¨äºå¤§è§„æ¨¡éƒ¨ç½²å’Œè¡¥ä¸å»¶è¿Ÿï¼ˆå¹³å‡ä¿®è¡¥æ—¶é—´è¶…è¿‡ 60 å¤©ï¼‰ã€‚ç°æœ‰é˜²å¾¡æªæ–½ï¼ŒåŒ…æ‹¬åŸºäºä¸»æœºçš„è¡¥ä¸å’ŒåŸºäºç½‘ç»œçš„è¿‡æ»¤ï¼Œç”±äºåœ¨å„ç§è®¾å¤‡ä¸Šçš„å¯æ‰©å±•æ€§å—é™ã€ä¸åµŒå…¥å¼æˆ–é—ç•™ç³»ç»Ÿçš„å…¼å®¹æ€§é—®é¢˜ä»¥åŠæ˜“å‡ºé”™çš„éƒ¨ç½²æµç¨‹ï¼ˆæ‰‹åŠ¨è¡¥ä¸éªŒè¯ï¼‰ï¼Œæ— æ³•å……åˆ†åº”å¯¹è¿™äº›å¨èƒã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† REFNï¼ˆReinforcement Learning From Networkï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ–°é¢–çš„æ¡†æ¶ï¼Œç”¨äºè®­ç»ƒ LLMs ä»¥è‡ªä¸»ç”Ÿæˆç½‘ç»œè¿‡æ»¤å™¨æ¥é˜²æ­¢ 1 æ—¥æˆ– n æ—¥æ¼æ´è¢«åˆ©ç”¨ã€‚REFN é€šè¿‡ç‹¬ç‰¹åœ°é‡‡ç”¨ç”±åœ¨çº¿ç½‘ç»œå¥–åŠ±é©±åŠ¨çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è€Œéä¼ ç»Ÿçš„äººç±»åé¦ˆï¼ˆRLHFï¼‰æ¥ç¡®ä¿å¯æ‰©å±•æ€§ã€‚REFN é€šè¿‡åœ¨è¾¹ç¼˜å®‰å…¨ç½‘å…³ï¼ˆAmazon Eeroï¼‰ä¸Šçš„ç»Ÿä¸€éƒ¨ç½²ä¿è¯å…¼å®¹æ€§ã€‚REFN é€šè¿‡ä½¿ç”¨çœŸå®ç½‘ç»œæµé‡è¿›è¡Œåœ¨çº¿éªŒè¯æ¥æä¾›é²æ£’æ€§ã€‚ å…³é”®æ˜¯ï¼ŒREFN é€šè¿‡ä¸‰é¡¹æ ¸å¿ƒæŒ‘æˆ˜æ¥è®­ç»ƒ LLMs ä»¥è¿›è¡Œæ¼æ´åˆ©ç”¨é˜²æŠ¤ï¼š1ï¼‰é€šè¿‡åŸºäº Agentic RAG çš„çŸ¥è¯†è’¸é¦æ‰©å±•å½“å‰ LLMs åœ¨æ¼æ´ä¿®å¤æ–¹é¢æœ‰é™çš„ä¸“ä¸šçŸ¥è¯†ï¼Œ2ï¼‰é€šè¿‡ä» VNF çš„ RL ç®¡é“å°†è¯­è¨€ä¸Šä¸‹æ–‡ï¼ˆæ¼æ´æè¿°ï¼‰è½¬åŒ–ä¸ºç½‘ç»œæ‰§è¡Œï¼Œå¼¥åˆå½“å‰ LLMs åœ¨è¯­è¨€åˆ°ç½‘ç»œæ–¹é¢çš„å·®è·ï¼Œ3ï¼‰é€šè¿‡åœ¨çº¿ Agentic éªŒè¯æƒ©ç½šé”™è¯¯è¾“å‡ºä»¥è§£å†³ LLM å¹»è§‰å’Œéç¡®å®šæ€§é—®é¢˜ã€‚åœ¨å¯¹ 22 ä¸ª 1 day æˆ– n day æ¼æ´åˆ©ç”¨å®¶æ—çš„è¯„ä¼°ä¸­ï¼ŒREFN å±•ç°å‡ºæœ‰æ•ˆæ€§ï¼ˆå‡†ç¡®ç‡æ¯”å…¶ä»–æ–¹æ³•é«˜ 21.1%ï¼‰ã€æ•ˆç‡ï¼ˆå¹³å‡ä¿®è¡¥æ—¶é—´ä¸º 3.65 å°æ—¶ï¼‰å’Œå¯æ‰©å±•æ€§ï¼ˆå¯è½»æ¾æ‰©å±•åˆ° 10K å°è®¾å¤‡ï¼‰ã€‚REFN ä½œä¸ºè®­ç»ƒ LLMs å¿«é€Ÿé˜²æ­¢å¤§è§„æ¨¡ 1 day æˆ– n day æ¼ç”¨çš„åˆæ­¥æ­¥éª¤ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 14:45:45 UTC
å‘å¸ƒï¼š2025-08-14 14:45:45 åè°ƒä¸–ç•Œæ—¶ï¼ˆUTCï¼‰</p>
<h2 id="55-learning-from-natural-language-feedback-for-personalized-question-answering--55-ä»è‡ªç„¶è¯­è¨€åé¦ˆä¸­å­¦ä¹ ä»¥å®ç°ä¸ªæ€§åŒ–é—®ç­”"><a href="https://arxiv.org/abs/2508.10695"target="_blank" rel="external nofollow noopener noreferrer">#55</a> <a href="https://papers.cool/arxiv/2508.10695"target="_blank" rel="external nofollow noopener noreferrer">Learning from Natural Language Feedback for Personalized Question Answering</a>  #55 ä»è‡ªç„¶è¯­è¨€åé¦ˆä¸­å­¦ä¹ ä»¥å®ç°ä¸ªæ€§åŒ–é—®ç­”</h2>
<p><strong>Authors</strong>: [Alireza Salemi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alireza"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alireza</a> Salemi), [Hamed Zamani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hamed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hamed</a> Zamani)
ä½œè€…ï¼šAlireza Salemiï¼ŒHamed Zamani</p>
<p>Personalization is crucial for enhancing both the effectiveness and user satisfaction of language technologies, particularly in information-seeking tasks like question answering. Current approaches for personalizing large language models (LLMs) often rely on retrieval-augmented generation (RAG), followed by reinforcement learning with scalar reward signals to teach models how to use retrieved personal context. We believe that these scalar rewards sometimes provide weak, non-instructive feedback, limiting learning efficiency and personalization quality. We introduce VAC, a novel framework for personalized response generation that replaces scalar rewards with natural language feedback (NLF) that are generated conditioned on the user profiles and the question narratives. NLF serves as a rich and actionable supervision signal, allowing the policy model to iteratively refine its outputs and internalize effective personalization strategies. Training alternates between optimizing the feedback model and fine-tuning the policy model on the improved responses, resulting in a policy model that no longer requires feedback at inference. Evaluation on the LaMP-QA benchmark that consists of three diverse domains demonstrates consistent and significant improvements over the state-of-the-art results. Human evaluations further confirm the superior quality of the generated responses. These results demonstrate that NLF provides more effective signals for optimizing personalized question answering.
ä¸ªæ€§åŒ–å¯¹äºæå‡è¯­è¨€æŠ€æœ¯çš„æœ‰æ•ˆæ€§å’Œç”¨æˆ·æ»¡æ„åº¦è‡³å…³é‡è¦ï¼Œå°¤å…¶æ˜¯åœ¨è¯¸å¦‚é—®ç­”ç­‰ä¿¡æ¯æ£€ç´¢ä»»åŠ¡ä¸­ã€‚å½“å‰ç”¨äºä¸ªæ€§åŒ–å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ–¹æ³•é€šå¸¸ä¾èµ–æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ï¼Œéšåé€šè¿‡å¸¦æ ‡é‡å›æŠ¥ä¿¡å·çš„å¼ºåŒ–å­¦ä¹ æ¥æ•™æ¨¡å‹å¦‚ä½•ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸ªäººä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™äº›æ ‡é‡å›æŠ¥æœ‰æ—¶æä¾›çš„åé¦ˆè–„å¼±ä¸”ç¼ºä¹æŒ‡å¯¼æ€§ï¼Œé™åˆ¶äº†å­¦ä¹ æ•ˆç‡å’Œä¸ªæ€§åŒ–è´¨é‡ã€‚æˆ‘ä»¬æå‡ºäº† VACï¼Œä¸€ç§ç”¨äºä¸ªæ€§åŒ–å“åº”ç”Ÿæˆçš„æ–°æ¡†æ¶ï¼Œç”¨ä»¥ç”¨åŸºäºç”¨æˆ·ç”»åƒå’Œé—®é¢˜å™è¿°æ¡ä»¶ç”Ÿæˆçš„è‡ªç„¶è¯­è¨€åé¦ˆï¼ˆNLFï¼‰æ›¿ä»£æ ‡é‡å›æŠ¥ã€‚NLF ä½œä¸ºä¸€ç§ä¸°å¯Œä¸”å¯æ“ä½œçš„ç›‘ç£ä¿¡å·ï¼Œä½¿ç­–ç•¥æ¨¡å‹èƒ½å¤Ÿè¿­ä»£åœ°ä¼˜åŒ–å…¶è¾“å‡ºå¹¶å†…åŒ–æœ‰æ•ˆçš„ä¸ªæ€§åŒ–ç­–ç•¥ã€‚è®­ç»ƒåœ¨ä¼˜åŒ–åé¦ˆæ¨¡å‹å’Œåœ¨æ”¹è¿›çš„å“åº”ä¸Šå¾®è°ƒç­–ç•¥æ¨¡å‹ä¹‹é—´äº¤æ›¿è¿›è¡Œï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªåœ¨æ¨ç†æ—¶ä¸å†éœ€è¦åé¦ˆçš„ç­–ç•¥æ¨¡å‹ã€‚ åœ¨ç”±ä¸‰ç§ä¸åŒé¢†åŸŸç»„æˆçš„ LaMP-QA åŸºå‡†ä¸Šçš„è¯„ä¼°æ˜¾ç¤ºï¼Œç›¸è¾ƒäºç›®å‰æœ€å…ˆè¿›çš„ç»“æœï¼Œæ€§èƒ½æŒç»­ä¸”æ˜¾è‘—æå‡ã€‚äººå·¥è¯„ä¼°è¿›ä¸€æ­¥ç¡®è®¤äº†ç”Ÿæˆå›ç­”çš„æ›´é«˜è´¨é‡ã€‚è¿™äº›ç»“æœè¡¨æ˜ï¼ŒNLF ä¸ºä¼˜åŒ–ä¸ªæ€§åŒ–é—®ç­”æä¾›äº†æ›´æœ‰æ•ˆçš„ä¿¡å·ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€ä¿¡æ¯æ£€ç´¢</p>
<p><strong>Publish</strong>: 2025-08-14 14:36:53 UTC
å‘å¸ƒï¼š2025-08-14 14:36:53 UTC</p>
<h2 id="56-continuous-bangla-sign-language-translation-mitigating-the-expense-of-gloss-annotation-with-the-assistance-of-graph--56-è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘åœ¨å›¾ç»“æ„è¾…åŠ©ä¸‹ç¼“è§£æ³¨é‡Šæ‰‹è¯­è¯æ±‡glossæˆæœ¬"><a href="https://arxiv.org/abs/2508.10687"target="_blank" rel="external nofollow noopener noreferrer">#56</a> <a href="https://papers.cool/arxiv/2508.10687"target="_blank" rel="external nofollow noopener noreferrer">Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph</a>  #56 è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘ï¼šåœ¨å›¾ç»“æ„è¾…åŠ©ä¸‹ç¼“è§£æ³¨é‡Šæ‰‹è¯­è¯æ±‡ï¼ˆglossï¼‰æˆæœ¬</h2>
<p><strong>Authors</strong>: [Safaeid Hossain Arib](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Safaeid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Safaeid</a> Hossain Arib), [Rabeya Akter](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rabeya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rabeya</a> Akter), [Sejuti Rahman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sejuti"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sejuti</a> Rahman)
ä½œè€…ï¼šSafaeid Hossain Aribã€Rabeya Akterã€Sejuti Rahman</p>
<p>Millions of individuals worldwide are affected by deafness and hearing impairment. Sign language serves as a sophisticated means of communication for the deaf and hard of hearing. However, in societies that prioritize spoken languages, sign language often faces underestimation, leading to communication barriers and social exclusion. The Continuous Bangla Sign Language Translation project aims to address this gap by enhancing translation methods. While recent approaches leverage transformer architecture for state-of-the-art results, our method integrates graph-based methods with the transformer architecture. This fusion, combining transformer and STGCN-LSTM architectures, proves more effective in gloss-free translation. Our contributions include architectural fusion, exploring various fusion strategies, and achieving a new state-of-the-art performance on diverse sign language datasets, namely RWTH-PHOENIX-2014T, CSL-Daily, How2Sign, and BornilDB v1.0. Our approach demonstrates superior performance compared to current translation outcomes across all datasets, showcasing notable improvements of BLEU-4 scores of 4.01, 2.07, and 0.5, surpassing those of GASLT, GASLT and slt_how2sign in RWTH-PHOENIX-2014T, CSL-Daily, and How2Sign, respectively. Also, we introduce benchmarking on the BornilDB v1.0 dataset for the first time. Our method sets a benchmark for future research, emphasizing the importance of gloss-free translation to improve communication accessibility for the deaf and hard of hearing.
å…¨çƒæœ‰æ•°ç™¾ä¸‡äººå—è‹å“‘å’Œå¬åŠ›æŸå¤±å½±å“ã€‚æ‰‹è¯­æ˜¯è‹äººå’Œå¬åŠ›å—æŸè€…çš„ä¸€ç§å¤æ‚çš„äº¤æµæ–¹å¼ã€‚ç„¶è€Œï¼Œåœ¨ä»¥å£è¯­ä¸ºä¸»çš„ç¤¾ä¼šä¸­ï¼Œæ‰‹è¯­å¸¸è¢«ä½ä¼°ï¼Œå¯¼è‡´äº¤æµéšœç¢å’Œç¤¾ä¼šæ’æ–¥ã€‚è¿ç»­å­ŸåŠ æ‹‰æ‰‹è¯­ç¿»è¯‘é¡¹ç›®æ—¨åœ¨é€šè¿‡æ”¹è¿›ç¿»è¯‘æ–¹æ³•æ¥å¼¥è¡¥è¿™ä¸€å·®è·ã€‚å°½ç®¡è¿‘æœŸæ–¹æ³•åˆ©ç”¨å˜æ¢å™¨ï¼ˆtransformerï¼‰æ¶æ„å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœï¼Œæˆ‘ä»¬çš„æ–¹æ³•å°†åŸºäºå›¾çš„æ–¹æ³•ä¸å˜æ¢å™¨æ¶æ„ç›¸ç»“åˆã€‚è¿™ç§èåˆâ€”â€”å°†å˜æ¢å™¨ä¸ STGCN-LSTM æ¶æ„ç»“åˆâ€”â€”åœ¨æ— è¯æ±‡æ³¨é‡Šï¼ˆgloss-freeï¼‰ç¿»è¯‘ä¸­è¯æ˜æ›´ä¸ºæœ‰æ•ˆã€‚ æˆ‘ä»¬çš„è´¡çŒ®åŒ…æ‹¬æ¶æ„èåˆã€æ¢ç´¢å¤šç§èåˆç­–ç•¥ï¼Œå¹¶åœ¨å¤šä¸ªæ‰‹è¯­æ•°æ®é›†ä¸Šå–å¾—äº†æ–°çš„æœ€å…ˆè¿›æ€§èƒ½ï¼Œå…·ä½“ä¸º RWTH-PHOENIX-2014Tã€CSL-Dailyã€How2Sign å’Œ BornilDB v1.0ã€‚ä¸å½“å‰å„æ•°æ®é›†çš„ç¿»è¯‘ç»“æœç›¸æ¯”ï¼Œæˆ‘ä»¬çš„æ–¹æ³•è¡¨ç°æ›´ä¼˜ï¼Œåœ¨ BLEU-4 åˆ†æ•°ä¸Šå–å¾—äº†æ˜¾è‘—æå‡ï¼šåœ¨ RWTH-PHOENIX-2014Tã€CSL-Daily å’Œ How2Sign ä¸Šåˆ†åˆ«è¾ƒ GASLTã€GASLT å’Œ slt_how2sign æé«˜äº† 4.01ã€2.07 å’Œ 0.5ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é¦–æ¬¡åœ¨ BornilDB v1.0 æ•°æ®é›†ä¸Šå¼•å…¥äº†åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä¸ºæœªæ¥ç ”ç©¶è®¾ç«‹äº†åŸºå‡†ï¼Œå¼ºè°ƒæ— è¯æ±‡æ³¨é‡Šï¼ˆgloss-freeï¼‰ç¿»è¯‘åœ¨æå‡è‹äººå’Œå¬åŠ›å—æŸè€…æ²Ÿé€šå¯åŠæ€§æ–¹é¢çš„é‡è¦æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 14:32:31 UTC
å‘å¸ƒï¼š2025-08-14 14:32:31 UTC</p>
<h2 id="57-hybrid-generative-fusion-for-efficient-and-privacy-preserving-face-recognition-dataset-generation--57-æ··åˆç”Ÿæˆèåˆç”¨äºé«˜æ•ˆä¸”éšç§ä¿æŠ¤çš„äººè„¸è¯†åˆ«æ•°æ®é›†ç”Ÿæˆ"><a href="https://arxiv.org/abs/2508.10672"target="_blank" rel="external nofollow noopener noreferrer">#57</a> <a href="https://papers.cool/arxiv/2508.10672"target="_blank" rel="external nofollow noopener noreferrer">Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation</a>  #57 æ··åˆç”Ÿæˆèåˆç”¨äºé«˜æ•ˆä¸”éšç§ä¿æŠ¤çš„äººè„¸è¯†åˆ«æ•°æ®é›†ç”Ÿæˆ</h2>
<p><strong>Authors</strong>: [Feiran Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Feiran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Feiran</a> Li), [Qianqian Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qianqian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qianqian</a> Xu), [Shilong Bao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shilong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shilong</a> Bao), [Boyu Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Boyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Boyu</a> Han), [Zhiyong Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyong</a> Yang), [Qingming Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingming</a> Huang)
ä½œè€…ï¼šFeiran Liã€Qianqian Xuã€Shilong Baoã€Boyu Hanã€Zhiyong Yangã€Qingming Huang</p>
<p>In this paper, we present our approach to the DataCV ICCV Challenge, which centers on building a high-quality face dataset to train a face recognition model. The constructed dataset must not contain identities overlapping with any existing public face datasets. To handle this challenge, we begin with a thorough cleaning of the baseline HSFace dataset, identifying and removing mislabeled or inconsistent identities through a Mixture-of-Experts (MoE) strategy combining face embedding clustering and GPT-4o-assisted verification. We retain the largest consistent identity cluster and apply data augmentation up to a fixed number of images per identity. To further diversify the dataset, we generate synthetic identities using Stable Diffusion with prompt engineering. As diffusion models are computationally intensive, we generate only one reference image per identity and efficiently expand it using Vec2Face, which rapidly produces 49 identity-consistent variants. This hybrid approach fuses GAN-based and diffusion-based samples, enabling efficient construction of a diverse and high-quality dataset. To address the high visual similarity among synthetic identities, we adopt a curriculum learning strategy by placing them early in the training schedule, allowing the model to progress from easier to harder samples. Our final dataset contains 50 images per identity, and all newly generated identities are checked with mainstream face datasets to ensure no identity leakage. Our method achieves \textbf{1st place} in the competition, and experimental results show that our dataset improves model performance across 10K, 20K, and 100K identity scales. Code is available at <a href="https://github.com/Ferry-Li/datacv_fr"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Ferry-Li/datacv_fr</a>.
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»‹ç»äº†ç”¨äº DataCV ICCV æŒ‘æˆ˜èµ›çš„æ–¹æ³•ï¼Œè¯¥æŒ‘æˆ˜çš„æ ¸å¿ƒæ˜¯åœ¨ä¸ä¸ä»»ä½•ç°æœ‰å…¬å¼€äººè„¸æ•°æ®é›†é‡åˆèº«ä»½çš„å‰æä¸‹ï¼Œæ„å»ºç”¨äºè®­ç»ƒäººè„¸è¯†åˆ«æ¨¡å‹çš„é«˜è´¨é‡äººè„¸æ•°æ®é›†ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é¦–å…ˆå¯¹åŸºçº¿ HSFace æ•°æ®é›†è¿›è¡Œäº†å½»åº•æ¸…ç†ï¼Œé€šè¿‡ä¸€ç§ä¸“å®¶æ··åˆï¼ˆMixture-of-Expertsï¼ŒMoEï¼‰ç­–ç•¥ç»“åˆäººè„¸åµŒå…¥èšç±»å’Œ GPT-4o è¾…åŠ©éªŒè¯ï¼Œè¯†åˆ«å¹¶ç§»é™¤æ ‡æ³¨é”™è¯¯æˆ–ä¸ä¸€è‡´çš„èº«ä»½ã€‚æˆ‘ä»¬ä¿ç•™æ¯ä¸ªèº«ä»½ä¸­æœ€å¤§ä¸”ä¸€è‡´çš„èšç±»ï¼Œå¹¶å¯¹æ¯ä¸ªèº«ä»½åº”ç”¨æ•°æ®å¢å¼ºï¼Œç›´è‡³è¾¾åˆ°å›ºå®šçš„å›¾åƒæ•°é‡ä¸Šé™ã€‚ä¸ºè¿›ä¸€æ­¥ä¸°å¯Œæ•°æ®é›†ï¼Œæˆ‘ä»¬ä½¿ç”¨å¸¦æœ‰æç¤ºå·¥ç¨‹çš„ Stable Diffusion ç”Ÿæˆåˆæˆèº«ä»½ã€‚ç”±äºæ‰©æ•£æ¨¡å‹è®¡ç®—æˆæœ¬é«˜æ˜‚ï¼Œæˆ‘ä»¬é’ˆå¯¹æ¯ä¸ªèº«ä»½ä»…ç”Ÿæˆä¸€å¼ å‚è€ƒå›¾åƒï¼Œå¹¶ä½¿ç”¨ Vec2Face é«˜æ•ˆæ‰©å±•è¯¥å›¾åƒï¼Œå¿«é€Ÿç”Ÿæˆ 49 å¼ ä¸èº«ä»½ä¸€è‡´çš„å˜ä½“ã€‚è¿™ç§æ··åˆæ–¹æ³•èåˆäº†åŸºäº GAN å’ŒåŸºäºæ‰©æ•£çš„æ ·æœ¬ï¼Œä½¿å¾—èƒ½å¤Ÿé«˜æ•ˆæ„å»ºå¤šæ ·ä¸”é«˜è´¨é‡çš„æ•°æ®é›†ã€‚ ä¸ºäº†è§£å†³åˆæˆèº«ä»½ä¹‹é—´é«˜åº¦çš„è§†è§‰ç›¸ä¼¼æ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†è¯¾ç¨‹å­¦ä¹ ç­–ç•¥ï¼Œå°†å®ƒä»¬å®‰æ’åœ¨è®­ç»ƒæ—¥ç¨‹çš„æ—©æœŸï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä»æ›´å®¹æ˜“çš„æ ·æœ¬é€æ­¥è¿‡æ¸¡åˆ°æ›´éš¾çš„æ ·æœ¬ã€‚æˆ‘ä»¬çš„æœ€ç»ˆæ•°æ®é›†æ¯ä¸ªèº«ä»½åŒ…å« 50 å¼ å›¾åƒï¼Œæ‰€æœ‰æ–°ç”Ÿæˆçš„èº«ä»½å‡ä¸ä¸»æµäººè„¸æ•°æ®é›†è¿›è¡Œæ ¸æŸ¥ä»¥ç¡®ä¿æ— èº«ä»½æ³„éœ²ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨æ¯”èµ›ä¸­è·å¾—äº†ç¬¬ä¸€åï¼Œå®éªŒç»“æœè¡¨æ˜æˆ‘ä»¬çš„æ•°æ®é›†åœ¨ 10Kã€20K å’Œ 100K èº«ä»½è§„æ¨¡ä¸‹å‡èƒ½æå‡æ¨¡å‹æ€§èƒ½ã€‚ä»£ç å¯åœ¨ <a href="https://github.com/Ferry-Li/datacv_fr"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/Ferry-Li/datacv_fr</a> è·å–ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 14:14:18 UTC
å‘å¸ƒï¼š2025-08-14 14:14:18 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="58-addressvlm-cross-view-alignment-tuning-for-image-address-localization-using-large-vision-language-models--58-addressvlmç”¨äºå›¾åƒåœ°å€å®šä½çš„å¤§å‹è§†å¬è¯­è¨€æ¨¡å‹çš„è·¨è§†å›¾å¯¹é½å¾®è°ƒ"><a href="https://arxiv.org/abs/2508.10667"target="_blank" rel="external nofollow noopener noreferrer">#58</a> <a href="https://papers.cool/arxiv/2508.10667"target="_blank" rel="external nofollow noopener noreferrer">AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models</a>  #58 AddressVLMï¼šç”¨äºå›¾åƒåœ°å€å®šä½çš„å¤§å‹è§†å¬è¯­è¨€æ¨¡å‹çš„è·¨è§†å›¾å¯¹é½å¾®è°ƒ</h2>
<p><strong>Authors</strong>: [Shixiong Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shixiong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shixiong</a> Xu), [Chenghao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chenghao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chenghao</a> Zhang), [Lubin Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lubin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lubin</a> Fan), [Yuan Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Zhou), [Bin Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bin</a> Fan), [Shiming Xiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiming</a> Xiang), [Gaofeng Meng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gaofeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gaofeng</a> Meng), [Jieping Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jieping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jieping</a> Ye)
ä½œè€…ï¼šè®¸ä¸–é›„ã€å¼ æˆæµ©ã€æ¨Šé²æ–Œã€å‘¨è¿œã€æ¨Šæ–Œã€é¡¹ä¸–æ˜ã€å­Ÿé«˜å³°ã€å¶æ°å¹³</p>
<p>Large visual language models (LVLMs) have demonstrated impressive performance in coarse-grained geo-localization at the country or city level, but they struggle with fine-grained street-level localization within urban areas. In this paper, we explore integrating city-wide address localization capabilities into LVLMs, facilitating flexible address-related question answering using street-view images. A key challenge is that the street-view visual question-and-answer (VQA) data provides only microscopic visual cues, leading to subpar performance in fine-tuned models. To tackle this issue, we incorporate perspective-invariant satellite images as macro cues and propose cross-view alignment tuning including a satellite-view and street-view image grafting mechanism, along with an automatic label generation mechanism. Then LVLM&rsquo;s global understanding of street distribution is enhanced through cross-view matching. Our proposed model, named AddressVLM, consists of two-stage training protocols: cross-view alignment tuning and address localization tuning. Furthermore, we have constructed two street-view VQA datasets based on image address localization datasets from Pittsburgh and San Francisco. Qualitative and quantitative evaluations demonstrate that AddressVLM outperforms counterpart LVLMs by over 9% and 12% in average address localization accuracy on these two datasets, respectively.
å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMï¼‰åœ¨å›½å®¶æˆ–åŸå¸‚çº§åˆ«çš„ç²—ç²’åº¦åœ°ç†å®šä½æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œä½†åœ¨åŸå¸‚åŒºåŸŸå†…çš„ç»†ç²’åº¦è¡—é“çº§å®šä½ä¸Šå­˜åœ¨å›°éš¾ã€‚æœ¬æ–‡æ¢è®¨äº†å°†å…¨å¸‚èŒƒå›´çš„åœ°å€å®šä½èƒ½åŠ›æ•´åˆåˆ° LVLM ä¸­ï¼Œä»¥ä¾¿ä½¿ç”¨è¡—æ™¯å›¾åƒè¿›è¡Œçµæ´»çš„ä¸åœ°å€ç›¸å…³çš„é—®ç­”ã€‚ä¸€ä¸ªå…³é”®æŒ‘æˆ˜åœ¨äºè¡—æ™¯è§†è§‰é—®ç­”ï¼ˆVQAï¼‰æ•°æ®ä»…æä¾›å¾®è§‚è§†è§‰çº¿ç´¢ï¼Œå¯¼è‡´å¾®è°ƒåçš„æ¨¡å‹è¡¨ç°ä¸ä½³ã€‚ä¸ºäº†è§£å†³æ­¤é—®é¢˜ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä½œä¸ºå®è§‚çº¿ç´¢çš„è§†è§’ä¸å˜çš„å«æ˜Ÿå›¾åƒï¼Œå¹¶æå‡ºäº†è·¨è§†å›¾å¯¹é½å¾®è°ƒæ–¹æ³•ï¼ŒåŒ…æ‹¬å«æ˜Ÿè§†å›¾ä¸è¡—æ™¯è§†å›¾å›¾åƒå«æ¥æœºåˆ¶ï¼Œä»¥åŠè‡ªåŠ¨æ ‡ç­¾ç”Ÿæˆæœºåˆ¶ã€‚éšåé€šè¿‡è·¨è§†å›¾åŒ¹é…å¢å¼ºäº† LVLM å¯¹è¡—é“åˆ†å¸ƒçš„å…¨å±€ç†è§£ã€‚æˆ‘ä»¬æå‡ºçš„æ¨¡å‹ç§°ä¸º AddressVLMï¼Œç”±ä¸¤é˜¶æ®µè®­ç»ƒæ–¹æ¡ˆç»„æˆï¼šè·¨è§†å›¾å¯¹é½å¾®è°ƒå’Œåœ°å€å®šä½å¾®è°ƒã€‚ æ­¤å¤–ï¼Œæˆ‘ä»¬åŸºäºåŒ¹å…¹å ¡å’Œæ—§é‡‘å±±çš„å›¾åƒåœ°å€å®šä½æ•°æ®é›†æ„å»ºäº†ä¸¤ä¸ªè¡—æ™¯è§†è§‰é—®ç­”æ•°æ®é›†ã€‚å®šæ€§å’Œå®šé‡è¯„ä¼°æ˜¾ç¤ºï¼ŒAddressVLM åœ¨è¿™ä¸¤ä¸ªæ•°æ®é›†ä¸Šçš„å¹³å‡åœ°å€å®šä½å‡†ç¡®ç‡åˆ†åˆ«æ¯”å…¶ä»–åŒç±»å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹é«˜å‡ºè¶…è¿‡ 9% å’Œ 12%ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 14:06:28 UTC
å‘å¸ƒï¼š2025-08-14 14:06:28 UTC</p>
<h2 id="59-deep-learning-in-classical-and-quantum-physics--59-ç»å…¸ä¸é‡å­ç‰©ç†ä¸­çš„æ·±åº¦å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10666"target="_blank" rel="external nofollow noopener noreferrer">#59</a> <a href="https://papers.cool/arxiv/2508.10666"target="_blank" rel="external nofollow noopener noreferrer">Deep Learning in Classical and Quantum Physics</a>  #59 ç»å…¸ä¸é‡å­ç‰©ç†ä¸­çš„æ·±åº¦å­¦ä¹ </h2>
<p><strong>Authors</strong>: [Timothy Heightman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Timothy"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Timothy</a> Heightman), [Marcin PÅ‚odzieÅ„](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Marcin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Marcin</a> PÅ‚odzieÅ„)
ä½œè€…ï¼šTimothy Heightmanï¼ŒMarcin PÅ‚odzieÅ„</p>
<p>Scientific progress is tightly coupled to the emergence of new research tools. Today, machine learning (ML)-especially deep learning (DL)-has become a transformative instrument for quantum science and technology. Owing to the intrinsic complexity of quantum systems, DL enables efficient exploration of large parameter spaces, extraction of patterns from experimental data, and data-driven guidance for research directions. These capabilities already support tasks such as refining quantum control protocols and accelerating the discovery of materials with targeted quantum properties, making ML/DL literacy an essential skill for the next generation of quantum scientists. At the same time, DL&rsquo;s power brings risks: models can overfit noisy data, obscure causal structure, and yield results with limited physical interpretability. Recognizing these limitations and deploying mitigation strategies is crucial for scientific rigor. These lecture notes provide a comprehensive, graduate-level introduction to DL for quantum applications, combining conceptual exposition with hands-on examples. Organized as a progressive sequence, they aim to equip readers to decide when and how to apply DL effectively, to understand its practical constraints, and to adapt AI methods responsibly to problems across quantum physics, chemistry, and engineering.
ç§‘å­¦è¿›æ­¥ä¸æ–°ç ”ç©¶å·¥å…·çš„å‡ºç°å¯†åˆ‡ç›¸å…³ã€‚å¦‚ä»Šï¼Œæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰â€”â€”å°¤å…¶æ˜¯æ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰â€”â€”å·²æˆä¸ºé‡å­ç§‘å­¦ä¸æŠ€æœ¯çš„å˜é©æ€§å·¥å…·ã€‚ç”±äºé‡å­ç³»ç»Ÿçš„å†…åœ¨å¤æ‚æ€§ï¼Œæ·±åº¦å­¦ä¹ èƒ½å¤Ÿé«˜æ•ˆæ¢ç´¢å¤§è§„æ¨¡å‚æ•°ç©ºé—´ã€ä»å®éªŒæ•°æ®ä¸­æå–æ¨¡å¼ï¼Œå¹¶ä¸ºç ”ç©¶æ–¹å‘æä¾›æ•°æ®é©±åŠ¨çš„æŒ‡å¯¼ã€‚è¿™äº›èƒ½åŠ›å·²æ”¯æŒè¯¸å¦‚ä¼˜åŒ–é‡å­æ§åˆ¶åè®®å’ŒåŠ é€Ÿå…·æœ‰ç‰¹å®šé‡å­ç‰¹æ€§çš„ææ–™å‘ç°ç­‰ä»»åŠ¡ï¼Œä½¿å¾—æŒæ¡ ML/DL æˆä¸ºä¸‹ä¸€ä»£é‡å­ç§‘å­¦å®¶çš„ä¸€é¡¹å¿…å¤‡æŠ€èƒ½ã€‚ä¸æ­¤åŒæ—¶ï¼Œæ·±åº¦å­¦ä¹ çš„å¼ºå¤§ä¹Ÿå¸¦æ¥é£é™©ï¼šæ¨¡å‹å¯èƒ½å¯¹å™ªå£°æ•°æ®è¿‡æ‹Ÿåˆã€æ©ç›–å› æœç»“æ„ï¼Œå¹¶äº§ç”Ÿç‰©ç†å¯è§£é‡Šæ€§æœ‰é™çš„ç»“æœã€‚è®¤è¯†åˆ°è¿™äº›å±€é™å¹¶éƒ¨ç½²ç¼“è§£ç­–ç•¥å¯¹äºç§‘å­¦ä¸¥è°¨æ€§è‡³å…³é‡è¦ã€‚è¿™äº›è®²ä¹‰æä¾›äº†é¢å‘é‡å­åº”ç”¨çš„å…¨é¢ç ”ç©¶ç”Ÿæ°´å¹³çš„æ·±åº¦å­¦ä¹ å…¥é—¨ï¼Œç»“åˆäº†æ¦‚å¿µæ€§é˜è¿°ä¸å®è·µç¤ºä¾‹ã€‚ ä½œä¸ºä¸€ä¸ªæ¸è¿›çš„åºåˆ—ç¼–æ’ï¼Œå®ƒä»¬æ—¨åœ¨ä½¿è¯»è€…èƒ½å¤Ÿåˆ¤æ–­ä½•æ—¶ä»¥åŠå¦‚ä½•æœ‰æ•ˆåœ°åº”ç”¨æ·±åº¦å­¦ä¹ ï¼Œç†è§£å…¶å®é™…å±€é™ï¼Œå¹¶åœ¨é‡å­ç‰©ç†ã€åŒ–å­¦å’Œå·¥ç¨‹ç­‰é¢†åŸŸè´Ÿè´£ä»»åœ°è°ƒæ•´äººå·¥æ™ºèƒ½æ–¹æ³•ä»¥è§£å†³é—®é¢˜ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/quant-ph"target="_blank" rel="external nofollow noopener noreferrer">Quantum Physics</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.NE"target="_blank" rel="external nofollow noopener noreferrer">Neural and Evolutionary Computing</a>, <a href="https://papers.cool/arxiv/physics.comp-ph"target="_blank" rel="external nofollow noopener noreferrer">Computational Physics</a>
å­¦ç§‘ï¼šé‡å­ç‰©ç†ã€äººå·¥æ™ºèƒ½ã€ç¥ç»ä¸è¿›åŒ–è®¡ç®—ã€è®¡ç®—ç‰©ç†</p>
<p><strong>Publish</strong>: 2025-08-14 14:05:12 UTC
å‘å¸ƒï¼š2025-08-14 14:05:12 UTC</p>
<h2 id="60-serial-over-parallel-learning-continual-unification-for-multi-modal-visual-object-tracking-and-benchmarking--60-ä¸²è¡Œèƒœè¿‡å¹¶è¡Œä¸ºå¤šæ¨¡æ€è§†è§‰ç›®æ ‡è·Ÿè¸ªå­¦ä¹ æŒç»­ç»Ÿä¸€ä¸åŸºå‡†è¯„ä¼°"><a href="https://arxiv.org/abs/2508.10655"target="_blank" rel="external nofollow noopener noreferrer">#60</a> <a href="https://papers.cool/arxiv/2508.10655"target="_blank" rel="external nofollow noopener noreferrer">Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking</a>  #60 ä¸²è¡Œèƒœè¿‡å¹¶è¡Œï¼šä¸ºå¤šæ¨¡æ€è§†è§‰ç›®æ ‡è·Ÿè¸ªå­¦ä¹ æŒç»­ç»Ÿä¸€ä¸åŸºå‡†è¯„ä¼°</h2>
<p><strong>Authors</strong>: [Zhangyong Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhangyong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhangyong</a> Tang), [Tianyang Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianyang</a> Xu), [Xuefeng Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuefeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuefeng</a> Zhu), [Chunyang Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chunyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chunyang</a> Cheng), [Tao Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tao</a> Zhou), [Xiaojun Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaojun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaojun</a> Wu), [Josef Kittler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Josef"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Josef</a> Kittler)
ä½œè€…ï¼šå¼ å‹‡å”ã€è®¸å¤©é˜³ã€æœ±é›ªå³°ã€ç¨‹æ˜¥é˜³ã€å‘¨æ¶›ã€å´æ™“å†›ã€Josef Kittler</p>
<p>Unifying multiple multi-modal visual object tracking (MMVOT) tasks draws increasing attention due to the complementary nature of different modalities in building robust tracking systems. Existing practices mix all data sensor types in a single training procedure, structuring a parallel paradigm from the data-centric perspective and aiming for a global optimum on the joint distribution of the involved tasks. However, the absence of a unified benchmark where all types of data coexist forces evaluations on separated benchmarks, causing \textit{inconsistency} between training and testing, thus leading to performance \textit{degradation}. To address these issues, this work advances in two aspects: \ding{182} A unified benchmark, coined as UniBench300, is introduced to bridge the inconsistency by incorporating multiple task data, reducing inference passes from three to one and cutting time consumption by 27%. \ding{183} The unification process is reformulated in a serial format, progressively integrating new tasks. In this way, the performance degradation can be specified as knowledge forgetting of previous tasks, which naturally aligns with the philosophy of continual learning (CL), motivating further exploration of injecting CL into the unification process. Extensive experiments conducted on two baselines and four benchmarks demonstrate the significance of UniBench300 and the superiority of CL in supporting a stable unification process. Moreover, while conducting dedicated analyses, the performance degradation is found to be negatively correlated with network capacity. Additionally, modality discrepancies contribute to varying degradation levels across tasks (RGBT &gt; RGBD &gt; RGBE in MMVOT), offering valuable insights for future multi-modal vision research. Source codes and the proposed benchmark is available at \textit{https://github.com/Zhangyong-Tang/UniBench300}.
ç»Ÿä¸€å¤šæ¨¡æ€è§†è§‰ç›®æ ‡è·Ÿè¸ªï¼ˆMMVOTï¼‰ä»»åŠ¡å› ä¸åŒæ¨¡æ€åœ¨æ„å»ºé²æ£’è·Ÿè¸ªç³»ç»Ÿæ—¶çš„äº’è¡¥æ€§è€Œå—åˆ°è¶Šæ¥è¶Šå¤šå…³æ³¨ã€‚ç°æœ‰åšæ³•åœ¨å•ä¸€è®­ç»ƒæµç¨‹ä¸­æ··åˆæ‰€æœ‰ä¼ æ„Ÿå™¨ç±»å‹çš„æ•°æ®ï¼Œä»æ•°æ®ä¸­å¿ƒè§†è§’æ„å»ºå¹¶è¡ŒèŒƒå¼ï¼Œæ—¨åœ¨å¯¹æ‰€æ¶‰ä»»åŠ¡çš„è”åˆåˆ†å¸ƒå¯»æ±‚å…¨å±€æœ€ä¼˜ã€‚ç„¶è€Œï¼Œç¼ºä¹ä¸€ä¸ªåŒ…å«æ‰€æœ‰ç±»å‹æ•°æ®çš„ç»Ÿä¸€åŸºå‡†è¿«ä½¿è¯„ä¼°åœ¨åˆ†ç¦»çš„åŸºå‡†ä¸Šè¿›è¡Œï¼Œå¯¼è‡´è®­ç»ƒä¸æµ‹è¯•ä¹‹é—´çš„â€œä¸ä¸€è‡´â€ï¼Œä»è€Œå¼•å‘æ€§èƒ½â€œé€€åŒ–â€ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæœ¬å·¥ä½œåœ¨ä¸¤æ–¹é¢å–å¾—è¿›å±•ï¼š\ding{182} å¼•å…¥ä¸€ä¸ªåä¸º UniBench300 çš„ç»Ÿä¸€åŸºå‡†ï¼Œé€šè¿‡çº³å…¥å¤šä»»åŠ¡æ•°æ®æ¥å¼¥åˆä¸ä¸€è‡´ï¼Œå°†æ¨ç†æ¬¡æ•°ä»ä¸‰æ¬¡å‡å°‘åˆ°ä¸€æ¬¡ï¼Œæ—¶é—´æ¶ˆè€—é™ä½äº† 27%ã€‚\ding{183} å°†ç»Ÿä¸€è¿‡ç¨‹é‡æ–°è¡¨è¿°ä¸ºä¸²è¡Œæ ¼å¼ï¼Œé€æ­¥æ•´åˆæ–°ä»»åŠ¡ã€‚ é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ€§èƒ½é€€åŒ–å¯ä»¥è¢«è¡¨è¿°ä¸ºå¯¹å…ˆå‰ä»»åŠ¡çš„çŸ¥è¯†é—å¿˜ï¼Œè¿™è‡ªç„¶å¥‘åˆæŒç»­å­¦ä¹ ï¼ˆCLï¼‰çš„ç†å¿µï¼Œä»è€Œæ¿€å‘å°† CL æ³¨å…¥ç»Ÿä¸€è¿‡ç¨‹çš„è¿›ä¸€æ­¥ç ”ç©¶ã€‚åœ¨ä¸¤ä¸ªåŸºçº¿æ–¹æ³•å’Œå››ä¸ªåŸºå‡†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒè¡¨æ˜äº† UniBench300 çš„é‡è¦æ€§ï¼Œä»¥åŠ CL åœ¨æ”¯æŒç¨³å®šç»Ÿä¸€è¿‡ç¨‹ä¸­çš„ä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼Œåœ¨è¿›è¡Œä¸“é—¨åˆ†ææ—¶å‘ç°ï¼Œæ€§èƒ½é€€åŒ–ä¸ç½‘ç»œå®¹é‡å‘ˆè´Ÿç›¸å…³ã€‚æ­¤å¤–ï¼Œä¸åŒæ¨¡æ€ä¹‹é—´çš„å·®å¼‚å¯¼è‡´å„ä»»åŠ¡çš„é€€åŒ–ç¨‹åº¦ä¸åŒï¼ˆåœ¨ MMVOT ä¸­ä¸º RGBT &gt; RGBD &gt; RGBEï¼‰ï¼Œä¸ºæœªæ¥å¤šæ¨¡æ€è§†è§‰ç ”ç©¶æä¾›äº†æœ‰ä»·å€¼çš„è§è§£ã€‚æºç å’Œæ‰€æå‡ºçš„åŸºå‡†å¯åœ¨ \textit{https://github.com/Zhangyong-Tang/UniBench300} è·å¾—ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 13:54:04 UTC
å‘å¸ƒï¼š2025-08-14 13:54:04 UTC</p>
<h2 id="61-sphenic-topology-informed-multi-view-clustering-for-spatial-transcriptomics--61-sphenic-åŸºäºæ‹“æ‰‘ä¿¡æ¯çš„ç©ºé—´è½¬å½•ç»„å¤šè§†å›¾èšç±»"><a href="https://arxiv.org/abs/2508.10646"target="_blank" rel="external nofollow noopener noreferrer">#61</a> <a href="https://papers.cool/arxiv/2508.10646"target="_blank" rel="external nofollow noopener noreferrer">SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics</a>  #61 SPHENIC: åŸºäºæ‹“æ‰‘ä¿¡æ¯çš„ç©ºé—´è½¬å½•ç»„å¤šè§†å›¾èšç±»</h2>
<p><strong>Authors</strong>: [Chenkai Guo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chenkai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chenkai</a> Guo), [Yikai Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yikai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yikai</a> Zhu), [Jing Yangum](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jing</a> Yangum), [Renxiang Guan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Renxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Renxiang</a> Guan), [Por Lip Yee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Por"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Por</a> Lip Yee), [Guangdun Peng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guangdun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guangdun</a> Peng), [Dayu Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dayu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dayu</a> Hu)
ä½œè€…ï¼šéƒ­æ™¨å‡¯ã€æœ±ä¸€æºã€æ¨é–é›ã€å…³ä»ç¥¥ã€Por Lip Yeeã€å½­å¹¿æ•¦ã€èƒ¡å¤§å®‡</p>
<p>By incorporating spatial location information, spatial-transcriptomics clustering yields more comprehensive insights into cell subpopulation identification. Despite recent progress, existing methods have at least two limitations: (i) topological learning typically considers only representations of individual cells or their interaction graphs; however, spatial transcriptomic profiles are often noisy, making these approaches vulnerable to low-quality topological signals, and (ii) insufficient modeling of spatial neighborhood information leads to low-quality spatial embeddings. To address these limitations, we propose SPHENIC, a novel Spatial Persistent Homology Enhanced Neighborhood Integrative Clustering method. Specifically, SPHENIC incorporates invariant topological features into the clustering network to achieve stable representation learning. Additionally, to construct high-quality spatial embeddings that reflect the true cellular distribution, we design the Spatial Constraint and Distribution Optimization Module (SCDOM). This module increases the similarity between a cell&rsquo;s embedding and those of its spatial neighbors, decreases similarity with non-neighboring cells, and thereby produces clustering-friendly spatial embeddings. Extensive experiments on 14 benchmark spatial transcriptomic slices demonstrate that SPHENIC achieves superior performance on the spatial clustering task, outperforming existing state-of-the-art methods by 3.31%-6.54% over the best alternative.
é€šè¿‡å¼•å…¥ç©ºé—´ä½ç½®ä¿¡æ¯ï¼Œç©ºé—´è½¬å½•ç»„èšç±»åœ¨ç»†èƒäºšç¾¤è¯†åˆ«æ–¹é¢æä¾›äº†æ›´å…¨é¢çš„è§è§£ã€‚å°½ç®¡è¿‘å¹´æ¥æœ‰æ‰€è¿›å±•ï¼Œç°æœ‰æ–¹æ³•ä»è‡³å°‘å­˜åœ¨ä¸¤ä¸ªå±€é™ï¼š (i) æ‹“æ‰‘å­¦ä¹ é€šå¸¸ä»…è€ƒè™‘å•ä¸ªç»†èƒçš„è¡¨ç¤ºæˆ–å…¶ç›¸äº’ä½œç”¨å›¾ï¼›ç„¶è€Œï¼Œç©ºé—´è½¬å½•ç»„è°±å¸¸å¸¸å«æœ‰å™ªå£°ï¼Œä½¿è¿™äº›æ–¹æ³•å¯¹ä½è´¨é‡çš„æ‹“æ‰‘ä¿¡å·è„†å¼±ï¼Œå’Œ (ii) ç©ºé—´é‚»åŸŸä¿¡æ¯å»ºæ¨¡ä¸è¶³å¯¼è‡´ä½è´¨é‡çš„ç©ºé—´åµŒå…¥ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† SPHENICï¼Œä¸€ç§æ–°é¢–çš„åŸºäºç©ºé—´æŒä¹…åŒè°ƒå¢å¼ºçš„é‚»åŸŸæ•´åˆèšç±»æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼ŒSPHENIC å°†ä¸å˜çš„æ‹“æ‰‘ç‰¹å¾çº³å…¥èšç±»ç½‘ç»œä»¥å®ç°ç¨³å®šçš„è¡¨ç¤ºå­¦ä¹ ã€‚æ­¤å¤–ï¼Œä¸ºäº†æ„å»ºåæ˜ çœŸå®ç»†èƒåˆ†å¸ƒçš„é«˜è´¨é‡ç©ºé—´åµŒå…¥ï¼Œæˆ‘ä»¬è®¾è®¡äº†ç©ºé—´çº¦æŸä¸åˆ†å¸ƒä¼˜åŒ–æ¨¡å—ï¼ˆSCDOMï¼‰ã€‚ è¯¥æ¨¡å—æé«˜äº†ä¸€ä¸ªç»†èƒåµŒå…¥ä¸å…¶ç©ºé—´é‚»å±…åµŒå…¥ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œé™ä½ä¸éé‚»å±…ç»†èƒçš„ç›¸ä¼¼åº¦ï¼Œä»è€Œç”Ÿæˆæœ‰åˆ©äºèšç±»çš„ç©ºé—´åµŒå…¥ã€‚åœ¨ 14 ä¸ªåŸºå‡†ç©ºé—´è½¬å½•ç»„åˆ‡ç‰‡ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒSPHENIC åœ¨ç©ºé—´èšç±»ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜è¶Šï¼Œæ¯”ç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•é«˜å‡º 3.31%â€“6.54%ï¼Œè¶…è¿‡æœ€ä½³æ›¿ä»£æ–¹æ³•ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 13:43:28 UTC
å‘å¸ƒï¼š2025-08-14 13:43:28 UTC</p>
<h2 id="62-fourier-guided-attention-upsampling-for-image-super-resolution--62-å‚…é‡Œå¶å¼•å¯¼æ³¨æ„åŠ›ä¸Šé‡‡æ ·ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡"><a href="https://arxiv.org/abs/2508.10616"target="_blank" rel="external nofollow noopener noreferrer">#62</a> <a href="https://papers.cool/arxiv/2508.10616"target="_blank" rel="external nofollow noopener noreferrer">Fourier-Guided Attention Upsampling for Image Super-Resolution</a>  #62 å‚…é‡Œå¶å¼•å¯¼æ³¨æ„åŠ›ä¸Šé‡‡æ ·ç”¨äºå›¾åƒè¶…åˆ†è¾¨ç‡</h2>
<p><strong>Authors</strong>: [Daejune Choi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daejune"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daejune</a> Choi), [Youchan No](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Youchan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Youchan</a> No), [Jinhyung Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinhyung"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinhyung</a> Lee), [Duksu Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Duksu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Duksu</a> Kim)
ä½œè€…ï¼šå´”å¤§ä¿Šï¼ˆDaejune Choiï¼‰ã€é²æ‚ ç¿ï¼ˆYouchan Noï¼‰ã€ææŒ¯ç‚¯ï¼ˆJinhyung Leeï¼‰ã€é‡‘å¾·æ´™ï¼ˆDuksu Kimï¼‰</p>
<p>We propose Frequency-Guided Attention (FGA), a lightweight upsampling module for single image super-resolution. Conventional upsamplers, such as Sub-Pixel Convolution, are efficient but frequently fail to reconstruct high-frequency details and introduce aliasing artifacts. FGA addresses these issues by integrating (1) a Fourier feature-based Multi-Layer Perceptron (MLP) for positional frequency encoding, (2) a cross-resolution Correlation Attention Layer for adaptive spatial alignment, and (3) a frequency-domain L1 loss for spectral fidelity supervision. Adding merely 0.3M parameters, FGA consistently enhances performance across five diverse super-resolution backbones in both lightweight and full-capacity scenarios. Experimental results demonstrate average PSNR gains of 0.12<del>0.14 dB and improved frequency-domain consistency by up to 29%, particularly evident on texture-rich datasets. Visual and spectral evaluations confirm FGA&rsquo;s effectiveness in reducing aliasing and preserving fine details, establishing it as a practical, scalable alternative to traditional upsampling methods.
æˆ‘ä»¬æå‡ºäº†é¢‘ç‡å¼•å¯¼æ³¨æ„åŠ›ï¼ˆFGAï¼‰ï¼Œä¸€ç§ç”¨äºå•å›¾åƒè¶…åˆ†è¾¨ç‡çš„è½»é‡çº§ä¸Šé‡‡æ ·æ¨¡å—ã€‚ä¼ ç»Ÿçš„ä¸Šé‡‡æ ·å™¨ï¼ˆå¦‚å­åƒç´ å·ç§¯ï¼‰è™½ç„¶é«˜æ•ˆï¼Œä½†ç»å¸¸æ— æ³•é‡å»ºé«˜é¢‘ç»†èŠ‚å¹¶å¼•å…¥æ··å ä¼ªå½±ã€‚FGA é€šè¿‡æ•´åˆä»¥ä¸‹ç»„ä»¶æ¥è§£å†³è¿™äº›é—®é¢˜ï¼š (1) åŸºäºå‚…é‡Œå¶ç‰¹å¾çš„å¤šå±‚æ„ŸçŸ¥æœºï¼ˆMLPï¼‰ç”¨äºä½ç½®é¢‘ç‡ç¼–ç ï¼Œ(2) ç”¨äºè‡ªé€‚åº”ç©ºé—´å¯¹é½çš„è·¨åˆ†è¾¨ç‡ç›¸å…³æ³¨æ„åŠ›å±‚ï¼Œå’Œ (3) ç”¨äºé¢‘è°±ä¿çœŸç›‘ç£çš„é¢‘åŸŸ L1 æŸå¤±ã€‚ä»…å¢åŠ  0.3M å‚æ•°ï¼ŒFGA åœ¨äº”ç§ä¸åŒçš„è¶…åˆ†è¾¨ç‡ä¸»å¹²ç½‘ç»œä¸Šï¼Œåœ¨è½»é‡çº§å’Œå…¨å®¹é‡åœºæ™¯ä¸­å‡æŒç»­æå‡æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜å¹³å‡ PSNR æå‡ 0.12</del>0.14 dBï¼Œé¢‘åŸŸä¸€è‡´æ€§æœ€å¤šæé«˜ 29%ï¼Œåœ¨çº¹ç†ä¸°å¯Œçš„æ•°æ®é›†ä¸Šå°¤ä¸ºæ˜æ˜¾ã€‚è§†è§‰å’Œé¢‘è°±è¯„ä¼°è¯å®äº† FGA åœ¨å‡å°‘æ··å å’Œä¿ç•™ç»†èŠ‚æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œç¡®ç«‹äº†å…¶ä½œä¸ºä¼ ç»Ÿä¸Šé‡‡æ ·æ–¹æ³•çš„å®ç”¨ä¸”å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 13:13:17 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 13:13:17 UTC</p>
<h2 id="63-on-spectral-properties-of-gradient-based-explanation-methods--63-å…³äºåŸºäºæ¢¯åº¦çš„è§£é‡Šæ–¹æ³•çš„è°±æ€§è´¨"><a href="https://arxiv.org/abs/2508.10595"target="_blank" rel="external nofollow noopener noreferrer">#63</a> <a href="https://papers.cool/arxiv/2508.10595"target="_blank" rel="external nofollow noopener noreferrer">On Spectral Properties of Gradient-based Explanation Methods</a>  #63 å…³äºåŸºäºæ¢¯åº¦çš„è§£é‡Šæ–¹æ³•çš„è°±æ€§è´¨</h2>
<p><strong>Authors</strong>: [Amir Mehrpanah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amir</a> Mehrpanah), [Erik Englesson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Erik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Erik</a> Englesson), [Hossein Azizpour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hossein</a> Azizpour)
ä½œè€…ï¼šAmir Mehrpanahã€Erik Englessonã€Hossein Azizpour</p>
<p>Understanding the behavior of deep networks is crucial to increase our confidence in their results. Despite an extensive body of work for explaining their predictions, researchers have faced reliability issues, which can be attributed to insufficient formalism. In our research, we adopt novel probabilistic and spectral perspectives to formally analyze explanation methods. Our study reveals a pervasive spectral bias stemming from the use of gradient, and sheds light on some common design choices that have been discovered experimentally, in particular, the use of squared gradient and input perturbation. We further characterize how the choice of perturbation hyperparameters in explanation methods, such as SmoothGrad, can lead to inconsistent explanations and introduce two remedies based on our proposed formalism: (i) a mechanism to determine a standard perturbation scale, and (ii) an aggregation method which we call SpectralLens. Finally, we substantiate our theoretical results through quantitative evaluations.
ç†è§£æ·±åº¦ç½‘ç»œçš„è¡Œä¸ºå¯¹äºå¢å¼ºæˆ‘ä»¬å¯¹å…¶ç»“æœçš„ä¿¡å¿ƒè‡³å…³é‡è¦ã€‚å°½ç®¡å·²æœ‰å¤§é‡å·¥ä½œç”¨äºè§£é‡Šå…¶é¢„æµ‹ï¼Œä½†ç ”ç©¶äººå‘˜ä»é¢ä¸´å¯é æ€§é—®é¢˜ï¼Œè¿™å¯ä»¥å½’å› äºå½¢å¼åŒ–ä¸è¶³ã€‚åœ¨æˆ‘ä»¬çš„ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é‡‡ç”¨æ–°é¢–çš„æ¦‚ç‡å’Œè°±è§†è§’å¯¹è§£é‡Šæ–¹æ³•è¿›è¡Œå½¢å¼åŒ–åˆ†æã€‚æˆ‘ä»¬çš„ç ”ç©¶æ­ç¤ºäº†ä¸€ä¸ªæºè‡ªæ¢¯åº¦ä½¿ç”¨çš„æ™®éè°±åç½®ï¼Œå¹¶é˜æ˜äº†ä¸€äº›é€šè¿‡å®éªŒè¯å®çš„å¸¸è§è®¾è®¡é€‰æ‹©ï¼Œç‰¹åˆ«æ˜¯å¹³æ–¹æ¢¯åº¦å’Œè¾“å…¥æ‰°åŠ¨çš„ä½¿ç”¨ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥åˆ»ç”»äº†è§£é‡Šæ–¹æ³•ä¸­æ‰°åŠ¨è¶…å‚æ•°ï¼ˆå¦‚ SmoothGradï¼‰çš„é€‰æ‹©å¦‚ä½•å¯¼è‡´ä¸ä¸€è‡´çš„è§£é‡Šï¼Œå¹¶åŸºäºæˆ‘ä»¬æå‡ºçš„å½¢å¼ä¸»ä¹‰å¼•å…¥äº†ä¸¤ç§è¡¥æ•‘æªæ–½ï¼šï¼ˆiï¼‰ä¸€ç§ç¡®å®šæ ‡å‡†æ‰°åŠ¨å°ºåº¦çš„æœºåˆ¶ï¼Œå’Œï¼ˆiiï¼‰ä¸€ç§æˆ‘ä»¬ç§°ä¹‹ä¸º SpectralLens çš„èšåˆæ–¹æ³•ã€‚æœ€åï¼Œæˆ‘ä»¬é€šè¿‡å®šé‡è¯„ä¼°è¯å®äº†æˆ‘ä»¬çš„ç†è®ºç»“æœã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>
å­¦ç§‘ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«</p>
<p><strong>Publish</strong>: 2025-08-14 12:37:22 UTC
å‘å¸ƒï¼š2025-08-14 12:37:22 UTC</p>
<h2 id="64-freegad-a-training-free-yet-effective-approach-for-graph-anomaly-detection--64-freegadä¸€ç§æ— éœ€è®­ç»ƒä½†æœ‰æ•ˆçš„å›¾å¼‚å¸¸æ£€æµ‹æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10594"target="_blank" rel="external nofollow noopener noreferrer">#64</a> <a href="https://papers.cool/arxiv/2508.10594"target="_blank" rel="external nofollow noopener noreferrer">FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection</a>  #64 FreeGADï¼šä¸€ç§æ— éœ€è®­ç»ƒä½†æœ‰æ•ˆçš„å›¾å¼‚å¸¸æ£€æµ‹æ–¹æ³•</h2>
<p><strong>Authors</strong>: [Yunfeng Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yunfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yunfeng</a> Zhao), [Yixin Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yixin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yixin</a> Liu), [Shiyuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiyuan</a> Li), [Qingfeng Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qingfeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qingfeng</a> Chen), [Yu Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu</a> Zheng), [Shirui Pan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shirui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shirui</a> Pan)
ä½œè€…ï¼šèµµäº‘å³°ã€åˆ˜å¥•é‘«ã€æè¯—æºã€é™ˆåº†å³°ã€éƒ‘å®‡ã€æ½˜ä¸–ç¿</p>
<p>Graph Anomaly Detection (GAD) aims to identify nodes that deviate from the majority within a graph, playing a crucial role in applications such as social networks and e-commerce. Despite the current advancements in deep learning-based GAD, existing approaches often suffer from high deployment costs and poor scalability due to their complex and resource-intensive training processes. Surprisingly, our empirical findings suggest that the training phase of deep GAD methods, commonly perceived as crucial, may actually contribute less to anomaly detection performance than expected. Inspired by this, we propose FreeGAD, a novel training-free yet effective GAD method. Specifically, it leverages an affinity-gated residual encoder to generate anomaly-aware representations. Meanwhile, FreeGAD identifies anchor nodes as pseudo-normal and anomalous guides, followed by calculating anomaly scores through anchor-guided statistical deviations. Extensive experiments demonstrate that FreeGAD achieves superior anomaly detection performance, efficiency, and scalability on multiple benchmark datasets from diverse domains, without any training or iterative optimization.
å›¾å¼‚å¸¸æ£€æµ‹ï¼ˆGADï¼‰æ—¨åœ¨è¯†åˆ«å›¾ä¸­ä¸å¤§å¤šæ•°èŠ‚ç‚¹å­˜åœ¨åç¦»çš„èŠ‚ç‚¹ï¼Œåœ¨ç¤¾äº¤ç½‘ç»œå’Œç”µå­å•†åŠ¡ç­‰åº”ç”¨ä¸­å‘æŒ¥é‡è¦ä½œç”¨ã€‚å°½ç®¡åŸºäºæ·±åº¦å­¦ä¹ çš„ GAD å–å¾—äº†è¿›å±•ï¼Œä½†ç°æœ‰æ–¹æ³•ç”±äºè®­ç»ƒè¿‡ç¨‹å¤æ‚ä¸”èµ„æºå¯†é›†ï¼Œå¾€å¾€é¢ä¸´é«˜éƒ¨ç½²æˆæœ¬å’Œå¯æ‰©å±•æ€§å·®çš„é—®é¢˜ã€‚ä»¤äººæƒŠè®¶çš„æ˜¯ï¼Œæˆ‘ä»¬çš„å®è¯å‘ç°è¡¨æ˜ï¼Œæ·±åº¦ GAD æ–¹æ³•ä¸­è¢«æ™®éè®¤ä¸ºè‡³å…³é‡è¦çš„è®­ç»ƒé˜¶æ®µï¼Œå®é™…ä¸Šå¯èƒ½å¯¹å¼‚å¸¸æ£€æµ‹æ€§èƒ½çš„è´¡çŒ®ä½äºé¢„æœŸã€‚å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬æå‡ºäº† FreeGADï¼Œä¸€ç§æ–°é¢–çš„æ— è®­ç»ƒä½†æœ‰æ•ˆçš„ GAD æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œå®ƒåˆ©ç”¨äº²å’Œé—¨æ§æ®‹å·®ç¼–ç å™¨ç”Ÿæˆå¯¹å¼‚å¸¸æ•æ„Ÿçš„è¡¨ç¤ºã€‚åŒæ—¶ï¼ŒFreeGAD å°†é”šèŠ‚ç‚¹è¯†åˆ«ä¸ºä¼ªæ­£å¸¸å’Œå¼‚å¸¸å¼•å¯¼ç‚¹ï¼Œéšåé€šè¿‡åŸºäºé”šç‚¹çš„ç»Ÿè®¡åå·®è®¡ç®—å¼‚å¸¸å¾—åˆ†ã€‚å¤§é‡å®éªŒè¡¨æ˜ï¼ŒFreeGAD åœ¨å¤šä¸ªæ¥è‡ªä¸åŒé¢†åŸŸçš„åŸºå‡†æ•°æ®é›†ä¸Šï¼Œåœ¨æ— éœ€ä»»ä½•è®­ç»ƒæˆ–è¿­ä»£ä¼˜åŒ–çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°äº†æ›´ä¼˜çš„å¼‚å¸¸æ£€æµ‹æ€§èƒ½ã€æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 12:37:20 UTC
å‘å¸ƒï¼š2025-08-14 12:37:20 UTC</p>
<h2 id="65-fake-speech-wild-detecting-deepfake-speech-on-social-media-platform--65-å‡è¯­ç‹‚æ½®åœ¨ç¤¾äº¤åª’ä½“å¹³å°ä¸Šæ£€æµ‹è¯­éŸ³æ·±åº¦ä¼ªé€ "><a href="https://arxiv.org/abs/2508.10559"target="_blank" rel="external nofollow noopener noreferrer">#65</a> <a href="https://papers.cool/arxiv/2508.10559"target="_blank" rel="external nofollow noopener noreferrer">Fake Speech Wild: Detecting Deepfake Speech on Social Media Platform</a>  #65 å‡è¯­ç‹‚æ½®ï¼šåœ¨ç¤¾äº¤åª’ä½“å¹³å°ä¸Šæ£€æµ‹è¯­éŸ³æ·±åº¦ä¼ªé€ </h2>
<p><strong>Authors</strong>: [Yuankun Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuankun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuankun</a> Xie), [Ruibo Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruibo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruibo</a> Fu), [Xiaopeng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaopeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaopeng</a> Wang), [Zhiyong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyong</a> Wang), [Ya Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ya</a> Li), [Zhengqi Wen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhengqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhengqi</a> Wen), [Haonnan Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haonnan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haonnan</a> Cheng), [Long Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Long"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Long</a> Ye)
ä½œè€…ï¼šè°¢å…ƒæ˜†ã€å‚…é”åšã€ç‹æ™“é¹ã€ç‹å¿—å‹‡ã€æé›…ã€æ¸©æ­£å¥‡ã€ç¨‹æµ©å—ã€å¶é¾™</p>
<p>The rapid advancement of speech generation technology has led to the widespread proliferation of deepfake speech across social media platforms. While deepfake audio countermeasures (CMs) achieve promising results on public datasets, their performance degrades significantly in cross-domain scenarios. To advance CMs for real-world deepfake detection, we first propose the Fake Speech Wild (FSW) dataset, which includes 254 hours of real and deepfake audio from four different media platforms, focusing on social media. As CMs, we establish a benchmark using public datasets and advanced selfsupervised learning (SSL)-based CMs to evaluate current CMs in real-world scenarios. We also assess the effectiveness of data augmentation strategies in enhancing CM robustness for detecting deepfake speech on social media. Finally, by augmenting public datasets and incorporating the FSW training set, we significantly advanced real-world deepfake audio detection performance, achieving an average equal error rate (EER) of 3.54% across all evaluation sets.
è¯­éŸ³ç”ŸæˆæŠ€æœ¯çš„å¿«é€Ÿå‘å±•å¯¼è‡´æ·±åº¦ä¼ªé€ è¯­éŸ³åœ¨ç¤¾äº¤åª’ä½“å¹³å°ä¸Šçš„å¹¿æ³›ä¼ æ’­ã€‚å°½ç®¡åœ¨å…¬å¼€æ•°æ®é›†ä¸Šæ·±åº¦ä¼ªé€ éŸ³é¢‘çš„å¯¹æŠ—æªæ–½ï¼ˆCMsï¼‰å–å¾—äº†å¯è§‚çš„æˆæœï¼Œä½†åœ¨è·¨åŸŸåœºæ™¯ä¸­å…¶æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚ä¸ºæ¨åŠ¨é¢å‘çœŸå®ä¸–ç•Œçš„æ·±åº¦ä¼ªé€ æ£€æµ‹ï¼Œæˆ‘ä»¬é¦–å…ˆæå‡ºäº† Fake Speech Wild (FSW) æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«æ¥è‡ªå››ä¸ªä¸åŒåª’ä½“å¹³å°çš„ 254 å°æ—¶çœŸå®ä¸ä¼ªé€ éŸ³é¢‘ï¼Œä¾§é‡äºç¤¾äº¤åª’ä½“ã€‚ä½œä¸ºå¯¹æŠ—æªæ–½ï¼Œæˆ‘ä»¬ä½¿ç”¨å…¬å¼€æ•°æ®é›†å’Œå…ˆè¿›çš„åŸºäºè‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰çš„ CMs å»ºç«‹äº†åŸºå‡†ï¼Œä»¥è¯„ä¼°å½“å‰å¯¹æŠ—æªæ–½åœ¨çœŸå®ä¸–ç•Œåœºæ™¯ä¸­çš„è¡¨ç°ã€‚æˆ‘ä»¬è¿˜è¯„ä¼°äº†æ•°æ®å¢å¼ºç­–ç•¥åœ¨æå‡å¯¹ç¤¾äº¤åª’ä½“ä¸Šæ·±åº¦ä¼ªé€ è¯­éŸ³æ£€æµ‹çš„é²æ£’æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æœ€åï¼Œé€šè¿‡å¢å¼ºå…¬å¼€æ•°æ®é›†å¹¶åŠ å…¥ FSW è®­ç»ƒé›†ï¼Œæˆ‘ä»¬æ˜¾è‘—æå‡äº†çœŸå®ä¸–ç•Œæ·±åº¦ä¼ªé€ éŸ³é¢‘æ£€æµ‹çš„æ€§èƒ½ï¼Œåœ¨æ‰€æœ‰è¯„ä¼°é›†ä¸Šçš„å¹³å‡ç­‰é”™è¯¯ç‡ï¼ˆEERï¼‰è¾¾åˆ°äº† 3.54%ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">Sound</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå£°éŸ³ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 11:56:30 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 11:56:30 åè°ƒä¸–ç•Œæ—¶ï¼ˆUTCï¼‰</p>
<h2 id="66-ptqat-a-hybrid-parameter-efficient-quantization-algorithm-for-3d-perception-tasks--66-ptqatä¸€ç§ç”¨äºä¸‰ç»´æ„ŸçŸ¥ä»»åŠ¡çš„æ··åˆå‚æ•°é«˜æ•ˆé‡åŒ–ç®—æ³•"><a href="https://arxiv.org/abs/2508.10557"target="_blank" rel="external nofollow noopener noreferrer">#66</a> <a href="https://papers.cool/arxiv/2508.10557"target="_blank" rel="external nofollow noopener noreferrer">PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks</a>  #66 PTQATï¼šä¸€ç§ç”¨äºä¸‰ç»´æ„ŸçŸ¥ä»»åŠ¡çš„æ··åˆå‚æ•°é«˜æ•ˆé‡åŒ–ç®—æ³•</h2>
<p><strong>Authors</strong>: [Xinhao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinhao</a> Wang), [Zhiwei Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiwei</a> Lin), [Zhongyu Xia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhongyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhongyu</a> Xia), [Yongtao Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yongtao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yongtao</a> Wang)
ä½œè€…ï¼šç‹æ–°æµ©ã€æ—å¿—ä¼Ÿã€å¤ä¸­å®‡ã€ç‹æ°¸æ¶›</p>
<p>Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) represent two mainstream model quantization approaches. However, PTQ often leads to unacceptable performance degradation in quantized models, while QAT imposes substantial GPU memory requirements and extended training time due to weight fine-tuning.In this paper, we propose PTQAT, a novel general hybrid quantization algorithm for the efficient deployment of 3D perception networks. To address the speed accuracy trade-off between PTQ and QAT, our method selects critical layers for QAT fine-tuning and performs PTQ on the remaining layers. Contrary to intuition, fine-tuning the layers with smaller output discrepancies before and after quantization, rather than those with larger discrepancies, actually leads to greater improvements in the model&rsquo;s quantization accuracy. This means we better compensate for quantization errors during their propagation, rather than addressing them at the point where they occur. The proposed PTQAT achieves similar performance to QAT with more efficiency by freezing nearly 50% of quantifiable layers. Additionally, PTQAT is a universal quantization method that supports various quantization bit widths (4 bits) as well as different model architectures, including CNNs and Transformers. The experimental results on nuScenes across diverse 3D perception tasks, including object detection, semantic segmentation, and occupancy prediction, show that our method consistently outperforms QAT-only baselines. Notably, it achieves 0.2%-0.9% NDS and 0.3%-1.0% mAP gains in object detection, 0.3%-2.0% mIoU gains in semantic segmentation and occupancy prediction while fine-tuning fewer weights.
åè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰å’Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰ä»£è¡¨äº†ä¸¤ç§ä¸»æµçš„æ¨¡å‹é‡åŒ–æ–¹æ³•ã€‚ç„¶è€Œï¼ŒPTQ ç»å¸¸å¯¼è‡´é‡åŒ–æ¨¡å‹å‡ºç°ä¸å¯æ¥å—çš„æ€§èƒ½ä¸‹é™ï¼Œè€Œ QAT åˆ™ç”±äºæƒé‡å¾®è°ƒè€Œå¯¹ GPU å†…å­˜æå‡ºäº†å¤§é‡éœ€æ±‚å¹¶å»¶é•¿äº†è®­ç»ƒæ—¶é—´ã€‚æœ¬æ–‡æå‡ºäº† PTQATï¼Œä¸€ç§ç”¨äºé«˜æ•ˆéƒ¨ç½² 3D æ„ŸçŸ¥ç½‘ç»œçš„æ–°å‹é€šç”¨æ··åˆé‡åŒ–ç®—æ³•ã€‚ä¸ºäº†è§£å†³ PTQ ä¸ QAT ä¹‹é—´çš„é€Ÿåº¦ä¸ç²¾åº¦æŠ˜ä¸­ï¼Œæˆ‘ä»¬çš„æ–¹æ³•é€‰æ‹©å…³é”®å±‚è¿›è¡Œ QAT å¾®è°ƒï¼Œå¹¶å¯¹å…¶ä½™å±‚æ‰§è¡Œ PTQã€‚ä¸ç›´è§‰ç›¸åï¼Œå¯¹é‡åŒ–å‰åè¾“å‡ºå·®å¼‚è¾ƒå°çš„å±‚è¿›è¡Œå¾®è°ƒï¼Œè€Œä¸æ˜¯å¯¹å·®å¼‚è¾ƒå¤§çš„å±‚è¿›è¡Œå¾®è°ƒï¼Œå®é™…ä¸Šèƒ½å¸¦æ¥å¯¹æ¨¡å‹é‡åŒ–ç²¾åº¦æ›´å¤§çš„æå‡ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬æ›´å¥½åœ°åœ¨è¯¯å·®ä¼ æ’­è¿‡ç¨‹ä¸­è¡¥å¿é‡åŒ–è¯¯å·®ï¼Œè€Œä¸æ˜¯åœ¨è¯¯å·®å‘ç”Ÿçš„ç‚¹ä¸Šå»å¤„ç†å®ƒä»¬ã€‚æ‰€æå‡ºçš„ PTQAT é€šè¿‡å†»ç»“è¿‘ 50% çš„å¯é‡åŒ–å±‚ï¼Œä»¥æ›´é«˜çš„æ•ˆç‡å®ç°äº†ä¸ QAT ç›¸ä¼¼çš„æ€§èƒ½ã€‚ æ­¤å¤–ï¼ŒPTQAT æ˜¯ä¸€ç§é€šç”¨é‡åŒ–æ–¹æ³•ï¼Œæ”¯æŒå¤šç§é‡åŒ–ä½å®½ï¼ˆ4 ä½ï¼‰ä»¥åŠåŒ…æ‹¬ CNN å’Œ Transformer åœ¨å†…çš„ä¸åŒæ¨¡å‹æ¶æ„ã€‚åœ¨ nuScenes ä¸Šé’ˆå¯¹åŒ…æ‹¬ç›®æ ‡æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²å’Œå æ®é¢„æµ‹ç­‰å¤šç§ 3D æ„ŸçŸ¥ä»»åŠ¡çš„å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•å§‹ç»ˆä¼˜äºä»…ä½¿ç”¨ QAT çš„åŸºçº¿æ–¹æ³•ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç›®æ ‡æ£€æµ‹ä¸­å…¶åˆ†åˆ«å¸¦æ¥äº† 0.2%â€“0.9% çš„ NDS å’Œ 0.3%â€“1.0% çš„ mAP æå‡ï¼Œåœ¨è¯­ä¹‰åˆ†å‰²å’Œå æ®é¢„æµ‹ä¸­å¸¦æ¥äº† 0.3%â€“2.0% çš„ mIoU æå‡ï¼ŒåŒæ—¶å¾®è°ƒäº†æ›´å°‘çš„æƒé‡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 11:55:21 UTC
å‘å¸ƒï¼š2025-08-14 11:55:21 UTC</p>
<h2 id="67-retrieval-augmented-prompt-for-ood-detection--67-ç”¨äº-ood-æ£€æµ‹çš„æ£€ç´¢å¢å¼ºæç¤º"><a href="https://arxiv.org/abs/2508.10556"target="_blank" rel="external nofollow noopener noreferrer">#67</a> <a href="https://papers.cool/arxiv/2508.10556"target="_blank" rel="external nofollow noopener noreferrer">Retrieval-Augmented Prompt for OOD Detection</a>  #67 ç”¨äº OOD æ£€æµ‹çš„æ£€ç´¢å¢å¼ºæç¤º</h2>
<p><strong>Authors</strong>: [Ruisong Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruisong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruisong</a> Han), [Zongbo Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zongbo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zongbo</a> Han), [Jiahao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiahao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiahao</a> Zhang), [Mingyue Cheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingyue</a> Cheng), [Changqing Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Changqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Changqing</a> Zhang)
ä½œè€…ï¼šéŸ©ç¿æ¾ï¼ŒéŸ©å®—åšï¼Œå¼ å®¶è±ªï¼Œç¨‹æ˜å²³ï¼Œå¼ é•¿é’</p>
<p>Out-of-Distribution (OOD) detection is crucial for the reliable deployment of machine learning models in-the-wild, enabling accurate identification of test samples that differ from the training data distribution. Existing methods rely on auxiliary outlier samples or in-distribution (ID) data to generate outlier information for training, but due to limited outliers and their mismatch with real test OOD samples, they often fail to provide sufficient semantic supervision, leading to suboptimal performance. To address this, we propose a novel OOD detection method called Retrieval-Augmented Prompt (RAP). RAP augments a pre-trained vision-language model&rsquo;s prompts by retrieving external knowledge, offering enhanced semantic supervision for OOD detection. During training, RAP retrieves descriptive words for outliers based on joint similarity with external textual knowledge and uses them to augment the model&rsquo;s OOD prompts. During testing, RAP dynamically updates OOD prompts in real-time based on the encountered OOD samples, enabling the model to rapidly adapt to the test environment. Our extensive experiments demonstrate that RAP achieves state-of-the-art performance on large-scale OOD detection benchmarks. For example, in 1-shot OOD detection on the ImageNet-1k dataset, RAP reduces the average FPR95 by 7.05% and improves the AUROC by 1.71% compared to previous methods. Additionally, comprehensive ablation studies validate the effectiveness of each module and the underlying motivations of our approach.
åˆ†å¸ƒå¤–ï¼ˆOODï¼‰æ£€æµ‹å¯¹äºæœºå™¨å­¦ä¹ æ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­å¯é éƒ¨ç½²è‡³å…³é‡è¦ï¼Œå®ƒèƒ½å¤Ÿå‡†ç¡®è¯†åˆ«ä¸è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸åŒçš„æµ‹è¯•æ ·æœ¬ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–è¾…åŠ©çš„å¼‚å¸¸æ ·æœ¬æˆ–åˆ†å¸ƒå†…ï¼ˆIDï¼‰æ•°æ®æ¥ç”Ÿæˆç”¨äºè®­ç»ƒçš„å¼‚å¸¸ä¿¡æ¯ï¼Œä½†ç”±äºå¼‚å¸¸æ ·æœ¬æœ‰é™ä¸”ä¸çœŸå®æµ‹è¯•ä¸­çš„ OOD æ ·æœ¬ä¸åŒ¹é…ï¼Œå®ƒä»¬å¸¸å¸¸æ— æ³•æä¾›è¶³å¤Ÿçš„è¯­ä¹‰ç›‘ç£ï¼Œå¯¼è‡´æ€§èƒ½ä¸ç†æƒ³ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åä¸ºæ£€ç´¢å¢å¼ºæç¤ºï¼ˆRAPï¼ŒRetrieval-Augmented Promptï¼‰çš„æ–°å‹ OOD æ£€æµ‹æ–¹æ³•ã€‚RAP é€šè¿‡æ£€ç´¢å¤–éƒ¨çŸ¥è¯†æ¥å¢å¼ºé¢„è®­ç»ƒè§†è§‰-è¯­è¨€æ¨¡å‹çš„æç¤ºï¼Œä¸º OOD æ£€æµ‹æä¾›æ›´ä¸°å¯Œçš„è¯­ä¹‰ç›‘ç£ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒRAP åŸºäºä¸å¤–éƒ¨æ–‡æœ¬çŸ¥è¯†çš„è”åˆç›¸ä¼¼æ€§æ£€ç´¢å‡ºæè¿°å¼‚å¸¸æ ·æœ¬çš„è¯æ±‡ï¼Œå¹¶ä½¿ç”¨è¿™äº›è¯æ±‡æ¥å¢å¼ºæ¨¡å‹çš„ OOD æç¤ºã€‚åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼ŒRAP æ ¹æ®é‡åˆ°çš„ OOD æ ·æœ¬å®æ—¶åŠ¨æ€æ›´æ–° OOD æç¤ºï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè¿…é€Ÿé€‚åº”æµ‹è¯•ç¯å¢ƒã€‚ æˆ‘ä»¬çš„å¤§é‡å®éªŒè¡¨æ˜ï¼ŒRAP åœ¨å¤§è§„æ¨¡ OOD æ£€æµ‹åŸºå‡†ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚ä¾‹å¦‚ï¼Œåœ¨ ImageNet-1k æ•°æ®é›†ä¸Šçš„ 1-shot OOD æ£€æµ‹ä¸­ï¼ŒRAP å°†å¹³å‡ FPR95 é™ä½äº† 7.05%ï¼Œå¹¶ç›¸æ¯”ä»¥å¾€æ–¹æ³•å°† AUROC æé«˜äº† 1.71%ã€‚æ­¤å¤–ï¼Œå…¨é¢çš„æ¶ˆèç ”ç©¶éªŒè¯äº†æ¯ä¸ªæ¨¡å—çš„æœ‰æ•ˆæ€§ä»¥åŠæˆ‘ä»¬æ–¹æ³•çš„åŸºæœ¬åŠ¨æœºã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 11:52:43 UTC
å‘å¸ƒï¼š2025-08-14 11:52:43 UTC</p>
<h2 id="68-when-language-overrules-revealing-text-dominance-in-multimodal-large-language-models--68-å½“è¯­è¨€å ä¸Šé£æ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ–‡æœ¬çš„ä¸»å¯¼åœ°ä½"><a href="https://arxiv.org/abs/2508.10552"target="_blank" rel="external nofollow noopener noreferrer">#68</a> <a href="https://papers.cool/arxiv/2508.10552"target="_blank" rel="external nofollow noopener noreferrer">When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models</a>  #68 å½“è¯­è¨€å ä¸Šé£ï¼šæ­ç¤ºå¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ–‡æœ¬çš„ä¸»å¯¼åœ°ä½</h2>
<p><strong>Authors</strong>: [Huyu Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huyu</a> Wu), [Meng Tang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meng</a> Tang), [Xinhan Zheng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinhan</a> Zheng), [Haiyun Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haiyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haiyun</a> Jiang)
ä½œè€…ï¼šå´è™å®‡ï¼Œå”èŒï¼Œéƒ‘æ¬£æ¶µï¼Œè’‹æµ·äº‘</p>
<p>Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across a diverse range of multimodal tasks. However, these models suffer from a core problem known as text dominance: they depend heavily on text for their inference, while underutilizing other modalities. While prior work has acknowledged this phenomenon in vision-language tasks, often attributing it to data biases or model architectures. In this paper, we conduct the first systematic investigation of text dominance across diverse data modalities, including images, videos, audio, time-series, and graphs. To measure this imbalance, we propose two evaluation metrics: the Modality Dominance Index (MDI) and the Attention Efficiency Index (AEI). Our comprehensive analysis reveals that text dominance is both significant and pervasive across all tested modalities. Our in-depth analysis identifies three underlying causes: attention dilution from severe token redundancy in non-textual modalities, the influence of fusion architecture design, and task formulations that implicitly favor textual inputs. Furthermore, we propose a simple token compression method that effectively rebalances model attention. Applying this method to LLaVA-7B, for instance, drastically reduces its MDI from 10.23 to a well-balanced value of 0.86. Our analysis and methodological framework offer a foundation for the development of more equitable and comprehensive multimodal language models.
å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰åœ¨å¤šç§å¤šæ¨¡æ€ä»»åŠ¡ä¸­å±•ç°å‡ºæ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹å­˜åœ¨ä¸€ä¸ªæ ¸å¿ƒé—®é¢˜ï¼Œç§°ä¸ºæ–‡æœ¬ä¸»å¯¼ï¼šå®ƒä»¬åœ¨æ¨ç†ä¸­é«˜åº¦ä¾èµ–æ–‡æœ¬ï¼Œè€Œæœªèƒ½å……åˆ†åˆ©ç”¨å…¶ä»–æ¨¡æ€ã€‚ä»¥å¾€å·¥ä½œåœ¨è§†è§‰-è¯­è¨€ä»»åŠ¡ä¸­å·²æ³¨æ„åˆ°è¿™ç§ç°è±¡ï¼Œé€šå¸¸å°†å…¶å½’å› äºæ•°æ®åå·®æˆ–æ¨¡å‹æ¶æ„ã€‚æœ¬æ–‡é¦–æ¬¡å¯¹åŒ…æ‹¬å›¾åƒã€è§†é¢‘ã€éŸ³é¢‘ã€æ—¶é—´åºåˆ—å’Œå›¾åœ¨å†…çš„å¤šç§æ•°æ®æ¨¡æ€ä¸Šçš„æ–‡æœ¬ä¸»å¯¼è¿›è¡Œäº†ç³»ç»Ÿæ€§çš„è°ƒæŸ¥ã€‚ä¸ºè¡¡é‡è¿™ç§ä¸å¹³è¡¡ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸¤é¡¹è¯„ä¼°æŒ‡æ ‡ï¼šæ¨¡æ€ä¸»å¯¼æŒ‡æ•°ï¼ˆMDIï¼‰å’Œæ³¨æ„åŠ›æ•ˆç‡æŒ‡æ•°ï¼ˆAEIï¼‰ã€‚æˆ‘ä»¬å…¨é¢çš„åˆ†æè¡¨æ˜ï¼Œæ–‡æœ¬ä¸»å¯¼åœ¨æ‰€æœ‰æµ‹è¯•æ¨¡æ€ä¸­éƒ½æ—¢æ˜¾è‘—åˆæ™®éã€‚æ·±å…¥åˆ†ææŒ‡å‡ºä¸‰ä¸ªæ ¹æœ¬åŸå› ï¼šéæ–‡æœ¬æ¨¡æ€ä¸­ä¸¥é‡çš„æ ‡è®°å†—ä½™å¯¼è‡´çš„æ³¨æ„åŠ›ç¨€é‡Šã€èåˆæ¶æ„è®¾è®¡çš„å½±å“ï¼Œä»¥åŠåœ¨ä»»åŠ¡è¡¨è¿°ä¸­éšå«åœ°åå‘æ–‡æœ¬è¾“å…¥ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•çš„æ ‡è®°å‹ç¼©æ–¹æ³•ï¼Œæœ‰æ•ˆåœ°é‡æ–°å¹³è¡¡äº†æ¨¡å‹çš„æ³¨æ„åŠ›ã€‚ ä¾‹å¦‚ï¼Œå°†æ­¤æ–¹æ³•åº”ç”¨äº LLaVA-7Bï¼Œèƒ½å°†å…¶ MDI ä» 10.23 å¤§å¹…é™ä½è‡³å¹³è¡¡è‰¯å¥½çš„ 0.86ã€‚æˆ‘ä»¬çš„åˆ†æä¸æ–¹æ³•è®ºæ¡†æ¶ä¸ºå¼€å‘æ›´å…¬å¹³ã€æ›´å…¨é¢çš„å¤šæ¨¡æ€è¯­è¨€æ¨¡å‹æä¾›äº†åŸºç¡€ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 11:44:52 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 11:44:52 UTC</p>
<h2 id="69-stabilizing-long-term-multi-turn-reinforcement-learning-with-gated-rewards--69-ç”¨é—¨æ§å¥–åŠ±ç¨³å®šé•¿æœŸå¤šè½®å¼ºåŒ–å­¦ä¹ -pdf-3--copy-kimi-1--rel"><a href="https://arxiv.org/abs/2508.10548"target="_blank" rel="external nofollow noopener noreferrer">#69</a> <a href="https://papers.cool/arxiv/2508.10548"target="_blank" rel="external nofollow noopener noreferrer">Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards</a>  #69 ç”¨é—¨æ§å¥–åŠ±ç¨³å®šé•¿æœŸå¤šè½®å¼ºåŒ–å­¦ä¹  [PDF 3 ] [Copy] [Kimi 1 ] [REL]</h2>
<p><strong>Authors</strong>: [Zetian Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zetian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zetian</a> Sun), [Dongfang Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongfang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongfang</a> Li), [Zhuoen Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuoen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuoen</a> Chen), [Yuhuai Qin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhuai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhuai</a> Qin), [Baotian Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Baotian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Baotian</a> Hu)
ä½œè€…ï¼šå­™æ³½å¤©ã€æä¸œæ–¹ã€é™ˆå“æ©ã€ç§¦å®‡æ·®ã€èƒ¡å®å¤©</p>
<p>Reward sparsity in long-horizon reinforcement learning (RL) tasks remains a significant challenge, while existing outcome-based reward shaping struggles to define meaningful immediate rewards without introducing bias or requiring explicit task decomposition. Alternatively, verification-based reward shaping uses stepwise critics, but misalignment between immediate rewards and long-term objectives can lead to reward hacking and suboptimal policies. In this work, we address this problem in the context of software engineering (SWE) tasks, where multi-turn reasoning and rule-based verification are critical. We introduce the SWE-oriented RL Framework, a unified system supporting multi-turn interaction, docker-based execution, and customizable reward functions. Additionally, we propose Gated Reward Accumulation (G-RA), a novel method that accumulates immediate rewards only when high-level (long-term) rewards meet a predefined threshold, ensuring stable RL optimization. Experiments on SWE-bench Verified and kBench demonstrate that G-RA leads to an increase in completion rates (47.6% \rightarrow 93.8% and 22.0% \rightarrow 86.0%) and modification rates (19.6% \rightarrow 23.8% and 12.0% \rightarrow 42.0%), while avoiding policy degradation caused by reward misalignment. Our findings highlight the importance of balanced reward accumulation in long-horizon RL and provide a practical solution.
åœ¨é•¿æ—¶ç¨‹å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰ä»»åŠ¡ä¸­ï¼Œå¥–åŠ±ç¨€ç–æ€§ä»ç„¶æ˜¯ä¸€ä¸ªé‡è¦æŒ‘æˆ˜ï¼Œè€Œç°æœ‰åŸºäºç»“æœçš„å¥–åŠ±å¡‘é€ éš¾ä»¥åœ¨ä¸å¼•å…¥åå·®æˆ–ä¸éœ€è¦æ˜¾å¼ä»»åŠ¡åˆ†è§£çš„æƒ…å†µä¸‹å®šä¹‰æœ‰æ„ä¹‰çš„å³æ—¶å¥–åŠ±ã€‚å¦ä¸€ç§åŸºäºéªŒè¯çš„å¥–åŠ±å¡‘é€ ä½¿ç”¨é€æ­¥è¯„åˆ†å™¨ï¼Œä½†å³æ—¶å¥–åŠ±ä¸é•¿æœŸç›®æ ‡ä¹‹é—´çš„ä¸ä¸€è‡´å¯èƒ½å¯¼è‡´å¥–åŠ±è¢«æ“çºµå’Œæ¬¡ä¼˜ç­–ç•¥ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åœ¨è½¯ä»¶å·¥ç¨‹ï¼ˆSWEï¼‰ä»»åŠ¡çš„èƒŒæ™¯ä¸‹è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œåœ¨æ­¤ç±»ä»»åŠ¡ä¸­å¤šå›åˆæ¨ç†å’ŒåŸºäºè§„åˆ™çš„éªŒè¯è‡³å…³é‡è¦ã€‚æˆ‘ä»¬å¼•å…¥äº†é¢å‘ SWE çš„ RL æ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªæ”¯æŒå¤šå›åˆäº¤äº’ã€åŸºäº docker çš„æ‰§è¡Œå’Œå¯å®šåˆ¶å¥–åŠ±å‡½æ•°çš„ç»Ÿä¸€ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†é—¨æ§å¥–åŠ±ç´¯ç§¯ï¼ˆG-RAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°æ–¹æ³•ï¼Œä»…å½“é«˜å±‚ï¼ˆé•¿æœŸï¼‰å¥–åŠ±è¾¾åˆ°é¢„å®šä¹‰é˜ˆå€¼æ—¶æ‰ç´¯ç§¯å³æ—¶å¥–åŠ±ï¼Œä»è€Œä¿è¯äº†ç¨³å®šçš„ RL ä¼˜åŒ–ã€‚ åœ¨ SWE-bench Verified å’Œ kBench ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒG-RA æé«˜äº†å®Œæˆç‡ï¼ˆ47.6% â†’ 93.8% å’Œ 22.0% â†’ 86.0%ï¼‰å’Œä¿®æ”¹ç‡ï¼ˆ19.6% â†’ 23.8% å’Œ 12.0% â†’ 42.0%ï¼‰ï¼ŒåŒæ—¶é¿å…äº†ç”±å¥–åŠ±ä¸ä¸€è‡´å¯¼è‡´çš„ç­–ç•¥é€€åŒ–ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœå¼ºè°ƒäº†åœ¨é•¿æ—¶ç¨‹å¼ºåŒ–å­¦ä¹ ä¸­å¹³è¡¡å¥–åŠ±ç´¯ç§¯çš„é‡è¦æ€§ï¼Œå¹¶æä¾›äº†ä¸€ä¸ªå®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-14 11:37:02 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 11:37:02 UTC</p>
<h2 id="70-med-glip-advancing-medical-language-image-pre-training-with-large-scale-grounded-dataset--70-med-glipé€šè¿‡å¤§è§„æ¨¡å¸¦å®šä½æ•°æ®é›†æ¨è¿›åŒ»å­¦è¯­è¨€-å›¾åƒé¢„è®­ç»ƒ"><a href="https://arxiv.org/abs/2508.10528"target="_blank" rel="external nofollow noopener noreferrer">#70</a> <a href="https://papers.cool/arxiv/2508.10528"target="_blank" rel="external nofollow noopener noreferrer">Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset</a>  #70 Med-GLIPï¼šé€šè¿‡å¤§è§„æ¨¡å¸¦å®šä½æ•°æ®é›†æ¨è¿›åŒ»å­¦è¯­è¨€-å›¾åƒé¢„è®­ç»ƒ</h2>
<p><strong>Authors</strong>: [Ziye Deng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziye</a> Deng), [Ruihan He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ruihan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ruihan</a> He), [Jiaxiang Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaxiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaxiang</a> Liu), [Yuan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan</a> Wang), [Zijie Meng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zijie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zijie</a> Meng), [Songtao Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Songtao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Songtao</a> Jiang), [Yong Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yong</a> Xie), [Zuozhu Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zuozhu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zuozhu</a> Liu)
ä½œè€…ï¼šé‚“å­çƒ¨ã€ä½•ç¿æ¶µã€åˆ˜å®¶ç¥¥ã€ç‹åŸã€å­Ÿå­æ°ã€è’‹æ¾æ¶›ã€è°¢å‹‡ã€åˆ˜ä½œåŠ©</p>
<p>Medical image grounding aims to align natural language phrases with specific regions in medical images, serving as a foundational task for intelligent diagnosis, visual question answering (VQA), and automated report generation (MRG). However, existing research is constrained by limited modality coverage, coarse-grained annotations, and the absence of a unified, generalizable grounding framework. To address these challenges, we construct a large-scale medical grounding dataset Med-GLIP-5M comprising over 5.3 million region-level annotations across seven imaging modalities, covering diverse anatomical structures and pathological findings. The dataset supports both segmentation and grounding tasks with hierarchical region labels, ranging from organ-level boundaries to fine-grained lesions. Based on this foundation, we propose Med-GLIP, a modality-aware grounding framework trained on Med-GLIP-5M. Rather than relying on explicitly designed expert modules, Med-GLIP implicitly acquires hierarchical semantic understanding from diverse training data &ndash; enabling it to recognize multi-granularity structures, such as distinguishing lungs from pneumonia lesions. Extensive experiments demonstrate that Med-GLIP consistently outperforms state-of-the-art baselines across multiple grounding benchmarks. Furthermore, integrating its spatial outputs into downstream tasks, including medical VQA and report generation, leads to substantial performance gains. Our dataset will be released soon.
åŒ»å­¦å½±åƒå®šä½æ—¨åœ¨å°†è‡ªç„¶è¯­è¨€çŸ­è¯­ä¸åŒ»å­¦å½±åƒä¸­çš„ç‰¹å®šåŒºåŸŸå¯¹é½ï¼Œæ˜¯æ™ºèƒ½è¯Šæ–­ã€è§†è§‰é—®ç­”ï¼ˆVQAï¼‰å’Œè‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆï¼ˆMRGï¼‰çš„åŸºç¡€ä»»åŠ¡ã€‚ç„¶è€Œï¼Œç°æœ‰ç ”ç©¶å—åˆ¶äºæ¨¡æ€è¦†ç›–æœ‰é™ã€æ³¨é‡Šç²’åº¦ç²—ç³™ä»¥åŠç¼ºä¹ç»Ÿä¸€ä¸”å¯æ³›åŒ–çš„å®šä½æ¡†æ¶ã€‚ä¸ºäº†è§£å†³è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æ„å»ºäº†å¤§è§„æ¨¡åŒ»å­¦å®šä½æ•°æ®é›† Med-GLIP-5Mï¼ŒåŒ…å«è¶…è¿‡ 530 ä¸‡æ¡è·¨ä¸ƒç§æˆåƒæ¨¡æ€çš„åŒºåŸŸçº§æ³¨é‡Šï¼Œæ¶µç›–å¤šç§è§£å‰–ç»“æ„å’Œç—…ç†å‘ç°ã€‚è¯¥æ•°æ®é›†é€šè¿‡åˆ†å±‚åŒºåŸŸæ ‡ç­¾æ”¯æŒåˆ†å‰²å’Œå®šä½ä»»åŠ¡ï¼Œæ ‡ç­¾ç²’åº¦ä»å™¨å®˜çº§è¾¹ç•Œåˆ°ç»†ç²’åº¦ç—…å˜ä¸ç­‰ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬æå‡ºäº† Med-GLIPï¼Œä¸€ç§åœ¨ Med-GLIP-5M ä¸Šè®­ç»ƒçš„æ¨¡æ€æ„ŸçŸ¥å®šä½æ¡†æ¶ã€‚Med-GLIP å¹¶ä¸ä¾èµ–æ˜¾å¼è®¾è®¡çš„ä¸“å®¶æ¨¡å—ï¼Œè€Œæ˜¯é€šè¿‡å¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®éšå¼è·å–åˆ†å±‚è¯­ä¹‰ç†è§£â€”â€”ä½¿å…¶èƒ½å¤Ÿè¯†åˆ«å¤šç²’åº¦ç»“æ„ï¼Œä¾‹å¦‚åŒºåˆ†è‚ºè„ä¸è‚ºç‚ç—…ç¶ã€‚ å¤§é‡å®éªŒè¡¨æ˜ï¼ŒMed-GLIP åœ¨å¤šä¸ªå®šä½åŸºå‡†ä¸Šå§‹ç»ˆä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•ã€‚æ­¤å¤–ï¼Œå°†å…¶ç©ºé—´è¾“å‡ºæ•´åˆåˆ°ä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼ˆåŒ…æ‹¬åŒ»å­¦è§†è§‰é—®ç­”å’ŒæŠ¥å‘Šç”Ÿæˆï¼‰èƒ½å¤Ÿå¸¦æ¥æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚æˆ‘ä»¬çš„æ•°æ®é›†å°†å¾ˆå¿«å‘å¸ƒã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 11:02:38 UTC
å‘å¸ƒï¼š2025-08-14 11:02:38 UTC</p>
<h2 id="71-multi-sample-anti-aliasing-and-constrained-optimization-for-3d-gaussian-splatting--71-å¤šæ ·æœ¬æŠ—é”¯é½¿ä¸å—çº¦æŸä¼˜åŒ–ç”¨äºä¸‰ç»´é«˜æ–¯ç‚¹æ¸²æŸ“"><a href="https://arxiv.org/abs/2508.10507"target="_blank" rel="external nofollow noopener noreferrer">#71</a> <a href="https://papers.cool/arxiv/2508.10507"target="_blank" rel="external nofollow noopener noreferrer">Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting</a>  #71 å¤šæ ·æœ¬æŠ—é”¯é½¿ä¸å—çº¦æŸä¼˜åŒ–ç”¨äºä¸‰ç»´é«˜æ–¯ç‚¹æ¸²æŸ“</h2>
<p><strong>Authors</strong>: [Zheng Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zheng</a> Zhou), [Jia-Chen Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jia-Chen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jia-Chen</a> Zhang), [Yu-Jie Xiong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu-Jie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yu-Jie</a> Xiong), [Chun-Ming Xia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chun-Ming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chun-Ming</a> Xia)
ä½œè€…ï¼šå‘¨å¾ã€å¼ å®¶è‡£ã€ç†Šå®‡æ°ã€å¤æ˜¥æ˜</p>
<p>Recent advances in 3D Gaussian splatting have significantly improved real-time novel view synthesis, yet insufficient geometric constraints during scene optimization often result in blurred reconstructions of fine-grained details, particularly in regions with high-frequency textures and sharp discontinuities. To address this, we propose a comprehensive optimization framework integrating multisample anti-aliasing (MSAA) with dual geometric constraints. Our system computes pixel colors through adaptive blending of quadruple subsamples, effectively reducing aliasing artifacts in high-frequency components. The framework introduces two constraints: (a) an adaptive weighting strategy that prioritizes under-reconstructed regions through dynamic gradient analysis, and (b) gradient differential constraints enforcing geometric regularization at object boundaries. This targeted optimization enables the model to allocate computational resources preferentially to critical regions requiring refinement while maintaining global consistency. Extensive experimental evaluations across multiple benchmarks demonstrate that our method achieves state-of-the-art performance in detail preservation, particularly in preserving high-frequency textures and sharp discontinuities, while maintaining real-time rendering efficiency. Quantitative metrics and perceptual studies confirm statistically significant improvements over baseline approaches in both structural similarity (SSIM) and perceptual quality (LPIPS).
è¿‘å¹´æ¥ï¼Œ3D é«˜æ–¯ç‚¹äº‘ï¼ˆGaussian splattingï¼‰åœ¨å®æ—¶æ–°è§†è§’åˆæˆæ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œä½†åœºæ™¯ä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ ä½•çº¦æŸä¸è¶³å¸¸å¯¼è‡´ç»†ç²’åº¦ç»†èŠ‚é‡å»ºæ¨¡ç³Šï¼Œå°¤å…¶æ˜¯åœ¨é«˜é¢‘çº¹ç†å’Œé”åˆ©æ–­è£‚çš„åŒºåŸŸã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå°†å¤šæ ·æœ¬æŠ—é”¯é½¿ï¼ˆMSAAï¼‰ä¸åŒé‡å‡ ä½•çº¦æŸç›¸ç»“åˆçš„ç»¼åˆä¼˜åŒ–æ¡†æ¶ã€‚æˆ‘ä»¬çš„ç³»ç»Ÿé€šè¿‡å¯¹å››é‡å­æ ·æœ¬çš„è‡ªé€‚åº”æ··åˆæ¥è®¡ç®—åƒç´ é¢œè‰²ï¼Œæœ‰æ•ˆå‡å°‘é«˜é¢‘æˆåˆ†ä¸­çš„é”¯é½¿ä¼ªå½±ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸¤é¡¹çº¦æŸï¼šï¼ˆaï¼‰ä¸€ç§è‡ªé€‚åº”åŠ æƒç­–ç•¥ï¼Œé€šè¿‡åŠ¨æ€æ¢¯åº¦åˆ†æä¼˜å…ˆå¤„ç†é‡å»ºä¸è¶³çš„åŒºåŸŸï¼›ï¼ˆbï¼‰åœ¨ç‰©ä½“è¾¹ç•Œå¤„æ–½åŠ å‡ ä½•æ­£åˆ™åŒ–çš„æ¢¯åº¦å·®åˆ†çº¦æŸã€‚è¯¥æœ‰é’ˆå¯¹æ€§çš„ä¼˜åŒ–ä½¿æ¨¡å‹åœ¨ä¿æŒå…¨å±€ä¸€è‡´æ€§çš„åŒæ—¶ï¼Œèƒ½å¤Ÿä¼˜å…ˆå°†è®¡ç®—èµ„æºåˆ†é…ç»™éœ€è¦ç»†åŒ–çš„å…³é”®åŒºåŸŸã€‚ åœ¨å¤šä¸ªåŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•åœ¨ç»†èŠ‚ä¿ç•™æ–¹é¢è¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œå°¤å…¶åœ¨ä¿ç•™é«˜é¢‘çº¹ç†å’Œæ¸…æ™°ä¸è¿ç»­æ€§æ–¹é¢è¡¨ç°çªå‡ºï¼ŒåŒæ—¶ä¿æŒå®æ—¶æ¸²æŸ“æ•ˆç‡ã€‚å®šé‡æŒ‡æ ‡å’Œæ„ŸçŸ¥ç ”ç©¶è¯å®ï¼Œä¸åŸºçº¿æ–¹æ³•ç›¸æ¯”ï¼Œåœ¨ç»“æ„ç›¸ä¼¼æ€§ï¼ˆSSIMï¼‰å’Œæ„ŸçŸ¥è´¨é‡ï¼ˆLPIPSï¼‰ä¸Šå‡å…·æœ‰ç»Ÿè®¡æ˜¾è‘—çš„æå‡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 10:14:36 UTC
å‘å¸ƒï¼š2025-08-14 10:14:36 UTC</p>
<h2 id="72-advances-in-logic-based-entity-resolution-enhancing-aspen-with-local-merges-and-optimality-criteria--72-åŸºäºé€»è¾‘çš„å®ä½“æ¶ˆè§£è¿›å±•é€šè¿‡å±€éƒ¨åˆå¹¶å’Œæœ€ä¼˜æ€§å‡†åˆ™å¢å¼º-aspen"><a href="https://arxiv.org/abs/2508.10504"target="_blank" rel="external nofollow noopener noreferrer">#72</a> <a href="https://papers.cool/arxiv/2508.10504"target="_blank" rel="external nofollow noopener noreferrer">Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria</a>  #72 åŸºäºé€»è¾‘çš„å®ä½“æ¶ˆè§£è¿›å±•ï¼šé€šè¿‡å±€éƒ¨åˆå¹¶å’Œæœ€ä¼˜æ€§å‡†åˆ™å¢å¼º ASPEN</h2>
<p><strong>Authors</strong>: [Zhliang Xiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhliang</a> Xiang), [Meghyn Bienvenu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meghyn"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meghyn</a> Bienvenu), [Gianluca Cima](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gianluca"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gianluca</a> Cima), [VÃ­ctor GutiÃ©rrez-Basulto](<a href="https://arxiv.org/search/?searchtype=author&amp;query=V"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=V</a>Ã­ctor GutiÃ©rrez-Basulto), [YazmÃ­n IbÃ¡Ã±ez-GarcÃ­a](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yazm"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yazm</a>Ã­n IbÃ¡Ã±ez-GarcÃ­a)
ä½œè€…ï¼šé¡¹å¿—è‰¯ã€Meghyn Bienvenuã€Gianluca Cimaã€VÃ­ctor GutiÃ©rrez-Basultoã€YazmÃ­n IbÃ¡Ã±ez-GarcÃ­a</p>
<p>In this paper, we present ASPEN+, which extends an existing ASP-based system, ASPEN,for collective entity resolution with two important functionalities: support for local merges and new optimality criteria for preferred solutions. Indeed, ASPEN only supports so-called global merges of entity-referring constants (e.g. author ids), in which all occurrences of matched constants are treated as equivalent and merged accordingly. However, it has been argued that when resolving data values, local merges are often more appropriate, as e.g. some instances of &lsquo;J. Lee&rsquo; may refer to &lsquo;Joy Lee&rsquo;, while others should be matched with &lsquo;Jake Lee&rsquo;. In addition to allowing such local merges, ASPEN+ offers new optimality criteria for selecting solutions, such as minimizing rule violations or maximising the number of rules supporting a merge. Our main contributions are thus (1) the formalisation and computational analysis of various notions of optimal solution, and (2) an extensive experimental evaluation on real-world datasets, demonstrating the effect of local merges and the new optimality criteria on both accuracy and runtime.
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† ASPEN+ï¼Œå®ƒæ‰©å±•äº†ç°æœ‰çš„åŸºäº ASP çš„é›†åˆå®ä½“è§£æç³»ç»Ÿ ASPENï¼ŒåŠ å…¥äº†ä¸¤é¡¹é‡è¦åŠŸèƒ½ï¼šå¯¹å±€éƒ¨åˆå¹¶çš„æ”¯æŒä»¥åŠç”¨äºä¼˜é€‰è§£çš„æ–°æœ€ä¼˜æ€§å‡†åˆ™ã€‚äº‹å®ä¸Šï¼ŒASPEN ä»…æ”¯æŒæ‰€è°“çš„å®ä½“æŒ‡ç§°å¸¸é‡ï¼ˆä¾‹å¦‚ä½œè€… idï¼‰çš„å…¨å±€åˆå¹¶ï¼Œåœ¨è¿™ç§åˆå¹¶ä¸­æ‰€æœ‰åŒ¹é…åˆ°çš„å¸¸é‡å‡ºç°éƒ½è¢«è§†ä¸ºç­‰ä»·å¹¶æ®æ­¤åˆå¹¶ã€‚ç„¶è€Œï¼Œæœ‰è§‚ç‚¹è®¤ä¸ºåœ¨è§£ææ•°æ®å€¼æ—¶ï¼Œå±€éƒ¨åˆå¹¶å¸¸å¸¸æ›´ä¸ºæ°å½“ï¼Œä¾‹å¦‚æœ‰äº›â€œJ. Leeâ€çš„å®ä¾‹å¯èƒ½æŒ‡ä»£â€œJoy Leeâ€ï¼Œè€Œå…¶ä»–åˆ™åº”ä¸â€œJake Leeâ€åŒ¹é…ã€‚é™¤äº†å…è®¸æ­¤ç±»å±€éƒ¨åˆå¹¶ä¹‹å¤–ï¼ŒASPEN+ è¿˜æä¾›äº†ç”¨äºé€‰æ‹©è§£çš„æ–°æœ€ä¼˜æ€§å‡†åˆ™ï¼Œä¾‹å¦‚æœ€å°åŒ–è§„åˆ™è¿ä¾‹æˆ–æœ€å¤§åŒ–æ”¯æŒåˆå¹¶çš„è§„åˆ™æ•°é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬çš„ä¸»è¦è´¡çŒ®ä¸ºï¼š(1) å„ç§æœ€ä¼˜è§£æ¦‚å¿µçš„å½¢å¼åŒ–å’Œè®¡ç®—åˆ†æï¼ŒåŠ (2) åœ¨çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè¿›è¡Œçš„å¤§è§„æ¨¡å®éªŒè¯„ä¼°ï¼Œå±•ç¤ºäº†å±€éƒ¨åˆå¹¶å’Œæ–°æœ€ä¼˜æ€§å‡†åˆ™å¯¹å‡†ç¡®æ€§å’Œè¿è¡Œæ—¶é—´çš„å½±å“ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.DB"target="_blank" rel="external nofollow noopener noreferrer">Databases</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæ•°æ®åº“ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 10:05:56 UTC
å‘å¸ƒï¼š2025-08-14 10:05:56 UTC</p>
<h2 id="73-a-unified-multi-agent-framework-for-universal-multimodal-understanding-and-generation--73-ä¸€ä¸ªç”¨äºé€šç”¨å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ™ºèƒ½ä½“æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10494"target="_blank" rel="external nofollow noopener noreferrer">#73</a> <a href="https://papers.cool/arxiv/2508.10494"target="_blank" rel="external nofollow noopener noreferrer">A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation</a>  #73 ä¸€ä¸ªç”¨äºé€šç”¨å¤šæ¨¡æ€ç†è§£ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ™ºèƒ½ä½“æ¡†æ¶</h2>
<p><strong>Authors</strong>: [Jiulin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiulin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiulin</a> Li), [Ping Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ping"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ping</a> Huang), [Yexin Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yexin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yexin</a> Li), [Shuo Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuo</a> Chen), [Juewen Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juewen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juewen</a> Hu), [Ye Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ye"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ye</a> Tian)
ä½œè€…ï¼šæä¹æ—ï¼Œé»„å¹³ï¼Œæä¸šæ–°ï¼Œé™ˆç¡•ï¼Œèƒ¡è§‰æ–‡ï¼Œç”°é‡</p>
<p>Real-world multimodal applications often require any-to-any capabilities, enabling both understanding and generation across modalities including text, image, audio, and video. However, integrating the strengths of autoregressive language models (LLMs) for reasoning and diffusion models for high-fidelity generation remains challenging. Existing approaches rely on rigid pipelines or tightly coupled architectures, limiting flexibility and scalability. We propose MAGUS (Multi-Agent Guided Unified Multimodal System), a modular framework that unifies multimodal understanding and generation via two decoupled phases: Cognition and Deliberation. MAGUS enables symbolic multi-agent collaboration within a shared textual workspace. In the Cognition phase, three role-conditioned multimodal LLM agents - Perceiver, Planner, and Reflector - engage in collaborative dialogue to perform structured understanding and planning. The Deliberation phase incorporates a Growth-Aware Search mechanism that orchestrates LLM-based reasoning and diffusion-based generation in a mutually reinforcing manner. MAGUS supports plug-and-play extensibility, scalable any-to-any modality conversion, and semantic alignment - all without the need for joint training. Experiments across multiple benchmarks, including image, video, and audio generation, as well as cross-modal instruction following, demonstrate that MAGUS outperforms strong baselines and state-of-the-art systems. Notably, on the MME benchmark, MAGUS surpasses the powerful closed-source model GPT-4o.
ç°å®ä¸–ç•Œçš„å¤šæ¨¡æ€åº”ç”¨é€šå¸¸éœ€è¦ä»»æ„åˆ°ä»»æ„çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘ç­‰æ¨¡æ€ä¹‹é—´åŒæ—¶è¿›è¡Œç†è§£å’Œç”Ÿæˆã€‚ç„¶è€Œï¼Œå°†ç”¨äºæ¨ç†çš„è‡ªå›å½’è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„ä¼˜åŠ¿ä¸ç”¨äºé«˜ä¿çœŸç”Ÿæˆçš„æ‰©æ•£æ¨¡å‹ç»“åˆä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ç°æœ‰æ–¹æ³•ä¾èµ–åƒµåŒ–çš„æµæ°´çº¿æˆ–ç´§è€¦åˆçš„æ¶æ„ï¼Œé™åˆ¶äº†çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ã€‚æˆ‘ä»¬æå‡ºäº† MAGUSï¼ˆMulti-Agent Guided Unified Multimodal Systemï¼Œå¤šæ™ºèƒ½ä½“å¼•å¯¼çš„ç»Ÿä¸€å¤šæ¨¡æ€ç³»ç»Ÿï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–æ¡†æ¶ï¼Œé€šè¿‡ä¸¤ä¸ªè§£è€¦çš„é˜¶æ®µâ€”â€”è®¤çŸ¥ï¼ˆCognitionï¼‰å’Œå®¡è®®ï¼ˆDeliberationï¼‰â€”â€”ç»Ÿä¸€äº†å¤šæ¨¡æ€çš„ç†è§£ä¸ç”Ÿæˆã€‚MAGUS åœ¨å…±äº«çš„æ–‡æœ¬å·¥ä½œç©ºé—´ä¸­å®ç°äº†ç¬¦å·åŒ–çš„å¤šæ™ºèƒ½ä½“åä½œã€‚åœ¨è®¤çŸ¥é˜¶æ®µï¼Œä¸‰ä¸ªåŸºäºè§’è‰²çš„å¤šæ¨¡æ€ LLM ä»£ç†â€”â€”æ„ŸçŸ¥è€…ï¼ˆPerceiverï¼‰ã€è§„åˆ’è€…ï¼ˆPlannerï¼‰å’Œåæ€è€…ï¼ˆReflectorï¼‰â€”â€”é€šè¿‡åä½œå¯¹è¯æ¥æ‰§è¡Œç»“æ„åŒ–çš„ç†è§£å’Œè§„åˆ’ã€‚å®¡è®®é˜¶æ®µåˆ™å¼•å…¥äº†ä¸€ç§æ„ŸçŸ¥å¢é•¿çš„æœç´¢æœºåˆ¶ï¼ˆGrowth-Aware Searchï¼‰ï¼Œä»¥ä¸€ç§ç›¸äº’å¢å¼ºçš„æ–¹å¼åè°ƒåŸºäº LLM çš„æ¨ç†ä¸åŸºäºæ‰©æ•£çš„ç”Ÿæˆã€‚ MAGUS æ”¯æŒå³æ’å³ç”¨çš„å¯æ‰©å±•æ€§ã€å¯æ‰©å±•çš„ä»»æ„åˆ°ä»»æ„æ¨¡æ€è½¬æ¢ä»¥åŠè¯­ä¹‰å¯¹é½â€”â€”æ‰€æœ‰è¿™äº›éƒ½æ— éœ€è”åˆè®­ç»ƒã€‚åœ¨åŒ…æ‹¬å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘ç”Ÿæˆä»¥åŠè·¨æ¨¡æ€æŒ‡ä»¤è·Ÿéšçš„å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­ï¼Œå®éªŒç»“æœè¡¨æ˜ MAGUS ä¼˜äºå¼ºåŸºçº¿å’Œæœ€å…ˆè¿›ç³»ç»Ÿã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œåœ¨ MME åŸºå‡†ä¸Šï¼ŒMAGUS è¶…è¿‡äº†å¼ºå¤§çš„é—­æºæ¨¡å‹ GPT-4oã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.MA"target="_blank" rel="external nofollow noopener noreferrer">Multiagent Systems</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ</p>
<p><strong>Publish</strong>: 2025-08-14 09:52:51 UTC
å‘å¸ƒï¼š2025-08-14 09:52:51 UTC</p>
<h2 id="74-contrastive-ecoc-learning-output-codes-for-adversarial-defense--74-contrastive-ecocä¸ºå¯¹æŠ—æ€§é˜²å¾¡å­¦ä¹ è¾“å‡ºç "><a href="https://arxiv.org/abs/2508.10491"target="_blank" rel="external nofollow noopener noreferrer">#74</a> <a href="https://papers.cool/arxiv/2508.10491"target="_blank" rel="external nofollow noopener noreferrer">Contrastive ECOC: Learning Output Codes for Adversarial Defense</a>  #74 Contrastive ECOCï¼šä¸ºå¯¹æŠ—æ€§é˜²å¾¡å­¦ä¹ è¾“å‡ºç </h2>
<p><strong>Authors</strong>: [Che-Yu Chou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Che-Yu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Che-Yu</a> Chou), [Hung-Hsuan Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hung-Hsuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hung-Hsuan</a> Chen)
ä½œè€…ï¼šChe-Yu Chouï¼ŒHung-Hsuan Chen</p>
<p>Although one-hot encoding is commonly used for multiclass classification, it is not always the most effective encoding mechanism. Error Correcting Output Codes (ECOC) address multiclass classification by mapping each class to a unique codeword used as a label. Traditional ECOC methods rely on manually designed or randomly generated codebooks, which are labor-intensive and may yield suboptimal, dataset-agnostic results. This paper introduces three models for automated codebook learning based on contrastive learning, allowing codebooks to be learned directly and adaptively from data. Across four datasets, our proposed models demonstrate superior robustness to adversarial attacks compared to two baselines. The source is available at <a href="https://github.com/YuChou20/Automated-Codebook-Learning-with-Error-Correcting-Output-Code-Technique"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/YuChou20/Automated-Codebook-Learning-with-Error-Correcting-Output-Code-Technique</a>.
å°½ç®¡ç‹¬çƒ­ç¼–ç é€šå¸¸ç”¨äºå¤šç±»åˆ†ç±»ï¼Œä½†å®ƒå¹¶ä¸æ€»æ˜¯æœ€æœ‰æ•ˆçš„ç¼–ç æœºåˆ¶ã€‚çº é”™è¾“å‡ºç ï¼ˆECOCï¼‰é€šè¿‡å°†æ¯ä¸ªç±»åˆ«æ˜ å°„åˆ°ä¸€ä¸ªç”¨ä½œæ ‡ç­¾çš„å”¯ä¸€ç å­—æ¥è§£å†³å¤šç±»åˆ†ç±»é—®é¢˜ã€‚ä¼ ç»Ÿçš„ ECOC æ–¹æ³•ä¾èµ–æ‰‹å·¥è®¾è®¡æˆ–éšæœºç”Ÿæˆçš„ç æœ¬ï¼Œè¿™æ—¢è´¹æ—¶åˆå¯èƒ½äº§ç”Ÿå¯¹æ•°æ®é›†ä¸æ•æ„Ÿã€æ¬¡ä¼˜çš„ç»“æœã€‚æœ¬æ–‡æå‡ºäº†ä¸‰ç§åŸºäºå¯¹æ¯”å­¦ä¹ çš„è‡ªåŠ¨ç æœ¬å­¦ä¹ æ¨¡å‹ï¼Œå…è®¸ç æœ¬ç›´æ¥ä»æ•°æ®ä¸­è‡ªé€‚åº”å­¦ä¹ ã€‚åœ¨å››ä¸ªæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„æ¨¡å‹ç›¸æ¯”ä¸¤ä¸ªåŸºçº¿æ–¹æ³•å¯¹æŠ—æ”»å‡»å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ã€‚æºç å¯åœ¨ <a href="https://github.com/YuChou20/Automated-Codebook-Learning-with-Error-Correcting-Output-Code-Technique"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/YuChou20/Automated-Codebook-Learning-with-Error-Correcting-Output-Code-Technique</a> è·å¾—ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.IT"target="_blank" rel="external nofollow noopener noreferrer">Information Theory</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½ï¼Œä¿¡æ¯è®º</p>
<p><strong>Publish</strong>: 2025-08-14 09:50:50 UTC
å‘è¡¨æ—¶é—´ï¼š2025-08-14 09:50:50 UTC</p>
<h2 id="75-on-the-complexity-faithfulness-trade-off-of-gradient-based-explanations--75-å…³äºåŸºäºæ¢¯åº¦çš„è§£é‡Šçš„å¤æ‚æ€§-å¿ å®æ€§æƒè¡¡-pdf--å‰¯æœ¬-kimi--rel"><a href="https://arxiv.org/abs/2508.10490"target="_blank" rel="external nofollow noopener noreferrer">#75</a> <a href="https://papers.cool/arxiv/2508.10490"target="_blank" rel="external nofollow noopener noreferrer">On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations</a>  #75 å…³äºåŸºäºæ¢¯åº¦çš„è§£é‡Šçš„å¤æ‚æ€§-å¿ å®æ€§æƒè¡¡ [PDF ] [å‰¯æœ¬] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [Amir Mehrpanah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Amir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Amir</a> Mehrpanah), [Matteo Gamba](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Matteo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Matteo</a> Gamba), [Kevin Smith](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kevin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kevin</a> Smith), [Hossein Azizpour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hossein</a> Azizpour)
ä½œè€…ï¼šAmir Mehrpanahã€Matteo Gambaã€Kevin Smithã€Hossein Azizpour</p>
<p>ReLU networks, while prevalent for visual data, have sharp transitions, sometimes relying on individual pixels for predictions, making vanilla gradient-based explanations noisy and difficult to interpret. Existing methods, such as GradCAM, smooth these explanations by producing surrogate models at the cost of faithfulness. We introduce a unifying spectral framework to systematically analyze and quantify smoothness, faithfulness, and their trade-off in explanations. Using this framework, we quantify and regularize the contribution of ReLU networks to high-frequency information, providing a principled approach to identifying this trade-off. Our analysis characterizes how surrogate-based smoothing distorts explanations, leading to an ``explanation gap&rsquo;&rsquo; that we formally define and measure for different post-hoc methods. Finally, we validate our theoretical findings across different design choices, datasets, and ablations.
ReLU ç½‘ç»œåœ¨è§†è§‰æ•°æ®ä¸­è™½å¾ˆå¸¸è§ï¼Œä½†å…·æœ‰å°–é”çš„è·ƒå˜ï¼Œæœ‰æ—¶ä¼šä¾èµ–å•ä¸ªåƒç´ æ¥åšå‡ºé¢„æµ‹ï¼Œè¿™ä½¿å¾—åŸºäºæ™®é€šæ¢¯åº¦çš„è§£é‡Šå™ªå£°è¾ƒå¤§ä¸”éš¾ä»¥è§£è¯»ã€‚ç°æœ‰æ–¹æ³•ï¼ˆå¦‚ GradCAMï¼‰é€šè¿‡ç”Ÿæˆä»£ç†æ¨¡å‹æ¥å¹³æ»‘è¿™äº›è§£é‡Šï¼Œä»£ä»·æ˜¯å¿ å®æ€§ä¸‹é™ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„è°±æ¡†æ¶ï¼Œä»¥ç³»ç»Ÿåœ°åˆ†æå¹¶é‡åŒ–è§£é‡Šä¸­çš„å¹³æ»‘æ€§ã€å¿ å®æ€§åŠå…¶æƒè¡¡ã€‚åˆ©ç”¨è¯¥æ¡†æ¶ï¼Œæˆ‘ä»¬é‡åŒ–å¹¶å¯¹ ReLU ç½‘ç»œå¯¹é«˜é¢‘ä¿¡æ¯çš„è´¡çŒ®è¿›è¡Œæ­£åˆ™åŒ–ï¼Œä¸ºè¯†åˆ«è¿™ä¸€æƒè¡¡æä¾›äº†åŸåˆ™æ€§çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„åˆ†æåˆ»ç”»äº†åŸºäºä»£ç†çš„å¹³æ»‘å¦‚ä½•æ‰­æ›²è§£é‡Šï¼Œä»è€Œå¯¼è‡´æˆ‘ä»¬æ­£å¼å®šä¹‰å¹¶ä¸ºä¸åŒäº‹åæ–¹æ³•æµ‹é‡çš„â€œè§£é‡Šå·®è·â€ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨ä¸åŒçš„è®¾è®¡é€‰æ‹©ã€æ•°æ®é›†å’Œæ¶ˆèå®éªŒä¸ŠéªŒè¯äº†æˆ‘ä»¬çš„ç†è®ºå‘ç°ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>
å­¦ç§‘ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«</p>
<p><strong>Publish</strong>: 2025-08-14 09:49:07 UTC
å‘å¸ƒï¼š2025-08-14 09:49:07 UTC</p>
<h2 id="76-pinet-optimizing-hard-constrained-neural-networks-with-orthogonal-projection-layers--76-pinetä½¿ç”¨æ­£äº¤æŠ•å½±å±‚ä¼˜åŒ–ç¡¬çº¦æŸç¥ç»ç½‘ç»œ-pdf--copy-kimi-1--rel"><a href="https://arxiv.org/abs/2508.10480"target="_blank" rel="external nofollow noopener noreferrer">#76</a> <a href="https://papers.cool/arxiv/2508.10480"target="_blank" rel="external nofollow noopener noreferrer">Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers</a>  #76 Pinetï¼šä½¿ç”¨æ­£äº¤æŠ•å½±å±‚ä¼˜åŒ–ç¡¬çº¦æŸç¥ç»ç½‘ç»œ [PDF ] [Copy] [Kimi 1 ] [REL]</h2>
<p><strong>Authors</strong>: [Panagiotis D. Grontas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Panagiotis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Panagiotis</a> D. Grontas), [Antonio Terpin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Antonio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Antonio</a> Terpin), [Efe C. Balta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Efe"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Efe</a> C. Balta), [Raffaello D&rsquo;Andrea](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raffaello"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raffaello</a> D&rsquo;Andrea), [John Lygeros](<a href="https://arxiv.org/search/?searchtype=author&amp;query=John"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=John</a> Lygeros)
ä½œè€…ï¼šPanagiotis D. Grontasã€Antonio Terpinã€Efe C. Baltaã€Raffaello D&rsquo;Andreaã€John Lygeros</p>
<p>We introduce an output layer for neural networks that ensures satisfaction of convex constraints. Our approach, Î net, leverages operator splitting for rapid and reliable projections in the forward pass, and the implicit function theorem for backpropagation. We deploy Î net as a feasible-by-design optimization proxy for parametric constrained optimization problems and obtain modest-accuracy solutions faster than traditional solvers when solving a single problem, and significantly faster for a batch of problems. We surpass state-of-the-art learning approaches in terms of training time, solution quality, and robustness to hyperparameter tuning, while maintaining similar inference times. Finally, we tackle multi-vehicle motion planning with non-convex trajectory preferences and provide Î net as a GPU-ready package implemented in JAX with effective tuning heuristics.
æˆ‘ä»¬æå‡ºäº†ä¸€ç§ç”¨äºç¥ç»ç½‘ç»œçš„è¾“å‡ºå±‚ï¼Œä»¥ç¡®ä¿æ»¡è¶³å‡¸çº¦æŸã€‚æˆ‘ä»¬çš„æ–¹æ³•ï¼Œ netï¼Œåˆ©ç”¨ç®—å­åˆ†è£‚åœ¨å‰å‘ä¼ æ’­ä¸­å®ç°å¿«é€Ÿä¸”å¯é çš„æŠ•å½±ï¼Œå¹¶åˆ©ç”¨éšå‡½æ•°å®šç†è¿›è¡Œåå‘ä¼ æ’­ã€‚æˆ‘ä»¬å°† net ä½œä¸ºå‚æ•°åŒ–çº¦æŸä¼˜åŒ–é—®é¢˜çš„å¯è¡Œæ€§è®¾è®¡ä¼˜åŒ–ä»£ç†ï¼Œåœ¨æ±‚è§£å•ä¸ªé—®é¢˜æ—¶æ¯”ä¼ ç»Ÿæ±‚è§£å™¨æ›´å¿«åœ°è·å¾—ä¸­ç­‰ç²¾åº¦è§£ï¼Œåœ¨æ‰¹é‡é—®é¢˜æ±‚è§£æ—¶åˆ™æ˜¾è‘—æ›´å¿«ã€‚ä¸æœ€å…ˆè¿›çš„å­¦ä¹ æ–¹æ³•ç›¸æ¯”ï¼Œæˆ‘ä»¬åœ¨è®­ç»ƒæ—¶é—´ã€è§£çš„è´¨é‡ä»¥åŠå¯¹è¶…å‚æ•°è°ƒä¼˜çš„ç¨³å¥æ€§æ–¹é¢éƒ½æœ‰æ‰€è¶…è¶Šï¼ŒåŒæ—¶ä¿æŒäº†ç›¸ä¼¼çš„æ¨ç†æ—¶é—´ã€‚æœ€åï¼Œæˆ‘ä»¬å¤„ç†äº†å…·æœ‰éå‡¸è½¨è¿¹åå¥½çš„å¤šè½¦è¿åŠ¨è§„åˆ’é—®é¢˜ï¼Œå¹¶æä¾›äº†ä»¥ JAX å®ç°ã€æ”¯æŒ GPU ä¸”å«æœ‰æ•ˆè°ƒä¼˜å¯å‘å¼çš„ net è½¯ä»¶åŒ…ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/math.OC"target="_blank" rel="external nofollow noopener noreferrer">Optimization and Control</a>
å­¦ç§‘ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€ä¼˜åŒ–ä¸æ§åˆ¶</p>
<p><strong>Publish</strong>: 2025-08-14 09:32:09 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 09:32:09 UTC</p>
<h2 id="77-enhanced-sparse-point-cloud-data-processing-for-privacy-aware-human-action-recognition--77-å¢å¼ºçš„ç¨€ç–ç‚¹äº‘æ•°æ®å¤„ç†ç”¨äºæ³¨é‡éšç§çš„äººä½“åŠ¨ä½œè¯†åˆ«"><a href="https://arxiv.org/abs/2508.10469"target="_blank" rel="external nofollow noopener noreferrer">#77</a> <a href="https://papers.cool/arxiv/2508.10469"target="_blank" rel="external nofollow noopener noreferrer">Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition</a>  #77 å¢å¼ºçš„ç¨€ç–ç‚¹äº‘æ•°æ®å¤„ç†ç”¨äºæ³¨é‡éšç§çš„äººä½“åŠ¨ä½œè¯†åˆ«</h2>
<p><strong>Authors</strong>: [Maimunatu Tunau](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maimunatu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maimunatu</a> Tunau), [Vincent Gbouna Zakka](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vincent"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vincent</a> Gbouna Zakka), [Zhuangzhuang Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuangzhuang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuangzhuang</a> Dai)
ä½œè€…ï¼šMaimunatu Tunauã€Vincent Gbouna Zakkaã€Zhuangzhuang Dai</p>
<p>Human Action Recognition (HAR) plays a crucial role in healthcare, fitness tracking, and ambient assisted living technologies. While traditional vision based HAR systems are effective, they pose privacy concerns. mmWave radar sensors offer a privacy preserving alternative but present challenges due to the sparse and noisy nature of their point cloud data. In the literature, three primary data processing methods: Density-Based Spatial Clustering of Applications with Noise (DBSCAN), the Hungarian Algorithm, and Kalman Filtering have been widely used to improve the quality and continuity of radar data. However, a comprehensive evaluation of these methods, both individually and in combination, remains lacking. This paper addresses that gap by conducting a detailed performance analysis of the three methods using the MiliPoint dataset. We evaluate each method individually, all possible pairwise combinations, and the combination of all three, assessing both recognition accuracy and computational cost. Furthermore, we propose targeted enhancements to the individual methods aimed at improving accuracy. Our results provide crucial insights into the strengths and trade-offs of each method and their integrations, guiding future work on mmWave based HAR systems
äººä½“åŠ¨ä½œè¯†åˆ«ï¼ˆHARï¼‰åœ¨åŒ»ç–—ä¿å¥ã€å¥èº«è¿½è¸ªå’Œç¯å¢ƒè¾…åŠ©ç”Ÿæ´»æŠ€æœ¯ä¸­èµ·ç€å…³é”®ä½œç”¨ã€‚å°½ç®¡ä¼ ç»Ÿçš„åŸºäºè§†è§‰çš„ HAR ç³»ç»Ÿæœ‰æ•ˆï¼Œä½†å®ƒä»¬ä¼šå¸¦æ¥éšç§é—®é¢˜ã€‚æ¯«ç±³æ³¢é›·è¾¾ä¼ æ„Ÿå™¨æä¾›äº†ä¸€ç§ä¿æŠ¤éšç§çš„æ›¿ä»£æ–¹æ¡ˆï¼Œä½†ç”±äºå…¶ç‚¹äº‘æ•°æ®ç¨€ç–ä¸”å™ªå£°å¤§è€Œå¸¦æ¥æŒ‘æˆ˜ã€‚æ–‡çŒ®ä¸­å¹¿æ³›ä½¿ç”¨äº†ä¸‰ç§ä¸»è¦çš„æ•°æ®å¤„ç†æ–¹æ³•ï¼šåŸºäºå¯†åº¦çš„å™ªå£°åº”ç”¨ç©ºé—´èšç±»ï¼ˆDBSCANï¼‰ã€åŒˆç‰™åˆ©ç®—æ³•å’Œå¡å°”æ›¼æ»¤æ³¢ï¼Œä»¥æ”¹å–„é›·è¾¾æ•°æ®çš„è´¨é‡å’Œè¿ç»­æ€§ã€‚ç„¶è€Œï¼Œè¿™äº›æ–¹æ³•æ— è®ºæ˜¯å•ç‹¬ä½¿ç”¨è¿˜æ˜¯ç»„åˆä½¿ç”¨çš„ç»¼åˆè¯„ä¼°ä»ç„¶ç¼ºä¹ã€‚æœ¬æ–‡é€šè¿‡ä½¿ç”¨ MiliPoint æ•°æ®é›†å¯¹è¿™ä¸‰ç§æ–¹æ³•è¿›è¡Œè¯¦å°½çš„æ€§èƒ½åˆ†æä»¥å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚æˆ‘ä»¬åˆ†åˆ«è¯„ä¼°äº†æ¯ç§æ–¹æ³•ã€æ‰€æœ‰å¯èƒ½çš„ä¸¤ä¸¤ç»„åˆä»¥åŠä¸‰è€…ç»„åˆï¼Œè€ƒå¯Ÿäº†è¯†åˆ«å‡†ç¡®æ€§å’Œè®¡ç®—æˆæœ¬ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†æ—¨åœ¨æé«˜å‡†ç¡®æ€§çš„é’ˆå¯¹æ€§æ”¹è¿›æªæ–½ã€‚ æˆ‘ä»¬çš„ç»“æœä¸ºæ¯ç§æ–¹æ³•åŠå…¶æ•´åˆçš„ä¼˜åŠ¿ä¸æƒè¡¡æä¾›äº†å…³é”®è§è§£ï¼Œä¸ºæœªæ¥åŸºäºæ¯«ç±³æ³¢çš„äººä½“åŠ¨ä½œè¯†åˆ«ç³»ç»Ÿçš„ç ”ç©¶æŒ‡æ˜äº†æ–¹å‘</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 09:09:49 UTC
å‘å¸ƒï¼š2025-08-14 09:09:49 UTC</p>
<h2 id="78-x-node-self-explanation-is-all-we-need--78-x-nodeè‡ªæˆ‘è§£é‡Šå°±æ˜¯æˆ‘ä»¬æ‰€éœ€çš„ä¸€åˆ‡"><a href="https://arxiv.org/abs/2508.10461"target="_blank" rel="external nofollow noopener noreferrer">#78</a> <a href="https://papers.cool/arxiv/2508.10461"target="_blank" rel="external nofollow noopener noreferrer">X-Node: Self-Explanation is All We Need</a>  #78 X-Nodeï¼šè‡ªæˆ‘è§£é‡Šå°±æ˜¯æˆ‘ä»¬æ‰€éœ€çš„ä¸€åˆ‡</h2>
<p><strong>Authors</strong>: [Prajit Sengupta](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prajit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prajit</a> Sengupta), [Islem Rekik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Islem"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Islem</a> Rekik)
ä½œè€…ï¼šPrajit Senguptaï¼ŒIslem Rekik</p>
<p>Graph neural networks (GNNs) have achieved state-of-the-art results in computer vision and medical image classification tasks by capturing structural dependencies across data instances. However, their decision-making remains largely opaque, limiting their trustworthiness in high-stakes clinical applications where interpretability is essential. Existing explainability techniques for GNNs are typically post-hoc and global, offering limited insight into individual node decisions or local reasoning. We introduce X-Node, a self-explaining GNN framework in which each node generates its own explanation as part of the prediction process. For every node, we construct a structured context vector encoding interpretable cues such as degree, centrality, clustering, feature saliency, and label agreement within its local topology. A lightweight Reasoner module maps this context into a compact explanation vector, which serves three purposes: (1) reconstructing the node&rsquo;s latent embedding via a decoder to enforce faithfulness, (2) generating a natural language explanation using a pre-trained LLM (e.g., Grok or Gemini), and (3) guiding the GNN itself via a &ldquo;text-injection&rdquo; mechanism that feeds explanations back into the message-passing pipeline. We evaluate X-Node on two graph datasets derived from MedMNIST and MorphoMNIST, integrating it with GCN, GAT, and GIN backbones. Our results show that X-Node maintains competitive classification accuracy while producing faithful, per-node explanations. Repository: <a href="https://github.com/basiralab/X-Node"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/basiralab/X-Node</a>.
å›¾ç¥ç»ç½‘ç»œï¼ˆGNNsï¼‰é€šè¿‡æ•æ‰æ•°æ®å®ä¾‹ä¹‹é—´çš„ç»“æ„ä¾èµ–ï¼Œåœ¨è®¡ç®—æœºè§†è§‰å’ŒåŒ»å­¦å›¾åƒåˆ†ç±»ä»»åŠ¡ä¸­å–å¾—äº†æœ€å…ˆè¿›çš„ç»“æœã€‚ç„¶è€Œï¼Œå®ƒä»¬çš„å†³ç­–è¿‡ç¨‹åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šä»ä¸é€æ˜ï¼Œè¿™é™åˆ¶äº†å…¶åœ¨éœ€è¦å¯è§£é‡Šæ€§çš„é«˜é£é™©ä¸´åºŠåº”ç”¨ä¸­çš„å¯ä¿¡åº¦ã€‚ç°æœ‰çš„ GNN å¯è§£é‡Šæ€§æŠ€æœ¯é€šå¸¸æ˜¯äº‹åä¸”å…¨å±€æ€§çš„ï¼Œéš¾ä»¥æ·±å…¥ç†è§£å•ä¸ªèŠ‚ç‚¹çš„å†³ç­–æˆ–å±€éƒ¨æ¨ç†ã€‚æˆ‘ä»¬æå‡ºäº† X-Nodeï¼Œä¸€ç§è‡ªè§£é‡Šçš„ GNN æ¡†æ¶ï¼Œå…¶ä¸­æ¯ä¸ªèŠ‚ç‚¹åœ¨é¢„æµ‹è¿‡ç¨‹ä¸­éƒ½ä¼šç”Ÿæˆè‡ªå·±çš„è§£é‡Šã€‚å¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªç»“æ„åŒ–çš„ä¸Šä¸‹æ–‡å‘é‡ï¼Œç¼–ç å¯è§£é‡Šçš„çº¿ç´¢ï¼Œä¾‹å¦‚åº¦æ•°ã€ä¸­å¿ƒæ€§ã€èšç±»ã€ç‰¹å¾æ˜¾è‘—æ€§ä»¥åŠå…¶å±€éƒ¨æ‹“æ‰‘å†…çš„æ ‡ç­¾ä¸€è‡´æ€§ã€‚ ä¸€ä¸ªè½»é‡çº§çš„ Reasoner æ¨¡å—å°†è¯¥ä¸Šä¸‹æ–‡æ˜ å°„ä¸ºä¸€ä¸ªç´§å‡‘çš„è§£é‡Šå‘é‡ï¼Œè¯¥å‘é‡æœ‰ä¸‰é‡ç”¨é€”ï¼šï¼ˆ1ï¼‰é€šè¿‡è§£ç å™¨é‡å»ºèŠ‚ç‚¹çš„æ½œåœ¨åµŒå…¥ä»¥å¼ºåˆ¶ä¿æŒå¿ å®æ€§ï¼Œï¼ˆ2ï¼‰ä½¿ç”¨é¢„è®­ç»ƒçš„ LLMï¼ˆä¾‹å¦‚ Grok æˆ– Geminiï¼‰ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Šï¼Œå’Œï¼ˆ3ï¼‰é€šè¿‡ä¸€ç§â€œæ–‡æœ¬æ³¨å…¥â€æœºåˆ¶å°†è§£é‡Šåé¦ˆåˆ°æ¶ˆæ¯ä¼ é€’ç®¡é“ä¸­ä»¥æŒ‡å¯¼ GNN æœ¬èº«ã€‚æˆ‘ä»¬åœ¨ä¸¤ä¸ªæ¥è‡ª MedMNIST å’Œ MorphoMNIST çš„å›¾æ•°æ®é›†ä¸Šè¯„ä¼°äº† X-Nodeï¼Œå¹¶å°†å…¶ä¸ GCNã€GAT å’Œ GIN ä¸»å¹²ç½‘ç»œé›†æˆã€‚æˆ‘ä»¬çš„ç»“æœè¡¨æ˜ X-Node åœ¨ä¿æŒå…·æœ‰ç«äº‰åŠ›çš„åˆ†ç±»å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œèƒ½å¤Ÿç”Ÿæˆå¯¹æ¯ä¸ªèŠ‚ç‚¹éƒ½å¿ å®çš„è§£é‡Šã€‚ä»£ç åº“ï¼š <a href="https://github.com/basiralab/X-Node"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/basiralab/X-Node</a>ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 09:00:45 UTC
å‘å¸ƒï¼š2025-08-14 09:00:45 UTC</p>
<h2 id="79-realac-a-domain-agnostic-framework-for-realistic-and-actionable-counterfactual-explanations--79-realac-ä¸€ä¸ªé¢†åŸŸæ— å…³çš„æ¡†æ¶ç”¨äºç”ŸæˆçœŸå®ä¸”å¯æ“ä½œçš„åäº‹å®è§£é‡Š-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10455"target="_blank" rel="external nofollow noopener noreferrer">#79</a> <a href="https://papers.cool/arxiv/2508.10455"target="_blank" rel="external nofollow noopener noreferrer">RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations</a>  #79 RealAC: ä¸€ä¸ªé¢†åŸŸæ— å…³çš„æ¡†æ¶ï¼Œç”¨äºç”ŸæˆçœŸå®ä¸”å¯æ“ä½œçš„åäº‹å®è§£é‡Š [PDF ] [Copy] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [Asiful Arefeen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Asiful"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Asiful</a> Arefeen), [Shovito Barua Soumma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shovito"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shovito</a> Barua Soumma), [Hassan Ghasemzadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hassan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hassan</a> Ghasemzadeh)
ä½œè€…ï¼šAsiful Arefeenã€Shovito Barua Soummaã€Hassan Ghasemzadeh</p>
<p>Counterfactual explanations provide human-understandable reasoning for AI-made decisions by describing minimal changes to input features that would alter a model&rsquo;s prediction. To be truly useful in practice, such explanations must be realistic and feasible &ndash; they should respect both the underlying data distribution and user-defined feasibility constraints. Existing approaches often enforce inter-feature dependencies through rigid, hand-crafted constraints or domain-specific knowledge, which limits their generalizability and ability to capture complex, nonlinear relations inherent in data. Moreover, they rarely accommodate user-specified preferences and suggest explanations that are causally implausible or infeasible to act upon. We introduce RealAC, a domain-agnostic framework for generating realistic and actionable counterfactuals. RealAC automatically preserves complex inter-feature dependencies without relying on explicit domain knowledge &ndash; by aligning the joint distributions of feature pairs between factual and counterfactual instances. The framework also allows end-users to ``freeze&rsquo;&rsquo; attributes they cannot or do not wish to change by suppressing change in frozen features during optimization. Evaluations on three synthetic and two real datasets demonstrate that RealAC balances realism with actionability. Our method outperforms state-of-the-art baselines and Large Language Model-based counterfactual generation techniques in causal edge score, dependency preservation score, and IM1 realism metric and offers a solution for causality-aware and user-centric counterfactual generation.
åäº‹å®è§£é‡Šé€šè¿‡æè¿°å¯¹è¾“å…¥ç‰¹å¾è¿›è¡Œæœ€å°æ”¹åŠ¨å³å¯æ”¹å˜æ¨¡å‹é¢„æµ‹ï¼Œä»è€Œä¸º AI åšå‡ºçš„å†³ç­–æä¾›äººç±»å¯ç†è§£çš„æ¨ç†ã€‚ä¸ºåœ¨å®è·µä¸­çœŸæ­£æœ‰ç”¨ï¼Œæ­¤ç±»è§£é‡Šå¿…é¡»çœŸå®ä¸”å¯è¡Œâ€”â€”å®ƒä»¬åº”å½“åŒæ—¶å°Šé‡åº•å±‚æ•°æ®åˆ†å¸ƒå’Œç”¨æˆ·å®šä¹‰çš„å¯è¡Œæ€§çº¦æŸã€‚ç°æœ‰æ–¹æ³•é€šå¸¸é€šè¿‡åƒµåŒ–çš„äººå·¥è®¾è®¡çº¦æŸæˆ–é¢†åŸŸç‰¹å®šçŸ¥è¯†æ¥å¼ºåˆ¶å®æ–½ç‰¹å¾é—´ä¾èµ–ï¼Œè¿™é™åˆ¶äº†å®ƒä»¬çš„æ³›åŒ–èƒ½åŠ›ä»¥åŠæ•æ‰æ•°æ®ä¸­å¤æ‚éçº¿æ€§å…³ç³»çš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œå®ƒä»¬å¾ˆå°‘è€ƒè™‘ç”¨æˆ·æŒ‡å®šçš„åå¥½ï¼Œä¸”å¸¸å¸¸æå‡ºåœ¨å› æœä¸Šä¸åˆç†æˆ–æ— æ³•ä»˜è¯¸å®è·µçš„è§£é‡Šã€‚æˆ‘ä»¬æå‡ºäº† RealACï¼Œä¸€ä¸ªä¸é¢†åŸŸæ— å…³çš„ç”ŸæˆçœŸå®ä¸”å¯æ‰§è¡Œåäº‹å®çš„æ¡†æ¶ã€‚RealAC æ— éœ€ä¾èµ–æ˜¾å¼é¢†åŸŸçŸ¥è¯†å³å¯è‡ªåŠ¨ä¿ç•™å¤æ‚çš„ç‰¹å¾é—´ä¾èµ–â€”â€”æ–¹æ³•æ˜¯é€šè¿‡ä½¿äº‹å®å®ä¾‹ä¸åäº‹å®å®ä¾‹ä¹‹é—´çš„ç‰¹å¾å¯¹è”åˆåˆ†å¸ƒå¯¹é½æ¥å®ç°çš„ã€‚ è¯¥æ¡†æ¶è¿˜å…è®¸æœ€ç»ˆç”¨æˆ·é€šè¿‡åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­æŠ‘åˆ¶å¯¹å·²å†»ç»“ç‰¹å¾çš„å˜åŒ–æ¥â€œå†»ç»“â€ä»–ä»¬æ— æ³•æˆ–ä¸æ„¿æ”¹å˜çš„å±æ€§ã€‚åœ¨ä¸‰ä¸ªåˆæˆæ•°æ®é›†å’Œä¸¤ä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒRealAC åœ¨ç°å®æ€§ä¸å¯æ“ä½œæ€§ä¹‹é—´å–å¾—äº†å¹³è¡¡ã€‚æˆ‘ä»¬çš„æ–¹æ³•åœ¨å› æœè¾¹å¾—åˆ†ã€ä¾èµ–æ€§ä¿æŒå¾—åˆ†å’Œ IM1 ç°å®æ€§æŒ‡æ ‡ä¸Šå‡ä¼˜äºæœ€å…ˆè¿›çš„åŸºçº¿æ–¹æ³•å’ŒåŸºäºå¤§å‹è¯­è¨€æ¨¡å‹çš„åäº‹å®ç”ŸæˆæŠ€æœ¯ï¼Œå¹¶ä¸ºå…·å¤‡å› æœæ„è¯†å’Œä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„åäº‹å®ç”Ÿæˆæä¾›äº†è§£å†³æ–¹æ¡ˆã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 08:51:39 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 08:51:39 UTC</p>
<h2 id="80-alternating-approach-putt-models-for-multi-stage-speech-enhancement--80-äº¤æ›¿ä¸Šåœº-æ¨æ†æ¨¡å‹ç”¨äºå¤šé˜¶æ®µè¯­éŸ³å¢å¼º"><a href="https://arxiv.org/abs/2508.10436"target="_blank" rel="external nofollow noopener noreferrer">#80</a> <a href="https://papers.cool/arxiv/2508.10436"target="_blank" rel="external nofollow noopener noreferrer">Alternating Approach-Putt Models for Multi-Stage Speech Enhancement</a>  #80 äº¤æ›¿â€œä¸Šåœº-æ¨æ†â€æ¨¡å‹ç”¨äºå¤šé˜¶æ®µè¯­éŸ³å¢å¼º</h2>
<p><strong>Authors</strong>: [Iksoon Jeong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Iksoon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Iksoon</a> Jeong), [Kyung-Joong Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyung-Joong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyung-Joong</a> Kim), [Kang-Hun Ahn](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kang-Hun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kang-Hun</a> Ahn)
ä½œè€…ï¼šIksoon Jeongï¼ŒKyung-Joong Kimï¼ŒKang-Hun Ahn</p>
<p>Speech enhancement using artificial neural networks aims to remove noise from noisy speech signals while preserving the speech content. However, speech enhancement networks often introduce distortions to the speech signal, referred to as artifacts, which can degrade audio quality. In this work, we propose a post-processing neural network designed to mitigate artifacts introduced by speech enhancement models. Inspired by the analogy of making a <code>Putt' after an </code>Approach&rsquo; in golf, we name our model PuttNet. We demonstrate that alternating between a speech enhancement model and the proposed Putt model leads to improved speech quality, as measured by perceptual quality scores (PESQ), objective intelligibility (STOI), and background noise intrusiveness (CBAK) scores. Furthermore, we illustrate with graphical analysis why this alternating Approach outperforms repeated application of either model alone.
ä½¿ç”¨äººå·¥ç¥ç»ç½‘ç»œçš„è¯­éŸ³å¢å¼ºæ—¨åœ¨ä»å¸¦å™ªè¯­éŸ³ä¿¡å·ä¸­å»é™¤å™ªå£°ï¼ŒåŒæ—¶ä¿ç•™è¯­éŸ³å†…å®¹ã€‚ç„¶è€Œï¼Œè¯­éŸ³å¢å¼ºç½‘ç»œå¸¸å¸¸ä¼šå¯¹è¯­éŸ³ä¿¡å·å¼•å…¥å¤±çœŸï¼Œå³æ‰€è°“çš„ä¼ªå½±ï¼Œè¿™ä¼šé™ä½éŸ³é¢‘è´¨é‡ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåå¤„ç†ç¥ç»ç½‘ç»œï¼Œæ—¨åœ¨å‡è½»è¯­éŸ³å¢å¼ºæ¨¡å‹å¼•å…¥çš„ä¼ªå½±ã€‚å—åˆ°é«˜å°”å¤«ä¸­â€œä¸Šåœºï¼ˆApproachï¼‰â€ä¹‹åè¿›è¡Œâ€œæ¨æ†ï¼ˆPuttï¼‰â€çš„ç±»æ¯”å¯å‘ï¼Œæˆ‘ä»¬å°†æ¨¡å‹å‘½åä¸º PuttNetã€‚æˆ‘ä»¬è¯æ˜äº†åœ¨è¯­éŸ³å¢å¼ºæ¨¡å‹å’Œæ‰€æ Putt æ¨¡å‹ä¹‹é—´äº¤æ›¿ä½¿ç”¨å¯ä»¥æé«˜è¯­éŸ³è´¨é‡ï¼Œè¡¡é‡æŒ‡æ ‡åŒ…æ‹¬æ„ŸçŸ¥è´¨é‡å¾—åˆ†ï¼ˆPESQï¼‰ã€å®¢è§‚å¯æ‡‚åº¦ï¼ˆSTOIï¼‰å’ŒèƒŒæ™¯å™ªå£°ä¾µå…¥åº¦ï¼ˆCBAKï¼‰å¾—åˆ†ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬é€šè¿‡å›¾å½¢åˆ†æè¯´æ˜äº†ä¸ºä½•è¿™ç§äº¤æ›¿çš„â€œä¸Šåœºâ€æ–¹æ³•ä¼˜äºå•ç‹¬é‡å¤åº”ç”¨ä»»ä¸€æ¨¡å‹ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">Sound</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">Audio and Speech Processing</a>
ä¸»é¢˜ï¼šå£°éŸ³ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ ï¼ŒéŸ³é¢‘ä¸è¯­éŸ³å¤„ç†</p>
<p><strong>Publish</strong>: 2025-08-14 08:18:42 UTC
å‘å¸ƒï¼š2025-08-14 08:18:42 UTC</p>
<h2 id="81-unpacking-the-implicit-norm-dynamics-of-sharpness-aware-minimization-in-tensorized-models--81-è§£æ„å¼ é‡åŒ–æ¨¡å‹ä¸­é”åº¦æ„ŸçŸ¥æœ€å°åŒ–çš„éšå«èŒƒæ•°åŠ¨åŠ›å­¦"><a href="https://arxiv.org/abs/2508.10435"target="_blank" rel="external nofollow noopener noreferrer">#81</a> <a href="https://papers.cool/arxiv/2508.10435"target="_blank" rel="external nofollow noopener noreferrer">Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models</a>  #81 è§£æ„å¼ é‡åŒ–æ¨¡å‹ä¸­é”åº¦æ„ŸçŸ¥æœ€å°åŒ–çš„éšå«èŒƒæ•°åŠ¨åŠ›å­¦</h2>
<p><strong>Authors</strong>: [Tianxiao Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianxiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianxiao</a> Cao), [Kyohei Atarashi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyohei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyohei</a> Atarashi), [Hisashi Kashima](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hisashi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hisashi</a> Kashima)
ä½œè€…ï¼šæ›¹å¤©æ™“ã€Atarashi Kyoheiã€æ¨«é—´ä¹…å¿—</p>
<p>Sharpness-Aware Minimization (SAM) has been proven to be an effective optimization technique for improving generalization in overparameterized models. While prior works have explored the implicit regularization of SAM in simple two-core scale-invariant settings, its behavior in more general tensorized or scale-invariant models remains underexplored. In this work, we leverage scale-invariance to analyze the norm dynamics of SAM in general tensorized models. We introduce the notion of \emph{Norm Deviation} as a global measure of core norm imbalance, and derive its evolution under SAM using gradient flow analysis. We show that SAM&rsquo;s implicit control of Norm Deviation is governed by the covariance between core norms and their gradient magnitudes. Motivated by these findings, we propose a simple yet effective method, \emph{Deviation-Aware Scaling (DAS)}, which explicitly mimics this regularization behavior by scaling core norms in a data-adaptive manner. Our experiments across tensor completion, noisy training, model compression, and parameter-efficient fine-tuning confirm that DAS achieves competitive or improved performance over SAM, while offering reduced computational overhead.
é”åº¦æ„ŸçŸ¥æœ€å°åŒ–ï¼ˆSAMï¼‰å·²è¢«è¯æ˜æ˜¯åœ¨å‚æ•°è¿‡å¤šæ¨¡å‹ä¸­æå‡æ³›åŒ–èƒ½åŠ›çš„ä¸€ç§æœ‰æ•ˆä¼˜åŒ–æŠ€æœ¯ã€‚å°½ç®¡ä»¥å¾€å·¥ä½œåœ¨ç®€å•çš„åŒæ ¸å°ºåº¦ä¸å˜è®¾å®šä¸­æ¢è®¨äº† SAM çš„éšå¼æ­£åˆ™åŒ–ï¼Œä½†å…¶åœ¨æ›´ä¸€èˆ¬çš„å¼ é‡åŒ–æˆ–å°ºåº¦ä¸å˜æ¨¡å‹ä¸­çš„è¡Œä¸ºä»æœªè¢«å……åˆ†ç ”ç©¶ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åˆ©ç”¨å°ºåº¦ä¸å˜æ€§æ¥åˆ†æ SAM åœ¨ä¸€èˆ¬å¼ é‡åŒ–æ¨¡å‹ä¸­çš„èŒƒæ•°åŠ¨åŠ›å­¦ã€‚æˆ‘ä»¬å¼•å…¥äº†â€œèŒƒæ•°åå·®â€ï¼ˆNorm Deviationï¼‰çš„æ¦‚å¿µï¼Œä½œä¸ºè¡¡é‡æ ¸å¿ƒèŒƒæ•°ä¸å¹³è¡¡çš„å…¨å±€æŒ‡æ ‡ï¼Œå¹¶é€šè¿‡æ¢¯åº¦æµåˆ†ææ¨å¯¼äº†å…¶åœ¨ SAM ä¸‹çš„æ¼”åŒ–ã€‚æˆ‘ä»¬è¯æ˜äº† SAM å¯¹èŒƒæ•°åå·®çš„éšå¼æ§åˆ¶ç”±æ ¸å¿ƒèŒƒæ•°ä¸å…¶æ¢¯åº¦å¹…åº¦ä¹‹é—´çš„åæ–¹å·®å†³å®šã€‚åŸºäºè¿™äº›å‘ç°ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„æ–¹æ³•â€”â€”â€œåå·®æ„ŸçŸ¥ç¼©æ”¾â€ï¼ˆDeviation-Aware Scalingï¼ŒDASï¼‰ï¼Œé€šè¿‡ä»¥æ•°æ®è‡ªé€‚åº”çš„æ–¹å¼ç¼©æ”¾æ ¸å¿ƒèŒƒæ•°æ¥æ˜¾å¼æ¨¡æ‹Ÿè¿™ç§æ­£åˆ™åŒ–è¡Œä¸ºã€‚æˆ‘ä»¬åœ¨å¼ é‡è¡¥å…¨ã€å¸¦å™ªè®­ç»ƒã€æ¨¡å‹å‹ç¼©å’Œå‚æ•°é«˜æ•ˆå¾®è°ƒç­‰ä»»åŠ¡ä¸Šçš„å®éªŒéªŒè¯äº† DAS åœ¨æ€§èƒ½ä¸Šä¸ SAM ç›¸å½“æˆ–æœ‰æ‰€æå‡ï¼ŒåŒæ—¶å…·å¤‡æ›´ä½çš„è®¡ç®—å¼€é”€ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/stat.ML"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 08:17:34 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 08:17:34 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="82-mash-cooperative-heterogeneous-multi-agent-reinforcement-learning-for-single-humanoid-robot-locomotion--82-mashç”¨äºå•äººå½¢æœºå™¨äººè¡Œèµ°çš„åä½œå¼‚è´¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10423"target="_blank" rel="external nofollow noopener noreferrer">#82</a> <a href="https://papers.cool/arxiv/2508.10423"target="_blank" rel="external nofollow noopener noreferrer">MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion</a>  #82 MASHï¼šç”¨äºå•äººå½¢æœºå™¨äººè¡Œèµ°çš„åä½œå¼‚è´¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ </h2>
<p><strong>Authors</strong>: [Qi Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qi</a> Liu), [Xiaopeng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaopeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaopeng</a> Zhang), [Mingshan Tan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingshan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingshan</a> Tan), [Shuaikang Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shuaikang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shuaikang</a> Ma), [Jinliang Ding](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinliang</a> Ding), [Yanjie Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanjie</a> Li)
ä½œè€…ï¼šQi Liuã€Xiaopeng Zhangã€Mingshan Tanã€Shuaikang Maã€Jinliang Dingã€Yanjie Li</p>
<p>This paper proposes a novel method to enhance locomotion for a single humanoid robot through cooperative-heterogeneous multi-agent deep reinforcement learning (MARL). While most existing methods typically employ single-agent reinforcement learning algorithms for a single humanoid robot or MARL algorithms for multi-robot system tasks, we propose a distinct paradigm: applying cooperative-heterogeneous MARL to optimize locomotion for a single humanoid robot. The proposed method, multi-agent reinforcement learning for single humanoid locomotion (MASH), treats each limb (legs and arms) as an independent agent that explores the robot&rsquo;s action space while sharing a global critic for cooperative learning. Experiments demonstrate that MASH accelerates training convergence and improves whole-body cooperation ability, outperforming conventional single-agent reinforcement learning methods. This work advances the integration of MARL into single-humanoid-robot control, offering new insights into efficient locomotion strategies.
æœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°æ–¹æ³•ï¼Œé€šè¿‡åä½œå¼‚æ„å¤šæ™ºèƒ½ä½“æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆMARLï¼‰æ¥å¢å¼ºå•ä¸ªäººå½¢æœºå™¨äººçš„è¿åŠ¨èƒ½åŠ›ã€‚å°½ç®¡å¤§å¤šæ•°ç°æœ‰æ–¹æ³•é€šå¸¸å¯¹å•ä¸ªäººå½¢æœºå™¨äººä½¿ç”¨å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œæˆ–å¯¹å¤šæœºå™¨äººç³»ç»Ÿä»»åŠ¡ä½¿ç”¨ MARL ç®—æ³•ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸åŒçš„èŒƒå¼ï¼šå°†åä½œå¼‚æ„ MARL åº”ç”¨äºä¼˜åŒ–å•ä¸ªäººå½¢æœºå™¨äººçš„è¿åŠ¨ã€‚æ‰€æå‡ºçš„æ–¹æ³•â€”â€”ç”¨äºå•ä¸ªäººå½¢æœºå™¨äººè¿åŠ¨çš„å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ ï¼ˆMASHï¼‰ï¼Œå°†æ¯æ¡è‚¢ä½“ï¼ˆè…¿å’Œè‡‚ï¼‰è§†ä¸ºç‹¬ç«‹çš„æ™ºèƒ½ä½“ï¼Œåœ¨æ¢ç´¢æœºå™¨äººåŠ¨ä½œç©ºé—´çš„åŒæ—¶å…±äº«ä¸€ä¸ªå…¨å±€è¯„è®ºå™¨ä»¥è¿›è¡Œåä½œå­¦ä¹ ã€‚å®éªŒè¡¨æ˜ï¼ŒMASH èƒ½åŠ é€Ÿè®­ç»ƒæ”¶æ•›å¹¶æé«˜å…¨èº«åä½œèƒ½åŠ›ï¼Œä¼˜äºä¼ ç»Ÿçš„å•æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ æ–¹æ³•ã€‚æœ¬å·¥ä½œæ¨è¿›äº† MARL åœ¨å•ä¸ªäººå½¢æœºå™¨äººæ§åˆ¶ä¸­çš„æ•´åˆï¼Œä¸ºé«˜æ•ˆè¿åŠ¨ç­–ç•¥æä¾›äº†æ–°çš„è§è§£ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">Robotics</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/eess.SY"target="_blank" rel="external nofollow noopener noreferrer">Systems and Control</a>
å­¦ç§‘ï¼šæœºå™¨äººå­¦ã€äººå·¥æ™ºèƒ½ã€ç³»ç»Ÿä¸æ§åˆ¶</p>
<p><strong>Publish</strong>: 2025-08-14 07:54:31 UTC
å‘å¸ƒï¼š2025-08-14 07:54:31 UTC</p>
<h2 id="83-comorag-a-cognitive-inspired-memory-organized-rag-for-stateful-long-narrative-reasoning--83-comoragä¸€ç§å—è®¤çŸ¥å¯å‘çš„è®°å¿†ç»„ç»‡å¼-ragç”¨äºæœ‰çŠ¶æ€çš„é•¿å™äº‹æ¨ç†"><a href="https://arxiv.org/abs/2508.10419"target="_blank" rel="external nofollow noopener noreferrer">#83</a> <a href="https://papers.cool/arxiv/2508.10419"target="_blank" rel="external nofollow noopener noreferrer">ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning</a>  #83 ComoRAGï¼šä¸€ç§å—è®¤çŸ¥å¯å‘çš„è®°å¿†ç»„ç»‡å¼ RAGï¼Œç”¨äºæœ‰çŠ¶æ€çš„é•¿å™äº‹æ¨ç†</h2>
<p><strong>Authors</strong>: [Juyuan Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juyuan</a> Wang), [Rongchen Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rongchen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rongchen</a> Zhao), [Wei Wei](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wei</a> Wei), [Yufeng Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yufeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yufeng</a> Wang), [Mo Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mo</a> Yu), [Jie Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jie</a> Zhou), [Jin Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jin</a> Xu), [Liyan Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liyan</a> Xu)
ä½œè€…ï¼šç‹èšæºã€èµµè£è‡£ã€é­å¨ã€ç‹ç‰å³°ã€äºå¢¨ã€å‘¨æ°ã€å¾æ™‹ã€è®¸ä¸½è‰³</p>
<p>Narrative comprehension on long stories and novels has been a challenging domain attributed to their intricate plotlines and entangled, often evolving relations among characters and entities. Given the LLM&rsquo;s diminished reasoning over extended context and high computational cost, retrieval-based approaches remain a pivotal role in practice. However, traditional RAG methods can fall short due to their stateless, single-step retrieval process, which often overlooks the dynamic nature of capturing interconnected relations within long-range context. In this work, we propose ComoRAG, holding the principle that narrative reasoning is not a one-shot process, but a dynamic, evolving interplay between new evidence acquisition and past knowledge consolidation, analogous to human cognition when reasoning with memory-related signals in the brain. Specifically, when encountering a reasoning impasse, ComoRAG undergoes iterative reasoning cycles while interacting with a dynamic memory workspace. In each cycle, it generates probing queries to devise new exploratory paths, then integrates the retrieved evidence of new aspects into a global memory pool, thereby supporting the emergence of a coherent context for the query resolution. Across four challenging long-context narrative benchmarks (200K+ tokens), ComoRAG outperforms strong RAG baselines with consistent relative gains up to 11% compared to the strongest baseline. Further analysis reveals that ComoRAG is particularly advantageous for complex queries requiring global comprehension, offering a principled, cognitively motivated paradigm for retrieval-based long context comprehension towards stateful reasoning. Our code is publicly released at <a href="https://github.com/EternityJune25/ComoRAG"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/EternityJune25/ComoRAG</a>
å¯¹é•¿ç¯‡æ•…äº‹å’Œå°è¯´çš„å™äº‹ç†è§£ä¸€ç›´æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸï¼Œè¿™å½’å› äºå…¶é”™ç»¼å¤æ‚çš„æƒ…èŠ‚çº¿å’Œäººç‰©ä¸å®ä½“ä¹‹é—´çº ç¼ ä¸”å¸¸å¸¸æ¼”å˜çš„å…³ç³»ã€‚é‰´äº LLM åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­çš„æ¨ç†èƒ½åŠ›ä¸‹é™ä¸”è®¡ç®—ä»£ä»·é«˜æ˜‚ï¼ŒåŸºäºæ£€ç´¢çš„æ–¹æ³•åœ¨å®è·µä¸­ä»ç„¶æ‰®æ¼”ç€å…³é”®è§’è‰²ã€‚ç„¶è€Œï¼Œä¼ ç»Ÿçš„ RAG æ–¹æ³•å¯èƒ½ä¸è¶³ä»¥åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œå› ä¸ºå…¶æ— çŠ¶æ€çš„ã€å•æ­¥çš„æ£€ç´¢è¿‡ç¨‹å¾€å¾€å¿½è§†äº†åœ¨é•¿ç¨‹ä¸Šä¸‹æ–‡ä¸­æ•æ‰ç›¸äº’å…³è”å…³ç³»çš„åŠ¨æ€ç‰¹æ€§ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† ComoRAGï¼Œç§‰æŒè¿™æ ·ä¸€ä¸ªåŸåˆ™ï¼šå™äº‹æ¨ç†å¹¶éä¸€æ¬¡æ€§çš„è¿‡ç¨‹ï¼Œè€Œæ˜¯æ–°è¯æ®è·å–ä¸è¿‡å»çŸ¥è¯†å·©å›ºä¹‹é—´çš„åŠ¨æ€ã€ä¸æ–­æ¼”åŒ–çš„ç›¸äº’ä½œç”¨ï¼Œè¿™ç±»ä¼¼äºäººè„‘åœ¨å¸¦æœ‰è®°å¿†ç›¸å…³ä¿¡å·çš„æ¨ç†æ—¶çš„è®¤çŸ¥è¿‡ç¨‹ã€‚å…·ä½“è€Œè¨€ï¼Œå½“é‡åˆ°æ¨ç†åƒµå±€æ—¶ï¼ŒComoRAG ä¼šåœ¨ä¸åŠ¨æ€è®°å¿†å·¥ä½œåŒºäº¤äº’çš„åŒæ—¶è¿›è¡Œè¿­ä»£æ¨ç†å¾ªç¯ã€‚ åœ¨æ¯ä¸ªå¾ªç¯ä¸­ï¼Œå®ƒç”Ÿæˆæ¢æµ‹æ€§æŸ¥è¯¢ä»¥è®¾è®¡æ–°çš„æ¢ç´¢è·¯å¾„ï¼Œç„¶åå°†æ£€ç´¢åˆ°çš„æ–°æ–¹é¢è¯æ®æ•´åˆåˆ°å…¨å±€è®°å¿†æ± ä¸­ï¼Œä»è€Œæ”¯æŒä¸ºæŸ¥è¯¢è§£å†³æ„å»ºè¿è´¯çš„ä¸Šä¸‹æ–‡ã€‚åœ¨å››ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„é•¿ä¸Šä¸‹æ–‡å™äº‹åŸºå‡†ï¼ˆ20 ä¸‡+ ä»¤ç‰Œï¼‰ä¸Šï¼ŒComoRAG ç›¸è¾ƒäºå¼ºå¤§çš„ RAG åŸºçº¿è¡¨ç°æ›´ä½³ï¼Œä¸æœ€å¼ºåŸºçº¿ç›¸æ¯”ä¸€è‡´æ€§ç›¸å¯¹æå‡é«˜è¾¾ 11%ã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼ŒComoRAG å¯¹äºéœ€è¦å…¨å±€ç†è§£çš„å¤æ‚æŸ¥è¯¢å°¤ä¸ºæœ‰åˆ©ï¼Œä¸ºåŸºäºæ£€ç´¢çš„é•¿ä¸Šä¸‹æ–‡ç†è§£æä¾›äº†ä¸€ç§æœ‰åŸåˆ™ã€å—è®¤çŸ¥å¯å‘çš„èŒƒå¼ï¼Œä»¥å®ç°æœ‰çŠ¶æ€æ¨ç†ã€‚æˆ‘ä»¬çš„ä»£ç å·²åœ¨ <a href="https://github.com/EternityJune25/ComoRAG"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/EternityJune25/ComoRAG</a> å…¬å¼€å‘å¸ƒã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-14 07:52:09 UTC
å‘å¸ƒï¼š2025-08-14 07:52:09 UTC</p>
<h2 id="84-correctnav-self-correction-flywheel-empowers-vision-language-action-navigation-model--84-correctnavè‡ªæˆ‘ä¿®æ­£é£è½®èµ‹èƒ½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨å¯¼èˆªæ¨¡å‹"><a href="https://arxiv.org/abs/2508.10416"target="_blank" rel="external nofollow noopener noreferrer">#84</a> <a href="https://papers.cool/arxiv/2508.10416"target="_blank" rel="external nofollow noopener noreferrer">CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model</a>  #84 CorrectNavï¼šè‡ªæˆ‘ä¿®æ­£é£è½®èµ‹èƒ½è§†è§‰-è¯­è¨€-è¡ŒåŠ¨å¯¼èˆªæ¨¡å‹</h2>
<p><strong>Authors</strong>: [Zhuoyuan Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuoyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuoyuan</a> Yu), [Yuxing Long](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuxing</a> Long), [Zihan Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zihan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zihan</a> Yang), [Chengyan Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengyan</a> Zeng), [Hongwei Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongwei</a> Fan), [Jiyao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiyao</a> Zhang), [Hao Dong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hao</a> Dong)
ä½œè€…ï¼šä½™å“è¿œï¼Œé¾™å®‡æ˜Ÿï¼Œæ¨å­æ¶µï¼Œæ›¾æˆè¨€ï¼ŒèŒƒå®ä¼Ÿï¼Œå¼ ä½³å°§ï¼Œè‘£æµ©</p>
<p>Existing vision-and-language navigation models often deviate from the correct trajectory when executing instructions. However, these models lack effective error correction capability, hindering their recovery from errors. To address this challenge, we propose Self-correction Flywheel, a novel post-training paradigm. Instead of considering the model&rsquo;s error trajectories on the training set as a drawback, our paradigm emphasizes their significance as a valuable data source. We have developed a method to identify deviations in these error trajectories and devised innovative techniques to automatically generate self-correction data for perception and action. These self-correction data serve as fuel to power the model&rsquo;s continued training. The brilliance of our paradigm is revealed when we re-evaluate the model on the training set, uncovering new error trajectories. At this time, the self-correction flywheel begins to spin. Through multiple flywheel iterations, we progressively enhance our monocular RGB-based VLA navigation model CorrectNav. Experiments on R2R-CE and RxR-CE benchmarks show CorrectNav achieves new state-of-the-art success rates of 65.1% and 69.3%, surpassing prior best VLA navigation models by 8.2% and 16.4%. Real robot tests in various indoor and outdoor environments demonstrate \method&rsquo;s superior capability of error correction, dynamic obstacle avoidance, and long instruction following.
ç°æœ‰çš„è§†è§‰ä¸è¯­è¨€å¯¼èˆªæ¨¡å‹åœ¨æ‰§è¡ŒæŒ‡ä»¤æ—¶å¸¸å¸¸åç¦»æ­£ç¡®è½¨è¿¹ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ç¼ºä¹æœ‰æ•ˆçš„é”™è¯¯çº æ­£èƒ½åŠ›ï¼Œé˜»ç¢äº†å®ƒä»¬ä»é”™è¯¯ä¸­æ¢å¤ã€‚ä¸ºäº†è§£å†³è¿™ä¸€æŒ‘æˆ˜ï¼Œæˆ‘ä»¬æå‡ºäº†è‡ªæˆ‘çº æ­£é£è½®ï¼ˆSelf-correction Flywheelï¼‰ï¼Œä¸€ç§æ–°é¢–çš„åè®­ç»ƒèŒƒå¼ã€‚æˆ‘ä»¬çš„èŒƒå¼å¹¶ä¸å°†è®­ç»ƒé›†ä¸Šæ¨¡å‹çš„é”™è¯¯è½¨è¿¹è§†ä¸ºç¼ºç‚¹ï¼Œè€Œæ˜¯å¼ºè°ƒå…¶ä½œä¸ºæœ‰ä»·å€¼æ•°æ®æºçš„é‡è¦æ€§ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–¹æ³•æ¥è¯†åˆ«è¿™äº›é”™è¯¯è½¨è¿¹ä¸­çš„åç¦»ï¼Œå¹¶è®¾è®¡äº†åˆ›æ–°æŠ€æœ¯ä»¥è‡ªåŠ¨ç”Ÿæˆç”¨äºæ„ŸçŸ¥å’ŒåŠ¨ä½œçš„è‡ªæˆ‘çº æ­£æ•°æ®ã€‚è¿™äº›è‡ªæˆ‘çº æ­£æ•°æ®ä½œä¸ºç‡ƒæ–™ï¼Œé©±åŠ¨æ¨¡å‹çš„ç»§ç»­è®­ç»ƒã€‚å½“æˆ‘ä»¬åœ¨è®­ç»ƒé›†ä¸Šé‡æ–°è¯„ä¼°æ¨¡å‹å¹¶å‘ç°æ–°çš„é”™è¯¯è½¨è¿¹æ—¶ï¼Œè¿™ä¸€èŒƒå¼çš„ç²¾å¦™ä¹‹å¤„æ˜¾ç°å‡ºæ¥â€”â€”æ­¤æ—¶è‡ªæˆ‘çº æ­£é£è½®å¼€å§‹è½¬åŠ¨ã€‚é€šè¿‡å¤šæ¬¡é£è½®è¿­ä»£ï¼Œæˆ‘ä»¬é€æ­¥æå‡äº†åŸºäºå•ç›® RGB çš„è§†è§‰è¯­è¨€å¯¼èˆªæ¨¡å‹ CorrectNavã€‚ åœ¨ R2R-CE å’Œ RxR-CE åŸºå‡†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒCorrectNav å®ç°äº†æ–°çš„æœ€å…ˆè¿›æˆåŠŸç‡ï¼Œåˆ†åˆ«ä¸º 65.1% å’Œ 69.3%ï¼Œæ¯”æ­¤å‰æœ€å¥½çš„ VLA å¯¼èˆªæ¨¡å‹åˆ†åˆ«é«˜å‡º 8.2% å’Œ 16.4%ã€‚åœ¨å„ç§å®¤å†…å’Œå®¤å¤–ç¯å¢ƒä¸­çš„çœŸå®æœºå™¨äººæµ‹è¯•å±•ç¤ºäº† \method åœ¨é”™è¯¯ä¿®æ­£ã€åŠ¨æ€éšœç¢ç‰©è§„é¿å’Œæ‰§è¡Œé•¿æŒ‡ä»¤æ–¹é¢çš„å‡ºè‰²èƒ½åŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.RO"target="_blank" rel="external nofollow noopener noreferrer">Robotics</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>
ä¸»é¢˜ï¼šæœºå™¨äººå­¦ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€ã€è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«</p>
<p><strong>Publish</strong>: 2025-08-14 07:39:26 UTC
å‘å¸ƒï¼š2025-08-14 07:39:26 UTC</p>
<h2 id="85-mcp2osc-parametric-control-by-natural-language--85-mcp2oscé€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œå‚æ•°åŒ–æ§åˆ¶"><a href="https://arxiv.org/abs/2508.10414"target="_blank" rel="external nofollow noopener noreferrer">#85</a> <a href="https://papers.cool/arxiv/2508.10414"target="_blank" rel="external nofollow noopener noreferrer">MCP2OSC: Parametric Control by Natural Language</a>  #85 MCP2OSCï¼šé€šè¿‡è‡ªç„¶è¯­è¨€è¿›è¡Œå‚æ•°åŒ–æ§åˆ¶</h2>
<p><strong>Author</strong>: [Yuan-Yi Fan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuan-Yi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuan-Yi</a> Fan) ä½œè€…ï¼šèŒƒå…ƒæ¯…</p>
<p>Text prompts enable intuitive content creation but may fall short in achieving high precision for intricate tasks; knob or slider controls offer precise adjustments at the cost of increased complexity. To address the gap between knobs and prompts, a new MCP (Model Context Protocol) server and a unique set of prompt design criteria are presented to enable exploring parametric OSC (OpenSoundControl) control by natural language prompts. Demonstrated by 14 practical QA examples with best practices and the generalized prompt templates, this study finds Claude integrated with the MCP2OSC server effective in generating OSC messages by natural language, interpreting, searching, and visualizing OSC messages, validating and debugging OSC messages, and managing OSC address patterns. MCP2OSC enhances human-machine collaboration by leveraging LLM (Large Language Model) to handle intricate OSC development tasks, and by empowering human creativity with an intuitive language interface featuring flexible precision controls: a prompt-based OSC tool. This study provides a novel perspective on the creative MCP application at the network protocol level by utilizing LLM&rsquo;s strength in directly processing and generating human-readable OSC messages. The results suggest its potential for a LLM-based universal control mechanism for multimedia devices.
æ–‡æœ¬æç¤ºä½¿ç›´è§‚å†…å®¹åˆ›ä½œæˆä¸ºå¯èƒ½ï¼Œä½†åœ¨æ‰§è¡Œå¤æ‚ä»»åŠ¡æ—¶å¯èƒ½éš¾ä»¥è¾¾åˆ°é«˜ç²¾åº¦ï¼›æ—‹é’®æˆ–æ»‘å—æ§åˆ¶åˆ™èƒ½å®ç°ç²¾ç¡®è°ƒèŠ‚ï¼Œä½†ä»£ä»·æ˜¯å¢åŠ äº†å¤æ‚æ€§ã€‚ä¸ºå¼¥åˆæ—‹é’®ä¸æç¤ºä¹‹é—´çš„å·®è·ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªæ–°çš„ MCPï¼ˆModel Context Protocolï¼‰æœåŠ¡å™¨å’Œä¸€å¥—ç‹¬ç‰¹çš„æç¤ºè®¾è®¡æ ‡å‡†ï¼Œä»¥æ”¯æŒé€šè¿‡è‡ªç„¶è¯­è¨€æç¤ºæ¢ç´¢å‚æ•°åŒ– OSCï¼ˆOpenSoundControlï¼‰æ§åˆ¶ã€‚é€šè¿‡ 14 ä¸ªåŒ…å«æœ€ä½³å®è·µå’Œé€šç”¨æç¤ºæ¨¡æ¿çš„å®ç”¨é—®ç­”ç¤ºä¾‹å±•ç¤ºï¼Œæœ¬ç ”ç©¶å‘ç°å°† Claude ä¸ MCP2OSC æœåŠ¡å™¨é›†æˆï¼Œåœ¨é€šè¿‡è‡ªç„¶è¯­è¨€ç”Ÿæˆ OSC æ¶ˆæ¯ã€è§£é‡Šã€æœç´¢å’Œå¯è§†åŒ– OSC æ¶ˆæ¯ã€éªŒè¯ä¸è°ƒè¯• OSC æ¶ˆæ¯ä»¥åŠç®¡ç† OSC åœ°å€æ¨¡å¼æ–¹é¢éƒ½éå¸¸æœ‰æ•ˆã€‚MCP2OSC é€šè¿‡åˆ©ç”¨ LLMï¼ˆLarge Language Modelï¼‰å¤„ç†å¤æ‚çš„ OSC å¼€å‘ä»»åŠ¡ï¼Œå¹¶ä»¥å…·æœ‰çµæ´»ç²¾åº¦æ§åˆ¶çš„ç›´è§‚è¯­è¨€ç•Œé¢èµ‹èƒ½äººç±»åˆ›æ„ï¼Œä»è€Œå¢å¼ºäº†äººæœºåä½œï¼šä¸€ä¸ªåŸºäºæç¤ºçš„ OSC å·¥å…·ã€‚ è¿™é¡¹ç ”ç©¶é€šè¿‡åˆ©ç”¨ LLM åœ¨ç›´æ¥å¤„ç†å’Œç”Ÿæˆäººç±»å¯è¯»çš„ OSC æ¶ˆæ¯æ–¹é¢çš„ä¼˜åŠ¿ï¼Œæä¾›äº†ä¸€ä¸ªå…³äºåœ¨ç½‘ç»œåè®®å±‚é¢åº”ç”¨åˆ›æ„ MCP çš„æ–°è§†è§’ã€‚ç»“æœè¡¨æ˜å…¶ä½œä¸ºåŸºäº LLM çš„å¤šåª’ä½“è®¾å¤‡é€šç”¨æ§åˆ¶æœºåˆ¶çš„æ½œåŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">Sound</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">Audio and Speech Processing</a>
ä¸»é¢˜ï¼šäººæœºäº¤äº’ã€äººå·¥æ™ºèƒ½ã€å£°éŸ³ã€éŸ³é¢‘ä¸è¯­éŸ³å¤„ç†</p>
<p><strong>Publish</strong>: 2025-08-14 07:38:01 UTC
å‘å¸ƒï¼š2025-08-14 07:38:01 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="86-analogseeker-an-open-source-foundation-language-model-for-analog-circuit-design--86-analogseekerä¸€ä¸ªç”¨äºæ¨¡æ‹Ÿç”µè·¯è®¾è®¡çš„å¼€æºåŸºç¡€è¯­è¨€æ¨¡å‹"><a href="https://arxiv.org/abs/2508.10409"target="_blank" rel="external nofollow noopener noreferrer">#86</a> <a href="https://papers.cool/arxiv/2508.10409"target="_blank" rel="external nofollow noopener noreferrer">AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design</a>  #86 AnalogSeekerï¼šä¸€ä¸ªç”¨äºæ¨¡æ‹Ÿç”µè·¯è®¾è®¡çš„å¼€æºåŸºç¡€è¯­è¨€æ¨¡å‹</h2>
<p><strong>Authors</strong>: [Zihao Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zihao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zihao</a> Chen), [Ji Zhuang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ji</a> Zhuang), [Jinyi Shen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinyi</a> Shen), [Xiaoyue Ke](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaoyue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaoyue</a> Ke), [Xinyi Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinyi</a> Yang), [Mingjie Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mingjie</a> Zhou), [Zhuoyao Du](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuoyao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuoyao</a> Du), [Xu Yan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xu</a> Yan), [Zhouyang Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhouyang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhouyang</a> Wu), [Zhenyu Xu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhenyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhenyu</a> Xu), [Jiangli Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiangli"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiangli</a> Huang), [Li Shang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Li"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Li</a> Shang), [Xuan Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuan</a> Zeng), [Fan Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fan</a> Yang)
ä½œè€…ï¼šé™ˆå­è±ªã€åº„å‰ã€æ²ˆæ™‹æ€¡ã€æŸ¯æ™“è¶Šã€æ¨æ¬£æ€¡ã€å‘¨æ˜æ°ã€æœå“å°§ã€é—«æ—­ã€å´æ´²æ´‹ã€å¾æŒ¯å®‡ã€é»„æ±Ÿåˆ©ã€å°šåŠ›ã€æ›¾è½©ã€æ¨å¸†</p>
<p>In this paper, we propose AnalogSeeker, an effort toward an open-source foundation language model for analog circuit design, with the aim of integrating domain knowledge and giving design assistance. To overcome the scarcity of data in this field, we employ a corpus collection strategy based on the domain knowledge framework of analog circuits. High-quality, accessible textbooks across relevant subfields are systematically curated and cleaned into a textual domain corpus. To address the complexity of knowledge of analog circuits, we introduce a granular domain knowledge distillation method. Raw, unlabeled domain corpus is decomposed into typical, granular learning nodes, where a multi-agent framework distills implicit knowledge embedded in unstructured text into question-answer data pairs with detailed reasoning processes, yielding a fine-grained, learnable dataset for fine-tuning. To address the unexplored challenges in training analog circuit foundation models, we explore and share our training methods through both theoretical analysis and experimental validation. We finally establish a fine-tuning-centric training paradigm, customizing and implementing a neighborhood self-constrained supervised fine-tuning algorithm. This approach enhances training outcomes by constraining the perturbation magnitude between the model&rsquo;s output distributions before and after training. In practice, we train the Qwen2.5-32B-Instruct model to obtain AnalogSeeker, which achieves 85.04% accuracy on AMSBench-TQA, the analog circuit knowledge evaluation benchmark, with a 15.67% point improvement over the original model and is competitive with mainstream commercial models. Furthermore, AnalogSeeker also shows effectiveness in the downstream operational amplifier design task. AnalogSeeker is open-sourced at <a href="https://huggingface.co/analogllm/analogseeker"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/analogllm/analogseeker</a> for research use.
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† AnalogSeekerï¼Œä¸€é¡¹æ—¨åœ¨ä¸ºæ¨¡æ‹Ÿç”µè·¯è®¾è®¡æ„å»ºå¼€æºåŸºç¡€è¯­è¨€æ¨¡å‹çš„å·¥ä½œï¼Œç›®æ ‡æ˜¯æ•´åˆé¢†åŸŸçŸ¥è¯†å¹¶æä¾›è®¾è®¡è¾…åŠ©ã€‚ä¸ºå…‹æœè¯¥é¢†åŸŸæ•°æ®ç¨€ç¼ºçš„é—®é¢˜ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§åŸºäºæ¨¡æ‹Ÿç”µè·¯é¢†åŸŸçŸ¥è¯†æ¡†æ¶çš„è¯­æ–™æ”¶é›†ç­–ç•¥ã€‚ç³»ç»Ÿåœ°ç­–åˆ’å¹¶æ¸…æ´—äº†è·¨ç›¸å…³å­é¢†åŸŸçš„é«˜è´¨é‡ã€å¯è·å–çš„æ•™æï¼Œå°†å…¶æ•´ç†ä¸ºæ–‡æœ¬é¢†åŸŸè¯­æ–™åº“ã€‚ä¸ºåº”å¯¹æ¨¡æ‹Ÿç”µè·¯çŸ¥è¯†çš„å¤æ‚æ€§ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ç§ç»†ç²’åº¦çš„é¢†åŸŸçŸ¥è¯†è’¸é¦æ–¹æ³•ã€‚å°†åŸå§‹ã€æœªæ ‡æ³¨çš„é¢†åŸŸè¯­æ–™åˆ†è§£ä¸ºå…¸å‹çš„ã€ç»†ç²’åº¦çš„å­¦ä¹ èŠ‚ç‚¹ï¼Œåœ¨å¤šæ™ºèƒ½ä½“æ¡†æ¶ä¸‹å°†åµŒå…¥äºéç»“æ„åŒ–æ–‡æœ¬ä¸­çš„éšå«çŸ¥è¯†è’¸é¦ä¸ºå¸¦æœ‰è¯¦ç»†æ¨ç†è¿‡ç¨‹çš„é—®ç­”æ•°æ®å¯¹ï¼Œä»è€Œç”Ÿæˆç”¨äºå¾®è°ƒçš„ç»†ç²’åº¦å¯å­¦ä¹ æ•°æ®é›†ã€‚ä¸ºè§£å†³è®­ç»ƒæ¨¡æ‹Ÿç”µè·¯åŸºç¡€æ¨¡å‹ä¸­å°šæœªæ¢ç´¢çš„æŒ‘æˆ˜ï¼Œæˆ‘ä»¬é€šè¿‡ç†è®ºåˆ†æå’Œå®éªŒéªŒè¯æ¢ç´¢å¹¶åˆ†äº«äº†æˆ‘ä»¬çš„è®­ç»ƒæ–¹æ³•ã€‚ æˆ‘ä»¬æœ€ç»ˆå»ºç«‹äº†ä»¥å¾®è°ƒä¸ºä¸­å¿ƒçš„è®­ç»ƒèŒƒå¼ï¼Œå®šåˆ¶å¹¶å®ç°äº†ä¸€ç§é‚»åŸŸè‡ªçº¦æŸçš„æœ‰ç›‘ç£å¾®è°ƒç®—æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡çº¦æŸæ¨¡å‹è®­ç»ƒå‰åè¾“å‡ºåˆ†å¸ƒä¹‹é—´çš„æ‰°åŠ¨å¹…åº¦æ¥æå‡è®­ç»ƒæ•ˆæœã€‚åœ¨å®è·µä¸­ï¼Œæˆ‘ä»¬å¯¹ Qwen2.5-32B-Instruct æ¨¡å‹è¿›è¡Œè®­ç»ƒå¾—åˆ° AnalogSeekerï¼Œåœ¨æ¨¡æ‹Ÿç”µè·¯çŸ¥è¯†è¯„ä¼°åŸºå‡† AMSBench-TQA ä¸Šå–å¾—äº† 85.04% çš„å‡†ç¡®ç‡ï¼Œæ¯”åŸå§‹æ¨¡å‹æé«˜äº† 15.67 ä¸ªç™¾åˆ†ç‚¹ï¼Œå¹¶ä¸”å¯ä»¥ä¸ä¸»æµå•†ä¸šæ¨¡å‹ç›¸åª²ç¾ã€‚æ­¤å¤–ï¼ŒAnalogSeeker åœ¨ä¸‹æ¸¸çš„è¿ç®—æ”¾å¤§å™¨è®¾è®¡ä»»åŠ¡ä¸­ä¹Ÿè¡¨ç°å‡ºæœ‰æ•ˆæ€§ã€‚AnalogSeeker å·²åœ¨ <a href="https://huggingface.co/analogllm/analogseeker"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/analogllm/analogseeker</a> å¼€æºä¾›ç ”ç©¶ä½¿ç”¨ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.AR"target="_blank" rel="external nofollow noopener noreferrer">Hardware Architecture</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šç¡¬ä»¶æ¶æ„ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 07:32:07 UTC
å‘å¸ƒï¼š2025-08-14 07:32:07 UTC</p>
<h2 id="87-layer-wise-perturbations-via-sparse-autoencoders-for-adversarial-text-generation--87-é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œé€å±‚æ‰°åŠ¨ä»¥ç”¨äºå¯¹æŠ—æ€§æ–‡æœ¬ç”Ÿæˆ"><a href="https://arxiv.org/abs/2508.10404"target="_blank" rel="external nofollow noopener noreferrer">#87</a> <a href="https://papers.cool/arxiv/2508.10404"target="_blank" rel="external nofollow noopener noreferrer">Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation</a>  #87 é€šè¿‡ç¨€ç–è‡ªç¼–ç å™¨è¿›è¡Œé€å±‚æ‰°åŠ¨ä»¥ç”¨äºå¯¹æŠ—æ€§æ–‡æœ¬ç”Ÿæˆ</h2>
<p><strong>Authors</strong>: [Huizhen Shu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Huizhen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Huizhen</a> Shu), [Xuying Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xuying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xuying</a> Li), [Qirui Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qirui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qirui</a> Wang), [Yuji Kosuga](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuji"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuji</a> Kosuga), [Mengqiu Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengqiu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mengqiu</a> Tian), [Zhuo Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhuo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhuo</a> Li)
ä½œè€…ï¼šèˆ’æ…§çã€ææ—­è‹±ã€ç‹é½ç¿ã€å¤èŠæ²»ã€ç”°æ¢¦ç§‹ã€æå“</p>
<p>With the rapid proliferation of Natural Language Processing (NLP), especially Large Language Models (LLMs), generating adversarial examples to jailbreak LLMs remains a key challenge for understanding model vulnerabilities and improving robustness. In this context, we propose a new black-box attack method that leverages the interpretability of large models. We introduce the Sparse Feature Perturbation Framework (SFPF), a novel approach for adversarial text generation that utilizes sparse autoencoders to identify and manipulate critical features in text. After using the SAE model to reconstruct hidden layer representations, we perform feature clustering on the successfully attacked texts to identify features with higher activations. These highly activated features are then perturbed to generate new adversarial texts. This selective perturbation preserves the malicious intent while amplifying safety signals, thereby increasing their potential to evade existing defenses. Our method enables a new red-teaming strategy that balances adversarial effectiveness with safety alignment. Experimental results demonstrate that adversarial texts generated by SFPF can bypass state-of-the-art defense mechanisms, revealing persistent vulnerabilities in current NLP systems.However, the method&rsquo;s effectiveness varies across prompts and layers, and its generalizability to other architectures and larger models remains to be validated.
éšç€è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ï¼Œå°¤å…¶æ˜¯ LLMs çš„å¿«é€Ÿæ™®åŠï¼Œç”Ÿæˆå¯¹æŠ—æ ·æœ¬æ¥è¶Šç‹± LLMs ä»ç„¶æ˜¯ç†è§£æ¨¡å‹è„†å¼±æ€§å’Œæå‡é²æ£’æ€§çš„å…³é”®æŒ‘æˆ˜ã€‚åœ¨æ­¤èƒŒæ™¯ä¸‹ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åˆ©ç”¨å¤§æ¨¡å‹å¯è§£é‡Šæ€§çš„å…¨æ–°é»‘ç®±æ”»å‡»æ–¹æ³•ã€‚æˆ‘ä»¬å¼•å…¥äº†ç¨€ç–ç‰¹å¾æ‰°åŠ¨æ¡†æ¶ï¼ˆSFPFï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ç¨€ç–è‡ªç¼–ç å™¨è¯†åˆ«å¹¶æ“çºµæ–‡æœ¬ä¸­å…³é”®ç‰¹å¾çš„å¯¹æŠ—æ–‡æœ¬ç”Ÿæˆæ–°æ–¹æ³•ã€‚åœ¨ä½¿ç”¨ SAE æ¨¡å‹é‡æ„éšè—å±‚è¡¨ç¤ºåï¼Œæˆ‘ä»¬å¯¹æˆåŠŸæ”»å‡»çš„æ–‡æœ¬è¿›è¡Œç‰¹å¾èšç±»ï¼Œä»¥è¯†åˆ«å…·æœ‰æ›´é«˜æ¿€æ´»çš„ç‰¹å¾ã€‚éšåå¯¹è¿™äº›é«˜æ¿€æ´»ç‰¹å¾è¿›è¡Œæ‰°åŠ¨ä»¥ç”Ÿæˆæ–°çš„å¯¹æŠ—æ–‡æœ¬ã€‚è¿™ç§é€‰æ‹©æ€§æ‰°åŠ¨åœ¨ä¿ç•™æ¶æ„æ„å›¾çš„åŒæ—¶æ”¾å¤§äº†å®‰å…¨ä¿¡å·ï¼Œä»è€Œæé«˜å…¶è§„é¿ç°æœ‰é˜²æŠ¤çš„æ½œåŠ›ã€‚æˆ‘ä»¬çš„æ–¹æ³•å®ç°äº†ä¸€ç§æ–°çš„çº¢é˜Ÿç­–ç•¥ï¼Œåœ¨å¯¹æŠ—æ•ˆæœä¸å®‰å…¨å¯¹é½ä¹‹é—´å–å¾—å¹³è¡¡ã€‚ å®éªŒç»“æœè¡¨æ˜ï¼Œç”± SFPF ç”Ÿæˆçš„å¯¹æŠ—æ–‡æœ¬èƒ½å¤Ÿç»•è¿‡æœ€å…ˆè¿›çš„é˜²å¾¡æœºåˆ¶ï¼Œæš´éœ²å‡ºç°æœ‰è‡ªç„¶è¯­è¨€å¤„ç†ç³»ç»Ÿä¸­æŒç»­å­˜åœ¨çš„è„†å¼±æ€§ã€‚ç„¶è€Œï¼Œè¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§åœ¨ä¸åŒæç¤ºè¯å’Œå±‚ä¹‹é—´å­˜åœ¨å·®å¼‚ï¼Œå…¶å¯¹å…¶ä»–æ¶æ„åŠæ›´å¤§æ¨¡å‹çš„æ³›åŒ–æ€§ä»æœ‰å¾…éªŒè¯ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 07:12:44 UTC
å‘å¸ƒï¼š2025-08-14 07:12:44 UTC</p>
<h2 id="88-pq-daf-pose-driven-quality-controlled-data-augmentation-for-data-scarce-driver-distraction-detection--88-pq-dafåŸºäºå§¿æ€çš„è´¨é‡å¯æ§æ•°æ®å¢å¼ºç”¨äºæ•°æ®ç¨€ç¼ºçš„é©¾é©¶å‘˜åˆ†å¿ƒæ£€æµ‹"><a href="https://arxiv.org/abs/2508.10397"target="_blank" rel="external nofollow noopener noreferrer">#88</a> <a href="https://papers.cool/arxiv/2508.10397"target="_blank" rel="external nofollow noopener noreferrer">PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection</a>  #88 PQ-DAFï¼šåŸºäºå§¿æ€çš„è´¨é‡å¯æ§æ•°æ®å¢å¼ºç”¨äºæ•°æ®ç¨€ç¼ºçš„é©¾é©¶å‘˜åˆ†å¿ƒæ£€æµ‹</h2>
<p><strong>Authors</strong>: [Haibin Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haibin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haibin</a> Sun), [Xinghui Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinghui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinghui</a> Song)
ä½œè€…ï¼šå­™æµ·æ»¨ï¼Œå®‹å…´è¾‰</p>
<p>Driver distraction detection is essential for improving traffic safety and reducing road accidents. However, existing models often suffer from degraded generalization when deployed in real-world scenarios. This limitation primarily arises from the few-shot learning challenge caused by the high cost of data annotation in practical environments, as well as the substantial domain shift between training datasets and target deployment conditions. To address these issues, we propose a Pose-driven Quality-controlled Data Augmentation Framework (PQ-DAF) that leverages a vision-language model for sample filtering to cost-effectively expand training data and enhance cross-domain robustness. Specifically, we employ a Progressive Conditional Diffusion Model (PCDMs) to accurately capture key driver pose features and synthesize diverse training examples. A sample quality assessment module, built upon the CogVLM vision-language model, is then introduced to filter out low-quality synthetic samples based on a confidence threshold, ensuring the reliability of the augmented dataset. Extensive experiments demonstrate that PQ-DAF substantially improves performance in few-shot driver distraction detection, achieving significant gains in model generalization under data-scarce conditions.
é©¾é©¶å‘˜åˆ†å¿ƒæ£€æµ‹å¯¹äºæé«˜äº¤é€šå®‰å…¨å’Œå‡å°‘é“è·¯äº‹æ•…è‡³å…³é‡è¦ã€‚ç„¶è€Œï¼Œç°æœ‰æ¨¡å‹åœ¨å®é™…éƒ¨ç½²æ—¶ç»å¸¸å‡ºç°æ³›åŒ–èƒ½åŠ›ä¸‹é™çš„é—®é¢˜ã€‚è¿™ä¸€å±€é™ä¸»è¦æºäºå®é™…ç¯å¢ƒä¸­æ•°æ®æ ‡æ³¨æˆæœ¬é«˜å¯¼è‡´çš„å°æ ·æœ¬å­¦ä¹ æŒ‘æˆ˜ï¼Œä»¥åŠè®­ç»ƒæ•°æ®é›†ä¸ç›®æ ‡éƒ¨ç½²æ¡ä»¶ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„åŸŸåç§»ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºå§¿æ€é©±åŠ¨ä¸”åŒ…å«è´¨é‡æ§åˆ¶çš„æ•°æ®å¢å¼ºæ¡†æ¶ï¼ˆPQ-DAFï¼‰ï¼Œåˆ©ç”¨è§†è§‰-è¯­è¨€æ¨¡å‹è¿›è¡Œæ ·æœ¬ç­›é€‰ï¼Œä»¥ä½æˆæœ¬æ‰©å±•è®­ç»ƒæ•°æ®å¹¶æå‡è·¨åŸŸé²æ£’æ€§ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é‡‡ç”¨æ¸è¿›æ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼ˆPCDMsï¼‰æ¥å‡†ç¡®æ•æ‰å…³é”®é©¾é©¶å‘˜å§¿æ€ç‰¹å¾å¹¶åˆæˆå¤šæ ·çš„è®­ç»ƒæ ·æœ¬ã€‚éšåå¼•å…¥ä¸€ä¸ªåŸºäº CogVLM è§†è§‰-è¯­è¨€æ¨¡å‹çš„æ ·æœ¬è´¨é‡è¯„ä¼°æ¨¡å—ï¼Œæ ¹æ®ç½®ä¿¡åº¦é˜ˆå€¼è¿‡æ»¤ä½è´¨é‡åˆæˆæ ·æœ¬ï¼Œç¡®ä¿å¢å¼ºæ•°æ®é›†çš„å¯é æ€§ã€‚ å¤§é‡å®éªŒè¡¨æ˜ï¼ŒPQ-DAF åœ¨å°‘æ ·æœ¬é©¾é©¶åˆ†å¿ƒæ£€æµ‹ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ€§èƒ½ï¼Œåœ¨æ•°æ®ç¨€ç¼ºæ¡ä»¶ä¸‹å®ç°äº†æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„å¤§å¹…æå‡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 06:54:28 UTC
å‘å¸ƒï¼š2025-08-14 06:54:28 UTC</p>
<h2 id="89-unlocking-robust-semantic-segmentation-performance-via-label-only-elastic-deformations-against-implicit-label-noise--89-é€šè¿‡ä»…æ ‡ç­¾çš„å¼¹æ€§å½¢å˜å¯¹æŠ—éšå«æ ‡ç­¾å™ªå£°ä»¥è§£é”ç¨³å¥è¯­ä¹‰åˆ†å‰²æ€§èƒ½"><a href="https://arxiv.org/abs/2508.10383"target="_blank" rel="external nofollow noopener noreferrer">#89</a> <a href="https://papers.cool/arxiv/2508.10383"target="_blank" rel="external nofollow noopener noreferrer">Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise</a>  #89 é€šè¿‡ä»…æ ‡ç­¾çš„å¼¹æ€§å½¢å˜å¯¹æŠ—éšå«æ ‡ç­¾å™ªå£°ä»¥è§£é”ç¨³å¥è¯­ä¹‰åˆ†å‰²æ€§èƒ½</h2>
<p><strong>Authors</strong>: [Yechan Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yechan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yechan</a> Kim), [Dongho Yoon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongho</a> Yoon), [Younkwan Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Younkwan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Younkwan</a> Lee), [Unse Fatima](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Unse"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Unse</a> Fatima), [Hong Kook Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hong</a> Kook Kim), [Songjae Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Songjae"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Songjae</a> Lee), [Sanga Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sanga"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sanga</a> Park), [Jeong Ho Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jeong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jeong</a> Ho Park), [Seonjong Kang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seonjong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seonjong</a> Kang), [Moongu Jeon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Moongu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Moongu</a> Jeon)
ä½œè€…ï¼šYechan Kimã€Dongho Yoonã€Younkwan Leeã€Unse Fatimaã€Hong Kook Kimã€Songjae Leeã€Sanga Parkã€Jeong Ho Parkã€Seonjong Kangã€Moongu Jeon</p>
<p>While previous studies on image segmentation focus on handling severe (or explicit) label noise, real-world datasets also exhibit subtle (or implicit) label imperfections. These arise from inherent challenges, such as ambiguous object boundaries and annotator variability. Although not explicitly present, such mild and latent noise can still impair model performance. Typical data augmentation methods, which apply identical transformations to the image and its label, risk amplifying these subtle imperfections and limiting the model&rsquo;s generalization capacity. In this paper, we introduce NSegment+, a novel augmentation framework that decouples image and label transformations to address such realistic noise for semantic segmentation. By introducing controlled elastic deformations only to segmentation labels while preserving the original images, our method encourages models to focus on learning robust representations of object structures despite minor label inconsistencies. Extensive experiments demonstrate that NSegment+ consistently improves performance, achieving mIoU gains of up to +2.29, +2.38, +1.75, and +3.39 in average on Vaihingen, LoveDA, Cityscapes, and PASCAL VOC, respectively-even without bells and whistles, highlighting the importance of addressing implicit label noise. These gains can be further amplified when combined with other training tricks, including CutMix and Label Smoothing.
ä»¥å¾€å…³äºå›¾åƒåˆ†å‰²çš„ç ”ç©¶å¤šé›†ä¸­äºå¤„ç†ä¸¥é‡ï¼ˆæˆ–æ˜æ˜¾ï¼‰çš„æ ‡ç­¾å™ªå£°ï¼Œè€Œç°å®ä¸–ç•Œçš„æ•°æ®é›†ä¹Ÿå­˜åœ¨å¾®å¦™ï¼ˆæˆ–éšæ€§ï¼‰çš„æ ‡ç­¾ä¸å®Œç¾ã€‚è¿™äº›é—®é¢˜æºè‡ªå†…åœ¨æŒ‘æˆ˜ï¼Œä¾‹å¦‚æ¨¡ç³Šçš„ç‰©ä½“è¾¹ç•Œå’Œæ ‡æ³¨è€…çš„å·®å¼‚ã€‚å³ä¾¿å¹¶éæ˜¾æ€§å­˜åœ¨ï¼Œè¿™ç±»è½»å¾®ä¸”æ½œåœ¨çš„å™ªå£°ä»å¯èƒ½æŸå®³æ¨¡å‹æ€§èƒ½ã€‚å…¸å‹çš„æ•°æ®å¢å¼ºæ–¹æ³•å¯¹å›¾åƒåŠå…¶æ ‡ç­¾æ–½åŠ ç›¸åŒçš„å˜æ¢ï¼Œå¯èƒ½ä¼šæ”¾å¤§è¿™äº›å¾®å¦™çš„ä¸å®Œå–„ï¼Œä»è€Œé™åˆ¶æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† NSegment+ï¼Œä¸€ç§æ–°é¢–çš„å¢å¼ºæ¡†æ¶ï¼Œé€šè¿‡è§£è€¦å›¾åƒä¸æ ‡ç­¾çš„å˜æ¢æ¥åº”å¯¹è¯­ä¹‰åˆ†å‰²ä¸­çš„æ­¤ç±»ç°å®å™ªå£°ã€‚æˆ‘ä»¬ä»…å¯¹åˆ†å‰²æ ‡ç­¾æ–½åŠ å¯æ§çš„å¼¹æ€§å½¢å˜ï¼ŒåŒæ—¶ä¿æŒåŸå§‹å›¾åƒä¸å˜ï¼Œä¿ƒä½¿æ¨¡å‹åœ¨å­˜åœ¨è½»å¾®æ ‡ç­¾ä¸ä¸€è‡´æ—¶ä»ä¸“æ³¨äºå­¦ä¹ ç‰©ä½“ç»“æ„çš„é²æ£’è¡¨å¾ã€‚ å¤§é‡å®éªŒè¯æ˜ï¼ŒNSegment+ å§‹ç»ˆèƒ½æå‡æ€§èƒ½ï¼Œåœ¨ Vaihingenã€LoveDAã€Cityscapes å’Œ PASCAL VOC ä¸Šå¹³å‡åˆ†åˆ«å¸¦æ¥é«˜è¾¾ +2.29ã€+2.38ã€+1.75 å’Œ +3.39 çš„ mIoU å¢ç›Šâ€”â€”å³ä¾¿æ²¡æœ‰ä»»ä½•èŠ±å“¨æŠ€å·§ï¼Œè¿™ä¹Ÿå‡¸æ˜¾äº†è§£å†³éšå«æ ‡ç­¾å™ªå£°çš„é‡è¦æ€§ã€‚ç»“åˆå…¶ä»–è®­ç»ƒæŠ€å·§ï¼ˆåŒ…æ‹¬ CutMix å’Œ æ ‡ç­¾å¹³æ»‘ï¼‰æ—¶ï¼Œè¿™äº›å¢ç›Šè¿˜å¯ä»¥è¿›ä¸€æ­¥æ”¾å¤§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 06:27:43 UTC
å‘å¸ƒï¼š2025-08-14 06:27:43 UTC</p>
<h2 id="90-emamba-efficient-acceleration-framework-for-mamba-models-in-edge-computing--90-emambaé¢å‘è¾¹ç¼˜è®¡ç®—çš„-mamba-æ¨¡å‹é«˜æ•ˆåŠ é€Ÿæ¡†æ¶"><a href="https://arxiv.org/abs/2508.10370"target="_blank" rel="external nofollow noopener noreferrer">#90</a> <a href="https://papers.cool/arxiv/2508.10370"target="_blank" rel="external nofollow noopener noreferrer">eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing</a>  #90 eMambaï¼šé¢å‘è¾¹ç¼˜è®¡ç®—çš„ Mamba æ¨¡å‹é«˜æ•ˆåŠ é€Ÿæ¡†æ¶</h2>
<p><strong>Authors</strong>: [Jiyong Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiyong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiyong</a> Kim), [Jaeho Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jaeho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jaeho</a> Lee), [Jiahao Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiahao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiahao</a> Lin), [Alish Kanani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alish"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alish</a> Kanani), [Miao Sun](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Miao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Miao</a> Sun), [Umit Y. Ogras](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Umit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Umit</a> Y. Ogras), [Jaehyun Park](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jaehyun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jaehyun</a> Park)
ä½œè€…ï¼šJiyong Kimã€Jaeho Leeã€Jiahao Linã€Alish Kananiã€Miao Sunã€Umit Y. Ograsã€Jaehyun Park</p>
<p>State Space Model (SSM)-based machine learning architectures have recently gained significant attention for processing sequential data. Mamba, a recent sequence-to-sequence SSM, offers competitive accuracy with superior computational efficiency compared to state-of-the-art transformer models. While this advantage makes Mamba particularly promising for resource-constrained edge devices, no hardware acceleration frameworks are currently optimized for deploying it in such environments. This paper presents eMamba, a comprehensive end-to-end hardware acceleration framework explicitly designed for deploying Mamba models on edge platforms. eMamba maximizes computational efficiency by replacing complex normalization layers with lightweight hardware-aware alternatives and approximating expensive operations, such as SiLU activation and exponentiation, considering the target applications. Then, it performs an approximation-aware neural architecture search (NAS) to tune the learnable parameters used during approximation. Evaluations with Fashion-MNIST, CIFAR-10, and MARS, an open-source human pose estimation dataset, show eMamba achieves comparable accuracy to state-of-the-art techniques using 1.63-19.9Ã— fewer parameters. In addition, it generalizes well to large-scale natural language tasks, demonstrating stable perplexity across varying sequence lengths on the WikiText2 dataset. We also quantize and implement the entire eMamba pipeline on an AMD ZCU102 FPGA and ASIC using GlobalFoundries (GF) 22 nm technology. Experimental results show 4.95-5.62Ã— lower latency and 2.22-9.95Ã— higher throughput, with 4.77Ã— smaller area, 9.84Ã— lower power, and 48.6Ã— lower energy consumption than baseline solutions while maintaining competitive accuracy.
åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰çš„æœºå™¨å­¦ä¹ æ¶æ„è¿‘å¹´æ¥åœ¨å¤„ç†åºåˆ—æ•°æ®æ–¹é¢å—åˆ°å¹¿æ³›å…³æ³¨ã€‚Mamba æ˜¯ä¸€ç§æ–°è¿‘çš„åºåˆ—åˆ°åºåˆ— SSMï¼Œä¸æœ€å…ˆè¿›çš„ Transformer æ¨¡å‹ç›¸æ¯”ï¼Œåœ¨è®¡ç®—æ•ˆç‡ä¸Šå…·æœ‰ä¼˜åŠ¿ä¸”ç²¾åº¦å…·æœ‰ç«äº‰åŠ›ã€‚è™½ç„¶è¿™ä¸€ä¼˜åŠ¿ä½¿å¾— Mamba å¯¹èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡å°¤ä¸ºæœ‰å‰æ™¯ï¼Œä½†ç›®å‰å°šæ— ä¸ºåœ¨æ­¤ç±»ç¯å¢ƒä¸­éƒ¨ç½²å®ƒè€Œä¼˜åŒ–çš„ç¡¬ä»¶åŠ é€Ÿæ¡†æ¶ã€‚æœ¬æ–‡æå‡ºäº† eMambaï¼Œä¸€ä¸ªä¸“ä¸ºåœ¨è¾¹ç¼˜å¹³å°ä¸Šéƒ¨ç½² Mamba æ¨¡å‹è€Œè®¾è®¡çš„ç«¯åˆ°ç«¯ç¡¬ä»¶åŠ é€Ÿæ¡†æ¶ã€‚eMamba é€šè¿‡ç”¨è½»é‡ä¸”ç¡¬ä»¶æ„ŸçŸ¥çš„æ›¿ä»£æ–¹æ¡ˆæ›¿æ¢å¤æ‚çš„å½’ä¸€åŒ–å±‚å¹¶å¯¹å¦‚ SiLU æ¿€æ´»å’ŒæŒ‡æ•°è¿ç®—ç­‰é«˜å¼€é”€æ“ä½œè¿›è¡Œè¿‘ä¼¼ï¼ˆè€ƒè™‘ç›®æ ‡åº”ç”¨ï¼‰ï¼Œä»¥æœ€å¤§åŒ–è®¡ç®—æ•ˆç‡ã€‚éšåï¼Œå®ƒæ‰§è¡Œä¸€ä¸ªè€ƒè™‘è¿‘ä¼¼è¯¯å·®çš„ç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰ï¼Œä»¥è°ƒæ•´åœ¨è¿‘ä¼¼è¿‡ç¨‹ä¸­ä½¿ç”¨çš„å¯å­¦ä¹ å‚æ•°ã€‚ åœ¨ Fashion-MNISTã€CIFAR-10 å’Œå¼€æºäººä½“å§¿æ€ä¼°è®¡æ•°æ®é›† MARS ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼ŒeMamba åœ¨å‡†ç¡®æ€§ä¸Šå¯ä¸æœ€å…ˆè¿›æŠ€æœ¯ç›¸åª²ç¾ï¼Œä½†å‚æ•°æ•°é‡å‡å°‘äº† 1.63â€“19.9 Ã— ã€‚æ­¤å¤–ï¼Œå®ƒåœ¨å¤§è§„æ¨¡è‡ªç„¶è¯­è¨€ä»»åŠ¡ä¸Šä¹Ÿå…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨ WikiText2 æ•°æ®é›†ä¸Šå¯¹ä¸åŒåºåˆ—é•¿åº¦è¡¨ç°å‡ºç¨³å®šçš„å›°æƒ‘åº¦ã€‚æˆ‘ä»¬è¿˜å¯¹æ•´ä¸ª eMamba æµæ°´çº¿åœ¨ AMD ZCU102 FPGA å’Œä½¿ç”¨ GlobalFoundries (GF) 22 nm å·¥è‰ºçš„ ASIC ä¸Šè¿›è¡Œäº†é‡åŒ–å’Œå®ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŸºçº¿è§£å†³æ–¹æ¡ˆç›¸æ¯”ï¼Œåœ¨ä¿æŒç«äº‰æ€§å‡†ç¡®ç‡çš„åŒæ—¶ï¼Œå»¶è¿Ÿé™ä½äº† 4.95â€“5.62 Ã— ï¼Œååé‡æé«˜äº† 2.22â€“9.95 Ã— ï¼Œé¢ç§¯å‡å°äº† 4.77 Ã— ï¼ŒåŠŸè€—é™ä½äº† 9.84 Ã— ï¼Œèƒ½è€—é™ä½äº† 48.6 Ã— ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 06:08:05 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 06:08:05 UTC</p>
<h2 id="91-welfare-centric-clustering--91-ä»¥ç¦åˆ©ä¸ºä¸­å¿ƒçš„èšç±»"><a href="https://arxiv.org/abs/2508.10345"target="_blank" rel="external nofollow noopener noreferrer">#91</a> <a href="https://papers.cool/arxiv/2508.10345"target="_blank" rel="external nofollow noopener noreferrer">Welfare-Centric Clustering</a>  #91 ä»¥ç¦åˆ©ä¸ºä¸­å¿ƒçš„èšç±»</h2>
<p><strong>Authors</strong>: [Claire Jie Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Claire"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Claire</a> Jie Zhang), [Seyed A. Esmaeili](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seyed"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seyed</a> A. Esmaeili), [Jamie Morgenstern](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jamie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jamie</a> Morgenstern)
ä½œè€…ï¼šClaire Jie Zhangã€Seyed A. Esmaeiliã€Jamie Morgenstern</p>
<p>Fair clustering has traditionally focused on ensuring equitable group representation or equalizing group-specific clustering costs. However, Dickerson et al. (2025) recently showed that these fairness notions may yield undesirable or unintuitive clustering outcomes and advocated for a welfare-centric clustering approach that models the utilities of the groups. In this work, we model group utilities based on both distances and proportional representation and formalize two optimization objectives based on welfare-centric clustering: the Rawlsian (Egalitarian) objective and the Utilitarian objective. We introduce novel algorithms for both objectives and prove theoretical guarantees for them. Empirical evaluations on multiple real-world datasets demonstrate that our methods significantly outperform existing fair clustering baselines.
å…¬å¹³èšç±»ä¼ ç»Ÿä¸Šä¾§é‡äºç¡®ä¿ç¾¤ä½“ä»£è¡¨æ€§çš„å…¬å¹³æˆ–å¹³è¡¡ç¾¤ä½“ç‰¹å®šçš„èšç±»ä»£ä»·ã€‚ç„¶è€Œï¼ŒDickerson ç­‰äººï¼ˆ2025ï¼‰æœ€è¿‘è¡¨æ˜ï¼Œè¿™äº›å…¬å¹³æ€§æ¦‚å¿µå¯èƒ½å¯¼è‡´ä¸è‰¯æˆ–ä¸åˆç›´è§‰çš„èšç±»ç»“æœï¼Œå¹¶å€¡å¯¼ä¸€ç§ä»¥ç¦åˆ©ä¸ºä¸­å¿ƒçš„èšç±»æ–¹æ³•æ¥å¯¹ç¾¤ä½“çš„æ•ˆç”¨è¿›è¡Œå»ºæ¨¡ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬åŸºäºè·ç¦»å’Œæ¯”ä¾‹ä»£è¡¨æ€§å¯¹ç¾¤ä½“æ•ˆç”¨è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶å°†ä¸¤ç§ä»¥ç¦åˆ©ä¸ºä¸­å¿ƒçš„èšç±»ä¼˜åŒ–ç›®æ ‡å½¢å¼åŒ–ï¼šç½—å°”æ–¯å¼ï¼ˆå¹³ç­‰ä¸»ä¹‰ï¼‰ç›®æ ‡å’ŒåŠŸåˆ©ä¸»ä¹‰ç›®æ ‡ã€‚æˆ‘ä»¬ä¸ºä¸¤ç§ç›®æ ‡å¼•å…¥äº†æ–°ç®—æ³•å¹¶è¯æ˜äº†å®ƒä»¬çš„ç†è®ºä¿è¯ã€‚åœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®è¯è¯„ä¼°è¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…¬å¹³èšç±»åŸºçº¿ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">Computers and Society</a>, <a href="https://papers.cool/arxiv/cs.DS"target="_blank" rel="external nofollow noopener noreferrer">Data Structures and Algorithms</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹  ï¼Œ äººå·¥æ™ºèƒ½ ï¼Œ è®¡ç®—æœºä¸ç¤¾ä¼š ï¼Œ æ•°æ®ç»“æ„ä¸ç®—æ³•</p>
<p><strong>Publish</strong>: 2025-08-14 05:02:32 UTC
å‘å¸ƒï¼š2025-08-14 05:02:32 UTC</p>
<h2 id="92-layer-wise-analysis-of-self-supervised-representations-for-age-and-gender-classification-in-children39s-speech--92-é¢å‘å„¿ç«¥è¯­éŸ³å¹´é¾„å’Œæ€§åˆ«åˆ†ç±»çš„è‡ªç›‘ç£è¡¨ç¤ºçš„é€å±‚åˆ†æ"><a href="https://arxiv.org/abs/2508.10332"target="_blank" rel="external nofollow noopener noreferrer">#92</a> <a href="https://papers.cool/arxiv/2508.10332"target="_blank" rel="external nofollow noopener noreferrer">Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech</a>  #92 é¢å‘å„¿ç«¥è¯­éŸ³å¹´é¾„å’Œæ€§åˆ«åˆ†ç±»çš„è‡ªç›‘ç£è¡¨ç¤ºçš„é€å±‚åˆ†æ</h2>
<p><strong>Authors</strong>: [Abhijit Sinha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abhijit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abhijit</a> Sinha), [Harishankar Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Harishankar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Harishankar</a> Kumar), [Mohit Joshi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohit</a> Joshi), [Hemant Kumar Kathania](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hemant"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hemant</a> Kumar Kathania), [Shrikanth Narayanan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shrikanth"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shrikanth</a> Narayanan), [Sudarsana Reddy Kadiri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sudarsana"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sudarsana</a> Reddy Kadiri)
ä½œè€…ï¼šAbhijit Sinhaã€Harishankar Kumarã€Mohit Joshiã€Hemant Kumar Kathaniaã€Shrikanth Narayananã€Sudarsana Reddy Kadiri</p>
<p>Children&rsquo;s speech presents challenges for age and gender classification due to high variability in pitch, articulation, and developmental traits. While self-supervised learning (SSL) models perform well on adult speech tasks, their ability to encode speaker traits in children remains underexplored. This paper presents a detailed layer-wise analysis of four Wav2Vec2 variants using the PFSTAR and CMU Kids datasets. Results show that early layers (1-7) capture speaker-specific cues more effectively than deeper layers, which increasingly focus on linguistic information. Applying PCA further improves classification, reducing redundancy and highlighting the most informative components. The Wav2Vec2-large-lv60 model achieves 97.14% (age) and 98.20% (gender) on CMU Kids; base-100h and large-lv60 models reach 86.05% and 95.00% on PFSTAR. These results reveal how speaker traits are structured across SSL model depth and support more targeted, adaptive strategies for child-aware speech interfaces.
å„¿ç«¥è¯­éŸ³åœ¨éŸ³é«˜ã€å‘éŸ³å’Œå‘è‚²ç‰¹å¾ä¸Šé«˜åº¦å¯å˜ï¼Œä»è€Œç»™å¹´é¾„å’Œæ€§åˆ«åˆ†ç±»å¸¦æ¥æŒ‘æˆ˜ã€‚å°½ç®¡è‡ªç›‘ç£å­¦ä¹ ï¼ˆSSLï¼‰æ¨¡å‹åœ¨æˆäººè¯­éŸ³ä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½ï¼Œä½†å®ƒä»¬åœ¨ç¼–ç å„¿ç«¥è¯´è¯è€…ç‰¹å¾æ–¹é¢çš„èƒ½åŠ›ä»æœªå¾—åˆ°å……åˆ†æ¢ç´¢ã€‚æœ¬æ–‡å¯¹å››ç§ Wav2Vec2 å˜ä½“åœ¨ PFSTAR å’Œ CMU Kids æ•°æ®é›†ä¸Šè¿›è¡Œäº†è¯¦ç»†çš„åˆ†å±‚åˆ†æã€‚ç»“æœæ˜¾ç¤ºï¼Œè¾ƒæµ…çš„å±‚ï¼ˆ1â€“7ï¼‰æ¯”æ›´æ·±çš„å±‚æ›´æœ‰æ•ˆåœ°æ•æ‰è¯´è¯è€…ç‰¹å®šçº¿ç´¢ï¼Œè€Œæ›´æ·±çš„å±‚åˆ™è¶Šæ¥è¶Šå…³æ³¨è¯­è¨€ä¿¡æ¯ã€‚åº”ç”¨ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰è¿›ä¸€æ­¥æ”¹å–„äº†åˆ†ç±»ï¼Œå‡å°‘äº†å†—ä½™å¹¶çªå‡ºäº†æœ€å…·ä¿¡æ¯é‡çš„æˆåˆ†ã€‚Wav2Vec2-large-lv60 æ¨¡å‹åœ¨ CMU Kids ä¸Šåˆ†åˆ«è¾¾åˆ°äº† 97.14%ï¼ˆå¹´é¾„ï¼‰å’Œ 98.20%ï¼ˆæ€§åˆ«ï¼‰ï¼›base-100h å’Œ large-lv60 æ¨¡å‹åœ¨ PFSTAR ä¸Šåˆ†åˆ«è¾¾åˆ°äº† 86.05% å’Œ 95.00%ã€‚è¿™äº›ç»“æœæ­ç¤ºäº†è¯´è¯è€…ç‰¹å¾åœ¨è‡ªç›‘ç£æ¨¡å‹æ·±åº¦ä¸Šçš„ç»“æ„åˆ†å¸ƒï¼Œå¹¶æ”¯æŒä¸ºå„¿ç«¥æ„ŸçŸ¥çš„è¯­éŸ³ç•Œé¢åˆ¶å®šæ›´æœ‰é’ˆå¯¹æ€§ã€å¯è‡ªé€‚åº”çš„ç­–ç•¥ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">Audio and Speech Processing</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">Sound</a>
ä¸»é¢˜ï¼šéŸ³é¢‘ä¸è¯­éŸ³å¤„ç†ã€äººå·¥æ™ºèƒ½ã€äººæœºäº¤äº’ã€æœºå™¨å­¦ä¹ ã€å£°éŸ³</p>
<p><strong>Publish</strong>: 2025-08-14 04:11:44 UTC
å‘å¸ƒï¼š2025-08-14 04:11:44 UTC</p>
<h2 id="93-a-vision-language-pre-training-model-guided-approach-for-mitigating-backdoor-attacks-in-federated-learning--93-ä¸€ç§ç”±è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹æŒ‡å¯¼çš„è”é‚¦å­¦ä¹ åé—¨æ”»å‡»ç¼“è§£æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10315"target="_blank" rel="external nofollow noopener noreferrer">#93</a> <a href="https://papers.cool/arxiv/2508.10315"target="_blank" rel="external nofollow noopener noreferrer">A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning</a>  #93 ä¸€ç§ç”±è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹æŒ‡å¯¼çš„è”é‚¦å­¦ä¹ åé—¨æ”»å‡»ç¼“è§£æ–¹æ³•</h2>
<p><strong>Authors</strong>: [Keke Gai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keke"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keke</a> Gai), [Dongjue Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dongjue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dongjue</a> Wang), [Jing Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jing</a> Yu), [Liehuang Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Liehuang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Liehuang</a> Zhu), [Qi Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qi</a> Wu)
ä½œè€…ï¼šKeke Gaiã€Dongjue Wangã€Jing Yuã€Liehuang Zhuã€Qi Wu</p>
<p>Existing backdoor defense methods in Federated Learning (FL) rely on the assumption of homogeneous client data distributions or the availability of a clean serve dataset, which limits the practicality and effectiveness. Defending against backdoor attacks under heterogeneous client data distributions while preserving model performance remains a significant challenge. In this paper, we propose a FL backdoor defense framework named CLIP-Fed, which leverages the zero-shot learning capabilities of vision-language pre-training models. By integrating both pre-aggregation and post-aggregation defense strategies, CLIP-Fed overcomes the limitations of Non-IID imposed on defense effectiveness. To address privacy concerns and enhance the coverage of the dataset against diverse triggers, we construct and augment the server dataset using the multimodal large language model and frequency analysis without any client samples. To address class prototype deviations caused by backdoor samples and eliminate the correlation between trigger patterns and target labels, CLIP-Fed aligns the knowledge of the global model and CLIP on the augmented dataset using prototype contrastive loss and Kullback-Leibler divergence. Extensive experiments on representative datasets validate the effectiveness of CLIP-Fed. Compared to state-of-the-art methods, CLIP-Fed achieves an average reduction in ASR, i.e., 2.03% on CIFAR-10 and 1.35% on CIFAR-10-LT, while improving average MA by 7.92% and 0.48%, respectively.
ç°æœ‰çš„è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰åé—¨é˜²å¾¡æ–¹æ³•ä¾èµ–äºå®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒåŒè´¨æ€§æˆ–å¯ç”¨çš„å¹²å‡€æœåŠ¡å™¨æ•°æ®é›†çš„å‡è®¾ï¼Œè¿™é™åˆ¶äº†å…¶å®ç”¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚åœ¨ä¿æŒæ¨¡å‹æ€§èƒ½çš„åŒæ—¶ï¼Œåœ¨å¼‚æ„å®¢æˆ·ç«¯æ•°æ®åˆ†å¸ƒä¸‹é˜²å¾¡åé—¨æ”»å‡»ä»ç„¶æ˜¯ä¸€ä¸ªé‡å¤§æŒ‘æˆ˜ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªåä¸º CLIP-Fed çš„ FL åé—¨é˜²å¾¡æ¡†æ¶ï¼Œè¯¥æ¡†æ¶åˆ©ç”¨è§†è§‰-è¯­è¨€é¢„è®­ç»ƒæ¨¡å‹çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›ã€‚é€šè¿‡ç»“åˆèšåˆå‰å’Œèšåˆåä¸¤ç§é˜²å¾¡ç­–ç•¥ï¼ŒCLIP-Fed å…‹æœäº†éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆNon-IIDï¼‰å¯¹é˜²å¾¡æ•ˆæœçš„é™åˆ¶ã€‚ä¸ºäº†è§£å†³éšç§é—®é¢˜å¹¶å¢å¼ºæœåŠ¡å™¨æ•°æ®é›†å¯¹å¤šæ ·è§¦å‘å™¨çš„è¦†ç›–ï¼Œæˆ‘ä»¬åœ¨ä¸ä½¿ç”¨ä»»ä½•å®¢æˆ·ç«¯æ ·æœ¬çš„æƒ…å†µä¸‹ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹å’Œé¢‘ç‡åˆ†ææ„å»ºå¹¶æ‰©å……äº†æœåŠ¡å™¨æ•°æ®é›†ã€‚ ä¸ºäº†è§£å†³ç”±åé—¨æ ·æœ¬å¯¼è‡´çš„ç±»åˆ«åŸå‹åç§»å¹¶æ¶ˆé™¤è§¦å‘æ¨¡å¼ä¸ç›®æ ‡æ ‡ç­¾ä¹‹é—´çš„ç›¸å…³æ€§ï¼ŒCLIP-Fed åœ¨å¢å¼ºæ•°æ®é›†ä¸Šä½¿ç”¨åŸå‹å¯¹æ¯”æŸå¤±å’Œ Kullback-Leibler æ•£åº¦å¯¹å…¨å±€æ¨¡å‹ä¸ CLIP çš„çŸ¥è¯†è¿›è¡Œå¯¹é½ã€‚å¤§é‡åœ¨ä»£è¡¨æ€§æ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯äº† CLIP-Fed çš„æœ‰æ•ˆæ€§ã€‚ä¸æœ€å…ˆè¿›çš„æ–¹æ³•ç›¸æ¯”ï¼ŒCLIP-Fed åœ¨ ASR ä¸Šå®ç°äº†å¹³å‡é™ä½ï¼Œå³åœ¨ CIFAR-10 ä¸Šé™ä½ 2.03%ï¼Œåœ¨ CIFAR-10-LT ä¸Šé™ä½ 1.35%ï¼ŒåŒæ—¶åˆ†åˆ«å°†å¹³å‡ MA æé«˜äº† 7.92% å’Œ 0.48%ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 03:39:54 UTC
å‘å¸ƒï¼š2025-08-14 03:39:54 UTC</p>
<h2 id="94-reviewrl-towards-automated-scientific-review-with-rl--94-reviewrlè¿ˆå‘ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç§‘å­¦è¯„å®¡"><a href="https://arxiv.org/abs/2508.10308"target="_blank" rel="external nofollow noopener noreferrer">#94</a> <a href="https://papers.cool/arxiv/2508.10308"target="_blank" rel="external nofollow noopener noreferrer">ReviewRL: Towards Automated Scientific Review with RL</a>  #94 ReviewRLï¼šè¿ˆå‘ä½¿ç”¨å¼ºåŒ–å­¦ä¹ çš„è‡ªåŠ¨åŒ–ç§‘å­¦è¯„å®¡</h2>
<p><strong>Authors</strong>: [Sihang Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sihang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sihang</a> Zeng), [Kai Tian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Tian), [Kaiyan Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaiyan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaiyan</a> Zhang), [Yuru wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuru"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuru</a> wang), [Junqi Gao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junqi</a> Gao), [Runze Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Runze"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Runze</a> Liu), [Sa Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sa</a> Yang), [Jingxuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingxuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingxuan</a> Li), [Xinwei Long](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xinwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xinwei</a> Long), [Jiaheng Ma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaheng</a> Ma), [Biqing Qi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Biqing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Biqing</a> Qi), [Bowen Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bowen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bowen</a> Zhou)
ä½œè€…ï¼šæ›¾æ€èˆªã€ç”°å‡¯ã€å¼ å‡¯å²©ã€ç‹é›¨èŒ¹ã€é«˜ä¿Šçªã€åˆ˜æ¶¦æ³½ã€æ¨è¨ã€æé–è½©ã€é¾™æ–°ä¸ºã€é©¬ä½³è¡¡ã€é½ç¢§é’ã€å‘¨åšæ–‡</p>
<p>Peer review is essential for scientific progress but faces growing challenges due to increasing submission volumes and reviewer fatigue. Existing automated review approaches struggle with factual accuracy, rating consistency, and analytical depth, often generating superficial or generic feedback lacking the insights characteristic of high-quality human reviews. We introduce ReviewRL, a reinforcement learning framework for generating comprehensive and factually grounded scientific paper reviews. Our approach combines: (1) an ArXiv-MCP retrieval-augmented context generation pipeline that incorporates relevant scientific literature, (2) supervised fine-tuning that establishes foundational reviewing capabilities, and (3) a reinforcement learning procedure with a composite reward function that jointly enhances review quality and rating accuracy. Experiments on ICLR 2025 papers demonstrate that ReviewRL significantly outperforms existing methods across both rule-based metrics and model-based quality assessments. ReviewRL establishes a foundational framework for RL-driven automatic critique generation in scientific discovery, demonstrating promising potential for future development in this domain. The implementation of ReviewRL will be released at GitHub.
åŒè¡Œè¯„å®¡å¯¹äºç§‘å­¦è¿›æ­¥è‡³å…³é‡è¦ï¼Œä½†ç”±äºæŠ•ç¨¿æ•°é‡å¢åŠ å’Œå®¡ç¨¿äººç–²åŠ³ï¼Œé¢ä¸´æ—¥ç›Šä¸¥å³»çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„è‡ªåŠ¨å®¡ç¨¿æ–¹æ³•åœ¨äº‹å®å‡†ç¡®æ€§ã€è¯„åˆ†ä¸€è‡´æ€§å’Œåˆ†ææ·±åº¦æ–¹é¢å­˜åœ¨å›°éš¾ï¼Œå¸¸å¸¸ç”Ÿæˆç¼ºä¹é«˜è´¨é‡äººå·¥è¯„å®¡ç‰¹æœ‰è§è§£çš„è‚¤æµ…æˆ–é€šç”¨åé¦ˆã€‚æˆ‘ä»¬æå‡ºäº† ReviewRLï¼Œä¸€ç§ç”¨äºç”Ÿæˆå…¨é¢ä¸”äº‹å®æœ‰æ®çš„ç§‘å­¦è®ºæ–‡è¯„å®¡çš„å¼ºåŒ–å­¦ä¹ æ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆäº†ï¼š(1) ä¸€ä¸ª ArXiv-MCP æ£€ç´¢å¢å¼ºçš„ä¸Šä¸‹æ–‡ç”Ÿæˆç®¡é“ï¼Œçº³å…¥ç›¸å…³çš„ç§‘å­¦æ–‡çŒ®ï¼Œ(2) å»ºç«‹åŸºç¡€å®¡ç¨¿èƒ½åŠ›çš„ç›‘ç£å¾®è°ƒï¼Œä»¥åŠ (3) å…·æœ‰å¤åˆå¥–åŠ±å‡½æ•°çš„å¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œèƒ½å¤Ÿå…±åŒæå‡è¯„å®¡è´¨é‡å’Œè¯„åˆ†å‡†ç¡®æ€§ã€‚åœ¨ ICLR 2025 è®ºæ–‡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒReviewRL åœ¨åŸºäºè§„åˆ™çš„æŒ‡æ ‡å’ŒåŸºäºæ¨¡å‹çš„è´¨é‡è¯„ä¼°ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ã€‚ ReviewRL ä¸ºåœ¨ç§‘å­¦å‘ç°ä¸­ç”±å¼ºåŒ–å­¦ä¹ é©±åŠ¨çš„è‡ªåŠ¨è¯„è®ºç”Ÿæˆå»ºç«‹äº†åŸºç¡€æ¡†æ¶ï¼Œå±•ç¤ºäº†è¯¥é¢†åŸŸæœªæ¥å‘å±•çš„è‰¯å¥½æ½œåŠ›ã€‚ReviewRL çš„å®ç°å°†åœ¨ GitHub ä¸Šå‘å¸ƒã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 03:26:13 UTC
å‘å¸ƒï¼š2025-08-14 03:26:13 UTC</p>
<h2 id="95-yet-another-algorithmic-bias-a-discursive-analysis-of-large-language-models-reinforcing-dominant-discourses-on-gender-and-race--95-åˆä¸€ä¾‹ç®—æ³•åè§å¯¹å¤§å‹è¯­è¨€æ¨¡å‹åŠ å¼ºå…³äºæ€§åˆ«ä¸ç§æ—æ”¯é…æ€§è¯è¯­çš„è®ºè¿°åˆ†æ-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10304"target="_blank" rel="external nofollow noopener noreferrer">#95</a> <a href="https://papers.cool/arxiv/2508.10304"target="_blank" rel="external nofollow noopener noreferrer">Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race</a>  #95 åˆä¸€ä¾‹ç®—æ³•åè§ï¼šå¯¹å¤§å‹è¯­è¨€æ¨¡å‹åŠ å¼ºå…³äºæ€§åˆ«ä¸ç§æ—æ”¯é…æ€§è¯è¯­çš„è®ºè¿°åˆ†æ [PDF ] [Copy] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [Gustavo Bonil](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gustavo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gustavo</a> Bonil), [Simone Hashiguti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Simone"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Simone</a> Hashiguti), [Jhessica Silva](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jhessica"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jhessica</a> Silva), [JoÃ£o Gondim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jo</a>Ã£o Gondim), [Helena Maia](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helena</a> Maia), [NÃ¡dia Silva](<a href="https://arxiv.org/search/?searchtype=author&amp;query=N"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=N</a>Ã¡dia Silva), [Helio Pedrini](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Helio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Helio</a> Pedrini), [Sandra Avila](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sandra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sandra</a> Avila)
ä½œè€…ï¼šGustavo Bonil, Simone Hashiguti, Jhessica Silva, JoÃ£o Gondim, Helena Maia, NÃ¡dia Silva, Helio Pedrini, Sandra Avila</p>
<p>With the advance of Artificial Intelligence (AI), Large Language Models (LLMs) have gained prominence and been applied in diverse contexts. As they evolve into more sophisticated versions, it is essential to assess whether they reproduce biases, such as discrimination and racialization, while maintaining hegemonic discourses. Current bias detection approaches rely mostly on quantitative, automated methods, which often overlook the nuanced ways in which biases emerge in natural language. This study proposes a qualitative, discursive framework to complement such methods. Through manual analysis of LLM-generated short stories featuring Black and white women, we investigate gender and racial biases. We contend that qualitative methods such as the one proposed here are fundamental to help both developers and users identify the precise ways in which biases manifest in LLM outputs, thus enabling better conditions to mitigate them. Results show that Black women are portrayed as tied to ancestry and resistance, while white women appear in self-discovery processes. These patterns reflect how language models replicate crystalized discursive representations, reinforcing essentialization and a sense of social immobility. When prompted to correct biases, models offered superficial revisions that maintained problematic meanings, revealing limitations in fostering inclusive narratives. Our results demonstrate the ideological functioning of algorithms and have significant implications for the ethical use and development of AI. The study reinforces the need for critical, interdisciplinary approaches to AI design and deployment, addressing how LLM-generated discourses reflect and perpetuate inequalities.
éšç€äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰çš„è¿›æ­¥ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ—¥ç›Šå—åˆ°å…³æ³¨å¹¶åœ¨å„ç§åœºæ™¯ä¸­å¾—åˆ°åº”ç”¨ã€‚éšç€å®ƒä»¬ä¸æ–­æ¼”è¿›ä¸ºæ›´å¤æ‚çš„ç‰ˆæœ¬ï¼Œæœ‰å¿…è¦è¯„ä¼°å®ƒä»¬æ˜¯å¦åœ¨ç»´æŒéœ¸æƒè¯è¯­çš„åŒæ—¶å†ç°äº†åè§ï¼Œå¦‚æ­§è§†å’Œç§æ—åŒ–ã€‚å½“å‰çš„åè§æ£€æµ‹æ–¹æ³•ä¸»è¦ä¾èµ–å®šé‡çš„è‡ªåŠ¨åŒ–æ‰‹æ®µï¼Œå¾€å¾€å¿½è§†äº†åè§åœ¨è‡ªç„¶è¯­è¨€ä¸­å‡ºç°çš„å¾®å¦™æ–¹å¼ã€‚æœ¬ç ”ç©¶æå‡ºä¸€ä¸ªå®šæ€§çš„ã€è¯è¯­åˆ†ææ¡†æ¶æ¥è¡¥å……æ­¤ç±»æ–¹æ³•ã€‚é€šè¿‡å¯¹ç”± LLM ç”Ÿæˆçš„ä»¥é»‘äººå¥³æ€§å’Œç™½äººå¥³æ€§ä¸ºä¸»è§’çš„çŸ­ç¯‡æ•…äº‹è¿›è¡Œäººå·¥åˆ†æï¼Œæˆ‘ä»¬è€ƒå¯Ÿäº†æ€§åˆ«ä¸ç§æ—åè§ã€‚æˆ‘ä»¬è®¤ä¸ºï¼Œåƒè¿™é‡Œæ‰€æå‡ºçš„å®šæ€§æ–¹æ³•å¯¹äºå¸®åŠ©å¼€å‘è€…å’Œç”¨æˆ·è¯†åˆ«åè§åœ¨ LLM è¾“å‡ºä¸­å…·ä½“å¦‚ä½•æ˜¾ç°è‡³å…³é‡è¦ï¼Œä»è€Œä¸ºå‡è½»è¿™äº›åè§åˆ›é€ æ›´å¥½çš„æ¡ä»¶ã€‚ç»“æœæ˜¾ç¤ºï¼Œé»‘äººå¥³æ€§è¢«æç»˜ä¸ºä¸ç¥–å…ˆå’ŒæŠµæŠ—ç›¸è¿ï¼Œè€Œç™½äººå¥³æ€§åˆ™å‡ºç°åœ¨è‡ªæˆ‘å‘ç°çš„è¿‡ç¨‹ä¸­ã€‚ è¿™äº›æ¨¡å¼åæ˜ äº†è¯­è¨€æ¨¡å‹å¦‚ä½•å¤åˆ¶å›ºåŒ–çš„è¯è¯­è¡¨å¾ï¼Œå¼ºåŒ–äº†æœ¬è´¨åŒ–å€¾å‘å’Œç¤¾ä¼šä¸æµåŠ¨æ„Ÿã€‚åœ¨è¢«æç¤ºçº æ­£åè§æ—¶ï¼Œæ¨¡å‹æä¾›äº†è¡¨é¢æ€§çš„ä¿®æ”¹ï¼Œä½†ä¿ç•™äº†é—®é¢˜æ€§çš„å«ä¹‰ï¼Œæ­ç¤ºäº†å…¶åœ¨ä¿ƒæˆåŒ…å®¹æ€§å™äº‹æ–¹é¢çš„å±€é™æ€§ã€‚æˆ‘ä»¬çš„ç»“æœå±•ç¤ºäº†ç®—æ³•çš„æ„è¯†å½¢æ€åŠŸèƒ½ï¼Œå¹¶å¯¹äººå·¥æ™ºèƒ½çš„ä¼¦ç†ä½¿ç”¨ä¸å¼€å‘å…·æœ‰é‡è¦å½±å“ã€‚è¯¥ç ”ç©¶å¼ºè°ƒéœ€è¦é‡‡ç”¨æ‰¹åˆ¤æ€§ã€è·¨å­¦ç§‘çš„æ–¹æ³•æ¥è®¾è®¡ä¸éƒ¨ç½²äººå·¥æ™ºèƒ½ï¼Œä»¥åº”å¯¹ LLM ç”Ÿæˆçš„è¯è¯­å¦‚ä½•åæ˜ å¹¶å»¶ç»­ä¸å¹³ç­‰ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-14 03:22:02 UTC
å‘å¸ƒï¼š2025-08-14 03:22:02 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="96-pose-robust-calibration-strategy-for-point-of-gaze-estimation-on-mobile-phones--96-é¢å‘æ‰‹æœºè§†çº¿ç‚¹ä¼°è®¡çš„å§¿æ€é²æ£’æ ¡å‡†ç­–ç•¥"><a href="https://arxiv.org/abs/2508.10268"target="_blank" rel="external nofollow noopener noreferrer">#96</a> <a href="https://papers.cool/arxiv/2508.10268"target="_blank" rel="external nofollow noopener noreferrer">Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones</a>  #96 é¢å‘æ‰‹æœºè§†çº¿ç‚¹ä¼°è®¡çš„å§¿æ€é²æ£’æ ¡å‡†ç­–ç•¥</h2>
<p><strong>Authors</strong>: [Yujie Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yujie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yujie</a> Zhao), [Jiabei Zeng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiabei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiabei</a> Zeng), [Shiguang Shan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shiguang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shiguang</a> Shan)
ä½œè€…ï¼šèµµå®‡æ°ã€æ›¾ä½³è““ã€å•ä¸–å…‰</p>
<p>Although appearance-based point-of-gaze (PoG) estimation has improved, the estimators still struggle to generalize across individuals due to personal differences. Therefore, person-specific calibration is required for accurate PoG estimation. However, calibrated PoG estimators are often sensitive to head pose variations. To address this, we investigate the key factors influencing calibrated estimators and explore pose-robust calibration strategies. Specifically, we first construct a benchmark, MobilePoG, which includes facial images from 32 individuals focusing on designated points under either fixed or continuously changing head poses. Using this benchmark, we systematically analyze how the diversity of calibration points and head poses influences estimation accuracy. Our experiments show that introducing a wider range of head poses during calibration improves the estimator&rsquo;s ability to handle pose variation. Building on this insight, we propose a dynamic calibration strategy in which users fixate on calibration points while moving their phones. This strategy naturally introduces head pose variation during a user-friendly and efficient calibration process, ultimately producing a better calibrated PoG estimator that is less sensitive to head pose variations than those using conventional calibration strategies. Codes and datasets are available at our project page.
å°½ç®¡åŸºäºå¤–è§‚çš„æ³¨è§†ç‚¹ï¼ˆPoGï¼‰ä¼°è®¡å·²æœ‰æ‰€æå‡ï¼Œä½†ç”±äºä¸ªä½“å·®å¼‚ï¼Œä¼°è®¡å™¨ä»éš¾ä»¥è·¨äººæ³›åŒ–ã€‚å› æ­¤ï¼Œä¸ºäº†è·å¾—å‡†ç¡®çš„ PoG ä¼°è®¡ï¼Œéœ€è¿›è¡Œä¸ªä½“åŒ–æ ¡å‡†ã€‚ç„¶è€Œï¼Œç»è¿‡æ ¡å‡†çš„ PoG ä¼°è®¡å™¨å¾€å¾€å¯¹å¤´éƒ¨å§¿æ€å˜åŒ–æ•æ„Ÿã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ç ”ç©¶äº†å½±å“æ ¡å‡†ä¼°è®¡å™¨çš„å…³é”®å› ç´ ï¼Œå¹¶æ¢ç´¢äº†å¯¹å§¿æ€é²æ£’çš„æ ¡å‡†ç­–ç•¥ã€‚å…·ä½“è€Œè¨€ï¼Œæˆ‘ä»¬é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªåŸºå‡†æ•°æ®é›† MobilePoGï¼Œè¯¥æ•°æ®é›†åŒ…å« 32 åä¸ªä½“åœ¨å›ºå®šæˆ–æŒç»­å˜åŒ–çš„å¤´éƒ¨å§¿æ€ä¸‹æ³¨è§†æŒ‡å®šç‚¹çš„é¢éƒ¨å›¾åƒã€‚åŸºäºè¯¥åŸºå‡†ï¼Œæˆ‘ä»¬ç³»ç»Ÿåœ°åˆ†æäº†æ ¡å‡†ç‚¹å’Œå¤´éƒ¨å§¿æ€å¤šæ ·æ€§å¦‚ä½•å½±å“ä¼°è®¡ç²¾åº¦ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨æ ¡å‡†è¿‡ç¨‹ä¸­å¼•å…¥æ›´å¹¿æ³›çš„å¤´éƒ¨å§¿æ€èŒƒå›´å¯æå‡ä¼°è®¡å™¨åº”å¯¹å§¿æ€å˜åŒ–çš„èƒ½åŠ›ã€‚åŸºäºè¿™ä¸€æ´è§ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŠ¨æ€æ ¡å‡†ç­–ç•¥ï¼Œç”¨æˆ·åœ¨æ³¨è§†æ ¡å‡†ç‚¹çš„åŒæ—¶ç§»åŠ¨æ‰‹æœºã€‚ è¯¥ç­–ç•¥åœ¨ç”¨æˆ·å‹å¥½ä¸”é«˜æ•ˆçš„æ ¡å‡†è¿‡ç¨‹ä¸­è‡ªç„¶å¼•å…¥äº†å¤´éƒ¨å§¿æ€å˜åŒ–ï¼Œæœ€ç»ˆäº§ç”Ÿäº†ä¸€ä¸ªæ›´å¥½çš„æ³¨è§†ç‚¹ï¼ˆPoGï¼‰ä¼°è®¡å™¨ï¼Œå…¶å¯¹å¤´éƒ¨å§¿æ€å˜åŒ–çš„æ•æ„Ÿæ€§ä½äºä½¿ç”¨ä¼ ç»Ÿæ ¡å‡†ç­–ç•¥çš„ä¼°è®¡å™¨ã€‚ä»£ç å’Œæ•°æ®é›†å¯åœ¨æˆ‘ä»¬çš„é¡¹ç›®é¡µé¢è·å–ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>
ä¸»é¢˜ï¼šè®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ï¼Œäººå·¥æ™ºèƒ½ï¼Œäººæœºäº¤äº’</p>
<p><strong>Publish</strong>: 2025-08-14 01:28:30 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-14 01:28:30 UTC</p>
<h2 id="97-mrfd-multi-region-fusion-decoding-with-self-consistency-for-mitigating-hallucinations-in-lvlms--97-mrfdå…·æœ‰è‡ªæ´½æ€§çš„å¤šåŒºåŸŸèåˆè§£ç ä»¥å‡è½»å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹lvlmsä¸­çš„è™šæ„é—®é¢˜"><a href="https://arxiv.org/abs/2508.10264"target="_blank" rel="external nofollow noopener noreferrer">#97</a> <a href="https://papers.cool/arxiv/2508.10264"target="_blank" rel="external nofollow noopener noreferrer">MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs</a>  #97 MRFDï¼šå…·æœ‰è‡ªæ´½æ€§çš„å¤šåŒºåŸŸèåˆè§£ç ä»¥å‡è½»å¤§è§„æ¨¡è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰ä¸­çš„è™šæ„é—®é¢˜</h2>
<p><strong>Authors</strong>: [Haonan Ge](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haonan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haonan</a> Ge), [Yiwei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiwei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiwei</a> Wang), [Ming-Hsuan Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ming-Hsuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ming-Hsuan</a> Yang), [Yujun Cai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yujun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yujun</a> Cai)
ä½œè€…ï¼šè‘›æµ©å—ï¼Œç‹ä¸€ä¼Ÿï¼Œæ¨é“­æ¡“ï¼Œè”¡å®‡å³»</p>
<p>Large Vision-Language Models (LVLMs) have shown strong performance across multimodal tasks. However, they often produce hallucinations &ndash; text that is inconsistent with visual input, due to the limited ability to verify information in different regions of the image. To address this, we propose Multi-Region Fusion Decoding (MRFD), a training-free decoding method that improves factual grounding by modeling inter-region consistency. MRFD identifies salient regions using cross-attention, generates initial responses for each, and computes reliability weights based on Jensen-Shannon Divergence (JSD) among the responses. These weights guide a consistency-aware fusion of per-region predictions, using region-aware prompts inspired by Chain-of-Thought reasoning. Experiments across multiple LVLMs and benchmarks show that MRFD significantly reduces hallucinations and improves response factuality without requiring model updates.
å¤§å‹è§†è§‰-è¯­è¨€æ¨¡å‹ï¼ˆLVLMsï¼‰åœ¨å¤šæ¨¡æ€ä»»åŠ¡ä¸­è¡¨ç°å¼ºåŠ²ã€‚ç„¶è€Œï¼Œå®ƒä»¬ç»å¸¸äº§ç”Ÿå¹»è§‰â€”â€”ä¸è§†è§‰è¾“å…¥ä¸ä¸€è‡´çš„æ–‡æœ¬ï¼Œè¿™æ˜¯ç”±äºéªŒè¯å›¾åƒä¸åŒåŒºåŸŸä¿¡æ¯çš„èƒ½åŠ›æœ‰é™æ‰€è‡´ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†å¤šåŒºåŸŸèåˆè§£ç ï¼ˆMRFDï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„è§£ç æ–¹æ³•ï¼Œé€šè¿‡å»ºæ¨¡åŒºåŸŸé—´ä¸€è‡´æ€§æ¥æé«˜äº‹å®æ€§æ”¯æ’‘ã€‚MRFD ä½¿ç”¨äº¤å‰æ³¨æ„åŠ›è¯†åˆ«æ˜¾è‘—åŒºåŸŸï¼Œä¸ºæ¯ä¸ªåŒºåŸŸç”Ÿæˆåˆå§‹å“åº”ï¼Œå¹¶åŸºäºè¿™äº›å“åº”ä¹‹é—´çš„è©¹æ£®-é¦™å†œæ•£åº¦ï¼ˆJSDï¼‰è®¡ç®—å¯é æ€§æƒé‡ã€‚è¿™äº›æƒé‡å¼•å¯¼å¯¹æ¯åŒºåŸŸé¢„æµ‹è¿›è¡Œä¸€è‡´æ€§æ„ŸçŸ¥çš„èåˆï¼Œé‡‡ç”¨å—é“¾å¼æ€ç»´æ¨ç†å¯å‘çš„åŒºåŸŸæ„ŸçŸ¥æç¤ºã€‚è·¨å¤šä¸ª LVLM å’ŒåŸºå‡†çš„å®éªŒè¡¨æ˜ï¼ŒMRFD åœ¨æ— éœ€æ›´æ–°æ¨¡å‹çš„æƒ…å†µä¸‹æ˜¾è‘—å‡å°‘äº†å¹»è§‰å¹¶æé«˜äº†å“åº”çš„äº‹å®æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-14 01:17:39 UTC
å‘å¸ƒï¼š2025-08-14 01:17:39 UTC</p>
<h2 id="98-dinomotion-advanced-robust-tissue-motion-tracking-with-dinov2-in-2d-cine-mri-guided-radiotherapy--98-dinomotionåœ¨-2d-cine-mri-å¼•å¯¼æ”¾ç–—ä¸­ä½¿ç”¨-dinov2-è¿›è¡Œå…ˆè¿›çš„ç¨³å¥ç»„ç»‡è¿åŠ¨è·Ÿè¸ª"><a href="https://arxiv.org/abs/2508.10260"target="_blank" rel="external nofollow noopener noreferrer">#98</a> <a href="https://papers.cool/arxiv/2508.10260"target="_blank" rel="external nofollow noopener noreferrer">DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy</a>  #98 DINOMotionï¼šåœ¨ 2D Cine MRI å¼•å¯¼æ”¾ç–—ä¸­ä½¿ç”¨ DINOv2 è¿›è¡Œå…ˆè¿›çš„ç¨³å¥ç»„ç»‡è¿åŠ¨è·Ÿè¸ª</h2>
<p><strong>Authors</strong>: [Soorena Salari](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Soorena"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Soorena</a> Salari), [Catherine Spino](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Catherine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Catherine</a> Spino), [Laurie-Anne Pharand](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Laurie-Anne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Laurie-Anne</a> Pharand), [Fabienne Lathuiliere](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fabienne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fabienne</a> Lathuiliere), [Hassan Rivaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hassan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hassan</a> Rivaz), [Silvain Beriault](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silvain"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silvain</a> Beriault), [Yiming Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yiming</a> Xiao)
ä½œè€…ï¼šSoorena Salariã€Catherine Spinoã€Laurie-Anne Pharandã€Fabienne Lathuiliereã€Hassan Rivazã€Silvain Beriaultã€Yiming Xiao</p>
<p>Accurate tissue motion tracking is critical to ensure treatment outcome and safety in 2D-Cine MRI-guided radiotherapy. This is typically achieved by registration of sequential images, but existing methods often face challenges with large misalignments and lack of interpretability. In this paper, we introduce DINOMotion, a novel deep learning framework based on DINOv2 with Low-Rank Adaptation (LoRA) layers for robust, efficient, and interpretable motion tracking. DINOMotion automatically detects corresponding landmarks to derive optimal image registration, enhancing interpretability by providing explicit visual correspondences between sequential images. The integration of LoRA layers reduces trainable parameters, improving training efficiency, while DINOv2&rsquo;s powerful feature representations offer robustness against large misalignments. Unlike iterative optimization-based methods, DINOMotion directly computes image registration at test time. Our experiments on volunteer and patient datasets demonstrate its effectiveness in estimating both linear and nonlinear transformations, achieving Dice scores of 92.07% for the kidney, 90.90% for the liver, and 95.23% for the lung, with corresponding Hausdorff distances of 5.47 mm, 8.31 mm, and 6.72 mm, respectively. DINOMotion processes each scan in approximately 30ms and consistently outperforms state-of-the-art methods, particularly in handling large misalignments. These results highlight its potential as a robust and interpretable solution for real-time motion tracking in 2D-Cine MRI-guided radiotherapy.
åœ¨ 2D-Cine MRI å¼•å¯¼æ”¾ç–—ä¸­ï¼Œç²¾ç¡®çš„ç»„ç»‡è¿åŠ¨è¿½è¸ªå¯¹äºç¡®ä¿æ²»ç–—æ•ˆæœå’Œå®‰å…¨æ€§è‡³å…³é‡è¦ã€‚é€šå¸¸é€šè¿‡å¯¹é¡ºåºå›¾åƒè¿›è¡Œé…å‡†æ¥å®ç°ï¼Œä½†ç°æœ‰æ–¹æ³•å¸¸åœ¨å¤§ä½ç§»æƒ…å†µä¸‹é‡åˆ°æŒ‘æˆ˜ä¸”ç¼ºä¹å¯è§£é‡Šæ€§ã€‚æœ¬æ–‡æå‡ºäº† DINOMotionï¼Œä¸€ç§åŸºäº DINOv2 å¹¶å¼•å…¥ä½ç§©è‡ªé€‚åº”ï¼ˆLoRAï¼‰å±‚çš„æ–°å‹æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºå®ç°é²æ£’ã€é«˜æ•ˆä¸”å…·å¯è§£é‡Šæ€§çš„è¿åŠ¨è¿½è¸ªã€‚DINOMotion è‡ªåŠ¨æ£€æµ‹å¯¹åº”çš„å…³é”®ç‚¹ä»¥æ¨å¯¼æœ€ä¼˜å›¾åƒé…å‡†ï¼Œé€šè¿‡åœ¨é¡ºåºå›¾åƒé—´æä¾›æ˜ç¡®çš„å¯è§†å¯¹åº”å…³ç³»æ¥å¢å¼ºå¯è§£é‡Šæ€§ã€‚å¼•å…¥ LoRA å±‚å‡å°‘äº†å¯è®­ç»ƒå‚æ•°ï¼Œä»è€Œæé«˜äº†è®­ç»ƒæ•ˆç‡ï¼Œè€Œ DINOv2 å¼ºå¤§çš„ç‰¹å¾è¡¨ç¤ºåˆ™åœ¨é¢å¯¹å¤§ä½ç§»æ—¶æä¾›äº†é²æ£’æ€§ã€‚ä¸åŸºäºè¿­ä»£ä¼˜åŒ–çš„æ–¹æ³•ä¸åŒï¼ŒDINOMotion åœ¨æµ‹è¯•æ—¶ç›´æ¥è®¡ç®—å›¾åƒé…å‡†ã€‚ æˆ‘ä»¬åœ¨å¿—æ„¿è€…å’Œæ‚£è€…æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¼°è®¡çº¿æ€§å’Œéçº¿æ€§å˜æ¢æ–¹é¢éƒ½å¾ˆæœ‰æ•ˆï¼Œè‚¾è„ã€è‚è„å’Œè‚ºéƒ¨çš„ Dice å¾—åˆ†åˆ†åˆ«ä¸º 92.07%ã€90.90%å’Œ 95.23%ï¼Œç›¸åº”çš„ Hausdorff è·ç¦»åˆ†åˆ«ä¸º 5.47 æ¯«ç±³ã€8.31 æ¯«ç±³å’Œ 6.72 æ¯«ç±³ã€‚DINOMotion å¤„ç†æ¯æ¬¡æ‰«æå¤§çº¦éœ€è¦ 30 æ¯«ç§’ï¼Œå¹¶ä¸”åœ¨å¤§é”™ä½å¤„ç†æ–¹é¢æŒç»­ä¼˜äºæœ€å…ˆè¿›çš„æ–¹æ³•ã€‚è¿™äº›ç»“æœçªæ˜¾äº†å…¶ä½œä¸ºä¸€ç§é²æ£’ä¸”å¯è§£é‡Šçš„å®æ—¶è¿åŠ¨è·Ÿè¸ªè§£å†³æ–¹æ¡ˆåœ¨ 2D-Cine MRI å¼•å¯¼æ”¾ç–—ä¸­çš„æ½œåŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/eess.IV"target="_blank" rel="external nofollow noopener noreferrer">Image and Video Processing</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>
ä¸»é¢˜ï¼šå›¾åƒä¸è§†é¢‘å¤„ç†ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«</p>
<p><strong>Publish</strong>: 2025-08-14 01:02:26 UTC
å‘å¸ƒï¼š2025-08-14 01:02:26 UTC</p>
<h2 id="99-facilitating-longitudinal-interaction-studies-of-ai-systems--99-ä¿ƒè¿›äººå·¥æ™ºèƒ½ç³»ç»Ÿçºµå‘äº¤äº’ç ”ç©¶"><a href="https://arxiv.org/abs/2508.10252"target="_blank" rel="external nofollow noopener noreferrer">#99</a> <a href="https://papers.cool/arxiv/2508.10252"target="_blank" rel="external nofollow noopener noreferrer">Facilitating Longitudinal Interaction Studies of AI Systems</a>  #99 ä¿ƒè¿›äººå·¥æ™ºèƒ½ç³»ç»Ÿçºµå‘äº¤äº’ç ”ç©¶</h2>
<p><strong>Authors</strong>: [Tao Long](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tao</a> Long), [Sitong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sitong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sitong</a> Wang), [Ã‰milie Fabre](<a href="https://arxiv.org/search/?searchtype=author&amp;query="target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=</a>Ã‰milie Fabre), [Tony Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tony"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tony</a> Wang), [Anup Sathya](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Anup"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Anup</a> Sathya), [Jason Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jason"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jason</a> Wu), [Savvas Petridis](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Savvas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Savvas</a> Petridis), [Dingzeyu Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dingzeyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dingzeyu</a> Li), [Tuhin Chakrabarty](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tuhin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tuhin</a> Chakrabarty), [Yue Jiang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yue"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yue</a> Jiang), [Jingyi Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jingyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jingyi</a> Li), [Tiffany Tseng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tiffany"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tiffany</a> Tseng), [Ken Nakagaki](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ken"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ken</a> Nakagaki), [Qian Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qian</a> Yang), [Nikolas Martelaro](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nikolas"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nikolas</a> Martelaro), [Jeffrey V. Nickerson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jeffrey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jeffrey</a> V. Nickerson), [Lydia B. Chilton](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lydia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lydia</a> B. Chilton)
ä½œè€…ï¼šTao Longã€Sitong Wangã€Ã‰milie Fabreã€Tony Wangã€Anup Sathyaã€Jason Wuã€Savvas Petridisã€Dingzeyu Liã€Tuhin Chakrabartyã€Yue Jiangã€Jingyi Liã€Tiffany Tsengã€Ken Nakagakiã€Qian Yangã€Nikolas Martelaroã€Jeffrey V. Nickersonã€Lydia B. Chilton</p>
<p>UIST researchers develop tools to address user challenges. However, user interactions with AI evolve over time through learning, adaptation, and repurposing, making one time evaluations insufficient. Capturing these dynamics requires longer-term studies, but challenges in deployment, evaluation design, and data collection have made such longitudinal research difficult to implement. Our workshop aims to tackle these challenges and prepare researchers with practical strategies for longitudinal studies. The workshop includes a keynote, panel discussions, and interactive breakout groups for discussion and hands-on protocol design and tool prototyping sessions. We seek to foster a community around longitudinal system research and promote it as a more embraced method for designing, building, and evaluating UIST tools.
UIST çš„ç ”ç©¶äººå‘˜å¼€å‘å·¥å…·ä»¥è§£å†³ç”¨æˆ·é¢ä¸´çš„æŒ‘æˆ˜ã€‚ç„¶è€Œï¼Œç”¨æˆ·ä¸äººå·¥æ™ºèƒ½çš„äº¤äº’ä¼šéšç€å­¦ä¹ ã€é€‚åº”å’Œé‡æ–°ç”¨é€”è€Œéšæ—¶é—´æ¼”å˜ï¼Œè¿™ä½¿å¾—ä¸€æ¬¡æ€§çš„è¯„ä¼°ä¸è¶³ä»¥åæ˜ çœŸå®æƒ…å†µã€‚è¦æ•æ‰è¿™äº›åŠ¨æ€å˜åŒ–éœ€è¦æ›´é•¿æœŸçš„ç ”ç©¶ï¼Œä½†åœ¨éƒ¨ç½²ã€è¯„ä¼°è®¾è®¡å’Œæ•°æ®æ”¶é›†æ–¹é¢çš„æŒ‘æˆ˜ä½¿å¾—æ­¤ç±»çºµå‘ç ”ç©¶éš¾ä»¥å®æ–½ã€‚æˆ‘ä»¬çš„ç ”è®¨ä¼šæ—¨åœ¨åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œå¹¶ä¸ºç ”ç©¶äººå‘˜æä¾›å¼€å±•çºµå‘ç ”ç©¶çš„å®ç”¨ç­–ç•¥ã€‚ç ”è®¨ä¼šåŒ…æ‹¬ä¸»é¢˜æ¼”è®²ã€ä¸“å®¶å°ç»„è®¨è®ºä»¥åŠç”¨äºè®¨è®ºå’ŒåŠ¨æ‰‹è®¾è®¡åè®®ä¸å·¥å…·åŸå‹çš„äº’åŠ¨åˆ†ç»„ç¯èŠ‚ã€‚æˆ‘ä»¬å¸Œæœ›åœ¨çºµå‘ç³»ç»Ÿç ”ç©¶æ–¹é¢åŸ¹è‚²ä¸€ä¸ªç¤¾åŒºï¼Œå¹¶æ¨åŠ¨å…¶æˆä¸ºè®¾è®¡ã€æ„å»ºå’Œè¯„ä¼° UIST å·¥å…·æ—¶æ›´å¹¿æ³›é‡‡ç”¨çš„æ–¹æ³•ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">Computers and Society</a>
ä¸»é¢˜ï¼šäººæœºäº¤äº’ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºä¸ç¤¾ä¼š</p>
<p><strong>Publish</strong>: 2025-08-14 00:38:23 UTC
å‘å¸ƒï¼š2025-08-14 00:38:23 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="100-no-free-lunch-from-audio-pretraining-in-bioacoustics-a-benchmark-study-of-embeddings--100-æ¥è‡ªéŸ³é¢‘é¢„è®­ç»ƒåœ¨ç”Ÿç‰©å£°å­¦ä¸­å¹¶éä¸‡èƒ½åµŒå…¥åŸºå‡†ç ”ç©¶"><a href="https://arxiv.org/abs/2508.10230"target="_blank" rel="external nofollow noopener noreferrer">#100</a> <a href="https://papers.cool/arxiv/2508.10230"target="_blank" rel="external nofollow noopener noreferrer">No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings</a>  #100 æ¥è‡ªéŸ³é¢‘é¢„è®­ç»ƒåœ¨ç”Ÿç‰©å£°å­¦ä¸­å¹¶éä¸‡èƒ½ï¼šåµŒå…¥åŸºå‡†ç ”ç©¶</h2>
<p><strong>Authors</strong>: [Chenggang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chenggang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chenggang</a> Chen), [Zhiyu Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhiyu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zhiyu</a> Yang)
ä½œè€…ï¼šé™ˆæˆåˆšï¼Œæ¨å¿—å®‡</p>
<p>Bioacoustics, the study of animal sounds, offers a non-invasive method to monitor ecosystems. Extracting embeddings from audio-pretrained deep learning (DL) models without fine-tuning has become popular for obtaining bioacoustic features for tasks. However, a recent benchmark study reveals that while fine-tuned audio-pretrained VGG and transformer models achieve state-of-the-art performance in some tasks, they fail in others. This study benchmarks 11 DL models on the same tasks by reducing their learned embeddings&rsquo; dimensionality and evaluating them through clustering. We found that audio-pretrained DL models 1) without fine-tuning even underperform fine-tuned AlexNet, 2) both with and without fine-tuning fail to separate the background from labeled sounds, but ResNet does, and 3) outperform other models when fewer background sounds are included during fine-tuning. This study underscores the necessity of fine-tuning audio-pretrained models and checking the embeddings after fine-tuning. Our codes are available: <a href="https://github.com/NeuroscienceAI/Audio"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/NeuroscienceAI/Audio</a>_Embeddings
ç”Ÿç‰©å£°å­¦æ˜¯ç ”ç©¶åŠ¨ç‰©å£°éŸ³çš„å­¦ç§‘ï¼Œæä¾›äº†ä¸€ç§ç”¨äºç›‘æµ‹ç”Ÿæ€ç³»ç»Ÿçš„éä¾µå…¥æ€§æ–¹æ³•ã€‚ä»æœªç»å¾®è°ƒçš„éŸ³é¢‘é¢„è®­ç»ƒæ·±åº¦å­¦ä¹ ï¼ˆDLï¼‰æ¨¡å‹ä¸­æå–åµŒå…¥å‘é‡å·²æˆä¸ºè·å–ç”Ÿç‰©å£°å­¦ç‰¹å¾ä»¥ç”¨äºå„ç±»ä»»åŠ¡çš„æµè¡Œåšæ³•ã€‚ç„¶è€Œï¼Œæœ€è¿‘çš„ä¸€é¡¹åŸºå‡†ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡ç»è¿‡å¾®è°ƒçš„éŸ³é¢‘é¢„è®­ç»ƒ VGG å’Œå˜æ¢å™¨æ¨¡å‹åœ¨æŸäº›ä»»åŠ¡ä¸Šè¾¾åˆ°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ï¼Œä½†å®ƒä»¬åœ¨å…¶ä»–ä»»åŠ¡ä¸Šå´è¡¨ç°ä¸ä½³ã€‚æœ¬ç ”ç©¶é€šè¿‡é™ä½æ‰€å­¦åµŒå…¥çš„ç»´åº¦å¹¶é€šè¿‡èšç±»è¯„ä¼°ï¼Œå¯¹ç›¸åŒä»»åŠ¡ä¸Šçš„ 11 ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬å‘ç°ï¼ŒéŸ³é¢‘é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ 1ï¼‰åœ¨æœªå¾®è°ƒæ—¶ç”šè‡³ä¸å¦‚å¾®è°ƒåçš„ AlexNetï¼Œ2ï¼‰æ— è®ºæ˜¯å¦å¾®è°ƒå‡æ— æ³•å°†èƒŒæ™¯ä¸æœ‰æ ‡ç­¾çš„å£°éŸ³åˆ†ç¦»ï¼Œä½† ResNet å¯ä»¥åšåˆ°ï¼Œ3ï¼‰åœ¨å¾®è°ƒæ—¶åŒ…å«è¾ƒå°‘èƒŒæ™¯å£°éŸ³çš„æƒ…å†µä¸‹è¡¨ç°ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚æœ¬ç ”ç©¶å¼ºè°ƒäº†å¯¹éŸ³é¢‘é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒå¹¶åœ¨å¾®è°ƒåæ£€æŸ¥åµŒå…¥å‘é‡çš„å¿…è¦æ€§ã€‚æˆ‘ä»¬çš„ä»£ç å¯åœ¨ä»¥ä¸‹åœ°å€è·å–ï¼šhttps://github.com/NeuroscienceAI/Audio_Embeddings</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">Sound</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå£°éŸ³ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 22:58:28 UTC
å‘å¸ƒï¼š2025-08-13 22:58:28 UTC</p>
<h2 id="101-using-large-language-models-to-measure-symptom-severity-in-patients-at-risk-for-schizophrenia--101-ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æœ‰ç²¾ç¥åˆ†è£‚ç—‡é£é™©æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦"><a href="https://arxiv.org/abs/2508.10226"target="_blank" rel="external nofollow noopener noreferrer">#101</a> <a href="https://papers.cool/arxiv/2508.10226"target="_blank" rel="external nofollow noopener noreferrer">Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia</a>  #101 ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¯„ä¼°æœ‰ç²¾ç¥åˆ†è£‚ç—‡é£é™©æ‚£è€…çš„ç—‡çŠ¶ä¸¥é‡ç¨‹åº¦</h2>
<p><strong>Authors</strong>: [Andrew X. Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrew"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrew</a> X. Chen), [Guillermo Horga](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Guillermo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Guillermo</a> Horga), [Sean Escola](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sean"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sean</a> Escola)
ä½œè€…ï¼šAndrew X. Chenã€Guillermo Horgaã€Sean Escola</p>
<p>Patients who are at clinical high risk (CHR) for schizophrenia need close monitoring of their symptoms to inform appropriate treatments. The Brief Psychiatric Rating Scale (BPRS) is a validated, commonly used research tool for measuring symptoms in patients with schizophrenia and other psychotic disorders; however, it is not commonly used in clinical practice as it requires a lengthy structured interview. Here, we utilize large language models (LLMs) to predict BPRS scores from clinical interview transcripts in 409 CHR patients from the Accelerating Medicines Partnership Schizophrenia (AMP-SCZ) cohort. Despite the interviews not being specifically structured to measure the BPRS, the zero-shot performance of the LLM predictions compared to the true assessment (median concordance: 0.84, ICC: 0.73) approaches human inter- and intra-rater reliability. We further demonstrate that LLMs have substantial potential to improve and standardize the assessment of CHR patients via their accuracy in assessing the BPRS in foreign languages (median concordance: 0.88, ICC: 0.70), and integrating longitudinal information in a one-shot or few-shot learning approach.
å¤„äºç²¾ç¥åˆ†è£‚ç—‡ä¸´åºŠé«˜é£é™©ï¼ˆCHRï¼‰çš„æ‚£è€…éœ€è¦å¯¹å…¶ç—‡çŠ¶è¿›è¡Œå¯†åˆ‡ç›‘æµ‹ä»¥æŒ‡å¯¼é€‚å½“çš„æ²»ç–—ã€‚ç®€çŸ­ç²¾ç¥ç—…è¯„å®šé‡è¡¨ï¼ˆBPRSï¼‰æ˜¯ä¸€ç§ç»è¿‡éªŒè¯ã€å¸¸ç”¨äºç ”ç©¶çš„å·¥å…·ï¼Œç”¨äºæµ‹é‡ç²¾ç¥åˆ†è£‚ç—‡åŠå…¶ä»–ç²¾ç¥ç—…æ€§éšœç¢æ‚£è€…çš„ç—‡çŠ¶ï¼›ç„¶è€Œï¼Œç”±äºå…¶éœ€è¦è¾ƒé•¿çš„ç»“æ„åŒ–è®¿è°ˆï¼Œä¸´åºŠå®è·µä¸­å¹¶ä¸å¸¸ç”¨ã€‚åœ¨æ­¤ï¼Œæˆ‘ä»¬åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä»æ¥è‡ªåŠ é€Ÿè¯ç‰©åˆä½œä¼™ä¼´å…³ç³»ç²¾ç¥åˆ†è£‚ç—‡ï¼ˆAMP-SCZï¼‰é˜Ÿåˆ—çš„ 409 å CHR æ‚£è€…çš„ä¸´åºŠè®¿è°ˆæ–‡æœ¬ä¸­é¢„æµ‹ BPRS è¯„åˆ†ã€‚å°½ç®¡è¿™äº›è®¿è°ˆå¹¶éä¸“é—¨ä¸ºè¡¡é‡ BPRS è€Œè®¾è®¡ï¼ŒLLM åœ¨é›¶æ ·æœ¬æƒ…å†µä¸‹çš„é¢„æµ‹ä¸çœŸå®è¯„ä¼°ç›¸æ¯”ï¼ˆä¸­ä½ä¸€è‡´æ€§ï¼š0.84ï¼ŒICCï¼š0.73ï¼‰æ¥è¿‘äººç±»è¯„ä¼°è€…ä¹‹é—´å’Œè¯„ä¼°è€…è‡ªèº«çš„ä¸€è‡´æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å±•ç¤ºäº† LLMs åœ¨æé«˜å’Œæ ‡å‡†åŒ– CHR æ‚£è€…è¯„ä¼°æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½“ç°åœ¨å…¶ç”¨å¤–è¯­è¯„ä¼° BPRS çš„å‡†ç¡®æ€§ï¼ˆä¸­ä½ä¸€è‡´æ€§ï¼š0.88ï¼ŒICCï¼š0.70ï¼‰ï¼Œä»¥åŠåœ¨ä¸€æ¬¡æˆ–å°‘é‡ç¤ºä¾‹å­¦ä¹ æ–¹æ³•ä¸­æ•´åˆçºµå‘ä¿¡æ¯çš„èƒ½åŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 22:47:01 UTC
å‘å¸ƒï¼š2025-08-13 22:47:01 UTC</p>
<h2 id="102-understanding-textual-emotion-through-emoji-prediction--102-é€šè¿‡è¡¨æƒ…ç¬¦å·é¢„æµ‹ç†è§£æ–‡æœ¬æƒ…ç»ª"><a href="https://arxiv.org/abs/2508.10222"target="_blank" rel="external nofollow noopener noreferrer">#102</a> <a href="https://papers.cool/arxiv/2508.10222"target="_blank" rel="external nofollow noopener noreferrer">Understanding Textual Emotion Through Emoji Prediction</a>  #102 é€šè¿‡è¡¨æƒ…ç¬¦å·é¢„æµ‹ç†è§£æ–‡æœ¬æƒ…ç»ª</h2>
<p><strong>Authors</strong>: [Ethan Gordon](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ethan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ethan</a> Gordon), [Nishank Kuppa](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nishank"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nishank</a> Kuppa), [Rigved Tummala](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rigved"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rigved</a> Tummala), [Sriram Anasuri](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sriram"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sriram</a> Anasuri)
ä½œè€…ï¼šEthan Gordonã€Nishank Kuppaã€Rigved Tummalaã€Sriram Anasuri</p>
<p>This project explores emoji prediction from short text sequences using four deep learning architectures: a feed-forward network, CNN, transformer, and BERT. Using the TweetEval dataset, we address class imbalance through focal loss and regularization techniques. Results show BERT achieves the highest overall performance due to its pre-training advantage, while CNN demonstrates superior efficacy on rare emoji classes. This research shows the importance of architecture selection and hyperparameter tuning for sentiment-aware emoji prediction, contributing to improved human-computer interaction.
æœ¬é¡¹ç›®ä½¿ç”¨å››ç§æ·±åº¦å­¦ä¹ æ¶æ„ï¼ˆå‰é¦ˆç½‘ç»œã€å·ç§¯ç¥ç»ç½‘ç»œã€Transformer å’Œ BERTï¼‰ä»çŸ­æ–‡æœ¬åºåˆ—ä¸­é¢„æµ‹è¡¨æƒ…ç¬¦å·ã€‚ä½¿ç”¨ TweetEval æ•°æ®é›†ï¼Œæˆ‘ä»¬é€šè¿‡ç„¦ç‚¹æŸå¤±å’Œæ­£åˆ™åŒ–æŠ€æœ¯æ¥åº”å¯¹ç±»åˆ«ä¸å¹³è¡¡ã€‚ç»“æœæ˜¾ç¤ºï¼Œç”±äºé¢„è®­ç»ƒä¼˜åŠ¿ï¼ŒBERT åœ¨æ•´ä½“æ€§èƒ½ä¸Šè¡¨ç°æœ€ä½³ï¼Œè€Œ CNN åœ¨ç¨€æœ‰è¡¨æƒ…ç¬¦å·ç±»åˆ«ä¸Šè¡¨ç°æ›´ä¸ºå‡ºè‰²ã€‚æœ¬ç ”ç©¶è¡¨æ˜ï¼Œå¯¹äºå…·æœ‰æƒ…æ„Ÿæ„è¯†çš„è¡¨æƒ…ç¬¦å·é¢„æµ‹ï¼Œæ¶æ„é€‰æ‹©å’Œè¶…å‚æ•°è°ƒä¼˜è‡³å…³é‡è¦ï¼Œæœ‰åŠ©äºæ”¹å–„äººæœºäº¤äº’ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.NE"target="_blank" rel="external nofollow noopener noreferrer">Neural and Evolutionary Computing</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€ç¥ç»ä¸è¿›åŒ–è®¡ç®—</p>
<p><strong>Publish</strong>: 2025-08-13 22:17:00 UTC
å‘å¸ƒï¼š2025-08-13 22:17:00 UTC</p>
<h2 id="103-an-explainable-ai-based-approach-for-monitoring-animal-health--103-åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½çš„åŠ¨ç‰©å¥åº·ç›‘æµ‹æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10210"target="_blank" rel="external nofollow noopener noreferrer">#103</a> <a href="https://papers.cool/arxiv/2508.10210"target="_blank" rel="external nofollow noopener noreferrer">An Explainable AI based approach for Monitoring Animal Health</a>  #103 åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½çš„åŠ¨ç‰©å¥åº·ç›‘æµ‹æ–¹æ³•</h2>
<p><strong>Authors</strong>: [Rahul Janaa](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rahul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rahul</a> Janaa), [Shubham Dixit](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shubham"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shubham</a> Dixit), [Mrityunjay Sharma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mrityunjay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mrityunjay</a> Sharma), [Ritesh Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ritesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ritesh</a> Kumar)
ä½œè€…ï¼šRahul Janaaã€Shubham Dixitã€Mrityunjay Sharmaã€Ritesh Kumar</p>
<p>Monitoring cattle health and optimizing yield are key challenges faced by dairy farmers due to difficulties in tracking all animals on the farm. This work aims to showcase modern data-driven farming practices based on explainable machine learning(ML) methods that explain the activity and behaviour of dairy cattle (cows). Continuous data collection of 3-axis accelerometer sensors and usage of robust ML methodologies and algorithms, provide farmers and researchers with actionable information on cattle activity, allowing farmers to make informed decisions and incorporate sustainable practices. This study utilizes Bluetooth-based Internet of Things (IoT) devices and 4G networks for seamless data transmission, immediate analysis, inference generation, and explains the models performance with explainability frameworks. Special emphasis is put on the pre-processing of the accelerometers time series data, including the extraction of statistical characteristics, signal processing techniques, and lag-based features using the sliding window technique. Various hyperparameter-optimized ML models are evaluated across varying window lengths for activity classification. The k-nearest neighbour Classifier achieved the best performance, with AUC of mean 0.98 and standard deviation of 0.0026 on the training set and 0.99 on testing set). In order to ensure transparency, Explainable AI based frameworks such as SHAP is used to interpret feature importance that can be understood and used by practitioners. A detailed comparison of the important features, along with the stability analysis of selected features, supports development of explainable and practical ML models for sustainable livestock management.
ç›‘æµ‹ç‰›åªå¥åº·å¹¶ä¼˜åŒ–äº§é‡æ˜¯å¥¶ç‰›å†œé¢ä¸´çš„å…³é”®æŒ‘æˆ˜ï¼Œå› ä¸ºéš¾ä»¥è¿½è¸ªå†œåœºä¸Šçš„æ‰€æœ‰åŠ¨ç‰©ã€‚æœ¬ç ”ç©¶æ—¨åœ¨å±•ç¤ºåŸºäºå¯è§£é‡Šæœºå™¨å­¦ä¹ ï¼ˆMLï¼‰æ–¹æ³•çš„ç°ä»£æ•°æ®é©±åŠ¨å…»æ®–å®è·µï¼Œè¿™äº›æ–¹æ³•èƒ½å¤Ÿè§£é‡Šä¹³ç‰›ï¼ˆå¥¶ç‰›ï¼‰çš„æ´»åŠ¨å’Œè¡Œä¸ºã€‚é€šè¿‡å¯¹ä¸‰è½´åŠ é€Ÿåº¦è®¡ä¼ æ„Ÿå™¨çš„è¿ç»­æ•°æ®é‡‡é›†ä»¥åŠä½¿ç”¨ç¨³å¥çš„æœºå™¨å­¦ä¹ æ–¹æ³•å’Œç®—æ³•ï¼Œä¸ºå†œæ°‘å’Œç ”ç©¶äººå‘˜æä¾›å…³äºç‰›åªæ´»åŠ¨çš„å¯æ“ä½œä¿¡æ¯ï¼Œä½¿å†œæ°‘èƒ½å¤Ÿåšå‡ºæ˜æ™ºå†³ç­–å¹¶çº³å…¥å¯æŒç»­åšæ³•ã€‚æœ¬ç ”ç©¶åˆ©ç”¨åŸºäºè“ç‰™çš„ç‰©è”ç½‘ï¼ˆIoTï¼‰è®¾å¤‡å’Œ 4G ç½‘ç»œå®ç°æ— ç¼æ•°æ®ä¼ è¾“ã€å³æ—¶åˆ†æã€æ¨æ–­ç”Ÿæˆï¼Œå¹¶é€šè¿‡å¯è§£é‡Šæ€§æ¡†æ¶è§£é‡Šæ¨¡å‹æ€§èƒ½ã€‚ç‰¹åˆ«å¼ºè°ƒäº†åŠ é€Ÿåº¦è®¡æ—¶é—´åºåˆ—æ•°æ®çš„é¢„å¤„ç†ï¼ŒåŒ…æ‹¬ç»Ÿè®¡ç‰¹å¾æå–ã€ä¿¡å·å¤„ç†æŠ€æœ¯ä»¥åŠä½¿ç”¨æ»‘åŠ¨çª—å£æŠ€æœ¯çš„åŸºäºæ»åçš„ç‰¹å¾æå–ã€‚é’ˆå¯¹ä¸åŒçª—å£é•¿åº¦å¯¹æ´»åŠ¨åˆ†ç±»è¯„ä¼°äº†å„ç§ç»è¶…å‚æ•°ä¼˜åŒ–çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚ k è¿‘é‚»åˆ†ç±»å™¨å–å¾—äº†æœ€ä½³æ€§èƒ½ï¼Œåœ¨è®­ç»ƒé›†ä¸Šçš„å¹³å‡ AUC ä¸º 0.98ï¼Œæ ‡å‡†å·®ä¸º 0.0026ï¼Œåœ¨æµ‹è¯•é›†ä¸Šä¸º 0.99ã€‚ä¸ºäº†ç¡®ä¿é€æ˜æ€§ï¼Œé‡‡ç”¨äº†åŸºäºå¯è§£é‡Šäººå·¥æ™ºèƒ½çš„æ¡†æ¶ï¼ˆä¾‹å¦‚ SHAPï¼‰æ¥è§£é‡Šå¯è¢«ä»ä¸šè€…ç†è§£å’Œä½¿ç”¨çš„ç‰¹å¾é‡è¦æ€§ã€‚å¯¹é‡è¦ç‰¹å¾çš„è¯¦ç»†æ¯”è¾ƒä»¥åŠæ‰€é€‰ç‰¹å¾çš„ç¨³å®šæ€§åˆ†æï¼Œæœ‰åŠ©äºå¼€å‘å¯è§£é‡Šä¸”å®ç”¨çš„ç”¨äºå¯æŒç»­ç•œç‰§ç®¡ç†çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 21:40:35 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-13 21:40:35 UTC</p>
<h2 id="104-catnet-a-geometric-deep-learning-approach-for-cat-bond-spread-prediction-in-the-primary-market--104-catnetä¸€ç§ç”¨äºåˆçº§å¸‚åœº-cat-å€ºåˆ¸åˆ©å·®é¢„æµ‹çš„å‡ ä½•æ·±åº¦å­¦ä¹ æ–¹æ³•"><a href="https://arxiv.org/abs/2508.10208"target="_blank" rel="external nofollow noopener noreferrer">#104</a> <a href="https://papers.cool/arxiv/2508.10208"target="_blank" rel="external nofollow noopener noreferrer">CATNet: A geometric deep learning approach for CAT bond spread prediction in the primary market</a>  #104 CATNetï¼šä¸€ç§ç”¨äºåˆçº§å¸‚åœº CAT å€ºåˆ¸åˆ©å·®é¢„æµ‹çš„å‡ ä½•æ·±åº¦å­¦ä¹ æ–¹æ³•</h2>
<p><strong>Authors</strong>: [Dixon Domfeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dixon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dixon</a> Domfeh), [Saeid Safarveisi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Saeid"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Saeid</a> Safarveisi)
ä½œè€…ï¼šDixon Domfehï¼ŒSaeid Safarveisi</p>
<p>Traditional models for pricing catastrophe (CAT) bonds struggle to capture the complex, relational data inherent in these instruments. This paper introduces CATNet, a novel framework that applies a geometric deep learning architecture, the Relational Graph Convolutional Network (R-GCN), to model the CAT bond primary market as a graph, leveraging its underlying network structure for spread prediction. Our analysis reveals that the CAT bond market exhibits the characteristics of a scale-free network, a structure dominated by a few highly connected and influential hubs. CATNet demonstrates high predictive performance, significantly outperforming a strong Random Forest benchmark. The inclusion of topological centrality measures as features provides a further, significant boost in accuracy. Interpretability analysis confirms that these network features are not mere statistical artifacts; they are quantitative proxies for long-held industry intuition regarding issuer reputation, underwriter influence, and peril concentration. This research provides evidence that network connectivity is a key determinant of price, offering a new paradigm for risk assessment and proving that graph-based models can deliver both state-of-the-art accuracy and deeper, quantifiable market insights.
ä¼ ç»Ÿçš„ç¾éš¾ï¼ˆCATï¼‰å€ºåˆ¸å®šä»·æ¨¡å‹éš¾ä»¥æ•æ‰è¿™äº›å·¥å…·ä¸­å›ºæœ‰çš„å¤æ‚å…³ç³»å‹æ•°æ®ã€‚æœ¬æ–‡æå‡ºäº† CATNetï¼Œä¸€ç§æ–°é¢–æ¡†æ¶ï¼Œé‡‡ç”¨å‡ ä½•æ·±åº¦å­¦ä¹ æ¶æ„â€”â€”å…³ç³»å›¾å·ç§¯ç½‘ç»œï¼ˆR-GCNï¼‰ï¼Œå°† CAT å€ºåˆ¸ä¸€çº§å¸‚åœºå»ºæ¨¡ä¸ºå›¾ç»“æ„ï¼Œåˆ©ç”¨å…¶æ½œåœ¨çš„ç½‘ç»œç»“æ„è¿›è¡Œåˆ©å·®é¢„æµ‹ã€‚æˆ‘ä»¬çš„åˆ†ææ˜¾ç¤ºï¼ŒCAT å€ºåˆ¸å¸‚åœºè¡¨ç°å‡ºæ— æ ‡åº¦ç½‘ç»œçš„ç‰¹å¾ï¼Œè¿™ç§ç»“æ„ç”±å°‘æ•°é«˜åº¦è¿æ¥ä¸”å…·æœ‰å½±å“åŠ›çš„æ¢çº½ä¸»å¯¼ã€‚CATNet å±•ç°å‡ºå¾ˆé«˜çš„é¢„æµ‹æ€§èƒ½ï¼Œæ˜¾è‘—ä¼˜äºå¼ºåŸºå‡†éšæœºæ£®æ—æ¨¡å‹ã€‚å°†æ‹“æ‰‘ä¸­å¿ƒæ€§åº¦é‡ä½œä¸ºç‰¹å¾çš„åŠ å…¥è¿›ä¸€æ­¥æ˜¾è‘—æå‡äº†å‡†ç¡®æ€§ã€‚å¯è§£é‡Šæ€§åˆ†æè¯å®ï¼Œè¿™äº›ç½‘ç»œç‰¹å¾å¹¶éå•çº¯çš„ç»Ÿè®¡ä¼ªåƒï¼›å®ƒä»¬æ˜¯é•¿æœŸè¡Œä¸šç›´è§‰ï¼ˆå…³äºå‘è¡Œäººå£°èª‰ã€æ‰¿é”€å•†å½±å“åŠ›å’Œé£é™©é›†ä¸­ï¼‰çš„é‡åŒ–ä»£ç†ã€‚ è¿™é¡¹ç ”ç©¶æä¾›è¯æ®è¡¨æ˜ç½‘ç»œè¿é€šæ€§æ˜¯ä»·æ ¼çš„å…³é”®å†³å®šå› ç´ ï¼Œæå‡ºäº†ä¸€ç§ç”¨äºé£é™©è¯„ä¼°çš„æ–°èŒƒå¼ï¼Œå¹¶è¯æ˜åŸºäºå›¾çš„æ¨¡å‹æ—¢èƒ½å®ç°æœ€å…ˆè¿›çš„å‡†ç¡®æ€§ï¼Œä¹Ÿèƒ½æä¾›æ›´æ·±åˆ»ã€å¯é‡åŒ–çš„å¸‚åœºæ´è§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/q-fin.PR"target="_blank" rel="external nofollow noopener noreferrer">Pricing of Securities</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/q-fin.CP"target="_blank" rel="external nofollow noopener noreferrer">Computational Finance</a>, <a href="https://papers.cool/arxiv/q-fin.RM"target="_blank" rel="external nofollow noopener noreferrer">Risk Management</a>
ä¸»é¢˜ï¼šè¯åˆ¸å®šä»·ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€è®¡ç®—é‡‘èã€é£é™©ç®¡ç†</p>
<p><strong>Publish</strong>: 2025-08-13 21:38:25 UTC
å‘å¸ƒï¼š2025-08-13 21:38:25 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="105-prompt-response-semantic-divergence-metrics-for-faithfulness-hallucination-and-misalignment-detection-in-large-language-models--105-æç¤º-å“åº”è¯­ä¹‰åç¦»åº¦é‡ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¿ å®æ€§å¹»è§‰å’Œä¸å¯¹é½æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10192"target="_blank" rel="external nofollow noopener noreferrer">#105</a> <a href="https://papers.cool/arxiv/2508.10192"target="_blank" rel="external nofollow noopener noreferrer">Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models</a>  #105 æç¤º-å“åº”è¯­ä¹‰åç¦»åº¦é‡ï¼Œç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„å¿ å®æ€§å¹»è§‰å’Œä¸å¯¹é½æ£€æµ‹</h2>
<p><strong>Author</strong>: [Igor Halperin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Igor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Igor</a> Halperin) ä½œè€…ï¼šIgor Halperin</p>
<p>The proliferation of Large Language Models (LLMs) is challenged by hallucinations, critical failure modes where models generate non-factual, nonsensical or unfaithful text. This paper introduces Semantic Divergence Metrics (SDM), a novel lightweight framework for detecting Faithfulness Hallucinations &ndash; events of severe deviations of LLMs responses from input contexts. We focus on a specific implementation of these LLM errors, {confabulations, defined as responses that are arbitrary and semantically misaligned with the user&rsquo;s query. Existing methods like Semantic Entropy test for arbitrariness by measuring the diversity of answers to a single, fixed prompt. Our SDM framework improves upon this by being more prompt-aware: we test for a deeper form of arbitrariness by measuring response consistency not only across multiple answers but also across multiple, semantically-equivalent paraphrases of the original prompt. Methodologically, our approach uses joint clustering on sentence embeddings to create a shared topic space for prompts and answers. A heatmap of topic co-occurances between prompts and responses can be viewed as a quantified two-dimensional visualization of the user-machine dialogue. We then compute a suite of information-theoretic metrics to measure the semantic divergence between prompts and responses. Our practical score, SH, combines the Jensen-Shannon divergence and Wasserstein distance to quantify this divergence, with a high score indicating a Faithfulness hallucination. Furthermore, we identify the KL divergence KL(Answer || Prompt) as a powerful indicator of \textbf{Semantic Exploration}, a key signal for distinguishing different generative behaviors. These metrics are further combined into the Semantic Box, a diagnostic framework for classifying LLM response types, including the dangerous, confident confabulation.
å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ™®åŠé¢ä¸´å¹»è§‰é—®é¢˜çš„æŒ‘æˆ˜ï¼Œå³æ¨¡å‹ç”Ÿæˆéäº‹å®æ€§çš„ã€è’è°¬çš„æˆ–ä¸å¿ å®æ–‡æœ¬çš„ä¸¥é‡å¤±æ•ˆæ¨¡å¼ã€‚æœ¬æ–‡æå‡ºäº†è¯­ä¹‰åç¦»åº¦é‡ï¼ˆSDMï¼‰ï¼Œä¸€ç§ç”¨äºæ£€æµ‹å¿ å®æ€§å¹»è§‰çš„è½»é‡çº§æ–°æ¡†æ¶â€”â€”å³ LLMs å›å¤ä¸è¾“å…¥ä¸Šä¸‹æ–‡ä¸¥é‡åç¦»çš„äº‹ä»¶ã€‚æˆ‘ä»¬å…³æ³¨è¿™ç±» LLM é”™è¯¯çš„ä¸€ç§å…·ä½“å®ç°ï¼Œæœæ’°ï¼ˆconfabulationsï¼‰ï¼Œå®šä¹‰ä¸ºå¯¹ç”¨æˆ·æŸ¥è¯¢ä»»æ„ä¸”è¯­ä¹‰ä¸å¯¹é½çš„å›å¤ã€‚ç°æœ‰æ–¹æ³•å¦‚è¯­ä¹‰ç†µé€šè¿‡è¡¡é‡å¯¹å•ä¸€å›ºå®šæç¤ºçš„ç­”æ¡ˆå¤šæ ·æ€§æ¥æµ‹è¯•ä»»æ„æ€§ã€‚æˆ‘ä»¬çš„ SDM æ¡†æ¶åœ¨æ­¤åŸºç¡€ä¸Šæ”¹è¿›ï¼Œæ›´åŠ è€ƒè™‘æç¤ºçš„å½±å“ï¼šæˆ‘ä»¬é€šè¿‡è¡¡é‡å›å¤åœ¨å¤šä¸ªç­”æ¡ˆä¹‹é—´ï¼Œä»¥åŠåœ¨åŸå§‹æç¤ºçš„å¤šä¸ªè¯­ä¹‰ç­‰ä»·æ”¹å†™ä¹‹é—´çš„ä¸€è‡´æ€§ï¼Œæ¥æ£€æµ‹æ›´æ·±å±‚æ¬¡çš„ä»»æ„æ€§ã€‚åœ¨æ–¹æ³•ä¸Šï¼Œæˆ‘ä»¬çš„åšæ³•ä½¿ç”¨å¥å­åµŒå…¥çš„è”åˆèšç±»ï¼Œä¸ºæç¤ºå’Œç­”æ¡ˆåˆ›å»ºä¸€ä¸ªå…±äº«çš„è¯é¢˜ç©ºé—´ã€‚ æç¤ºä¸å›å¤ä¹‹é—´ä¸»é¢˜å…±ç°çš„çƒ­åŠ›å›¾å¯ä»¥è¢«è§†ä¸ºç”¨æˆ·â€”æœºå™¨å¯¹è¯çš„é‡åŒ–äºŒç»´å¯è§†åŒ–ã€‚éšåæˆ‘ä»¬è®¡ç®—äº†ä¸€ç»„ä¿¡æ¯è®ºæŒ‡æ ‡æ¥è¡¡é‡æç¤ºä¸å›å¤ä¹‹é—´çš„è¯­ä¹‰åç¦»ã€‚æˆ‘ä»¬çš„å®ç”¨å¾—åˆ†ï¼Œ SH ï¼Œç»“åˆäº† Jensenâ€“Shannon æ•£åº¦å’Œ Wasserstein è·ç¦»æ¥é‡åŒ–è¿™ç§åç¦»ï¼Œå¾—åˆ†è¶Šé«˜è¡¨ç¤ºæ˜¯ä¸€ä¸ªå¿ å®æ€§å¹»è§‰ï¼ˆFaithfulness hallucinationï¼‰ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯†åˆ«å‡º KL æ•£åº¦ KL(Answer || Prompt) ä½œä¸ºä¸€ä¸ªå¼ºæœ‰åŠ›çš„â€œè¯­ä¹‰æ¢ç´¢â€ï¼ˆSemantic Explorationï¼‰æŒ‡ç¤ºå™¨ï¼Œè¿™æ˜¯åŒºåˆ†ä¸åŒç”Ÿæˆè¡Œä¸ºçš„å…³é”®ä¿¡å·ã€‚è¿™äº›æŒ‡æ ‡è¿›ä¸€æ­¥è¢«ç»„åˆæˆè¯­ä¹‰ç›’ï¼ˆSemantic Boxï¼‰ï¼Œä½œä¸ºç”¨äºå¯¹ LLM å“åº”ç±»å‹è¿›è¡Œåˆ†ç±»çš„è¯Šæ–­æ¡†æ¶ï¼ŒåŒ…æ‹¬å±é™©çš„ã€è‡ªä¿¡çš„æœæ’°ï¼ˆconfident confabulationï¼‰ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/q-fin.CP"target="_blank" rel="external nofollow noopener noreferrer">Computational Finance</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ ï¼Œè®¡ç®—é‡‘è</p>
<p><strong>Publish</strong>: 2025-08-13 20:55:26 UTC
å‘å¸ƒï¼š2025-08-13 20:55:26 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="106-pakbbq-a-culturally-adapted-bias-benchmark-for-qa--106-pakbbqé’ˆå¯¹é—®ç­”çš„æ–‡åŒ–é€‚é…åè§åŸºå‡†"><a href="https://arxiv.org/abs/2508.10186"target="_blank" rel="external nofollow noopener noreferrer">#106</a> <a href="https://papers.cool/arxiv/2508.10186"target="_blank" rel="external nofollow noopener noreferrer">PakBBQ: A Culturally Adapted Bias Benchmark for QA</a>  #106 PakBBQï¼šé’ˆå¯¹é—®ç­”çš„æ–‡åŒ–é€‚é…åè§åŸºå‡†</h2>
<p><strong>Authors</strong>: [Abdullah Hashmat](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abdullah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abdullah</a> Hashmat), [Muhammad Arham Mirza](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhammad</a> Arham Mirza), [Agha Ali Raza](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Agha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Agha</a> Ali Raza)
ä½œè€…ï¼šAbdullah Hashmatã€Muhammad Arham Mirzaã€Agha Ali Raza</p>
<p>With the widespread adoption of Large Language Models (LLMs) across various applications, it is empirical to ensure their fairness across all user communities. However, most LLMs are trained and evaluated on Western centric data, with little attention paid to low-resource languages and regional contexts. To address this gap, we introduce PakBBQ, a culturally and regionally adapted extension of the original Bias Benchmark for Question Answering (BBQ) dataset. PakBBQ comprises over 214 templates, 17180 QA pairs across 8 categories in both English and Urdu, covering eight bias dimensions including age, disability, appearance, gender, socio-economic status, religious, regional affiliation, and language formality that are relevant in Pakistan. We evaluate multiple multilingual LLMs under both ambiguous and explicitly disambiguated contexts, as well as negative versus non negative question framings. Our experiments reveal (i) an average accuracy gain of 12% with disambiguation, (ii) consistently stronger counter bias behaviors in Urdu than in English, and (iii) marked framing effects that reduce stereotypical responses when questions are posed negatively. These findings highlight the importance of contextualized benchmarks and simple prompt engineering strategies for bias mitigation in low resource settings.
éšç€å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§åº”ç”¨ä¸­çš„å¹¿æ³›é‡‡ç”¨ï¼Œç¡®ä¿å®ƒä»¬åœ¨æ‰€æœ‰ç”¨æˆ·ç¾¤ä½“ä¸­çš„å…¬å¹³æ€§æ˜¯ç»éªŒä¸Šå¿…è¦çš„ã€‚ç„¶è€Œï¼Œå¤§å¤šæ•° LLMs æ˜¯åœ¨ä»¥è¥¿æ–¹ä¸ºä¸­å¿ƒçš„æ•°æ®ä¸Šè®­ç»ƒå’Œè¯„ä¼°çš„ï¼Œå¯¹èµ„æºåŒ®ä¹çš„è¯­è¨€å’ŒåŒºåŸŸè¯­å¢ƒå…³æ³¨ç”šå°‘ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼•å…¥äº† PakBBQï¼Œè¿™æ˜¯å¯¹åŸå§‹é—®ç­”åè§åŸºå‡†æ•°æ®é›†ï¼ˆBias Benchmark for Question Answeringï¼ŒBBQï¼‰åœ¨æ–‡åŒ–å’ŒåŒºåŸŸä¸Šé€‚é…çš„æ‰©å±•ã€‚PakBBQ åŒ…å«è¶…è¿‡ 214 ä¸ªæ¨¡æ¿ã€17180 å¯¹é—®ç­”ï¼Œè¦†ç›–è‹±è¯­å’Œä¹Œå°”éƒ½è¯­çš„ 8 ä¸ªç±»åˆ«ï¼Œæ¶‰åŠä¸å·´åŸºæ–¯å¦ç›¸å…³çš„å…«ä¸ªåè§ç»´åº¦ï¼šå¹´é¾„ã€æ®‹ç–¾ã€å¤–è²Œã€æ€§åˆ«ã€ç¤¾ä¼šç»æµåœ°ä½ã€å®—æ•™ã€åœ°åŒºå½’å±å’Œè¯­è¨€ç¤¼è²Œç¨‹åº¦ã€‚æˆ‘ä»¬åœ¨å«ç³Šå’Œæ˜ç¡®æ¶ˆæ­§çš„è¯­å¢ƒä¸‹ï¼Œä»¥åŠæ¶ˆæä¸éæ¶ˆæçš„é—®é¢˜è¡¨è¿°ä¸‹ï¼Œè¯„ä¼°äº†å¤šç§å¤šè¯­ç§ LLMsã€‚æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼š(i) é€šè¿‡æ¶ˆæ­§å¹³å‡å‡†ç¡®ç‡æé«˜äº† 12%ï¼›(ii) ä¹Œå°”éƒ½è¯­åœ¨ååè§è¡Œä¸ºä¸Šå§‹ç»ˆæ¯”è‹±è¯­æ›´å¼ºï¼›(iii) é—®é¢˜ä»¥æ¶ˆææ–¹å¼æå‡ºæ—¶å­˜åœ¨æ˜¾è‘—çš„æ¡†æ¶æ•ˆåº”ï¼Œä¼šå‡å°‘åˆ»æ¿åŒ–çš„å›ç­”ã€‚ è¿™äº›å‘ç°å¼ºè°ƒäº†åœ¨èµ„æºç¨€ç¼ºç¯å¢ƒä¸­é‡‡ç”¨è¯­å¢ƒåŒ–åŸºå‡†å’Œç®€å•æç¤ºå·¥ç¨‹ç­–ç•¥æ¥å‡è½»åè§çš„é‡è¦æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">Computers and Society</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—æœºä¸ç¤¾ä¼šã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-13 20:42:44 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-13 20:42:44 UTC</p>
<h2 id="107-laajmeter-a-framework-for-laaj-evaluation--107-laajmeterç”¨äº-laaj-è¯„ä¼°çš„æ¡†æ¶"><a href="https://arxiv.org/abs/2508.10161"target="_blank" rel="external nofollow noopener noreferrer">#107</a> <a href="https://papers.cool/arxiv/2508.10161"target="_blank" rel="external nofollow noopener noreferrer">LaajMeter: A Framework for LaaJ Evaluation</a>  #107 LaajMeterï¼šç”¨äº LaaJ è¯„ä¼°çš„æ¡†æ¶</h2>
<p><strong>Authors</strong>: [Gal Amram](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gal</a> Amram), [Eitan Farchi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eitan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eitan</a> Farchi), [Shmulik Froimovich](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shmulik"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shmulik</a> Froimovich), [Raviv Gal](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raviv"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raviv</a> Gal), [Avi Ziv](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Avi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Avi</a> Ziv)
ä½œè€…ï¼šGal Amramã€Eitan Farchiã€Shmulik Froimovichã€Raviv Galã€Avi Ziv</p>
<p>Large Language Models (LLMs) are increasingly used as evaluators in natural language processing tasks, a paradigm known as LLM-as-a-Judge (LaaJ). While effective in general domains, LaaJs pose significant challenges in domain-specific contexts, where annotated data is scarce and expert evaluation is costly. In such cases, meta-evaluation is often performed using metrics that have not been validated for the specific domain in which they are applied. As a result, it becomes difficult to determine which metrics effectively identify LaaJ quality, and further, what threshold indicates sufficient evaluator performance. In this work, we introduce LaaJMeter, a simulation-based framework for controlled meta-evaluation of LaaJs. LaaJMeter enables engineers to generate synthetic data representing virtual models and judges, allowing systematic analysis of evaluation metrics under realistic conditions. This helps practitioners validate and refine LaaJs for specific evaluation tasks: they can test whether their metrics correctly distinguish between better and worse (virtual) LaaJs, and estimate appropriate thresholds for evaluator adequacy. We demonstrate the utility of LaaJMeter in a code translation task involving a legacy programming language, showing how different metrics vary in sensitivity to evaluator quality. Our results highlight the limitations of common metrics and the importance of principled metric selection. LaaJMeter provides a scalable and extensible solution for assessing LaaJs in low-resource settings, contributing to the broader effort to ensure trustworthy and reproducible evaluation in NLP.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ­£è¶Šæ¥è¶Šå¤šåœ°è¢«ç”¨ä½œè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸­çš„è¯„ä¼°è€…ï¼Œè¿™ä¸€èŒƒå¼è¢«ç§°ä¸º LLM-as-a-Judgeï¼ˆLaaJï¼‰ã€‚å°½ç®¡åœ¨ä¸€èˆ¬é¢†åŸŸä¸­æ­¤æ–¹æ³•æœ‰æ•ˆï¼ŒLaaJ åœ¨ç‰¹å®šé¢†åŸŸæƒ…å¢ƒä¸‹å´å¸¦æ¥äº†é‡å¤§æŒ‘æˆ˜ï¼Œå› ä¸ºè¯¥æƒ…å¢ƒä¸‹æ ‡æ³¨æ•°æ®ç¨€ç¼ºä¸”ä¸“å®¶è¯„ä¼°ä»£ä»·é«˜æ˜‚ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå…ƒè¯„ä¼°é€šå¸¸ä½¿ç”¨å°šæœªåœ¨æ‰€åº”ç”¨çš„ç‰¹å®šé¢†åŸŸä¸­éªŒè¯çš„åº¦é‡æ ‡å‡†æ¥è¿›è¡Œã€‚å› æ­¤ï¼Œéš¾ä»¥ç¡®å®šå“ªäº›åº¦é‡èƒ½æœ‰æ•ˆè¯†åˆ« LaaJ çš„è´¨é‡ï¼Œå¹¶è¿›ä¸€æ­¥ç¡®å®šä½•ç§é˜ˆå€¼è¡¨æ˜è¯„ä¼°è€…è¡¨ç°è¶³å¤Ÿå¥½ã€‚åœ¨æœ¬å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† LaaJMeterï¼Œä¸€ç§ç”¨äºå¯¹ LaaJ è¿›è¡Œå—æ§å…ƒè¯„ä¼°çš„åŸºäºä»¿çœŸçš„æ¡†æ¶ã€‚LaaJMeter ä½¿å·¥ç¨‹å¸ˆèƒ½å¤Ÿç”Ÿæˆä»£è¡¨è™šæ‹Ÿæ¨¡å‹å’Œè¯„åˆ¤è€…çš„åˆæˆæ•°æ®ï¼Œä»è€Œåœ¨ç°å®æ¡ä»¶ä¸‹å¯¹è¯„ä¼°åº¦é‡è¿›è¡Œç³»ç»Ÿåˆ†æã€‚è¿™æœ‰åŠ©äºä»ä¸šè€…ä¸ºç‰¹å®šè¯„ä¼°ä»»åŠ¡éªŒè¯å’Œæ”¹è¿› LaaJï¼šä»–ä»¬å¯ä»¥æµ‹è¯•å…¶åº¦é‡æ˜¯å¦èƒ½æ­£ç¡®åŒºåˆ†æ›´å¥½ä¸æ›´å·®çš„ï¼ˆè™šæ‹Ÿï¼‰LaaJï¼Œå¹¶ä¼°ç®—è¯„ä¼°è€…æ˜¯å¦è¶³å¤Ÿçš„é€‚å½“é˜ˆå€¼ã€‚ æˆ‘ä»¬å±•ç¤ºäº† LaaJMeter åœ¨ä¸€ä¸ªæ¶‰åŠé—ç•™ç¼–ç¨‹è¯­è¨€çš„ä»£ç ç¿»è¯‘ä»»åŠ¡ä¸­çš„å®ç”¨æ€§ï¼Œè¯´æ˜äº†ä¸åŒè¯„ä»·æŒ‡æ ‡åœ¨å¯¹è¯„ä¼°è€…è´¨é‡çš„æ•æ„Ÿæ€§ä¸Šå¦‚ä½•æœ‰æ‰€ä¸åŒã€‚æˆ‘ä»¬çš„ç»“æœçªå‡ºäº†å¸¸ç”¨æŒ‡æ ‡çš„å±€é™æ€§ä»¥åŠåŸåˆ™æ€§é€‰æ‹©æŒ‡æ ‡çš„é‡è¦æ€§ã€‚LaaJMeter ä¸ºåœ¨èµ„æºåŒ®ä¹ç¯å¢ƒä¸­è¯„ä¼° LaaJs æä¾›äº†å¯æ‰©å±•ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆï¼Œæœ‰åŠ©äºæ›´å¹¿æ³›åœ°ç¡®ä¿ NLP é¢†åŸŸçš„å¯ä¿¡å’Œå¯é‡å¤çš„è¯„ä¼°å·¥ä½œã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 19:51:05 UTC
å‘å¸ƒï¼š2025-08-13 19:51:05 UTC</p>
<h2 id="108-improving-watermelon-citrullus-lanatus-disease-classification-with-generative-artificial-intelligence-genai-based-synthetic-and-real-field-images-via-a-custom-efficientnetv2-l-model--108-ä½¿ç”¨åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½genaiçš„åˆæˆä¸çœŸå®ç”°é—´å›¾åƒé€šè¿‡å®šåˆ¶-efficientnetv2-l-æ¨¡å‹æ”¹è¿›è¥¿ç“œcitrullus-lanatusç—…å®³åˆ†ç±»"><a href="https://arxiv.org/abs/2508.10156"target="_blank" rel="external nofollow noopener noreferrer">#108</a> <a href="https://papers.cool/arxiv/2508.10156"target="_blank" rel="external nofollow noopener noreferrer">Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model</a>  #108 ä½¿ç”¨åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenAIï¼‰çš„åˆæˆä¸çœŸå®ç”°é—´å›¾åƒé€šè¿‡å®šåˆ¶ EfficientNetV2-L æ¨¡å‹æ”¹è¿›è¥¿ç“œï¼ˆCitrullus lanatusï¼‰ç—…å®³åˆ†ç±»</h2>
<p><strong>Authors</strong>: [Nitin Rai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nitin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nitin</a> Rai), [Nathan S. Boyd](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nathan</a> S. Boyd), [Gary E. Vallad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gary"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gary</a> E. Vallad), [Arnold W. Schumann](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arnold"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arnold</a> W. Schumann)
ä½œè€…ï¼šNitin Rai, Nathan S. Boyd, Gary E. Vallad, Arnold W. Schumann</p>
<p>The current advancements in generative artificial intelligence (GenAI) models have paved the way for new possibilities for generating high-resolution synthetic images, thereby offering a promising alternative to traditional image acquisition for training computer vision models in agriculture. In the context of crop disease diagnosis, GenAI models are being used to create synthetic images of various diseases, potentially facilitating model creation and reducing the dependency on resource-intensive in-field data collection. However, limited research has been conducted on evaluating the effectiveness of integrating real with synthetic images to improve disease classification performance. Therefore, this study aims to investigate whether combining a limited number of real images with synthetic images can enhance the prediction accuracy of an EfficientNetV2-L model for classifying watermelon \textit{(Citrullus lanatus)} diseases. The training dataset was divided into five treatments: H0 (only real images), H1 (only synthetic images), H2 (1:1 real-to-synthetic), H3 (1:10 real-to-synthetic), and H4 (H3 + random images to improve variability and model generalization). All treatments were trained using a custom EfficientNetV2-L architecture with enhanced fine-tuning and transfer learning techniques. Models trained on H2, H3, and H4 treatments demonstrated high precision, recall, and F1-score metrics. Additionally, the weighted F1-score increased from 0.65 (on H0) to 1.00 (on H3-H4) signifying that the addition of a small number of real images with a considerable volume of synthetic images improved model performance and generalizability. Overall, this validates the findings that synthetic images alone cannot adequately substitute for real images; instead, both must be used in a hybrid manner to maximize model performance for crop disease classification.
å½“å‰ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenAIï¼‰æ¨¡å‹çš„è¿›æ­¥ä¸ºç”Ÿæˆé«˜åˆ†è¾¨ç‡åˆæˆå›¾åƒå¼€è¾Ÿäº†æ–°é€”å¾„ï¼Œä»è€Œä¸ºåœ¨å†œä¸šä¸­è®­ç»ƒè®¡ç®—æœºè§†è§‰æ¨¡å‹æä¾›äº†æ›¿ä»£ä¼ ç»Ÿå›¾åƒé‡‡é›†çš„æœ‰å¸Œæœ›æ–¹æ³•ã€‚åœ¨ä½œç‰©ç—…å®³è¯Šæ–­çš„èƒŒæ™¯ä¸‹ï¼ŒGenAI æ¨¡å‹è¢«ç”¨äºåˆ›å»ºå„ç§ç—…å®³çš„åˆæˆå›¾åƒï¼Œå¯èƒ½æœ‰åŠ©äºæ¨¡å‹æ„å»ºå¹¶å‡å°‘å¯¹è€—è´¹èµ„æºçš„ç”°é—´æ•°æ®é‡‡é›†çš„ä¾èµ–ã€‚ç„¶è€Œï¼Œå…³äºè¯„ä¼°å°†çœŸå®å›¾åƒä¸åˆæˆå›¾åƒç›¸ç»“åˆä»¥æé«˜ç—…å®³åˆ†ç±»æ€§èƒ½çš„æœ‰æ•ˆæ€§çš„ç ”ç©¶ä»ç„¶æœ‰é™ã€‚å› æ­¤ï¼Œæœ¬ç ”ç©¶æ—¨åœ¨æ¢è®¨å°†å°‘é‡çœŸå®å›¾åƒä¸åˆæˆå›¾åƒç»“åˆæ˜¯å¦èƒ½å¤Ÿæé«˜ EfficientNetV2-L æ¨¡å‹å¯¹è¥¿ç“œï¼ˆCitrullus lanatusï¼‰ç—…å®³åˆ†ç±»çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚è®­ç»ƒæ•°æ®é›†è¢«åˆ†ä¸ºäº”ç§å¤„ç†ï¼šH0ï¼ˆä»…çœŸå®å›¾åƒï¼‰ã€H1ï¼ˆä»…åˆæˆå›¾åƒï¼‰ã€H2ï¼ˆçœŸå®ä¸åˆæˆ 1:1ï¼‰ã€H3ï¼ˆçœŸå®ä¸åˆæˆ 1:10ï¼‰ä»¥åŠ H4ï¼ˆH3 + éšæœºå›¾åƒä»¥æé«˜å˜å¼‚æ€§å’Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›ï¼‰ã€‚ æ‰€æœ‰å¤„ç†å‡ä½¿ç”¨è‡ªå®šä¹‰çš„ EfficientNetV2-L æ¶æ„è¿›è¡Œè®­ç»ƒï¼Œé‡‡ç”¨äº†å¢å¼ºçš„å¾®è°ƒå’Œè¿ç§»å­¦ä¹ æŠ€æœ¯ã€‚åœ¨ H2ã€H3 å’Œ H4 å¤„ç†ä¸Šè®­ç»ƒçš„æ¨¡å‹æ˜¾ç¤ºå‡ºé«˜ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œ F1 åˆ†æ•°ã€‚æ­¤å¤–ï¼ŒåŠ æƒ F1 åˆ†æ•°ä» 0.65ï¼ˆåœ¨ H0 ä¸Šï¼‰æé«˜åˆ° 1.00ï¼ˆåœ¨ H3â€“H4 ä¸Šï¼‰ï¼Œè¿™è¡¨æ˜åœ¨å¤§é‡åˆæˆå›¾åƒçš„åŸºç¡€ä¸ŠåŠ å…¥å°‘é‡çœŸå®å›¾åƒèƒ½å¤Ÿæå‡æ¨¡å‹æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ€»ä½“è€Œè¨€ï¼Œè¿™éªŒè¯äº†å•é åˆæˆå›¾åƒæ— æ³•å……åˆ†æ›¿ä»£çœŸå®å›¾åƒçš„ç»“è®ºï¼›ç›¸åï¼Œå¿…é¡»ä»¥æ··åˆæ–¹å¼åŒæ—¶ä½¿ç”¨ä¸¤è€…ä»¥æœ€å¤§åŒ–ä½œç‰©ç—…å®³åˆ†ç±»æ¨¡å‹çš„æ€§èƒ½ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.ET"target="_blank" rel="external nofollow noopener noreferrer">Emerging Technologies</a>
ä¸»é¢˜ï¼šè®¡ç®—æœºè§†è§‰ä¸æ¨¡å¼è¯†åˆ«ã€äººå·¥æ™ºèƒ½ã€æ–°å…´æŠ€æœ¯</p>
<p><strong>Publish</strong>: 2025-08-13 19:39:39 UTC
å‘å¸ƒï¼š2025-08-13 19:39:39 UTC</p>
<h2 id="109-out-of-distribution-detection-using-counterfactual-distance--109-ä½¿ç”¨åäº‹å®è·ç¦»çš„åˆ†å¸ƒå¤–æ£€æµ‹-pdf-1--å¤åˆ¶-kimi--å…³è”"><a href="https://arxiv.org/abs/2508.10148"target="_blank" rel="external nofollow noopener noreferrer">#109</a> <a href="https://papers.cool/arxiv/2508.10148"target="_blank" rel="external nofollow noopener noreferrer">Out-of-Distribution Detection using Counterfactual Distance</a>  #109 ä½¿ç”¨åäº‹å®è·ç¦»çš„åˆ†å¸ƒå¤–æ£€æµ‹ [PDF 1 ] [å¤åˆ¶] [Kimi ] [å…³è”]</h2>
<p><strong>Authors</strong>: [Maria Stoica](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maria"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maria</a> Stoica), [Francesco Leofante](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Francesco"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Francesco</a> Leofante), [Alessio Lomuscio](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Alessio"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Alessio</a> Lomuscio)
ä½œè€…ï¼šMaria Stoicaã€Francesco Leofanteã€Alessio Lomuscio</p>
<p>Accurate and explainable out-of-distribution (OOD) detection is required to use machine learning systems safely. Previous work has shown that feature distance to decision boundaries can be used to identify OOD data effectively. In this paper, we build on this intuition and propose a post-hoc OOD detection method that, given an input, calculates the distance to decision boundaries by leveraging counterfactual explanations. Since computing explanations can be expensive for large architectures, we also propose strategies to improve scalability by computing counterfactuals directly in embedding space. Crucially, as the method employs counterfactual explanations, we can seamlessly use them to help interpret the results of our detector. We show that our method is in line with the state of the art on CIFAR-10, achieving 93.50% AUROC and 25.80% FPR95. Our method outperforms these methods on CIFAR-100 with 97.05% AUROC and 13.79% FPR95 and on ImageNet-200 with 92.55% AUROC and 33.55% FPR95 across four OOD datasets
ä¸ºäº†å®‰å…¨ä½¿ç”¨æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼Œéœ€è¦å‡†ç¡®ä¸”å¯è§£é‡Šçš„åˆ†å¸ƒå¤–ï¼ˆOODï¼‰æ£€æµ‹ã€‚ä»¥å¾€å·¥ä½œè¡¨æ˜ï¼Œç‰¹å¾åˆ°å†³ç­–è¾¹ç•Œçš„è·ç¦»å¯æœ‰æ•ˆç”¨äºè¯†åˆ« OOD æ•°æ®ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åŸºäºè¿™ä¸€ç›´è§‰æå‡ºäº†ä¸€ç§äº‹åï¼ˆpost-hocï¼‰OOD æ£€æµ‹æ–¹æ³•ï¼šå¯¹äºç»™å®šè¾“å…¥ï¼Œé€šè¿‡åˆ©ç”¨åäº‹å®è§£é‡Šæ¥è®¡ç®—ä¸å†³ç­–è¾¹ç•Œçš„è·ç¦»ã€‚ç”±äºå¯¹å¤§å‹æ¶æ„è®¡ç®—è§£é‡Šå¯èƒ½ä»£ä»·é«˜æ˜‚ï¼Œæˆ‘ä»¬è¿˜æå‡ºäº†é€šè¿‡åœ¨åµŒå…¥ç©ºé—´ä¸­ç›´æ¥è®¡ç®—åäº‹å®æ¥æé«˜å¯æ‰©å±•æ€§çš„ç­–ç•¥ã€‚å…³é”®åœ¨äºï¼Œç”±äºè¯¥æ–¹æ³•é‡‡ç”¨åäº‹å®è§£é‡Šï¼Œæˆ‘ä»¬å¯ä»¥æ— ç¼åœ°åˆ©ç”¨å®ƒä»¬æ¥å¸®åŠ©è§£é‡Šæ£€æµ‹å™¨çš„ç»“æœã€‚æˆ‘ä»¬å±•ç¤ºäº†è¯¥æ–¹æ³•åœ¨ CIFAR-10 ä¸Šä¸æœ€æ–°æ–¹æ³•ä¿æŒä¸€è‡´ï¼Œè¾¾åˆ° 93.50% AUROC å’Œ 25.80% FPR95ã€‚åœ¨ CIFAR-100 ä¸Šæˆ‘ä»¬çš„æ–¹æ³•ä¼˜äºè¿™äº›æ–¹æ³•ï¼Œå–å¾—äº† 97.05% AUROC å’Œ 13.79% FPR95ï¼›åœ¨ ImageNet-200 ä¸Šï¼Œåœ¨å››ä¸ª OOD æ•°æ®é›†ä¸Šå–å¾—äº† 92.55% AUROC å’Œ 33.55% FPR95ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 19:17:05 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-13 19:17:05 UTC</p>
<h2 id="110-retf-semisl-semi-supervised-learning-for-neural-collapse-in-temporal-data--110-retf-semislç”¨äºæ—¶é—´æ•°æ®ä¸­ç¥ç»å¡Œç¼©çš„åŠç›‘ç£å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10147"target="_blank" rel="external nofollow noopener noreferrer">#110</a> <a href="https://papers.cool/arxiv/2508.10147"target="_blank" rel="external nofollow noopener noreferrer">rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data</a>  #110 rETF-semiSLï¼šç”¨äºæ—¶é—´æ•°æ®ä¸­ç¥ç»å¡Œç¼©çš„åŠç›‘ç£å­¦ä¹ </h2>
<p><strong>Authors</strong>: [Yuhan Xie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuhan</a> Xie), [William Cappelletti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=William"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=William</a> Cappelletti), [Mahsa Shoaran](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mahsa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mahsa</a> Shoaran), [Pascal Frossard](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pascal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pascal</a> Frossard)
ä½œè€…ï¼šè°¢å®‡æ¶µï¼ˆYuhan Xieï¼‰ã€William Cappellettiã€Mahsa Shoaranã€Pascal Frossard</p>
<p>Deep neural networks for time series must capture complex temporal patterns, to effectively represent dynamic data. Self- and semi-supervised learning methods show promising results in pre-training large models, which &ndash; when finetuned for classification &ndash; often outperform their counterparts trained from scratch. Still, the choice of pretext training tasks is often heuristic and their transferability to downstream classification is not granted, thus we propose a novel semi-supervised pre-training strategy to enforce latent representations that satisfy the Neural Collapse phenomenon observed in optimally trained neural classifiers. We use a rotational equiangular tight frame-classifier and pseudo-labeling to pre-train deep encoders with few labeled samples. Furthermore, to effectively capture temporal dynamics while enforcing embedding separability, we integrate generative pretext tasks with our method, and we define a novel sequential augmentation strategy. We show that our method significantly outperforms previous pretext tasks when applied to LSTMs, transformers, and state-space models on three multivariate time series classification datasets. These results highlight the benefit of aligning pre-training objectives with theoretically grounded embedding geometry.
æ—¶é—´åºåˆ—çš„æ·±åº¦ç¥ç»ç½‘ç»œå¿…é¡»æ•æ‰å¤æ‚çš„æ—¶é—´æ¨¡å¼ï¼Œä»¥æœ‰æ•ˆè¡¨ç¤ºåŠ¨æ€æ•°æ®ã€‚è‡ªç›‘ç£å’ŒåŠç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨å¤§æ¨¡å‹çš„é¢„è®­ç»ƒä¸­å±•ç°å‡ºæœ‰å¸Œæœ›çš„ç»“æœâ€”â€”è¿™äº›æ¨¡å‹åœ¨å¾®è°ƒç”¨äºåˆ†ç±»æ—¶ï¼Œå¾€å¾€ä¼˜äºä»å¤´è®­ç»ƒçš„å¯¹åº”æ¨¡å‹ã€‚ç„¶è€Œï¼Œå‰ç½®è®­ç»ƒä»»åŠ¡çš„é€‰æ‹©å¾€å¾€å…·æœ‰å¯å‘æ€§ï¼Œå…¶å¯¹ä¸‹æ¸¸åˆ†ç±»ä»»åŠ¡çš„å¯è¿ç§»æ€§å¹¶ä¸ç¡®å®šã€‚å› æ­¤æˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„åŠç›‘ç£é¢„è®­ç»ƒç­–ç•¥ï¼Œä»¥å¼ºåˆ¶æ½œåœ¨è¡¨ç¤ºæ»¡è¶³åœ¨æœ€ä¼˜è®­ç»ƒçš„ç¥ç»åˆ†ç±»å™¨ä¸­è§‚å¯Ÿåˆ°çš„ç¥ç»å¡Œç¼©ï¼ˆNeural Collapseï¼‰ç°è±¡ã€‚æˆ‘ä»¬ä½¿ç”¨æ—‹è½¬ç­‰è§’ç´§æ¡†æ¶ï¼ˆrotational equiangular tight frameï¼‰åˆ†ç±»å™¨å’Œä¼ªæ ‡ç­¾ï¼Œåœ¨å°‘é‡æ ‡æ³¨æ ·æœ¬ä¸‹é¢„è®­ç»ƒæ·±åº¦ç¼–ç å™¨ã€‚æ­¤å¤–ï¼Œä¸ºäº†åœ¨å¼ºåˆ¶åµŒå…¥å¯åˆ†ç¦»æ€§çš„åŒæ—¶æœ‰æ•ˆæ•æ‰æ—¶é—´åŠ¨æ€ï¼Œæˆ‘ä»¬å°†ç”Ÿæˆå¼å‰ç½®ä»»åŠ¡ä¸æˆ‘ä»¬çš„æ–¹æ³•ç»“åˆï¼Œå¹¶å®šä¹‰äº†ä¸€ç§æ–°é¢–çš„åºåˆ—å¢å¼ºç­–ç•¥ã€‚æˆ‘ä»¬å±•ç¤ºäº†åœ¨ä¸‰ä¸ªå¤šå˜é‡æ—¶é—´åºåˆ—åˆ†ç±»æ•°æ®é›†ä¸Šï¼Œå°†æœ¬æ–¹æ³•åº”ç”¨äº LSTMã€transformer å’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹æ—¶ï¼Œæ˜¾è‘—ä¼˜äºä»¥å¾€çš„å‰ç½®ä»»åŠ¡ã€‚ è¿™äº›ç»“æœçªå‡ºäº†å°†é¢„è®­ç»ƒç›®æ ‡ä¸ç†è®ºæ”¯æ’‘çš„åµŒå…¥å‡ ä½•å¯¹é½çš„ç›Šå¤„ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 19:16:47 UTC
å‘å¸ƒï¼š2025-08-13 19:16:47 UTC</p>
<h2 id="111-mscore-a-multilingual-and-scalable-benchmark-for-skill-based-commonsense-reasoning--111mscoreä¸€ä¸ª-m-å¤šè¯­ç§ä¸”å¯æ‰©å±•çš„åŸºå‡†ç”¨äº-s-åŸºäºæŠ€èƒ½çš„-co-æ— æ„ä¹‰-re-æ¨ç†"><a href="https://arxiv.org/abs/2508.10137"target="_blank" rel="external nofollow noopener noreferrer">#111</a> <a href="https://papers.cool/arxiv/2508.10137"target="_blank" rel="external nofollow noopener noreferrer">mSCoRe: a Multilingual and Scalable Benchmark for Skill-based Commonsense Reasoning</a>  #111mSCoReï¼šä¸€ä¸ª M å¤šè¯­ç§ä¸”å¯æ‰©å±•çš„åŸºå‡†ï¼Œç”¨äº S åŸºäºæŠ€èƒ½çš„ Co æ— æ„ä¹‰ Re æ¨ç†</h2>
<p><strong>Authors</strong>: [Nghia Trung Ngo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nghia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nghia</a> Trung Ngo), [Franck Dernoncourt](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Franck"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Franck</a> Dernoncourt), [Thien Huu Nguyen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Thien"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Thien</a> Huu Nguyen)
ä½œè€…ï¼šNghia Trung Ngoã€Franck Dernoncourtã€Thien Huu Nguyen</p>
<p>Recent advancements in reasoning-reinforced Large Language Models (LLMs) have shown remarkable capabilities in complex reasoning tasks. However, the mechanism underlying their utilization of different human reasoning skills remains poorly investigated, especially for multilingual commonsense reasoning that involves everyday knowledge across different languages and cultures. To address this gap, we propose a \textbf{M}ultilingual and Scalable Benchmark for \textbf{S}kill-based \textbf{Co}mmonsense \textbf{Re}asoning (\textbf{mSCoRe}). Our benchmark incorporates three key components that are designed to systematically evaluate LLM&rsquo;s reasoning capabilities, including: (1) a novel taxonomy of reasoning skills that enables fine-grained analysis of models&rsquo; reasoning processes, (2) a robust data synthesis pipeline tailored specifically for commonsense reasoning evaluation, and (3) a complexity scaling framework allowing task difficulty to scale dynamically alongside future improvements in LLM abilities. Extensive experiments on eights state-of-the-art LLMs of varying sizes and training approaches demonstrate that \textbf{mSCoRe} remains significantly challenging for current models, particularly at higher complexity levels. Our results reveal the limitations of such reasoning-reinforced models when confronted with nuanced multilingual general and cultural commonsense. We further provide detailed analysis on the models&rsquo; reasoning processes, suggesting future directions for improving multilingual commonsense reasoning capabilities.
è¿‘å¹´æ¥ï¼Œå¼ºåŒ–æ¨ç†èƒ½åŠ›çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šå±•ç°å‡ºæ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œå®ƒä»¬å¦‚ä½•åˆ©ç”¨ä¸åŒçš„äººç±»æ¨ç†æŠ€èƒ½çš„æœºåˆ¶å°šæœªè¢«å……åˆ†ç ”ç©¶ï¼Œç‰¹åˆ«æ˜¯æ¶‰åŠè·¨è¯­è¨€å’Œè·¨æ–‡åŒ–çš„æ—¥å¸¸å¸¸è¯†æ¨ç†ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šè¯­ç§ä¸”å¯æ‰©å±•çš„åŸºäºæŠ€èƒ½çš„å¸¸è¯†æ¨ç†åŸºå‡†ï¼ˆmSCoReï¼‰ã€‚æˆ‘ä»¬çš„åŸºå‡†åŒ…å«ä¸‰ä¸ªå…³é”®ç»„ä»¶ï¼Œæ—¨åœ¨ç³»ç»Ÿåœ°è¯„ä¼° LLM çš„æ¨ç†èƒ½åŠ›ï¼ŒåŒ…æ‹¬ï¼š (1) ä¸€ç§æ–°é¢–çš„æ¨ç†æŠ€èƒ½åˆ†ç±»æ³•ï¼Œèƒ½å¤Ÿå¯¹æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹è¿›è¡Œç»†ç²’åº¦åˆ†æï¼Œ(2) ä¸€ä¸ªä¸“ä¸ºå¸¸è¯†æ¨ç†è¯„ä¼°é‡èº«å®šåˆ¶çš„ç¨³å¥æ•°æ®åˆæˆæµç¨‹ï¼Œ(3) ä¸€ä¸ªå¤æ‚æ€§å¯æ‰©å±•æ¡†æ¶ï¼Œå…è®¸ä»»åŠ¡éš¾åº¦éšç€æœªæ¥ LLM èƒ½åŠ›çš„æå‡è€ŒåŠ¨æ€æ‰©å±•ã€‚ åœ¨å¯¹å…«ç§ä¸åŒè§„æ¨¡å’Œè®­ç»ƒæ–¹æ³•çš„æœ€å…ˆè¿› LLMs è¿›è¡Œçš„å¤§é‡å®éªŒä¸­è¡¨æ˜ï¼Œ\textbf{mSCoRe} å¯¹å½“å‰æ¨¡å‹ä»ç„¶å…·æœ‰æ˜¾è‘—æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨æ›´é«˜å¤æ‚åº¦çº§åˆ«æ—¶ã€‚æˆ‘ä»¬çš„ç»“æœæ­ç¤ºäº†åœ¨é¢å¯¹ç»†å¾®çš„å¤šè¯­è¨€é€šç”¨ä¸æ–‡åŒ–å¸¸è¯†æ—¶ï¼Œè¿™ç±»ä»¥æ¨ç†å¼ºåŒ–çš„æ¨¡å‹çš„å±€é™æ€§ã€‚æˆ‘ä»¬è¿˜å¯¹æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹è¿›è¡Œäº†è¯¦ç»†åˆ†æï¼Œå¹¶æå‡ºäº†æ”¹è¿›å¤šè¯­è¨€å¸¸è¯†æ¨ç†èƒ½åŠ›çš„æœªæ¥æ–¹å‘ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 18:59:02 UTC
å‘å¸ƒï¼š2025-08-13 18:59:02 UTC</p>
<h2 id="112-nested-reft-efficient-reinforcement-learning-for-large-language-model-fine-tuning-via-off-policy-rollouts--112-åµŒå¥—-refté€šè¿‡ç¦»ç­–ç•¥å›åˆå®ç°é¢å‘å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒçš„é«˜æ•ˆå¼ºåŒ–å­¦ä¹ "><a href="https://arxiv.org/abs/2508.10123"target="_blank" rel="external nofollow noopener noreferrer">#112</a> <a href="https://papers.cool/arxiv/2508.10123"target="_blank" rel="external nofollow noopener noreferrer">Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts</a>  #112 åµŒå¥—-ReFTï¼šé€šè¿‡ç¦»ç­–ç•¥å›åˆå®ç°é¢å‘å¤§å‹è¯­è¨€æ¨¡å‹å¾®è°ƒçš„é«˜æ•ˆå¼ºåŒ–å­¦ä¹ </h2>
<p><strong>Authors</strong>: [Maxime Heuillet](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maxime"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maxime</a> Heuillet), [Yufei Cui](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yufei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yufei</a> Cui), [Boxing Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Boxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Boxing</a> Chen), [Audrey Durand](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Audrey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Audrey</a> Durand), [Prasanna Parthasarathi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Prasanna"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Prasanna</a> Parthasarathi)
ä½œè€…ï¼šMaxime Heuilletã€Yufei Cuiã€Boxing Chenã€Audrey Durandã€Prasanna Parthasarathi</p>
<p>Advanced reasoning in LLMs on challenging domains like mathematical reasoning can be tackled using verifiable rewards based reinforced fine-tuning (ReFT). In standard ReFT frameworks, a behavior model generates multiple completions with answers per problem, for the answer to be then scored by a reward function. While such RL post-training methods demonstrate significant performance improvements across challenging reasoning domains, the computational cost of generating completions during training with multiple inference steps makes the training cost non-trivial. To address this, we draw inspiration from off-policy RL, and speculative decoding to introduce a novel ReFT framework, dubbed Nested-ReFT, where a subset of layers of the target model acts as the behavior model to generate off-policy completions during training. The behavior model configured with dynamic layer skipping per batch during training decreases the inference cost compared to the standard ReFT frameworks. Our theoretical analysis shows that Nested-ReFT yields unbiased gradient estimates with controlled variance. Our empirical analysis demonstrates improved computational efficiency measured as tokens/sec across multiple math reasoning benchmarks and model sizes. Additionally, we explore three variants of bias mitigation to minimize the off-policyness in the gradient updates that allows for maintaining performance that matches the baseline ReFT performance.
åœ¨åƒæ•°å­¦æ¨ç†è¿™æ ·å…·æœ‰æŒ‘æˆ˜æ€§çš„é¢†åŸŸä¸­ï¼Œé’ˆå¯¹ LLMs çš„é«˜çº§æ¨ç†å¯ä»¥é€šè¿‡å¯éªŒè¯å¥–åŠ±çš„åŸºäºå¼ºåŒ–çš„å¾®è°ƒï¼ˆReFTï¼‰æ¥è§£å†³ã€‚åœ¨æ ‡å‡†çš„ ReFT æ¡†æ¶ä¸­ï¼Œè¡Œä¸ºæ¨¡å‹é’ˆå¯¹æ¯ä¸ªé—®é¢˜ç”Ÿæˆå¤šä¸ªå¸¦ç­”æ¡ˆçš„å®Œæˆç»“æœï¼Œç„¶åç”±å¥–åŠ±å‡½æ•°å¯¹ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ã€‚å°½ç®¡æ­¤ç±»å¼ºåŒ–å­¦ä¹ åè®­ç»ƒæ–¹æ³•åœ¨å›°éš¾æ¨ç†é¢†åŸŸå±•ç¤ºäº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼Œä½†åœ¨è®­ç»ƒæœŸé—´ä½¿ç”¨å¤šæ¬¡æ¨ç†æ­¥éª¤ç”Ÿæˆå®Œæˆç»“æœçš„è®¡ç®—æˆæœ¬ä½¿è®­ç»ƒå¼€é”€å˜å¾—ä¸å®¹å¿½è§†ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬ä»ç¦»ç­–ç•¥å¼ºåŒ–å­¦ä¹ å’Œæ¨æµ‹æ€§è§£ç ä¸­è·å¾—çµæ„Ÿï¼Œæå‡ºäº†ä¸€ç§æ–°çš„ ReFT æ¡†æ¶ï¼Œç§°ä¸º Nested-ReFTï¼Œå…¶ä¸­ç›®æ ‡æ¨¡å‹çš„éƒ¨åˆ†å±‚å……å½“è¡Œä¸ºæ¨¡å‹ï¼Œåœ¨è®­ç»ƒæœŸé—´ç”Ÿæˆç¦»ç­–ç•¥çš„å®Œæˆç»“æœã€‚è¯¥è¡Œä¸ºæ¨¡å‹åœ¨è®­ç»ƒæ—¶é’ˆå¯¹æ¯ä¸ªæ‰¹æ¬¡é…ç½®åŠ¨æ€è·³å±‚ï¼Œä¸æ ‡å‡† ReFT æ¡†æ¶ç›¸æ¯”é™ä½äº†æ¨ç†æˆæœ¬ã€‚æˆ‘ä»¬çš„ç†è®ºåˆ†æè¡¨æ˜ï¼ŒNested-ReFT åœ¨æ–¹å·®å—æ§çš„æƒ…å†µä¸‹äº§ç”Ÿæ— åçš„æ¢¯åº¦ä¼°è®¡ã€‚ æˆ‘ä»¬çš„å®è¯åˆ†æè¡¨æ˜ï¼Œåœ¨å¤šä¸ªæ•°å­¦æ¨ç†åŸºå‡†å’Œä¸åŒæ¨¡å‹è§„æ¨¡ä¸Šï¼Œä»¥ æ¯ç§’æ ‡è®°æ•°ï¼ˆtokens/secï¼‰ è¡¡é‡çš„è®¡ç®—æ•ˆç‡æœ‰æ‰€æå‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æ¢è®¨äº†ä¸‰ç§å‡åå˜ä½“ï¼Œä»¥å°½é‡å‡å°‘æ¢¯åº¦æ›´æ–°ä¸­çš„è„±ç¦»ç­–ç•¥æ€§ï¼ˆoff-policynessï¼‰ï¼Œä»è€Œèƒ½å¤Ÿç»´æŒä¸åŸºçº¿ ReFT æ€§èƒ½ç›¸å½“çš„è¡¨ç°ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-13 18:37:46 UTC
å‘å¸ƒï¼š2025-08-13 18:37:46 UTC</p>
<h2 id="113-less-is-more-learning-graph-tasks-with-just-llms--113-å°‘å³æ˜¯å¤šä»…ç”¨-llms-å­¦ä¹ å›¾ä»»åŠ¡"><a href="https://arxiv.org/abs/2508.10115"target="_blank" rel="external nofollow noopener noreferrer">#113</a> <a href="https://papers.cool/arxiv/2508.10115"target="_blank" rel="external nofollow noopener noreferrer">Less is More: Learning Graph Tasks with Just LLMs</a>  #113 å°‘å³æ˜¯å¤šï¼šä»…ç”¨ LLMs å­¦ä¹ å›¾ä»»åŠ¡</h2>
<p><strong>Authors</strong>: [Sola Shirai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sola"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sola</a> Shirai), [Kavitha Srinivas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kavitha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kavitha</a> Srinivas), [Julian Dolby](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Julian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Julian</a> Dolby), [Michael Katz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> Katz), [Horst Samulowitz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Horst"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Horst</a> Samulowitz), [Shirin Sohrabi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shirin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shirin</a> Sohrabi)
ä½œè€…ï¼šSola Shirai, Kavitha Srinivas, Julian Dolby, Michael Katz, Horst Samulowitz, Shirin Sohrabi</p>
<p>For large language models (LLMs), reasoning over graphs could help solve many problems. Prior work has tried to improve LLM graph reasoning by examining how best to serialize graphs as text and by combining GNNs and LLMs. However, the merits of such approaches remain unclear, so we empirically answer the following research questions: (1) Can LLMs learn to solve fundamental graph tasks without specialized graph encoding models?, (2) Can LLMs generalize learned solutions to unseen graph structures or tasks?, and (3) What are the merits of competing approaches to learn graph tasks? We show that even small LLMs can learn to solve graph tasks by training them with instructive chain-of-thought solutions, and this training generalizes, without specialized graph encoders, to new tasks and graph structures.
å¯¹äºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è€Œè¨€ï¼Œå¯¹å›¾çš„æ¨ç†å¯ä»¥å¸®åŠ©è§£å†³è®¸å¤šé—®é¢˜ã€‚ä»¥å¾€çš„å·¥ä½œè¯•å›¾é€šè¿‡ç ”ç©¶å¦‚ä½•å°†å›¾åºåˆ—åŒ–ä¸ºæ–‡æœ¬ä»¥åŠç»“åˆ GNNs å’Œ LLMs æ¥æ”¹è¿› LLM çš„å›¾æ¨ç†èƒ½åŠ›ã€‚ç„¶è€Œï¼Œæ­¤ç±»æ–¹æ³•çš„ä¼˜åŠ£ä»ä¸æ˜ç¡®ï¼Œå› æ­¤æˆ‘ä»¬é€šè¿‡å®è¯å›ç­”ä»¥ä¸‹ç ”ç©¶é—®é¢˜ï¼š (1) LLMs æ˜¯å¦èƒ½åœ¨æ²¡æœ‰ä¸“é—¨å›¾ç¼–ç æ¨¡å‹çš„æƒ…å†µä¸‹å­¦ä¼šè§£å†³åŸºç¡€å›¾ä»»åŠ¡ï¼Ÿ (2) LLMs æ˜¯å¦èƒ½å°†å­¦åˆ°çš„è§£å†³æ–¹æ¡ˆæ³›åŒ–åˆ°æœªè§è¿‡çš„å›¾ç»“æ„æˆ–ä»»åŠ¡ï¼Ÿä»¥åŠ (3) å­¦ä¹ å›¾ä»»åŠ¡çš„ä¸åŒæ–¹æ³•å„æœ‰ä»€ä¹ˆä¼˜ç‚¹ï¼Ÿæˆ‘ä»¬è¯æ˜ï¼Œå³ä½¿æ˜¯å°å‹ LLMs ä¹Ÿå¯ä»¥é€šè¿‡ç”¨å¸¦æœ‰æŒ‡å¯¼æ€§æ€è·¯é“¾ï¼ˆchain-of-thoughtï¼‰çš„è§£æ³•è¿›è¡Œè®­ç»ƒæ¥å­¦ä¼šè§£å†³å›¾ä»»åŠ¡ï¼Œè€Œä¸”è¿™ç§è®­ç»ƒå¯ä»¥åœ¨æ²¡æœ‰ä¸“é—¨å›¾ç¼–ç å™¨çš„æƒ…å†µä¸‹æ³›åŒ–åˆ°æ–°çš„ä»»åŠ¡å’Œå›¾ç»“æ„ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-13 18:21:05 UTC
å‘å¸ƒï¼š2025-08-13 18:21:05 UTC</p>
<h2 id="114-empowering-morphing-attack-detection-using-interpretable-image-text-foundation-model--114-ä½¿ç”¨å¯è§£é‡Šçš„å›¾åƒ-æ–‡æœ¬åŸºç¡€æ¨¡å‹å¢å¼ºå˜å½¢æ”»å‡»æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10110"target="_blank" rel="external nofollow noopener noreferrer">#114</a> <a href="https://papers.cool/arxiv/2508.10110"target="_blank" rel="external nofollow noopener noreferrer">Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model</a>  #114 ä½¿ç”¨å¯è§£é‡Šçš„å›¾åƒ-æ–‡æœ¬åŸºç¡€æ¨¡å‹å¢å¼ºå˜å½¢æ”»å‡»æ£€æµ‹</h2>
<p><strong>Authors</strong>: [Sushrut Patwardhan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sushrut"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sushrut</a> Patwardhan), [Raghavendra Ramachandra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raghavendra"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raghavendra</a> Ramachandra), [Sushma Venkatesh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sushma"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sushma</a> Venkatesh)
ä½œè€…ï¼šSushrut Patwardhan, Raghavendra Ramachandra, Sushma Venkatesh</p>
<p>Morphing attack detection has become an essential component of face recognition systems for ensuring a reliable verification scenario. In this paper, we present a multimodal learning approach that can provide a textual description of morphing attack detection. We first show that zero-shot evaluation of the proposed framework using Contrastive Language-Image Pretraining (CLIP) can yield not only generalizable morphing attack detection, but also predict the most relevant text snippet. We present an extensive analysis of ten different textual prompts that include both short and long textual prompts. These prompts are engineered by considering the human understandable textual snippet. Extensive experiments were performed on a face morphing dataset that was developed using a publicly available face biometric dataset. We present an evaluation of SOTA pre-trained neural networks together with the proposed framework in the zero-shot evaluation of five different morphing generation techniques that are captured in three different mediums.
å˜å½¢æ”»å‡»æ£€æµ‹å·²æˆä¸ºäººè„¸è¯†åˆ«ç³»ç»Ÿä¸­ç¡®ä¿å¯é éªŒè¯åœºæ™¯çš„å…³é”®ç»„æˆéƒ¨åˆ†ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ç§å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•ï¼Œèƒ½å¤Ÿä¸ºå˜å½¢æ”»å‡»æ£€æµ‹æä¾›æ–‡æœ¬æè¿°ã€‚æˆ‘ä»¬é¦–å…ˆå±•ç¤ºäº†ä½¿ç”¨å¯¹æ¯”è¯­è¨€-å›¾åƒé¢„è®­ç»ƒï¼ˆCLIPï¼‰å¯¹æ‰€æå‡ºæ¡†æ¶è¿›è¡Œé›¶æ ·æœ¬è¯„ä¼°ï¼Œä¸ä»…å¯ä»¥äº§ç”Ÿå…·æœ‰è‰¯å¥½æ³›åŒ–æ€§çš„å˜å½¢æ”»å‡»æ£€æµ‹ï¼Œè¿˜èƒ½é¢„æµ‹æœ€ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µã€‚æˆ‘ä»¬å¯¹åç§ä¸åŒçš„æ–‡æœ¬æç¤ºè¿›è¡Œäº†è¯¦å°½åˆ†æï¼Œè¿™äº›æç¤ºåŒ…å«ç®€çŸ­å’Œå†—é•¿ä¸¤ç±»æ–‡æœ¬æç¤ºã€‚è¿™äº›æç¤ºçš„è®¾è®¡è€ƒè™‘äº†äººç±»å¯ç†è§£çš„æ–‡æœ¬ç‰‡æ®µã€‚æˆ‘ä»¬åœ¨ä½¿ç”¨å…¬å¼€å¯ç”¨äººè„¸ç”Ÿç‰©ç‰¹å¾æ•°æ®é›†å¼€å‘çš„ä¸€ä¸ªäººè„¸å˜å½¢æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤§é‡å®éªŒã€‚æˆ‘ä»¬åœ¨é›¶æ ·æœ¬è¯„ä¼°ä¸­å¯¹äº”ç§ä¸åŒçš„å˜å½¢ç”ŸæˆæŠ€æœ¯ï¼ˆåœ¨ä¸‰ç§ä¸åŒä»‹è´¨ä¸­é‡‡é›†ï¼‰è¿›è¡Œäº†è¯„ä¼°ï¼Œå¹¶æ¯”è¾ƒäº†ç°æœ‰æœ€å…ˆè¿›çš„é¢„è®­ç»ƒç¥ç»ç½‘ç»œä¸æ‰€æå‡ºæ¡†æ¶çš„è¡¨ç°ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CV"target="_blank" rel="external nofollow noopener noreferrer">Computer Vision and Pattern Recognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a></p>
<p><strong>Publish</strong>: 2025-08-13 18:06:29 UTC
å‘å¸ƒï¼š2025-08-13 18:06:29 ä¸–ç•Œåè°ƒæ—¶é—´</p>
<h2 id="115-advancing-data-equity-practitioner-responsibility-and-accountability-in-nlp-data-practices--115-æ¨è¿›æ•°æ®å…¬å¹³ä»ä¸šè€…åœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ•°æ®å®è·µä¸­çš„è´£ä»»ä¸é—®è´£"><a href="https://arxiv.org/abs/2508.10071"target="_blank" rel="external nofollow noopener noreferrer">#115</a> <a href="https://papers.cool/arxiv/2508.10071"target="_blank" rel="external nofollow noopener noreferrer">Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices</a>  #115 æ¨è¿›æ•°æ®å…¬å¹³ï¼šä»ä¸šè€…åœ¨è‡ªç„¶è¯­è¨€å¤„ç†æ•°æ®å®è·µä¸­çš„è´£ä»»ä¸é—®è´£</h2>
<p><strong>Authors</strong>: [Jay L. Cunningham](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jay</a> L. Cunningham), [Kevin Zhongyang Shao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kevin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kevin</a> Zhongyang Shao), [Rock Yuren Pang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rock"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rock</a> Yuren Pang), [Nathaniel Mengist](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nathaniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nathaniel</a> Mengist)
ä½œè€…ï¼šJay L. Cunninghamã€Kevin Zhongyang Shaoã€Rock Yuren Pangã€Nathaniel Mengist</p>
<p>While research has focused on surfacing and auditing algorithmic bias to ensure equitable AI development, less is known about how NLP practitioners - those directly involved in dataset development, annotation, and deployment - perceive and navigate issues of NLP data equity. This study is among the first to center practitioners&rsquo; perspectives, linking their experiences to a multi-scalar AI governance framework and advancing participatory recommendations that bridge technical, policy, and community domains. Drawing on a 2024 questionnaire and focus group, we examine how U.S.-based NLP data practitioners conceptualize fairness, contend with organizational and systemic constraints, and engage emerging governance efforts such as the U.S. AI Bill of Rights. Findings reveal persistent tensions between commercial objectives and equity commitments, alongside calls for more participatory and accountable data workflows. We critically engage debates on data diversity and diversity washing, arguing that improving NLP equity requires structural governance reforms that support practitioner agency and community consent.
å°½ç®¡ç ”ç©¶é›†ä¸­äºæ­ç¤ºå’Œå®¡è®¡ç®—æ³•åè§ä»¥ç¡®ä¿å…¬å¹³çš„äººå·¥æ™ºèƒ½å‘å±•ï¼Œä½†å¯¹ç›´æ¥å‚ä¸æ•°æ®é›†å¼€å‘ã€æ ‡æ³¨å’Œéƒ¨ç½²çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»ä¸šè€…å¦‚ä½•çœ‹å¾…å¹¶åº”å¯¹ NLP æ•°æ®å…¬å¹³é—®é¢˜çŸ¥ä¹‹ç”šå°‘ã€‚æœ¬ç ”ç©¶æ˜¯é¦–æ‰¹ä»¥ä»ä¸šè€…è§†è§’ä¸ºä¸­å¿ƒçš„ç ”ç©¶ä¹‹ä¸€ï¼Œå°†ä»–ä»¬çš„ç»éªŒä¸å¤šå°ºåº¦çš„äººå·¥æ™ºèƒ½æ²»ç†æ¡†æ¶è”ç³»èµ·æ¥ï¼Œå¹¶æ¨è¿›è¿æ¥æŠ€æœ¯ã€æ”¿ç­–ä¸ç¤¾åŒºé¢†åŸŸçš„å‚ä¸å¼å»ºè®®ã€‚åŸºäº 2024 å¹´çš„é—®å·è°ƒæŸ¥å’Œç„¦ç‚¹å°ç»„ï¼Œæˆ‘ä»¬è€ƒå¯Ÿäº†ç¾å›½çš„ NLP æ•°æ®ä»ä¸šè€…å¦‚ä½•æ¦‚å¿µåŒ–å…¬å¹³ï¼Œå¦‚ä½•åº”å¯¹ç»„ç»‡ä¸åˆ¶åº¦çº¦æŸï¼Œä»¥åŠå¦‚ä½•å‚ä¸è¯¸å¦‚ç¾å›½äººå·¥æ™ºèƒ½æƒåˆ©æ³•æ¡ˆç­‰æ–°å…´æ²»ç†åŠªåŠ›ã€‚ç ”ç©¶å‘ç°å•†ä¸šç›®æ ‡ä¸å…¬å¹³æ‰¿è¯ºä¹‹é—´å­˜åœ¨æŒç»­ç´§å¼ ï¼ŒåŒæ—¶ä¹Ÿå‡ºç°äº†å¯¹æ›´åŠ å‚ä¸å¼ä¸é—®è´£æ€§æ•°æ®å·¥ä½œæµçš„å‘¼å£°ã€‚æˆ‘ä»¬å¯¹æ•°æ®å¤šæ ·æ€§ä¸â€œå¤šæ ·æ€§æ´—ç‰Œâ€ç›¸å…³äº‰è®ºè¿›è¡Œäº†æ‰¹åˆ¤æ€§è®¨è®ºï¼Œè®¤ä¸ºæ”¹å–„ NLP å…¬å¹³éœ€è¦æ”¯æŒä»ä¸šè€…èƒ½åŠ¨æ€§ä¸ç¤¾åŒºåŒæ„çš„ç»“æ„æ€§æ²»ç†æ”¹é©ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">Computers and Society</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>
ä¸»é¢˜ï¼šè®¡ç®—æœºä¸ç¤¾ä¼šã€äººå·¥æ™ºèƒ½ã€äººæœºäº¤äº’</p>
<p><strong>Publish</strong>: 2025-08-13 13:14:43 UTC
å‘è¡¨ï¼š2025-08-13 13:14:43 UTC</p>
<h2 id="116-large-language-models-show-signs-of-alignment-with-human-neurocognition-during-abstract-reasoning--116-å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­è¡¨ç°å‡ºä¸äººç±»ç¥ç»è®¤çŸ¥ä¸€è‡´çš„è¿¹è±¡"><a href="https://arxiv.org/abs/2508.10057"target="_blank" rel="external nofollow noopener noreferrer">#116</a> <a href="https://papers.cool/arxiv/2508.10057"target="_blank" rel="external nofollow noopener noreferrer">Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning</a>  #116 å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­è¡¨ç°å‡ºä¸äººç±»ç¥ç»è®¤çŸ¥ä¸€è‡´çš„è¿¹è±¡</h2>
<p><strong>Authors</strong>: [Christopher Pinier](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Christopher"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Christopher</a> Pinier), [Sonia AcuÃ±a Vargas](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sonia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sonia</a> AcuÃ±a Vargas), [Mariia Steeghs-Turchina](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mariia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mariia</a> Steeghs-Turchina), [Dora Matzke](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dora"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dora</a> Matzke), [Claire E. Stevenson](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Claire"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Claire</a> E. Stevenson), [Michael D. Nunez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Michael"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Michael</a> D. Nunez)
ä½œè€…ï¼šChristopher Pinierã€Sonia AcuÃ±a Vargasã€Mariia Steeghs-Turchinaã€Dora Matzkeã€Claire E. Stevensonã€Michael D. Nunez</p>
<p>This study investigates whether large language models (LLMs) mirror human neurocognition during abstract reasoning. We compared the performance and neural representations of human participants with those of eight open-source LLMs on an abstract-pattern-completion task. We leveraged pattern type differences in task performance and in fixation-related potentials (FRPs) as recorded by electroencephalography (EEG) during the task. Our findings indicate that only the largest tested LLMs (~70 billion parameters) achieve human-comparable accuracy, with Qwen-2.5-72B and DeepSeek-R1-70B also showing similarities with the human pattern-specific difficulty profile. Critically, every LLM tested forms representations that distinctly cluster the abstract pattern categories within their intermediate layers, although the strength of this clustering scales with their performance on the task. Moderate positive correlations were observed between the representational geometries of task-optimal LLM layers and human frontal FRPs. These results consistently diverged from comparisons with other EEG measures (response-locked ERPs and resting EEG), suggesting a potential shared representational space for abstract patterns. This indicates that LLMs might mirror human brain mechanisms in abstract reasoning, offering preliminary evidence of shared principles between biological and artificial intelligence.
æœ¬ç ”ç©¶æ¢è®¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æŠ½è±¡æ¨ç†æ—¶æ˜¯å¦åæ˜ äº†äººç±»çš„ç¥ç»è®¤çŸ¥ã€‚æˆ‘ä»¬å°†äººç±»å‚ä¸è€…ä¸å…«ä¸ªå¼€æº LLM åœ¨ä¸€ç§æŠ½è±¡æ¨¡å¼è¡¥å…¨ä»»åŠ¡ä¸Šçš„è¡¨ç°ä¸ç¥ç»è¡¨å¾è¿›è¡Œäº†æ¯”è¾ƒã€‚æˆ‘ä»¬åˆ©ç”¨äº†ä»»åŠ¡è¡¨ç°ä¸­çš„æ¨¡å¼ç±»å‹å·®å¼‚ä»¥åŠä»»åŠ¡è¿‡ç¨‹ä¸­é€šè¿‡è„‘ç”µå›¾ï¼ˆEEGï¼‰è®°å½•çš„æ³¨è§†ç›¸å…³ç”µä½ï¼ˆFRPsï¼‰ä¸­çš„å·®å¼‚ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œåªæœ‰æµ‹è¯•ä¸­æœ€å¤§çš„ LLMsï¼ˆçº¦ 700 äº¿å‚æ•°ï¼‰è¾¾åˆ°äº†ä¸äººç±»ç›¸å½“çš„å‡†ç¡®ç‡ï¼Œå…¶ä¸­ Qwen-2.5-72B å’Œ DeepSeek-R1-70B è¿˜å±•ç°å‡ºä¸äººç±»åœ¨ç‰¹å®šæ¨¡å¼éš¾åº¦åˆ†å¸ƒä¸Šçš„ç›¸ä¼¼æ€§ã€‚å…³é”®çš„æ˜¯ï¼Œæ¯ä¸ªè¢«æµ‹è¯•çš„ LLM åœ¨å…¶ä¸­é—´å±‚éƒ½å½¢æˆäº†èƒ½å¤Ÿæ¸…æ™°åŒºåˆ†æŠ½è±¡æ¨¡å¼ç±»åˆ«çš„è¡¨å¾ï¼Œå°½ç®¡è¿™ç§èšç±»çš„å¼ºåº¦éšå…¶åœ¨ä»»åŠ¡ä¸Šçš„è¡¨ç°è€Œå˜åŒ–ã€‚ä»»åŠ¡æœ€ä¼˜ LLM å±‚çš„è¡¨å¾å‡ ä½•ä¸äººç±»é¢å¶ FRPs ä¹‹é—´è§‚å¯Ÿåˆ°ä¸­ç­‰ç¨‹åº¦çš„æ­£ç›¸å…³ã€‚ è¿™äº›ç»“æœä¸å…¶ä»–è„‘ç”µæµ‹é‡ï¼ˆååº”é”å®šäº‹ä»¶ç›¸å…³ç”µä½å’Œé™æ¯è„‘ç”µï¼‰çš„æ¯”è¾ƒæŒç»­å‡ºç°åˆ†æ­§ï¼Œè¡¨æ˜æŠ½è±¡æ¨¡å¼å¯èƒ½å­˜åœ¨ä¸€ä¸ªå…±äº«çš„è¡¨å¾ç©ºé—´ã€‚è¿™è¡¨æ˜ LLMs å¯èƒ½åœ¨æŠ½è±¡æ¨ç†ä¸Šåæ˜ äº†äººç±»å¤§è„‘çš„æœºåˆ¶ï¼Œæä¾›äº†ç”Ÿç‰©æ™ºèƒ½ä¸äººå·¥æ™ºèƒ½ä¹‹é—´å…±äº«åŸç†çš„åˆæ­¥è¯æ®ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/q-bio.NC"target="_blank" rel="external nofollow noopener noreferrer">Neurons and Cognition</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šç¥ç»å…ƒä¸è®¤çŸ¥ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-12 21:38:46 UTC
å‘å¸ƒï¼š2025-08-12 21:38:46 UTC</p>
<h2 id="117-netmoniai-an-agentic-ai-framework-for-network-security--monitoring--117-netmoniaiä¸€ä¸ªç”¨äºç½‘ç»œå®‰å…¨ä¸ç›‘æ§çš„è‡ªä¸»æ™ºèƒ½ä½“-ai-æ¡†æ¶-pdf--copy-kimi-1--rel"><a href="https://arxiv.org/abs/2508.10052"target="_blank" rel="external nofollow noopener noreferrer">#117</a> <a href="https://papers.cool/arxiv/2508.10052"target="_blank" rel="external nofollow noopener noreferrer">NetMoniAI: An Agentic AI Framework for Network Security &amp; Monitoring</a>  #117 NetMoniAIï¼šä¸€ä¸ªç”¨äºç½‘ç»œå®‰å…¨ä¸ç›‘æ§çš„è‡ªä¸»æ™ºèƒ½ä½“ AI æ¡†æ¶ [PDF ] [Copy] [Kimi 1 ] [REL]</h2>
<p><strong>Authors</strong>: [Pallavi Zambare](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pallavi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pallavi</a> Zambare), [Venkata Nikhil Thanikella](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Venkata"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Venkata</a> Nikhil Thanikella), [Nikhil Padmanabh Kottur](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nikhil"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nikhil</a> Padmanabh Kottur), [Sree Akhil Akula](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sree"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sree</a> Akhil Akula), [Ying Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ying</a> Liu)
ä½œè€…ï¼šPallavi Zambareã€Venkata Nikhil Thanikellaã€Nikhil Padmanabh Kotturã€Sree Akhil Akulaã€Ying Liu</p>
<p>In this paper, we present NetMoniAI, an agentic AI framework for automatic network monitoring and security that integrates decentralized analysis with lightweight centralized coordination. The framework consists of two layers: autonomous micro-agents at each node perform local traffic analysis and anomaly detection. A central controller then aggregates insights across nodes to detect coordinated attacks and maintain system-wide situational awareness. We evaluated NetMoniAI on a local micro-testbed and through NS-3 simulations. Results confirm that the two-tier agentic-AI design scales under resource constraints, reduces redundancy, and improves response time without compromising accuracy. To facilitate broader adoption and reproducibility, the complete framework is available as open source. This enables researchers and practitioners to replicate, validate, and extend it across diverse network environments and threat scenarios. Github link: <a href="https://github.com/pzambare3/NetMoniAI"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/pzambare3/NetMoniAI</a>
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† NetMoniAIï¼Œä¸€ç§ç”¨äºè‡ªåŠ¨ç½‘ç»œç›‘æ§ä¸å®‰å…¨çš„æ™ºèƒ½ä½“å¼ AI æ¡†æ¶ï¼Œæ•´åˆäº†å»ä¸­å¿ƒåŒ–åˆ†æä¸è½»é‡åŒ–ä¸­å¿ƒåè°ƒã€‚è¯¥æ¡†æ¶ç”±ä¸¤å±‚ç»„æˆï¼šæ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„è‡ªä¸»å¾®å‹æ™ºèƒ½ä½“æ‰§è¡Œæœ¬åœ°æµé‡åˆ†æä¸å¼‚å¸¸æ£€æµ‹ï¼›ä¸­å¤®æ§åˆ¶å™¨åˆ™èšåˆè·¨èŠ‚ç‚¹çš„æ´è§ä»¥æ£€æµ‹ååŒæ”»å‡»å¹¶ç»´æŠ¤å…¨ç³»ç»Ÿçš„æ€åŠ¿æ„ŸçŸ¥ã€‚æˆ‘ä»¬åœ¨æœ¬åœ°å¾®å‹æµ‹è¯•åºŠå’Œ NS-3 ä»¿çœŸä¸­è¯„ä¼°äº† NetMoniAIã€‚ç»“æœç¡®è®¤ï¼Œè¿™ç§ä¸¤å±‚æ™ºèƒ½ä½“å¼ AI è®¾è®¡åœ¨èµ„æºå—é™æƒ…å†µä¸‹å…·æœ‰å¯æ‰©å±•æ€§ã€å‡å°‘å†—ä½™å¹¶æå‡å“åº”æ—¶é—´ï¼ŒåŒæ—¶ä¸æŸå®³å‡†ç¡®æ€§ã€‚ä¸ºä¿ƒè¿›æ›´å¹¿æ³›çš„é‡‡ç”¨å’Œå¯å¤ç°æ€§ï¼Œå®Œæ•´æ¡†æ¶ä»¥å¼€æºå½¢å¼æä¾›ã€‚è¿™ä½¿ç ”ç©¶äººå‘˜å’Œå®è·µè€…èƒ½å¤Ÿåœ¨ä¸åŒçš„ç½‘ç»œç¯å¢ƒå’Œå¨èƒåœºæ™¯ä¸‹å¤ç°ã€éªŒè¯å¹¶æ‰©å±•è¯¥æ¡†æ¶ã€‚Github é“¾æ¥: <a href="https://github.com/pzambare3/NetMoniAI"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/pzambare3/NetMoniAI</a></p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨æ€§ , äººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-12 15:48:53 UTC
å‘å¸ƒï¼š2025-08-12 15:48:53 UTC</p>
<h2 id="118-legal-zero-days-a-novel-risk-vector-for-advanced-ai-systems--118-åˆæ³•é›¶æ—¥æ¼æ´é¢å‘é«˜çº§äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ–°å‹é£é™©å‘é‡"><a href="https://arxiv.org/abs/2508.10050"target="_blank" rel="external nofollow noopener noreferrer">#118</a> <a href="https://papers.cool/arxiv/2508.10050"target="_blank" rel="external nofollow noopener noreferrer">Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems</a>  #118 åˆæ³•é›¶æ—¥æ¼æ´ï¼šé¢å‘é«˜çº§äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ–°å‹é£é™©å‘é‡</h2>
<p><strong>Authors</strong>: [Greg Sadler](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Greg"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Greg</a> Sadler), [Nathan Sherburn](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Nathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Nathan</a> Sherburn)
ä½œè€…ï¼šGreg Sadlerã€Nathan Sherburn</p>
<p>We introduce the concept of &ldquo;Legal Zero-Days&rdquo; as a novel risk vector for advanced AI systems. Legal Zero-Days are previously undiscovered vulnerabilities in legal frameworks that, when exploited, can cause immediate and significant societal disruption without requiring litigation or other processes before impact. We present a risk model for identifying and evaluating these vulnerabilities, demonstrating their potential to bypass safeguards or impede government responses to AI incidents. Using the 2017 Australian dual citizenship crisis as a case study, we illustrate how seemingly minor legal oversights can lead to large-scale governance disruption. We develop a methodology for creating &ldquo;legal puzzles&rdquo; as evaluation instruments for assessing AI systems&rsquo; capabilities to discover such vulnerabilities. Our findings suggest that while current AI models may not reliably find impactful Legal Zero-Days, future systems may develop this capability, presenting both risks and opportunities for improving legal robustness. This work contributes to the broader effort to identify and mitigate previously unrecognized risks from frontier AI systems.
æˆ‘ä»¬æå‡ºäº†â€œæ³•å¾‹é›¶æ—¥æ¼æ´â€ï¼ˆLegal Zero-Daysï¼‰çš„æ¦‚å¿µï¼Œä½œä¸ºé’ˆå¯¹å…ˆè¿›äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„ä¸€ç§æ–°å‹é£é™©å‘é‡ã€‚æ³•å¾‹é›¶æ—¥æ¼æ´æŒ‡çš„æ˜¯æ³•å¾‹æ¡†æ¶ä¸­æ­¤å‰æœªè¢«å‘ç°çš„è„†å¼±ç‚¹ï¼Œä¸€æ—¦è¢«åˆ©ç”¨ï¼Œèƒ½å¤Ÿåœ¨æ— éœ€é€šè¿‡è¯‰è®¼æˆ–å…¶ä»–ç¨‹åºå³å¯äº§ç”Ÿå³æ—¶ä¸”é‡å¤§ç¤¾ä¼šç ´åã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç”¨äºè¯†åˆ«å’Œè¯„ä¼°è¿™äº›æ¼æ´çš„é£é™©æ¨¡å‹ï¼Œå±•ç¤ºäº†å®ƒä»¬å¦‚ä½•æœ‰å¯èƒ½ç»•è¿‡é˜²æŠ¤æªæ–½æˆ–é˜»ç¢æ”¿åºœå¯¹äººå·¥æ™ºèƒ½äº‹ä»¶çš„å“åº”ã€‚ä»¥ 2017 å¹´æ¾³å¤§åˆ©äºšåŒé‡å›½ç±å±æœºä¸ºæ¡ˆä¾‹ç ”ç©¶ï¼Œæˆ‘ä»¬è¯´æ˜äº†çœ‹ä¼¼å¾®å°çš„æ³•å¾‹ç–æ¼å¦‚ä½•å¯¼è‡´å¤§è§„æ¨¡çš„æ²»ç†æ··ä¹±ã€‚æˆ‘ä»¬å¼€å‘äº†ä¸€ç§æ–¹æ³•è®ºï¼Œç”¨ä»¥åˆ›å»ºâ€œæ³•å¾‹è°œé¢˜â€ä½œä¸ºè¯„ä¼°å·¥å…·ï¼Œè¯„ä¼°äººå·¥æ™ºèƒ½ç³»ç»Ÿå‘ç°æ­¤ç±»æ¼æ´çš„èƒ½åŠ›ã€‚æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œå°½ç®¡ç°æœ‰çš„äººå·¥æ™ºèƒ½æ¨¡å‹å¯èƒ½å°šä¸èƒ½å¯é åœ°å‘ç°å…·æœ‰é‡å¤§å½±å“çš„æ³•å¾‹é›¶æ—¥æ¼æ´ï¼Œä½†æœªæ¥çš„ç³»ç»Ÿå¯èƒ½ä¼šå‘å±•å‡ºè¿™ä¸€èƒ½åŠ›ï¼Œè¿™æ—¢å¸¦æ¥é£é™©ä¹Ÿæä¾›äº†æ”¹è¿›æ³•å¾‹ç¨³å¥æ€§çš„æœºä¼šã€‚æœ¬å·¥ä½œæœ‰åŠ©äºæ›´å¹¿æ³›çš„åŠªåŠ›ï¼Œå³è¯†åˆ«å¹¶ç¼“è§£å‰æ²¿äººå·¥æ™ºèƒ½ç³»ç»Ÿå¸¦æ¥çš„æ­¤å‰æœªè¢«è®¤è¯†çš„é£é™©ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">Computers and Society</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—æœºä¸ç¤¾ä¼šï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-12 11:43:00 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-12 11:43:00 UTC</p>
<h2 id="119-sabia-an-ai-powered-tool-for-detecting-opioid-related-behaviors-on-social-media--119-sabiaä¸€ç§ç”¨äºæ£€æµ‹ç¤¾äº¤åª’ä½“ä¸Šä¸é˜¿ç‰‡ç±»è¯ç‰©ç›¸å…³è¡Œä¸ºçš„-ai-å·¥å…·"><a href="https://arxiv.org/abs/2508.10046"target="_blank" rel="external nofollow noopener noreferrer">#119</a> <a href="https://papers.cool/arxiv/2508.10046"target="_blank" rel="external nofollow noopener noreferrer">SABIA: An AI-Powered Tool for Detecting Opioid-Related Behaviors on Social Media</a>  #119 SABIAï¼šä¸€ç§ç”¨äºæ£€æµ‹ç¤¾äº¤åª’ä½“ä¸Šä¸é˜¿ç‰‡ç±»è¯ç‰©ç›¸å…³è¡Œä¸ºçš„ AI å·¥å…·</h2>
<p><strong>Authors</strong>: [Muhammad Ahmad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhammad</a> Ahmad), [Fida Ullah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fida"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fida</a> Ullah), [Muhammad Usman](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Muhammad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Muhammad</a> Usman), [Ildar Batyrshin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ildar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ildar</a> Batyrshin), [Grigori Sidorov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Grigori"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Grigori</a> Sidorov)
ä½œè€…ï¼šMuhammad Ahmadã€Fida Ullahã€Muhammad Usmanã€Ildar Batyrshinã€Grigori Sidorov</p>
<p>Social media platforms have become valuable tools for understanding public health challenges by offering insights into patient behaviors, medication use, and mental health issues. However, analyzing such data remains difficult due to the prevalence of informal language, slang, and coded communication, which can obscure the detection of opioid misuse. This study addresses the issue of opioid-related user behavior on social media, including informal expressions, slang terms, and misspelled or coded language. We analyzed the existing Bidirectional Encoder Representations from Transformers (BERT) technique and developed a BERT-BiLSTM-3CNN hybrid deep learning model, named SABIA, to create a single-task classifier that effectively captures the features of the target dataset. The SABIA model demonstrated strong capabilities in capturing semantics and contextual information. The proposed approach includes: (1) data preprocessing, (2) data representation using the SABIA model, (3) a fine-tuning phase, and (4) classification of user behavior into five categories. A new dataset was constructed from Reddit posts, identifying opioid user behaviors across five classes: Dealers, Active Opioid Users, Recovered Users, Prescription Users, and Non-Users, supported by detailed annotation guidelines. Experiments were conducted using supervised learning. Results show that SABIA achieved benchmark performance, outperforming the baseline (Logistic Regression, LR = 0.86) and improving accuracy by 9.30%. Comparisons with seven previous studies confirmed its effectiveness and robustness. This study demonstrates the potential of hybrid deep learning models for detecting complex opioid-related behaviors on social media, supporting public health monitoring and intervention efforts.
ç¤¾äº¤åª’ä½“å¹³å°å·²æˆä¸ºç†è§£å…¬å…±å«ç”ŸæŒ‘æˆ˜çš„å®è´µå·¥å…·ï¼Œé€šè¿‡æä¾›å…³äºæ‚£è€…è¡Œä¸ºã€è¯ç‰©ä½¿ç”¨å’Œå¿ƒç†å¥åº·é—®é¢˜çš„æ´è§ã€‚ç„¶è€Œï¼Œç”±äºéæ­£å¼è¯­è¨€ã€ä¿šè¯­å’Œç¼–ç åŒ–äº¤æµçš„æ™®éå­˜åœ¨ï¼Œè¿™ç±»æ•°æ®çš„åˆ†æä»ç„¶å›°éš¾ï¼Œè¿™äº›å› ç´ å¯èƒ½æ©ç›–é˜¿ç‰‡ç±»è¯ç‰©æ»¥ç”¨çš„æ£€æµ‹ã€‚æœ¬ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“ä¸Šä¸é˜¿ç‰‡ç±»è¯ç‰©ç›¸å…³çš„ç”¨æˆ·è¡Œä¸ºé—®é¢˜ï¼ŒåŒ…æ‹¬éæ­£å¼è¡¨è¾¾ã€ä¿šè¯­æœ¯è¯­ä»¥åŠæ‹¼å†™é”™è¯¯æˆ–ç¼–ç åŒ–è¯­è¨€ã€‚æˆ‘ä»¬åˆ†æäº†ç°æœ‰çš„åŒå‘ç¼–ç å™¨è¡¨ç¤º(BERT)æŠ€æœ¯ï¼Œå¹¶å¼€å‘äº†ä¸€ä¸ªåä¸º SABIA çš„ BERT-BiLSTM-3CNN æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä»¥æ„å»ºä¸€ä¸ªèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰ç›®æ ‡æ•°æ®é›†ç‰¹å¾çš„å•ä»»åŠ¡åˆ†ç±»å™¨ã€‚SABIA æ¨¡å‹åœ¨æ•æ‰è¯­ä¹‰å’Œä¸Šä¸‹æ–‡ä¿¡æ¯æ–¹é¢è¡¨ç°å‡ºå¼ºå¤§èƒ½åŠ›ã€‚æ‰€æå‡ºçš„æ–¹æ³•åŒ…æ‹¬ï¼š(1) æ•°æ®é¢„å¤„ç†ï¼Œ(2) ä½¿ç”¨ SABIA æ¨¡å‹è¿›è¡Œæ•°æ®è¡¨ç¤ºï¼Œ(3) å¾®è°ƒé˜¶æ®µï¼Œä»¥åŠ(4) å°†ç”¨æˆ·è¡Œä¸ºåˆ’åˆ†ä¸ºäº”ç±»çš„åˆ†ç±»ã€‚ ä» Reddit å¸–å­æ„å»ºäº†ä¸€ä¸ªæ–°æ•°æ®é›†ï¼Œè¯†åˆ«äº†äº”ç±»ä¸é˜¿ç‰‡ç±»è¯ç‰©ä½¿ç”¨è€…ç›¸å…³çš„è¡Œä¸ºï¼šç»é”€å•†ã€æ´»è·ƒé˜¿ç‰‡ç±»è¯ç‰©ä½¿ç”¨è€…ã€åº·å¤è€…ã€å¤„æ–¹è¯ä½¿ç”¨è€…å’Œéä½¿ç”¨è€…ï¼Œå¹¶è¾…ä»¥è¯¦å°½çš„æ³¨é‡ŠæŒ‡å—ã€‚ä½¿ç”¨ç›‘ç£å­¦ä¹ è¿›è¡Œäº†å®éªŒã€‚ç»“æœæ˜¾ç¤ºï¼ŒSABIA è¾¾åˆ°åŸºå‡†æ€§èƒ½ï¼Œä¼˜äºåŸºçº¿æ¨¡å‹ï¼ˆé€»è¾‘å›å½’ï¼ŒLR = 0.86ï¼‰ï¼Œå‡†ç¡®ç‡æå‡äº† 9.30%ã€‚ä¸ä¹‹å‰ä¸ƒé¡¹ç ”ç©¶çš„æ¯”è¾ƒè¯å®äº†å…¶æœ‰æ•ˆæ€§å’Œç¨³å¥æ€§ã€‚æœ¬ç ”ç©¶å±•ç¤ºäº†æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨ç¤¾äº¤åª’ä½“ä¸Šæ£€æµ‹å¤æ‚é˜¿ç‰‡ç±»ç›¸å…³è¡Œä¸ºçš„æ½œåŠ›ï¼Œæœ‰åŠ©äºå…¬å…±å«ç”Ÿç›‘æµ‹å’Œå¹²é¢„å·¥ä½œã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.SI"target="_blank" rel="external nofollow noopener noreferrer">Social and Information Networks</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šç¤¾äº¤ä¸ä¿¡æ¯ç½‘ç»œï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-12 06:52:41 UTC
å‘å¸ƒï¼š2025-08-12 06:52:41 ä¸–ç•Œåè°ƒæ—¶é—´</p>
<h2 id="120-generative-ai-for-cybersecurity-of-energy-management-systems-methods-challenges-and-future-directions--120-é¢å‘èƒ½æºç®¡ç†ç³»ç»Ÿç½‘ç»œå®‰å…¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ–¹æ³•æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘"><a href="https://arxiv.org/abs/2508.10044"target="_blank" rel="external nofollow noopener noreferrer">#120</a> <a href="https://papers.cool/arxiv/2508.10044"target="_blank" rel="external nofollow noopener noreferrer">Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions</a>  #120 é¢å‘èƒ½æºç®¡ç†ç³»ç»Ÿç½‘ç»œå®‰å…¨çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šæ–¹æ³•ã€æŒ‘æˆ˜ä¸æœªæ¥æ–¹å‘</h2>
<p><strong>Authors</strong>: [Aydin Zaboli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aydin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aydin</a> Zaboli), [Junho Hong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Junho"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Junho</a> Hong)
ä½œè€…ï¼šAydin Zaboliã€Junho Hong</p>
<p>This paper elaborates on an extensive security framework specifically designed for energy management systems (EMSs), which effectively tackles the dynamic environment of cybersecurity vulnerabilities and/or system problems (SPs), accomplished through the incorporation of novel methodologies. A comprehensive multi-point attack/error model is initially proposed to systematically identify vulnerabilities throughout the entire EMS data processing pipeline, including post state estimation (SE) stealth attacks, EMS database manipulation, and human-machine interface (HMI) display corruption according to the real-time database (RTDB) storage. This framework acknowledges the interconnected nature of modern attack vectors, which utilize various phases of supervisory control and data acquisition (SCADA) data flow. Then, generative AI (GenAI)-based anomaly detection systems (ADSs) for EMSs are proposed for the first time in the power system domain to handle the scenarios. Further, a set-of-mark generative intelligence (SoM-GI) framework, which leverages multimodal analysis by integrating visual markers with rules considering the GenAI capabilities, is suggested to overcome inherent spatial reasoning limitations. The SoM-GI methodology employs systematic visual indicators to enable accurate interpretation of segmented HMI displays and detect visual anomalies that numerical methods fail to identify. Validation on the IEEE 14-Bus system shows the framework&rsquo;s effectiveness across scenarios, while visual analysis identifies inconsistencies. This integrated approach combines numerical analysis with visual pattern recognition and linguistic rules to protect against cyber threats and system errors.
æœ¬æ–‡è¯¦ç»†é˜è¿°äº†ä¸€ä¸ªä¸“ä¸ºèƒ½æºç®¡ç†ç³»ç»Ÿï¼ˆEMSï¼‰è®¾è®¡çš„å…¨é¢å®‰å…¨æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥æ–°é¢–æ–¹æ³•ï¼Œæœ‰æ•ˆåº”å¯¹ç½‘ç»œå®‰å…¨æ¼æ´å’Œ/æˆ–ç³»ç»Ÿé—®é¢˜ï¼ˆSPsï¼‰çš„åŠ¨æ€ç¯å¢ƒã€‚é¦–å…ˆæå‡ºäº†ä¸€ä¸ªç»¼åˆçš„å¤šç‚¹æ”»å‡»/é”™è¯¯æ¨¡å‹ï¼Œä»¥ç³»ç»Ÿæ€§åœ°è¯†åˆ«æ•´ä¸ª EMS æ•°æ®å¤„ç†ç®¡é“ä¸­çš„è„†å¼±æ€§ï¼Œæ¶µç›–çŠ¶æ€ä¼°è®¡ï¼ˆSEï¼‰åæ½œä¼æ”»å‡»ã€EMS æ•°æ®åº“ç¯¡æ”¹ä»¥åŠåŸºäºå®æ—¶æ•°æ®åº“ï¼ˆRTDBï¼‰å­˜å‚¨çš„äººæœºç•Œé¢ï¼ˆHMIï¼‰æ˜¾ç¤ºæŸåã€‚è¯¥æ¡†æ¶æ‰¿è®¤ç°ä»£æ”»å‡»å‘é‡çš„ç›¸äº’å…³è”æ€§ï¼Œè¿™äº›å‘é‡åˆ©ç”¨äº†ç›‘æ§ä¸æ•°æ®é‡‡é›†ï¼ˆSCADAï¼‰æ•°æ®æµçš„å„ä¸ªé˜¶æ®µã€‚éšåï¼Œæ–‡ä¸­é¦–æ¬¡åœ¨ç”µåŠ›ç³»ç»Ÿé¢†åŸŸæå‡ºåŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenAIï¼‰çš„ EMS å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿï¼ˆADSsï¼‰ä»¥åº”å¯¹è¿™äº›æƒ…æ™¯ã€‚ æ­¤å¤–ï¼Œæå‡ºäº†ä¸€ç§æ ‡è®°é›†ç”Ÿæˆæ™ºèƒ½ï¼ˆSoM-GIï¼‰æ¡†æ¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡å°†è§†è§‰æ ‡è®°ä¸è€ƒè™‘åˆ°ç”Ÿæˆå¼äººå·¥æ™ºèƒ½èƒ½åŠ›çš„è§„åˆ™ç›¸ç»“åˆæ¥åˆ©ç”¨å¤šæ¨¡æ€åˆ†æï¼Œä»¥å…‹æœå›ºæœ‰çš„ç©ºé—´æ¨ç†å±€é™æ€§ã€‚SoM-GI æ–¹æ³•è®ºé‡‡ç”¨ç³»ç»ŸåŒ–çš„è§†è§‰æŒ‡ç¤ºå™¨ï¼Œä»¥å®ç°å¯¹åˆ†å‰²çš„äººæœºç•Œé¢ï¼ˆHMIï¼‰æ˜¾ç¤ºçš„å‡†ç¡®è§£è¯»ï¼Œå¹¶æ£€æµ‹æ•°å€¼æ–¹æ³•æ— æ³•è¯†åˆ«çš„è§†è§‰å¼‚å¸¸ã€‚åœ¨ IEEE 14 æ€»çº¿ç³»ç»Ÿä¸Šçš„éªŒè¯è¡¨æ˜è¯¥æ¡†æ¶åœ¨å¤šç§æƒ…æ™¯ä¸‹å‡æœ‰æ•ˆï¼ŒåŒæ—¶è§†è§‰åˆ†æèƒ½å¤Ÿè¯†åˆ«ä¸ä¸€è‡´ä¹‹å¤„ã€‚è¿™ç§é›†æˆæ–¹æ³•å°†æ•°å€¼åˆ†æä¸è§†è§‰æ¨¡å¼è¯†åˆ«å’Œè¯­è¨€è§„åˆ™ç›¸ç»“åˆï¼Œä»¥é˜²å¾¡ç½‘ç»œå¨èƒå’Œç³»ç»Ÿé”™è¯¯ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨æ€§ , äººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-12 03:10:22 UTC
å‘å¸ƒï¼š2025-08-12 03:10:22 åè°ƒä¸–ç•Œæ—¶</p>
<h2 id="121-securing-agentic-ai-threat-modeling-and-risk-analysis-for-network-monitoring-agentic-ai-system--121-ä¿éšœå…·å¤‡ä»£ç†èƒ½åŠ›çš„äººå·¥æ™ºèƒ½é’ˆå¯¹ç½‘ç»œç›‘æ§ä»£ç†å¼äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¨èƒå»ºæ¨¡ä¸é£é™©åˆ†æ"><a href="https://arxiv.org/abs/2508.10043"target="_blank" rel="external nofollow noopener noreferrer">#121</a> <a href="https://papers.cool/arxiv/2508.10043"target="_blank" rel="external nofollow noopener noreferrer">Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System</a>  #121 ä¿éšœå…·å¤‡ä»£ç†èƒ½åŠ›çš„äººå·¥æ™ºèƒ½ï¼šé’ˆå¯¹ç½‘ç»œç›‘æ§ä»£ç†å¼äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„å¨èƒå»ºæ¨¡ä¸é£é™©åˆ†æ</h2>
<p><strong>Authors</strong>: [Pallavi Zambare](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pallavi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pallavi</a> Zambare), [Venkata Nikhil Thanikella](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Venkata"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Venkata</a> Nikhil Thanikella), [Ying Liu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ying"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ying</a> Liu)
ä½œè€…ï¼šPallavi Zambareã€Venkata Nikhil Thanikellaã€Ying Liu</p>
<p>When combining Large Language Models (LLMs) with autonomous agents, used in network monitoring and decision-making systems, this will create serious security issues. In this research, the MAESTRO framework consisting of the seven layers threat modeling architecture in the system was used to expose, evaluate, and eliminate vulnerabilities of agentic AI. The prototype agent system was constructed and implemented, using Python, LangChain, and telemetry in WebSockets, and deployed with inference, memory, parameter tuning, and anomaly detection modules. Two practical threat cases were confirmed as follows: (i) resource denial of service by traffic replay denial-of-service, and (ii) memory poisoning by tampering with the historical log file maintained by the agent. These situations resulted in measurable levels of performance degradation, i.e. telemetry updates were delayed, and computational loads were increased, as a result of poor system adaptations. It was suggested to use a multilayered defense-in-depth approach with memory isolation, validation of planners and anomaly response systems in real-time. These findings verify that MAESTRO is viable in operational threat mapping, prospective risk scoring, and the basis of the resilient system design. The authors bring attention to the importance of the enforcement of memory integrity, paying attention to the adaptation logic monitoring, and cross-layer communication protection that guarantee the agentic AI reliability in adversarial settings.
å½“å°† LLMs ä¸ç”¨äºç½‘ç»œç›‘æ§å’Œå†³ç­–ç³»ç»Ÿçš„è‡ªä¸»ä»£ç†ç»“åˆä½¿ç”¨æ—¶ï¼Œä¼šäº§ç”Ÿä¸¥é‡çš„å®‰å…¨é—®é¢˜ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œä½¿ç”¨ç”±ä¸ƒå±‚å¨èƒå»ºæ¨¡æ¶æ„ç»„æˆçš„ MAESTRO æ¡†æ¶æ¥æ­ç¤ºã€è¯„ä¼°å¹¶æ¶ˆé™¤ä»£ç†å¼äººå·¥æ™ºèƒ½çš„æ¼æ´ã€‚ç”¨ Pythonã€LangChain å’Œé€šè¿‡ WebSockets çš„é¥æµ‹æ„å»ºå¹¶å®ç°äº†åŸå‹ä»£ç†ç³»ç»Ÿï¼Œå¹¶éƒ¨ç½²äº†æ¨ç†ã€è®°å¿†ã€å‚æ•°è°ƒä¼˜å’Œå¼‚å¸¸æ£€æµ‹æ¨¡å—ã€‚ç¡®è®¤äº†ä¸¤ä¸ªå®é™…å¨èƒæ¡ˆä¾‹ï¼š(i) é€šè¿‡æµé‡é‡æ”¾å¯¼è‡´çš„èµ„æºæ‹’ç»æœåŠ¡ï¼Œä»¥åŠ (ii) é€šè¿‡ç¯¡æ”¹ä»£ç†ç»´æŠ¤çš„å†å²æ—¥å¿—æ–‡ä»¶å¯¼è‡´çš„è®°å¿†æŠ•æ¯’ã€‚è¿™äº›æƒ…å†µå¯¼è‡´äº†å¯æµ‹é‡çš„æ€§èƒ½ä¸‹é™ï¼Œä¾‹å¦‚é¥æµ‹æ›´æ–°è¢«å»¶è¿Ÿã€è®¡ç®—è´Ÿè½½å¢åŠ ï¼Œå‡ä¸ºç³»ç»Ÿé€‚åº”ä¸è‰¯æ‰€è‡´ã€‚ç ”ç©¶å»ºè®®é‡‡ç”¨å¤šå±‚é˜²å¾¡çºµæ·±ç­–ç•¥ï¼Œç»“åˆè®°å¿†éš”ç¦»ã€è§„åˆ’å™¨éªŒè¯å’Œå®æ—¶å¼‚å¸¸å“åº”ç³»ç»Ÿã€‚ è¿™äº›å‘ç°éªŒè¯äº† MAESTRO åœ¨å®é™…å¨èƒæ˜ å°„ã€å‰ç»æ€§é£é™©è¯„åˆ†ä»¥åŠæ„å»ºå¼¹æ€§ç³»ç»Ÿè®¾è®¡åŸºç¡€æ–¹é¢çš„å¯è¡Œæ€§ã€‚ä½œè€…å¼ºè°ƒäº†å¼ºåˆ¶æ‰§è¡Œå†…å­˜å®Œæ•´æ€§çš„é‡è¦æ€§ï¼Œæ³¨é‡å¯¹é€‚åº”æ€§é€»è¾‘çš„ç›‘æ§ä»¥åŠè·¨å±‚é€šä¿¡ä¿æŠ¤ï¼Œä»¥ç¡®ä¿åœ¨å¯¹æŠ—æ€§ç¯å¢ƒä¸­è‡ªæ²»å‹äººå·¥æ™ºèƒ½çš„å¯é æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨æ€§ , äººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-12 00:14:12 UTC
å‘å¸ƒï¼š2025-08-12 00:14:12 UTC</p>
<h2 id="122-fidelis-blockchain-enabled-protection-against-poisoning-attacks-in-federated-learning--122-fidelisåŸºäºåŒºå—é“¾çš„è”é‚¦å­¦ä¹ ä¸­å¯¹æŠ—æŠ•æ¯’æ”»å‡»çš„ä¿æŠ¤"><a href="https://arxiv.org/abs/2508.10042"target="_blank" rel="external nofollow noopener noreferrer">#122</a> <a href="https://papers.cool/arxiv/2508.10042"target="_blank" rel="external nofollow noopener noreferrer">FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning</a>  #122 FIDELISï¼šåŸºäºåŒºå—é“¾çš„è”é‚¦å­¦ä¹ ä¸­å¯¹æŠ—æŠ•æ¯’æ”»å‡»çš„ä¿æŠ¤</h2>
<p><strong>Authors</strong>: [Jane Carney](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jane"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jane</a> Carney), [Kushal Upreti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kushal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kushal</a> Upreti), [Gaby G. Dagher](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gaby"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gaby</a> G. Dagher), [Tim Andersen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tim</a> Andersen)
ä½œè€…ï¼šJane Carneyã€Kushal Upretiã€Gaby G. Dagherã€Tim Andersen</p>
<p>Federated learning enhances traditional deep learning by enabling the joint training of a model with the use of IoT device&rsquo;s private data. It ensures privacy for clients, but is susceptible to data poisoning attacks during training that degrade model performance and integrity. Current poisoning detection methods in federated learning lack a standardized detection method or take significant liberties with trust. In this paper, we present \Sys, a novel blockchain-enabled poison detection framework in federated learning. The framework decentralizes the role of the global server across participating clients. We introduce a judge model used to detect data poisoning in model updates. The judge model is produced by each client and verified to reach consensus on a single judge model. We implement our solution to show \Sys is robust against data poisoning attacks and the creation of our judge model is scalable.
è”é‚¦å­¦ä¹ é€šè¿‡åˆ©ç”¨ç‰©è”ç½‘è®¾å¤‡çš„ç§æœ‰æ•°æ®æ¥å®ç°æ¨¡å‹çš„è”åˆè®­ç»ƒï¼Œä»è€Œå¢å¼ºäº†ä¼ ç»Ÿæ·±åº¦å­¦ä¹ ã€‚å®ƒä¸ºå®¢æˆ·ç«¯æä¾›éšç§ä¿éšœï¼Œä½†åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ˜“å—åˆ°æ•°æ®æŠ•æ¯’æ”»å‡»ï¼Œä»è€Œç ´åæ¨¡å‹çš„æ€§èƒ½å’Œå®Œæ•´æ€§ã€‚å½“å‰è”é‚¦å­¦ä¹ ä¸­çš„æŠ•æ¯’æ£€æµ‹æ–¹æ³•ç¼ºä¹æ ‡å‡†åŒ–çš„æ£€æµ‹æ‰‹æ®µæˆ–åœ¨ä¿¡ä»»ä¸Šåšå‡ºè¾ƒå¤§è®©æ­¥ã€‚æœ¬æ–‡æå‡ºäº†\Sysï¼Œä¸€ç§æ–°é¢–çš„åŸºäºåŒºå—é“¾çš„è”é‚¦å­¦ä¹ æŠ•æ¯’æ£€æµ‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†å…¨å±€æœåŠ¡å™¨çš„è§’è‰²å»ä¸­å¿ƒåŒ–åˆ°å‚ä¸çš„å®¢æˆ·ç«¯ä¸­ã€‚æˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ªç”¨äºæ£€æµ‹æ¨¡å‹æ›´æ–°ä¸­æ•°æ®æŠ•æ¯’çš„è£åˆ¤æ¨¡å‹ã€‚è£åˆ¤æ¨¡å‹ç”±æ¯ä¸ªå®¢æˆ·ç«¯ç”Ÿæˆå¹¶ç»è¿‡éªŒè¯ä»¥è¾¾æˆå¯¹å•ä¸€è£åˆ¤æ¨¡å‹çš„å…±è¯†ã€‚æˆ‘ä»¬å®ç°äº†è¯¥æ–¹æ¡ˆï¼Œå±•ç¤ºäº†\Sys å¯¹æ•°æ®æŠ•æ¯’æ”»å‡»çš„é²æ£’æ€§ä»¥åŠè£åˆ¤æ¨¡å‹ç”Ÿæˆçš„å¯æ‰©å±•æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨æ€§ , äººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-11 22:12:27 UTC
å‘å¸ƒï¼š2025-08-11 22:12:27 UTC</p>
<h2 id="123-exploring-content-and-social-connections-of-fake-news-with-explainable-text-and-graph-learning--123-ä½¿ç”¨å¯è§£é‡Šçš„æ–‡æœ¬å’Œå›¾å­¦ä¹ æ¢ç´¢å‡æ–°é—»çš„å†…å®¹ä¸ç¤¾äº¤å…³ç³»"><a href="https://arxiv.org/abs/2508.10040"target="_blank" rel="external nofollow noopener noreferrer">#123</a> <a href="https://papers.cool/arxiv/2508.10040"target="_blank" rel="external nofollow noopener noreferrer">Exploring Content and Social Connections of Fake News with Explainable Text and Graph Learning</a>  #123 ä½¿ç”¨å¯è§£é‡Šçš„æ–‡æœ¬å’Œå›¾å­¦ä¹ æ¢ç´¢å‡æ–°é—»çš„å†…å®¹ä¸ç¤¾äº¤å…³ç³»</h2>
<p><strong>Authors</strong>: [VÃ­tor N. LourenÃ§o](<a href="https://arxiv.org/search/?searchtype=author&amp;query=V"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=V</a>Ã­tor N. LourenÃ§o), [Aline Paes](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aline"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aline</a> Paes), [and Tillman Weyde](<a href="https://arxiv.org/search/?searchtype=author&amp;query=and"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=and</a> Tillman Weyde)
ä½œè€…ï¼šVÃ­tor N. LourenÃ§oã€Aline Paes å’Œ Tillman Weyde</p>
<p>The global spread of misinformation and concerns about content trustworthiness have driven the development of automated fact-checking systems. Since false information often exploits social media dynamics such as &ldquo;likes&rdquo; and user networks to amplify its reach, effective solutions must go beyond content analysis to incorporate these factors. Moreover, simply labelling content as false can be ineffective or even reinforce biases such as automation and confirmation bias. This paper proposes an explainable framework that combines content, social media, and graph-based features to enhance fact-checking. It integrates a misinformation classifier with explainability techniques to deliver complete and interpretable insights supporting classification decisions. Experiments demonstrate that multimodal information improves performance over single modalities, with evaluations conducted on datasets in English, Spanish, and Portuguese. Additionally, the framework&rsquo;s explanations were assessed for interpretability, trustworthiness, and robustness with a novel protocol, showing that it effectively generates human-understandable justifications for its predictions.
å…¨çƒèŒƒå›´å†…é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ä»¥åŠå¯¹å†…å®¹å¯ä¿¡åº¦çš„æ‹…å¿§æ¨åŠ¨äº†è‡ªåŠ¨äº‹å®æ ¸æŸ¥ç³»ç»Ÿçš„å‘å±•ã€‚ç”±äºè™šå‡ä¿¡æ¯å¸¸å¸¸åˆ©ç”¨â€œç‚¹èµâ€ç­‰ç¤¾äº¤åª’ä½“äº’åŠ¨å’Œç”¨æˆ·ç½‘ç»œç­‰åŠ¨æ€æ¥æ‰©å¤§å…¶ä¼ æ’­èŒƒå›´ï¼Œå› æ­¤æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆå¿…é¡»è¶…è¶Šå†…å®¹åˆ†æï¼Œå°†è¿™äº›å› ç´ çº³å…¥è€ƒé‡ã€‚æ­¤å¤–ï¼Œå•çº¯å°†å†…å®¹æ ‡æ³¨ä¸ºä¸å®å¯èƒ½æ— æ•ˆï¼Œç”šè‡³ä¼šå¼ºåŒ–è¯¸å¦‚å¯¹è‡ªåŠ¨åŒ–çš„åè§å’Œç¡®è®¤åè§ç­‰é—®é¢˜ã€‚æœ¬æ–‡æå‡ºäº†ä¸€ä¸ªå¯è§£é‡Šæ¡†æ¶ï¼Œç»“åˆå†…å®¹ç‰¹å¾ã€ç¤¾äº¤åª’ä½“ç‰¹å¾å’ŒåŸºäºå›¾çš„ç‰¹å¾ä»¥å¢å¼ºäº‹å®æ ¸æŸ¥ã€‚è¯¥æ¡†æ¶å°†é”™è¯¯ä¿¡æ¯åˆ†ç±»å™¨ä¸å¯è§£é‡Šæ€§æŠ€æœ¯ç»“åˆï¼Œæä¾›æ”¯æŒåˆ†ç±»å†³ç­–çš„å®Œæ•´ä¸”å¯è§£é‡Šçš„æ´è§ã€‚å®éªŒè¡¨æ˜ï¼Œå¤šæ¨¡æ€ä¿¡æ¯ç›¸æ¯”å•ä¸€æ¨¡æ€èƒ½æå‡æ€§èƒ½ï¼Œè¯„ä¼°åœ¨è‹±è¯­ã€è¥¿ç­ç‰™è¯­å’Œè‘¡è„ç‰™è¯­çš„æ•°æ®é›†ä¸Šè¿›è¡Œã€‚æ­¤å¤–ï¼Œæœ¬æ–‡ä½¿ç”¨ä¸€ç§æ–°é¢–çš„åè®®å¯¹æ¡†æ¶ç”Ÿæˆçš„è§£é‡Šåœ¨å¯è§£é‡Šæ€§ã€å¯ä¿¡åº¦å’Œé²æ£’æ€§æ–¹é¢è¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºå…¶èƒ½å¤Ÿä¸ºé¢„æµ‹ç”Ÿæˆæ˜“äºäººç±»ç†è§£çš„ç†ç”±ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.SI"target="_blank" rel="external nofollow noopener noreferrer">Social and Information Networks</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šç¤¾äº¤ä¸ä¿¡æ¯ç½‘ç»œï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-11 12:03:37 UTC
å‘å¸ƒï¼š2025-08-11 12:03:37 UTC</p>
<h2 id="124-multi-task-adversarial-attacks-against-black-box-model-with-few-shot-queries--124-é’ˆå¯¹é»‘ç®±æ¨¡å‹çš„å°‘æ ·æœ¬æŸ¥è¯¢å¤šä»»åŠ¡å¯¹æŠ—æ”»å‡»"><a href="https://arxiv.org/abs/2508.10039"target="_blank" rel="external nofollow noopener noreferrer">#124</a> <a href="https://papers.cool/arxiv/2508.10039"target="_blank" rel="external nofollow noopener noreferrer">Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries</a>  #124 é’ˆå¯¹é»‘ç®±æ¨¡å‹çš„å°‘æ ·æœ¬æŸ¥è¯¢å¤šä»»åŠ¡å¯¹æŠ—æ”»å‡»</h2>
<p><strong>Authors</strong>: [Wenqiang Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenqiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenqiang</a> Wang), [Yan Xiao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yan</a> Xiao), [Hao Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hao</a> Lin), [Yangshijie Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yangshijie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yangshijie</a> Zhang), [Xiaochun Cao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiaochun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiaochun</a> Cao)
ä½œè€…ï¼šç‹æ–‡å¼ºã€è‚–ç‡•ã€æ—æµ©ã€å¼ æ‰¬ä¸–æ°ã€æ›¹æ™“æ˜¥</p>
<p>Current multi-task adversarial text attacks rely on abundant access to shared internal features and numerous queries, often limited to a single task type. As a result, these attacks are less effective against practical scenarios involving black-box feedback APIs, limited queries, or multiple task types. To bridge this gap, we propose \textbf{C}luster and \textbf{E}nsemble \textbf{M}ulti-task Text Adversarial \textbf{A}ttack (\textbf{CEMA}), an effective black-box attack that exploits the transferability of adversarial texts across different tasks. CEMA simplifies complex multi-task scenarios by using a \textit{deep-level substitute model} trained in a \textit{plug-and-play} manner for text classification, enabling attacks without mimicking the victim model. This approach requires only a few queries for training, converting multi-task attacks into classification attacks and allowing attacks across various tasks. CEMA generates multiple adversarial candidates using different text classification methods and selects the one that most effectively attacks substitute models. In experiments involving multi-task models with two, three, or six tasks&ndash;spanning classification, translation, summarization, and text-to-image generation&ndash;CEMA demonstrates significant attack success with as few as 100 queries. Furthermore, CEMA can target commercial APIs (e.g., Baidu and Google Translate), large language models (e.g., ChatGPT 4o), and image-generation models (e.g., Stable Diffusion V2), showcasing its versatility and effectiveness in real-world applications.
ç›®å‰çš„å¤šä»»åŠ¡å¯¹æŠ—æ€§æ–‡æœ¬æ”»å‡»ä¾èµ–äºå¤§é‡è·å–å…±äº«å†…éƒ¨ç‰¹å¾å’Œå¤§é‡æŸ¥è¯¢ï¼Œä¸”é€šå¸¸å±€é™äºå•ä¸€ä»»åŠ¡ç±»å‹ã€‚å› æ­¤ï¼Œè¿™äº›æ”»å‡»åœ¨é¢å¯¹å…·æœ‰é»‘ç®±åé¦ˆ APIã€æŸ¥è¯¢å—é™æˆ–å¤šä»»åŠ¡ç±»å‹çš„å®é™…åœºæ™¯æ—¶æ•ˆæœè¾ƒå·®ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€å·®è·ï¼Œæˆ‘ä»¬æå‡ºäº†ç°‡ä¸é›†æˆå¤šä»»åŠ¡æ–‡æœ¬å¯¹æŠ—æ”»å‡»ï¼ˆCEMAï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æœ‰æ•ˆçš„é»‘ç®±æ”»å‡»æ–¹æ³•ï¼Œåˆ©ç”¨å¯¹æŠ—æ–‡æœ¬åœ¨ä¸åŒä»»åŠ¡é—´çš„å¯è¿ç§»æ€§ã€‚CEMA é€šè¿‡ä½¿ç”¨ä»¥æ’æ‹”å¼æ–¹å¼è®­ç»ƒçš„æ·±å±‚æ›¿ä»£æ¨¡å‹ï¼ˆç”¨äºæ–‡æœ¬åˆ†ç±»ï¼‰ç®€åŒ–å¤æ‚çš„å¤šä»»åŠ¡åœºæ™¯ï¼Œä½¿å¾—åœ¨æ— éœ€æ¨¡æ‹Ÿå—å®³è€…æ¨¡å‹çš„æƒ…å†µä¸‹ä¹Ÿèƒ½å‘èµ·æ”»å‡»ã€‚è¯¥æ–¹æ³•ä»…éœ€å°‘é‡æŸ¥è¯¢è¿›è¡Œè®­ç»ƒï¼Œå°†å¤šä»»åŠ¡æ”»å‡»è½¬åŒ–ä¸ºåˆ†ç±»æ”»å‡»ï¼Œä»è€Œèƒ½å¤Ÿè·¨å¤šç§ä»»åŠ¡è¿›è¡Œæ”»å‡»ã€‚CEMA ä½¿ç”¨ä¸åŒçš„æ–‡æœ¬åˆ†ç±»æ–¹æ³•ç”Ÿæˆå¤šä¸ªå¯¹æŠ—å€™é€‰æ–‡æœ¬ï¼Œå¹¶é€‰æ‹©å…¶ä¸­å¯¹æ›¿ä»£æ¨¡å‹æ”»å‡»æ•ˆæœæœ€å¥½çš„å€™é€‰ã€‚ åœ¨æ¶‰åŠä¸¤ä¸ªã€ä¸‰ä¸ªæˆ–å…­ä¸ªä»»åŠ¡çš„å¤šä»»åŠ¡æ¨¡å‹çš„å®éªŒä¸­â€”â€”æ¶µç›–åˆ†ç±»ã€ç¿»è¯‘ã€æ‘˜è¦å’Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆâ€”â€”CEMA åœ¨ä»…çº¦ 100 æ¬¡æŸ¥è¯¢ä¸‹å°±è¡¨ç°å‡ºæ˜¾è‘—çš„æ”»å‡»æˆåŠŸç‡ã€‚æ­¤å¤–ï¼ŒCEMA èƒ½å¤Ÿé’ˆå¯¹å•†ä¸š APIï¼ˆä¾‹å¦‚ç™¾åº¦å’Œ Google ç¿»è¯‘ï¼‰ã€å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆä¾‹å¦‚ ChatGPT 4oï¼‰ä»¥åŠå›¾åƒç”Ÿæˆæ¨¡å‹ï¼ˆä¾‹å¦‚ Stable Diffusion V2ï¼‰ï¼Œå±•ç¤ºäº†å…¶åœ¨ç°å®åº”ç”¨ä¸­çš„å¤šåŠŸèƒ½æ€§å’Œæœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨æ€§ , äººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-10 12:46:47 UTC
å‘å¸ƒï¼š2025-08-10 12:46:47 UTC</p>
<h2 id="125-certifiably-robust-malware-detectors-by-design--125-é€šè¿‡è®¾è®¡å®ç°å¯éªŒè¯é²æ£’çš„æ¶æ„è½¯ä»¶æ£€æµ‹å™¨"><a href="https://arxiv.org/abs/2508.10038"target="_blank" rel="external nofollow noopener noreferrer">#125</a> <a href="https://papers.cool/arxiv/2508.10038"target="_blank" rel="external nofollow noopener noreferrer">Certifiably robust malware detectors by design</a>  #125 é€šè¿‡è®¾è®¡å®ç°å¯éªŒè¯é²æ£’çš„æ¶æ„è½¯ä»¶æ£€æµ‹å™¨</h2>
<p><strong>Authors</strong>: [Pierre-Francois Gimenez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Pierre-Francois"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Pierre-Francois</a> Gimenez), [Sarath Sivaprasad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sarath"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sarath</a> Sivaprasad), [Mario Fritz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mario"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mario</a> Fritz)
ä½œè€…ï¼šPierre-Francois Gimenezã€Sarath Sivaprasadã€Mario Fritz</p>
<p>Malware analysis involves analyzing suspicious software to detect malicious payloads. Static malware analysis, which does not require software execution, relies increasingly on machine learning techniques to achieve scalability. Although such techniques obtain very high detection accuracy, they can be easily evaded with adversarial examples where a few modifications of the sample can dupe the detector without modifying the behavior of the software. Unlike other domains, such as computer vision, creating an adversarial example of malware without altering its functionality requires specific transformations. We propose a new model architecture for certifiably robust malware detection by design. In addition, we show that every robust detector can be decomposed into a specific structure, which can be applied to learn empirically robust malware detectors, even on fragile features. Our framework ERDALT is based on this structure. We compare and validate these approaches with machine-learning-based malware detection methods, allowing for robust detection with limited reduction of detection performance.
æ¶æ„è½¯ä»¶åˆ†ææ¶‰åŠåˆ†æå¯ç–‘è½¯ä»¶ä»¥æ£€æµ‹æ¶æ„è´Ÿè½½ã€‚é™æ€æ¶æ„è½¯ä»¶åˆ†æä¸éœ€è¦æ‰§è¡Œè½¯ä»¶ï¼Œè¶Šæ¥è¶Šä¾èµ–æœºå™¨å­¦ä¹ æŠ€æœ¯ä»¥å®ç°å¯æ‰©å±•æ€§ã€‚å°½ç®¡æ­¤ç±»æŠ€æœ¯èƒ½è·å¾—éå¸¸é«˜çš„æ£€æµ‹å‡†ç¡®ç‡ï¼Œä½†å®ƒä»¬å¾ˆå®¹æ˜“è¢«å¯¹æŠ—æ€§æ ·æœ¬è§„é¿â€”â€”åªéœ€å¯¹æ ·æœ¬è¿›è¡Œå°‘é‡ä¿®æ”¹å³å¯æ¬ºéª—æ£€æµ‹å™¨ï¼Œè€Œä¸æ”¹å˜è½¯ä»¶çš„è¡Œä¸ºã€‚ä¸è®¡ç®—æœºè§†è§‰ç­‰å…¶ä»–é¢†åŸŸä¸åŒï¼Œåœ¨ä¸æ”¹å˜åŠŸèƒ½æ€§çš„å‰æä¸‹åˆ›å»ºæ¶æ„è½¯ä»¶çš„å¯¹æŠ—æ€§æ ·æœ¬éœ€è¦ç‰¹å®šçš„å˜æ¢ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ç§é€šè¿‡è®¾è®¡å®ç°å¯è¯æ˜ç¡®ä¿ç¨³å¥çš„æ¶æ„è½¯ä»¶æ£€æµ‹æ–°æ¨¡å‹æ¶æ„ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¯æ˜æ¯ä¸ªç¨³å¥çš„æ£€æµ‹å™¨éƒ½å¯ä»¥åˆ†è§£ä¸ºä¸€ç§ç‰¹å®šç»“æ„ï¼Œè¯¥ç»“æ„å¯ç”¨äºåœ¨è„†å¼±ç‰¹å¾ä¸Šå­¦ä¹ ç»éªŒä¸Šç¨³å¥çš„æ¶æ„è½¯ä»¶æ£€æµ‹å™¨ã€‚æˆ‘ä»¬çš„æ¡†æ¶ ERDALT åŸºäºæ­¤ç»“æ„ã€‚æˆ‘ä»¬å°†è¿™äº›æ–¹æ³•ä¸åŸºäºæœºå™¨å­¦ä¹ çš„æ¶æ„è½¯ä»¶æ£€æµ‹æ–¹æ³•è¿›è¡Œäº†æ¯”è¾ƒå’ŒéªŒè¯ï¼Œä½¿å¾—åœ¨å¯¹æ£€æµ‹æ€§èƒ½é€ æˆæœ‰é™é™ä½çš„æƒ…å†µä¸‹å®ç°ç¨³å¥æ£€æµ‹ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨æ€§ , äººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-10 09:19:29 UTC
å‘å¸ƒï¼š2025-08-10 09:19:29 ä¸–ç•Œåè°ƒæ—¶</p>
<h2 id="126-reflect-then-learn-active-prompting-for-information-extraction-guided-by-introspective-confusion--126-å…ˆåæ€åå­¦ä¹ ç”±å†…çœæ€§å›°æƒ‘å¼•å¯¼çš„ä¿¡æ¯æŠ½å–ä¸»åŠ¨æç¤º"><a href="https://arxiv.org/abs/2508.10036"target="_blank" rel="external nofollow noopener noreferrer">#126</a> <a href="https://papers.cool/arxiv/2508.10036"target="_blank" rel="external nofollow noopener noreferrer">Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion</a>  #126 å…ˆåæ€åå­¦ä¹ ï¼šç”±å†…çœæ€§å›°æƒ‘å¼•å¯¼çš„ä¿¡æ¯æŠ½å–ä¸»åŠ¨æç¤º</h2>
<p><strong>Authors</strong>: [Dong Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dong</a> Zhao), [Yadong Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yadong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yadong</a> Wang), [Xiang Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiang</a> Chen), [Chenxi Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chenxi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chenxi</a> Wang), [Hongliang Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hongliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hongliang</a> Dai), [Chuanxing Geng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chuanxing"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chuanxing</a> Geng), [Shengzhong Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shengzhong"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shengzhong</a> Zhang), [Shaoyuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shaoyuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shaoyuan</a> Li), [Sheng-Jun Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sheng-Jun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sheng-Jun</a> Huang)
ä½œè€…ï¼šèµµä¸œï¼Œç‹äºšä¸œï¼Œé™ˆç¿”ï¼Œç‹æ™¨æ›¦ï¼Œæˆ´å®äº®ï¼Œè€¿ä¼ å…´ï¼Œå¼ èƒœä¸­ï¼Œæå°‘å…ƒï¼Œé»„èƒœå†›</p>
<p>Large Language Models (LLMs) show remarkable potential for few-shot information extraction (IE), yet their performance is highly sensitive to the choice of in-context examples. Conventional selection strategies often fail to provide informative guidance, as they overlook a key source of model fallibility: confusion stemming not just from semantic content, but also from the generation of well-structured formats required by IE tasks. To address this, we introduce Active Prompting for Information Extraction (APIE), a novel active prompting framework guided by a principle we term introspective confusion. Our method empowers an LLM to assess its own confusion through a dual-component uncertainty metric that uniquely quantifies both Format Uncertainty (difficulty in generating correct syntax) and Content Uncertainty (inconsistency in extracted semantics). By ranking unlabeled data with this comprehensive score, our framework actively selects the most challenging and informative samples to serve as few-shot exemplars. Extensive experiments on four benchmarks show that our approach consistently outperforms strong baselines, yielding significant improvements in both extraction accuracy and robustness. Our work highlights the critical importance of a fine-grained, dual-level view of model uncertainty when it comes to building effective and reliable structured generation systems.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å°‘æ ·æœ¬ä¿¡æ¯æŠ½å–ï¼ˆIEï¼‰æ–¹é¢å±•ç°å‡ºæ˜¾è‘—æ½œåŠ›ï¼Œä½†å…¶æ€§èƒ½å¯¹ä¸Šä¸‹æ–‡ç¤ºä¾‹çš„é€‰æ‹©é«˜åº¦æ•æ„Ÿã€‚ä¼ ç»Ÿçš„é€‰æ‹©ç­–ç•¥å¾€å¾€æ— æ³•æä¾›æœ‰æ•ˆçš„æŒ‡å¯¼ï¼Œå› ä¸ºå®ƒä»¬å¿½è§†äº†æ¨¡å‹æ˜“å‡ºé”™çš„ä¸€ä¸ªå…³é”®æ¥æºï¼šå›°æƒ‘ä¸ä»…æºè‡ªè¯­ä¹‰å†…å®¹ï¼Œè¿˜æ¥è‡ªäºç”Ÿæˆä¿¡æ¯æŠ½å–ä»»åŠ¡æ‰€éœ€çš„è‰¯å¥½ç»“æ„åŒ–æ ¼å¼ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ç”¨äºä¿¡æ¯æŠ½å–çš„ä¸»åŠ¨æç¤ºï¼ˆAPIEï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç”±æˆ‘ä»¬ç§°ä¸ºå†…çœæ€§å›°æƒ‘çš„åŸåˆ™æŒ‡å¯¼çš„æ–°å‹ä¸»åŠ¨æç¤ºæ¡†æ¶ã€‚æˆ‘ä»¬çš„æ–¹æ³•ä½¿ LLM èƒ½å¤Ÿé€šè¿‡ä¸€ä¸ªåŒæˆåˆ†ä¸ç¡®å®šæ€§åº¦é‡æ¥è¯„ä¼°è‡ªèº«çš„å›°æƒ‘ï¼Œè¯¥åº¦é‡ç‹¬ç‰¹åœ°é‡åŒ–äº†æ ¼å¼ä¸ç¡®å®šæ€§ï¼ˆç”Ÿæˆæ­£ç¡®è¯­æ³•çš„å›°éš¾ï¼‰å’Œå†…å®¹ä¸ç¡®å®šæ€§ï¼ˆæŠ½å–è¯­ä¹‰çš„ä¸ä¸€è‡´æ€§ï¼‰ã€‚é€šè¿‡ç”¨è¿™ä¸€ç»¼åˆåˆ†æ•°å¯¹æœªæ ‡æ³¨æ•°æ®æ’åºï¼Œæˆ‘ä»¬çš„æ¡†æ¶ä¸»åŠ¨é€‰æ‹©æœ€å…·æŒ‘æˆ˜æ€§å’Œä¿¡æ¯é‡çš„æ ·æœ¬ä½œä¸ºå°‘æ ·æœ¬ç¤ºä¾‹ã€‚ åœ¨å››ä¸ªåŸºå‡†æ•°æ®é›†ä¸Šçš„å¤§é‡å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ–¹æ³•æŒç»­ä¼˜äºå¼ºåŸºçº¿ï¼Œåœ¨æŠ½å–å‡†ç¡®æ€§å’Œç¨³å¥æ€§æ–¹é¢å‡å¸¦æ¥æ˜¾è‘—æå‡ã€‚æˆ‘ä»¬çš„å·¥ä½œå¼ºè°ƒäº†åœ¨æ„å»ºæœ‰æ•ˆä¸”å¯é çš„ç»“æ„åŒ–ç”Ÿæˆç³»ç»Ÿæ—¶ï¼Œå¯¹æ¨¡å‹ä¸ç¡®å®šæ€§è¿›è¡Œç»†ç²’åº¦åŒå±‚è§†è§’çš„é‡è¦æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œä¿¡æ¯æ£€ç´¢ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-10 02:27:41 UTC
å‘å¸ƒï¼š2025-08-10 02:27:41 UTC</p>
<h2 id="127-jet-image-tagging-using-deep-learning-an-ensemble-model--127-å–·æ°”æœºå›¾åƒæ ‡æ³¨ä½¿ç”¨æ·±åº¦å­¦ä¹ ä¸€ç§é›†æˆæ¨¡å‹"><a href="https://arxiv.org/abs/2508.10034"target="_blank" rel="external nofollow noopener noreferrer">#127</a> <a href="https://papers.cool/arxiv/2508.10034"target="_blank" rel="external nofollow noopener noreferrer">Jet Image Tagging Using Deep Learning: An Ensemble Model</a>  #127 å–·æ°”æœºå›¾åƒæ ‡æ³¨ä½¿ç”¨æ·±åº¦å­¦ä¹ ï¼šä¸€ç§é›†æˆæ¨¡å‹</h2>
<p><strong>Authors</strong>: [Juvenal Bassa](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Juvenal"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Juvenal</a> Bassa), [Vidya Manian](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vidya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vidya</a> Manian), [Sudhir Malik](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sudhir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sudhir</a> Malik), [Arghya Chattopadhyay](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Arghya"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Arghya</a> Chattopadhyay)
ä½œè€…ï¼šJuvenal Bassaã€Vidya Manianã€Sudhir Malikã€Arghya Chattopadhyay</p>
<p>Jet classification in high-energy particle physics is important for understanding fundamental interactions and probing phenomena beyond the Standard Model. Jets originate from the fragmentation and hadronization of quarks and gluons, and pose a challenge for identification due to their complex, multidimensional structure. Traditional classification methods often fall short in capturing these intricacies, necessitating advanced machine learning approaches. In this paper, we employ two neural networks simultaneously as an ensemble to tag various jet types. We convert the jet data to two-dimensional histograms instead of representing them as points in a higher-dimensional space. Specifically, this ensemble approach, hereafter referred to as Ensemble Model, is used to tag jets into classes from the JetNet dataset, corresponding to: Top Quarks, Light Quarks (up or down), and W and Z bosons. For the jet classes mentioned above, we show that the Ensemble Model can be used for both binary and multi-categorical classification. This ensemble approach learns jet features by leveraging the strengths of each constituent network achieving superior performance compared to either individual network.
åœ¨é«˜èƒ½ç²’å­ç‰©ç†å­¦ä¸­ï¼Œå–·æ³¨åˆ†ç±»å¯¹äºç†è§£åŸºæœ¬ç›¸äº’ä½œç”¨å’Œæ¢ç´¢è¶…å‡ºæ ‡å‡†æ¨¡å‹çš„ç°è±¡è‡³å…³é‡è¦ã€‚å–·æ³¨èµ·æºäºå¤¸å…‹å’Œèƒ¶å­å‘ç”Ÿç¢è£‚ä¸å¼ºå­åŒ–çš„è¿‡ç¨‹ï¼Œå…¶å¤æ‚çš„å¤šç»´ç»“æ„ä½¿å¾—è¯†åˆ«æˆä¸ºä¸€é¡¹æŒ‘æˆ˜ã€‚ä¼ ç»Ÿçš„åˆ†ç±»æ–¹æ³•å¾€å¾€éš¾ä»¥æ•æ‰è¿™äº›å¤æ‚æ€§ï¼Œå› æ­¤éœ€è¦æ›´å…ˆè¿›çš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åŒæ—¶ä½¿ç”¨ä¸¤ä¸ªç¥ç»ç½‘ç»œä½œä¸ºä¸€ä¸ªé›†æˆæ¥æ ‡æ³¨ä¸åŒç±»å‹çš„å–·æ³¨ã€‚æˆ‘ä»¬å°†å–·æ³¨æ•°æ®è½¬æ¢ä¸ºäºŒç»´ç›´æ–¹å›¾ï¼Œè€Œä¸æ˜¯å°†å®ƒä»¬è¡¨ç¤ºä¸ºé«˜ç»´ç©ºé—´ä¸­çš„ç‚¹ã€‚å…·ä½“è€Œè¨€ï¼Œè¿™ç§é›†æˆæ–¹æ³•ï¼ˆä¸‹æ–‡ç§°ä¸ºâ€œé›†æˆæ¨¡å‹â€ï¼‰ç”¨äºå¯¹ JetNet æ•°æ®é›†ä¸­å¯¹åº”ä»¥ä¸‹ç±»åˆ«çš„å–·æ³¨è¿›è¡Œæ ‡æ³¨ï¼šé¡¶å¤¸å…‹ã€è½»å¤¸å…‹ï¼ˆä¸Šæˆ–ä¸‹ï¼‰ä»¥åŠ W å’Œ Z ç»è‰²å­ã€‚å¯¹äºä¸Šè¿°å–·æ³¨ç±»åˆ«ï¼Œæˆ‘ä»¬å±•ç¤ºäº†é›†æˆæ¨¡å‹æ—¢å¯ç”¨äºäºŒåˆ†ç±»ï¼Œä¹Ÿå¯ç”¨äºå¤šç±»åˆ«åˆ†ç±»ã€‚ è¿™ç§é›†æˆæ–¹æ³•é€šè¿‡åˆ©ç”¨æ¯ä¸ªç»„æˆç½‘ç»œçš„ä¼˜åŠ¿æ¥å­¦ä¹ å–·æ³¨ç‰¹å¾ï¼Œä»è€Œæ¯”ä»»ä¸€å•ç‹¬ç½‘ç»œéƒ½èƒ½å–å¾—æ›´ä¼˜çš„æ€§èƒ½ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/physics.data-an"target="_blank" rel="external nofollow noopener noreferrer">Data Analysis, Statistics and Probability</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/hep-ex"target="_blank" rel="external nofollow noopener noreferrer">High Energy Physics - Experiment</a>, <a href="https://papers.cool/arxiv/hep-ph"target="_blank" rel="external nofollow noopener noreferrer">High Energy Physics - Phenomenology</a>
å­¦ç§‘ï¼šæ•°æ®åˆ†æã€ç»Ÿè®¡ä¸æ¦‚ç‡ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€å®éªŒé«˜èƒ½ç‰©ç†ã€é«˜èƒ½ç‰©ç†â€”ç°è±¡å­¦</p>
<p><strong>Publish</strong>: 2025-08-09 17:40:15 UTC
å‘å¸ƒï¼š2025-08-09 17:40:15 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="128-cognitive-cybersecurity-for-artificial-intelligence-guardrail-engineering-with-ccs-7--128-é¢å‘äººå·¥æ™ºèƒ½çš„è®¤çŸ¥ç½‘ç»œå®‰å…¨ä½¿ç”¨-ccs-7-çš„æŠ¤æ å·¥ç¨‹"><a href="https://arxiv.org/abs/2508.10033"target="_blank" rel="external nofollow noopener noreferrer">#128</a> <a href="https://papers.cool/arxiv/2508.10033"target="_blank" rel="external nofollow noopener noreferrer">Cognitive Cybersecurity for Artificial Intelligence: Guardrail Engineering with CCS-7</a>  #128 é¢å‘äººå·¥æ™ºèƒ½çš„è®¤çŸ¥ç½‘ç»œå®‰å…¨ï¼šä½¿ç”¨ CCS-7 çš„æŠ¤æ å·¥ç¨‹</h2>
<p><strong>Author</strong>: [Yuksel Aydin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuksel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuksel</a> Aydin) ä½œè€…ï¼šYuksel Aydin</p>
<p>Language models exhibit human-like cognitive vulnerabilities, such as emotional framing, that escape traditional behavioral alignment. We present CCS-7 (Cognitive Cybersecurity Suite), a taxonomy of seven vulnerabilities grounded in human cognitive security research. To establish a human benchmark, we ran a randomized controlled trial with 151 participants: a &ldquo;Think First, Verify Always&rdquo; (TFVA) lesson improved cognitive security by +7.9% overall. We then evaluated TFVA-style guardrails across 12,180 experiments on seven diverse language model architectures. Results reveal architecture-dependent risk patterns: some vulnerabilities (e.g., identity confusion) are almost fully mitigated, while others (e.g., source interference) exhibit escalating backfire, with error rates increasing by up to 135% in certain models. Humans, in contrast, show consistent moderate improvement. These findings reframe cognitive safety as a model-specific engineering problem: interventions effective in one architecture may fail, or actively harm, another, underscoring the need for architecture-aware cognitive safety testing before deployment.
è¯­è¨€æ¨¡å‹è¡¨ç°å‡ºç±»ä¼¼äººç±»çš„è®¤çŸ¥å¼±ç‚¹ï¼Œä¾‹å¦‚æƒ…ç»ªæ¡†æ¶æ•ˆåº”ï¼Œè¿™äº›å¼±ç‚¹è¶…å‡ºäº†ä¼ ç»Ÿè¡Œä¸ºå¯¹é½çš„è¦†ç›–èŒƒå›´ã€‚æˆ‘ä»¬æå‡ºäº† CCS-7ï¼ˆè®¤çŸ¥ç½‘ç»œå®‰å…¨å¥—ä»¶ï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºäººç±»è®¤çŸ¥å®‰å…¨ç ”ç©¶çš„ä¸ƒç±»å¼±ç‚¹åˆ†ç±»æ³•ã€‚ä¸ºäº†å»ºç«‹äººç±»åŸºå‡†ï¼Œæˆ‘ä»¬å¼€å±•äº†ä¸€é¡¹æ¶‰åŠ 151 åå‚ä¸è€…çš„éšæœºå¯¹ç…§è¯•éªŒï¼šâ€œå…ˆæ€è€ƒã€åéªŒè¯â€ï¼ˆTFVAï¼‰è¯¾ç¨‹ä½¿è®¤çŸ¥å®‰å…¨æ€»ä½“æå‡äº†+7.9%ã€‚éšåæˆ‘ä»¬åœ¨ä¸ƒç§ä¸åŒçš„è¯­è¨€æ¨¡å‹æ¶æ„ä¸Šè¿›è¡Œäº† 12,180 æ¬¡å…³äº TFVA å¼é˜²æŠ¤æªæ–½çš„è¯„ä¼°ã€‚ç»“æœæ˜¾ç¤ºå‡ºä¸æ¶æ„ç›¸å…³çš„é£é™©æ¨¡å¼ï¼šæŸäº›å¼±ç‚¹ï¼ˆä¾‹å¦‚èº«ä»½æ··æ·†ï¼‰å‡ ä¹è¢«å®Œå…¨ç¼“è§£ï¼Œè€Œå¦ä¸€äº›å¼±ç‚¹ï¼ˆä¾‹å¦‚æ¥æºå¹²æ‰°ï¼‰åˆ™å‡ºç°é€æ­¥åæ•ˆæœï¼Œåœ¨æŸäº›æ¨¡å‹ä¸­é”™è¯¯ç‡æå‡äº†å¤šè¾¾ 135%ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œäººç±»è¡¨ç°å‡ºæŒç»­çš„ä¸­åº¦æ”¹è¿›ã€‚è¿™äº›å‘ç°å°†è®¤çŸ¥å®‰å…¨é‡æ–°å®šä½ä¸ºä¸€ä¸ªç‰¹å®šæ¶æ„çš„å·¥ç¨‹é—®é¢˜ï¼šåœ¨ä¸€ç§æ¶æ„ä¸­æœ‰æ•ˆçš„å¹²é¢„æªæ–½å¯èƒ½åœ¨å¦ä¸€ç§æ¶æ„ä¸­å¤±æ•ˆï¼Œç”šè‡³äº§ç”Ÿè´Ÿé¢å½±å“ï¼Œå› æ­¤åœ¨éƒ¨ç½²å‰éœ€è¦è¿›è¡Œé¢å‘æ¶æ„çš„è®¤çŸ¥å®‰å…¨æµ‹è¯•ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨æ€§ , äººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-09 15:46:30 UTC
å‘å¸ƒï¼š2025-08-09 15:46:30 UTC</p>
<h2 id="129-the-cost-of-thinking-increased-jailbreak-risk-in-large-language-models--129-æ€è€ƒçš„ä»£ä»·å¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¶Šç‹±é£é™©çš„å¢åŠ "><a href="https://arxiv.org/abs/2508.10032"target="_blank" rel="external nofollow noopener noreferrer">#129</a> <a href="https://papers.cool/arxiv/2508.10032"target="_blank" rel="external nofollow noopener noreferrer">The Cost of Thinking: Increased Jailbreak Risk in Large Language Models</a>  #129 æ€è€ƒçš„ä»£ä»·ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ä¸­è¶Šç‹±é£é™©çš„å¢åŠ </h2>
<p><strong>Author</strong>: [Fan Yang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fan</a> Yang) ä½œè€…ï¼šæ¨å¸†</p>
<p>Thinking mode has always been regarded as one of the most valuable modes in LLMs. However, we uncover a surprising and previously overlooked phenomenon: LLMs with thinking mode are more easily broken by Jailbreak attack. We evaluate 9 LLMs on AdvBench and HarmBench and find that the success rate of attacking thinking mode in LLMs is almost higher than that of non-thinking mode. Through large numbers of sample studies, it is found that for educational purposes and excessively long thinking lengths are the characteristics of successfully attacked data, and LLMs also give harmful answers when they mostly know that the questions are harmful. In order to alleviate the above problems, this paper proposes a method of safe thinking intervention for LLMs, which explicitly guides the internal thinking processes of LLMs by adding &ldquo;specific thinking tokens&rdquo; of LLMs to the prompt. The results demonstrate that the safe thinking intervention can significantly reduce the attack success rate of LLMs with thinking mode.
æ€ç»´æ¨¡å¼ä¸€ç›´è¢«è§†ä¸º LLMs ä¸­æœ€æœ‰ä»·å€¼çš„æ¨¡å¼ä¹‹ä¸€ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬å‘ç°äº†ä¸€ä¸ªä»¤äººæƒŠè®¶ä¸”æ­¤å‰è¢«å¿½è§†çš„ç°è±¡ï¼šå…·æœ‰æ€ç»´æ¨¡å¼çš„ LLMs æ›´å®¹æ˜“è¢«è¶Šç‹±æ”»å‡»ï¼ˆJailbreak attackï¼‰çªç ´ã€‚æˆ‘ä»¬åœ¨ AdvBench å’Œ HarmBench ä¸Šè¯„ä¼°äº† 9 ä¸ª LLMsï¼Œå‘ç°é’ˆå¯¹ LLMs æ€ç»´æ¨¡å¼çš„æ”»å‡»æˆåŠŸç‡å‡ ä¹éƒ½é«˜äºéæ€ç»´æ¨¡å¼ã€‚é€šè¿‡å¤§é‡æ ·æœ¬ç ”ç©¶å‘ç°ï¼Œç”¨äºæ•™è‚²ç›®çš„å’Œè¿‡é•¿çš„æ€ç»´é•¿åº¦æ˜¯è¢«æˆåŠŸæ”»å‡»æ•°æ®çš„ç‰¹å¾ï¼Œè€Œä¸”å½“ LLMs å¤§ä½“ä¸ŠçŸ¥é“é—®é¢˜æ˜¯æœ‰å®³çš„æ—¶ï¼Œå®ƒä»¬ä¹Ÿä¼šç»™å‡ºæœ‰å®³å›ç­”ã€‚ä¸ºç¼“è§£ä¸Šè¿°é—®é¢˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§å¯¹ LLMs è¿›è¡Œå®‰å…¨æ€ç»´å¹²é¢„çš„æ–¹æ³•ï¼Œé€šè¿‡åœ¨æç¤ºä¸­åŠ å…¥ LLMs çš„â€œç‰¹å®šæ€ç»´æ ‡è®°â€æ¥æ˜¾å¼å¼•å¯¼ LLMs çš„å†…éƒ¨æ€ç»´è¿‡ç¨‹ã€‚ç»“æœè¡¨æ˜ï¼Œå®‰å…¨æ€ç»´å¹²é¢„å¯ä»¥æ˜¾è‘—é™ä½å…·æœ‰æ€ç»´æ¨¡å¼çš„ LLMs çš„æ”»å‡»æˆåŠŸç‡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-09 09:49:49 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-09 09:49:49 UTC</p>
<h2 id="130-context-misleads-llms-the-role-of-context-filtering-in-maintaining-safe-alignment-of-llms--130-ä¸Šä¸‹æ–‡è¯¯å¯¼-llmsä¸Šä¸‹æ–‡è¿‡æ»¤åœ¨ç»´æŒ-llms-å®‰å…¨å¯¹é½ä¸­çš„ä½œç”¨"><a href="https://arxiv.org/abs/2508.10031"target="_blank" rel="external nofollow noopener noreferrer">#130</a> <a href="https://papers.cool/arxiv/2508.10031"target="_blank" rel="external nofollow noopener noreferrer">Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs</a>  #130 ä¸Šä¸‹æ–‡è¯¯å¯¼ LLMsï¼šä¸Šä¸‹æ–‡è¿‡æ»¤åœ¨ç»´æŒ LLMs å®‰å…¨å¯¹é½ä¸­çš„ä½œç”¨</h2>
<p><strong>Authors</strong>: [Jinhwa Kim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinhwa"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinhwa</a> Kim), [Ian G. Harris](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ian</a> G. Harris)
ä½œè€…ï¼šJinhwa Kim, Ian G. Harris</p>
<p>While Large Language Models (LLMs) have shown significant advancements in performance, various jailbreak attacks have posed growing safety and ethical risks. Malicious users often exploit adversarial context to deceive LLMs, prompting them to generate responses to harmful queries. In this study, we propose a new defense mechanism called Context Filtering model, an input pre-processing method designed to filter out untrustworthy and unreliable context while identifying the primary prompts containing the real user intent to uncover concealed malicious intent. Given that enhancing the safety of LLMs often compromises their helpfulness, potentially affecting the experience of benign users, our method aims to improve the safety of the LLMs while preserving their original performance. We evaluate the effectiveness of our model in defending against jailbreak attacks through comparative analysis, comparing our approach with state-of-the-art defense mechanisms against six different attacks and assessing the helpfulness of LLMs under these defenses. Our model demonstrates its ability to reduce the Attack Success Rates of jailbreak attacks by up to 88% while maintaining the original LLMs&rsquo; performance, achieving state-of-the-art Safety and Helpfulness Product results. Notably, our model is a plug-and-play method that can be applied to all LLMs, including both white-box and black-box models, to enhance their safety without requiring any fine-tuning of the models themselves. We will make our model publicly available for research purposes.
å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ€§èƒ½ä¸Šå–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå„ç§è¶Šç‹±æ”»å‡»å´å¸¦æ¥äº†æ—¥ç›Šå¢é•¿çš„å®‰å…¨å’Œä¼¦ç†é£é™©ã€‚æ¶æ„ç”¨æˆ·å¸¸é€šè¿‡å¯¹æŠ—æ€§ä¸Šä¸‹æ–‡æ¬ºéª— LLMsï¼Œä¿ƒä½¿å…¶å¯¹æœ‰å®³æŸ¥è¯¢ç”Ÿæˆå“åº”ã€‚åœ¨æœ¬ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°çš„é˜²å¾¡æœºåˆ¶ï¼Œç§°ä¸ºä¸Šä¸‹æ–‡è¿‡æ»¤æ¨¡å‹ï¼ˆContext Filtering modelï¼‰ï¼Œè¿™æ˜¯ä¸€ç§è¾“å…¥é¢„å¤„ç†æ–¹æ³•ï¼Œæ—¨åœ¨è¿‡æ»¤ä¸å¯ä¿¡å’Œä¸å¯é çš„ä¸Šä¸‹æ–‡ï¼ŒåŒæ—¶è¯†åˆ«åŒ…å«çœŸå®ç”¨æˆ·æ„å›¾çš„ä¸»è¦æç¤ºï¼Œä»¥æ­ç¤ºéšè—çš„æ¶æ„æ„å›¾ã€‚é‰´äºæé«˜ LLMs çš„å®‰å…¨æ€§å¸¸å¸¸ä¼šç‰ºç‰²å…¶æœ‰ç”¨æ€§ï¼Œå¯èƒ½å½±å“è‰¯æ€§ç”¨æˆ·çš„ä½“éªŒï¼Œæˆ‘ä»¬çš„æ–¹æ³•æ—¨åœ¨åœ¨ä¿æŒåŸæœ‰æ€§èƒ½çš„åŒæ—¶æå‡ LLMs çš„å®‰å…¨æ€§ã€‚æˆ‘ä»¬é€šè¿‡æ¯”è¾ƒåˆ†æè¯„ä¼°äº†æ¨¡å‹åœ¨é˜²å¾¡è¶Šç‹±æ”»å‡»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå°†æˆ‘ä»¬çš„æ–¹æ³•ä¸æœ€å…ˆè¿›çš„é˜²å¾¡æœºåˆ¶åœ¨å…­ç§ä¸åŒæ”»å‡»ä¸‹è¿›è¡Œæ¯”è¾ƒï¼Œå¹¶è¯„ä¼°åœ¨è¿™äº›é˜²å¾¡æªæ–½ä¸‹ LLMs çš„æœ‰ç”¨æ€§ã€‚ æˆ‘ä»¬çš„æ¨¡å‹å±•ç¤ºäº†åœ¨ä¿æŒåŸå§‹ LLMs æ€§èƒ½çš„åŒæ—¶ï¼Œå°†è¶Šç‹±æ”»å‡»çš„æˆåŠŸç‡é™ä½å¤šè¾¾ 88%çš„èƒ½åŠ›ï¼Œè¾¾åˆ°äº†æœ€å…ˆè¿›çš„å®‰å…¨æ€§å’Œæœ‰ç”¨æ€§äº§å“ç»“æœã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„æ¨¡å‹æ˜¯ä¸€ç§å³æ’å³ç”¨çš„æ–¹æ³•ï¼Œå¯åº”ç”¨äºæ‰€æœ‰ LLMsï¼ŒåŒ…æ‹¬ç™½ç›’å’Œé»‘ç›’æ¨¡å‹ï¼Œä»¥åœ¨ä¸éœ€è¦å¯¹æ¨¡å‹æœ¬èº«è¿›è¡Œä»»ä½•å¾®è°ƒçš„æƒ…å†µä¸‹æå‡å…¶å®‰å…¨æ€§ã€‚æˆ‘ä»¬å°†æŠŠæˆ‘ä»¬çš„æ¨¡å‹å…¬å¼€ç”¨äºç ”ç©¶ç›®çš„ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨ã€äººå·¥æ™ºèƒ½ã€è®¡ç®—ä¸è¯­è¨€</p>
<p><strong>Publish</strong>: 2025-08-09 02:37:59 UTC
å‘å¸ƒï¼š2025-08-09 02:37:59 UTC</p>
<h2 id="131-inference-aware-prompt-optimization-for-aligning-black-box-large-language-models--131-é¢å‘æ¨ç†çš„æç¤ºä¼˜åŒ–ä»¥å¯¹é½é»‘ç›’å¤§å‹è¯­è¨€æ¨¡å‹"><a href="https://arxiv.org/abs/2508.10030"target="_blank" rel="external nofollow noopener noreferrer">#131</a> <a href="https://papers.cool/arxiv/2508.10030"target="_blank" rel="external nofollow noopener noreferrer">Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models</a>  #131 é¢å‘æ¨ç†çš„æç¤ºä¼˜åŒ–ä»¥å¯¹é½é»‘ç›’å¤§å‹è¯­è¨€æ¨¡å‹</h2>
<p><strong>Authors</strong>: [Saaduddin Mahmud](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Saaduddin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Saaduddin</a> Mahmud), [Mason Nakamura](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mason"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mason</a> Nakamura), [Kyle H. Wray](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kyle"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kyle</a> H. Wray), [Shlomo Zilberstein](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shlomo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shlomo</a> Zilberstein)
ä½œè€…ï¼šSaaduddin Mahmudã€Mason Nakamuraã€Kyle H. Wrayã€Shlomo Zilberstein</p>
<p>Prompt optimization methods have demonstrated significant effectiveness in aligning black-box large language models (LLMs). In parallel, inference scaling strategies such as Best-of-N Sampling and Majority Voting have also proven to enhance alignment and performance by trading off computation. However, existing prompt optimization approaches are inference strategy agnostic; that is, they optimize prompts without regard to the inference strategy employed during deployment. This constitutes a significant methodological gap, as our empirical and theoretical analysis reveals a strong interdependence between these two paradigms. Moreover, we find that user preferences regarding trade-offs among multiple objectives and inference budgets substantially influence the choice of prompt and inference configuration. To address this gap, we introduce a unified novel framework named IAPO (Inference-Aware Prompt Optimization) that jointly optimizes the prompt and inference scale, while being aware of the inference budget and different task objectives. We then develop a fixed-budget training algorithm for IAPO, which we call PSST (Prompt Scaling via Sequential Trimming), and analyze finite-budget guarantees on error probability. Finally, we evaluate the effectiveness of PSST on six different tasks, including multi-objective text generation and reasoning, and demonstrate the critical role of incorporating inference-awareness when aligning black-box LLMs through prompt optimization.
æç¤ºè¯ä¼˜åŒ–æ–¹æ³•åœ¨ä½¿é»‘ç®±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹é½æ–¹é¢å·²æ˜¾ç¤ºå‡ºæ˜¾è‘—æ•ˆæœã€‚ä¸æ­¤åŒæ—¶ï¼Œè¯¸å¦‚ Best-of-N é‡‡æ ·å’Œå¤šæ•°æŠ•ç¥¨ä¹‹ç±»çš„æ¨ç†æ‰©å±•ç­–ç•¥ä¹Ÿè¢«è¯æ˜èƒ½å¤Ÿé€šè¿‡ä»¥è®¡ç®—ä¸ºä»£ä»·æ¥æå‡å¯¹é½åº¦å’Œæ€§èƒ½ã€‚ç„¶è€Œï¼Œç°æœ‰çš„æç¤ºè¯ä¼˜åŒ–æ–¹æ³•å¯¹æ¨ç†ç­–ç•¥ä¿æŒä¸­ç«‹ï¼›ä¹Ÿå°±æ˜¯è¯´ï¼Œå®ƒä»¬åœ¨ä¼˜åŒ–æç¤ºè¯æ—¶å¹¶ä¸è€ƒè™‘éƒ¨ç½²æ—¶æ‰€é‡‡ç”¨çš„æ¨ç†ç­–ç•¥ã€‚è¿™æ„æˆäº†ä¸€ä¸ªé‡è¦çš„æ–¹æ³•å­¦ç¼ºå£ï¼Œå› ä¸ºæˆ‘ä»¬çš„å®è¯å’Œç†è®ºåˆ†ææ­ç¤ºäº†è¿™ä¸¤ç§èŒƒå¼ä¹‹é—´å­˜åœ¨å¼ºçƒˆçš„ç›¸äº’ä¾èµ–æ€§ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°ç”¨æˆ·åœ¨å¤šç›®æ ‡æƒè¡¡å’Œæ¨ç†é¢„ç®—æ–¹é¢çš„åå¥½ä¼šæ˜¾è‘—å½±å“æç¤ºè¯å’Œæ¨ç†é…ç½®çš„é€‰æ‹©ã€‚ä¸ºäº†è§£å†³è¿™ä¸€ç¼ºå£ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„æ–°æ¡†æ¶ IAPOï¼ˆInference-Aware Prompt Optimizationï¼‰ï¼Œè¯¥æ¡†æ¶åœ¨è€ƒè™‘æ¨ç†é¢„ç®—å’Œä¸åŒä»»åŠ¡ç›®æ ‡çš„åŒæ—¶ï¼Œè”åˆä¼˜åŒ–æç¤ºè¯å’Œæ¨ç†è§„æ¨¡ã€‚ æ¥ç€æˆ‘ä»¬ä¸º IAPO å¼€å‘äº†ä¸€ç§å›ºå®šé¢„ç®—è®­ç»ƒç®—æ³•ï¼Œç§°ä¸º PSSTï¼ˆé€šè¿‡åºåˆ—ä¿®å‰ªè¿›è¡Œæç¤ºç¼©æ”¾ï¼‰ï¼Œå¹¶åˆ†æäº†åœ¨æœ‰é™é¢„ç®—ä¸‹å¯¹é”™è¯¯æ¦‚ç‡çš„ä¿è¯ã€‚æœ€åï¼Œæˆ‘ä»¬åœ¨å…­ä¸ªä¸åŒä»»åŠ¡ä¸Šè¯„ä¼°äº† PSST çš„æœ‰æ•ˆæ€§ï¼ŒåŒ…æ‹¬å¤šç›®æ ‡æ–‡æœ¬ç”Ÿæˆå’Œæ¨ç†ï¼Œå¹¶è¯æ˜åœ¨é€šè¿‡æç¤ºä¼˜åŒ–å¯¹é»‘ç®± LLMs è¿›è¡Œå¯¹é½æ—¶å¼•å…¥æ¨ç†æ„ŸçŸ¥çš„é‡è¦ä½œç”¨ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-08 18:45:53 UTC
å‘å¸ƒï¼š2025-08-08 18:45:53 UTC</p>
<h2 id="132-latent-fusion-jailbreak-blending-harmful-and-harmless-representations-to-elicit-unsafe-llm-outputs--132-æ½œåœ¨èåˆè¶Šç‹±æ··åˆæœ‰å®³ä¸æ— å®³è¡¨å¾ä»¥å¼•å‡ºä¸å®‰å…¨çš„-llm-è¾“å‡º"><a href="https://arxiv.org/abs/2508.10029"target="_blank" rel="external nofollow noopener noreferrer">#132</a> <a href="https://papers.cool/arxiv/2508.10029"target="_blank" rel="external nofollow noopener noreferrer">Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs</a>  #132 æ½œåœ¨èåˆè¶Šç‹±ï¼šæ··åˆæœ‰å®³ä¸æ— å®³è¡¨å¾ä»¥å¼•å‡ºä¸å®‰å…¨çš„ LLM è¾“å‡º</h2>
<p><strong>Authors</strong>: [Wenpeng Xing](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenpeng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenpeng</a> Xing), [Mohan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohan</a> Li), [Chunqiang Hu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chunqiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chunqiang</a> Hu), [Haitao XuNingyu Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Haitao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Haitao</a> XuNingyu Zhang), [Bo Lin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bo</a> Lin), [Meng Han](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Meng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Meng</a> Han)
ä½œè€…ï¼šWenpeng Xingã€Mohan Liã€Chunqiang Huã€Haitao Xuã€Ningyu Zhangã€Bo Linã€Meng Han</p>
<p>Large language models (LLMs) demonstrate impressive capabilities in various language tasks but are susceptible to jailbreak attacks that circumvent their safety alignments. This paper introduces Latent Fusion Jailbreak (LFJ), a representation-based attack that interpolates hidden states from harmful and benign query pairs to elicit prohibited responses. LFJ begins by selecting query pairs with high thematic and syntactic similarity, then performs gradient-guided interpolation at influential layers and tokens, followed by optimization to balance attack success, output fluency, and computational efficiency. Evaluations on models such as Vicuna and LLaMA-2 across benchmarks like AdvBench and MaliciousInstruct yield an average attack success rate (ASR) of 94.01%, outperforming existing methods. To mitigate LFJ, we propose an adversarial training defense that fine-tunes models on interpolated examples, reducing ASR by over 80% without degrading performance on benign inputs. Ablation studies validate the importance of query pair selection, hidden state interpolation components, and optimization strategies in LFJ&rsquo;s effectiveness.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å„ç§è¯­è¨€ä»»åŠ¡ä¸Šå±•ç¤ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„èƒ½åŠ›ï¼Œä½†æ˜“å—ç»•è¿‡å…¶å®‰å…¨å¯¹é½çš„è¶Šç‹±æ”»å‡»ã€‚æœ¬æ–‡æå‡ºäº†æ½œåœ¨èåˆè¶Šç‹±ï¼ˆLatent Fusion Jailbreakï¼ŒLFJï¼‰ï¼Œè¿™æ˜¯ä¸€ç§åŸºäºè¡¨å¾çš„æ”»å‡»æ–¹æ³•ï¼Œé€šè¿‡å¯¹æœ‰å®³ä¸è‰¯æ€§æŸ¥è¯¢å¯¹çš„éšè—çŠ¶æ€è¿›è¡Œæ’å€¼ä»¥è¯±å¯¼ç¦ç”¨å“åº”ã€‚LFJ é¦–å…ˆé€‰æ‹©ä¸»é¢˜å’Œå¥æ³•é«˜åº¦ç›¸ä¼¼çš„æŸ¥è¯¢å¯¹ï¼Œç„¶ååœ¨æœ‰å½±å“åŠ›çš„å±‚å’Œæ ‡è®°ä¸Šè¿›è¡Œæ¢¯åº¦å¼•å¯¼çš„æ’å€¼ï¼Œéšåè¿›è¡Œä¼˜åŒ–ä»¥åœ¨æ”»å‡»æˆåŠŸç‡ã€è¾“å‡ºæµç•…æ€§å’Œè®¡ç®—æ•ˆç‡ä¹‹é—´å–å¾—å¹³è¡¡ã€‚åœ¨å¯¹ Vicuna å’Œ LLaMA-2 ç­‰æ¨¡å‹ã€ä»¥åŠ AdvBench å’Œ MaliciousInstruct ç­‰åŸºå‡†çš„è¯„ä¼°ä¸­ï¼Œå¹³å‡æ”»å‡»æˆåŠŸç‡ï¼ˆASRï¼‰è¾¾åˆ° 94.01%ï¼Œä¼˜äºç°æœ‰æ–¹æ³•ã€‚ä¸ºç¼“è§£ LFJï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯¹æŠ—è®­ç»ƒé˜²å¾¡ï¼Œé€šè¿‡åœ¨æ’å€¼ç¤ºä¾‹ä¸Šå¾®è°ƒæ¨¡å‹ï¼Œå°† ASR é™ä½è¶…è¿‡ 80%ï¼Œä¸”ä¸é™ä½å¯¹è‰¯æ€§è¾“å…¥çš„æ€§èƒ½ã€‚æ¶ˆèç ”ç©¶éªŒè¯äº†æŸ¥è¯¢å¯¹é€‰æ‹©ã€éšè—çŠ¶æ€æ’å€¼ç»„æˆéƒ¨åˆ†å’Œä¼˜åŒ–ç­–ç•¥åœ¨ LFJ æœ‰æ•ˆæ€§ä¸­çš„é‡è¦æ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€å¯†ç å­¦ä¸å®‰å…¨</p>
<p><strong>Publish</strong>: 2025-08-08 17:29:16 UTC
å‘å¸ƒï¼š2025-08-08 17:29:16 UTC</p>
<h2 id="133-pref-reference-free-evaluation-of-personalised-text-generation-in-llms--133-åå¥½åœ¨-llms-ä¸­å¯¹ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆè¿›è¡Œæ— å‚è€ƒè¯„ä¼°"><a href="https://arxiv.org/abs/2508.10028"target="_blank" rel="external nofollow noopener noreferrer">#133</a> <a href="https://papers.cool/arxiv/2508.10028"target="_blank" rel="external nofollow noopener noreferrer">PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs</a>  #133 åå¥½ï¼šåœ¨ LLMs ä¸­å¯¹ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆè¿›è¡Œæ— å‚è€ƒè¯„ä¼°</h2>
<p><strong>Authors</strong>: [Xiao Fu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xiao</a> Fu), [Hossein A. Rahmani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hossein</a> A. Rahmani), [Bin Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Bin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Bin</a> Wu), [Jerome Ramos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jerome"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jerome</a> Ramos), [Emine Yilmaz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Emine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Emine</a> Yilmaz), [Aldo Lipani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aldo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aldo</a> Lipani)
ä½œè€…ï¼šXiao Fuã€Hossein A. Rahmaniã€Bin Wuã€Jerome Ramosã€Emine Yilmazã€Aldo Lipani</p>
<p>Personalised text generation is essential for user-centric information systems, yet most evaluation methods overlook the individuality of users. We introduce \textbf{PREF}, a \textbf{P}ersonalised \textbf{R}eference-free \textbf{E}valuation \textbf{F}ramework that jointly measures general output quality and user-specific alignment without requiring gold personalised references. PREF operates in a three-step pipeline: (1) a coverage stage uses a large language model (LLM) to generate a comprehensive, query-specific guideline covering universal criteria such as factuality, coherence, and completeness; (2) a preference stage re-ranks and selectively augments these factors using the target user&rsquo;s profile, stated or inferred preferences, and context, producing a personalised evaluation rubric; and (3) a scoring stage applies an LLM judge to rate candidate answers against this rubric, ensuring baseline adequacy while capturing subjective priorities. This separation of coverage from preference improves robustness, transparency, and reusability, and allows smaller models to approximate the personalised quality of larger ones. Experiments on the PrefEval benchmark, including implicit preference-following tasks, show that PREF achieves higher accuracy, better calibration, and closer alignment with human judgments than strong baselines. By enabling scalable, interpretable, and user-aligned evaluation, PREF lays the groundwork for more reliable assessment and development of personalised language generation systems.
ä¸ªæ€§åŒ–æ–‡æœ¬ç”Ÿæˆå¯¹äºä»¥ç”¨æˆ·ä¸ºä¸­å¿ƒçš„ä¿¡æ¯ç³»ç»Ÿè‡³å…³é‡è¦ï¼Œä½†å¤§å¤šæ•°è¯„ä¼°æ–¹æ³•å¿½è§†äº†ç”¨æˆ·çš„ä¸ªæ€§å·®å¼‚ã€‚æˆ‘ä»¬æå‡ºäº† PREFï¼Œä¸€ä¸ªä¸ªäººåŒ–çš„æ— å‚è€ƒè¯„ä¼°æ¡†æ¶ï¼ˆPersonalised Reference-free Evaluation Frameworkï¼‰ï¼Œå®ƒåœ¨ä¸éœ€è¦é‡‘æ ‡å‡†ä¸ªæ€§åŒ–å‚è€ƒçš„æƒ…å†µä¸‹ï¼Œè”åˆè¡¡é‡é€šç”¨è¾“å‡ºè´¨é‡ä¸ç”¨æˆ·ç‰¹å®šçš„ä¸€è‡´æ€§ã€‚PREF ä½¿ç”¨ä¸‰æ­¥æµæ°´çº¿è¿è¡Œï¼š (1) è¦†ç›–é˜¶æ®µä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ç”Ÿæˆä¸€å¥—å…¨é¢çš„ã€é’ˆå¯¹æŸ¥è¯¢çš„æŒ‡å¯¼æ–¹é’ˆï¼Œæ¶µç›–äº‹å®æ€§ã€è¿è´¯æ€§å’Œå®Œæ•´æ€§ç­‰é€šç”¨æ ‡å‡†ï¼›(2) åå¥½é˜¶æ®µåˆ©ç”¨ç›®æ ‡ç”¨æˆ·çš„èµ„æ–™ã€é™ˆè¿°æˆ–æ¨æ–­çš„åå¥½ä»¥åŠä¸Šä¸‹æ–‡ï¼Œå¯¹è¿™äº›å› ç´ è¿›è¡Œé‡æ–°æ’åºå¹¶æœ‰é€‰æ‹©åœ°å¢è¡¥ï¼Œä»è€Œç”Ÿæˆä¸ªæ€§åŒ–è¯„ä¼°é‡è¡¨ï¼›(3) è¯„åˆ†é˜¶æ®µç”± LLM è¯„åˆ¤æ ¹æ®è¯¥é‡è¡¨å¯¹å€™é€‰ç­”æ¡ˆè¿›è¡Œè¯„åˆ†ï¼Œæ—¢ä¿è¯åŸºæœ¬å……åˆ†æ€§åˆæ•æ‰ä¸»è§‚ä¼˜å…ˆçº§ã€‚å°†è¦†ç›–ä¸åå¥½åˆ†ç¦»æé«˜äº†ç¨³å¥æ€§ã€é€æ˜æ€§å’Œå¯é‡ç”¨æ€§ï¼Œå¹¶å…è®¸è¾ƒå°æ¨¡å‹é€¼è¿‘è¾ƒå¤§æ¨¡å‹çš„ä¸ªæ€§åŒ–è´¨é‡ã€‚ åœ¨ PrefEval åŸºå‡†ä¸Šçš„å®éªŒï¼ˆåŒ…æ‹¬éšå¼åå¥½è·Ÿéšä»»åŠ¡ï¼‰è¡¨æ˜ï¼ŒPREF åœ¨å‡†ç¡®æ€§ã€æ›´å¥½çš„æ ¡å‡†ä»¥åŠä¸äººç±»åˆ¤æ–­çš„æ›´é«˜ä¸€è‡´æ€§æ–¹é¢å‡ä¼˜äºå¼ºåŸºçº¿ã€‚é€šè¿‡å®ç°å¯æ‰©å±•ã€å¯è§£é‡Šä¸”ä¸ç”¨æˆ·ä¸€è‡´çš„è¯„ä¼°ï¼ŒPREF ä¸ºæ›´å¯é çš„ä¸ªæ€§åŒ–è¯­è¨€ç”Ÿæˆç³»ç»Ÿçš„è¯„ä¼°å’Œå¼€å‘å¥ å®šäº†åŸºç¡€ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€äººæœºäº¤äº’ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-08 14:32:31 UTC
å‘å¸ƒï¼š2025-08-08 14:32:31 UTC</p>
<h2 id="134-llmcare-alzheimer39s-detection-via-transformer-models-enhanced-by-llm-generated-synthetic-data--134-llmcareé€šè¿‡ç”±-llm-ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºçš„-transformer-æ¨¡å‹è¿›è¡Œé˜¿å°”èŒ¨æµ·é»˜ç—‡æ£€æµ‹"><a href="https://arxiv.org/abs/2508.10027"target="_blank" rel="external nofollow noopener noreferrer">#134</a> <a href="https://papers.cool/arxiv/2508.10027"target="_blank" rel="external nofollow noopener noreferrer">LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data</a>  #134 LLMCAREï¼šé€šè¿‡ç”± LLM ç”Ÿæˆçš„åˆæˆæ•°æ®å¢å¼ºçš„ Transformer æ¨¡å‹è¿›è¡Œé˜¿å°”èŒ¨æµ·é»˜ç—‡æ£€æµ‹</h2>
<p><strong>Authors</strong>: [Ali Zolnour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ali"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ali</a> Zolnour), [Hossein Azadmaleki](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hossein</a> Azadmaleki), [Yasaman Haghbin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yasaman"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yasaman</a> Haghbin), [Fatemeh Taherinezhad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fatemeh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fatemeh</a> Taherinezhad), [Mohamad Javad Momeni Nezhad](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mohamad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mohamad</a> Javad Momeni Nezhad), [Sina Rashidi](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sina"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sina</a> Rashidi), [Masoud Khani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Masoud"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Masoud</a> Khani), [AmirSajjad Taleban](<a href="https://arxiv.org/search/?searchtype=author&amp;query=AmirSajjad"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=AmirSajjad</a> Taleban), [Samin Mahdizadeh Sani](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Samin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Samin</a> Mahdizadeh Sani), [Maryam Dadkhah](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maryam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maryam</a> Dadkhah), [James M. Noble](<a href="https://arxiv.org/search/?searchtype=author&amp;query=James"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=James</a> M. Noble), [Suzanne Bakken](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Suzanne"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Suzanne</a> Bakken), [Yadollah Yaghoobzadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yadollah"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yadollah</a> Yaghoobzadeh), [Abdol-Hossein Vahabie](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abdol-Hossein"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abdol-Hossein</a> Vahabie), [Masoud Rouhizadeh](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Masoud"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Masoud</a> Rouhizadeh), [Maryam Zolnoori](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maryam"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maryam</a> Zolnoori)
ä½œè€…ï¼šAli Zolnourã€Hossein Azadmalekiã€Yasaman Haghbinã€Fatemeh Taherinezhadã€Mohamad Javad Momeni Nezhadã€Sina Rashidiã€Masoud Khaniã€AmirSajjad Talebanã€Samin Mahdizadeh Saniã€Maryam Dadkhahã€James M. Nobleã€Suzanne Bakkenã€Yadollah Yaghoobzadehã€Abdol-Hossein Vahabieã€Masoud Rouhizadehã€Maryam Zolnoori</p>
<p>Alzheimer&rsquo;s disease and related dementias (ADRD) affect approximately five million older adults in the U.S., yet over half remain undiagnosed. Speech-based natural language processing (NLP) offers a promising, scalable approach to detect early cognitive decline through linguistic markers. To develop and evaluate a screening pipeline that (i) fuses transformer embeddings with handcrafted linguistic features, (ii) tests data augmentation using synthetic speech generated by large language models (LLMs), and (iii) benchmarks unimodal and multimodal LLM classifiers for ADRD detection. Transcripts from the DementiaBank &ldquo;cookie-theft&rdquo; task (n = 237) were used. Ten transformer models were evaluated under three fine-tuning strategies. A fusion model combined embeddings from the top-performing transformer with 110 lexical-derived linguistic features. Five LLMs (LLaMA-8B/70B, MedAlpaca-7B, Ministral-8B, GPT-4o) were fine-tuned to generate label-conditioned synthetic speech, which was used to augment training data. Three multimodal models (GPT-4o, Qwen-Omni, Phi-4) were tested for speech-text classification in zero-shot and fine-tuned settings. The fusion model achieved F1 = 83.3 (AUC = 89.5), outperforming linguistic or transformer-only baselines. Augmenting training data with 2x MedAlpaca-7B synthetic speech increased F1 to 85.7. Fine-tuning significantly improved unimodal LLM classifiers (e.g., MedAlpaca: F1 = 47.3 -&gt; 78.5 F1). Current multimodal models demonstrated lower performance (GPT-4o = 70.2 F1; Qwen = 66.0). Performance gains aligned with the distributional similarity between synthetic and real speech. Integrating transformer embeddings with linguistic features enhances ADRD detection from speech. Clinically tuned LLMs effectively support both classification and data augmentation, while further advancement is needed in multimodal modeling.
é˜¿å°”èŒ¨æµ·é»˜ç—…åŠç›¸å…³ç—´å‘†ï¼ˆADRDï¼‰å½±å“å¤§çº¦äº”ç™¾ä¸‡ç¾å›½è€å¹´äººï¼Œä½†è¶…è¿‡ä¸€åŠæœªè¢«è¯Šæ–­ã€‚åŸºäºè¯­éŸ³çš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰é€šè¿‡è¯­è¨€å­¦æ ‡å¿—æä¾›äº†ä¸€ç§æœ‰å‰æ™¯ä¸”å¯æ‰©å±•çš„æ–¹æ³•æ¥æ£€æµ‹æ—©æœŸè®¤çŸ¥è¡°é€€ã€‚ä¸ºæ­¤æˆ‘ä»¬å¼€å‘å¹¶è¯„ä¼°äº†ä¸€ä¸ªç­›æŸ¥æµç¨‹ï¼Œå…¶ç›®æ ‡ä¸ºï¼š(i) å°† transformer åµŒå…¥ä¸æ‰‹å·¥è®¾è®¡çš„è¯­è¨€ç‰¹å¾èåˆï¼Œ(ii) æµ‹è¯•ä½¿ç”¨ç”±å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæˆçš„åˆæˆè¯­éŸ³è¿›è¡Œæ•°æ®å¢å¼ºï¼Œ(iii) å¯¹ç”¨äº ADRD æ£€æµ‹çš„å•æ¨¡æ€å’Œå¤šæ¨¡æ€ LLM åˆ†ç±»å™¨è¿›è¡ŒåŸºå‡†æ¯”è¾ƒã€‚ä½¿ç”¨äº† DementiaBank â€œå·é¥¼â€ä»»åŠ¡çš„è½¬å½•æ–‡æœ¬ï¼ˆn = 237ï¼‰ã€‚åœ¨ä¸‰ç§å¾®è°ƒç­–ç•¥ä¸‹è¯„ä¼°äº†åä¸ª transformer æ¨¡å‹ã€‚ä¸€ä¸ªèåˆæ¨¡å‹å°†è¡¨ç°æœ€ä½³çš„ transformer çš„åµŒå…¥ä¸ 110 ä¸ªè¯æ±‡æ´¾ç”Ÿçš„è¯­è¨€ç‰¹å¾ç»“åˆã€‚äº”ä¸ª LLMï¼ˆLLaMA-8B/70Bã€MedAlpaca-7Bã€Ministral-8Bã€GPT-4oï¼‰è¢«å¾®è°ƒç”¨äºç”Ÿæˆæ¡ä»¶åŒ–æ ‡ç­¾çš„åˆæˆè¯­éŸ³ï¼Œå¹¶ç”¨äºå¢å¼ºè®­ç»ƒæ•°æ®ã€‚ä¸‰ç§å¤šæ¨¡æ€æ¨¡å‹ï¼ˆGPT-4oã€Qwen-Omniã€Phi-4ï¼‰åœ¨é›¶æ ·æœ¬å’Œå¾®è°ƒè®¾ç½®ä¸‹ç”¨äºè¯­éŸ³-æ–‡æœ¬åˆ†ç±»æµ‹è¯•ã€‚ èåˆæ¨¡å‹å–å¾— F1 = 83.3ï¼ˆAUC = 89.5ï¼‰ï¼Œä¼˜äºä»…ä½¿ç”¨è¯­è¨€å­¦æˆ–ä»…ä½¿ç”¨ transformer çš„åŸºçº¿ã€‚ç”¨ 2 å€é‡çš„ MedAlpaca-7B åˆæˆè¯­éŸ³æ‰©å……è®­ç»ƒæ•°æ®ä½¿ F1 æå‡åˆ° 85.7ã€‚å¾®è°ƒæ˜¾è‘—æ”¹å–„äº†å•æ¨¡æ€ LLM åˆ†ç±»å™¨ï¼ˆä¾‹å¦‚ï¼ŒMedAlpacaï¼šF1 = 47.3 -&gt; 78.5 F1ï¼‰ã€‚å½“å‰çš„å¤šæ¨¡æ€æ¨¡å‹è¡¨ç°è¾ƒä½ï¼ˆGPT-4o = 70.2 F1ï¼›Qwen = 66.0ï¼‰ã€‚æ€§èƒ½æå‡ä¸åˆæˆè¯­éŸ³å’ŒçœŸå®è¯­éŸ³ä¹‹é—´çš„åˆ†å¸ƒç›¸ä¼¼æ€§ä¸€è‡´ã€‚å°† transformer åµŒå…¥ä¸è¯­è¨€å­¦ç‰¹å¾ç»“åˆèƒ½å¤Ÿå¢å¼ºåŸºäºè¯­éŸ³çš„ ADRD æ£€æµ‹ã€‚ç»è¿‡ä¸´åºŠè°ƒæ•´çš„ LLM æœ‰æ•ˆæ”¯æŒåˆ†ç±»å’Œæ•°æ®å¢å¼ºï¼Œè€Œå¤šæ¨¡æ€å»ºæ¨¡ä»éœ€è¿›ä¸€æ­¥æ”¹è¿›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-08 13:44:55 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-08 13:44:55 ä¸–ç•Œåè°ƒæ—¶é—´</p>
<h2 id="135-saber-switchable-and-balanced-training-for-efficient-llm-reasoning--135-saber-å¯åˆ‡æ¢ä¸”å¹³è¡¡çš„è®­ç»ƒä»¥å®ç°é«˜æ•ˆçš„-llm-æ¨ç†-pdf-5--copy-kimi-2--rel"><a href="https://arxiv.org/abs/2508.10026"target="_blank" rel="external nofollow noopener noreferrer">#135</a> <a href="https://papers.cool/arxiv/2508.10026"target="_blank" rel="external nofollow noopener noreferrer">SABER: Switchable and Balanced Training for Efficient LLM Reasoning</a>  #135 SABER: å¯åˆ‡æ¢ä¸”å¹³è¡¡çš„è®­ç»ƒä»¥å®ç°é«˜æ•ˆçš„ LLM æ¨ç† [PDF 5 ] [Copy] [Kimi 2 ] [REL]</h2>
<p><strong>Authors</strong>: [Kai Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Zhao), [Yanjun Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yanjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yanjun</a> Zhao), [Jiaming Song](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaming"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jiaming</a> Song), [Shien He](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shien"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shien</a> He), [Lusheng Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lusheng"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lusheng</a> Zhang), [Qiang Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiang</a> Zhang), [Tianjiao Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Tianjiao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Tianjiao</a> Li)
ä½œè€…ï¼šKai Zhao, Yanjun Zhao, Jiaming Song, Shien He, Lusheng Zhang, Qiang Zhang, Tianjiao Li</p>
<p>Large language models (LLMs) empowered by chain-of-thought reasoning have achieved impressive accuracy on complex tasks but suffer from excessive inference costs and latency when applied uniformly to all problems. We propose SABER (Switchable and Balanced Training for Efficient LLM Reasoning), a reinforcement learning framework that endows LLMs with user-controllable, token-budgeted reasoning. SABER first profiles each training example&rsquo;s base-model thinking token usage and assigns it to one of the predefined budget tiers. During fine-tuning, the model is guided by system prompts and length-aware rewards to respect its assigned budget. In parallel, we incorporate no-think examples to ensure the model remains reliable even when explicit reasoning is turned off. SABER further supports four discrete inference modes - NoThink, FastThink, CoreThink, and DeepThink, enabling flexible trade-offs between latency and reasoning depth. Extensive evaluations on math reasoning (MATH, GSM8K), code generation (MBPP), and logical reasoning (LiveBench-Reasoning) demonstrate that SABER achieves high accuracy under tight budgets, graceful degradation, and effective cross-scale and cross-domain generalization. In particular, SABER-FastThink cuts reasoning length by 65.4% and yields a 3.6% accuracy gain compared with the base model on the MATH benchmark.
ç”±é“¾è·¯å¼æ€ç»´ï¼ˆchain-of-thoughtï¼‰æ¨ç†å¢å¼ºçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤æ‚ä»»åŠ¡ä¸Šå–å¾—äº†ä»¤äººå°è±¡æ·±åˆ»çš„å‡†ç¡®æ€§ï¼Œä½†åœ¨å¯¹æ‰€æœ‰é—®é¢˜ä¸€è§†åŒä»åœ°åº”ç”¨æ—¶ä¼šé­é‡è¿‡é«˜çš„æ¨ç†æˆæœ¬å’Œå»¶è¿Ÿã€‚æˆ‘ä»¬æå‡ºäº† SABERï¼ˆå¯åˆ‡æ¢ä¸å¹³è¡¡è®­ç»ƒä»¥å®ç°é«˜æ•ˆ LLM æ¨ç†ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡å¼ºåŒ–å­¦ä¹ èµ‹äºˆ LLMs å¯ç”±ç”¨æˆ·æ§åˆ¶ã€æŒ‰ä»¤ç‰Œé¢„ç®—è¿›è¡Œæ¨ç†çš„æ¡†æ¶ã€‚SABER é¦–å…ˆåˆ†ææ¯ä¸ªè®­ç»ƒç¤ºä¾‹åœ¨åŸºç¡€æ¨¡å‹ä¸‹çš„æ€è€ƒä»¤ç‰Œä½¿ç”¨æƒ…å†µï¼Œå¹¶å°†å…¶åˆ†é…åˆ°é¢„å®šä¹‰çš„é¢„ç®—å±‚çº§ä¹‹ä¸€ã€‚åœ¨å¾®è°ƒè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹é€šè¿‡ç³»ç»Ÿæç¤ºå’Œè€ƒè™‘é•¿åº¦çš„å¥–åŠ±æ¥éµå®ˆå…¶åˆ†é…çš„é¢„ç®—ã€‚ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬å¹¶å…¥äº†æ— æ€è€ƒç¤ºä¾‹ï¼Œä»¥ç¡®ä¿å³ä½¿åœ¨å…³é—­æ˜¾å¼æ¨ç†æ—¶æ¨¡å‹ä»ç„¶å¯é ã€‚SABER è¿›ä¸€æ­¥æ”¯æŒå››ç§ç¦»æ•£çš„æ¨ç†æ¨¡å¼â€”â€”NoThinkã€FastThinkã€CoreThink å’Œ DeepThinkï¼Œä»è€Œåœ¨å»¶è¿Ÿä¸æ¨ç†æ·±åº¦ä¹‹é—´å®ç°çµæ´»çš„æƒè¡¡ã€‚ åœ¨æ•°å­¦æ¨ç†ï¼ˆMATHã€GSM8Kï¼‰ã€ä»£ç ç”Ÿæˆï¼ˆMBPPï¼‰å’Œé€»è¾‘æ¨ç†ï¼ˆLiveBench-Reasoningï¼‰ä¸Šçš„å¤§é‡è¯„ä¼°è¡¨æ˜ï¼ŒSABER åœ¨ä¸¥æ ¼çš„é¢„ç®—ä¸‹èƒ½è¾¾åˆ°é«˜å‡†ç¡®ç‡ï¼Œé€€åŒ–å¹³ç¼“ï¼Œå¹¶å…·æœ‰æœ‰æ•ˆçš„è·¨å°ºåº¦å’Œè·¨é¢†åŸŸæ³›åŒ–èƒ½åŠ›ã€‚å°¤å…¶æ˜¯ï¼Œåœ¨ MATH åŸºå‡†ä¸Šï¼ŒSABER-FastThink å°†æ¨ç†é•¿åº¦å‡å°‘äº† 65.4%ï¼Œå¹¶ç›¸æ¯”åŸºç¡€æ¨¡å‹å¸¦æ¥äº† 3.6% çš„å‡†ç¡®ç‡æå‡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-08 11:27:48 UTC
å‘å¸ƒï¼š2025-08-08 11:27:48 UTC</p>
<h2 id="136-detecting-and-explaining-postpartum-depression-in-real-time-with-generative-artificial-intelligence--136-ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®æ—¶æ£€æµ‹å¹¶è§£é‡Šäº§åæŠ‘éƒç—‡"><a href="https://arxiv.org/abs/2508.10025"target="_blank" rel="external nofollow noopener noreferrer">#136</a> <a href="https://papers.cool/arxiv/2508.10025"target="_blank" rel="external nofollow noopener noreferrer">Detecting and explaining postpartum depression in real-time with generative artificial intelligence</a>  #136 ä½¿ç”¨ç”Ÿæˆå¼äººå·¥æ™ºèƒ½å®æ—¶æ£€æµ‹å¹¶è§£é‡Šäº§åæŠ‘éƒç—‡</h2>
<p><strong>Authors</strong>: [Silvia GarcÃ­a-MÃ©ndez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Silvia"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Silvia</a> GarcÃ­a-MÃ©ndez), [Francisco de Arriba-PÃ©rez](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Francisco"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Francisco</a> de Arriba-PÃ©rez)</p>
<p>Among the many challenges mothers undergo after childbirth, postpartum depression (PPD) is a severe condition that significantly impacts their mental and physical well-being. Consequently, the rapid detection of ppd and their associated risk factors is critical for in-time assessment and intervention through specialized prevention procedures. Accordingly, this work addresses the need to help practitioners make decisions with the latest technological advancements to enable real-time screening and treatment recommendations. Mainly, our work contributes to an intelligent PPD screening system that combines Natural Language Processing, Machine Learning (ML), and Large Language Models (LLMs) towards an affordable, real-time, and non-invasive free speech analysis. Moreover, it addresses the black box problem since the predictions are described to the end users thanks to the combination of LLMs with interpretable ml models (i.e., tree-based algorithms) using feature importance and natural language. The results obtained are 90 % on ppd detection for all evaluation metrics, outperforming the competing solutions in the literature. Ultimately, our solution contributes to the rapid detection of PPD and their associated risk factors, critical for in-time and proper assessment and intervention.
åœ¨äº§åæ¯äº²é¢ä¸´çš„è¯¸å¤šæŒ‘æˆ˜ä¸­ï¼Œäº§åæŠ‘éƒï¼ˆPPDï¼‰æ˜¯ä¸€ç§ä¸¥é‡çš„çŠ¶å†µï¼Œæ˜¾è‘—å½±å“å¥¹ä»¬çš„å¿ƒç†å’Œèº«ä½“å¥åº·ã€‚å› æ­¤ï¼Œå¿«é€Ÿæ£€æµ‹ PPD åŠå…¶ç›¸å…³é£é™©å› ç´ å¯¹äºåŠæ—¶è¯„ä¼°å’Œé€šè¿‡ä¸“ä¸šé¢„é˜²æªæ–½è¿›è¡Œå¹²é¢„è‡³å…³é‡è¦ã€‚æœ¬ç ”ç©¶æ—¨åœ¨å¸®åŠ©ä»ä¸šè€…åˆ©ç”¨æœ€æ–°æŠ€æœ¯è¿›å±•åšå‡ºå†³ç­–ï¼Œä»¥å®ç°å®æ—¶ç­›æŸ¥å’Œæ²»ç–—å»ºè®®ã€‚ä¸»è¦è€Œè¨€ï¼Œæˆ‘ä»¬çš„å·¥ä½œè´¡çŒ®åœ¨äºæ„å»ºä¸€ç§æ™ºèƒ½çš„ PPD ç­›æŸ¥ç³»ç»Ÿï¼Œç»“åˆè‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨å­¦ä¹ ï¼ˆMLï¼‰å’Œ LLMsï¼Œä»¥å®ç°ç»æµã€å®æ—¶ä¸”éä¾µå…¥æ€§çš„è‡ªç”±è¯­éŸ³åˆ†æã€‚æ­¤å¤–ï¼Œé€šè¿‡å°† LLMs ä¸å¯è§£é‡Šçš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆå³åŸºäºæ ‘çš„ç®—æ³•ï¼‰ç»“åˆå¹¶ä½¿ç”¨ç‰¹å¾é‡è¦æ€§ä¸è‡ªç„¶è¯­è¨€æè¿°ï¼Œæœ¬ç ”ç©¶è§£å†³äº†â€œé»‘ç®±â€é—®é¢˜ï¼Œä½¿é¢„æµ‹ç»“æœèƒ½å¤Ÿä¸ºæœ€ç»ˆç”¨æˆ·æ‰€ç†è§£ã€‚æ‰€å¾—ç»“æœåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šçš„ PPD æ£€æµ‹å‡†ç¡®ç‡ä¸º 90%ï¼Œä¼˜äºæ–‡çŒ®ä¸­ç°æœ‰çš„ç«äº‰æ–¹æ¡ˆã€‚ æœ€ç»ˆï¼Œæˆ‘ä»¬çš„æ–¹æ¡ˆæœ‰åŠ©äºå¿«é€Ÿæ£€æµ‹äº§åæŠ‘éƒåŠå…¶ç›¸å…³é£é™©å› ç´ ï¼Œè¿™å¯¹äºåŠæ—¶ä¸”æ°å½“çš„è¯„ä¼°ä¸å¹²é¢„è‡³å…³é‡è¦ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œæœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-08 07:57:05 UTC
å‘å¸ƒï¼š2025-08-08 07:57:05 UTC</p>
<h2 id="137-rttc-reward-guided-collaborative-test-time-compute--137-rttcä»¥å¥–åŠ±ä¸ºå¯¼å‘çš„åä½œå¼æµ‹è¯•æ—¶è®¡ç®—-pdf-1--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10024"target="_blank" rel="external nofollow noopener noreferrer">#137</a> <a href="https://papers.cool/arxiv/2508.10024"target="_blank" rel="external nofollow noopener noreferrer">RTTC: Reward-Guided Collaborative Test-Time Compute</a>  #137 RTTCï¼šä»¥å¥–åŠ±ä¸ºå¯¼å‘çš„åä½œå¼æµ‹è¯•æ—¶è®¡ç®— [PDF 1 ] [Copy] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [J. Pablo MuÃ±oz](<a href="https://arxiv.org/search/?searchtype=author&amp;query=J"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=J</a>. Pablo MuÃ±oz), [Jinjie Yuan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinjie"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jinjie</a> Yuan)
ä½œè€…ï¼šJ. Pablo MuÃ±ozã€Jinjie Yuan</p>
<p>Test-Time Compute (TTC) has emerged as a powerful paradigm for enhancing the performance of Large Language Models (LLMs) at inference, leveraging strategies such as Test-Time Training (TTT) and Retrieval-Augmented Generation (RAG). However, the optimal adaptation strategy varies across queries, and indiscriminate application of TTC strategy incurs substantial computational overhead. In this work, we introduce Reward-Guided Test-Time Compute (RTTC), a novel framework that adaptively selects the most effective TTC strategy for each query via a pretrained reward model, maximizing downstream accuracy across diverse domains and tasks. RTTC operates in a distributed server-client architecture, retrieving relevant samples from a remote knowledge base and applying RAG or lightweight fine-tuning on client devices only when necessary. To further mitigate redundant computation, we propose Query-State Caching, which enables the efficient reuse of historical query states at both retrieval and adaptation levels. Extensive experiments across multiple LLMs and benchmarks demonstrate that RTTC consistently achieves superior accuracy compared to vanilla RAG or TTT, validating the necessity of adaptive, reward-guided TTC selection and the potential of RTTC for scalable, high-performance language model adaptation.
æµ‹è¯•æ—¶è®¡ç®—ï¼ˆTTCï¼‰å·²æˆä¸ºä¸€ç§åœ¨æ¨ç†é˜¶æ®µå¢å¼ºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ€§èƒ½çš„å¼ºå¤§èŒƒå¼ï¼Œåˆ©ç”¨è¯¸å¦‚æµ‹è¯•æ—¶è®­ç»ƒï¼ˆTTTï¼‰å’Œæ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰ç­‰ç­–ç•¥ã€‚ç„¶è€Œï¼Œæœ€ä½³çš„è‡ªé€‚åº”ç­–ç•¥å› æŸ¥è¯¢è€Œå¼‚ï¼Œä¸”æ— å·®åˆ«åœ°åº”ç”¨ TTC ç­–ç•¥ä¼šå¸¦æ¥å¤§é‡è®¡ç®—å¼€é”€ã€‚åœ¨è¿™é¡¹å·¥ä½œä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†å¥–åŠ±å¼•å¯¼çš„æµ‹è¯•æ—¶è®¡ç®—ï¼ˆRTTCï¼‰ï¼Œè¿™æ˜¯ä¸€ç§æ–°æ¡†æ¶ï¼Œé€šè¿‡é¢„è®­ç»ƒçš„å¥–åŠ±æ¨¡å‹ä¸ºæ¯ä¸ªæŸ¥è¯¢è‡ªé€‚åº”åœ°é€‰æ‹©æœ€æœ‰æ•ˆçš„ TTC ç­–ç•¥ï¼Œåœ¨ä¸åŒé¢†åŸŸå’Œä»»åŠ¡ä¸­æœ€å¤§åŒ–ä¸‹æ¸¸å‡†ç¡®æ€§ã€‚RTTC åœ¨åˆ†å¸ƒå¼æœåŠ¡å™¨-å®¢æˆ·ç«¯æ¶æ„ä¸­è¿è¡Œï¼Œä»è¿œç¨‹çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ ·æœ¬ï¼Œå¹¶ä»…åœ¨å¿…è¦æ—¶åœ¨å®¢æˆ·ç«¯è®¾å¤‡ä¸Šåº”ç”¨ RAG æˆ–è½»é‡å¾®è°ƒã€‚ä¸ºè¿›ä¸€æ­¥å‡å°‘å†—ä½™è®¡ç®—ï¼Œæˆ‘ä»¬æå‡ºäº†æŸ¥è¯¢çŠ¶æ€ç¼“å­˜ï¼ˆQuery-State Cachingï¼‰ï¼Œå®ƒä½¿å¾—åœ¨æ£€ç´¢å’Œè‡ªé€‚åº”å±‚é¢ä¸Šé«˜æ•ˆå¤ç”¨å†å²æŸ¥è¯¢çŠ¶æ€æˆä¸ºå¯èƒ½ã€‚ åœ¨å¤šä¸ª LLMs å’ŒåŸºå‡†ä¸Šçš„å¤§é‡å®éªŒè¯æ˜ï¼ŒRTTC ç›¸è¾ƒäºåŸå§‹çš„ RAG æˆ– TTT å§‹ç»ˆèƒ½å®ç°æ›´é«˜çš„å‡†ç¡®ç‡ï¼ŒéªŒè¯äº†è‡ªé€‚åº”ã€åŸºäºå¥–åŠ±çš„ TTC é€‰æ‹©çš„å¿…è¦æ€§ä»¥åŠ RTTC åœ¨å¯æ‰©å±•ã€é«˜æ€§èƒ½è¯­è¨€æ¨¡å‹é€‚é…æ–¹é¢çš„æ½œåŠ›ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€ä¿¡æ¯æ£€ç´¢</p>
<p><strong>Publish</strong>: 2025-08-07 21:18:52 UTC
å‘å¸ƒï¼š2025-08-07 21:18:52 UTC</p>
<h2 id="138-conformal-p-value-in-multiple-choice-question-answering-tasks-with-provable-risk-control--138-åœ¨å…·æœ‰å¯è¯æ˜é£é™©æ§åˆ¶çš„å¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ä»»åŠ¡ä¸­çš„ç¬¦åˆæ€§-p-å€¼"><a href="https://arxiv.org/abs/2508.10022"target="_blank" rel="external nofollow noopener noreferrer">#138</a> <a href="https://papers.cool/arxiv/2508.10022"target="_blank" rel="external nofollow noopener noreferrer">Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control</a>  #138 åœ¨å…·æœ‰å¯è¯æ˜é£é™©æ§åˆ¶çš„å¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ä»»åŠ¡ä¸­çš„ç¬¦åˆæ€§ P å€¼</h2>
<p><strong>Author</strong>: [Yuanchang Ye](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuanchang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yuanchang</a> Ye) ä½œè€…ï¼šå¶å…ƒæ˜Œ</p>
<p>This study introduces a significance testing-enhanced conformal prediction (CP) framework to improve trustworthiness of large language models (LLMs) in multiple-choice question answering (MCQA). While LLMs have been increasingly deployed in disciplinary QA scenarios, hallucination and nonfactual generation substantially compromise response reliability. Although CP provides statistically rigorous marginal coverage guarantees for prediction sets, and significance testing offers established statistical rigor, their synergistic integration remains unexplored. To mitigate hallucination and factual inaccuracies, our framework integrates p-value computation with conformity scoring through self-consistency resampling of MCQA responses. This approach calculates option frequencies to address LLMs&rsquo; black-box nature, subsequently constructing prediction sets via null hypothesis testing (H0) with empirically derived p-values. Evaluations on MMLU and MMLU-Pro benchmarks using off-the-shelf LLMs demonstrate: (1) The enhanced CP achieves user-specified empirical miscoverage rates; (2) Test-set average prediction set size (APSS) decreases monotonically with increasing risk levels (Î±), validating APSS as an effective uncertainty metric. This work establishes a principled statistical framework for trustworthy LLM deployment in high-stakes QA applications.
æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆæ˜¾è‘—æ€§æ£€éªŒçš„ä¿åºé¢„æµ‹ï¼ˆCPï¼‰æ¡†æ¶ï¼Œä»¥æé«˜å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šé¡¹é€‰æ‹©é¢˜é—®ç­”ï¼ˆMCQAï¼‰ä¸­çš„å¯ä¿¡åº¦ã€‚å°½ç®¡ LLMs åœ¨å­¦ç§‘é—®ç­”åœºæ™¯ä¸­çš„åº”ç”¨æ—¥ç›Šå¢å¤šï¼Œä½†å¹»è§‰å’Œéäº‹å®ç”Ÿæˆå¤§å¤§æŸå®³äº†å›ç­”çš„å¯é æ€§ã€‚å°½ç®¡ CP ä¸ºé¢„æµ‹é›†æä¾›äº†ç»Ÿè®¡ä¸Šä¸¥æ ¼çš„è¾¹é™…è¦†ç›–ä¿è¯ï¼Œæ˜¾è‘—æ€§æ£€éªŒä¹Ÿå…·æœ‰æ—¢å®šçš„ç»Ÿè®¡ä¸¥è°¨æ€§ï¼Œä½†äºŒè€…çš„ååŒæ•´åˆå°šæœªè¢«æ¢ç´¢ã€‚ä¸ºç¼“è§£å¹»è§‰å’Œäº‹å®ä¸å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬çš„æ¡†æ¶å°† p p å€¼è®¡ç®—ä¸é€šè¿‡å¯¹ MCQA å›ç­”è¿›è¡Œè‡ªæ´½é‡é‡‡æ ·çš„ç¬¦åˆåº¦è¯„åˆ†ç›¸ç»“åˆã€‚è¯¥æ–¹æ³•è®¡ç®—é€‰é¡¹é¢‘ç‡ä»¥åº”å¯¹ LLMs çš„é»‘ç®±ç‰¹æ€§ï¼Œéšåé€šè¿‡é›¶å‡è®¾æ£€éªŒï¼ˆ H0 ï¼‰å¹¶ä½¿ç”¨ç»éªŒå¾—å‡ºçš„ p p å€¼æ„å»ºé¢„æµ‹é›†ã€‚ åœ¨ä½¿ç”¨ç°æˆ LLMs å¯¹ MMLU å’Œ MMLU-Pro åŸºå‡†è¿›è¡Œçš„è¯„ä¼°è¡¨æ˜ï¼š(1) å¢å¼ºçš„ CP å®ç°äº†ç”¨æˆ·æŒ‡å®šçš„ç»éªŒå¤±è¦†ç›–ç‡ï¼›(2) éšç€é£é™©æ°´å¹³çš„æé«˜ï¼Œæµ‹è¯•é›†ä¸Šçš„å¹³å‡é¢„æµ‹é›†å¤§å°ï¼ˆAPSSï¼‰å•è°ƒé€’å‡ï¼ˆ Î± ï¼‰ï¼ŒéªŒè¯äº† APSS ä½œä¸ºæœ‰æ•ˆä¸ç¡®å®šæ€§åº¦é‡çš„ä½œç”¨ã€‚æœ¬å·¥ä½œä¸ºåœ¨é«˜é£é™©é—®ç­”åº”ç”¨ä¸­å¯ä¿¡èµ–åœ°éƒ¨ç½² LLMs å»ºç«‹äº†ä¸€ä¸ªæœ‰åŸåˆ™çš„ç»Ÿè®¡æ¡†æ¶ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-07 16:46:47 UTC
å‘å¸ƒï¼š2025-08-07 16:46:47 UTC</p>
<h2 id="139-latte-learning-aligned-transactions-and-textual-embeddings-for-bank-clients--139-latteä¸ºé“¶è¡Œå®¢æˆ·å­¦ä¹ å¯¹é½çš„äº¤æ˜“ä¸æ–‡æœ¬åµŒå…¥"><a href="https://arxiv.org/abs/2508.10021"target="_blank" rel="external nofollow noopener noreferrer">#139</a> <a href="https://papers.cool/arxiv/2508.10021"target="_blank" rel="external nofollow noopener noreferrer">LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients</a>  #139 LATTEï¼šä¸ºé“¶è¡Œå®¢æˆ·å­¦ä¹ å¯¹é½çš„äº¤æ˜“ä¸æ–‡æœ¬åµŒå…¥</h2>
<p><strong>Authors</strong>: [Egor Fadeev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Egor"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Egor</a> Fadeev), [Dzhambulat Mollaev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dzhambulat"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dzhambulat</a> Mollaev), [Aleksei Shestov](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Aleksei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Aleksei</a> Shestov), [Dima Korolev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Dima"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Dima</a> Korolev), [Omar Zoloev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Omar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Omar</a> Zoloev), [Ivan Kireev](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivan</a> Kireev), [Andrey Savchenko](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrey"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrey</a> Savchenko), [Maksim Makarenko](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Maksim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Maksim</a> Makarenko)
ä½œè€…ï¼šEgor Fadeevã€Dzhambulat Mollaevã€Aleksei Shestovã€Dima Korolevã€Omar Zoloevã€Ivan Kireevã€Andrey Savchenkoã€Maksim Makarenko</p>
<p>Learning clients embeddings from sequences of their historic communications is central to financial applications. While large language models (LLMs) offer general world knowledge, their direct use on long event sequences is computationally expensive and impractical in real-world pipelines. In this paper, we propose LATTE, a contrastive learning framework that aligns raw event embeddings with semantic embeddings from frozen LLMs. Behavioral features are summarized into short prompts, embedded by the LLM, and used as supervision via contrastive loss. The proposed approach significantly reduces inference cost and input size compared to conventional processing of complete sequence by LLM. We experimentally show that our method outperforms state-of-the-art techniques for learning event sequence representations on real-world financial datasets while remaining deployable in latency-sensitive environments.
ä»å†å²é€šä¿¡åºåˆ—ä¸­å­¦ä¹ å®¢æˆ·åµŒå…¥å¯¹äºé‡‘èåº”ç”¨è‡³å…³é‡è¦ã€‚è™½ç„¶å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æä¾›äº†é€šç”¨çš„ä¸–ç•ŒçŸ¥è¯†ï¼Œä½†å®ƒä»¬åœ¨é•¿äº‹ä»¶åºåˆ—ä¸Šçš„ç›´æ¥ä½¿ç”¨åœ¨è®¡ç®—ä¸Šä»£ä»·é«˜æ˜‚ä¸”åœ¨å®é™…æµæ°´çº¿ä¸­ä¸åˆ‡å®é™…ã€‚æœ¬æ–‡æå‡ºäº† LATTEï¼Œä¸€ç§å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œå°†åŸå§‹äº‹ä»¶åµŒå…¥ä¸æ¥è‡ªå†»ç»“ LLM çš„è¯­ä¹‰åµŒå…¥å¯¹é½ã€‚è¡Œä¸ºç‰¹å¾è¢«æ€»ç»“ä¸ºç®€çŸ­æç¤ºï¼Œç”± LLM åµŒå…¥ï¼Œå¹¶é€šè¿‡å¯¹æ¯”æŸå¤±ç”¨ä½œç›‘ç£ã€‚ä¸ä¼ ç»Ÿç”± LLM å¤„ç†å®Œæ•´åºåˆ—çš„æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ–¹æ³•æ˜¾è‘—é™ä½äº†æ¨ç†æˆæœ¬å’Œè¾“å…¥è§„æ¨¡ã€‚æˆ‘ä»¬çš„å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨çœŸå®é‡‘èæ•°æ®é›†ä¸Šå­¦ä¹ äº‹ä»¶åºåˆ—è¡¨ç¤ºæ–¹é¢ä¼˜äºæœ€å…ˆè¿›æŠ€æœ¯ï¼ŒåŒæ—¶ä»å¯éƒ¨ç½²äºå¯¹å»¶è¿Ÿæ•æ„Ÿçš„ç¯å¢ƒä¸­ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-07 16:46:38 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-07 16:46:38 åè°ƒä¸–ç•Œæ—¶ (UTC)</p>
<h2 id="140-fedcot-communication-efficient-federated-reasoning-enhancement-for-large-language-models--140-fedcoté¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„é€šä¿¡é«˜æ•ˆè”é‚¦æ¨ç†å¢å¼º"><a href="https://arxiv.org/abs/2508.10020"target="_blank" rel="external nofollow noopener noreferrer">#140</a> <a href="https://papers.cool/arxiv/2508.10020"target="_blank" rel="external nofollow noopener noreferrer">FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models</a>  #140 FedCoTï¼šé¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„é€šä¿¡é«˜æ•ˆè”é‚¦æ¨ç†å¢å¼º</h2>
<p><strong>Authors</strong>: [Chuan Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chuan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chuan</a> Li), [Qianyi Zhao](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qianyi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qianyi</a> Zhao), [Fengran Mo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Fengran"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Fengran</a> Mo), [Cen Chen](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Cen"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Cen</a> Chen)
ä½œè€…ï¼šChuan Liã€Qianyi Zhaoã€Fengran Moã€Cen Chen</p>
<p>Efficiently enhancing the reasoning capabilities of large language models (LLMs) in federated learning environments remains challenging, particularly when balancing performance gains with strict computational, communication, and privacy constraints. This challenge is especially acute in healthcare, where decisions-spanning clinical, operational, and patient-facing contexts-demand not only accurate outputs but also interpretable, traceable rationales to ensure safety, accountability, and regulatory compliance. Conventional federated tuning approaches on LLM fail to address this need: they optimize primarily for answer correctness while neglecting rationale quality, leaving CoT capabilities dependent on models&rsquo; innate pre-training abilities. Moreover, existing methods for improving rationales typically rely on privacy-violating knowledge distillation from centralized models. Additionally, the communication overhead in traditional federated fine-tuning on LLMs remains substantial. We addresses this gap by proposing FedCoT, a novel framework specifically designed to enhance reasoning in federated settings. FedCoT leverages a lightweight chain-of-thought enhancement mechanism: local models generate multiple reasoning paths, and a compact discriminator dynamically selects the most promising one. This approach improves reasoning accuracy and robustness while providing valuable interpretability, which is particularly critical for medical applications. To manage client heterogeneity efficiently, we adopt an improved aggregation approach building upon advanced LoRA module stacking, incorporating client classifier-awareness to achieve noise-free aggregation across diverse clients. Comprehensive experiments on medical reasoning tasks demonstrate that FedCoT significantly boosts client-side reasoning performance under stringent resource budgets while fully preserving data privacy.
åœ¨è”é‚¦å­¦ä¹ ç¯å¢ƒä¸­é«˜æ•ˆæå‡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„æ¨ç†èƒ½åŠ›ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå°¤å…¶æ˜¯åœ¨éœ€è¦åœ¨æ€§èƒ½æå‡ä¸ä¸¥æ ¼çš„è®¡ç®—ã€é€šä¿¡å’Œéšç§çº¦æŸä¹‹é—´å–å¾—å¹³è¡¡æ—¶ã€‚è¿™ä¸€æŒ‘æˆ˜åœ¨åŒ»ç–—é¢†åŸŸå°¤ä¸ºçªå‡ºï¼Œé‚£é‡Œè·¨ä¸´åºŠã€è¿è¥å’Œé¢å‘æ‚£è€…çš„å†³ç­–ä¸ä»…éœ€è¦å‡†ç¡®çš„è¾“å‡ºï¼Œè¿˜éœ€è¦å¯è§£é‡Šã€å¯è¿½æº¯çš„æ¨ç†ä¾æ®ä»¥ç¡®ä¿å®‰å…¨ã€é—®è´£å’Œåˆè§„æ€§ã€‚ä¼ ç»Ÿçš„é’ˆå¯¹ LLM çš„è”é‚¦å¾®è°ƒæ–¹æ³•æ— æ³•æ»¡è¶³è¿™ä¸€éœ€æ±‚ï¼šå®ƒä»¬ä¸»è¦ä¼˜åŒ–ç­”æ¡ˆçš„æ­£ç¡®æ€§è€Œå¿½è§†æ¨ç†ä¾æ®çš„è´¨é‡ï¼Œä½¿å¾—é“¾å¼æ€è€ƒï¼ˆCoTï¼‰èƒ½åŠ›ä¾èµ–äºæ¨¡å‹å›ºæœ‰çš„é¢„è®­ç»ƒèƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç°æœ‰æå‡æ¨ç†ä¾æ®çš„æ–¹æ³•é€šå¸¸ä¾èµ–äºæ¥è‡ªé›†ä¸­å¼æ¨¡å‹çš„ã€ä¾µçŠ¯éšç§çš„çŸ¥è¯†è’¸é¦ã€‚å†è€…ï¼Œä¼ ç»Ÿè”é‚¦å¾®è°ƒ LLMs çš„é€šä¿¡å¼€é”€ä¾ç„¶å¾ˆå¤§ã€‚æˆ‘ä»¬æå‡ºäº† FedCoTï¼Œä¸€ä¸ªä¸“é—¨è®¾è®¡ç”¨äºåœ¨è”é‚¦ç¯å¢ƒä¸­å¢å¼ºæ¨ç†èƒ½åŠ›çš„æ–°æ¡†æ¶ï¼Œä»¥å¡«è¡¥è¿™ä¸€ç©ºç™½ã€‚ FedCoT åˆ©ç”¨ä¸€ç§è½»é‡çº§çš„é“¾å¼æ€ç»´å¢å¼ºæœºåˆ¶ï¼šæœ¬åœ°æ¨¡å‹ç”Ÿæˆå¤šæ¡æ¨ç†è·¯å¾„ï¼Œç´§å‡‘çš„åˆ¤åˆ«å™¨åŠ¨æ€é€‰æ‹©æœ€æœ‰å‰æ™¯çš„ä¸€æ¡ã€‚è¯¥æ–¹æ³•åœ¨æé«˜æ¨ç†å‡†ç¡®æ€§å’Œé²æ£’æ€§çš„åŒæ—¶æä¾›äº†æœ‰ä»·å€¼çš„å¯è§£é‡Šæ€§ï¼Œè¿™å¯¹åŒ»ç–—åº”ç”¨å°¤ä¸ºå…³é”®ã€‚ä¸ºé«˜æ•ˆç®¡ç†å®¢æˆ·ç«¯å¼‚æ„æ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§æ”¹è¿›çš„èšåˆæ–¹æ³•ï¼ŒåŸºäºé«˜çº§ LoRA æ¨¡å—å †å ï¼Œå¹¶åŠ å…¥å®¢æˆ·ç«¯åˆ†ç±»å™¨æ„ŸçŸ¥ï¼Œä»¥åœ¨å¤šæ ·åŒ–å®¢æˆ·ç«¯ä¹‹é—´å®ç°æ— å™ªå£°èšåˆã€‚åœ¨åŒ»ç–—æ¨ç†ä»»åŠ¡ä¸Šçš„å…¨é¢å®éªŒè¡¨æ˜ï¼ŒFedCoT åœ¨ä¸¥æ ¼çš„èµ„æºé¢„ç®—ä¸‹æ˜¾è‘—æå‡äº†å®¢æˆ·ç«¯çš„æ¨ç†æ€§èƒ½ï¼ŒåŒæ—¶å®Œå…¨ä¿ç•™äº†æ•°æ®éšç§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-07 06:50:15 UTC
å‘å¸ƒï¼š2025-08-07 06:50:15 UTC</p>
<h2 id="141-decoupling-understanding-from-reasoning-via-problem-space-mapping-for-small-scale-model-reasoning--141-é€šè¿‡é—®é¢˜ç©ºé—´æ˜ å°„å°†ç†è§£ä¸æ¨ç†è§£è€¦ä»¥ç”¨äºå°è§„æ¨¡æ¨¡å‹æ¨ç†"><a href="https://arxiv.org/abs/2508.10019"target="_blank" rel="external nofollow noopener noreferrer">#141</a> <a href="https://papers.cool/arxiv/2508.10019"target="_blank" rel="external nofollow noopener noreferrer">Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning</a>  #141 é€šè¿‡é—®é¢˜ç©ºé—´æ˜ å°„å°†ç†è§£ä¸æ¨ç†è§£è€¦ä»¥ç”¨äºå°è§„æ¨¡æ¨¡å‹æ¨ç†</h2>
<p><strong>Authors</strong>: [Li Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Li"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Li</a> Wang), [Changhao Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Changhao"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Changhao</a> Zhang), [Zengqi Xiu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Zengqi"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Zengqi</a> Xiu), [Kai Lu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kai"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kai</a> Lu), [Xin Yu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Xin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Xin</a> Yu), [Kui Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kui"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kui</a> Zhang), [Wenjun Wu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Wenjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Wenjun</a> Wu)
ä½œè€…ï¼šç‹ä¸½ï¼Œå¼ é•¿æµ©ï¼Œä¿®å¢å¥‡ï¼Œé™†å‡¯ï¼Œä½™é‘«ï¼Œå¼ é­ï¼Œå´æ–‡ä¿Š</p>
<p>Despite recent advances in the reasoning capabilities of Large Language Models (LLMs), improving the reasoning ability of Small Language Models (SLMs, e.g., â‰¤ 1.5B) remains challenging. A key obstacle lies in the complexity and variability of natural language: essentially equivalent problems often appear in diverse surface forms, often obscured by redundant or distracting details. This imposes a dual burden on SLMs: they must first extract the core problem from complex linguistic input, and then perform reasoning based on that understanding. The resulting vast and noisy problem space hinders optimization, particularly for models with limited capacity. To address this, we propose a new framework that decouples understanding from reasoning by mapping natural language problems into a canonical problem space-a semantically simplified yet expressive domain. This enables SLMs to focus on reasoning over standardized inputs, free from linguistic variability. Within this framework, we introduce DURIT (Decoupled Understanding from Reasoning via Iterative Training), a three-step algorithm that iteratively: (1) mapping natural language problems via reinforcement learning, (2) aligns reasoning trajectories through self-distillation, and (3) trains reasoning policies in the problem space. The mapper and reasoner are co-trained in an alternating loop throughout this process. Experiments show that DURIT substantially improves SLMs&rsquo; performance on both in-domain and out-of-domain mathematical and logical reasoning tasks. Beyond improving reasoning capabilities, DURIT also improves the robustness of reasoning, validating decoupling understanding from reasoning as an effective strategy for strengthening SLMs.
å°½ç®¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ¨ç†èƒ½åŠ›ä¸Šæœ€è¿‘å–å¾—äº†è¿›å±•ï¼Œä½†æé«˜å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼Œä¾‹å¦‚ â‰¤ 1.5Bï¼‰çš„æ¨ç†èƒ½åŠ›ä»ç„¶å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä¸€ä¸ªå…³é”®éšœç¢åœ¨äºè‡ªç„¶è¯­è¨€çš„å¤æ‚æ€§å’Œå¤šæ ·æ€§ï¼šæœ¬è´¨ç­‰ä»·çš„é—®é¢˜å¸¸ä»¥å¤šç§è¡¨é¢å½¢å¼å‡ºç°ï¼Œä¸”å¸¸è¢«å†—ä½™æˆ–å¹²æ‰°æ€§ç»†èŠ‚æ©ç›–ã€‚è¿™å¯¹ SLMs æå‡ºäº†åŒé‡è´Ÿæ‹…ï¼šå®ƒä»¬å¿…é¡»é¦–å…ˆä»å¤æ‚çš„è¯­è¨€è¾“å…¥ä¸­æå–æ ¸å¿ƒé—®é¢˜ï¼Œç„¶ååŸºäºè¯¥ç†è§£è¿›è¡Œæ¨ç†ã€‚ç”±æ­¤äº§ç”Ÿçš„å¤§é‡ä¸”å˜ˆæ‚çš„é—®é¢˜ç©ºé—´é˜»ç¢äº†ä¼˜åŒ–ï¼Œå°¤å…¶å¯¹äºå®¹é‡æœ‰é™çš„æ¨¡å‹ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå°†ç†è§£ä¸æ¨ç†è§£è€¦çš„æ–°æ¡†æ¶ï¼Œé€šè¿‡å°†è‡ªç„¶è¯­è¨€é—®é¢˜æ˜ å°„åˆ°ä¸€ä¸ªè§„èŒƒåŒ–çš„é—®é¢˜ç©ºé—´â€”â€”ä¸€ä¸ªè¯­ä¹‰ä¸Šç®€åŒ–ä½†å…·æœ‰è¡¨è¾¾æ€§çš„é¢†åŸŸâ€”â€”æ¥å®ç°ã€‚è¿™ä½¿å¾— SLMs èƒ½å¤Ÿä¸“æ³¨äºåœ¨æ ‡å‡†åŒ–è¾“å…¥ä¸Šè¿›è¡Œæ¨ç†ï¼Œè€Œä¸å—è¯­è¨€å˜å¼‚æ€§çš„å½±å“ã€‚ åœ¨è¯¥æ¡†æ¶ä¸‹ï¼Œæˆ‘ä»¬å¼•å…¥äº† DURITï¼ˆé€šè¿‡è¿­ä»£è®­ç»ƒå®ç°ç†è§£ä¸æ¨ç†è§£è€¦ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ä¸‰æ­¥ç®—æ³•ï¼Œè¿­ä»£åœ°æ‰§è¡Œï¼š(1) é€šè¿‡å¼ºåŒ–å­¦ä¹ å°†è‡ªç„¶è¯­è¨€é—®é¢˜æ˜ å°„ï¼Œ(2) é€šè¿‡è‡ªæˆ‘è’¸é¦å¯¹é½æ¨ç†è½¨è¿¹ï¼Œ(3) åœ¨é—®é¢˜ç©ºé—´ä¸­è®­ç»ƒæ¨ç†ç­–ç•¥ã€‚æ˜ å°„å™¨å’Œæ¨ç†å™¨åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä»¥äº¤æ›¿å¾ªç¯çš„æ–¹å¼å…±åŒè®­ç»ƒã€‚å®éªŒè¡¨æ˜ï¼ŒDURIT åœ¨åŸŸå†…å’ŒåŸŸå¤–çš„æ•°å­¦ä¸é€»è¾‘æ¨ç†ä»»åŠ¡ä¸Šéƒ½å¤§å¹…æå‡äº†å°å‹è¯­è¨€æ¨¡å‹ï¼ˆSLMsï¼‰çš„æ€§èƒ½ã€‚é™¤äº†æå‡æ¨ç†èƒ½åŠ›å¤–ï¼ŒDURIT è¿˜æé«˜äº†æ¨ç†çš„é²æ£’æ€§ï¼ŒéªŒè¯äº†å°†ç†è§£ä¸æ¨ç†è§£è€¦ä½œä¸ºå¼ºåŒ– SLMs çš„ä¸€ç§æœ‰æ•ˆç­–ç•¥ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-07 01:13:30 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-07 01:13:30 UTC</p>
<h2 id="142-a-rose-by-any-other-name-would-smell-as-sweet-categorical-homotopy-theory-for-large-language-models--142-æ— è®ºä½•åçš„ç«ç‘°é—»èµ·æ¥éƒ½ä¸€æ ·é¦™é¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„èŒƒç•´åŒä¼¦è®º"><a href="https://arxiv.org/abs/2508.10018"target="_blank" rel="external nofollow noopener noreferrer">#142</a> <a href="https://papers.cool/arxiv/2508.10018"target="_blank" rel="external nofollow noopener noreferrer">A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models</a>  #142 æ— è®ºä½•åçš„ç«ç‘°é—»èµ·æ¥éƒ½ä¸€æ ·é¦™ï¼šé¢å‘å¤§å‹è¯­è¨€æ¨¡å‹çš„èŒƒç•´åŒä¼¦è®º</h2>
<p><strong>Author</strong>: [Sridhar Mahadevan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sridhar"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sridhar</a> Mahadevan)</p>
<p>Natural language is replete with superficially different statements, such as <code>Charles Darwin wrote&quot; and </code>Charles Darwin is the author of&quot;, which carry the same meaning. Large language models (LLMs) should generate the same next-token probabilities in such cases, but usually do not. Empirical workarounds have been explored, such as using k-NN estimates of sentence similarity to produce smoothed estimates. In this paper, we tackle this problem more abstractly, introducing a categorical homotopy framework for LLMs. We introduce an LLM Markov category to represent probability distributions in language generated by an LLM, where the probability of a sentence, such as <code>Charles Darwin wrote&quot; is defined by an arrow in a Markov category. However, this approach runs into difficulties as language is full of equivalent rephrases, and each generates a non-isomorphic arrow in the LLM Markov category. To address this fundamental problem, we use categorical homotopy techniques to capture </code>weak equivalences&quot; in an LLM Markov category. We present a detailed overview of application of categorical homotopy to LLMs, from higher algebraic K-theory to model categories, building on powerful theoretical results developed over the past half a century.
è‡ªç„¶è¯­è¨€å……æ–¥ç€è¡¨é¢ä¸Šä¸åŒä½†æ„ä¹‰ç›¸åŒçš„è¡¨è¿°ï¼Œä¾‹å¦‚â€œCharles Darwin wroteâ€å’Œâ€œCharles Darwin is the author ofâ€ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒLLMs åº”å½“ç”Ÿæˆç›¸åŒçš„ä¸‹ä¸€ä¸ªè¯çš„æ¦‚ç‡åˆ†å¸ƒï¼Œä½†é€šå¸¸å¹¶éå¦‚æ­¤ã€‚å·²æœ‰å®è¯ä¸Šçš„æƒå®œä¹‹è®¡è¢«æ¢ç´¢ï¼Œä¾‹å¦‚ä½¿ç”¨ k-NN çš„å¥å­ç›¸ä¼¼åº¦ä¼°è®¡æ¥ç”Ÿæˆå¹³æ»‘çš„ä¼°è®¡å€¼ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬ä»¥æ›´æŠ½è±¡çš„æ–¹å¼å¤„ç†è¿™ä¸ªé—®é¢˜ï¼Œå¼•å…¥äº†ä¸€ä¸ªç”¨äº LLMs çš„èŒƒç•´åŒä¼¦æ¡†æ¶ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ª LLM é©¬å°”å¯å¤«èŒƒç•´ï¼Œç”¨ä»¥è¡¨ç¤ºç”± LLM ç”Ÿæˆçš„è¯­è¨€ä¸­çš„æ¦‚ç‡åˆ†å¸ƒï¼Œå…¶ä¸­ä¸€å¥è¯çš„æ¦‚ç‡ï¼Œä¾‹å¦‚â€œCharles Darwin wroteâ€ï¼Œç”±é©¬å°”å¯å¤«èŒƒç•´ä¸­çš„ä¸€æ¡ç®­è¡¨ç¤ºã€‚ç„¶è€Œï¼Œè¿™ç§æ–¹æ³•é‡åˆ°äº†å›°éš¾ï¼Œå› ä¸ºè¯­è¨€å……æ»¡äº†ç­‰ä»·çš„æ”¹å†™ï¼Œè€Œæ¯ä¸€ç§æ”¹å†™åœ¨ LLM é©¬å°”å¯å¤«èŒƒç•´ä¸­éƒ½ä¼šç”Ÿæˆä¸€æ¡éåŒæ„çš„ç®­ã€‚ä¸ºäº†è§£å†³è¿™ä¸€åŸºæœ¬é—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨èŒƒç•´åŒä¼¦æŠ€æœ¯æ¥æ•æ‰ LLM é©¬å°”å¯å¤«èŒƒç•´ä¸­çš„â€œå¼±ç­‰ä»·â€ã€‚ æˆ‘ä»¬å‘ˆç°äº†å°†èŒƒç•´åŒä¼¦è®ºåº”ç”¨äº LLMs çš„è¯¦ç»†ç»¼è¿°ï¼Œå†…å®¹æ¶µç›–ä»é«˜é˜¶ä»£æ•° K ç†è®ºåˆ°æ¨¡å‹èŒƒç•´ï¼Œå»ºç«‹åœ¨è¿‡å»åŠä¸ªä¸–çºªå‘å±•å‡ºçš„å¼ºå¤§ç†è®ºæˆæœä¹‹ä¸Šã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/math.AT"target="_blank" rel="external nofollow noopener noreferrer">Algebraic Topology</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½ï¼Œä»£æ•°æ‹“æ‰‘</p>
<p><strong>Publish</strong>: 2025-08-07 00:48:30 UTC
å‘å¸ƒï¼š2025-08-07 00:48:30 UTC</p>
<h2 id="143-a-robust-pipeline-for-differentially-private-federated-learning-on-imbalanced-clinical-data-using-smotetomek-and-fedprox--143-ä½¿ç”¨-smotetomek-å’Œ-fedprox-åœ¨ä¸å¹³è¡¡ä¸´åºŠæ•°æ®ä¸Šå®ç°å·®åˆ†éšç§è”é‚¦å­¦ä¹ çš„é²æ£’æµç¨‹"><a href="https://arxiv.org/abs/2508.10017"target="_blank" rel="external nofollow noopener noreferrer">#143</a> <a href="https://papers.cool/arxiv/2508.10017"target="_blank" rel="external nofollow noopener noreferrer">A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx</a>  #143 ä½¿ç”¨ SMOTETomek å’Œ FedProx åœ¨ä¸å¹³è¡¡ä¸´åºŠæ•°æ®ä¸Šå®ç°å·®åˆ†éšç§è”é‚¦å­¦ä¹ çš„é²æ£’æµç¨‹</h2>
<p><strong>Author</strong>: [Rodrigo Tertulino](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rodrigo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rodrigo</a> Tertulino)
ä½œè€…ï¼šRodrigo Tertulino</p>
<p>Federated Learning (FL) presents a groundbreaking approach for collaborative health research, allowing model training on decentralized data while safeguarding patient privacy. FL offers formal security guarantees when combined with Differential Privacy (DP). The integration of these technologies, however, introduces a significant trade-off between privacy and clinical utility, a challenge further complicated by the severe class imbalance often present in medical datasets. The research presented herein addresses these interconnected issues through a systematic, multi-stage analysis. An FL framework was implemented for cardiovascular risk prediction, where initial experiments showed that standard methods struggled with imbalanced data, resulting in a recall of zero. To overcome such a limitation, we first integrated the hybrid Synthetic Minority Over-sampling Technique with Tomek Links (SMOTETomek) at the client level, successfully developing a clinically useful model. Subsequently, the framework was optimized for non-IID data using a tuned FedProx algorithm. Our final results reveal a clear, non-linear trade-off between the privacy budget (epsilon) and model recall, with the optimized FedProx consistently out-performing standard FedAvg. An optimal operational region was identified on the privacy-utility frontier, where strong privacy guarantees (with epsilon 9.0) can be achieved while maintaining high clinical utility (recall greater than 77%). Ultimately, our study provides a practical methodological blueprint for creating effective, secure, and accurate diagnostic tools that can be applied to real-world, heterogeneous healthcare data.
è”é‚¦å­¦ä¹ ï¼ˆFLï¼‰ä¸ºåä½œæ€§å¥åº·ç ”ç©¶æä¾›äº†ä¸€ç§å¼€åˆ›æ€§çš„æ–¹æ³•ï¼Œå…è®¸åœ¨å»ä¸­å¿ƒåŒ–æ•°æ®ä¸Šè¿›è¡Œæ¨¡å‹è®­ç»ƒï¼ŒåŒæ—¶ä¿æŠ¤æ‚£è€…éšç§ã€‚å½“ä¸å·®åˆ†éšç§ï¼ˆDPï¼‰ç»“åˆæ—¶ï¼Œè”é‚¦å­¦ä¹ èƒ½å¤Ÿæä¾›å½¢å¼åŒ–çš„å®‰å…¨æ€§ä¿è¯ã€‚ç„¶è€Œï¼Œè¿™äº›æŠ€æœ¯çš„ç»“åˆåœ¨éšç§ä¸ä¸´åºŠæ•ˆç”¨ä¹‹é—´å¼•å…¥äº†æ˜¾è‘—çš„æƒè¡¡ï¼Œè€ŒåŒ»å­¦æ•°æ®é›†ä¸­å¸¸è§çš„ä¸¥é‡ç±»åˆ«ä¸å¹³è¡¡ä½¿è¿™ä¸€æŒ‘æˆ˜æ›´ä¸ºå¤æ‚ã€‚æœ¬æ–‡æ‰€å‘ˆç°çš„ç ”ç©¶é€šè¿‡ç³»ç»Ÿçš„å¤šé˜¶æ®µåˆ†ææ¥åº”å¯¹è¿™äº›ç›¸äº’å…³è”çš„é—®é¢˜ã€‚æˆ‘ä»¬ä¸ºå¿ƒè¡€ç®¡é£é™©é¢„æµ‹å®ç°äº†ä¸€ä¸ªè”é‚¦å­¦ä¹ æ¡†æ¶ï¼Œåˆæ­¥å®éªŒè¡¨æ˜æ ‡å‡†æ–¹æ³•åœ¨ä¸å¹³è¡¡æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ï¼Œå¯¼è‡´å¬å›ç‡ä¸ºé›¶ã€‚ä¸ºå…‹æœæ­¤ç±»é™åˆ¶ï¼Œæˆ‘ä»¬é¦–å…ˆåœ¨å®¢æˆ·ç«¯å±‚é¢æ•´åˆäº†æ··åˆçš„åˆæˆå°‘æ•°ç±»è¿‡é‡‡æ ·æŠ€æœ¯ä¸ Tomek Linksï¼ˆSMOTETomekï¼‰ï¼ŒæˆåŠŸå¼€å‘å‡ºå…·æœ‰ä¸´åºŠä»·å€¼çš„æ¨¡å‹ã€‚éšåï¼Œæˆ‘ä»¬ä½¿ç”¨è°ƒä¼˜åçš„ FedProx ç®—æ³•å¯¹è¯¥æ¡†æ¶è¿›è¡Œäº†é’ˆå¯¹éç‹¬ç«‹åŒåˆ†å¸ƒï¼ˆnon-IIDï¼‰æ•°æ®çš„ä¼˜åŒ–ã€‚ æˆ‘ä»¬çš„æœ€ç»ˆç»“æœæ˜¾ç¤ºéšç§é¢„ç®—ï¼ˆepsilonï¼‰ä¸æ¨¡å‹å¬å›ç‡ä¹‹é—´å­˜åœ¨æ˜æ˜¾çš„éçº¿æ€§æƒè¡¡ï¼ŒåŒæ—¶ç»è¿‡ä¼˜åŒ–çš„ FedProx å§‹ç»ˆä¼˜äºæ ‡å‡†çš„ FedAvgã€‚åœ¨éšç§-æ•ˆç”¨å‰æ²¿ä¸Šç¡®å®šäº†ä¸€ä¸ªæœ€ä½³è¿è¡ŒåŒºåŸŸï¼Œåœ¨è¯¥åŒºåŸŸå†…å¯ä»¥åœ¨ä¿æŒé«˜ä¸´åºŠæ•ˆç”¨ï¼ˆå¬å›ç‡å¤§äº 77%ï¼‰çš„åŒæ—¶å®ç°å¼ºéšç§ä¿éšœï¼ˆepsilon ä¸º 9.0ï¼‰ã€‚æœ€ç»ˆï¼Œæˆ‘ä»¬çš„ç ”ç©¶ä¸ºåœ¨çœŸå®å¼‚æ„åŒ»ç–—æ•°æ®ä¸Šæ„å»ºæœ‰æ•ˆã€å®‰å…¨ä¸”å‡†ç¡®çš„è¯Šæ–­å·¥å…·æä¾›äº†å®ç”¨çš„æ–¹æ³•è“å›¾ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CR"target="_blank" rel="external nofollow noopener noreferrer">Cryptography and Security</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">Software Engineering</a>
ä¸»é¢˜ï¼šå¯†ç å­¦ä¸å®‰å…¨ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€è½¯ä»¶å·¥ç¨‹</p>
<p><strong>Publish</strong>: 2025-08-06 20:47:50 UTC
å‘è¡¨ï¼š2025-08-06 20:47:50 UTC</p>
<h2 id="144-beyond-hard-sharing-efficient-multi-task-speech-to-text-modeling-with-supervised-mixture-of-experts--144-è¶…è¶Šç¡¬æ€§å…±äº«ä½¿ç”¨ç›‘ç£ä¸“å®¶æ··åˆçš„é«˜æ•ˆå¤šä»»åŠ¡è¯­éŸ³è½¬æ–‡æœ¬å»ºæ¨¡"><a href="https://arxiv.org/abs/2508.10009"target="_blank" rel="external nofollow noopener noreferrer">#144</a> <a href="https://papers.cool/arxiv/2508.10009"target="_blank" rel="external nofollow noopener noreferrer">Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts</a>  #144 è¶…è¶Šç¡¬æ€§å…±äº«ï¼šä½¿ç”¨ç›‘ç£ä¸“å®¶æ··åˆçš„é«˜æ•ˆå¤šä»»åŠ¡è¯­éŸ³è½¬æ–‡æœ¬å»ºæ¨¡</h2>
<p><strong>Authors</strong>: [Hojun Jin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hojun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hojun</a> Jin), [Eunsoo Hong](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Eunsoo"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Eunsoo</a> Hong), [Ziwon Hyung](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ziwon"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ziwon</a> Hyung), [Sungjun Lim](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sungjun"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sungjun</a> Lim), [Seungjin Lee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Seungjin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Seungjin</a> Lee), [Keunseok Cho](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Keunseok"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Keunseok</a> Cho)
ä½œè€…ï¼šHojun Jinã€Eunsoo Hongã€Ziwon Hyungã€Sungjun Limã€Seungjin Leeã€Keunseok Cho</p>
<p>Hard-parameter sharing is a common strategy to train a single model jointly across diverse tasks. However, this often leads to task interference, impeding overall model performance. To address the issue, we propose a simple yet effective Supervised Mixture of Experts (S-MoE). Unlike traditional Mixture of Experts models, S-MoE eliminates the need for training gating functions by utilizing special guiding tokens to route each task to its designated expert. By assigning each task to a separate feedforward network, S-MoE overcomes the limitations of hard-parameter sharing. We further apply S-MoE to a speech-to-text model, enabling the model to process mixed-bandwidth input while jointly performing automatic speech recognition (ASR) and speech translation (ST). Experimental results demonstrate the effectiveness of the proposed S-MoE, achieving a 6.35% relative improvement in Word Error Rate (WER) when applied to both the encoder and decoder.
ç¡¬å‚æ•°å…±äº«æ˜¯ä¸€ç§å¸¸è§ç­–ç•¥ï¼Œç”¨äºåœ¨å¤šæ ·åŒ–ä»»åŠ¡ä¸Šè”åˆè®­ç»ƒå•ä¸€æ¨¡å‹ã€‚ç„¶è€Œï¼Œè¿™é€šå¸¸ä¼šå¯¼è‡´ä»»åŠ¡å¹²æ‰°ï¼Œé˜»ç¢æ•´ä½“æ¨¡å‹æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¯¥é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œæœ‰æ•ˆçš„ç›‘ç£å¼ä¸“å®¶æ··åˆæ¨¡å‹ï¼ˆSupervised Mixture of Expertsï¼ŒS-MoEï¼‰ã€‚ä¸ä¼ ç»Ÿçš„ä¸“å®¶æ··åˆæ¨¡å‹ä¸åŒï¼ŒS-MoE é€šè¿‡ä½¿ç”¨ç‰¹æ®Šçš„å¼•å¯¼ä»¤ç‰Œå°†æ¯ä¸ªä»»åŠ¡è·¯ç”±åˆ°å…¶æŒ‡å®šä¸“å®¶ï¼Œæ¶ˆé™¤äº†è®­ç»ƒé—¨æ§å‡½æ•°çš„éœ€è¦ã€‚é€šè¿‡å°†æ¯ä¸ªä»»åŠ¡åˆ†é…ç»™ç‹¬ç«‹çš„å‰é¦ˆç½‘ç»œï¼ŒS-MoE å…‹æœäº†ç¡¬å‚æ•°å…±äº«çš„å±€é™æ€§ã€‚æˆ‘ä»¬è¿›ä¸€æ­¥å°† S-MoE åº”ç”¨äºè¯­éŸ³åˆ°æ–‡æœ¬æ¨¡å‹ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿå¤„ç†æ··åˆå¸¦å®½è¾“å…¥ï¼ŒåŒæ—¶è”åˆæ‰§è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰å’Œè¯­éŸ³ç¿»è¯‘ï¼ˆSTï¼‰ã€‚å®éªŒç»“æœè¯æ˜äº†æ‰€æå‡º S-MoE çš„æœ‰æ•ˆæ€§ï¼šå½“åŒæ—¶åº”ç”¨äºç¼–ç å™¨å’Œè§£ç å™¨æ—¶ï¼Œåœ¨è¯é”™è¯¯ç‡ï¼ˆWERï¼‰ä¸Šå®ç°äº† 6.35% çš„ç›¸å¯¹æå‡ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.SD"target="_blank" rel="external nofollow noopener noreferrer">Sound</a>, <a href="https://papers.cool/arxiv/eess.AS"target="_blank" rel="external nofollow noopener noreferrer">Audio and Speech Processing</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€å£°éŸ³ã€éŸ³é¢‘ä¸è¯­éŸ³å¤„ç†</p>
<p><strong>Publish</strong>: 2025-08-05 23:56:11 UTC
å‘å¸ƒï¼š2025-08-05 23:56:11 UTC</p>
<h2 id="145-from-answers-to-questions-eqgbench-for-evaluating-llms39-educational-question-generation"><a href="https://arxiv.org/abs/2508.10005"target="_blank" rel="external nofollow noopener noreferrer">#145</a> <a href="https://papers.cool/arxiv/2508.10005"target="_blank" rel="external nofollow noopener noreferrer">From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation</a></h2>
<p><strong>Authors</strong>: [Chengliang Zhou](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Chengliang"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Chengliang</a> Zhou), [Mei Wang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Mei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Mei</a> Wang), [Ting Zhang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ting"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ting</a> Zhang), [Qiannan Zhu](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiannan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Qiannan</a> Zhu), [Jian Li](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jian"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jian</a> Li), [Hua Huang](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hua"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hua</a> Huang)
ä½œè€…ï¼šå‘¨æˆäº®ï¼Œç‹æ¢…ï¼Œå¼ å©·ï¼Œæœ±å€©æ¥ ï¼Œæå‰‘ï¼Œé»„å</p>
<p>Large Language Models (LLMs) have demonstrated remarkable capabilities in mathematical problem-solving. However, the transition from providing answers to generating high-quality educational questions presents significant challenges that remain underexplored. To advance Educational Question Generation (EQG) and facilitate LLMs in generating pedagogically valuable and educationally effective questions, we introduce EQGBench, a comprehensive benchmark specifically designed for evaluating LLMs&rsquo; performance in Chinese EQG. EQGBench establishes a five-dimensional evaluation framework supported by a dataset of 900 evaluation samples spanning three fundamental middle school disciplines: mathematics, physics, and chemistry. The dataset incorporates user queries with varying knowledge points, difficulty gradients, and question type specifications to simulate realistic educational scenarios. Through systematic evaluation of 46 mainstream large models, we reveal significant room for development in generating questions that reflect educational value and foster students&rsquo; comprehensive abilities.
å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ•°å­¦é—®é¢˜æ±‚è§£æ–¹é¢è¡¨ç°å‡ºæ˜¾è‘—èƒ½åŠ›ã€‚ç„¶è€Œï¼Œä»ç›´æ¥ç»™å‡ºç­”æ¡ˆåˆ°ç”Ÿæˆé«˜è´¨é‡æ•™è‚²æ€§é—®é¢˜çš„è¿‡æ¸¡ä»ç„¶å­˜åœ¨é‡å¤§æŒ‘æˆ˜ï¼Œä¸”è¿™äº›æŒ‘æˆ˜å°šæœªè¢«å……åˆ†æ¢è®¨ã€‚ä¸ºæ¨åŠ¨æ•™è‚²é—®é¢˜ç”Ÿæˆï¼ˆEQGï¼‰ç ”ç©¶å¹¶å¸®åŠ© LLMs ç”Ÿæˆå…·æœ‰æ•™å­¦ä»·å€¼å’Œæ•™è‚²æœ‰æ•ˆæ€§çš„é—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº† EQGBenchâ€”â€”ä¸€ä¸ªä¸“é—¨ç”¨äºè¯„ä¼° LLMs åœ¨ä¸­æ–‡ EQG è¡¨ç°çš„ç»¼åˆåŸºå‡†ã€‚EQGBench å»ºç«‹äº†ä¸€ä¸ªç”±äº”ä¸ªç»´åº¦ç»„æˆçš„è¯„ä¼°æ¡†æ¶ï¼Œå¹¶åŸºäºæ¶µç›–åˆä¸­ä¸‰é—¨åŸºç¡€å­¦ç§‘ï¼ˆæ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦ï¼‰çš„ 900 ä¸ªè¯„ä¼°æ ·æœ¬æ„å»ºæ•°æ®é›†ã€‚è¯¥æ•°æ®é›†åŒ…å«å…·æœ‰ä¸åŒçŸ¥è¯†ç‚¹ã€éš¾åº¦æ¢¯åº¦å’Œé¢˜å‹è¦æ±‚çš„ç”¨æˆ·æŸ¥è¯¢ï¼Œä»¥æ¨¡æ‹ŸçœŸå®çš„æ•™è‚²åœºæ™¯ã€‚é€šè¿‡å¯¹ 46 ä¸ªä¸»æµå¤§æ¨¡å‹çš„ç³»ç»Ÿè¯„ä¼°ï¼Œæˆ‘ä»¬å‘ç°è¿™äº›æ¨¡å‹åœ¨ç”Ÿæˆå…·æœ‰æ•™è‚²ä»·å€¼å¹¶ä¿ƒè¿›å­¦ç”Ÿç»¼åˆèƒ½åŠ›çš„é—®é¢˜æ–¹é¢ä»æœ‰æ˜¾è‘—æå‡ç©ºé—´ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-05 14:16:42 UTC
å‘å¸ƒï¼š2025-08-05 14:16:42 UTC</p>
<h2 id="146-user-perception-of-attention-visualizations-effects-on-interpretability-across-evidence-based-medical-documents--146-æ³¨æ„åŠ›å¯è§†åŒ–çš„ç”¨æˆ·æ„ŸçŸ¥åŸºäºè¯æ®çš„åŒ»å­¦æ–‡æ¡£ä¸­å¯¹å¯è§£é‡Šæ€§çš„å½±å“"><a href="https://arxiv.org/abs/2508.10004"target="_blank" rel="external nofollow noopener noreferrer">#146</a> <a href="https://papers.cool/arxiv/2508.10004"target="_blank" rel="external nofollow noopener noreferrer">User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents</a>  #146 æ³¨æ„åŠ›å¯è§†åŒ–çš„ç”¨æˆ·æ„ŸçŸ¥ï¼šåŸºäºè¯æ®çš„åŒ»å­¦æ–‡æ¡£ä¸­å¯¹å¯è§£é‡Šæ€§çš„å½±å“</h2>
<p><strong>Authors</strong>: [AndrÃ©s Carvallo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andr"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andr</a>Ã©s Carvallo), [Denis Parra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Denis"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Denis</a> Parra), [Peter Brusilovsky](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Peter"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Peter</a> Brusilovsky), [Hernan Valdivieso](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Hernan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Hernan</a> Valdivieso), [Gabriel Rada](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gabriel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gabriel</a> Rada), [Ivania Donoso](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Ivania"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Ivania</a> Donoso), [Vladimir Araujo](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Vladimir"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Vladimir</a> Araujo)
ä½œè€…ï¼šAndrÃ©s Carvalloã€Denis Parraã€Peter Brusilovskyã€Hernan Valdiviesoã€Gabriel Radaã€Ivania Donosoã€Vladimir Araujo</p>
<p>The attention mechanism is a core component of the Transformer architecture. Beyond improving performance, attention has been proposed as a mechanism for explainability via attention weights, which are associated with input features (e.g., tokens in a document). In this context, larger attention weights may imply more relevant features for the model&rsquo;s prediction. In evidence-based medicine, such explanations could support physicians&rsquo; understanding and interaction with AI systems used to categorize biomedical literature. However, there is still no consensus on whether attention weights provide helpful explanations. Moreover, little research has explored how visualizing attention affects its usefulness as an explanation aid. To bridge this gap, we conducted a user study to evaluate whether attention-based explanations support users in biomedical document classification and whether there is a preferred way to visualize them. The study involved medical experts from various disciplines who classified articles based on study design (e.g., systematic reviews, broad synthesis, randomized and non-randomized trials). Our findings show that the Transformer model (XLNet) classified documents accurately; however, the attention weights were not perceived as particularly helpful for explaining the predictions. However, this perception varied significantly depending on how attention was visualized. Contrary to Munzner&rsquo;s principle of visual effectiveness, which favors precise encodings like bar length, users preferred more intuitive formats, such as text brightness or background color. While our results do not confirm the overall utility of attention weights for explanation, they suggest that their perceived helpfulness is influenced by how they are visually presented.
æ³¨æ„åŠ›æœºåˆ¶æ˜¯ Transformer æ¶æ„çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ã€‚é™¤äº†èƒ½æå‡æ€§èƒ½å¤–ï¼Œæ³¨æ„åŠ›è¿˜è¢«æå‡ºä½œä¸ºä¸€ç§é€šè¿‡æ³¨æ„åŠ›æƒé‡å®ç°å¯è§£é‡Šæ€§çš„æœºåˆ¶ï¼Œè¿™äº›æƒé‡ä¸è¾“å…¥ç‰¹å¾ï¼ˆä¾‹å¦‚æ–‡æ¡£ä¸­çš„æ ‡è®°ï¼‰ç›¸å…³è”ã€‚åœ¨è¿™ç§æƒ…å¢ƒä¸‹ï¼Œæ›´å¤§çš„æ³¨æ„åŠ›æƒé‡å¯èƒ½æ„å‘³ç€å¯¹æ¨¡å‹é¢„æµ‹æ›´ç›¸å…³çš„ç‰¹å¾ã€‚åœ¨å¾ªè¯åŒ»å­¦ä¸­ï¼Œæ­¤ç±»è§£é‡Šå¯ä»¥å¸®åŠ©åŒ»ç”Ÿç†è§£å¹¶ä¸ç”¨äºå¯¹ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®è¿›è¡Œåˆ†ç±»çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè¿›è¡Œäº¤äº’ã€‚ç„¶è€Œï¼Œå…³äºæ³¨æ„åŠ›æƒé‡æ˜¯å¦æä¾›æœ‰ç”¨è§£é‡Šï¼Œç›®å‰ä»æœªè¾¾æˆå…±è¯†ã€‚æ­¤å¤–ï¼Œå…³äºå¯è§†åŒ–æ³¨æ„åŠ›å¦‚ä½•å½±å“å…¶ä½œä¸ºè§£é‡Šè¾…åŠ©å·¥å…·çš„æœ‰ç”¨æ€§çš„ç ”ç©¶ä¹Ÿå¾ˆå°‘ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œæˆ‘ä»¬å¼€å±•äº†ä¸€é¡¹ç”¨æˆ·ç ”ç©¶ï¼Œè¯„ä¼°åŸºäºæ³¨æ„åŠ›çš„è§£é‡Šæ˜¯å¦èƒ½åœ¨ç”Ÿç‰©åŒ»å­¦æ–‡æ¡£åˆ†ç±»ä¸­æ”¯æŒç”¨æˆ·ï¼Œä»¥åŠæ˜¯å¦å­˜åœ¨ä¸€ç§é¦–é€‰çš„å¯è§†åŒ–æ–¹å¼ã€‚è¯¥ç ”ç©¶é‚€è¯·äº†æ¥è‡ªå„ä¸ªå­¦ç§‘çš„åŒ»å­¦ä¸“å®¶ï¼Œä»–ä»¬æ ¹æ®ç ”ç©¶è®¾è®¡ï¼ˆä¾‹å¦‚ç³»ç»Ÿç»¼è¿°ã€å¹¿æ³›ç»¼è¿°ã€éšæœºå’Œééšæœºè¯•éªŒï¼‰å¯¹æ–‡ç« è¿›è¡Œåˆ†ç±»ã€‚ æˆ‘ä»¬çš„ç ”ç©¶ç»“æœè¡¨æ˜ï¼ŒTransformer æ¨¡å‹ï¼ˆXLNetï¼‰èƒ½å¤Ÿå‡†ç¡®åœ°å¯¹æ–‡æ¡£è¿›è¡Œåˆ†ç±»ï¼›ç„¶è€Œï¼Œæ³¨æ„åŠ›æƒé‡å¹¶æœªè¢«è®¤ä¸ºå¯¹è§£é‡Šæ¨¡å‹é¢„æµ‹ç‰¹åˆ«æœ‰å¸®åŠ©ã€‚ä¸è¿‡ï¼Œè¿™ç§çœ‹æ³•åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºæ³¨æ„åŠ›çš„å¯è§†åŒ–æ–¹å¼ã€‚ä¸ Munzner æ‰€å€¡å¯¼çš„è§†è§‰æœ‰æ•ˆæ€§åŸåˆ™ï¼ˆåå¥½åƒæ¡å½¢é•¿åº¦è¿™æ ·ç²¾ç¡®çš„ç¼–ç ï¼‰ç›¸åï¼Œç”¨æˆ·æ›´åå¥½æ›´ç›´è§‚çš„å½¢å¼ï¼Œä¾‹å¦‚æ–‡æœ¬äº®åº¦æˆ–èƒŒæ™¯é¢œè‰²ã€‚å°½ç®¡æˆ‘ä»¬çš„ç»“æœå¹¶ä¸èƒ½ç¡®è®¤æ³¨æ„åŠ›æƒé‡åœ¨è§£é‡Šæ–¹é¢çš„æ€»ä½“æ•ˆç”¨ï¼Œä½†å®ƒä»¬è¡¨æ˜æ³¨æ„åŠ›çš„å¯è§†åŒ–å‘ˆç°æ–¹å¼ä¼šå½±å“äººä»¬å¯¹å…¶æœ‰ç”¨æ€§çš„æ„ŸçŸ¥ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.HC"target="_blank" rel="external nofollow noopener noreferrer">Human-Computer Interaction</a>, <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€äººæœºäº¤äº’ã€ä¿¡æ¯æ£€ç´¢ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-05 13:24:52 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-05 13:24:52 UTC</p>
<h2 id="147-semantic-structure-in-large-language-model-embeddings--147-å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­çš„è¯­ä¹‰ç»“æ„"><a href="https://arxiv.org/abs/2508.10003"target="_blank" rel="external nofollow noopener noreferrer">#147</a> <a href="https://papers.cool/arxiv/2508.10003"target="_blank" rel="external nofollow noopener noreferrer">Semantic Structure in Large Language Model Embeddings</a>  #147 å¤§å‹è¯­è¨€æ¨¡å‹åµŒå…¥ä¸­çš„è¯­ä¹‰ç»“æ„</h2>
<p><strong>Authors</strong>: [Austin C. Kozlowski](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Austin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Austin</a> C. Kozlowski), [Callin Dai](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Callin"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Callin</a> Dai), [Andrei Boutyline](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Andrei"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Andrei</a> Boutyline)
ä½œè€…ï¼šAustin C. Kozlowskiã€Callin Daiã€Andrei Boutyline</p>
<p>Psychological research consistently finds that human ratings of words across diverse semantic scales can be reduced to a low-dimensional form with relatively little information loss. We find that the semantic associations encoded in the embedding matrices of large language models (LLMs) exhibit a similar structure. We show that the projections of words on semantic directions defined by antonym pairs (e.g. kind - cruel) correlate highly with human ratings, and further find that these projections effectively reduce to a 3-dimensional subspace within LLM embeddings, closely resembling the patterns derived from human survey responses. Moreover, we find that shifting tokens along one semantic direction causes off-target effects on geometrically aligned features proportional to their cosine similarity. These findings suggest that semantic features are entangled within LLMs similarly to how they are interconnected in human language, and a great deal of semantic information, despite its apparent complexity, is surprisingly low-dimensional. Furthermore, accounting for this semantic structure may prove essential for avoiding unintended consequences when steering features.
å¿ƒç†å­¦ç ”ç©¶ä¸€è´¯å‘ç°ï¼Œäººä»¬å¯¹è¯è¯­åœ¨å„ç§è¯­ä¹‰é‡è¡¨ä¸Šçš„è¯„åˆ†å¯ä»¥è¢«å‹ç¼©ä¸ºä½ç»´å½¢å¼ï¼Œè€Œä¿¡æ¯æŸå¤±ç›¸å¯¹è¾ƒå°ã€‚æˆ‘ä»¬å‘ç°ï¼Œå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åµŒå…¥çŸ©é˜µä¸­ç¼–ç çš„è¯­ä¹‰è”æƒ³å‘ˆç°å‡ºç±»ä¼¼çš„ç»“æ„ã€‚æˆ‘ä»¬å±•ç¤ºäº†ç”±åä¹‰è¯å¯¹ï¼ˆä¾‹å¦‚ kind - cruelï¼‰å®šä¹‰çš„è¯­ä¹‰æ–¹å‘ä¸Šè¯é¡¹çš„æŠ•å½±ä¸äººç±»è¯„åˆ†é«˜åº¦ç›¸å…³ï¼Œå¹¶è¿›ä¸€æ­¥å‘ç°è¿™äº›æŠ•å½±åœ¨ LLM åµŒå…¥ä¸­æœ‰æ•ˆåœ°çº¦ç®€ä¸ºä¸‰ç»´å­ç©ºé—´ï¼Œä¸ä»äººç±»è°ƒæŸ¥å“åº”ä¸­å¾—å‡ºçš„æ¨¡å¼éå¸¸ç›¸ä¼¼ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°æ²¿æŸä¸€è¯­ä¹‰æ–¹å‘ç§»åŠ¨æ ‡è®°ä¼šå¯¹å‡ ä½•ä¸Šå¯¹é½çš„ç‰¹å¾äº§ç”ŸæŒ‰å…¶ä½™å¼¦ç›¸ä¼¼åº¦æˆæ¯”ä¾‹çš„éç›®æ ‡å½±å“ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼Œè¯­ä¹‰ç‰¹å¾åœ¨ LLMs ä¸­åƒåœ¨äººç±»è¯­è¨€ä¸­é‚£æ ·ç›¸äº’ç¼ ç»•ï¼Œå°½ç®¡è¯­ä¹‰çœ‹ä¼¼å¤æ‚ï¼Œä½†å¤§é‡è¯­ä¹‰ä¿¡æ¯å‡ºäººæ„æ–™åœ°æ˜¯ä½ç»´çš„ã€‚æ­¤å¤–ï¼Œè€ƒè™‘åˆ°è¿™ç§è¯­ä¹‰ç»“æ„åœ¨å¼•å¯¼ç‰¹å¾æ—¶å¯èƒ½å¯¹é¿å…æ„å¤–åæœè‡³å…³é‡è¦ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-04 20:21:50 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-04 20:21:50 UTC</p>
<h2 id="148-hifactmix-a-code-mixed-benchmark-and-graph-aware-model-for-evidencebased-political-claim-verification-in-hinglish--148-hifactmixä¸€ä¸ªç”¨äºå°åœ°è‹±æ··åˆhinglishè¯æ®å‹æ”¿æ²»ä¸»å¼ éªŒè¯çš„ä»£ç æ··åˆåŸºå‡†ä¸å›¾æ„ŸçŸ¥æ¨¡å‹-pdf--copy-kimi--rel"><a href="https://arxiv.org/abs/2508.10001"target="_blank" rel="external nofollow noopener noreferrer">#148</a> <a href="https://papers.cool/arxiv/2508.10001"target="_blank" rel="external nofollow noopener noreferrer">HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish</a>  #148 HiFACTMixï¼šä¸€ä¸ªç”¨äºå°åœ°è‹±æ··åˆï¼ˆHinglishï¼‰è¯æ®å‹æ”¿æ²»ä¸»å¼ éªŒè¯çš„ä»£ç æ··åˆåŸºå‡†ä¸å›¾æ„ŸçŸ¥æ¨¡å‹ [PDF ] [Copy] [Kimi ] [REL]</h2>
<p><strong>Authors</strong>: [Rakesh Thakur](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rakesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rakesh</a> Thakur), [Sneha Sharma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Sneha"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Sneha</a> Sharma), [Gauri Chopra](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gauri"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gauri</a> Chopra)
ä½œè€…ï¼šRakesh Thakurã€Sneha Sharmaã€Gauri Chopra</p>
<p>Fact-checking in code-mixed, low-resource languages such as Hinglish remains an underexplored challenge in natural language processing. Existing fact-verification systems largely focus on high-resource, monolingual settings and fail to generalize to real-world political discourse in linguistically diverse regions like India. Given the widespread use of Hinglish by public figures, particularly political figures, and the growing influence of social media on public opinion, there&rsquo;s a critical need for robust, multilingual and context-aware fact-checking tools. To address this gap a novel benchmark HiFACT dataset is introduced with 1,500 realworld factual claims made by 28 Indian state Chief Ministers in Hinglish, under a highly code-mixed low-resource setting. Each claim is annotated with textual evidence and veracity labels. To evaluate this benchmark, a novel graphaware, retrieval-augmented fact-checking model is proposed that combines multilingual contextual encoding, claim-evidence semantic alignment, evidence graph construction, graph neural reasoning, and natural language explanation generation. Experimental results show that HiFACTMix outperformed accuracy in comparison to state of art multilingual baselines models and provides faithful justifications for its verdicts. This work opens a new direction for multilingual, code-mixed, and politically grounded fact verification research.
åœ¨åƒå°åœ°è‹±æ··åˆè¯­ï¼ˆHinglishï¼‰è¿™æ ·ä»£ç æ··åˆã€ä½èµ„æºçš„è¯­è¨€ä¸­è¿›è¡Œäº‹å®æ ¸æŸ¥ï¼Œä»ç„¶æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸä¸€ä¸ªæœªå……åˆ†æ¢ç´¢çš„æŒ‘æˆ˜ã€‚ç°æœ‰çš„äº‹å®éªŒè¯ç³»ç»Ÿä¸»è¦é›†ä¸­åœ¨é«˜èµ„æºçš„å•è¯­ç¯å¢ƒï¼Œæ— æ³•æ¨å¹¿åˆ°åƒå°åº¦è¿™æ ·è¯­è¨€å¤šæ ·çš„åœ°åŒºçš„ç°å®æ”¿æ²»è¯è¯­ã€‚é‰´äºå…¬ä¼—äººç‰©ï¼Œå°¤å…¶æ˜¯æ”¿æ²»äººç‰©å¹¿æ³›ä½¿ç”¨ Hinglishï¼Œä»¥åŠç¤¾äº¤åª’ä½“å¯¹å…¬ä¼—èˆ†è®ºæ—¥ç›Šå¢é•¿çš„å½±å“ï¼Œè¿«åˆ‡éœ€è¦é²æ£’çš„ã€å¤šè¯­è¨€ä¸”å…·ä¸Šä¸‹æ–‡æ„è¯†çš„äº‹å®æ ¸æŸ¥å·¥å…·ã€‚ä¸ºå¼¥è¡¥è¿™ä¸€ç©ºç™½ï¼Œæå‡ºäº†ä¸€ä¸ªæ–°åŸºå‡† HiFACT æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«ç”± 28 ä½å°åº¦é‚¦é¦–å¸­éƒ¨é•¿ä»¥ Hinglish æå‡ºçš„ 1500 æ¡çœŸå®ä¸–ç•Œäº‹å®æ€§å£°æ˜ï¼Œå¤„äºé«˜åº¦ä»£ç æ··åˆçš„ä½èµ„æºç¯å¢ƒä¸­ã€‚æ¯æ¡å£°æ˜å‡æ ‡æ³¨äº†æ–‡æœ¬è¯æ®å’ŒçœŸå®æ€§æ ‡ç­¾ã€‚ä¸ºè¯„ä¼°è¯¥åŸºå‡†ï¼Œæå‡ºäº†ä¸€ç§æ–°é¢–çš„å›¾æ„ŸçŸ¥æ£€ç´¢å¢å¼ºäº‹å®æ ¸æŸ¥æ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç»“åˆäº†å¤šè¯­è¨€ä¸Šä¸‹æ–‡ç¼–ç ã€å£°æ˜ä¸è¯æ®çš„è¯­ä¹‰å¯¹é½ã€è¯æ®å›¾æ„å»ºã€å›¾ç¥ç»ç½‘ç»œæ¨ç†ä»¥åŠè‡ªç„¶è¯­è¨€è§£é‡Šç”Ÿæˆã€‚ å®éªŒç»“æœè¡¨æ˜ï¼ŒHiFACTMix åœ¨å‡†ç¡®æ€§æ–¹é¢ä¼˜äºæœ€å…ˆè¿›çš„å¤šè¯­è¨€åŸºçº¿æ¨¡å‹ï¼Œå¹¶ä¸ºå…¶ç»“è®ºæä¾›äº†å¯ä¿¡çš„ç†ç”±ã€‚è¿™é¡¹å·¥ä½œä¸ºå¤šè¯­è¨€ã€ä»£ç æ··åˆå’Œä»¥æ”¿æ²»ä¸ºåŸºç¡€çš„äº‹å®éªŒè¯ç ”ç©¶å¼€è¾Ÿäº†æ–°çš„æ–¹å‘ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-04 17:14:03 UTC
å‘å¸ƒï¼š2025-08-04 17:14:03 UTC</p>
<h2 id="149-intima-a-benchmark-for-human-ai-companionship-behavior--149-intimaç”¨äºäººæœºä¼´ä¾£è¡Œä¸ºçš„åŸºå‡†æµ‹è¯•"><a href="https://arxiv.org/abs/2508.09998"target="_blank" rel="external nofollow noopener noreferrer">#149</a> <a href="https://papers.cool/arxiv/2508.09998"target="_blank" rel="external nofollow noopener noreferrer">INTIMA: A Benchmark for Human-AI Companionship Behavior</a>  #149 INTIMAï¼šç”¨äºäººæœºä¼´ä¾£è¡Œä¸ºçš„åŸºå‡†æµ‹è¯•</h2>
<p><strong>Authors</strong>: [Lucie-AimÃ©e Kaffee](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lucie-Aim"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lucie-Aim</a>Ã©e Kaffee), [Giada Pistilli](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Giada"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Giada</a> Pistilli), [Yacine Jernite](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Yacine"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Yacine</a> Jernite)
ä½œè€…ï¼šLucie-AimÃ©e Kaffeeã€Giada Pistilliã€Yacine Jernite</p>
<p>AI companionship, where users develop emotional bonds with AI systems, has emerged as a significant pattern with positive but also concerning implications. We introduce Interactions and Machine Attachment Benchmark (INTIMA), a benchmark for evaluating companionship behaviors in language models. Drawing from psychological theories and user data, we develop a taxonomy of 31 behaviors across four categories and 368 targeted prompts. Responses to these prompts are evaluated as companionship-reinforcing, boundary-maintaining, or neutral. Applying INTIMA to Gemma-3, Phi-4, o3-mini, and Claude-4 reveals that companionship-reinforcing behaviors remain much more common across all models, though we observe marked differences between models. Different commercial providers prioritize different categories within the more sensitive parts of the benchmark, which is concerning since both appropriate boundary-setting and emotional support matter for user well-being. These findings highlight the need for more consistent approaches to handling emotionally charged interactions.
AI ä¼´ä¾£å…³ç³»ï¼Œå³ç”¨æˆ·ä¸ AI ç³»ç»Ÿå»ºç«‹æƒ…æ„Ÿçº½å¸¦ï¼Œå·²æˆä¸ºä¸€ç§é‡è¦çš„æ¨¡å¼ï¼Œæ—¢å¸¦æ¥ç§¯æå½±å“ä¹Ÿå¼•å‘ä»¤äººæ‹…å¿§çš„é—®é¢˜ã€‚æˆ‘ä»¬æå‡ºäº†äº¤äº’ä¸æœºå™¨ä¾æ‹åŸºå‡†ï¼ˆInteractions and Machine Attachment Benchmarkï¼Œç®€ç§° INTIMAï¼‰ï¼Œç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹ä¸­çš„ä¼´ä¾£è¡Œä¸ºã€‚åŸºäºå¿ƒç†å­¦ç†è®ºå’Œç”¨æˆ·æ•°æ®ï¼Œæˆ‘ä»¬æ„å»ºäº†æ¶µç›–å››ç±»å…± 31 ç§è¡Œä¸ºçš„åˆ†ç±»æ³•ï¼Œå¹¶è®¾è®¡äº† 368 æ¡é’ˆå¯¹æ€§æç¤ºã€‚å¯¹è¿™äº›æç¤ºçš„å›å¤è¢«è¯„ä¼°ä¸ºå¼ºåŒ–ä¼´ä¾£å…³ç³»ã€ç»´æŒç•Œé™æˆ–ä¸­æ€§ã€‚å°† INTIMA åº”ç”¨äº Gemma-3ã€Phi-4ã€o3-mini å’Œ Claude-4 æ—¶å‘ç°ï¼Œå¼ºåŒ–ä¼´ä¾£å…³ç³»çš„è¡Œä¸ºåœ¨æ‰€æœ‰æ¨¡å‹ä¸­ä»è¿œæ¯”å…¶ä»–ç±»å‹å¸¸è§ï¼Œå°½ç®¡å„æ¨¡å‹ä¹‹é—´å­˜åœ¨æ˜æ˜¾å·®å¼‚ã€‚ä¸åŒå•†ä¸šæä¾›è€…åœ¨è¯¥åŸºå‡†æ›´ä¸ºæ•æ„Ÿçš„éƒ¨åˆ†ä¼˜å…ˆä¾§é‡ä¸åŒç±»åˆ«ï¼Œè¿™ä»¤äººæ‹…å¿§ï¼Œå› ä¸ºæ°å½“çš„ç•Œé™è®¾å®šä¸æƒ…æ„Ÿæ”¯æŒå¯¹ç”¨æˆ·ç¦ç¥‰åŒæ ·é‡è¦ã€‚è¿™äº›å‘ç°å‡¸æ˜¾äº†åœ¨å¤„ç†æƒ…ç»ªåŒ–äº’åŠ¨æ—¶éœ€è¦æ›´ä¸€è‡´çš„æ–¹æ³•ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-08-04 08:25:38 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-08-04 08:25:38 UTC</p>
<h2 id="150-openfpl-an-open-source-forecasting-method-rivaling-state-of-the-art-fantasy-premier-league-services--150-openfplä¸€ä¸ªå¯ä¸æœ€å…ˆè¿›çš„-fantasy-premier-league-æœåŠ¡åª²ç¾çš„å¼€æºé¢„æµ‹æ–¹æ³•"><a href="https://arxiv.org/abs/2508.09992"target="_blank" rel="external nofollow noopener noreferrer">#150</a> <a href="https://papers.cool/arxiv/2508.09992"target="_blank" rel="external nofollow noopener noreferrer">OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services</a>  #150 OpenFPLï¼šä¸€ä¸ªå¯ä¸æœ€å…ˆè¿›çš„ Fantasy Premier League æœåŠ¡åª²ç¾çš„å¼€æºé¢„æµ‹æ–¹æ³•</h2>
<p><strong>Author</strong>: [Daniel Groos](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Daniel</a> Groos) ä½œè€…ï¼šDaniel Groos</p>
<p>Fantasy Premier League engages the football community in selecting the Premier League players who will perform best from gameweek to gameweek. Access to accurate performance forecasts gives participants an edge over competitors by guiding expectations about player outcomes and reducing uncertainty in squad selection. However, high-accuracy forecasts are currently limited to commercial services whose inner workings are undisclosed and that rely on proprietary data. This paper aims to democratize access to highly accurate forecasts of player performance by presenting OpenFPL, an open-source Fantasy Premier League forecasting method developed exclusively from public data. Comprising position-specific ensemble models optimized on Fantasy Premier League and Understat data from four previous seasons (2020-21 to 2023-24), OpenFPL achieves accuracy comparable to a leading commercial service when tested prospectively on data from the 2024-25 season. OpenFPL also surpasses the commercial benchmark for high-return players (&gt; 2 points), which are most influential for rank gains. These findings hold across one-, two-, and three-gameweek forecast horizons, supporting long-term planning of transfers and strategies while also informing final-day decisions.
å¹»æƒ³è‹±è¶…ï¼ˆFantasy Premier Leagueï¼‰è®©è¶³çƒç¤¾åŒºå‚ä¸é€‰æ‹©æ¯ä¸€è½®æ¯”èµ›ä¸­è¡¨ç°æœ€å¥½çš„è‹±è¶…çƒå‘˜ã€‚è·å–å‡†ç¡®çš„è¡¨ç°é¢„æµ‹å¯ä»¥é€šè¿‡æŒ‡å¯¼å¯¹çƒå‘˜ç»“æœçš„é¢„æœŸå¹¶å‡å°‘é˜µå®¹é€‰æ‹©çš„ä¸ç¡®å®šæ€§ï¼Œå¸®åŠ©å‚ä¸è€…åœ¨ç«äº‰ä¸­å–å¾—ä¼˜åŠ¿ã€‚ç„¶è€Œï¼Œé«˜ç²¾åº¦çš„é¢„æµ‹ç›®å‰ä»…é™äºå…¶å†…éƒ¨è¿ä½œæœªå…¬å¼€ä¸”ä¾èµ–ä¸“æœ‰æ•°æ®çš„å•†ä¸šæœåŠ¡ã€‚æœ¬æ–‡æ—¨åœ¨é€šè¿‡æå‡º OpenFPL æ¥å®ç°å¯¹çƒå‘˜è¡¨ç°é«˜ç²¾åº¦é¢„æµ‹çš„æ™®åŠåŒ–ï¼ŒOpenFPL æ˜¯ä¸€ä¸ªå®Œå…¨åŸºäºå…¬å¼€æ•°æ®å¼€å‘çš„å¼€æºå¹»æƒ³è‹±è¶…é¢„æµ‹æ–¹æ³•ã€‚OpenFPL ç”±é’ˆå¯¹ä¸åŒä½ç½®çš„é›†æˆæ¨¡å‹ç»„æˆï¼Œè¿™äº›æ¨¡å‹åœ¨è¿‡å»å››ä¸ªèµ›å­£ï¼ˆ2020-21 è‡³ 2023-24ï¼‰çš„ Fantasy Premier League å’Œ Understat æ•°æ®ä¸Šè¿›è¡Œäº†ä¼˜åŒ–ï¼Œåœ¨å¯¹ 2024-25 èµ›å­£çš„å‰ç»æ€§æµ‹è¯•ä¸­ï¼Œå…¶å‡†ç¡®æ€§å¯ä¸ä¸€å®¶é¢†å…ˆçš„å•†ä¸šæœåŠ¡ç›¸åª²ç¾ã€‚å¯¹äºé«˜å›æŠ¥çƒå‘˜ï¼ˆ &gt; 2 åˆ†ï¼‰ï¼Œå³å¯¹æ’åæå‡å½±å“æœ€å¤§çš„çƒå‘˜ï¼ŒOpenFPL çš„è¡¨ç°ç”šè‡³è¶…è¿‡äº†è¯¥å•†ä¸šåŸºå‡†ã€‚ è¿™äº›å‘ç°é€‚ç”¨äºä¸€å‘¨ã€ä¸¤å‘¨å’Œä¸‰å‘¨çš„é¢„æµ‹æœŸï¼Œä¸ºé•¿æœŸè½¬ä¼šå’Œç­–ç•¥è§„åˆ’æä¾›æ”¯æŒï¼ŒåŒæ—¶ä¹Ÿä¸ºæœ€åä¸€å¤©çš„å†³ç­–æä¾›å‚è€ƒã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>
ä¸»é¢˜ï¼šæœºå™¨å­¦ä¹ ï¼Œäººå·¥æ™ºèƒ½</p>
<p><strong>Publish</strong>: 2025-07-29 13:59:51 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-07-29 13:59:51 UTC</p>
<h2 id="151-bridging-ai-innovation-and-healthcare-needs-lessons-learned-from-incorporating-modern-nlp-at-the-bc-cancer-registry--151-åœ¨äººå·¥æ™ºèƒ½åˆ›æ–°ä¸åŒ»ç–—éœ€æ±‚ä¹‹é—´æ¶æ¡¥åœ¨å‘è¯—çœç™Œç—‡ç™»è®°å¤„å¼•å…¥ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»éªŒæ•™è®­"><a href="https://arxiv.org/abs/2508.09991"target="_blank" rel="external nofollow noopener noreferrer">#151</a> <a href="https://papers.cool/arxiv/2508.09991"target="_blank" rel="external nofollow noopener noreferrer">Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry</a>  #151 åœ¨äººå·¥æ™ºèƒ½åˆ›æ–°ä¸åŒ»ç–—éœ€æ±‚ä¹‹é—´æ¶æ¡¥ï¼šåœ¨å‘è¯—çœç™Œç—‡ç™»è®°å¤„å¼•å…¥ç°ä»£è‡ªç„¶è¯­è¨€å¤„ç†çš„ç»éªŒæ•™è®­</h2>
<p><strong>Authors</strong>: [Lovedeep Gondara](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lovedeep"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lovedeep</a> Gondara), [Gregory Arbour](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gregory"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gregory</a> Arbour), [Raymond Ng](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Raymond"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Raymond</a> Ng), [Jonathan Simkin](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonathan</a> Simkin), [Shebnum Devji](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shebnum"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shebnum</a> Devji)
ä½œè€…ï¼šLovedeep Gondaraã€Gregory Arbourã€Raymond Ngã€Jonathan Simkinã€Shebnum Devji</p>
<p>Automating data extraction from clinical documents offers significant potential to improve efficiency in healthcare settings, yet deploying Natural Language Processing (NLP) solutions presents practical challenges. Drawing upon our experience implementing various NLP models for information extraction and classification tasks at the British Columbia Cancer Registry (BCCR), this paper shares key lessons learned throughout the project lifecycle. We emphasize the critical importance of defining problems based on clear business objectives rather than solely technical accuracy, adopting an iterative approach to development, and fostering deep interdisciplinary collaboration and co-design involving domain experts, end-users, and ML specialists from inception. Further insights highlight the need for pragmatic model selection (including hybrid approaches and simpler methods where appropriate), rigorous attention to data quality (representativeness, drift, annotation), robust error mitigation strategies involving human-in-the-loop validation and ongoing audits, and building organizational AI literacy. These practical considerations, generalizable beyond cancer registries, provide guidance for healthcare organizations seeking to successfully implement AI/NLP solutions to enhance data management processes and ultimately improve patient care and public health outcomes.
ä»ä¸´åºŠæ–‡æ¡£ä¸­è‡ªåŠ¨æå–æ•°æ®åœ¨æå‡åŒ»ç–—ç¯å¢ƒæ•ˆç‡æ–¹é¢å…·æœ‰æ˜¾è‘—æ½œåŠ›ï¼Œä½†éƒ¨ç½²è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰è§£å†³æ–¹æ¡ˆä¹Ÿå¸¦æ¥äº†å®é™…æŒ‘æˆ˜ã€‚æœ¬æ–‡ä»¥æˆ‘ä»¬åœ¨ä¸åˆ—é¢ å“¥ä¼¦æ¯”äºšçœç™Œç—‡ç™»è®°å¤„ï¼ˆBCCRï¼‰å®æ–½å¤šç§ç”¨äºä¿¡æ¯æŠ½å–å’Œåˆ†ç±»ä»»åŠ¡çš„ NLP æ¨¡å‹çš„ç»éªŒä¸ºåŸºç¡€ï¼Œåˆ†äº«äº†åœ¨é¡¹ç›®ç”Ÿå‘½å‘¨æœŸä¸­å­¦åˆ°çš„å…³é”®æ•™è®­ã€‚æˆ‘ä»¬å¼ºè°ƒåŸºäºæ¸…æ™°çš„ä¸šåŠ¡ç›®æ ‡è€Œéä»…ä»…æŠ€æœ¯å‡†ç¡®æ€§æ¥å®šä¹‰é—®é¢˜çš„é‡è¦æ€§ï¼Œé‡‡ç”¨è¿­ä»£å¼€å‘æ–¹æ³•ï¼Œä»¥åŠä»ä¸€å¼€å§‹å°±ä¿ƒè¿›é¢†åŸŸä¸“å®¶ã€æœ€ç»ˆç”¨æˆ·å’Œæœºå™¨å­¦ä¹ ä¸“å®¶ä¹‹é—´çš„æ·±åº¦è·¨å­¦ç§‘åä½œä¸å…±åŒè®¾è®¡ã€‚è¿›ä¸€æ­¥çš„è§è§£å¼ºè°ƒäº†åŠ¡å®çš„æ¨¡å‹é€‰æ‹©ï¼ˆåœ¨é€‚å½“æƒ…å†µä¸‹åŒ…æ‹¬æ··åˆæ–¹æ³•å’Œæ›´ç®€å•çš„æ–¹æ³•ï¼‰ã€å¯¹æ•°æ®è´¨é‡ï¼ˆä»£è¡¨æ€§ã€æ¼‚ç§»ã€æ ‡æ³¨ï¼‰çš„ä¸¥æ ¼å…³æ³¨ã€æ¶‰åŠäººæœºå¾ªç¯éªŒè¯å’ŒæŒç»­å®¡è®¡çš„ç¨³å¥é”™è¯¯ç¼“è§£ç­–ç•¥ï¼Œä»¥åŠæ„å»ºç»„ç»‡æ€§äººå·¥æ™ºèƒ½ç´ å…»çš„å¿…è¦æ€§ã€‚ è¿™äº›åˆ‡å®å¯è¡Œçš„è€ƒè™‘å› ç´ ä¸ä»…é€‚ç”¨äºç™Œç—‡ç™»è®°å¤„ï¼Œè¿˜ä¸ºå¯»æ±‚æˆåŠŸå®æ–½ AI/NLP è§£å†³æ–¹æ¡ˆä»¥å¢å¼ºæ•°æ®ç®¡ç†æµç¨‹å¹¶æœ€ç»ˆæ”¹å–„ç—…äººæŠ¤ç†å’Œå…¬å…±å¥åº·æˆæœçš„åŒ»ç–—æœºæ„æä¾›äº†æŒ‡å¯¼ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">Computation and Language</a>, <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">Artificial Intelligence</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>, <a href="https://papers.cool/arxiv/cs.SE"target="_blank" rel="external nofollow noopener noreferrer">Software Engineering</a>
ä¸»é¢˜ï¼šè®¡ç®—ä¸è¯­è¨€ã€äººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€è½¯ä»¶å·¥ç¨‹</p>
<p><strong>Publish</strong>: 2025-07-27 15:06:43 UTC
å‘å¸ƒæ—¥æœŸï¼š2025-07-27 15:06:43 UTC</p>
<h2 id="152-personalized-product-search-ranking-a-multi-task-learning-approach-with-tabular-and-non-tabular-data--152-ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åºä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•"><a href="https://arxiv.org/abs/2508.09636"target="_blank" rel="external nofollow noopener noreferrer">#152</a> <a href="https://papers.cool/arxiv/2508.09636"target="_blank" rel="external nofollow noopener noreferrer">Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data</a>  #152 ä¸ªæ€§åŒ–äº§å“æœç´¢æ’åºï¼šä¸€ç§ç»“åˆè¡¨æ ¼ä¸éè¡¨æ ¼æ•°æ®çš„å¤šä»»åŠ¡å­¦ä¹ æ–¹æ³•</h2>
<p><strong>Authors</strong>: [Lalitesh Morishetti](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Lalitesh"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Lalitesh</a> Morishetti), [Abhay Kumar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Abhay"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Abhay</a> Kumar), [Jonathan Scott](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Jonathan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Jonathan</a> Scott), [Kaushiki Nag](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kaushiki"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kaushiki</a> Nag), [Gunjan Sharma](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Gunjan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Gunjan</a> Sharma), [Shanu Vashishtha](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Shanu"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Shanu</a> Vashishtha), [Rahul Sridhar](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rahul"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rahul</a> Sridhar), [Rohit Chatter](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Rohit"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Rohit</a> Chatter), [Kannan Achan](<a href="https://arxiv.org/search/?searchtype=author&amp;query=Kannan"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/search/?searchtype=author&query=Kannan</a> Achan)
ä½œè€…ï¼šLalitesh Morishettiã€Abhay Kumarã€Jonathan Scottã€Kaushiki Nagã€Gunjan Sharmaã€Shanu Vashishthaã€Rahul Sridharã€Rohit Chatterã€Kannan Achan</p>
<p>In this paper, we present a novel model architecture for optimizing personalized product search ranking using a multi-task learning (MTL) framework. Our approach uniquely integrates tabular and non-tabular data, leveraging a pre-trained TinyBERT model for semantic embeddings and a novel sampling technique to capture diverse customer behaviors. We evaluate our model against several baselines, including XGBoost, TabNet, FT-Transformer, DCN-V2, and MMoE, focusing on their ability to handle mixed data types and optimize personalized ranking. Additionally, we propose a scalable relevance labeling mechanism based on click-through rates, click positions, and semantic similarity, offering an alternative to traditional human-annotated labels. Experimental results show that combining non-tabular data with advanced embedding techniques in multi-task learning paradigm significantly enhances model performance. Ablation studies further underscore the benefits of incorporating relevance labels, fine-tuning TinyBERT layers, and TinyBERT query-product embedding interactions. These results demonstrate the effectiveness of our approach in achieving improved personalized product search ranking.
åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°é¢–çš„æ¨¡å‹æ¶æ„ï¼Œä½¿ç”¨å¤šä»»åŠ¡å­¦ä¹ ï¼ˆMTLï¼‰æ¡†æ¶æ¥ä¼˜åŒ–ä¸ªæ€§åŒ–å•†å“æœç´¢æ’åã€‚æˆ‘ä»¬çš„æ–¹æ³•ç‹¬ç‰¹åœ°æ•´åˆäº†è¡¨æ ¼æ•°æ®å’Œéè¡¨æ ¼æ•°æ®ï¼Œåˆ©ç”¨é¢„è®­ç»ƒçš„ TinyBERT æ¨¡å‹è·å–è¯­ä¹‰åµŒå…¥ï¼Œå¹¶å¼•å…¥äº†ä¸€ç§æ–°é¢–çš„é‡‡æ ·æŠ€æœ¯ä»¥æ•æ‰å¤šæ ·çš„å®¢æˆ·è¡Œä¸ºã€‚æˆ‘ä»¬å°†æ¨¡å‹ä¸å¤šä¸ªåŸºçº¿æ–¹æ³•è¿›è¡Œè¯„ä¼°ï¼ŒåŒ…æ‹¬ XGBoostã€TabNetã€FT-Transformerã€DCN-V2 å’Œ MMoEï¼Œé‡ç‚¹è€ƒå¯Ÿå®ƒä»¬å¤„ç†æ··åˆæ•°æ®ç±»å‹å’Œä¼˜åŒ–ä¸ªæ€§åŒ–æ’åºçš„èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å¯æ‰©å±•çš„ç›¸å…³æ€§æ ‡æ³¨æœºåˆ¶ï¼ŒåŸºäºç‚¹å‡»ç‡ã€ç‚¹å‡»ä½ç½®å’Œè¯­ä¹‰ç›¸ä¼¼åº¦ï¼Œä¸ºä¼ ç»Ÿçš„äººä¸ºæ ‡æ³¨æ ‡ç­¾æä¾›äº†ä¸€ç§æ›¿ä»£æ–¹æ¡ˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šä»»åŠ¡å­¦ä¹ èŒƒå¼ä¸­å°†éè¡¨æ ¼æ•°æ®ä¸å…ˆè¿›çš„åµŒå…¥æŠ€æœ¯ç›¸ç»“åˆå¯ä»¥æ˜¾è‘—æå‡æ¨¡å‹æ€§èƒ½ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥å¼ºè°ƒäº†å¼•å…¥ç›¸å…³æ€§æ ‡ç­¾ã€å¾®è°ƒ TinyBERT å±‚ä»¥åŠ TinyBERT æŸ¥è¯¢-å•†å“åµŒå…¥äº¤äº’çš„å¥½å¤„ã€‚è¿™äº›ç»“æœè¯æ˜äº†æˆ‘ä»¬æ–¹æ³•åœ¨å®ç°æ”¹è¿›çš„ä¸ªæ€§åŒ–å•†å“æœç´¢æ’åæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚</p>
<p><strong>Subjects</strong>: <a href="https://papers.cool/arxiv/cs.IR"target="_blank" rel="external nofollow noopener noreferrer">Information Retrieval</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">Machine Learning</a>
ä¸»é¢˜ï¼šä¿¡æ¯æ£€ç´¢ã€æœºå™¨å­¦ä¹ </p>
<p><strong>Publish</strong>: 2025-08-13 09:15:08 UTC
å‘å¸ƒæ—¶é—´ï¼š2025-08-13 09:15:08 UTC</p>
<h1 id="13-huggingface">1.3 Huggingface</h1>
<ul>
<li><a href="https://huggingface.co/papers/2508.09983?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">Story2Boardï¼šä¸€ç§æ— éœ€åŸ¹è®­çš„è¡¨è¾¾æ•…äº‹æ¿ç”Ÿæˆæ–¹æ³•ï¼ˆ40â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.08401?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">Mol-R1ï¼šåˆ†å­å‘ç°ä¸­çš„æ˜¾å¼é•¿cotæ¨ç†ï¼ˆ28â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.07901?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">Stand-Inï¼šç”¨äºè§†é¢‘ç”Ÿæˆçš„è½»é‡çº§å³æ’å³ç”¨èº«ä»½æ§åˆ¶ï¼ˆ24â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.09192?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">æ‰©æ•£LLMså¯ä»¥é€šè¿‡ç¦»æ•£æ‰©æ•£å¼ºè¿«è¿›è¡Œæ¯”aræ›´å¿«çš„æ¨ç†ï¼ˆ22â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.09889?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">AWorldï¼šå…·æœ‰ç¨³å®šæœºåŠ¨çš„åŠ¨æ€å¤šæ™ºèƒ½ä½“ç³»ç»Ÿé²æ£’GAIAé—®é¢˜æ±‚è§£ï¼ˆ21â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.09736?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">è§†è§‰ã€å¬è§‰ã€è®°å¿†å’Œæ¨ç†ï¼šå…·æœ‰é•¿æœŸè®°å¿†çš„å¤šæ¨¡æ€æ™ºèƒ½ä½“ï¼ˆ21â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.09987?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">echo - 40ï¼šåˆ©ç”¨gpt - 40åˆæˆå›¾åƒçš„åŠ›é‡æ¥æ”¹è¿›å›¾åƒç”Ÿæˆï¼ˆ16â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.07750?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">å­¦ä¹ å¯¹é½ï¼Œå¯¹é½å­¦ä¹ ï¼šè‡ªæˆ‘ä¼˜åŒ–å¯¹é½çš„ç»Ÿä¸€æ–¹æ³•ï¼ˆ14â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.06009?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">MathRealï¼šæˆ‘ä»¬ä¿æŒçœŸå®ï¼ è¯„ä¼°å¤šæ¨¡æ€å¤§å‹è¯­è¨€æ¨¡å‹ä¸­æ•°å­¦æ¨ç†çš„çœŸå®åœºæ™¯åŸºå‡†ï¼ˆ10â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.05613?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">Cooperï¼šå¤§å‹è¯­è¨€æ¨¡å‹å¼ºåŒ–å­¦ä¹ ä¸­çš„ååŒä¼˜åŒ–ç­–ç•¥å’Œå¥–åŠ±æ¨¡å‹ï¼ˆ7â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.09456?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">IAGï¼šåŸºäºè§†è§‰æ¥åœ°çš„VLMsè¾“å…¥æ„ŸçŸ¥åé—¨æ”»å‡»ï¼ˆ6â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers/2508.09968?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">å™ªå£°è¶…ç½‘ç»œï¼šæ‰©æ•£æ¨¡å‹çš„å¹³æ‘Šæµ‹è¯•æ—¶é—´è®¡ç®—ï¼ˆ5â–²ï¼‰ </a></li>
<li><a href="https://huggingface.co/papers?utm_source=digest-papers&amp;utm_medium=email&amp;utm_campaign=2025-08-14"target="_blank" rel="external nofollow noopener noreferrer">è¿˜æœ‰11ç¯‡è®ºæ–‡</a></li>
</ul>
<h1 id="14-x">1.4 X</h1>
<h1 id="15-å°çº¢ä¹¦">1.5 å°çº¢ä¹¦</h1>
<h1 id="2-æ„Ÿå…´è¶£ç ”ç©¶">2. æ„Ÿå…´è¶£ç ”ç©¶</h1>
<p>å…¬ä¼—å·æ–‡ç« å·²å®Œæˆåˆ†ç±»æ€»ç»“ã€‚</p>
</div></article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">Public - 2025</span><span class="author" itemprop="copyrightHolder">
              <a href="/LLMDailyDigestWeb/"></a></span></div><div class="footer-line statistics"></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">Theme FixIt works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="preload" href="/LLMDailyDigestWeb/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/cookieconsent/cookieconsent.min.css"><script src="/LLMDailyDigestWeb/lib/sharer/sharer.min.js" async defer></script><script src="/LLMDailyDigestWeb/lib/typeit/index.umd.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/katex.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/auto-render.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/copy-tex.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/mhchem.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-desktop":"LLM-DailyDigest å¤§æ¨¡å‹ç ”ç©¶æ—¥æŠ¥","typeit-header-title-mobile":"LLM-DailyDigest å¤§æ¨¡å‹ç ”ç©¶æ—¥æŠ¥"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-desktop":["typeit-header-desktop"],"typeit-header-title-mobile":["typeit-header-title-mobile"]},"duration":-1,"loop":false,"speed":100}};</script><script src="/LLMDailyDigestWeb/js/theme.min.js" defer></script></body>
</html>
