<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>具身智能 - LLM-DailyDigest</title><meta name="author" content="">
<meta name="author-link" content="">
<meta name="description" content="具身智能

Genesis是一个生成式物理引擎，由 CMU 联合 20 多所研究实验室历时两年联合开发，能够生成 4D 动态世界、模拟广泛的材料和物理现象，专为通用机器人、具身 AI 和物理 AI 应用而设计。https://mp.weixin.qq.com/s/TsmMqip3r9kWxJdg1HfIrw
2025-06-26 13:57:58 Thursday


论文链接：https://www.roboticsproceedings.org/rss21/p020.pdf
论文主页：https://playground.mujoco.org/
机构：UC 伯克利、Google DeepMind、多伦多大学、剑桥大学
作者：Kevin Zakka, Baruch Tabanpour, Qiayuan Liao, Mustafa Haiderbhai, Samuel Holt, Jing Yuan Luo, Arthur Allshire, Erik Frey, Koushil Sreenath, Lueder Alexander Kahrs, Carmelo Sferrazza, Yuval Tassa, Pieter Abbeel

论文摘要： 该研究提出了 MuJoCo Playground—— 这是一个基于 MJX 构建的完全开源机器人学习框架，其核心设计目标是大幅简化仿真环境搭建、模型训练以及仿真到现实场景的迁移全流程。研究人员仅需执行简单的「pip install playground」安装命令，即可在单 GPU 硬件上完成分钟级策略训练。

2025-06-26 14:05:00 Thursday

由香港大学与上海AI Lab联合提出的 VLN-R1 ，具备将自然语言指令直接转化为第一人称视角下的连续导航动作的能力，无需依赖离散地图，能在复杂环境中灵活感知、决策与行动，实现类人级别的具身智能导航。
https://mp.weixin.qq.com/s/XhcnUxYUXi2jvX51u3zpsw" /><meta name="keywords" content='Hugo, FixIt' />
  <meta itemprop="name" content="具身智能">
  <meta itemprop="description" content="具身智能 Genesis是一个生成式物理引擎，由 CMU 联合 20 多所研究实验室历时两年联合开发，能够生成 4D 动态世界、模拟广泛的材料和物理现象，专为通用机器人、具身 AI 和物理 AI 应用而设计。https://mp.weixin.qq.com/s/TsmMqip3r9kWxJdg1HfIrw 2025-06-26 13:57:58 Thursday 论文链接：https://www.roboticsproceedings.org/rss21/p020.pdf 论文主页：https://playground.mujoco.org/ 机构：UC 伯克利、Google DeepMind、多伦多大学、剑桥大学 作者：Kevin Zakka, Baruch Tabanpour, Qiayuan Liao, Mustafa Haiderbhai, Samuel Holt, Jing Yuan Luo, Arthur Allshire, Erik Frey, Koushil Sreenath, Lueder Alexander Kahrs, Carmelo Sferrazza, Yuval Tassa, Pieter Abbeel 论文摘要： 该研究提出了 MuJoCo Playground—— 这是一个基于 MJX 构建的完全开源机器人学习框架，其核心设计目标是大幅简化仿真环境搭建、模型训练以及仿真到现实场景的迁移全流程。研究人员仅需执行简单的「pip install playground」安装命令，即可在单 GPU 硬件上完成分钟级策略训练。
2025-06-26 14:05:00 Thursday 由香港大学与上海AI Lab联合提出的 VLN-R1 ，具备将自然语言指令直接转化为第一人称视角下的连续导航动作的能力，无需依赖离散地图，能在复杂环境中灵活感知、决策与行动，实现类人级别的具身智能导航。
https://mp.weixin.qq.com/s/XhcnUxYUXi2jvX51u3zpsw">
  <meta itemprop="datePublished" content="2025-08-08T00:00:00+08:00">
  <meta itemprop="dateModified" content="2025-08-08T00:00:00+08:00">
  <meta itemprop="wordCount" content="176"><meta property="og:url" content="http://localhost:1313/topic/%E5%85%B7%E8%BA%AB/">
  <meta property="og:site_name" content="LLM-DailyDigest">
  <meta property="og:title" content="具身智能">
  <meta property="og:description" content="具身智能 Genesis是一个生成式物理引擎，由 CMU 联合 20 多所研究实验室历时两年联合开发，能够生成 4D 动态世界、模拟广泛的材料和物理现象，专为通用机器人、具身 AI 和物理 AI 应用而设计。https://mp.weixin.qq.com/s/TsmMqip3r9kWxJdg1HfIrw 2025-06-26 13:57:58 Thursday 论文链接：https://www.roboticsproceedings.org/rss21/p020.pdf 论文主页：https://playground.mujoco.org/ 机构：UC 伯克利、Google DeepMind、多伦多大学、剑桥大学 作者：Kevin Zakka, Baruch Tabanpour, Qiayuan Liao, Mustafa Haiderbhai, Samuel Holt, Jing Yuan Luo, Arthur Allshire, Erik Frey, Koushil Sreenath, Lueder Alexander Kahrs, Carmelo Sferrazza, Yuval Tassa, Pieter Abbeel 论文摘要： 该研究提出了 MuJoCo Playground—— 这是一个基于 MJX 构建的完全开源机器人学习框架，其核心设计目标是大幅简化仿真环境搭建、模型训练以及仿真到现实场景的迁移全流程。研究人员仅需执行简单的「pip install playground」安装命令，即可在单 GPU 硬件上完成分钟级策略训练。
2025-06-26 14:05:00 Thursday 由香港大学与上海AI Lab联合提出的 VLN-R1 ，具备将自然语言指令直接转化为第一人称视角下的连续导航动作的能力，无需依赖离散地图，能在复杂环境中灵活感知、决策与行动，实现类人级别的具身智能导航。
https://mp.weixin.qq.com/s/XhcnUxYUXi2jvX51u3zpsw">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="topic">
    <meta property="article:published_time" content="2025-08-08T00:00:00+08:00">
    <meta property="article:modified_time" content="2025-08-08T00:00:00+08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="具身智能">
  <meta name="twitter:description" content="具身智能 Genesis是一个生成式物理引擎，由 CMU 联合 20 多所研究实验室历时两年联合开发，能够生成 4D 动态世界、模拟广泛的材料和物理现象，专为通用机器人、具身 AI 和物理 AI 应用而设计。https://mp.weixin.qq.com/s/TsmMqip3r9kWxJdg1HfIrw 2025-06-26 13:57:58 Thursday 论文链接：https://www.roboticsproceedings.org/rss21/p020.pdf 论文主页：https://playground.mujoco.org/ 机构：UC 伯克利、Google DeepMind、多伦多大学、剑桥大学 作者：Kevin Zakka, Baruch Tabanpour, Qiayuan Liao, Mustafa Haiderbhai, Samuel Holt, Jing Yuan Luo, Arthur Allshire, Erik Frey, Koushil Sreenath, Lueder Alexander Kahrs, Carmelo Sferrazza, Yuval Tassa, Pieter Abbeel 论文摘要： 该研究提出了 MuJoCo Playground—— 这是一个基于 MJX 构建的完全开源机器人学习框架，其核心设计目标是大幅简化仿真环境搭建、模型训练以及仿真到现实场景的迁移全流程。研究人员仅需执行简单的「pip install playground」安装命令，即可在单 GPU 硬件上完成分钟级策略训练。
2025-06-26 14:05:00 Thursday 由香港大学与上海AI Lab联合提出的 VLN-R1 ，具备将自然语言指令直接转化为第一人称视角下的连续导航动作的能力，无需依赖离散地图，能在复杂环境中灵活感知、决策与行动，实现类人级别的具身智能导航。
https://mp.weixin.qq.com/s/XhcnUxYUXi2jvX51u3zpsw">
<meta name="application-name" content="LLM-DailyDigest">
<meta name="apple-mobile-web-app-title" content="LLM-DailyDigest"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" href="http://localhost:1313/topic/%E5%85%B7%E8%BA%AB/" /><link rel="prev" href="http://localhost:1313/topic/%E5%8D%9A%E5%BC%88/" /><link rel="next" href="http://localhost:1313/topic/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "具身智能",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "http:\/\/localhost:1313\/topic\/%E5%85%B7%E8%BA%AB\/"
    },"genre": "topic","wordcount":  176 ,
    "url": "http:\/\/localhost:1313\/topic\/%E5%85%B7%E8%BA%AB\/","datePublished": "2025-08-08T00:00:00+08:00","dateModified": "2025-08-08T00:00:00+08:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "Author"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/" title="LLM-DailyDigest"><img loading="lazy" src="/fixit.svg" data-title="LLM-DailyDigest" data-alt="LLM-DailyDigest" class="logo" style="background: url(/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-desktop" class="typeit"></span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/posts/llm-dailydigest"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/resources/"
                
                
              >资源</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/topic/"
                
                
              >主题</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/updates/"
                
                
              >日报</a></li><li class="menu-item delimiter"></li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/" title="LLM-DailyDigest"><img loading="lazy" src="/fixit.svg" data-title="/fixit.svg" data-alt="/fixit.svg" class="logo" style="background: url(/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-title-mobile" class="typeit"></span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/posts/llm-dailydigest"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/resources/"
                  
                  
                >资源</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/topic/"
                  
                  
                >主题</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/updates/"
                  
                  
                >日报</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><main class="container"><aside class="toc" id="toc-auto"><h2 class="toc-title">Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom">
    </aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span>具身智能</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      </span></span></div>
      <div class="post-meta-line"><span title="published on 2025-08-08 00:00:00"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden="true"></i><time datetime="2025-08-08">2025-08-08</time></span>&nbsp;<span title="Updated on 2025-08-08 00:00:00"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden="true"></i><time datetime="2025-08-08">2025-08-08</time></span>&nbsp;<span title="176 words"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>About 200 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>One minute</span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" data-kept="false">
        <div class="details-summary toc-title">
          <span>Contents</span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#世界模型">世界模型</a></li>
    <li><a href="#数字人">数字人</a></li>
    <li><a href="#机器人">机器人</a></li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h1 id="具身智能">具身智能</h1>
<ol>
<li>Genesis是一个生成式物理引擎，由 CMU 联合 20 多所研究实验室历时两年联合开发，能够生成 4D 动态世界、模拟广泛的材料和物理现象，专为通用机器人、具身 AI 和物理 AI 应用而设计。<a href="https://mp.weixin.qq.com/s/TsmMqip3r9kWxJdg1HfIrw"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/TsmMqip3r9kWxJdg1HfIrw</a></li>
<li>2025-06-26 13:57:58 Thursday</li>
</ol>
<ul>
<li>论文链接：https://www.roboticsproceedings.org/rss21/p020.pdf</li>
<li>论文主页：https://playground.mujoco.org/</li>
<li>机构：UC 伯克利、Google DeepMind、多伦多大学、剑桥大学</li>
<li>作者：Kevin Zakka, Baruch Tabanpour, Qiayuan Liao, Mustafa Haiderbhai, Samuel Holt, Jing Yuan Luo, Arthur Allshire, Erik Frey, Koushil Sreenath, Lueder Alexander Kahrs, Carmelo Sferrazza, Yuval Tassa, Pieter Abbeel</li>
</ul>
<p><strong>论文摘要：</strong> 该研究提出了 MuJoCo Playground—— 这是一个基于 MJX 构建的完全开源机器人学习框架，其核心设计目标是大幅简化仿真环境搭建、模型训练以及仿真到现实场景的迁移全流程。研究人员仅需执行简单的「pip install playground」安装命令，即可在单 GPU 硬件上完成分钟级策略训练。</p>
<ol start="3">
<li>2025-06-26 14:05:00 Thursday</li>
</ol>
<p>由香港大学与上海AI Lab联合提出的 <strong>VLN-R1</strong> ，具备将自然语言指令直接转化为第一人称视角下的连续导航动作的能力，无需依赖离散地图，能在复杂环境中灵活感知、决策与行动，实现类人级别的具身智能导航。</p>
<p><a href="https://mp.weixin.qq.com/s/XhcnUxYUXi2jvX51u3zpsw"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/XhcnUxYUXi2jvX51u3zpsw</a></p>
<ol start="4">
<li>2025-06-26 14:06:50 Thursday</li>
</ol>
<p><strong>Google DeepMind</strong>团队首个可以完全在机器人本地运行的视觉-语言-动作（VLA）模型<strong>Gemini Robotics On-Device</strong>发布。https://mp.weixin.qq.com/s/oyT1CRRdbUxfF9cvApePRg</p>
<p>2025-06-27 14:06:04 Friday ｜ 中科院自动化所提出BridgeVLA模型，通过将3D输入投影为2D图像并利用2D热图进行动作预测，实现了高效且泛化的3D机器人操作学习。实验表明，BridgeVLA在仿真和真实场景中均展现出卓越的性能和数据效率，仅需3条轨迹即可在基础任务中达到96.8%的成功率。 <a href="https://mp.weixin.qq.com/s/PKA5T4ybjYwc46WH6QmcDg"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/PKA5T4ybjYwc46WH6QmcDg</a></p>
<h2 id="世界模型">世界模型</h2>
<p>2025-07-02 13:11:27 Wednesday ｜ 伯克利&amp;Meta面向具身智能的世界模型：让AI通过全身动作「看见」未来 <a href="https://mp.weixin.qq.com/s/id_ISbf7wVvk3pl2GCIgWA"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/id_ISbf7wVvk3pl2GCIgWA</a></p>
<p>论文标题：Whole-Body Conditioned Egocentric Video Prediction</p>
<p>论文地址：https://arxiv.org/pdf/2506.21552</p>
<p>项目地址：https://dannytran123.github.io/PEVA/</p>
<p>参考阅读链接：https://x.com/YutongBAI1002/status/1938442251866411281</p>
<p>相比传统模型只用「速度 + 方向」做预测，PEVA 把整个人的 3D 姿态（包括关节位置和旋转）一并喂进模型，和历史的视频帧一起输入，从而让 AI 学会：身体的动作，会如何重新组织我们能看到的世界。</p>
<ol start="2">
<li>2025-07-01 11:27:15 Tuesday ｜ 世界模型。而且就在最近，LeCun团队的世界模型新进展来了。名叫**PEVA模型 **<strong><a href="https://mp.weixin.qq.com/s/MBTNAYeu-J_9MI_-jpxQBA"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/MBTNAYeu-J_9MI_-jpxQBA</a></strong></li>
</ol>
<p>该模型通过<strong>结构化动作表示将</strong>人体48维关节运动学数据与<strong>条件扩散Transformer</strong>结合。</p>
<p>利用VAE编码视频帧、自适应层归一化嵌入动作条件及跨历史帧注意力机制等，实现了从全身动作<strong>预测第一视角视频</strong>的高精度生成与长期时序连贯。</p>
<p>论文地址：https://arxiv.org/abs/2506.21552</p>
<p>项目地址：https://dannytran123.github.io/PEVA/</p>
<ol start="3">
<li>2025-06-19 19:34:50 Thursday｜ EX-4D来了，实现单目视频到自由视角生成</li>
</ol>
<p><a href="https://mp.weixin.qq.com/s/U4zom1havvpV4NwNXL65Vg"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/U4zom1havvpV4NwNXL65Vg</a></p>
<p><strong>相机可控的视频生成技术</strong>堪称核心拼图 —— 它让视频生成模型不再是单向的 “世界模拟器”，而是能被用户自由探索的 “平行宇宙”，为沉浸式 3D 电影等颠覆性应用奠定基础！</p>
<p>对此，PICO-MR 团队提出了一个破局方案：EX-4D，可以从任意单目视频生成其对应的新视角视频。 <strong>EX-4D</strong> ：</p>
<ul>
<li><strong>一致性更强：</strong> EX-4D 在 FID、FVD 等指标上超越了最新的开源方法，支持生成高物理一致性的新视角视频。</li>
<li><strong>视角跨度更大：</strong> 得益于新几何先验格式，EX-4D 能支持极端视角下的高质量视频生成。</li>
<li><strong>综合效果更好：</strong> 轻量级 LoRA Adapter 能充分利用 WAN-2.1 基座模型的强大生成能力，生成细节、质量更好的视频。</li>
</ul>
<p>Arxiv 链接: <a href="https://arxiv.org/abs/2506.05554"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2506.05554</a></p>
<p>项目主页链接: <a href="https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html"target="_blank" rel="external nofollow noopener noreferrer">https://tau-yihouxiang.github.io/projects/EX-4D/EX-4D.html</a></p>
<p>代码链接: <a href="https://github.com/tau-yihouxiang/EX-4D"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/tau-yihouxiang/EX-4D</a></p>
<h2 id="数字人">数字人</h2>
<p>2025-06-26 12:02:42 Thursday ｜ 如何做到在手机上实时跑3D真人数字人？MNN-TaoAvatar开源了！ <a href="https://mp.weixin.qq.com/s/YW9ASa_bPDdwQ2nANqPKEw"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/YW9ASa_bPDdwQ2nANqPKEw</a></p>
<ol>
<li>TaoAvatar 基于先进的 3D 高斯泼溅技术，提供了一套全身互动式的真人数字人解决方案。</li>
</ol>
<h2 id="机器人">机器人</h2>
<ol>
<li>20250808｜<a href="https://mp.weixin.qq.com/s/0Ap9BW0jCrDyfunJuyhodg"target="_blank" rel="external nofollow noopener noreferrer">哇塞，今天北京被机器人人人人人塞满了！</a>
<ol>
<li>通用机器人的特点就是能力非常广泛，可以胜任多种任务和环境；不再像以往的专用机器人，只能处理例如扫地、焊接这样单一的任务。</li>
<li>目标就是实现 <strong>类人或类通用智能体的灵活性和适应性</strong> ，可以根据不同指令、上下文甚至环境变化，自主决策并完成任务。</li>
<li><strong>全域全身视觉-语言-行动大模型</strong> —— <strong>GOVLA</strong> （Global &amp; Omni-body Vision-Language-Action Model）</li>
</ol>
</li>
</ol>
</div></article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">Public - 2025</span><span class="author" itemprop="copyrightHolder">
              <a href="/"></a></span></div><div class="footer-line statistics"></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">Theme FixIt works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="preload" href="/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script src="/lib/sharer/sharer.min.js" async defer></script><script src="/lib/typeit/index.umd.js" defer></script><script src="/lib/katex/katex.min.js" defer></script><script src="/lib/katex/auto-render.min.js" defer></script><script src="/lib/katex/copy-tex.min.js" defer></script><script src="/lib/katex/mhchem.min.js" defer></script><script src="/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-desktop":"LLM-DailyDigest 大模型研究日报","typeit-header-title-mobile":"LLM-DailyDigest 大模型研究日报"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-desktop":["typeit-header-desktop"],"typeit-header-title-mobile":["typeit-header-title-mobile"]},"duration":-1,"loop":false,"speed":100}};</script><script src="/js/theme.min.js" defer></script></body>
</html>
