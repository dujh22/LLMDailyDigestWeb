<!DOCTYPE html>
<html itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <head><script src="/LLMDailyDigestWeb/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=LLMDailyDigestWeb/livereload" data-no-instant defer></script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
    <meta name="robots" content="noodp" />
    <title>应用 - LLM-DailyDigest</title><meta name="author" content="">
<meta name="author-link" content="">
<meta name="description" content="应用
社会学研究
辩论

2025-07-03 11:37:35 Thursday ｜

LLM 中理解和说服之间的细线 [PDF()] [Copy] [Kimi()] [REL]
Authors : Adrian de Wynter, Tangming Yuan
大型语言模型 （LLM） 在维护高层次、令人信服的对话方面非常出色。它们正在被快速部署为敏感领域的聊天机器人和评估器，例如同行评审和心理健康应用程序。这一点，以及关于他们推理能力的不同描述，需要对 LLM 及其对对话的理解进行更仔细的检查。在这项工作中，我们首先评估了 LLM 维持辩论的能力——这是人类交流的最纯粹但最复杂的形式之一。然后我们衡量这种能力如何与他们对所谈论内容的理解相关，即他们对对话结构和语用上下文的理解。我们发现 LLM 能够保持连贯、有说服力的辩论，经常动摇参与者和听众的信念。我们还注意到，对 AI 参与的认识或怀疑会鼓励人们对所提出的论点持更多批评态度。然而，当对 LLM 进行民意调查时，他们无法证明这种理解。我们的研究结果将 LLM 作为评估者的缺点与他们理解上下文的（不）能力联系起来。更广泛地说，对于论证论领域，我们假设，如果一个代理人能够令人信服地维持对话，那么它就没有必要知道它在说什么。因此，语用背景和连贯性的建模是次于有效性的。
科目 :  计算和语言 , 计算机与社会
决策

2025-07-03 11:38:51 Thursday ｜

面向决策的文本评估 [PDF()] [Copy] [Kimi()] [REL]
Authors : Yu-Shiang Huang, Chuan-Ju Wang, Chung-Chi Chen" /><meta name="keywords" content='Hugo, FixIt' />
  <meta itemprop="name" content="应用">
  <meta itemprop="description" content="应用 社会学研究 辩论 2025-07-03 11:37:35 Thursday ｜ LLM 中理解和说服之间的细线 [PDF()] [Copy] [Kimi()] [REL]
Authors : Adrian de Wynter, Tangming Yuan
大型语言模型 （LLM） 在维护高层次、令人信服的对话方面非常出色。它们正在被快速部署为敏感领域的聊天机器人和评估器，例如同行评审和心理健康应用程序。这一点，以及关于他们推理能力的不同描述，需要对 LLM 及其对对话的理解进行更仔细的检查。在这项工作中，我们首先评估了 LLM 维持辩论的能力——这是人类交流的最纯粹但最复杂的形式之一。然后我们衡量这种能力如何与他们对所谈论内容的理解相关，即他们对对话结构和语用上下文的理解。我们发现 LLM 能够保持连贯、有说服力的辩论，经常动摇参与者和听众的信念。我们还注意到，对 AI 参与的认识或怀疑会鼓励人们对所提出的论点持更多批评态度。然而，当对 LLM 进行民意调查时，他们无法证明这种理解。我们的研究结果将 LLM 作为评估者的缺点与他们理解上下文的（不）能力联系起来。更广泛地说，对于论证论领域，我们假设，如果一个代理人能够令人信服地维持对话，那么它就没有必要知道它在说什么。因此，语用背景和连贯性的建模是次于有效性的。
科目 : 计算和语言 , 计算机与社会
决策 2025-07-03 11:38:51 Thursday ｜ 面向决策的文本评估 [PDF()] [Copy] [Kimi()] [REL]
Authors : Yu-Shiang Huang, Chuan-Ju Wang, Chung-Chi Chen">
  <meta itemprop="datePublished" content="2025-08-15T00:00:00+08:00">
  <meta itemprop="dateModified" content="2025-08-15T00:00:00+08:00">
  <meta itemprop="wordCount" content="456"><meta property="og:url" content="http://localhost:1313/LLMDailyDigestWeb/topic/%E5%BA%94%E7%94%A8/">
  <meta property="og:site_name" content="LLM-DailyDigest">
  <meta property="og:title" content="应用">
  <meta property="og:description" content="应用 社会学研究 辩论 2025-07-03 11:37:35 Thursday ｜ LLM 中理解和说服之间的细线 [PDF()] [Copy] [Kimi()] [REL]
Authors : Adrian de Wynter, Tangming Yuan
大型语言模型 （LLM） 在维护高层次、令人信服的对话方面非常出色。它们正在被快速部署为敏感领域的聊天机器人和评估器，例如同行评审和心理健康应用程序。这一点，以及关于他们推理能力的不同描述，需要对 LLM 及其对对话的理解进行更仔细的检查。在这项工作中，我们首先评估了 LLM 维持辩论的能力——这是人类交流的最纯粹但最复杂的形式之一。然后我们衡量这种能力如何与他们对所谈论内容的理解相关，即他们对对话结构和语用上下文的理解。我们发现 LLM 能够保持连贯、有说服力的辩论，经常动摇参与者和听众的信念。我们还注意到，对 AI 参与的认识或怀疑会鼓励人们对所提出的论点持更多批评态度。然而，当对 LLM 进行民意调查时，他们无法证明这种理解。我们的研究结果将 LLM 作为评估者的缺点与他们理解上下文的（不）能力联系起来。更广泛地说，对于论证论领域，我们假设，如果一个代理人能够令人信服地维持对话，那么它就没有必要知道它在说什么。因此，语用背景和连贯性的建模是次于有效性的。
科目 : 计算和语言 , 计算机与社会
决策 2025-07-03 11:38:51 Thursday ｜ 面向决策的文本评估 [PDF()] [Copy] [Kimi()] [REL]
Authors : Yu-Shiang Huang, Chuan-Ju Wang, Chung-Chi Chen">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="topic">
    <meta property="article:published_time" content="2025-08-15T00:00:00+08:00">
    <meta property="article:modified_time" content="2025-08-15T00:00:00+08:00">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="应用">
  <meta name="twitter:description" content="应用 社会学研究 辩论 2025-07-03 11:37:35 Thursday ｜ LLM 中理解和说服之间的细线 [PDF()] [Copy] [Kimi()] [REL]
Authors : Adrian de Wynter, Tangming Yuan
大型语言模型 （LLM） 在维护高层次、令人信服的对话方面非常出色。它们正在被快速部署为敏感领域的聊天机器人和评估器，例如同行评审和心理健康应用程序。这一点，以及关于他们推理能力的不同描述，需要对 LLM 及其对对话的理解进行更仔细的检查。在这项工作中，我们首先评估了 LLM 维持辩论的能力——这是人类交流的最纯粹但最复杂的形式之一。然后我们衡量这种能力如何与他们对所谈论内容的理解相关，即他们对对话结构和语用上下文的理解。我们发现 LLM 能够保持连贯、有说服力的辩论，经常动摇参与者和听众的信念。我们还注意到，对 AI 参与的认识或怀疑会鼓励人们对所提出的论点持更多批评态度。然而，当对 LLM 进行民意调查时，他们无法证明这种理解。我们的研究结果将 LLM 作为评估者的缺点与他们理解上下文的（不）能力联系起来。更广泛地说，对于论证论领域，我们假设，如果一个代理人能够令人信服地维持对话，那么它就没有必要知道它在说什么。因此，语用背景和连贯性的建模是次于有效性的。
科目 : 计算和语言 , 计算机与社会
决策 2025-07-03 11:38:51 Thursday ｜ 面向决策的文本评估 [PDF()] [Copy] [Kimi()] [REL]
Authors : Yu-Shiang Huang, Chuan-Ju Wang, Chung-Chi Chen">
<meta name="application-name" content="LLM-DailyDigest">
<meta name="apple-mobile-web-app-title" content="LLM-DailyDigest"><meta name="theme-color" data-light="#f8f8f8" data-dark="#252627" content="#f8f8f8"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="canonical" href="http://localhost:1313/LLMDailyDigestWeb/topic/%E5%BA%94%E7%94%A8/" /><link rel="prev" href="http://localhost:1313/LLMDailyDigestWeb/topic/%E6%96%B0%E9%97%BB/" /><link rel="next" href="http://localhost:1313/LLMDailyDigestWeb/topic/%E8%AE%B0%E5%BF%86/" /><link rel="stylesheet" href="/LLMDailyDigestWeb/css/style.min.css"><link rel="preload" href="/LLMDailyDigestWeb/lib/fontawesome-free/all.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/LLMDailyDigestWeb/lib/animate/animate.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "headline": "应用",
    "inLanguage": "zh-CN",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "http:\/\/localhost:1313\/LLMDailyDigestWeb\/topic\/%E5%BA%94%E7%94%A8\/"
    },"genre": "topic","wordcount":  456 ,
    "url": "http:\/\/localhost:1313\/LLMDailyDigestWeb\/topic\/%E5%BA%94%E7%94%A8\/","datePublished": "2025-08-15T00:00:00+08:00","dateModified": "2025-08-15T00:00:00+08:00","publisher": {
      "@type": "Organization",
      "name": ""},"author": {
        "@type": "Person",
        "name": "Author"
      },"description": ""
  }
  </script></head>
  <body data-header-desktop="sticky" data-header-mobile="auto"><script>(window.localStorage?.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('data-theme', 'dark');</script><div class="wrapper" data-page-style="normal"><header class="desktop animate__faster" id="header-desktop">
  <div class="header-wrapper">
    <div class="header-title">
      <a href="/LLMDailyDigestWeb/" title="LLM-DailyDigest"><img loading="lazy" src="/LLMDailyDigestWeb/fixit.svg" data-title="LLM-DailyDigest" data-alt="LLM-DailyDigest" class="logo" style="background: url(/LLMDailyDigestWeb/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-desktop" class="typeit"></span></a><span class="header-subtitle"></span></div>
    <nav>
      <ul class="menu"><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/posts/llmdailydigest"
                
                
              ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/resources/"
                
                
              >资源</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/topic/"
                
                
              >主题</a></li><li class="menu-item">
              <a
                class="menu-link"
                href="/LLMDailyDigestWeb/updates/"
                
                
              >日报</a></li><li class="menu-item delimiter"></li><li class="menu-item theme-switch" title="Switch Theme">
          <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
        </li></ul>
    </nav>
  </div>
</header><header class="mobile animate__faster" id="header-mobile">
  <div class="header-container">
    <div class="header-wrapper">
      <div class="header-title">
        <a href="/LLMDailyDigestWeb/" title="LLM-DailyDigest"><img loading="lazy" src="/LLMDailyDigestWeb/fixit.svg" data-title="/LLMDailyDigestWeb/fixit.svg" data-alt="/LLMDailyDigestWeb/fixit.svg" class="logo" style="background: url(/LLMDailyDigestWeb/svg/loading.min.svg) no-repeat center;" onload="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}this.dataset.lazyloaded='';" onerror="this.title=this.dataset.title;this.alt=this.dataset.alt;for(const i of ['style', 'data-title','data-alt','onerror','onload']){this.removeAttribute(i);}"/><span id="typeit-header-title-mobile" class="typeit"></span></a><span class="header-subtitle"></span></div>
      <div class="menu-toggle" id="menu-toggle-mobile">
        <span></span><span></span><span></span>
      </div>
    </div>
    <nav>
      <ul class="menu" id="menu-mobile"><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/posts/llmdailydigest"
                  
                  
                ><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden="true"></i> 详情</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/resources/"
                  
                  
                >资源</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/topic/"
                  
                  
                >主题</a></li><li
              class="menu-item"
            ><a
                  class="menu-link"
                  href="/LLMDailyDigestWeb/updates/"
                  
                  
                >日报</a></li><li class="menu-item menu-system">
          <span class="menu-system-item theme-switch" title="Switch Theme"><i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i></span></li>
      </ul>
    </nav>
  </div>
</header><main class="container"><aside class="toc" id="toc-auto"><h2 class="toc-title">Contents&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden="true"></i></h2>
      <div class="toc-content" id="toc-content-auto"></div></aside>

  <aside class="aside-custom">
    </aside>

  <article class="page single">
    <div class="header"><h1 class="single-title animate__animated animate__flipInX"><span>应用</span>
      </h1></div><div class="post-meta">
      <div class="post-meta-line"><span class="post-author"><span class="author"><i class="fa-solid fa-user-circle" aria-hidden="true"></i>
      </span></span></div>
      <div class="post-meta-line"><span title="published on 2025-08-15 00:00:00"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden="true"></i><time datetime="2025-08-15">2025-08-15</time></span>&nbsp;<span title="Updated on 2025-08-15 00:00:00"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden="true"></i><time datetime="2025-08-15">2025-08-15</time></span>&nbsp;<span title="456 words"><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden="true"></i>About 500 words</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden="true"></i>3 minutes</span>&nbsp;</div>
    </div><div class="details toc" id="toc-static" data-kept="false">
        <div class="details-summary toc-title">
          <span>Contents</span><i class="details-icon fa-solid fa-angle-right" aria-hidden="true"></i></div>
        <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#社会学研究">社会学研究</a>
      <ul>
        <li><a href="#辩论">辩论</a></li>
        <li><a href="#决策">决策</a></li>
      </ul>
    </li>
    <li><a href="#选型">选型</a></li>
    <li><a href="#时序">时序</a></li>
    <li><a href="#提示工程">提示工程</a></li>
    <li><a href="#rag">RAG</a></li>
    <li><a href="#情感情绪">情感&amp;情绪</a></li>
    <li><a href="#深度研究">深度研究</a>
      <ul>
        <li>
          <ul>
            <li><a href="#季峰陈天桥联手agi首秀炸场最强开源深度研究模型gaia测试824分超openai"><a href="https://mp.weixin.qq.com/s/VHR2vxmuHlTc6H4xzTxH_A">季峰陈天桥联手AGI首秀炸场！最强开源深度研究模型，GAIA测试82.4分超OpenAI</a></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#生物">生物</a>
      <ul>
        <li>
          <ul>
            <li><a href="#蛋白质基座的gpt时代来了"><a href="https://mp.weixin.qq.com/s/WmGTYPO9gTm2XJ-Rjqvm-Q">蛋白质基座的GPT时代来了？！</a></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#医疗">医疗</a>
      <ul>
        <li>
          <ul>
            <li><a href="#gpt-5超越人类医生推理能力比专家高出24理解力强29"><a href="https://mp.weixin.qq.com/s/gfM7kMxSt9Cs7Ark8gaOcA">GPT-5超越人类医生！推理能力比专家高出24%，理解力强29%</a></a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#预测">预测</a></li>
  </ul>
</nav></div>
      </div><div
      class="content"
      id="content"
      
      
    ><h1 id="应用">应用</h1>
<h2 id="社会学研究">社会学研究</h2>
<h3 id="辩论">辩论</h3>
<ol>
<li>2025-07-03 11:37:35 Thursday ｜</li>
</ol>
<p><strong><a href="https://papers.cool/arxiv/2507.01936"target="_blank" rel="external nofollow noopener noreferrer">LLM 中理解和说服之间的细线</a></strong> <strong>[PDF()]</strong> <strong>[Copy]</strong> <strong>[Kimi()]</strong> <strong>[REL]</strong></p>
<p><strong>Authors</strong> : <a href="https://arxiv.org/search/?searchtype=author&amp;query=Adrian%20de%20Wynter"target="_blank" rel="external nofollow noopener noreferrer">Adrian de Wynter</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Tangming%20Yuan"target="_blank" rel="external nofollow noopener noreferrer">Tangming Yuan</a></p>
<p>大型语言模型 （LLM） 在维护高层次、令人信服的对话方面非常出色。它们正在被快速部署为敏感领域的聊天机器人和评估器，例如同行评审和心理健康应用程序。这一点，以及关于他们推理能力的不同描述，需要对 LLM 及其对对话的理解进行更仔细的检查。在这项工作中，我们首先评估了 LLM 维持辩论的能力——这是人类交流的最纯粹但最复杂的形式之一。然后我们衡量这种能力如何与他们对所谈论内容的理解相关，即他们对对话结构和语用上下文的理解。我们发现 LLM 能够保持连贯、有说服力的辩论，经常动摇参与者和听众的信念。我们还注意到，对 AI 参与的认识或怀疑会鼓励人们对所提出的论点持更多批评态度。然而，当对 LLM 进行民意调查时，他们无法证明这种理解。我们的研究结果将 LLM 作为评估者的缺点与他们理解上下文的（不）能力联系起来。更广泛地说，对于论证论领域，我们假设，如果一个代理人能够令人信服地维持对话，那么它就没有必要知道它在说什么。因此，语用背景和连贯性的建模是次于有效性的。</p>
<p><strong>科目</strong> :  <strong><a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></strong> , <a href="https://papers.cool/arxiv/cs.CY"target="_blank" rel="external nofollow noopener noreferrer">计算机与社会</a></p>
<h3 id="决策">决策</h3>
<ol start="3">
<li>2025-07-03 11:38:51 Thursday ｜</li>
</ol>
<p><strong><a href="https://papers.cool/arxiv/2507.01923"target="_blank" rel="external nofollow noopener noreferrer">面向决策的文本评估</a></strong> <strong>[PDF()]</strong> <strong>[Copy]</strong> <strong>[Kimi()]</strong> <strong>[REL]</strong></p>
<p><strong>Authors</strong> : <a href="https://arxiv.org/search/?searchtype=author&amp;query=Yu-Shiang%20Huang"target="_blank" rel="external nofollow noopener noreferrer">Yu-Shiang Huang</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Chuan-Ju%20Wang"target="_blank" rel="external nofollow noopener noreferrer">Chuan-Ju Wang</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Chung-Chi%20Chen"target="_blank" rel="external nofollow noopener noreferrer">Chung-Chi Chen</a></p>
<p>自然语言生成 （NLG） 越来越多地部署在高风险领域，但常见的内在评估方法，如 n-gram 重叠或句子合理性，与实际决策效率的相关性很弱。我们提出了一个以决策为导向的框架，通过直接测量其对人类和大型语言模型 （LLM） 决策结果的影响来评估生成的文本。使用市场摘要文本（包括客观的早间总结和主观的收盘钟分析）作为测试案例，我们根据人类投资者和独立 LLM 代理人执行的交易的财务表现来评估决策质量，这些交易仅由这些文本提供信息。我们的研究结果表明，当仅依赖摘要时，人类和 LLM 代理都没有始终超过随机性能。然而，更丰富的分析评论使协作的人类 LLM 团队能够显著优于个人人类或代理基线。我们的方法强调了通过促进人类和 LLM 之间协同决策的能力来评估生成文本的重要性，突出了传统内在指标的关键局限性。</p>
<p><strong>主题</strong> : <strong><a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></strong></p>
<h2 id="选型">选型</h2>
<ol start="3">
<li>2025-06-19 20:07:43 Thursday ｜ 告别玄学选LLM！弗吉尼亚理工选型框架入选ICML 2025 <a href="https://mp.weixin.qq.com/s/JTXjazJ8KRCURggbfTjNIA"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/JTXjazJ8KRCURggbfTjNIA</a></li>
</ol>
<p>来自弗吉尼亚理工大学的研究人员推出了个选型框架 <strong>LensLLM</strong> ——</p>
<p>大幅提升选型效果的同时，成本却降低近90%。</p>
<p>LensLLM的理论基础来自一项 <strong>全新的PAC-Bayes泛化界限推导</strong> ，首次从数学上揭示了LLM在不同数据规模下微调表现的 <strong>非线性变化规律</strong> ，</p>
<p>研究团队构建了一个基于 <strong>神经切线核（NTK）增强的缩放律模型</strong> ，能够在只微调极少量数据的前提下：</p>
<ul>
<li>精确拟合整个微调曲线（如图2和表2所示）</li>
<li>预测最终测试性能</li>
<li>排出最优模型排名</li>
</ul>
<h2 id="时序">时序</h2>
<ol start="4">
<li>2025-06-30 17:59:43 Monday ｜ 航空发动机用上大模型：解决复杂时序问题，性能超越ChatGPT-4o实现SOTA｜上交创智复旦 <a href="https://mp.weixin.qq.com/s/DzOOT8ojdd2zTeS3IpYcug"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/DzOOT8ojdd2zTeS3IpYcug</a></li>
<li>2025-06-23 12:50:53 Monday ｜ 首个「万亿级时间点」预训练，清华发布生成式时序大模型日晷 | ICML Oral <a href="https://mp.weixin.qq.com/s/y3sc2e2lmW1sqfnoK-ZdDA"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/y3sc2e2lmW1sqfnoK-ZdDA</a></li>
</ol>
<h2 id="提示工程">提示工程</h2>
<p>2025-06-24 13:38:50 Tuesday｜</p>
<p>RiOT: Efficient Prompt Refinement with Residual Optimization Tree
<strong>链接</strong> ：https://arxiv.org/abs/2506.16389</p>
<p><strong>作者</strong> ：ou, Zhengyan Shi, Yuan Yao, Lei Liang, Huajun Chen, Qiang Zhang
<strong>摘要</strong> ：大型语言模型（LLM）的最新进展突出了它们在各种任务中的潜力，但它们的性能仍然严重依赖于有效提示的设计。现有的自动提示优化方法面临两个挑战：缺乏多样性，限制了对有价值和创新方向的探索，以及语义漂移，其中对一个任务的优化可能会降低其他任务的性能。为了解决这些问题，我们提出了残差优化树（RiOT），一种新的自动提示优化框架。RiOT通过文本梯度迭代地细化提示，在每一步生成多个语义不同的候选项，并使用困惑度选择最佳提示。此外，RiOT结合了文本剩余连接，通过在优化迭代中选择性地保留有益内容来减轻语义漂移。树结构有效地管理优化过程，确保可扩展性和灵活性。在五个基准测试中进行了广泛的实验，涵盖常识，数学，逻辑，时间和语义推理，证明RiOT优于以前的提示优化方法和手动提示。</p>
<ol start="2">
<li>2025-06-25 10:42:37 Wednesday  ｜ LLM进入「拖拽时代」！只靠Prompt，几秒定制一个大模型，效率飙升12000倍 <a href="https://mp.weixin.qq.com/s/geOn7zyJRQwfJra38EjcxQ"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/geOn7zyJRQwfJra38EjcxQ</a></li>
</ol>
<p>DnD是一种基于提示词的参数生成器，能够对LLM进行无需训练的自适应微调。</p>
<p>通过一个轻量级文本编码器与一个级联超卷积解码器的组合，DnD能在数秒内，仅根据无标签的任务提示词，生成针对该任务的LoRA权重矩阵。</p>
<p>总结来说，DnD的核心优势如下：</p>
<ul>
<li><strong>极致效率：</strong> 其计算开销比传统的全量微调低12,000倍。</li>
<li><strong>卓越性能：</strong> 在零样本学习的常识推理、数学、编码及多模态基准测试中，其性能比最强大的、需要训练的LoRA模型还要高出30%。</li>
<li><strong>强大泛化：</strong> 仅需无标签的提示词，即可在不同领域间展现出强大的泛化能力</li>
</ul>
<h2 id="rag">RAG</h2>
<ol start="6">
<li>2025-06-27 13:34:29 Friday ｜ 全模态RAG突破文本局限，港大构建跨模态一体化系统 <a href="https://mp.weixin.qq.com/s/lFKyKvm0luZTpx8_nGyWEw"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/lFKyKvm0luZTpx8_nGyWEw</a></li>
</ol>
<p><a href="https://mp.weixin.qq.com/s/VuowC1hvE3P4RxIfYDZlLA"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/VuowC1hvE3P4RxIfYDZlLA</a></p>
<p>突破传统检索增强生成（RAG）技术的单一文本局限，实现对文档中文字、图表、表格、公式等复杂内容的统一智能理解。</p>
<p>香港大学黄超教授团队开源多模态智能处理系统RAG-Anything，将碎片化的信息孤岛转化为结构化的知识网络，为智能多模态文档分析开辟了全新技术路径。</p>
<h2 id="情感情绪">情感&amp;情绪</h2>
<p>2025-06-28 17:43:13 Saturday Anthropic最新研究：Claude正悄悄进化为“情绪价值大师” <a href="https://mp.weixin.qq.com/s/mGEbAVCSWZjydrwwOouzOA"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/mGEbAVCSWZjydrwwOouzOA</a></p>
<h2 id="深度研究">深度研究</h2>
<p>2025-07-03 11:40:31 Thursday ｜</p>
<p><strong><a href="https://papers.cool/arxiv/2507.01903"target="_blank" rel="external nofollow noopener noreferrer">AI4Research：人工智能对科学研究的调查</a></strong> <strong>[PDF(3)]</strong> <strong>[Copy]</strong> <strong>[Kimi()]</strong> <strong>[REL]</strong></p>
<p><strong>Authors</strong> : <a href="https://arxiv.org/search/?searchtype=author&amp;query=Qiguang%20Chen"target="_blank" rel="external nofollow noopener noreferrer">Qiguang Chen</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Mingda%20Yang"target="_blank" rel="external nofollow noopener noreferrer">Mingda Yang</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Libo%20Qin"target="_blank" rel="external nofollow noopener noreferrer">Libo Qin</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Jinhao%20Liu"target="_blank" rel="external nofollow noopener noreferrer">Jinhao Liu</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Zheng%20Yan"target="_blank" rel="external nofollow noopener noreferrer">Zheng Yan</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiannan%20Guan"target="_blank" rel="external nofollow noopener noreferrer">Jiannan Guan</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Dengyun%20Peng"target="_blank" rel="external nofollow noopener noreferrer">Dengyun Peng</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Yiyan%20Ji"target="_blank" rel="external nofollow noopener noreferrer">Yiyan Ji</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Hanjing%20Li"target="_blank" rel="external nofollow noopener noreferrer">Hanjing Li</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Mengkang%20Hu"target="_blank" rel="external nofollow noopener noreferrer">Mengkang Hu</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Yimeng%20Zhang"target="_blank" rel="external nofollow noopener noreferrer">Yimeng Zhang</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Yihao%20Liang"target="_blank" rel="external nofollow noopener noreferrer">Yihao Liang</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Yuhang%20Zhou"target="_blank" rel="external nofollow noopener noreferrer">Yuhang Zhou</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Jiaqi%20Wang"target="_blank" rel="external nofollow noopener noreferrer">Jiaqi Wang</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Zhi%20Chen"target="_blank" rel="external nofollow noopener noreferrer">Zhi Chen</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Wanxiang%20Che"target="_blank" rel="external nofollow noopener noreferrer">Wanxiang Che</a></p>
<p>人工智能 （AI） 的最新进展，特别是在 OpenAI-o1 和 DeepSeek-R1 等大型语言模型 （LLM） 方面，在逻辑推理和实验编码等复杂领域展示了卓越的能力。在这些进步的推动下，许多研究探索了人工智能在创新过程中的应用，特别是在科学研究的背景下。这些 AI 技术的主要目的是开发能够在广泛的科学学科中自主进行研究过程的系统。尽管取得了这些重大进展，但仍然缺乏对人工智能研究 （AI4Research） 的全面调查，这阻碍了我们的理解并阻碍了该领域的进一步发展。为了解决这一差距，我们提出了一项全面的调查，并提供了关于 AI4Research 的统一观点。具体来说，我们工作的主要贡献如下：（1） 系统分类法：我们首先引入了系统分类法，对 AI4Research 中的五个主流任务进行分类。（2） 新前沿：然后，我们确定关键的研究差距并突出有希望的未来方向，重点关注自动化实验的严谨性和可扩展性，以及社会影响。（3） 丰富的应用程序和资源：最后，我们编译了丰富的资源，包括相关的多学科应用程序、数据语料库和工具。我们希望我们的工作能够为研究界提供快速访问这些资源的途径，并激发 AI4Research 的创新突破。</p>
<p><strong>科目</strong> :  <strong><a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></strong> , <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a></p>
<p><strong>发布</strong> ： 2025-07-02 17：19：20 UTC</p>
<ol start="2">
<li>2025-06-27 13:40:46 Friday ｜ 北大发布学术搜索评测ScholarSearch：难倒一众DeepResearch的“开卷考试” <a href="https://mp.weixin.qq.com/s/avGM6aB5aQcn6w5sKnZdKA"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/avGM6aB5aQcn6w5sKnZdKA</a></li>
</ol>
<p>OpenAI的Deep Research、Grok的DeepSearch、Gemini的Deep Research以及月之暗面的Kimi-Researcher等，以“深度搜索”功能为核心，为攻克高难度信息检索任务提供了新的范式。</p>
<ol start="3">
<li>2025-06-16 12:10:08 Monday ｜</li>
</ol>
<p>DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents
<strong>标题</strong> ： 深度研究平台：深度研究代理的全面基准
<strong>链接</strong> ：https://arxiv.org/abs/2506.11763</p>
<p><strong>作者</strong> ： Mingxuan Du,  Benfeng Xu,  Chiwei Zhu,  Xiaorui Wang,  Zhendong Mao
<strong>备注</strong> ：31 pages, 5 figures
<strong>摘要</strong> ：深度研究代理是基于LLM的代理的突出类别。通过自动编排多步骤的网络探索、目标检索和高阶综合，他们将大量的在线信息转化为分析师级的、引用丰富的报告&ndash;将数小时的手动桌面研究压缩为几分钟。然而，仍然没有一个全面的基准来系统地评价这些代理人的能力。为了弥合这一差距，我们提出了DeepResearch Bench，这是一个由100个博士级研究任务组成的基准，每个任务都由22个不同领域的领域专家精心制作。评估DRA本质上是复杂和劳动密集型的。因此，我们提出了两种新的方法，实现与人类判断的强烈一致。第一种是基于参考文献的方法，采用自适应标准来评估生成的研究报告的质量。另一个框架是通过评估其有效引用计数和整体引用准确性来评估图书馆的信息检索和收集能力。我们在https://github.com/Ayanami0730/deep_research_bench上拥有开源的DeepResearch Bench和这些框架的关键组件，以加速实用的基于法学硕士的代理的开发。</p>
<h4 id="季峰陈天桥联手agi首秀炸场最强开源深度研究模型gaia测试824分超openai"><a href="https://mp.weixin.qq.com/s/VHR2vxmuHlTc6H4xzTxH_A"target="_blank" rel="external nofollow noopener noreferrer">季峰陈天桥联手AGI首秀炸场！最强开源深度研究模型，GAIA测试82.4分超OpenAI</a></h4>
<ol>
<li>
<p>MiroMind ODR（Open Deep Research），来自代季峰加盟陈天桥的技术首秀。</p>
</li>
<li>
<p>它是真·全开源可复现，它的核心模型、数据、训练流程、AI Infra、DR Agent框架统统开源。</p>
</li>
<li>
<p>与现有的深度研究方法相比，MiroMind ODR项目开放了深度研究的各个阶段，包括四个子项目：MiroFlow（Agent框架）、MiroThinker（模型）、MiroVerse（数据）和MiroTrain（训练基础设施）。</p>
<ol>
<li><strong>MiroFlow</strong> ，支持多种主流工具调用，扩展大语言模型，支持工具辅助的深度研究推理。它的亮点在于可以稳定复现最强性能，也就是GAIA上82.4的成绩。</li>
<li><strong>MiroThinker</strong> ，原生支持工具辅助推理的大语言模型，可训练、可复现，在 GAIA 中表现最佳。</li>
<li><strong>MiroVerse</strong> ，147K开源训练数据支持深度研究训练。此外团队还会关注社区反馈，每月持续提供高质量、深入的研究数据集。</li>
<li><strong>MiroTrain</strong> ，支持深度研究模型的稳定高效训练，覆盖整个Deep Research训练流程，支持长文本训练和RL训练工具。</li>
</ol>
</li>
<li>
<p>MiroMind-M1是一系列基于Qwen-2.5 完全开源推理语言模型，专注于提升数学推理能力。</p>
<ol>
<li>该模型通过监督式微调（SFT）在 719K 个精心筛选的问题集上进行训练，并采用可验证奖励的强化学习（RLVR）在 62K 个具有挑战性的示例上进行优化，使用了基于上下文的多阶段策略优化方法（CAMPO）。</li>
</ol>
</li>
<li>
<p>Blog: <a href="https://miromind.ai/blog/miromind-open-deep-research"target="_blank" rel="external nofollow noopener noreferrer">https://miromind.ai/blog/miromind-open-deep-research</a>
Demo: <a href="https://dr.miromind.ai/"target="_blank" rel="external nofollow noopener noreferrer">https://dr.miromind.ai/</a>
GitHub: <a href="https://github.com/MiroMindAI"target="_blank" rel="external nofollow noopener noreferrer">https://github.com/MiroMindAI</a>
Hugging Face: <a href="https://huggingface.co/miromind-ai"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/miromind-ai</a></p>
</li>
</ol>
<h2 id="生物">生物</h2>
<ol>
<li>2025-06-27 13:42:36 Friday ｜ Deepmind突破性生物模型**AlphaGenome  **<a href="https://mp.weixin.qq.com/s/fhsKbgoPFuJ_2IInt_Q-tQ"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/fhsKbgoPFuJ_2IInt_Q-tQ</a></li>
</ol>
<p>谷歌DeepMind重磅发布AlphaGenome——一款革命性的AI工具，以及103页的详细技术报告。</p>
<p>论文地址：https://deepmind.google/discover/blog/alphagenome-ai-for-better-understanding-the-genome/</p>
<ol start="2">
<li>2025-07-02 15:21:56 Wednesday ｜ 诺奖得主Hassabis预言成真！AI零样本发现新抗体，轰动整个医药圈 <a href="https://mp.weixin.qq.com/s/yOd6_Qn6mlVqfRDkdS_eyw"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/yOd6_Qn6mlVqfRDkdS_eyw</a></li>
</ol>
<p>Chai-2的重磅发布，意味着：在今年年底，AI设计药物有望进入临床试验。</p>
<h4 id="蛋白质基座的gpt时代来了"><a href="https://mp.weixin.qq.com/s/WmGTYPO9gTm2XJ-Rjqvm-Q"target="_blank" rel="external nofollow noopener noreferrer">蛋白质基座的GPT时代来了？！</a></h4>
<ol>
<li>清华大学智能产业研究院（AIR）周浩副教授课题组联合上海人工智能实验室发布了 <strong>AMix-1</strong> ：首次以<strong>Scaling Law、Emergent Ability、In-Context Learning和Test-time Scaling的系统化方法论</strong>来构建蛋白质基座模型。</li>
<li>AMix-1是 <strong>基于贝叶斯流网络</strong> （Bayesian Flow Networks, BFNs）的蛋白质基座新范式，为蛋白质基座模型实现Test-time Scaling提供了一整套系统性的技术方案</li>
<li>技术报告：https://arxiv.org/pdf/2507.08920
项目主页：https://gensi-thuair.github.io/AMix-1/
模型权重：https://huggingface.co/GenSI/AMix-1-1.7B
代码仓库：https://github.com/GenSI-THUAIR/AMix-1</li>
<li>虚拟生物实验室：https://virtualbiolab.intern-ai.org.cn/</li>
</ol>
<h2 id="医疗">医疗</h2>
<ol>
<li>
<p><a href="https://mp.weixin.qq.com/s/YCfbNgiGGwzmUnrWSEY8zw"target="_blank" rel="external nofollow noopener noreferrer">让OpenAI只领先5天，百川发布推理新模型，掀翻医疗垂域开源天花板</a></p>
<ol>
<li>百川开源最新医疗推理大模型 <strong>Baichuan-M2-32B</strong> ，在OpenAI发布的Healthbench评测集上，超越其刚刚发布5天的开源模型gpt-oss-120b。</li>
<li>HealthBench是由OpenAI今年发布的一个医疗健康领域评估测试集，数据集中包含5000条多轮对话，模拟模型与个人用户或医疗专业人士之间的真实交流。这些对话跨越多语言、多背景（如急诊、临床数据解读、全球健康等）。
<ol>
<li>每段对话配有由262名医生（来自60个国家）撰写的具体评价准则，一共涉及48562条特点明确的标题标准（rubric criteria）。评分不仅涵盖医学准确性，还包括指令遵从、沟通能力等行为维度。</li>
</ol>
</li>
<li>创新性提出了 <strong>患者模拟器和Verifier系统</strong> 。核心基于一个大型的Verifier系统，能够从真实存在的医疗问题出发，进行端到端强化学习训练，能够在保持模型通用能力同时大幅提升医疗领域表现。</li>
<li>Blog：https://www.baichuan-ai.com/blog/baichuan-M2</li>
</ol>
</li>
</ol>
<h4 id="gpt-5超越人类医生推理能力比专家高出24理解力强29"><a href="https://mp.weixin.qq.com/s/gfM7kMxSt9Cs7Ark8gaOcA"target="_blank" rel="external nofollow noopener noreferrer">GPT-5超越人类医生！推理能力比专家高出24%，理解力强29%</a></h4>
<p>2025-08-15</p>
<ol>
<li>最新研究显示，GPT-5对医学影像的推理和理解准确率分别 <strong>比人类专家高出24.23%和29.40%</strong> 。</li>
<li><strong>USMLE是美国医师执照考试</strong> ，有标准化的命题和严格的评分体系，是全球医学教育和人才评估的重要参考基准。</li>
<li><strong>MedXpertQA测试</strong>是一个用于评估模型专家级医学知识与高级推理能力的综合基准，有文本测试和多模态测试，共涵盖4460道题目，涉及17个医学专科和11个身体系统，其数据源自超20个美国医师执照考试、欧洲放射学委员会考试等权威内容。</li>
<li><strong>VQA-RAD测试</strong>是医学视觉问答测试，该数据集包含315张放射影像以及与之对应的3515个问答对。常用于评估医学多模态大语言模型解读复杂医学图像并生成准确文本描述的能力。</li>
<li><em>论文地址：https://arxiv.org/abs/2508.08224</em></li>
</ol>
<h2 id="预测">预测</h2>
<ol start="10">
<li>2025-06-30 19:59:32 Monday ｜</li>
</ol>
<p><strong><a href="https://papers.cool/arxiv/2506.21558"target="_blank" rel="external nofollow noopener noreferrer">面向未来的基准：预测代理的 Pastcasting 基准</a></strong> <strong>[PDF()]</strong> <strong>[Copy]</strong> <strong>[Kimi()]</strong> <strong>[REL]</strong></p>
<p><strong>Authors</strong> : <a href="https://arxiv.org/search/?searchtype=author&amp;query=FutureSearch"target="_blank" rel="external nofollow noopener noreferrer">FutureSearch</a>: <a href="https://arxiv.org/search/?searchtype=author&amp;query=Jack%20Wildman"target="_blank" rel="external nofollow noopener noreferrer">Jack Wildman</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Nikos%20I.%20Bosse"target="_blank" rel="external nofollow noopener noreferrer">Nikos I. Bosse</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Daniel%20Hnyk"target="_blank" rel="external nofollow noopener noreferrer">Daniel Hnyk</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Peter%20M%C3%BChlbacher"target="_blank" rel="external nofollow noopener noreferrer">Peter Mühlbacher</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Finn%20Hambly"target="_blank" rel="external nofollow noopener noreferrer">Finn Hambly</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Jon%20Evans"target="_blank" rel="external nofollow noopener noreferrer">Jon Evans</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Dan%20Schwarz"target="_blank" rel="external nofollow noopener noreferrer">Dan Schwarz</a>, <a href="https://arxiv.org/search/?searchtype=author&amp;query=Lawrence%20Phillips"target="_blank" rel="external nofollow noopener noreferrer">Lawrence Phillips</a></p>
<p>预测是一项具有挑战性的任务，它为研究 AI 系统提供了一种明确可衡量的方法。预测需要在互联网上进行大量研究，而评估需要时间让事件发生，这使得预测基准的开发具有挑战性。迄今为止，还没有预测基准为 LLM 预测者提供真实、封闭和可重复的环境。我们介绍了 Bench To the Future （BTF），这是一个“pastcasting”基准测试，其中包含数百个高质量的问题，其解决方案已经已知。每个问题都伴随着一个包含数万个相关网页的大型离线语料库，从而能够从 LLM 中得出对过去事件的现实“预测”。结果表明，我们的过去广播环境可以产生与基于使用互联网对当时未解决的问题的预测的结果相当的结果。我们使用多个 LLM（包括最近发布的 Claude 4 模型）展示了对代理和思维链预测方法的结果，并展示了 BTF 随着时间的推移跟踪稳定预测能力进展的能力。我们打算将其作为一个活的基准，不断添加新问题，以解决不断增加的训练数据截止日期的问题。我们邀请研究人员通过 <a href="mailto:hello@futuresearch.ai">hello@futuresearch.ai</a> 与我们联系，以利用我们的基准测试或工具进行自己的研究。</p>
<p><strong>科目</strong> :  <strong><a href="https://papers.cool/arxiv/cs.CL"target="_blank" rel="external nofollow noopener noreferrer">计算和语言</a></strong> , <a href="https://papers.cool/arxiv/cs.AI"target="_blank" rel="external nofollow noopener noreferrer">人工智能</a>, <a href="https://papers.cool/arxiv/cs.LG"target="_blank" rel="external nofollow noopener noreferrer">机器学习</a></p>
<p><strong>发布</strong> ： 2025-06-11 16：18：40 UTC</p>
</div></article></main><footer class="footer">
    <div class="footer-container"><div class="footer-line copyright" itemscope itemtype="http://schema.org/CreativeWork"><i class="fa-regular fa-copyright fa-fw" aria-hidden="true"></i>
            <span itemprop="copyrightYear">Public - 2025</span><span class="author" itemprop="copyrightHolder">
              <a href="/LLMDailyDigestWeb/"></a></span></div><div class="footer-line statistics"></div></div>
  </footer></div><div class="widgets"><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role="button" aria-label="Back to Top"><i class="fa-solid fa-arrow-up fa-fw" aria-hidden="true"></i><span class="variant-numeric d-none">0%</span>
        </div></div><div id="mask"></div><noscript>
    <div class="noscript-warning">Theme FixIt works best with JavaScript enabled.</div>
  </noscript>
</div><link rel="preload" href="/LLMDailyDigestWeb/lib/katex/katex.min.css" as="style" onload="this.removeAttribute('onload');this.rel='stylesheet'">
    <noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/katex/katex.min.css"></noscript><link rel="stylesheet" href="/LLMDailyDigestWeb/lib/cookieconsent/cookieconsent.min.css"><script src="/LLMDailyDigestWeb/lib/sharer/sharer.min.js" async defer></script><script src="/LLMDailyDigestWeb/lib/typeit/index.umd.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/katex.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/auto-render.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/copy-tex.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/katex/mhchem.min.js" defer></script><script src="/LLMDailyDigestWeb/lib/cookieconsent/cookieconsent.min.js" defer></script><script>window.config={"code":{"copyTitle":"Copy to clipboard","editLockTitle":"Lock editable code block","editUnLockTitle":"Unlock editable code block","editable":true,"maxShownLines":10},"comment":{"enable":false},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"data":{"typeit-header-desktop":"LLM-DailyDigest 大模型研究日报","typeit-header-title-mobile":"LLM-DailyDigest 大模型研究日报"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":true,"left":"\\begin{equation}","right":"\\end{equation}"},{"display":true,"left":"\\begin{equation*}","right":"\\end{equation*}"},{"display":true,"left":"\\begin{align}","right":"\\end{align}"},{"display":true,"left":"\\begin{align*}","right":"\\end{align*}"},{"display":true,"left":"\\begin{alignat}","right":"\\end{alignat}"},{"display":true,"left":"\\begin{alignat*}","right":"\\end{alignat*}"},{"display":true,"left":"\\begin{gather}","right":"\\end{gather}"},{"display":true,"left":"\\begin{CD}","right":"\\end{CD}"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"typeit":{"cursorChar":"|","cursorSpeed":1000,"data":{"typeit-header-desktop":["typeit-header-desktop"],"typeit-header-title-mobile":["typeit-header-title-mobile"]},"duration":-1,"loop":false,"speed":100}};</script><script src="/LLMDailyDigestWeb/js/theme.min.js" defer></script></body>
</html>
