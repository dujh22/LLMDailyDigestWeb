Paper ID,Title,URL,Summary,First Author,Publish Date,Update Date,Code URL,Stars
2410.18980v1,Very massive stars and Nitrogen-emitting galaxies,http://arxiv.org/abs/2410.18980v1,"Recent studies of high-redshift galaxies using JWST, such as GN-z11 revealedhighly elevated levels of nitrogen (N). This phenomenon extends togravitationally-lensed galaxies like the Sunburst Arc at z = 2.37, as well asto globular clusters (GCs). We propose that this originates from the presenceof very massive stars (VMSs) with masses ranging from 100 to 1000\,\Msun. TheHe {\sc ii} observed in the Sunburst Arc could also stem from thedisproportionately large contribution of VMSs. We build an entirely newFramework for massive star evolution which is no longer set by Dutch or othermass-loss ""recipes"" but which take the physics of $\Gamma$ or $L/M$-dependentwinds into account. We discuss the mass-loss kink and the transition mass-lossrate between optically thin and thick winds, before we study the evaporativemass-loss history of VMSs. Our novel evolution models exhibit verticalevolution in the HR-diagram from the zero-age main sequence due to aself-regulatory effect driven by their wind-dominated nature, and we discusswhat wind physics sets the stellar upper-mass limit. Our estimate for theSunburst Arc in Vink (2023) suggests that the significant amounts of N found instar-forming galaxies likely arise from VMSs. We evaluate the strengths andweaknesses of previous hypotheses, including fast rotating massive stars andsupermassive stars (SMSs), and we conclude that only our VMS model satisfiesthe relevant criteria. Finally, we advocate for the inclusion of VMSs inpopulation synthesis and chemical evolution models, emphasizing the need for aself-consistent wind approach, which currently does not exist. Even minorinaccuracies in mass-loss rates dramatically impact the stellar evolution ofVMS, as well as their ionizing and chemical feedback.",Jorick S. Vink,2024-10-24,2024-10-24,,N/A
2410.18979v1,PixelGaussian: Generalizable 3D Gaussian Reconstruction from Arbitrary Views,http://arxiv.org/abs/2410.18979v1,"We propose PixelGaussian, an efficient feed-forward framework for learninggeneralizable 3D Gaussian reconstruction from arbitrary views. Most existingmethods rely on uniform pixel-wise Gaussian representations, which learn afixed number of 3D Gaussians for each view and cannot generalize well to moreinput views. Differently, our PixelGaussian dynamically adapts both theGaussian distribution and quantity based on geometric complexity, leading tomore efficient representations and significant improvements in reconstructionquality. Specifically, we introduce a Cascade Gaussian Adapter to adjustGaussian distribution according to local geometry complexity identified by akeypoint scorer. CGA leverages deformable attention in context-awarehypernetworks to guide Gaussian pruning and splitting, ensuring accuraterepresentation in complex regions while reducing redundancy. Furthermore, wedesign a transformer-based Iterative Gaussian Refiner module that refinesGaussian representations through direct image-Gaussian interactions. OurPixelGaussian can effectively reduce Gaussian redundancy as input viewsincrease. We conduct extensive experiments on the large-scale ACID andRealEstate10K datasets, where our method achieves state-of-the-art performancewith good generalization to various numbers of views. Code:https://github.com/Barrybarry-Smith/PixelGaussian.",Xin Fei,2024-10-24,2024-10-24,https://github.com/barrybarry-smith/pixelgaussian,0
2410.18978v1,Framer: Interactive Frame Interpolation,http://arxiv.org/abs/2410.18978v1,"We propose Framer for interactive frame interpolation, which targetsproducing smoothly transitioning frames between two images as per usercreativity. Concretely, besides taking the start and end frames as inputs, ourapproach supports customizing the transition process by tailoring thetrajectory of some selected keypoints. Such a design enjoys two clear benefits.First, incorporating human interaction mitigates the issue arising fromnumerous possibilities of transforming one image to another, and in turnenables finer control of local motions. Second, as the most basic form ofinteraction, keypoints help establish the correspondence across frames,enhancing the model to handle challenging cases (e.g., objects on the start andend frames are of different shapes and styles). It is noteworthy that oursystem also offers an ""autopilot"" mode, where we introduce a module to estimatethe keypoints and refine the trajectory automatically, to simplify the usage inpractice. Extensive experimental results demonstrate the appealing performanceof Framer on various applications, such as image morphing, time-lapse videogeneration, cartoon interpolation, etc. The code, the model, and the interfacewill be released to facilitate further research.",Wen Wang,2024-10-24,2024-10-24,,N/A
2410.18977v1,MotionCLR: Motion Generation and Training-free Editing via Understanding Attention Mechanisms,http://arxiv.org/abs/2410.18977v1,"This research delves into the problem of interactive editing of human motiongeneration. Previous motion diffusion models lack explicit modeling of theword-level text-motion correspondence and good explainability, hencerestricting their fine-grained editing ability. To address this issue, wepropose an attention-based motion diffusion model, namely MotionCLR, with CLeaRmodeling of attention mechanisms. Technically, MotionCLR models the in-modalityand cross-modality interactions with self-attention and cross-attention,respectively. More specifically, the self-attention mechanism aims to measurethe sequential similarity between frames and impacts the order of motionfeatures. By contrast, the cross-attention mechanism works to find thefine-grained word-sequence correspondence and activate the correspondingtimesteps in the motion sequence. Based on these key properties, we develop aversatile set of simple yet effective motion editing methods via manipulatingattention maps, such as motion (de-)emphasizing, in-place motion replacement,and example-based motion generation, etc. For further verification of theexplainability of the attention mechanism, we additionally explore thepotential of action-counting and grounded motion generation ability viaattention maps. Our experimental results show that our method enjoys goodgeneration and editing ability with good explainability.",Ling-Hao Chen,2024-10-24,2024-10-24,,N/A
2410.18976v1,CAMEL-Bench: A Comprehensive Arabic LMM Benchmark,http://arxiv.org/abs/2410.18976v1,"Recent years have witnessed a significant interest in developing largemultimodal models (LMMs) capable of performing various visual reasoning andunderstanding tasks. This has led to the introduction of multiple LMMbenchmarks to evaluate LMMs on different tasks. However, most existing LMMevaluation benchmarks are predominantly English-centric. In this work, wedevelop a comprehensive LMM evaluation benchmark for the Arabic language torepresent a large population of over 400 million speakers. The proposedbenchmark, named CAMEL-Bench, comprises eight diverse domains and 38sub-domains including, multi-image understanding, complex visual perception,handwritten document understanding, video understanding, medical imaging, plantdiseases, and remote sensing-based land use understanding to evaluate broadscenario generalizability. Our CAMEL-Bench comprises around 29,036 questionsthat are filtered from a larger pool of samples, where the quality is manuallyverified by native speakers to ensure reliable model assessment. We conductevaluations of both closed-source, including GPT-4 series, and open-sourceLMMs. Our analysis reveals the need for substantial improvement, especiallyamong the best open-source models, with even the closed-source GPT-4o achievingan overall score of 62%. Our benchmark and evaluation scripts are open-sourced.",Sara Ghaboura,2024-10-24,2024-10-24,,N/A
2410.18975v1,Unbounded: A Generative Infinite Game of Character Life Simulation,http://arxiv.org/abs/2410.18975v1,"We introduce the concept of a generative infinite game, a video game thattranscends the traditional boundaries of finite, hard-coded systems by usinggenerative models. Inspired by James P. Carse's distinction between finite andinfinite games, we leverage recent advances in generative AI to createUnbounded: a game of character life simulation that is fully encapsulated ingenerative models. Specifically, Unbounded draws inspiration from sandbox lifesimulations and allows you to interact with your autonomous virtual characterin a virtual world by feeding, playing with and guiding it - with open-endedmechanics generated by an LLM, some of which can be emergent. In order todevelop Unbounded, we propose technical innovations in both the LLM and visualgeneration domains. Specifically, we present: (1) a specialized, distilledlarge language model (LLM) that dynamically generates game mechanics,narratives, and character interactions in real-time, and (2) a new dynamicregional image prompt Adapter (IP-Adapter) for vision models that ensuresconsistent yet flexible visual generation of a character across multipleenvironments. We evaluate our system through both qualitative and quantitativeanalysis, showing significant improvements in character life simulation, userinstruction following, narrative coherence, and visual consistency for bothcharacters and the environments compared to traditional related approaches.",Jialu Li,2024-10-24,2024-10-24,,N/A
2410.18974v1,3D-Adapter: Geometry-Consistent Multi-View Diffusion for High-Quality 3D Generation,http://arxiv.org/abs/2410.18974v1,"Multi-view image diffusion models have significantly advanced open-domain 3Dobject generation. However, most existing models rely on 2D networkarchitectures that lack inherent 3D biases, resulting in compromised geometricconsistency. To address this challenge, we introduce 3D-Adapter, a plug-inmodule designed to infuse 3D geometry awareness into pretrained image diffusionmodels. Central to our approach is the idea of 3D feedback augmentation: foreach denoising step in the sampling loop, 3D-Adapter decodes intermediatemulti-view features into a coherent 3D representation, then re-encodes therendered RGBD views to augment the pretrained base model through featureaddition. We study two variants of 3D-Adapter: a fast feed-forward versionbased on Gaussian splatting and a versatile training-free version utilizingneural fields and meshes. Our extensive experiments demonstrate that 3D-Adapternot only greatly enhances the geometry quality of text-to-multi-view modelssuch as Instant3D and Zero123++, but also enables high-quality 3D generationusing the plain text-to-image Stable Diffusion. Furthermore, we showcase thebroad application potential of 3D-Adapter by presenting high quality results intext-to-3D, image-to-3D, text-to-texture, and text-to-avatar tasks.",Hansheng Chen,2024-10-24,2024-10-24,https://github.com/Lakonik/MVEdit,235
2410.18972v1,Deep Insights into Cognitive Decline: A Survey of Leveraging Non-Intrusive Modalities with Deep Learning Techniques,http://arxiv.org/abs/2410.18972v1,"Cognitive decline is a natural part of aging, often resulting in reducedcognitive abilities. In some cases, however, this decline is more pronounced,typically due to disorders such as Alzheimer's disease. Early detection ofanomalous cognitive decline is crucial, as it can facilitate timelyprofessional intervention. While medical data can help in this detection, itoften involves invasive procedures. An alternative approach is to employnon-intrusive techniques such as speech or handwriting analysis, which do notnecessarily affect daily activities. This survey reviews the most relevantmethodologies that use deep learning techniques to automate the cognitivedecline estimation task, including audio, text, and visual processing. Wediscuss the key features and advantages of each modality and methodology,including state-of-the-art approaches like Transformer architecture andfoundation models. In addition, we present works that integrate differentmodalities to develop multimodal models. We also highlight the most significantdatasets and the quantitative results from studies using these resources. Fromthis review, several conclusions emerge. In most cases, the textual modalityachieves the best results and is the most relevant for detecting cognitivedecline. Moreover, combining various approaches from individual modalities intoa multimodal model consistently enhances performance across nearly allscenarios.",David Ortiz-Perez,2024-10-24,2024-10-24,,N/A
2410.18970v1,ConceptDrift: Uncovering Biases through the Lens of Foundational Models,http://arxiv.org/abs/2410.18970v1,"Datasets and pre-trained models come with intrinsic biases. Most methods relyon spotting them by analysing misclassified samples, in a semi-automatedhuman-computer validation. In contrast, we propose ConceptDrift, a method whichanalyzes the weights of a linear probe, learned on top a foundational model. Wecapitalize on the weight update trajectory, which starts from the embedding ofthe textual representation of the class, and proceeds to drift towardsembeddings that disclose hidden biases. Different from prior work, with thisapproach we can pin-point unwanted correlations from a dataset, providing morethan just possible explanations for the wrong predictions. We empirically provethe efficacy of our method, by significantly improving zero-shot performancewith biased-augmented prompting. Our method is not bounded to a singlemodality, and we experiment in this work with both image (Waterbirds, CelebA,Nico++) and text datasets (CivilComments).",Cristian Daniel PÄƒduraru,2024-10-24,2024-10-24,,N/A
2410.18968v1,Stimulated Emission of Dark Matter via Thermal Scattering: Novel Limits for Freeze-In and eV Cold Dark Matter,http://arxiv.org/abs/2410.18968v1,"Recently, one of the present authors noticed a stimulated emission process ofbosonic dark matter via the two-body decay of a mother particle in a thermalplasma similar to the operation principle of a laser in 2301.08735. In thispaper, we show that in a $2 \to 2$ process, including a bosonic final particle(e.g., an axion or dark photon), the stimulated emission occurs as well due toa small angle scattering of the thermal mother particles and thus thephenomenon is more universal. Two important conclusions follow: (1) Care mustbe taken when studying the freeze-in production of a bosonic dark matter, asthe abundance and momentum distribution of dark matter can differ significantlydue to this effect. (2) eV-mass-range bosonic dark matter is special andtheoretically well-motivated because models for freeze-in or other thermalproduction of dark matter include the parameter region of cold eV dark matter.We also study the dark matter mass effect for the stimulated emission.",Kodai Sakurai,2024-10-24,2024-10-24,,N/A
2410.18967v1,Ferret-UI 2: Mastering Universal User Interface Understanding Across Platforms,http://arxiv.org/abs/2410.18967v1,"Building a generalist model for user interface (UI) understanding ischallenging due to various foundational issues, such as platform diversity,resolution variation, and data limitation. In this paper, we introduceFerret-UI 2, a multimodal large language model (MLLM) designed for universal UIunderstanding across a wide range of platforms, including iPhone, Android,iPad, Webpage, and AppleTV. Building on the foundation of Ferret-UI, Ferret-UI2 introduces three key innovations: support for multiple platform types,high-resolution perception through adaptive scaling, and advanced task trainingdata generation powered by GPT-4o with set-of-mark visual prompting. Theseadvancements enable Ferret-UI 2 to perform complex, user-centered interactions,making it highly versatile and adaptable for the expanding diversity ofplatform ecosystems. Extensive empirical experiments on referring, grounding,user-centric advanced tasks (comprising 9 subtasks $\times$ 5 platforms), GUIDEnext-action prediction dataset, and GUI-World multi-platform benchmarkdemonstrate that Ferret-UI 2 significantly outperforms Ferret-UI, and alsoshows strong cross-platform transfer capabilities.",Zhangheng Li,2024-10-24,2024-10-24,,N/A
2410.18966v1,Does Data Contamination Detection Work (Well) for LLMs? A Survey and Evaluation on Detection Assumptions,http://arxiv.org/abs/2410.18966v1,"Large language models (LLMs) have demonstrated great performance acrossvarious benchmarks, showing potential as general-purpose task solvers. However,as LLMs are typically trained on vast amounts of data, a significant concern intheir evaluation is data contamination, where overlap between training data andevaluation datasets inflates performance assessments. While multiple approacheshave been developed to identify data contamination, these approaches rely onspecific assumptions that may not hold universally across different settings.To bridge this gap, we systematically review 47 papers on data contaminationdetection, categorize the underlying assumptions, and assess whether they havebeen rigorously validated. We identify and analyze eight categories ofassumptions and test three of them as case studies. Our analysis reveals thatwhen classifying instances used for pretraining LLMs, detection approachesbased on these three assumptions perform close to random guessing, suggestingthat current LLMs learn data distributions rather than memorizing individualinstances. Overall, this work underscores the importance of approaches clearlystating their underlying assumptions and testing their validity across variousscenarios.",Yujuan Fu,2024-10-24,2024-10-24,,N/A
2410.18965v1,On the Crucial Role of Initialization for Matrix Factorization,http://arxiv.org/abs/2410.18965v1,"This work revisits the classical low-rank matrix factorization problem andunveils the critical role of initialization in shaping convergence rates forsuch nonconvex and nonsmooth optimization. We introduce Nystrom initialization,which significantly improves the global convergence of Scaled Gradient Descent(ScaledGD) in both symmetric and asymmetric matrix factorization tasks.Specifically, we prove that ScaledGD with Nystrom initialization achievesquadratic convergence in cases where only linear rates were previously known.Furthermore, we extend this initialization to low-rank adapters (LoRA) commonlyused for finetuning foundation models. Our approach, NoRA, i.e., LoRA withNystrom initialization, demonstrates superior performance across variousdownstream tasks and model scales, from 1B to 7B parameters, in large languageand diffusion models.",Bingcong Li,2024-10-24,2024-10-24,,N/A
2410.18963v1,OSCAR: Operating System Control via State-Aware Reasoning and Re-Planning,http://arxiv.org/abs/2410.18963v1,"Large language models (LLMs) and large multimodal models (LMMs) have showngreat potential in automating complex tasks like web browsing and gaming.However, their ability to generalize across diverse applications remainslimited, hindering broader utility. To address this challenge, we presentOSCAR: Operating System Control via state-Aware reasoning and Re-planning.OSCAR is a generalist agent designed to autonomously navigate and interact withvarious desktop and mobile applications through standardized controls, such asmouse and keyboard inputs, while processing screen images to fulfill usercommands. OSCAR translates human instructions into executable Python code,enabling precise control over graphical user interfaces (GUIs). To enhancestability and adaptability, OSCAR operates as a state machine, equipped witherror-handling mechanisms and dynamic task re-planning, allowing it toefficiently adjust to real-time feedback and exceptions. We demonstrate OSCAR'seffectiveness through extensive experiments on diverse benchmarks acrossdesktop and mobile platforms, where it transforms complex workflows into simplenatural language commands, significantly boosting user productivity. Our codewill be open-source upon publication.",Xiaoqiang Wang,2024-10-24,2024-10-24,,N/A
2410.18962v1,Where Am I and What Will I See: An Auto-Regressive Model for Spatial Localization and View Prediction,http://arxiv.org/abs/2410.18962v1,"Spatial intelligence is the ability of a machine to perceive, reason, and actin three dimensions within space and time. Recent advancements in large-scaleauto-regressive models have demonstrated remarkable capabilities across variousreasoning tasks. However, these models often struggle with fundamental aspectsof spatial reasoning, particularly in answering questions like ""Where am I?""and ""What will I see?"". While some attempts have been done, existing approachestypically treat them as separate tasks, failing to capture their interconnectednature. In this paper, we present Generative Spatial Transformer (GST), a novelauto-regressive framework that jointly addresses spatial localization and viewprediction. Our model simultaneously estimates the camera pose from a singleimage and predicts the view from a new camera pose, effectively bridging thegap between spatial awareness and visual prediction. The proposed innovativecamera tokenization method enables the model to learn the joint distribution of2D projections and their corresponding spatial perspectives in anauto-regressive manner. This unified training paradigm demonstrates that jointoptimization of pose estimation and novel view synthesis leads to improvedperformance in both tasks, for the first time, highlighting the inherentrelationship between spatial awareness and visual prediction.",Junyi Chen,2024-10-24,2024-10-24,,N/A
2410.18959v1,Context is Key: A Benchmark for Forecasting with Essential Textual Information,http://arxiv.org/abs/2410.18959v1,"Forecasting is a critical task in decision making across various domains.While numerical data provides a foundation, it often lacks crucial contextnecessary for accurate predictions. Human forecasters frequently rely onadditional information, such as background knowledge or constraints, which canbe efficiently communicated through natural language. However, the ability ofexisting forecasting models to effectively integrate this textual informationremains an open question. To address this, we introduce ""Context is Key"" (CiK),a time series forecasting benchmark that pairs numerical data with diversetypes of carefully crafted textual context, requiring models to integrate bothmodalities. We evaluate a range of approaches, including statistical models,time series foundation models, and LLM-based forecasters, and propose a simpleyet effective LLM prompting method that outperforms all other tested methods onour benchmark. Our experiments highlight the importance of incorporatingcontextual information, demonstrate surprising performance when using LLM-basedforecasting models, and also reveal some of their critical shortcomings. Bypresenting this benchmark, we aim to advance multimodal forecasting, promotingmodels that are both accurate and accessible to decision-makers with variedtechnical expertise. The benchmark can be visualized athttps://servicenow.github.io/context-is-key-forecasting/v0/ .",Andrew Robert Williams,2024-10-24,2024-10-24,https://github.com/servicenow/context-is-key-forecasting,0
2410.18958v1,Stable Consistency Tuning: Understanding and Improving Consistency Models,http://arxiv.org/abs/2410.18958v1,"Diffusion models achieve superior generation quality but suffer from slowgeneration speed due to the iterative nature of denoising. In contrast,consistency models, a new generative family, achieve competitive performancewith significantly faster sampling. These models are trained either throughconsistency distillation, which leverages pretrained diffusion models, orconsistency training/tuning directly from raw data. In this work, we propose anovel framework for understanding consistency models by modeling the denoisingprocess of the diffusion model as a Markov Decision Process (MDP) and framingconsistency model training as the value estimation through TemporalDifference~(TD) Learning. More importantly, this framework allows us to analyzethe limitations of current consistency training/tuning strategies. Built uponEasy Consistency Tuning (ECT), we propose Stable Consistency Tuning (SCT),which incorporates variance-reduced learning using the score identity. SCTleads to significant performance improvements on benchmarks such as CIFAR-10and ImageNet-64. On ImageNet-64, SCT achieves 1-step FID 2.42 and 2-step FID1.55, a new SoTA for consistency models.",Fu-Yun Wang,2024-10-24,2024-10-24,https://github.com/G-U-N/Stable-Consistency-Tuning,8
2410.18957v1,Bridge-Coder: Unlocking LLMs' Potential to Overcome Language Gaps in Low-Resource Code,http://arxiv.org/abs/2410.18957v1,"Large Language Models (LLMs) demonstrate strong proficiency in generatingcode for high-resource programming languages (HRPLs) like Python but strugglesignificantly with low-resource programming languages (LRPLs) such as Racket orD. This performance gap deepens the digital divide, preventing developers usingLRPLs from benefiting equally from LLM advancements and reinforcing disparitiesin innovation within underrepresented programming communities. While generatingadditional training data for LRPLs is promising, it faces two key challenges:manual annotation is labor-intensive and costly, and LLM-generated LRPL code isoften of subpar quality. The underlying cause of this issue is the gap betweennatural language to programming language gap (NL-PL Gap), which is especiallypronounced in LRPLs due to limited aligned data. In this work, we introduce anovel approach called Bridge-Coder, which leverages LLMs' intrinsiccapabilities to enhance the performance on LRPLs. Our method consists of twokey stages. Bridge Generation, where we create high-quality dataset byutilizing LLMs' general knowledge understanding, proficiency in HRPLs, andin-context learning abilities. Then, we apply the Bridged Alignment, whichprogressively improves the alignment between NL instructions and LRPLs.Experimental results across multiple LRPLs show that Bridge-Coder significantlyenhances model performance, demonstrating the effectiveness and generalizationof our approach. Furthermore, we offer a detailed analysis of the keycomponents of our method, providing valuable insights for future work aimed ataddressing the challenges associated with LRPLs.",Jipeng Zhang,2024-10-24,2024-10-24,,N/A
2410.18956v1,Large Spatial Model: End-to-end Unposed Images to Semantic 3D,http://arxiv.org/abs/2410.18956v1,"Reconstructing and understanding 3D structures from a limited number ofimages is a well-established problem in computer vision. Traditional methodsusually break this task into multiple subtasks, each requiring complextransformations between different data representations. For instance, densereconstruction through Structure-from-Motion (SfM) involves converting imagesinto key points, optimizing camera parameters, and estimating structures.Afterward, accurate sparse reconstructions are required for further densemodeling, which is subsequently fed into task-specific neural networks. Thismulti-step process results in considerable processing time and increasedengineering complexity.  In this work, we present the Large Spatial Model (LSM), which processesunposed RGB images directly into semantic radiance fields. LSM simultaneouslyestimates geometry, appearance, and semantics in a single feed-forwardoperation, and it can generate versatile label maps by interacting withlanguage at novel viewpoints. Leveraging a Transformer-based architecture, LSMintegrates global geometry through pixel-aligned point maps. To enhance spatialattribute regression, we incorporate local context aggregation with multi-scalefusion, improving the accuracy of fine local details. To tackle the scarcity oflabeled 3D semantic data and enable natural language-driven scene manipulation,we incorporate a pre-trained 2D language-based segmentation model into a3D-consistent semantic feature field. An efficient decoder then parameterizes aset of semantic anisotropic Gaussians, facilitating supervised end-to-endlearning. Extensive experiments across various tasks show that LSM unifiesmultiple 3D vision tasks directly from unposed images, achieving real-timesemantic 3D reconstruction for the first time.",Zhiwen Fan,2024-10-24,2024-10-24,,N/A
2410.18955v1,BioMistral-NLU: Towards More Generalizable Medical Language Understanding through Instruction Tuning,http://arxiv.org/abs/2410.18955v1,"Large language models (LLMs) such as ChatGPT are fine-tuned on large anddiverse instruction-following corpora, and can generalize to new tasks.However, those instruction-tuned LLMs often perform poorly in specializedmedical natural language understanding (NLU) tasks that require domainknowledge, granular text comprehension, and structured data extraction. Tobridge the gap, we: (1) propose a unified prompting format for 7 important NLUtasks, % through span extraction and multi-choice question-answering (QA), (2)curate an instruction-tuning dataset, MNLU-Instruct, utilizing diverse existingopen-source medical NLU corpora, and (3) develop BioMistral-NLU, ageneralizable medical NLU model, through fine-tuning BioMistral onMNLU-Instruct. We evaluate BioMistral-NLU in a zero-shot setting, across 6important NLU tasks, from two widely adopted medical NLU benchmarks: BiomedicalLanguage Understanding Evaluation (BLUE) and Biomedical Language Understandingand Reasoning Benchmark (BLURB). Our experiments show that our BioMistral-NLUoutperforms the original BioMistral, as well as the proprietary LLMs - ChatGPTand GPT-4. Our dataset-agnostic prompting strategy and instruction tuning stepover diverse NLU tasks enhance LLMs' generalizability across diverse medicalNLU tasks. Our ablation experiments show that instruction-tuning on a widervariety of tasks, even when the total number of training instances remainsconstant, enhances downstream zero-shot generalization.",Yujuan Velvin Fu,2024-10-24,2024-10-24,,N/A
2410.18954v1,Learning Structured Compressed Sensing with Automatic Resource Allocation,http://arxiv.org/abs/2410.18954v1,"Multidimensional data acquisition often requires extensive time and posessignificant challenges for hardware and software regarding data storage andprocessing. Rather than designing a single compression matrix as inconventional compressed sensing, structured compressed sensing yieldsdimension-specific compression matrices, reducing the number of optimizableparameters. Recent advances in machine learning (ML) have enabled task-basedsupervised learning of subsampling matrices, albeit at the expense of complexdownstream models. Additionally, the sampling resource allocation acrossdimensions is often determined in advance through heuristics. To address thesechallenges, we introduce Structured COmpressed Sensing with Automatic ResourceAllocation (SCOSARA) with an information theory-based unsupervised learningstrategy. SCOSARA adaptively distributes samples across sampling dimensionswhile maximizing Fisher information content. Using ultrasound localization as acase study, we compare SCOSARA to state-of-the-art ML-based and greedy searchalgorithms. Simulation results demonstrate that SCOSARA can producehigh-quality subsampling matrices that achieve lower Cram\'er-Rao Bound valuesthan the baselines. In addition, SCOSARA outperforms other ML-based algorithmsin terms of the number of trainable parameters, computational complexity, andmemory requirements while automatically choosing the number of samples peraxis.",Han Wang,2024-10-24,2024-10-24,,N/A
2410.18952v1,Dynamic Vocabulary Pruning in Early-Exit LLMs,http://arxiv.org/abs/2410.18952v1,"Increasing the size of large language models (LLMs) has been shown to lead tobetter performance. However, this comes at the cost of slower and moreexpensive inference. Early-exiting is a promising approach for improving theefficiency of LLM inference by enabling next token prediction at intermediatelayers. Yet, the large vocabulary size in modern LLMs makes the confidenceestimation required for exit decisions computationally expensive, diminishingthe efficiency gains. To address this, we propose dynamically pruning thevocabulary at test time for each token. Specifically, the vocabulary is prunedat one of the initial layers, and the smaller vocabulary is then usedthroughout the rest of the forward pass. Our experiments demonstrate that suchpost-hoc dynamic vocabulary pruning improves the efficiency of confidenceestimation in early-exit LLMs while maintaining competitive performance.",Jort Vincenti,2024-10-24,2024-10-24,https://github.com/matteonulli/vocabulary_pruning,0
2410.18951v1,Initial PIP-II Beam Current Monitor Fault Case Analyses & Beam Position Monitor Linearity Studies in CST Studio Suite,http://arxiv.org/abs/2410.18951v1,"The use of non-invasive sensors & systems to measure particle beamcharacteristics is a crucial part of modern accelerator control systems due totheir ability to return real time passive measurements without impacting thebeam quality. Simulations, which can predict these sensors' behaviour andperformance under anticipated accelerator conditions, are valuable tools toensure confidence in the sensors' functionality prior to a physical bench test.This paper details the design, testing, and results of two sensor modelsdeveloped using CST Studio Suite software. One model is an elliptical,large-aperture beam position monitor (BPM) for which vertical & horizontalposition signal linearity was analyzed. The second model is an AC currenttransformer (ACCT) beam current monitor (BCM), which was used to search forpotential fault cases within the BCM and beam pipe flange gaps. Fermilab ProtonImprovement Plan II (PIP-II) accelerator beam conditions were applied, andspecial focus is given to the discovery of linearity variations within the BPMas well as the use of frequency domain techniques in the BCM fault caseanalyses.",A. Rouzky,2024-10-24,2024-10-24,,N/A
2410.18949v1,Lattice Approximations to NLS,http://arxiv.org/abs/2410.18949v1,"In this paper, we prove that solutions of the discrete NLS lattice model for$L^2$ initial data with double frequency components converge to solutions of acoupled system of cubic NLS.",Zhimeng Ouyang,2024-10-24,2024-10-24,,N/A
2410.18948v1,"Gravothermalizing into primordial black holes, boson stars, and cannibal stars",http://arxiv.org/abs/2410.18948v1,"Very little is known about the cosmological history from after the end ofinflation until Big Bang Nucleosynthesis. Various well-motivated models predictthat the universe could have undergone a period of matter domination in thisearly epoch. We demonstrate that if the particles causing matter dominationhave self-interactions, they can form halos that undergo a gravothermalcollapse. This scenario, in principle, provides a novel way to produceprimordial black holes within the mass range of $1$ to $10^{26}$ g. We alsofind that it is not only black holes that can form in the aftermath of agravothermal evolution. In particular, we show that number-changingannihilations of the particles can create sufficient heat to halt thegravothermal evolution, thus forming a ""cannibal star"". Likewise, the pressurefrom the particle's repulsive self-interactions can form a boson star during agravothermal evolution. Thus, our study highlights that structure formation inthe early universe can have a rich complexity.",Pranjal Ralegankar,2024-10-24,2024-10-24,,N/A
2410.18946v1,A geometric characterization of steady laminar flow,http://arxiv.org/abs/2410.18946v1,"We study the steady states of the Euler equations on the periodic channel orannulus. We show that if these flows are laminar (layered by closednon-contractible streamlines which foliate the domain), then they must beeither parallel or circular flows. We also show that a large subset of theseshear flows are isolated from non-shear stationary states. For Poiseuille flow,$(v(y),0)=(y^2,0)$, our result shows that all stationary solutions in asufficiently small $C^2$ neighborhood are shear flows. We then show that if$v(y)=y^n$ with $n \geq 1$, then in any $C^{n-}$ neighborhood, there existsmooth non-shear steady states, traveling waves, and quasiperiodic solutions ofany number of non-commensurate frequencies. This proves the rigidity nearPoiseuille is sharp. Finally, we prove that on general compact doubly connecteddomains, laminar steady Euler flows with constant velocity on the boundary mustalso be either parallel or circular, and the domain a periodic channel or anannulus. This shows that laminar free boundary Euler solutions must haveEuclidean symmetry.",Theodore D. Drivas,2024-10-24,2024-10-24,,N/A
2410.18945v1,Mosqlimate: a platform to providing automatable access to data and forecasting models for arbovirus disease,http://arxiv.org/abs/2410.18945v1,"Dengue is a climate-sensitive mosquito-borne disease with a complextransmission dynamic. Data related to climate, environmental andsociodemographic characteristics of the target population are important forproject scenarios. Different datasets and methodologies have been applied tobuild complex models for dengue forecast, stressing the need to evaluate thesemodels and their relative accuracy grounded on a reproducible methodology. Thegoal of this work is to describe and present Mosqlimate, a web-based platformcomposed by a dashboard, a data store, model and rediction registries andsupport for a community of practice in arbovirus forecasting. Multiple APIendpoints give access to data for development, open registration of predictivemodels from different approaches and sharing of predictive models forarboviruses incidence, facilitating interaction between modellers and allowingfor proper comparison of the performance of different registered models, bymeans of probabilistic scores. Epidemiological, entomological, climatic andsociodemographic datasets related to arboviruses in Brazil, are freelyavailable for download, alongside full documentation.",Fabiana Ganem,2024-10-24,2024-10-24,,N/A
2410.18944v1,Path Guiding for Monte Carlo PDE Solvers,http://arxiv.org/abs/2410.18944v1,"In recent years, Monte Carlo PDE solvers have garnered increasing attentionin computer graphics, demonstrating value across a wide range of applications.Despite offering clear advantages over traditional methods-such as avoidingdiscretization and enabling local evaluations-Monte Carlo PDE solvers facechallenges due to their stochastic nature, including high variance and slowconvergence rates. To mitigate the variance issue, we draw inspiration fromMonte Carlo path tracing and apply the path guiding technique to the Walk onStars estimator. Specifically, we examine the target sampling distribution ateach step of the Walk on Stars estimator, parameterize it, and introduce neuralimplicit representations to model the spatially-varying guiding distribution.This path guiding approach is implemented in a wavefront-style PDE solver, andexperimental results demonstrate that it effectively reduces variance in MonteCarlo PDE solvers.",Tianyu Huang,2024-10-24,2024-10-24,,N/A
2410.18941v1,PRODIGE -- envelope to disk with NOEMA. IV. An infalling gas bridge surrounding two Class 0/I systems in L1448N,http://arxiv.org/abs/2410.18941v1,"Context. The formation of stars has been subject to extensive studies in thepast decades from molecular cloud to protoplanetary disk scales. It is stillnot fully understood how the surrounding material in a protostellar system,that often shows asymmetric structures with complex kinematic properties, feedsthe central protostar(s) and their disk(s). Aims. We study the spatialmorphology and kinematic properties of the molecular gas surrounding the IRS3Aand IRS3B protostellar systems in the L1448N region located in the Perseusmolecular cloud. Methods. We present 1 mm NOEMA observations of the PRODIGElarge program and analyze the kinematic properties of molecular lines. Giventhe complexity of the spectral profiles, the lines are fitted with up to threeGaussian velocity components. The clustering algorithm DBSCAN is used todisentangle the velocity components into the underlying physical structure.Results. We discover an extended gas bridge (~3000 au) surrounding both theIRS3A and IRS3B systems in six molecular line tracers (C18O, SO, DCN, H2CO,HC3N, and CH3OH). This gas bridge is oriented along the northeast-southwestdirection and shows clear velocity gradients on the order of 100 km/s/pctowards the IRS3A system. We find that the observed velocity profile isconsistent with analytical streamline models of gravitational infall towardsIRS3A. The high-velocity C18O (2-1) emission towards IRS3A indicates aprotostellar mass of ~1.2 Msun. Conclusions. While high angular resolutioncontinuum data often show IRS3A and IRS3B in isolation, molecular gasobservations reveal that these systems are still embedded within a large-scalemass reservoir with a complex spatial morphology as well as velocity profiles.The kinematic properties of the extended gas bridge are consistent withgravitational infall toward the IRS3A protostar.",C. Gieser,2024-10-24,2024-10-24,,N/A
2410.18940v1,An assessment of event-based imaging velocimetry for online dimensionality reduction in turbulent flows,http://arxiv.org/abs/2410.18940v1,"This study explores the potential of neuromorphic EBV cameras for fast latentcoordinate representation in turbulent flows. Unlike conventional imagingsystems, EBV cameras asynchronously capture changes in temporal contrast ateach pixel, delivering high-frequency output with reduced data bandwidth andenhanced sensitivity, particularly in low-light conditions. Pulsed EBIV isassessed against traditional PIV through two synchronized experiments: asubmerged water jet and airflow around a square rib in a channel. Theassessment includes a detailed comparison of flow statistics and spectralcontent, alongside an evaluation of reduced-order modeling capabilities usingPOD. The event stream from the EBV camera is converted into pseudo-snapshots,from which velocity fields are computed using standard PIV processingtechniques. These fields are then compared after interpolation onto a commongrid. Modal analysis demonstrates that EBIV can successfully identify dominantflow structures, along with their energy and dynamics, accurately discerningsingular values, spatial modes, and temporal modes. While noise contaminationprimarily affects higher modes-less critical for flow controlapplications-overall performance remains robust. Additionally, comparisons ofLOR validate EBIV's capability to provide reliable reduced-order models ofturbulent flows, essential for flow control purposes. These findings positionEBV sensors as a promising technology for real-time, imaging-based closed-loopflow control systems.",Luca Franceschelli,2024-10-24,2024-10-24,,N/A
2410.18939v1,Adaptive partition Factor Analysis,http://arxiv.org/abs/2410.18939v1,"Factor Analysis has traditionally been utilized across diverse disciplines toextrapolate latent traits that influence the behavior of multivariate observedvariables. Historically, the focus has been on analyzing data from a singlestudy, neglecting the potential study-specific variations present in data frommultiple studies. Multi-study factor analysis has emerged as a recentmethodological advancement that addresses this gap by distinguishing betweenlatent traits shared across studies and study-specific components arising fromartifactual or population-specific sources of variation. In this paper, weextend the current methodologies by introducing novel shrinkage priors for thelatent factors, thereby accommodating a broader spectrum of scenarios -- fromthe absence of study-specific latent factors to models in which factors pertainonly to small subgroups nested within or shared between the studies. For theproposed construction we provide conditions for identifiability of factorloadings and guidelines to perform straightforward posterior computation viaGibbs sampling. Through comprehensive simulation studies, we demonstrate thatour proposed method exhibits competing performance across a variety ofscenarios compared to existing methods, yet providing richer insights. Thepractical benefits of our approach are further illustrated through applicationsto bird species co-occurrence data and ovarian cancer gene expression data.",Elena Bortolato,2024-10-24,2024-10-24,,N/A
2410.18938v1,A Random Matrix Theory Perspective on the Spectrum of Learned Features and Asymptotic Generalization Capabilities,http://arxiv.org/abs/2410.18938v1,"A key property of neural networks is their capacity of adapting to dataduring training. Yet, our current mathematical understanding of featurelearning and its relationship to generalization remain limited. In this work,we provide a random matrix analysis of how fully-connected two-layer neuralnetworks adapt to the target function after a single, but aggressive, gradientdescent step. We rigorously establish the equivalence between the updatedfeatures and an isotropic spiked random feature model, in the limit of largebatch size. For the latter model, we derive a deterministic equivalentdescription of the feature empirical covariance matrix in terms of certainlow-dimensional operators. This allows us to sharply characterize the impact oftraining in the asymptotic feature spectrum, and in particular, provides atheoretical grounding for how the tails of the feature spectrum modify withtraining. The deterministic equivalent further yields the exact asymptoticgeneralization error, shedding light on the mechanisms behind its improvementin the presence of feature learning. Our result goes beyond standard randommatrix ensembles, and therefore we believe it is of independent technicalinterest. Different from previous work, our result holds in the challengingmaximal learning rate regime, is fully rigorous and allows for finitelysupported second layer initialization, which turns out to be crucial forstudying the functional expressivity of the learned features. This provides asharp description of the impact of feature learning in the generalization oftwo-layer neural networks, beyond the random features and lazy trainingregimes.",Yatin Dandi,2024-10-24,2024-10-24,,N/A
2410.18937v1,Python workflow for segmenting multiphase flow in porous rocks,http://arxiv.org/abs/2410.18937v1,"X-ray micro-computed tomography (X-ray micro-CT) is widely employed toinvestigate flow phenomena in porous media, providing a powerful alternative tocore-scale experiments for estimating traditional petrophysical properties suchas porosity, single-phase permeability or fluid connectivity. However, thesegmentation process, critical for deriving these properties from greyscaleimages, varies significantly between studies due to the absence of astandardized workflow or any ground truth data. This introduces challenges incomparing results across different studies, especially for properties sensitiveto segmentation. To address this, we present a fully open-source, automatedworkflow for the segmentation of a Bentheimer sandstone filled with nitrogenand brine. The workflow incorporates a traditional image processing pipeline,including non-local means filtering, image registration, watershed segmentationof grains, and a combination of differential imaging and thresholding forsegmentation of the fluid phases. Our workflow enhances reproducibility byenabling other research groups to easily replicate and validate findings,fostering consistency in petrophysical property estimation. Moreover, itsmodular structure facilitates integration into modeling frameworks, allowingfor forward-backward communication and parameter sensitivity analyses. We applythe workflow to exploring the sensitivity of the non-wetting phase volume,surface area, and connectivity to image processing. This adaptable tool pavesthe way for future advancements in X-ray micro-CT analysis of porous media.",Catherine Spurin,2024-10-24,2024-10-24,,N/A
2410.18936v1,Matching Composition and Efficient Weight Reduction in Dynamic Matching,http://arxiv.org/abs/2410.18936v1,"We consider the foundational problem of maintaining a$(1-\varepsilon)$-approximate maximum weight matching (MWM) in an $n$-nodedynamic graph undergoing edge insertions and deletions. We provide a generalreduction that reduces the problem on graphs with a weight range of$\mathrm{poly}(n)$ to $\mathrm{poly}(1/\varepsilon)$ at the cost of just anadditive $\mathrm{poly}(1/\varepsilon)$ in update time. This improves upon theprior reduction of Gupta-Peng (FOCS 2013) which reduces the problem to a weightrange of $\varepsilon^{-O(1/\varepsilon)}$ with a multiplicative cost of$O(\log n)$.  When combined with a reduction of Bernstein-Dudeja-Langley (STOC 2021) thisyields a reduction from dynamic $(1-\varepsilon)$-approximate MWM in bipartitegraphs with a weight range of $\mathrm{poly}(n)$ to dynamic$(1-\varepsilon)$-approximate maximum cardinality matching in bipartite graphsat the cost of a multiplicative $\mathrm{poly}(1/\varepsilon)$ in update time,thereby resolving an open problem in [GP'13; BDL'21]. Additionally, we showthat our approach is amenable to MWM problems in streaming, shared-memorywork-depth, and massively parallel computation models. We also apply ourtechniques to obtain an efficient dynamic algorithm for rounding weightedfractional matchings in general graphs. Underlying our framework is a newstructural result about MWM that we call the ""matching composition lemma"" andnew dynamic matching subroutines that may be of independent interest.",Aaron Bernstein,2024-10-24,2024-10-24,,N/A
2410.18935v1,Schema-Guided Culture-Aware Complex Event Simulation with Multi-Agent Role-Play,http://arxiv.org/abs/2410.18935v1,"Complex news events, such as natural disasters and socio-political conflicts,require swift responses from the government and society. Relying on historicalevents to project the future is insufficient as such events are sparse and donot cover all possible conditions and nuanced situations. Simulation of thesecomplex events can help better prepare and reduce the negative impact. Wedevelop a controllable complex news event simulator guided by both the eventschema representing domain knowledge about the scenario and user-providedassumptions representing case-specific conditions. As event dynamics depend onthe fine-grained social and cultural context, we further introduce ageo-diverse commonsense and cultural norm-aware knowledge enhancementcomponent. To enhance the coherence of the simulation, apart from the globaltimeline of events, we take an agent-based approach to simulate the individualcharacter states, plans, and actions. By incorporating the schema and culturalnorms, our generated simulations achieve much higher coherence andappropriateness and are received favorably by participants from a humanitarianassistance organization.",Sha Li,2024-10-24,2024-10-24,,N/A
2410.18934v1,Exact solutions for topological surface states of three-dimensional lattice models,http://arxiv.org/abs/2410.18934v1,"In this work, we establish a generalized transfer matrix method that providesexact analytical and numerical solutions for lattice versions of topologicalmodels with surface termination in one direction. We construct a generalizedeigenvalue equation, equivalent to the conventional transfer matrix, whichneither suffers from nor requires singular (non-invertible) inter-layer hoppingmatrices, in contrast to previous works. We then apply this formalism toderive, with exactness, the topological surface states and Fermi arc states intwo prototypical topological models: the 3D Bernevig-Hughes-Zhang model and alattice model exhibiting Weyl semimetal behavior. Our results show that thesurface states and bulk bands, across the projected 2D Brillouin zone, agreeperfectly with those obtained through direct numerical diagonalization of thecorresponding Hamiltonians in a slab geometry. This highlights that thegeneralized transfer matrix method is not only a powerful tool but also ahighly efficient alternative to fully numerical methods for investigatingsurface physics and interfaces in topological systems, particularly when it isrequired to go beyond low-energy effective descriptions.",Matias Mustonen,2024-10-24,2024-10-24,,N/A
2410.18933v1,Confidence is detection-like in high-dimensional spaces,http://arxiv.org/abs/2410.18933v1,"Confidence estimates are often ""detection-like"" - driven by positive evidencein favour of a decision. This empirical observation has been interpreted asshowing human metacognition is limited by biases or heuristics. Here we showthat Bayesian confidence estimates also exhibit heightened sensitivity todecision-congruent evidence in higher-dimensional signal detection theoreticspaces, leading to detection-like confidence criteria. This effect is due to anonlinearity induced by normalisation of confidence by a large number ofunchosen alternatives. Our analysis suggests that detection-like confidence isrational when computing confidence in a higher-dimensional evidence space thanthat assumed by the experimenter.",Stephen M. Fleming,2024-10-24,2024-10-24,,N/A
2410.18930v1,"More on the Operator Space Entanglement (OSE): RÃ©nyi OSE, revivals, and integrability breaking",http://arxiv.org/abs/2410.18930v1,"We investigate the dynamics of the R\'enyi Operator Space Entanglement($OSE$) entropies $S_n$ across several one-dimensional integrable and chaoticmodels. As a paradigmatic integrable system, we first consider the so-calledrule $54$ chain. Our numerical results reveal that the R\'enyi $OSE$ entropiesof diagonal operators with nonzero trace saturate at long times, in contrastwith the behavior of von Neumann entropy. Oppositely, the R\'enyi entropies oftraceless operators exhibit logarithmic growth with time, with the prefactor ofthis growth depending in a nontrivial manner on $n$. Notably, at long times,the complete operator entanglement spectrum ($ES$) of an operator can bereconstructed from the spectrum of its traceless part. We observe a similarpattern in the $XXZ$ chain, suggesting universal behavior. Additionally, weconsider dynamics in nonintegrable deformations of the $XXZ$ chain. Finite-timecorrections do not allow to access the long-time behavior of the von Neumannentropy. On the other hand, for $n>1$ the growth of the entropies is milder,and it is compatible with a sublinear growth, at least for operators associatedwith global conserved quantities. Finally, we show that in finite-sizeintegrable systems, $S_n$ exhibit strong revivals, which are washed out whenintegrability is broken.",Vincenzo Alba,2024-10-24,2024-10-24,,N/A
2410.18927v1,SafeBench: A Safety Evaluation Framework for Multimodal Large Language Models,http://arxiv.org/abs/2410.18927v1,"Multimodal Large Language Models (MLLMs) are showing strong safety concerns(e.g., generating harmful outputs for users), which motivates the developmentof safety evaluation benchmarks. However, we observe that existing safetybenchmarks for MLLMs show limitations in query quality and evaluationreliability limiting the detection of model safety implications as MLLMscontinue to evolve. In this paper, we propose \toolns, a comprehensiveframework designed for conducting safety evaluations of MLLMs. Our frameworkconsists of a comprehensive harmful query dataset and an automated evaluationprotocol that aims to address the above limitations, respectively. We firstdesign an automatic safety dataset generation pipeline, where we employ a setof LLM judges to recognize and categorize the risk scenarios that are mostharmful and diverse for MLLMs; based on the taxonomy, we further ask thesejudges to generate high-quality harmful queries accordingly resulting in 23risk scenarios with 2,300 multi-modal harmful query pairs. During safetyevaluation, we draw inspiration from the jury system in judicial proceedingsand pioneer the jury deliberation evaluation protocol that adopts collaborativeLLMs to evaluate whether target models exhibit specific harmful behaviors,providing a reliable and unbiased assessment of content security risks. Inaddition, our benchmark can also be extended to the audio modality showing highscalability and potential. Based on our framework, we conducted large-scaleexperiments on 15 widely-used open-source MLLMs and 6 commercial MLLMs (e.g.,GPT-4o, Gemini), where we revealed widespread safety issues in existing MLLMsand instantiated several insights on MLLM safety performance such as imagequality and parameter size.",Zonghao Ying,2024-10-24,2024-10-24,,N/A
2410.18925v1,Stability analysis of power-law cosmological models,http://arxiv.org/abs/2410.18925v1,"In this paper, we revisit the stability analysis of power-law models,focusing on an alternative approach that differs significantly from thestandard approaches used in studying power-law models. In the standardapproach, stability is studied by reducing the system of background FRWequations to a one-dimensional system for a new background variable $X$ interms of the number of e-foldings. However, we rewrote the equations, including$H$ also into the system and went on to do the calculations up to second order.We demonstrate by computing the deviations from the power-law exact solution tosecond-order and show that power-law contraction is never an attractor,regardless of parameter values. Our analysis shows that while first-ordercorrections align with existing interpretations, second-order correctionsintroduce significant deviations that cannot be explained by a simple timeshift that explains the first-order diverging terms. We also support our claimwith numerical results. This new insight has broader implications for the studyof attractor behaviour of differential equation solutions and raises questionsabout the stability of scenarios like the ekpyrotic bounce driven by anexponential potential.",Jose Mathew,2024-10-24,2024-10-24,,N/A
2410.18923v1,SegLLM: Multi-round Reasoning Segmentation,http://arxiv.org/abs/2410.18923v1,"We present SegLLM, a novel multi-round interactive reasoning segmentationmodel that enhances LLM-based segmentation by exploiting conversational memoryof both visual and textual outputs. By leveraging a mask-aware multimodal LLM,SegLLM re-integrates previous segmentation results into its input stream,enabling it to reason about complex user intentions and segment objects inrelation to previously identified entities, including positional,interactional, and hierarchical relationships, across multiple interactions.This capability allows SegLLM to respond to visual and text queries in achat-like manner. Evaluated on the newly curated MRSeg benchmark, SegLLMoutperforms existing methods in multi-round interactive reasoning segmentationby over 20%. Additionally, we observed that training on multi-round reasoningsegmentation data enhances performance on standard single-round referringsegmentation and localization tasks, resulting in a 5.5% increase in cIoU forreferring expression segmentation and a 4.5% improvement in Acc@0.5 forreferring expression localization.",XuDong Wang,2024-10-24,2024-10-24,,N/A
2410.18922v1,How to Design a Quantum Streaming Algorithm Without Knowing Anything About Quantum Computing,http://arxiv.org/abs/2410.18922v1,"A series of work [GKK+08, Kal22, KPV24] has shown that asymptotic advantagesin space complexity are possible for quantum algorithms over their classicalcounterparts in the streaming model. We give a simple quantum sketch thatencompasses all these results, allowing them to be derived from entirelyclassical algorithms using our quantum sketch as a black box. The quantumsketch and its proof of correctness are designed to be accessible to a readerwith no background in quantum computation, relying on only a small number ofself-contained quantum postulates.",John Kallaugher,2024-10-24,2024-10-24,,N/A
2410.18921v1,From Blind Solvers to Logical Thinkers: Benchmarking LLMs' Logical Integrity on Faulty Mathematical Problems,http://arxiv.org/abs/2410.18921v1,"Consider the math problem: ""Lily received 3 cookies from her best friendyesterday and ate 5 for breakfast. Today, her friend gave her 3 more cookies.How many cookies does Lily have now?"" Many large language models (LLMs) inprevious research approach this problem by calculating the answer ""1"" using theequation ""3 - 5 + 3."" However, from a human perspective, we recognize theinherent flaw in this problem: Lily cannot eat 5 cookies if she initially onlyhad 3. This discrepancy prompts a key question: Are current LLMs merely BlindSolver that apply mathematical operations without deeper reasoning, or can theyfunction as Logical Thinker capable of identifying logical inconsistencies?  To explore this question, we propose a benchmark dataset, FaultyMath, whichincludes faulty math problems of rich diversity: i) multiple mathematicalcategories, e.g., algebra, geometry, number theory, etc., ii) varying levels ofdifficulty, and iii) different origins of faultiness -- ranging from violationsof common sense and ambiguous statements to mathematical contradictions andmore. We evaluate a broad spectrum of LLMs, including open-source,closed-source, and math-specialized models, using FaultyMath across threedimensions: (i) How accurately can the models detect faulty math problemswithout being explicitly prompted to do so? (ii) When provided with hints --either correct or misleading -- about the validity of the problems, to whatextent do LLMs adapt to become reliable Logical Thinker? (iii) How trustworthyare the explanations generated by LLMs when they recognize a math problem asflawed? Through extensive experimentation and detailed analysis, our resultsdemonstrate that existing LLMs largely function as Blind Solver and fall shortof the reasoning capabilities required to perform as Logical Thinker.",A M Muntasir Rahman,2024-10-24,2024-10-24,,N/A
2410.18918v1,MissNODAG: Differentiable Cyclic Causal Graph Learning from Incomplete Data,http://arxiv.org/abs/2410.18918v1,"Causal discovery in real-world systems, such as biological networks, is oftencomplicated by feedback loops and incomplete data. Standard algorithms, whichassume acyclic structures or fully observed data, struggle with thesechallenges. To address this gap, we propose MissNODAG, a differentiableframework for learning both the underlying cyclic causal graph and themissingness mechanism from partially observed data, including data missing notat random. Our framework integrates an additive noise model with anexpectation-maximization procedure, alternating between imputing missing valuesand optimizing the observed data likelihood, to uncover both the cyclicstructures and the missingness mechanism. We demonstrate the effectiveness ofMissNODAG through synthetic experiments and an application to real-world geneperturbation data.",Muralikrishnna G. Sethuraman,2024-10-24,2024-10-24,https://github.com/muralikgs/missnodag,0
2410.18917v1,Using Parametric PINNs for Predicting Internal and External Turbulent Flows,http://arxiv.org/abs/2410.18917v1,"Computational fluid dynamics (CFD) solvers employing two-equation eddyviscosity models are the industry standard for simulating turbulent flows usingthe Reynolds-averaged Navier-Stokes (RANS) formulation. While these methods arecomputationally less expensive than direct numerical simulations, they canstill incur significant computational costs to achieve the desired accuracy. Inthis context, physics-informed neural networks (PINNs) offer a promisingapproach for developing parametric surrogate models that leverage bothexisting, but limited CFD solutions and the governing differential equations topredict simulation outcomes in a computationally efficient, differentiable, andnear real-time manner. In this work, we build upon the previously proposedRANS-PINN framework, which only focused on predicting flow over a cylinder. Toinvestigate the efficacy of RANS-PINN as a viable approach to buildingparametric surrogate models, we investigate its accuracy in predicting relevantturbulent flow variables for both internal and external flows. To ensuretraining convergence with a more complex loss function, we adopt a novelsampling approach that exploits the domain geometry to ensure a proper balanceamong the contributions from various regions within the solution domain. Theeffectiveness of this framework is then demonstrated for two scenarios thatrepresent a broad class of internal and external flow problems.",Shinjan Ghosh,2024-10-24,2024-10-24,,N/A
2410.18916v1,Parity-violating Gravitational Wave Background Search with a Network of Space-borne Triangular Detectors,http://arxiv.org/abs/2410.18916v1,"Circularly polarized gravitational wave backgrounds are predicted in manywell-motivated models of inflation and phase transitions involving spontaneousparity violation. In this work, we investigate the detection of suchparity-violating signals with the network of two space-borne triangulardetectors. We derive the general analytical formula for the overlap reductionfunctions of networks composed of two triangular detectors, by exploiting thesystem's symmetrical properties under the long-wave approximation. Based onthese results, we further assess the detectability of a parity-violatingbackground with alternative LISA-Taiji network configurations. We find that thesensitivity to the parity-violating component can be significantly enhanced atlow frequencies by adjusting the orientation of Taiji's constellation plane.This sensitivity gain is approximately an order of magnitude around themillihertz band, making the peak sensitivity comparable to that of the totalintensity. This provides a promising opportunity to constrain variousparity-violating theories in the millihertz band with upcoming space-bornedetectors.",Ju Chen,2024-10-24,2024-10-24,,N/A
2410.18913v1,Quantum Many-Body Scars beyond the PXP model in Rydberg simulators,http://arxiv.org/abs/2410.18913v1,"Persistent revivals recently observed in Rydberg atom simulators havechallenged our understanding of thermalization and attracted much interest tothe concept of quantum many-body scars (QMBSs). QMBSs are non-thermal highlyexcited eigenstates that coexist with typical eigenstates in the spectrum ofmany-body Hamiltonians, and have since been reported in multiple theoreticalmodels, including the so-called PXP model, approximately realized by Rydbergsimulators. At the same time, questions of how common QMBSs are and in whatmodels they are physically realized remain open. In this Letter, we demonstratethat QMBSs exist in a broader family of models that includes and generalizesPXP to longer-range constraints and states with different periodicity. We showthat in each model, multiple QMBS families can be found. Each of them relies ona different approximate $\mathfrak{su}(2)$ algebra, leading to oscillatorydynamics in all cases. However, in contrast to the PXP model, their observationrequires launching dynamics from weakly entangled initial states rather thanfrom a product state. QMBSs reported here may be experimentally probed usingRydberg atom simulator in the regime of longer-range Rydberg blockades.",Aron Kerschbaumer,2024-10-24,2024-10-24,,N/A
2410.18912v1,Dynamic 3D Gaussian Tracking for Graph-Based Neural Dynamics Modeling,http://arxiv.org/abs/2410.18912v1,"Videos of robots interacting with objects encode rich information about theobjects' dynamics. However, existing video prediction approaches typically donot explicitly account for the 3D information from videos, such as robotactions and objects' 3D states, limiting their use in real-world roboticapplications. In this work, we introduce a framework to learn object dynamicsdirectly from multi-view RGB videos by explicitly considering the robot'saction trajectories and their effects on scene dynamics. We utilize the 3DGaussian representation of 3D Gaussian Splatting (3DGS) to train aparticle-based dynamics model using Graph Neural Networks. This model operateson sparse control particles downsampled from the densely tracked 3D Gaussianreconstructions. By learning the neural dynamics model on offline robotinteraction data, our method can predict object motions under varying initialconfigurations and unseen robot actions. The 3D transformations of Gaussianscan be interpolated from the motions of control particles, enabling therendering of predicted future object states and achieving action-conditionedvideo prediction. The dynamics model can also be applied to model-basedplanning frameworks for object manipulation tasks. We conduct experiments onvarious kinds of deformable materials, including ropes, clothes, and stuffedanimals, demonstrating our framework's ability to model complex shapes anddynamics. Our project page is available at https://gs-dynamics.github.io.",Mingtong Zhang,2024-10-24,2024-10-24,,N/A
2410.18909v1,A Study of Polycyclic Aromatic Hydrocarbon Emission in 30 Dor as seen by JWST,http://arxiv.org/abs/2410.18909v1,"Polycyclic aromatic hydrocarbons (PAHs) are responsible for strong mid-IRemission features near star-forming regions. It is well known thatlow-metallicity environments exhibit weaker PAH emission, but it is not clearhow the metallicity affects the properties of the emitting PAH population. Wepresent a detailed study of the PAH emission in the low-metallicity regimerepresented by 30 Dor in the Large Magellanic Cloud (LMC) and we compare it tothe PAH emission in the Orion Bar to investigate the characteristics of the PAHpopulation and how the environments affects the resulting IR emission. Weanalyze JWST observations of 30 Dor that include imaging (NIRCam, MIRI) andspectroscopy (NIRSpec/IFU, MIRI/MRS). We extracted NIRSpec/IFU and MIRI/MRSspectra from 18 apertures that cover the morphological structures of 30 Dor. Wecharacterize the profiles and relative intensities of PAH emission in theseapertures. The detailed profiles of the PAH emission bands in 30 Dor are allvery similar, and compare well to those from one of the dissociation fronts(DF2) in the Orion Bar. The relative band ratios on the other hand show a muchlarger range than in the Orion Bar. The PAH emission in 30 Dor originates froma population with a higher ionization fraction than in the Orion Bar, and asize distribution that has more smaller PAHs. Since smaller PAHs typicallyphoto-fragment before larger PAHs, our findings support the hypothesis that thelower PAH emission for lower metallicities is the result of inhibition ofgrowth toward larger PAHs rather than photo-fragmentation.",Congcong Zhang,2024-10-24,2024-10-24,,N/A
2410.18908v1,A Survey on Speech Large Language Models,http://arxiv.org/abs/2410.18908v1,"Large Language Models (LLMs) exhibit strong contextual understanding andremarkable multi-task performance. Therefore, researchers have been seeking tointegrate LLMs in the broad sense of Spoken Language Understanding (SLU) field.Different from the traditional method of cascading LLMs to process textgenerated by Automatic Speech Recognition(ASR), new efforts have focused ondesigning architectures centered around Audio Feature Extraction - MultimodalInformation Fusion - LLM Inference(Speech LLMs). This approach enables richeraudio feature extraction while simultaneously facilitating end-to-end fusion ofaudio and text modalities, thereby achieving deeper understanding and reasoningfrom audio data. This paper elucidates the development of Speech LLMs, offeringan in-depth analysis of system architectures and training strategies. Throughextensive research and a series of targeted experiments, the paper assessesSpeech LLMs' advancements in Rich Audio Transcription and its potential forCross-task Integration within the SLU field. Additionally, it indicates keychallenges uncovered through experimentation, such as the Dormancy of LLMsunder certain conditions. The paper further delves into the training strategiesfor Speech LLMs, proposing potential solutions based on these findings, andoffering valuable insights and references for future research in this domain,as well as LLM applications in multimodal contexts.",Jing Peng,2024-10-24,2024-10-24,,N/A
2410.18907v1,SkillMimicGen: Automated Demonstration Generation for Efficient Skill Learning and Deployment,http://arxiv.org/abs/2410.18907v1,"Imitation learning from human demonstrations is an effective paradigm forrobot manipulation, but acquiring large datasets is costly andresource-intensive, especially for long-horizon tasks. To address this issue,we propose SkillMimicGen (SkillGen), an automated system for generatingdemonstration datasets from a few human demos. SkillGen segments human demosinto manipulation skills, adapts these skills to new contexts, and stitchesthem together through free-space transit and transfer motion. We also propose aHybrid Skill Policy (HSP) framework for learning skill initiation, control, andtermination components from SkillGen datasets, enabling skills to be sequencedusing motion planning at test-time. We demonstrate that SkillGen greatlyimproves data generation and policy learning performance over astate-of-the-art data generation framework, resulting in the capability toproduce data for large scene variations, including clutter, and agents that areon average 24% more successful. We demonstrate the efficacy of SkillGen bygenerating over 24K demonstrations across 18 task variants in simulation fromjust 60 human demonstrations, and training proficient, often near-perfect, HSPagents. Finally, we apply SkillGen to 3 real-world manipulation tasks and alsodemonstrate zero-shot sim-to-real transfer on a long-horizon assembly task.Videos, and more at https://skillgen.github.io.",Caelan Garrett,2024-10-24,2024-10-24,,N/A
2410.18906v1,PRISM: A Methodology for Auditing Biases in Large Language Models,http://arxiv.org/abs/2410.18906v1,"Auditing Large Language Models (LLMs) to discover their biases andpreferences is an emerging challenge in creating Responsible ArtificialIntelligence (AI). While various methods have been proposed to elicit thepreferences of such models, countermeasures have been taken by LLM trainers,such that LLMs hide, obfuscate or point blank refuse to disclosure theirpositions on certain subjects. This paper presents PRISM, a flexible,inquiry-based methodology for auditing LLMs - that seeks to illicit suchpositions indirectly through task-based inquiry prompting rather than directinquiry of said preferences. To demonstrate the utility of the methodology, weapplied PRISM on the Political Compass Test, where we assessed the politicalleanings of twenty-one LLMs from seven providers. We show LLMs, by default,espouse positions that are economically left and socially liberal (consistentwith prior work). We also show the space of positions that these models arewilling to espouse - where some models are more constrained and less compliantthan others - while others are more neutral and objective. In sum, PRISM canmore reliably probe and audit LLMs to understand their preferences, biases andconstraints.",Leif Azzopardi,2024-10-24,2024-10-24,https://github.com/cis-phawm/prism,0
2410.18905v1,The critical density of the Stochastic Sandpile Model,http://arxiv.org/abs/2410.18905v1,"We study the stochastic sandpile model on $\mathbb{Z}^d$ and demonstrate thatthe critical density is strictly less than one in all dimensions. Thisgeneralizes a previous result by Hoffman, Hu, Richey, and Rizzolo (2022), whichwas limited to the one-dimensional case. In addition, we show that the criticaldensity is strictly positive on any vertex-transitive graph, extending theearlier result of Sidoravicius and Teixeira (2018) and providing a simplerproof.",Concetta Campailla,2024-10-24,2024-10-24,,N/A
2410.18904v1,Modulated Adaptive Fourier Neural Operators for Temporal Interpolation of Weather Forecasts,http://arxiv.org/abs/2410.18904v1,"Weather and climate data are often available at limited temporal resolution,either due to storage limitations, or in the case of weather forecast modelsbased on deep learning, their inherently long time steps. The coarse temporalresolution makes it difficult to capture rapidly evolving weather events. Toaddress this limitation, we introduce an interpolation model that reconstructsthe atmospheric state between two points in time for which the state is known.The model makes use of a novel network layer that modifies the adaptive Fourierneural operator (AFNO), which has been previously used in weather predictionand other applications of machine learning to physics problems. The modulatedAFNO (ModAFNO) layer takes an embedding, here computed from the interpolationtarget time, as an additional input and applies a learned shift-scale operationinside the AFNO layers to adapt them to the target time. Thus, one model can beused to produce all intermediate time steps. Trained to interpolate between twotime steps 6 h apart, the ModAFNO-based interpolation model produces 1 hresolution intermediate time steps that are visually nearly indistinguishablefrom the actual corresponding 1 h resolution data. The model reduces the RMSEloss of reconstructing the intermediate steps by approximately 50% compared tolinear interpolation. We also demonstrate its ability to reproduce thestatistics of extreme weather events such as hurricanes and heat waves betterthan 6 h resolution data. The ModAFNO layer is generic and is expected to beapplicable to other problems, including weather forecasting with tunable leadtime.",Jussi Leinonen,2024-10-24,2024-10-24,,N/A
2410.18902v1,LLMs for Extremely Low-Resource Finno-Ugric Languages,http://arxiv.org/abs/2410.18902v1,"The advancement of large language models (LLMs) has predominantly focused onhigh-resource languages, leaving low-resource languages, such as those in theFinno-Ugric family, significantly underrepresented. This paper addresses thisgap by focusing on V\~oro, Livonian, and Komi. We cover almost the entire cycleof LLM creation, from data collection to instruction tuning and evaluation. Ourcontributions include developing multilingual base and instruction-tunedmodels; creating evaluation benchmarks, including the smugri-MT-benchmulti-turn conversational benchmark; and conducting human evaluation. We intendfor this work to promote linguistic diversity, ensuring that lesser-resourcedlanguages can benefit from advancements in NLP.",Taido Purason,2024-10-24,2024-10-24,,N/A
2410.18898v1,Aging and memory effects in social and economic dynamics,http://arxiv.org/abs/2410.18898v1,"In this doctoral thesis, we investigate the complex interplay betweentemporal dynamics associated with aging and memory and their effects on socialand economic systems. To do so, we combine theoretical modeling, to explore theaging implications in threshold (peer pressure) models, and empirical analysis,to address the impact of temporal and spatial patterns in real complex systems,taking housing market as a case study.",David Abella,2024-10-24,2024-10-24,,N/A
2410.18897v1,Generation of synthetic financial time series by diffusion models,http://arxiv.org/abs/2410.18897v1,"Despite its practical significance, generating realistic synthetic financialtime series is challenging due to statistical properties known as stylizedfacts, such as fat tails, volatility clustering, and seasonality patterns.Various generative models, including generative adversarial networks (GANs) andvariational autoencoders (VAEs), have been employed to address this challenge,although no model yet satisfies all the stylized facts. We alternativelypropose utilizing diffusion models, specifically denoising diffusionprobabilistic models (DDPMs), to generate synthetic financial time series. Thisapproach employs wavelet transformation to convert multiple time series (intoimages), such as stock prices, trading volumes, and spreads. Given theseconverted images, the model gains the ability to generate images that can betransformed back into realistic time series by inverse wavelet transformation.We demonstrate that our proposed approach satisfies stylized facts.",Tomonori Takahashi,2024-10-24,2024-10-24,,N/A
2410.18894v1,Meta-Learning with Heterogeneous Tasks,http://arxiv.org/abs/2410.18894v1,"Meta-learning is a general approach to equip machine learning models with theability to handle few-shot scenarios when dealing with many tasks. Mostexisting meta-learning methods work based on the assumption that all tasks areof equal importance. However, real-world applications often presentheterogeneous tasks characterized by varying difficulty levels, noise intraining samples, or being distinctively different from most other tasks. Inthis paper, we introduce a novel meta-learning method designed to effectivelymanage such heterogeneous tasks by employing rank-based task-level learningobjectives, Heterogeneous Tasks Robust Meta-learning (HeTRoM). HeTRoM isproficient in handling heterogeneous tasks, and it prevents easy tasks fromoverwhelming the meta-learner. The approach allows for an efficient iterativeoptimization algorithm based on bi-level optimization, which is then improvedby integrating statistical guidance. Our experimental results demonstrate thatour method provides flexibility, enabling users to adapt to diverse tasksettings and enhancing the meta-learner's overall performance.",Zhaofeng Si,2024-10-24,2024-10-24,,N/A
2410.18893v1,Creating and Repairing Robot Programs in Open-World Domains,http://arxiv.org/abs/2410.18893v1,"Using Large Language Models (LLMs) to produce robot programs from naturallanguage has allowed for robot systems that can complete a higher diversity oftasks. However, LLM-generated programs may be faulty, either due to ambiguityin instructions, misinterpretation of the desired task, or missing informationabout the world state. As these programs run, the state of the world changesand they gather new information. When a failure occurs, it is important thatthey recover from the current world state and avoid repeating steps that theythey previously completed successfully. We propose RoboRepair, a system whichtraces the execution of a program up until error, and then runs an LLM-producedrecovery program that minimizes repeated actions.  To evaluate the efficacy of our system, we create a benchmark consisting ofeleven tasks with various error conditions that require the generation of arecovery program. We compare the efficiency of the recovery program to a planbuilt with an oracle that has foreknowledge of future errors.",Claire Schlesinger,2024-10-24,2024-10-24,,N/A
2410.18890v1,Improving Small-Scale Large Language Models Function Calling for Reasoning Tasks,http://arxiv.org/abs/2410.18890v1,"Recent advancements in Large Language Models (LLMs) have demonstratedexceptional capabilities in natural language understanding and generation.While these models excel in general complex reasoning tasks, they still facechallenges in mathematical problem-solving and logical reasoning. To addressthese limitations, researchers have explored function calling abilities,allowing LLMs to execute provided functions and utilize their outputs for taskcompletion. However, concentrating on specific tasks can be very inefficientfor large-scale LLMs to be used, because of the expensive cost of training andinference stages they need in terms of computational resources. This studyintroduces a novel framework for training smaller language models in functioncalling, focusing on specific logical and mathematical reasoning tasks. Theapproach aims to improve performances of small-scale models for these tasksusing function calling, ensuring a high level of accuracy. Our frameworkemploys an agent that, given a problem and a set of callable functions, queriesthe LLM by injecting a description and examples of the usable functions intothe prompt and managing their calls in a step-by-step reasoning chain. Thisprocess is used to create a dataset of correct and incorrect reasoning chainchat completions from a large-scale LLM. This dataset is used to train asmaller LLM using Reinforcement Learning from Human Feedback (RLHF),specifically employing the Direct Preference Optimization (DPO) technique.Experimental results demonstrate how the proposed approach balances thetrade-off between model size and performance, improving the ability of functioncalling for reasoning tasks, in smaller models.",Graziano A. Manduzio,2024-10-24,2024-10-24,,N/A
2410.18889v1,Are LLMs Better than Reported? Detecting Label Errors and Mitigating Their Effect on Model Performance,http://arxiv.org/abs/2410.18889v1,"NLP benchmarks rely on standardized datasets for training and evaluatingmodels and are crucial for advancing the field. Traditionally, expertannotations ensure high-quality labels; however, the cost of expert annotationdoes not scale well with the growing demand for larger datasets required bymodern models. While crowd-sourcing provides a more scalable solution, it oftencomes at the expense of annotation precision and consistency. Recentadvancements in large language models (LLMs) offer new opportunities to enhancethe annotation process, particularly for detecting label errors in existingdatasets. In this work, we consider the recent approach of LLM-as-a-judge,leveraging an ensemble of LLMs to flag potentially mislabeled examples. Througha case study of four datasets from the TRUE benchmark, covering different tasksand domains, we empirically analyze the labeling quality of existing datasets,and compare expert, crowd-sourced, and our LLM-based annotations in terms ofagreement, label quality, and efficiency, demonstrating the strengths andlimitations of each annotation method. Our findings reveal a substantial numberof label errors, which, when corrected, induce a significant upward shift inreported model performance. This suggests that many of the LLMs so-calledmistakes are due to label errors rather than genuine model failures.Additionally, we discuss the implications of mislabeled data and proposemethods to mitigate them in training to improve model performance.",Omer Nahum,2024-10-24,2024-10-24,,N/A
2410.18888v1,Existence of solutions to port-Hamiltonian systems: initial value problems and optimal control,http://arxiv.org/abs/2410.18888v1,"We investigate the existence of solutions of reversible and irreversibleport-Hamiltonian systems. To this end, we utilize the associated exergy, afunction that is composed of the system's Hamiltonian and entropy, to proveglobal existence in time for bounded control functions. The results are thenleveraged to prove existence of solutions of energy- and entropy-optimalcontrol problems. Last, we explore model predictive control tailored toirreversible port-Hamiltonian systems by means of a numerical case study with aheat exchanger network.",Willem Esterhuizen,2024-10-24,2024-10-24,,N/A
2410.18884v1,Symmetry in Hyper Suprime-Cam galaxy spin directions,http://arxiv.org/abs/2410.18884v1,"We perform a Bayesian analysis of anisotropy in binary galaxy spin directionsin the Hyper-Suprime Cam Data Release 3 catalogue, in response to a recentclaim that it exhibits a dipole Shamir 2024. We find no significant evidencefor anisotropy, or for a direction-independent spin probability that differsfrom 0.5. These results are unchanged allowing for a quadrupole or simplysearching for a fixed anisotropy between any two hemispheres, and the Bayesfactor indicates decisive evidence for the isotropic model. Our principledmethod contrasts with the ad-hoc statistic employed by Shamir 2024. Our code ispublicly available.",Richard Stiskalek,2024-10-24,2024-10-24,,N/A
2410.18882v1,A Survey of Multimodal Sarcasm Detection,http://arxiv.org/abs/2410.18882v1,"Sarcasm is a rhetorical device that is used to convey the opposite of theliteral meaning of an utterance. Sarcasm is widely used on social media andother forms of computer-mediated communication motivating the use ofcomputational models to identify it automatically. While the clear majority ofapproaches to sarcasm detection have been carried out on text only, sarcasmdetection often requires additional information present in tonality, facialexpression, and contextual images. This has led to the introduction ofmultimodal models, opening the possibility to detect sarcasm in multiplemodalities such as audio, images, text, and video. In this paper, we presentthe first comprehensive survey on multimodal sarcasm detection - henceforth MSD- to date. We survey papers published between 2018 and 2023 on the topic, anddiscuss the models and datasets used for this task. We also present futureresearch directions in MSD.",Shafkat Farabi,2024-10-24,2024-10-24,,N/A
2410.18881v1,Diff-Instruct++: Training One-step Text-to-image Generator Model to Align with Human Preferences,http://arxiv.org/abs/2410.18881v1,"One-step text-to-image generator models offer advantages such as swiftinference efficiency, flexible architectures, and state-of-the-art generationperformance. In this paper, we study the problem of aligning one-step generatormodels with human preferences for the first time. Inspired by the success ofreinforcement learning using human feedback (RLHF), we formulate the alignmentproblem as maximizing expected human reward functions while adding an IntegralKullback-Leibler divergence term to prevent the generator from diverging. Byovercoming technical challenges, we introduce Diff-Instruct++ (DI++), thefirst, fast-converging and image data-free human preference alignment methodfor one-step text-to-image generators. We also introduce novel theoreticalinsights, showing that using CFG for diffusion distillation is secretly doingRLHF with DI++. Such an interesting finding brings understanding and potentialcontributions to future research involving CFG. In the experiment sections, wealign both UNet-based and DiT-based one-step generators using DI++, which usethe Stable Diffusion 1.5 and the PixelArt-$\alpha$ as the reference diffusionprocesses. The resulting DiT-based one-step text-to-image model achieves astrong Aesthetic Score of 6.19 and an Image Reward of 1.24 on the COCOvalidation prompt dataset. It also achieves a leading Human preference Score(HPSv2.0) of 28.48, outperforming other open-sourced models such as StableDiffusion XL, DMD2, SD-Turbo, as well as PixelArt-$\alpha$. Both theoreticalcontributions and empirical evidence indicate that DI++ is a stronghuman-preference alignment approach for one-step text-to-image models.",Weijian Luo,2024-10-24,2024-10-24,,N/A
2410.18879v1,Multi-Class Abnormality Classification in Video Capsule Endoscopy Using Deep Learning,http://arxiv.org/abs/2410.18879v1,"This report outlines Team Seq2Cure's deep learning approach for the CapsuleVision 2024 Challenge, leveraging an ensemble of convolutional neural networks(CNNs) and transformer-based architectures for multi-class abnormalityclassification in video capsule endoscopy frames. The dataset comprised over50,000 frames from three public sources and one private dataset, labeled across10 abnormality classes. To overcome the limitations of traditional CNNs incapturing global context, we integrated CNN and transformer models within amulti-model ensemble. Our approach achieved a balanced accuracy of 86.34percent and a mean AUC-ROC score of 0.9908 on the validation set, withsignificant improvements in classifying complex abnormalities. Code isavailable at http://github.com/arnavs04/capsule-vision-2024 .",Arnav Samal,2024-10-24,2024-10-24,https://github.com/arnavs04/capsule-vision-2024,1
2410.18876v1,Guiding Empowerment Model: Liberating Neurodiversity in Online Higher Education,http://arxiv.org/abs/2410.18876v1,"In this innovative practice full paper, we address the equity gap forneurodivergent and situationally limited learners by identifying the spectrumof dynamic factors that impact learning and function. Educators have shown agrowing interest in identifying learners' cognitive abilities and learningpreferences to measure their impact on academic achievement. Often institutionsemploy one-size-fits-all approaches leaving the burden on disabled students toself-advocate or tolerate inadequate support. Emerging frameworks guideneurodivergent learners through instructional approaches, such as onlineeducation. However, these frameworks fail to address holistic environmentalneeds or recommend technology interventions, particularly for those withundisclosed learning or developmental disabilities and situational limitations.In this article, we integrate a neurodivergent perspective through secondaryresearch of around 100 articles to introduce a Guiding Empowerment Modelinvolving key cognitive and situational factors that contextualize day-to-dayexperiences affecting learner ability. We synthesize three sample studentprofiles that highlight user problems in functioning. We use this model toevaluate sample learning platform features and other supportive technologysolutions. The proposed approach augments frameworks such as Universal Designfor Learning to consider factors including various sensory processingdifferences, social connection challenges, and environmental limitations. Wesuggest that by applying the mode through technology-enabled features such ascustomizable task management, guided varied content access, and guidedmulti-modal collaboration, major learning barriers of neurodivergent andsituationally limited learners will be removed to activate the successfulpursuit of their academic goals.",Hannah Beaux,2024-10-24,2024-10-24,,N/A
2410.18875v1,Exploring the Universe with SNAD: Anomaly Detection in Astronomy,http://arxiv.org/abs/2410.18875v1,"SNAD is an international project with a primary focus on detectingastronomical anomalies within large-scale surveys, using active learning andother machine learning algorithms. The work carried out by SNAD not onlycontributes to the discovery and classification of various astronomicalphenomena but also enhances our understanding and implementation of machinelearning techniques within the field of astrophysics. This paper provides areview of the SNAD project and summarizes the advancements and achievementsmade by the team over several years.",Alina A. Volnova,2024-10-24,2024-10-24,,N/A
2410.18874v1,Diffusion of impurities in a moderately dense confined granular gas,http://arxiv.org/abs/2410.18874v1,"Mass transport of impurities immersed in a confined quasi-two-dimensionalmoderately dense granular gas of inelastic hard spheres is studied. The effectof the confinement on granular particles is modeled through a collisional model(the so-called $\Delta$-model) that includes an effective mechanism to transferthe kinetic energy injected by vibration in the vertical direction to thehorizontal degrees of freedom of grains. The impurity can differ in mass,diameter, inelasticity, or the energy injection at collisions, compared to thegas particles. The Enskog--Lorentz kinetic equation for the impurities issolved via the Chapman--Enskog method to first order in spatial gradients forstates close to the homogeneous steady state. As usual, the three diffusiontransport coefficients for tracer particles in a mixture are given in terms ofthe solutions of a set of coupled linear integral equations which are solved byconsidering the lowest Sonine approximation. The theoretical predictions forthe tracer diffusion coefficient (relating the mass flux with the gradient ofthe number density of tracer particles) are compared with both directsimulation Monte Carlo and molecular dynamics simulations. The agreement is ingeneral good, except for strong inelasticity and/or large contrast of energyinjection at tracer-gas collisions compared to gas-gas collisions. Finally, asan application of our results, the segregation problem induced by both athermal gradient and gravity is exhaustively analyzed.",RubÃ©n GÃ³mez GonzÃ¡lez,2024-10-24,2024-10-24,,N/A
2410.18873v1,High-throughput search for topological magnon materials,http://arxiv.org/abs/2410.18873v1,"Topological magnons give rise to possibilities for engineering novelspintronics devices with critical applications in quantum information andcomputation, due to its symmetry-protected robustness and low dissipation.However, to make reliable and systematic predictions about material realizationof topological magnons has been a major challenge, due to the lack of neutronscattering data for most materials. In this work, we significantly advance thesymmetry-based approach for identifying topological magnons through developinga fully automated algorithm, utilizing the theory of symmetry indicators, thatenables a highly efficient and large-scale search for candidate materialshosting field-induced topological magnons. This progress not only streamlinesthe discovery process but also expands the scope of materials explorationbeyond previous manual or traditional methods, offering a powerful tool foruncovering novel topological phases in magnetic systems. Performing alarge-scale search over all 1649 magnetic materials in Bilbao CrystallographicServer with a commensurate magnetic order, we discover 387 candidate materialsfor topological magnons, significantly expanding the pool of topological magnonmaterials. We further discuss examples and experimental accessibility of thecandidate materials, shedding light on future experimental realizations oftopological magnons in magnetic materials.",Mohammed J. Karaki,2024-10-24,2024-10-24,,N/A
2410.18871v1,"Learning Collusion in Episodic, Inventory-Constrained Markets",http://arxiv.org/abs/2410.18871v1,"Pricing algorithms have demonstrated the capability to learn tacit collusionthat is largely unaddressed by current regulations. Their increasing use inmarkets, including oligopolistic industries with a history of collusion, callsfor closer examination by competition authorities. In this paper, we extend thestudy of tacit collusion in learning algorithms from basic pricing games tomore complex markets characterized by perishable goods with fixed supply andsell-by dates, such as airline tickets, perishables, and hotel rooms. Weformalize collusion within this framework and introduce a metric based on pricelevels under both the competitive (Nash) equilibrium and collusive(monopolistic) optimum. Since no analytical expressions for these price levelsexist, we propose an efficient computational approach to derive them. Throughexperiments, we demonstrate that deep reinforcement learning agents can learnto collude in this more complex domain. Additionally, we analyze the underlyingmechanisms and structures of the collusive strategies these agents adopt.",Paul Friedrich,2024-10-24,2024-10-24,,N/A
2410.18870v1,End-to-end Training for Recommendation with Language-based User Profiles,http://arxiv.org/abs/2410.18870v1,"Many online platforms maintain user profiles for personalization.Unfortunately, these profiles are typically not interpretable or easilymodifiable by the user. To remedy this shortcoming, we explore naturallanguage-based user profiles, as they promise enhanced transparency andscrutability of recommender systems. While existing work has shown thatlanguage-based profiles from standard LLMs can be effective, such generalistLLMs are unlikely to be optimal for this task. In this paper, we introduceLangPTune, the first end-to-end learning method for training LLMs to producelanguage-based user profiles that optimize recommendation effectiveness.Through comprehensive evaluations of LangPTune across various trainingconfigurations and benchmarks, we demonstrate that our approach significantlyoutperforms existing profile-based methods. In addition, it approachesperformance levels comparable to state-of-the-art, less transparent recommendersystems, providing a robust and interpretable alternative to conventionalsystems. Finally, we validate the relative interpretability of theselanguage-based user profiles through user studies involving crowdworkers andGPT-4-based evaluations. Implementation of LangPTune can be found athttps://github.com/ZhaolinGao/LangPTune.",Zhaolin Gao,2024-10-24,2024-10-24,https://github.com/zhaolingao/langptune,0
2410.18869v1,On the mean-field limit of diffusive games through the master equation: extreme value analysis,http://arxiv.org/abs/2410.18869v1,"We consider an $N$-player game where the players control the drifts of theirdiffusive states which have no interaction in the noise terms. The aim of eachplayer is to minimize the expected value of her cost, which is a function ofthe player's state and the empirical measure of the states of all the players.Our aim is to determine the $N \to \infty$ asymptotic behavior of the upperorder statistics of the player's states under Nash equilibrium (the Nashstates). For this purpose, we consider also a system of interacting diffusionswhich is constructed by using the Master PDE of the game and approximates thesystem of the Nash states, and we improve an $L^2$ estimate for the distancebetween the drifts of the two systems which has been used for establishingCentral Limit Theorems and Large Deviations Principles for the Nash states inthe past. By differentiating the Master PDE, we obtain that estimate also in$L^{\infty}$, which allows us to control the Radon-Nikodym derivative of aGirsanov transformation that connects the two systems. The latter allows us toreduce the problem to the case of $N$ uncontrolled diffusions with standardmean-field interaction in the drifts, which has been treated in a previouswork.",Erhan Bayraktar,2024-10-24,2024-10-24,,N/A
2410.18868v1,A Riemannian Framework for Learning Reduced-order Lagrangian Dynamics,http://arxiv.org/abs/2410.18868v1,"By incorporating physical consistency as inductive bias, deep neural networksdisplay increased generalization capabilities and data efficiency in learningnonlinear dynamic models. However, the complexity of these models generallyincreases with the system dimensionality, requiring larger datasets, morecomplex deep networks, and significant computational effort. We propose a novelgeometric network architecture to learn physically-consistent reduced-orderdynamic parameters that accurately describe the original high-dimensionalsystem behavior. This is achieved by building on recent advances in model-orderreduction and by adopting a Riemannian perspective to jointly learn astructure-preserving latent space and the associated low-dimensional dynamics.Our approach enables accurate long-term predictions of the high-dimensionaldynamics of rigid and deformable systems with increased data efficiency byinferring interpretable and physically plausible reduced Lagrangian models.",Katharina Friedl,2024-10-24,2024-10-24,,N/A
2410.18866v1,The Cat and Mouse Game: The Ongoing Arms Race Between Diffusion Models and Detection Methods,http://arxiv.org/abs/2410.18866v1,"The emergence of diffusion models has transformed synthetic media generation,offering unmatched realism and control over content creation. Theseadvancements have driven innovation across fields such as art, design, andscientific visualization. However, they also introduce significant ethical andsocietal challenges, particularly through the creation of hyper-realisticimages that can facilitate deepfakes, misinformation, and unauthorizedreproduction of copyrighted material. In response, the need for effectivedetection mechanisms has become increasingly urgent. This review examines theevolving adversarial relationship between diffusion model development and theadvancement of detection methods. We present a thorough analysis ofcontemporary detection strategies, including frequency and spatial domaintechniques, deep learning-based approaches, and hybrid models that combinemultiple methodologies. We also highlight the importance of diverse datasetsand standardized evaluation metrics in improving detection accuracy andgeneralizability. Our discussion explores the practical applications of thesedetection systems in copyright protection, misinformation prevention, andforensic analysis, while also addressing the ethical implications of syntheticmedia. Finally, we identify key research gaps and propose future directions toenhance the robustness and adaptability of detection methods in line with therapid advancements of diffusion models. This review emphasizes the necessity ofa comprehensive approach to mitigating the risks associated with AI-generatedcontent in an increasingly digital world.",Linda Laurier,2024-10-24,2024-10-24,,N/A
2410.18864v1,Omics-driven hybrid dynamic modeling of bioprocesses with uncertainty estimation,http://arxiv.org/abs/2410.18864v1,"This work presents an omics-driven modeling pipeline that integratesmachine-learning tools to facilitate the dynamic modeling of multiscalebiological systems. Random forests and permutation feature importance areproposed to mine omics datasets, guiding feature selection and dimensionalityreduction for dynamic modeling. Continuous and differentiable machine-learningfunctions can be trained to link the reduced omics feature set to keycomponents of the dynamic model, resulting in a hybrid model. As proof ofconcept, we apply this framework to a high-dimensional proteomics dataset of$\textit{Saccharomyces cerevisiae}$. After identifying key intracellularproteins that correlate with cell growth, targeted dynamic experiments aredesigned, and key model parameters are captured as functions of the selectedproteins using Gaussian processes. This approach captures the dynamic behaviorof yeast strains under varying proteome profiles while estimating theuncertainty in the hybrid model's predictions. The outlined modeling frameworkis adaptable to other scenarios, such as integrating additional layers of omicsdata for more advanced multiscale biological systems, or employing alternativemachine-learning methods to handle larger datasets. Overall, this studyoutlines a strategy for leveraging omics data to inform multiscale dynamicmodeling in systems biology and bioprocess engineering.",SebastiÃ¡n Espinel-RÃ­os,2024-10-24,2024-10-24,,N/A
2410.18862v1,FedSPD: A Soft-clustering Approach for Personalized Decentralized Federated Learning,http://arxiv.org/abs/2410.18862v1,"Federated learning has recently gained popularity as a framework fordistributed clients to collaboratively train a machine learning model usinglocal data. While traditional federated learning relies on a central server formodel aggregation, recent advancements adopt a decentralized framework,enabling direct model exchange between clients and eliminating the single pointof failure. However, existing decentralized frameworks often assume all clientstrain a shared model. Personalizing each client's model can enhanceperformance, especially with heterogeneous client data distributions. Wepropose FedSPD, an efficient personalized federated learning algorithm for thedecentralized setting, and show that it learns accurate models even inlow-connectivity networks. To provide theoretical guarantees on convergence, weintroduce a clustering-based framework that enables consensus on models fordistinct data clusters while personalizing to unique mixtures of these clustersat different clients. This flexibility, allowing selective model updates basedon data distribution, substantially reduces communication costs compared toprior work on personalized federated learning in decentralized settings.Experimental results on real-world datasets show that FedSPD outperformsmultiple decentralized variants of personalized federated learning algorithms,especially in scenarios with low-connectivity networks.",I-Cheng Lin,2024-10-24,2024-10-24,,N/A
2410.18861v1,Provably Robust Watermarks for Open-Source Language Models,http://arxiv.org/abs/2410.18861v1,"The recent explosion of high-quality language models has necessitated newmethods for identifying AI-generated text. Watermarking is a leading solutionand could prove to be an essential tool in the age of generative AI. Existingapproaches embed watermarks at inference and crucially rely on the largelanguage model (LLM) specification and parameters being secret, which makesthem inapplicable to the open-source setting. In this work, we introduce thefirst watermarking scheme for open-source LLMs. Our scheme works by modifyingthe parameters of the model, but the watermark can be detected from just theoutputs of the model. Perhaps surprisingly, we prove that our watermarks areunremovable under certain assumptions about the adversary's knowledge. Todemonstrate the behavior of our construction under concrete parameterinstantiations, we present experimental results with OPT-6.7B and OPT-1.3B. Wedemonstrate robustness to both token substitution and perturbation of the modelparameters. We find that the stronger of these attacks, the model-perturbationattack, requires deteriorating the quality score to 0 out of 100 in order tobring the detection rate down to 50%.",Miranda Christ,2024-10-24,2024-10-24,,N/A
2410.18860v1,DeCoRe: Decoding by Contrasting Retrieval Heads to Mitigate Hallucinations,http://arxiv.org/abs/2410.18860v1,"Large Language Models (LLMs) often hallucinate, producing unfaithful orfactually incorrect outputs by misrepresenting the provided context orincorrectly recalling internal knowledge. Recent studies have identifiedspecific attention heads within the Transformer architecture, known asretrieval heads, responsible for extracting relevant contextual information. Wehypothesise that masking these retrieval heads can induce hallucinations andthat contrasting the outputs of the base LLM and the masked LLM can reducehallucinations. To this end, we propose Decoding by Contrasting Retrieval Heads(DeCoRe), a novel training-free decoding strategy that amplifies informationfound in the context and model parameters. DeCoRe mitigates potentiallyhallucinated responses by dynamically contrasting the outputs of the base LLMand the masked LLM, using conditional entropy as a guide. Our extensiveexperiments confirm that DeCoRe significantly improves performance on tasksrequiring high contextual faithfulness, such as summarisation (XSum by 18.6%),instruction following (MemoTrap by 10.9%), and open-book question answering(NQ-Open by 2.4% and NQ-Swap by 5.5%).",Aryo Pradipta Gema,2024-10-24,2024-10-24,https://github.com/aryopg/decore,4
2410.18858v1,Bilinear Sequence Regression: A Model for Learning from Long Sequences of High-dimensional Tokens,http://arxiv.org/abs/2410.18858v1,"Current progress in artificial intelligence is centered around so-calledlarge language models that consist of neural networks processing long sequencesof high-dimensional vectors called tokens. Statistical physics providespowerful tools to study the functioning of learning with neural networks andhas played a recognized role in the development of modern machine learning. Thestatistical physics approach relies on simplified and analytically tractablemodels of data. However, simple tractable models for long sequences ofhigh-dimensional tokens are largely underexplored. Inspired by the crucial rolemodels such as the single-layer teacher-student perceptron (aka generalizedlinear regression) played in the theory of fully connected neural networks, inthis paper, we introduce and study the bilinear sequence regression (BSR) asone of the most basic models for sequences of tokens. We note that modernarchitectures naturally subsume the BSR model due to the skip connections.Building on recent methodological progress, we compute the Bayes-optimalgeneralization error for the model in the limit of long sequences ofhigh-dimensional tokens, and provide a message-passing algorithm that matchesthis performance. We quantify the improvement that optimal learning brings withrespect to vectorizing the sequence of tokens and learning via simple linearregression. We also unveil surprising properties of the gradient descentalgorithms in the BSR model.",Vittorio Erba,2024-10-24,2024-10-24,https://github.com/SPOC-group/bilinear-sequence-regression,0
2410.18857v1,Probabilistic Language-Image Pre-Training,http://arxiv.org/abs/2410.18857v1,"Vision-language models (VLMs) embed aligned image-text pairs into a jointspace but often rely on deterministic embeddings, assuming a one-to-onecorrespondence between images and texts. This oversimplifies real-worldrelationships, which are inherently many-to-many, with multiple captionsdescribing a single image and vice versa. We introduce ProbabilisticLanguage-Image Pre-training (ProLIP), the first probabilistic VLM pre-trainedon a billion-scale image-text dataset using only probabilistic objectives,achieving a strong zero-shot capability (e.g., 74.6% ImageNet zero-shotaccuracy with ViT-B/16). ProLIP efficiently estimates uncertainty by an""uncertainty token"" without extra parameters. We also introduce a novelinclusion loss that enforces distributional inclusion relationships betweenimage-text pairs and between original and masked inputs. Experimentsdemonstrate that, by leveraging uncertainty estimates, ProLIP benefitsdownstream tasks and aligns with intuitive notions of uncertainty, e.g.,shorter texts being more uncertain and more general inputs including specificones. Utilizing text uncertainties, we further improve ImageNet accuracy from74.6% to 75.8% (under a few-shot setting), supporting the practical advantagesof our probabilistic approach. The code is available athttps://github.com/naver-ai/prolip",Sanghyuk Chun,2024-10-24,2024-10-24,,N/A
2410.18856v1,Demystifying Large Language Models for Medicine: A Primer,http://arxiv.org/abs/2410.18856v1,"Large language models (LLMs) represent a transformative class of AI toolscapable of revolutionizing various aspects of healthcare by generatinghuman-like responses across diverse contexts and adapting to novel tasksfollowing human instructions. Their potential application spans a broad rangeof medical tasks, such as clinical documentation, matching patients to clinicaltrials, and answering medical questions. In this primer paper, we propose anactionable guideline to help healthcare professionals more efficiently utilizeLLMs in their work, along with a set of best practices. This approach consistsof several main phases, including formulating the task, choosing LLMs, promptengineering, fine-tuning, and deployment. We start with the discussion ofcritical considerations in identifying healthcare tasks that align with thecore capabilities of LLMs and selecting models based on the selected task anddata, performance requirements, and model interface. We then review thestrategies, such as prompt engineering and fine-tuning, to adapt standard LLMsto specialized medical tasks. Deployment considerations, including regulatorycompliance, ethical guidelines, and continuous monitoring for fairness andbias, are also discussed. By providing a structured step-by-step methodology,this tutorial aims to equip healthcare professionals with the tools necessaryto effectively integrate LLMs into clinical practice, ensuring that thesepowerful technologies are applied in a safe, reliable, and impactful manner.",Qiao Jin,2024-10-24,2024-10-24,https://github.com/ncbi-nlp/llm-medicine-primer,0
2410.18854v1,Preempting Fermion Sign Problem: Unveiling Quantum Criticality through Nonequilibrium Dynamics,http://arxiv.org/abs/2410.18854v1,"The notorious fermion sign problem, arising from fermion statistics,constitutes one of the main obstacles of deciphering quantum many-body systemsby numerical approach. The progress in overcoming sign problem will definitelylead to a great leap in various areas of modern physics. Here, by deviatingfrom the conventional cognition that nonequilibrium studies should be morecomplicated than equilibrium cases, we propose an innovative framework based onnonequilibrium critical dynamics to preempt sign problem and investigatequantum critical point in fermionic model through numerically exact quantumMonte Carlo (QMC) simulation. By virtue of universal scaling theory ofimaginary-time relaxation dynamics, we demonstrate that accurate critical pointand critical exponents can be obtained in the short-time stage, in which thesign problem is not severe such that the QMC is accessible. After confirmingthe effectiveness of the method in two typical interacting fermionic modelsfeaturing Dirac quantum critical point (QCP), we for the first time reveal thequantum phase diagram in the Hubbard model hosting $\rm SU(3)$-symmetric Diracfermions, and find that the QCP between Dirac semi-metal and a$\lambda_8$-antiferromagnetic phase belongs to a new universality classdifferent from the previously known Gross-Neveu transitions.",Yin-Kai Yu,2024-10-24,2024-10-24,,N/A
2410.18851v1,Intention Is All You Need,http://arxiv.org/abs/2410.18851v1,"Among the many narratives of the transformative power of Generative AI is onethat sees in the world a latent nation of programmers who need to wield nothingbut intentions and natural language to render their ideas in software. In thispaper, this outlook is problematised in two ways. First, it is observed thatgenerative AI is not a neutral vehicle of intention. Multiple recent studiespaint a picture of the ""mechanised convergence"" phenomenon, namely, thatgenerative AI has a homogenising effect on intention. Second, it is observedthat the formation of intention itself is immensely challenging. Constraints,materiality, and resistance can offer paths to design metaphors for intentionaltools. Finally, existentialist approaches to intention are discussed andpossible implications for programming are proposed in the form of aspeculative, illustrative set of intentional programming practices.",Advait Sarkar,2024-10-24,2024-10-24,,N/A
2410.18850v1,We Augmented Whisper With kNN and You Won't Believe What Came Next,http://arxiv.org/abs/2410.18850v1,"Speech recognition performance varies by language, domain, and speakercharacteristics such as accent, and fine-tuning a model on any of thesecategories may lead to catastrophic forgetting. $k$ nearest neighbor search($k$NN), first proposed for neural sequence decoders for natural languagegeneration (NLG) and machine translation (MT), is a non-parametric method thatcan instead adapt by building an external datastore that can then be searchedduring inference time, without training the underlying model. We show thatWhisper, a transformer end-to-end speech model, benefits from $k$NN. Weinvestigate the differences between the speech and text setups. We discussimplications for speaker adaptation, and analyze improvements by gender,accent, and age.",Maya K. Nachesa,2024-10-24,2024-10-24,,N/A
2410.18848v1,Sensing Accuracy Optimization for Communication-assisted Dual-baseline UAV-InSAR,http://arxiv.org/abs/2410.18848v1,"In this paper, we study the optimization of the sensing accuracy of unmannedaerial vehicle (UAV)-based dual-baseline interferometric synthetic apertureradar (InSAR) systems. A swarm of three UAV-synthetic aperture radar (SAR)systems is deployed to image an area of interest from different angles,enabling the creation of two independent digital elevation models (DEMs). Toreduce the InSAR sensing error, i.e., the height estimation error, the two DEMsare fused based on weighted average techniques into one final DEM. The heavycomputations required for this process are performed on the ground. To thisend, the radar data is offloaded in real time via a frequency division multipleaccess (FDMA) air-to-ground backhaul link. In this work, we focus on improvingthe sensing accuracy by minimizing the worst-case height estimation error ofthe final DEM. To this end, the UAV formation and the power allocated foroffloading are jointly optimized based on alternating optimization (AO), whilemeeting practical InSAR sensing and communication constraints. Our simulationresults demonstrate that the proposed solution can improve the sensing accuracyby over 39% compared to a classical single-baseline UAV-InSAR system and bymore than 12% compared to other benchmark schemes.",Mohamed-Amine Lahmeri,2024-10-24,2024-10-24,,N/A
2410.18847v1,A novel quantum machine learning classifier to search for new physics,http://arxiv.org/abs/2410.18847v1,"Due to the success of the Standard Model~(SM), it is reasonable to anticipatethat, the signal of new physics~(NP) beyond the SM is small, and futuresearches for NP and precision tests of the SM will require high luminositycollider experiments. Moreover, as the precision tests of the SM advances,rarer processes with a greater number of final-state particles will requireconsideration, which will in turn require the analysis of a multitude ofobservables. As an inherent consequence of the high luminosity, the generationof a large amount of experimental data in a large feature space presents asignificant challenge for data processing. In recent years, quantum machinelearning has emerged as a promising approach for processing large amounts ofcomplex data on a quantum computer. In this study, we propose a variationalquantum searching neighbor~(VQSN) algorithm to search for NP. As an example, weapply the VQSN in the phenomenological study of the gluon quartic gaugecouplings~(gQGCs) at the Large Hadron Collider. The results suggest that VQSNdemonstrates superior efficiency to a classical counterpart k-nearest neighboralgorithm, even when dealing with classical data.",Ji-Chong Yang,2024-10-24,2024-10-24,,N/A
2410.18844v1,Learning to Explore with Lagrangians for Bandits under Unknown Linear Constraints,http://arxiv.org/abs/2410.18844v1,"Pure exploration in bandits models multiple real-world problems, such astuning hyper-parameters or conducting user studies, where different safety,resource, and fairness constraints on the decision space naturally appear. Westudy these problems as pure exploration in multi-armed bandits with unknownlinear constraints, where the aim is to identify an $r$$\textit{-good feasiblepolicy}$. First, we propose a Lagrangian relaxation of the sample complexitylower bound for pure exploration under constraints. We show how this lowerbound evolves with the sequential estimation of constraints. Second, weleverage the Lagrangian lower bound and the properties of convex optimisationto propose two computationally efficient extensions of Track-and-Stop andGamified Explorer, namely LATS and LAGEX. To this end, we propose aconstraint-adaptive stopping rule, and while tracking the lower bound, usepessimistic estimate of the feasible set at each step. We show that thesealgorithms achieve asymptotically optimal sample complexity upper bounds up toconstraint-dependent constants. Finally, we conduct numerical experiments withdifferent reward distributions and constraints that validate efficientperformance of LAGEX and LATS with respect to baselines.",Udvas Das,2024-10-24,2024-10-24,,N/A
2410.18843v1,Multi-qubit entanglement swapping with squeezed modes,http://arxiv.org/abs/2410.18843v1,"We present a hybrid continuous variable-discrete variable entanglementswapping protocol using linear optics and homodyne measurements, capable ofproducing a large number of high-fidelity Bell pairs per signal, with anapproximate $0.5$ probability of success. The effectiveness of the protocol isdetermined by the squeezing strength. To increase the number of Bell pairs,approximately 3 dB of extra squeezing is needed for each additional Bell pair.The protocol also generates single Bell pairs with an approximate $0.75$probability for squeezing strengths $\lessapprox 15dB$, achievable with currenttechnology.",Alexandru Macridin,2024-10-24,2024-10-24,,N/A
2410.18842v1,A diffusion MRI model for random walks confined on cylindrical surfaces: Towards non-invasive quantification of myelin sheath radius,http://arxiv.org/abs/2410.18842v1,"Quantifying the myelin sheath radius of myelinated axons in vivo is importantfor understanding, diagnosing, and monitoring various neurological disorders.Despite advancements in diffusion MRI (dMRI) microstructure techniques, modelsspecifically designed to estimate myelin sheath radii remain unavailable. Inthis proof-of-concept theoretical study, we present two novel dMRI models thatcharacterize the signal from water diffusion confined to cylindrical surfaces,approximating myelin water diffusion. We derive their spherical mean signals,which conveniently eliminate fiber orientation and dispersion effects. Thesemodels are further extended to account for multiple concentric cylinders,mimicking the layered structure of myelin. Additionally, we introduce a methodto convert histological distributions of axonal inner radii from the literatureinto myelin sheath radius distributions and derive analytical expressions toestimate the effective myelin sheath radius expected from these distributions.Monte Carlo (MC) simulations conducted in cylindrical and spiral geometriesvalidate the models, demonstrating agreement with analytical predictions acrossvarious diffusion regimes and significant correlations between the effectiveradii estimated from the histological distributions and the effective radiusobtained by fitting the resulting dMRI signal to a single-cylinder model. Thesemodels may be integrated into existing multi-compartment dMRI techniques,opening the door to non-invasive, in vivo assessments of myelin sheath radii inMRI scanners equipped with strong diffusion gradients that enable measurementswith short echo times. Further work is required to validate the technique withreal dMRI data.",Erick J Canales-RodrÃ­guez,2024-10-24,2024-10-24,,N/A
2410.18841v1,From Efficiency to Equity: Measuring Fairness in Preference Learning,http://arxiv.org/abs/2410.18841v1,"As AI systems, particularly generative models, increasingly influencedecision-making, ensuring that they are able to fairly represent diverse humanpreferences becomes crucial. This paper introduces a novel framework forevaluating epistemic fairness in preference learning models inspired byeconomic theories of inequality and Rawlsian justice. We propose metricsadapted from the Gini Coefficient, Atkinson Index, and Kuznets Ratio toquantify fairness in these models. We validate our approach using two datasets:a custom visual preference dataset (AI-EDI-Space) and the Jester Jokes dataset.Our analysis reveals variations in model performance across users, highlightingpotential epistemic injustices. We explore pre-processing and in-processingtechniques to mitigate these inequalities, demonstrating a complex relationshipbetween model efficiency and fairness. This work contributes to AI ethics byproviding a framework for evaluating and improving epistemic fairness inpreference learning models, offering insights for developing more inclusive AIsystems in contexts where diverse human preferences are crucial.",Shreeyash Gowaikar,2024-10-24,2024-10-24,,N/A
2410.18837v1,High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws,http://arxiv.org/abs/2410.18837v1,"A growing number of machine learning scenarios rely on knowledge distillationwhere one uses the output of a surrogate model as labels to supervise thetraining of a target model. In this work, we provide a sharp characterizationof this process for ridgeless, high-dimensional regression, under two settings:(i) model shift, where the surrogate model is arbitrary, and (ii) distributionshift, where the surrogate model is the solution of empirical risk minimizationwith out-of-distribution data. In both cases, we characterize the precise riskof the target model through non-asymptotic bounds in terms of sample size anddata distribution under mild conditions. As a consequence, we identify the formof the optimal surrogate model, which reveals the benefits and limitations ofdiscarding weak features in a data-dependent fashion. In the context ofweak-to-strong (W2S) generalization, this has the interpretation that (i) W2Straining, with the surrogate as the weak model, can provably outperformtraining with strong labels under the same data budget, but (ii) it is unableto improve the data scaling law. We validate our results on numericalexperiments both on ridgeless regression and on neural network architectures.",M. Emrullah Ildiz,2024-10-24,2024-10-24,,N/A
2410.18836v1,From English-Centric to Effective Bilingual: LLMs with Custom Tokenizers for Underrepresented Languages,http://arxiv.org/abs/2410.18836v1,"In this paper, we propose a model-agnostic cost-effective approach todeveloping bilingual base large language models (LLMs) to support English andany target language. The method includes vocabulary expansion, initializationof new embeddings, model training and evaluation. We performed our experimentswith three languages, each using a non-Latin script - Ukrainian, Arabic, andGeorgian.  Our approach demonstrates improved language performance while reducingcomputational costs. It mitigates the disproportionate penalization ofunderrepresented languages, promoting fairness and minimizing adverse phenomenasuch as code-switching and broken grammar. Additionally, we introduce newmetrics to evaluate language quality, revealing that vocabulary sizesignificantly impacts the quality of generated text.",Artur Kiulian,2024-10-24,2024-10-24,,N/A
2410.18835v1,Diffusion for Multi-Embodiment Grasping,http://arxiv.org/abs/2410.18835v1,"Grasping is a fundamental skill in robotics with diverse applications acrossmedical, industrial, and domestic domains. However, current approaches forpredicting valid grasps are often tailored to specific grippers, limiting theirapplicability when gripper designs change. To address this limitation, weexplore the transfer of grasping strategies between various gripper designs,enabling the use of data from diverse sources. In this work, we present anapproach based on equivariant diffusion that facilitates gripper-agnosticencoding of scenes containing graspable objects and gripper-aware decoding ofgrasp poses by integrating gripper geometry into the model. We also develop adataset generation framework that produces cluttered scenes with variable-sizedobject heaps, improving the training of grasp synthesis methods. Experimentalevaluation on diverse object datasets demonstrates the generalizability of ourapproach across gripper architectures, ranging from simple parallel-jawgrippers to humanoid hands, outperforming both single-gripper and multi-gripperstate-of-the-art methods.",Roman Freiberg,2024-10-24,2024-10-24,,N/A
2410.18834v1,Highly efficient non-rigid registration in k-space with application to cardiac Magnetic Resonance Imaging,http://arxiv.org/abs/2410.18834v1,"In Magnetic Resonance Imaging (MRI), high temporal-resolved motion can beuseful for image acquisition and reconstruction, MR-guided radiotherapy,dynamic contrast-enhancement, flow and perfusion imaging, and functionalassessment of motion patterns in cardiovascular, abdominal, peristaltic, fetal,or musculoskeletal imaging. Conventionally, these motion estimates are derivedthrough image-based registration, a particularly challenging task for complexmotion patterns and high dynamic resolution. The accelerated scans in suchapplications result in imaging artifacts that compromise the motion estimation.In this work, we propose a novel self-supervised deep learning-based framework,dubbed the Local-All Pass Attention Network (LAPANet), for non-rigid motionestimation directly from the acquired accelerated Fourier space, i.e. k-space.The proposed approach models non-rigid motion as the cumulative sum of localtranslational displacements, following the Local All-Pass (LAP) registrationtechnique. LAPANet was evaluated on cardiac motion estimation across varioussampling trajectories and acceleration rates. Our results demonstrate superioraccuracy compared to prior conventional and deep learning-based registrationmethods, accommodating as few as 2 lines/frame in a Cartesian trajectory and 3spokes/frame in a non-Cartesian trajectory. The achieved high temporalresolution (less than 5 ms) for non-rigid motion opens new avenues for motiondetection, tracking and correction in dynamic and real-time MRI applications.",Aya Ghoul,2024-10-24,2024-10-24,https://github.com/lab-midas/LAPANet,0
2410.18832v1,"MazeNet: An Accurate, Fast, and Scalable Deep Learning Solution for Steiner Minimum Trees",http://arxiv.org/abs/2410.18832v1,"The Obstacle Avoiding Rectilinear Steiner Minimum Tree (OARSMT) problem,which seeks the shortest interconnection of a given number of terminals in arectilinear plane while avoiding obstacles, is a critical task in integratedcircuit design, network optimization, and robot path planning. Since OARSMT isNP-hard, exact algorithms scale poorly with the number of terminals, leadingpractical solvers to sacrifice accuracy for large problems. We propose MazeNet,a deep learning-based method that learns to solve the OARSMT from data. MazeNetreframes OARSMT as a maze-solving task that can be addressed with a recurrentconvolutional neural network (RCNN). A key hallmark of MazeNet is itsscalability: we only need to train the RCNN blocks on mazes with a small numberof terminals; larger mazes can be solved by replicating the same pre-trainedblocks to create a larger network. Across a wide range of experiments, MazeNetachieves perfect OARSMT-solving accuracy, significantly reduces runtimecompared to classical exact algorithms, and can handle more terminals thanstate-of-the-art approximate algorithms.",Gabriel DÃ­az Ramos,2024-10-24,2024-10-24,,N/A
2410.18830v1,Multi-Scale Diffusion: Enhancing Spatial Layout in High-Resolution Panoramic Image Generation,http://arxiv.org/abs/2410.18830v1,"Diffusion models have recently gained recognition for generating diverse andhigh-quality content, especially in the domain of image synthesis. These modelsexcel not only in creating fixed-size images but also in producing panoramicimages. However, existing methods often struggle with spatial layoutconsistency when producing high-resolution panoramas, due to the lack ofguidance of the global image layout. In this paper, we introduce theMulti-Scale Diffusion (MSD) framework, a plug-and-play module that extends theexisting panoramic image generation framework to multiple resolution levels. Byutilizing gradient descent techniques, our method effectively incorporatesstructural information from low-resolution images into high-resolution outputs.A comprehensive evaluation of the proposed method was conducted, comparing itwith the prior works in qualitative and quantitative dimensions. The evaluationresults demonstrate that our method significantly outperforms others ingenerating coherent high-resolution panoramas.",Xiaoyu Zhang,2024-10-24,2024-10-24,,N/A
2410.18827v1,Investigation of the nature of the wind interaction in HD93205 based on multi-epoch X-ray observations,http://arxiv.org/abs/2410.18827v1,"The study of the X-ray emission from massive binaries constitutes a relevantapproach to investigate shock physics. The case of short period binaries mayturn out to be quite challenging, especially in very asymmetric systems wherethe primary wind may overwhelm that of the secondary in the wind interaction.Our objective consists in providing an observational diagnostic of the X-raybehaviour of HD93205, that is a very good candidate to investigate theseaspects. We analysed 31 epochs of XMM-Newton X-ray data spanning about twodecades to investigate its spectral and timing behaviour. The X-ray spectrum isvery soft along the full orbit, with a luminosity exclusively from the windinteraction region in the range of 2.3 --5.4\,$\times$10$^{32}$\,erg\,s$^{-1}$. The light curve peaks close toperiastron, with a rather wide pre-periastron low-state coincident with thesecondary's body hiding a part of the X-ray emitting region close to itssurface. We determined a variability time scale of 6.0807\,$\pm$\,0.0013\,d, infull agreement with the orbital period. Making use of a one-dimensionalapproach to deal with mutual radiative effects, our results point to a verylikely hybrid wind interaction, with a wind-photosphere occurring along most ofthe orbit, while a brief episode of wind-wind interaction may still developclose to apastron. Beside mutual radiative effects, the radiative nature of theshock that leads to some additional pre-shock obliquitity of the primary windflow certainly explains the very soft emission. HD93205 constitutes a relevanttarget to investigate shock physics in short period, asymmetric massive binarysystems, where various mutual radiative effects and radiative shocks concur todisplay an instructive soft X-ray behaviour. HD93205 should be considered as avalid, though challenging target for future three-dimensional modellinginitiatives.",Bharti Arora,2024-10-24,2024-10-24,,N/A
2410.18826v1,Tetragonal BaCoO$_3$: A Co$^{4+}$ Ferromagnetic Mott Insulator with Inverted Spin Crossover,http://arxiv.org/abs/2410.18826v1,"The interplay between crystal electric field splitting of d states and Hund'srule exchange energy in cobalt-based perovskites offers a promising avenue forinducing spin-state transitions. This study reports a new body-centeredtetragonal (BCT) phase of BaCoO$_3$ (BCT-BaCoO$_3$), synthesized under highpressure (15 GPa) and high temperature (1200 {\deg}C) conditions. BCT-BaCoO$_3$adopts a double perovskite structure of EuTiO$_3$-type (space group I4/mcm,#140), confirmed by high-resolution scanning transmission electron microscopy.X-ray photoelectron spectroscopy reveals a rare Co$^{4+}$ valence state.Magnetization and X-ray absorption measurements reveal a low-spin to high-spintransition that takes place between 200 and 300 K. While spin crossovers arerelatively common among common oxides, the one observed in BCT-BaCoO$_3$ isremarkable in that it proceeds in the opposite direction from conventional spintransitions. BCT-BaCoO$_3$ exhibits a low-spin (S = 1/2) state at hightemperatures and transitions to a high-spin (S = 5/2) state at lowtemperatures. Within the high-spin state, hard ferromagnetic order onsets atT$_C$ = 107 K. Electrical resistivity indicates weak magnetoresistance andinsulating behavior. Overall, BCT-BaCoO$_3$ presents an exceptional model forthe exploration of spin-state transitions and the study of Co spin states incobalt-based perovskites.",Mingyu Xu,2024-10-24,2024-10-24,,N/A
2410.18824v1,PSY: Posterior Sampling Based Privacy Enhancer in Large Language Models,http://arxiv.org/abs/2410.18824v1,"Privacy vulnerabilities in LLMs, such as leakage from memorization, have beenconstantly identified, and various mitigation proposals have been proposed.LoRA is usually used in fine-tuning LLMs and a good entry point to insertprivacy-enhancing modules. In this ongoing research, we introduce PSY, aPosterior Sampling based PrivacY enhancer that can be used in LoRA. We proposea simple yet effective realization of PSY using posterior sampling, whicheffectively prevents privacy leakage from intermediate information and, inturn, preserves the privacy of data owners. We evaluate LoRA extended with PSYagainst state-of-the-art membership inference and data extraction attacks. Theexperiments are executed on three different LLM architectures fine-tuned onthree datasets with LoRA. In contrast to the commonly used differential privacymethod, we find that our proposed modification consistently reduces the attacksuccess rate. Meanwhile, our method has almost no negative impact on modelfine-tuning or final performance. Most importantly, PSY reveals a promisingpath toward privacy enhancement with latent space extensions.",Yulian Sun,2024-10-24,2024-10-24,,N/A
